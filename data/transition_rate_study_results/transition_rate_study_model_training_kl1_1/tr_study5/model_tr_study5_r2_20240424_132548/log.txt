Args:
Namespace(name='model_tr_study5', outdir='out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2', training_data='data/transition_rate_studies/tr_study5/tr_study5_training/r2', validation_data='data/transition_rate_studies/tr_study5/tr_study5_validation/r2', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1946758289

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.990484588089146		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.990484588089146 | validation: 8.279003283250656]
	TIME [epoch: 112 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.110712467551304		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.110712467551304 | validation: 7.794690665309336]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.489951198988746		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.489951198988746 | validation: 7.214961978622377]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.021879242862073		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.021879242862073 | validation: 6.719836313683963]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.656705884567623		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.656705884567623 | validation: 6.74613354893527]
	TIME [epoch: 24.8 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.514317360098136		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.514317360098136 | validation: 6.223847213387306]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.4085923670459195		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.4085923670459195 | validation: 6.72962964842422]
	TIME [epoch: 24.8 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.337681209525029		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.337681209525029 | validation: 6.079439020974424]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.069778402889628		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.069778402889628 | validation: 5.802568086717314]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.944065128715632		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.944065128715632 | validation: 5.748085483154815]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.870600924566564		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.870600924566564 | validation: 5.675824300485553]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.846626763685205		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.846626763685205 | validation: 5.677689670400094]
	TIME [epoch: 24.8 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.866476645735604		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.866476645735604 | validation: 5.4650860385231885]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.76109589034639		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.76109589034639 | validation: 5.702522037741703]
	TIME [epoch: 24.8 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7285681541011675		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.7285681541011675 | validation: 5.455701773960373]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.703094151101485		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.703094151101485 | validation: 5.500209614793461]
	TIME [epoch: 24.9 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.73466088293834		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.73466088293834 | validation: 5.6320052695428675]
	TIME [epoch: 24.8 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.6724568201139265		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.6724568201139265 | validation: 5.601371933143629]
	TIME [epoch: 24.9 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.910797974098083		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.910797974098083 | validation: 5.32654923901807]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.638071949101711		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.638071949101711 | validation: 5.929853341574065]
	TIME [epoch: 24.8 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.696814315369446		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.696814315369446 | validation: 5.418401743747317]
	TIME [epoch: 24.9 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.837342003948465		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.837342003948465 | validation: 6.887662018545647]
	TIME [epoch: 24.8 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8790423485631145		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.8790423485631145 | validation: 5.317977730368985]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.510459170905163		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.510459170905163 | validation: 5.286454875236116]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.489853929492709		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.489853929492709 | validation: 5.245580241355005]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.427444447840584		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.427444447840584 | validation: 5.188485384436933]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.346663614980793		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.346663614980793 | validation: 5.168169009870807]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.522027834336831		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.522027834336831 | validation: 5.638001286230085]
	TIME [epoch: 24.8 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.439053664765617		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.439053664765617 | validation: 5.10801188288353]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.300284727474221		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.300284727474221 | validation: 4.817293856241401]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.84958808921653		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.84958808921653 | validation: 11.28841994188387]
	TIME [epoch: 24.8 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.477236400549849		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.477236400549849 | validation: 5.2755504377698825]
	TIME [epoch: 24.9 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.658701705415314		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.658701705415314 | validation: 5.212560646256361]
	TIME [epoch: 24.8 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.40543813952631		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.40543813952631 | validation: 5.177820229473002]
	TIME [epoch: 24.9 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.33824076923439		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.33824076923439 | validation: 4.919297958579328]
	TIME [epoch: 24.8 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.14725502475886		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.14725502475886 | validation: 6.783789263767903]
	TIME [epoch: 24.8 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.296395205788753		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.296395205788753 | validation: 5.234504204278157]
	TIME [epoch: 24.8 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.5306601755582525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.5306601755582525 | validation: 5.05965251199201]
	TIME [epoch: 24.8 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.297288639147114		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.297288639147114 | validation: 4.886123980178897]
	TIME [epoch: 24.8 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.323397530009734		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.323397530009734 | validation: 4.86430022006938]
	TIME [epoch: 24.8 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.014704429773437		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.014704429773437 | validation: 4.758155245301531]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.050619834358201		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.050619834358201 | validation: 4.466615551335608]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.8620054926257055		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.8620054926257055 | validation: 4.505314956127994]
	TIME [epoch: 24.8 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.821911734424863		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.821911734424863 | validation: 6.124399552702576]
	TIME [epoch: 24.9 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.936822166804548		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.936822166804548 | validation: 6.385669468361179]
	TIME [epoch: 24.8 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.382970833168679		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.382970833168679 | validation: 4.441361582147985]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.625689812507913		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.625689812507913 | validation: 4.345277504466848]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.624366119803501		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.624366119803501 | validation: 4.247812325699732]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.119770980168925		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.119770980168925 | validation: 4.874501064405668]
	TIME [epoch: 24.8 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.956563176348034		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.956563176348034 | validation: 4.4319286578242325]
	TIME [epoch: 24.9 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.403153895676338		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 4.403153895676338 | validation: 4.189813135255044]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.764456997021516		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 4.764456997021516 | validation: 4.410586632090837]
	TIME [epoch: 24.8 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4109604196230645		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 4.4109604196230645 | validation: 3.9151864957892895]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.731251525726313		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 4.731251525726313 | validation: 4.486796232726622]
	TIME [epoch: 24.9 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6036648414770625		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 4.6036648414770625 | validation: 4.696368986309546]
	TIME [epoch: 24.8 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.6463147670673735		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 5.6463147670673735 | validation: 4.395659441718485]
	TIME [epoch: 24.9 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.3399556322714075		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 4.3399556322714075 | validation: 4.044485688040503]
	TIME [epoch: 24.9 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.465254388012515		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 4.465254388012515 | validation: 4.353448628478721]
	TIME [epoch: 24.8 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.390143934291888		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 4.390143934291888 | validation: 4.0335047836864915]
	TIME [epoch: 24.9 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.432381107572349		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 4.432381107572349 | validation: 4.504596405512002]
	TIME [epoch: 24.9 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.85865247837478		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 4.85865247837478 | validation: 4.342514350868824]
	TIME [epoch: 24.8 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4027493796856		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 4.4027493796856 | validation: 4.059795844756451]
	TIME [epoch: 24.9 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.242857243954627		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 4.242857243954627 | validation: 3.711221681175815]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.716473231532811		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 4.716473231532811 | validation: 4.689482901803475]
	TIME [epoch: 24.8 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.300196480634783		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 4.300196480634783 | validation: 3.7328653436599364]
	TIME [epoch: 24.9 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.680777473510149		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 4.680777473510149 | validation: 4.087644113942665]
	TIME [epoch: 24.9 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6846244960685866		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 4.6846244960685866 | validation: 3.757000693061233]
	TIME [epoch: 24.8 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8862066190947426		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 3.8862066190947426 | validation: 4.021266573200746]
	TIME [epoch: 24.9 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.253837107046395		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 4.253837107046395 | validation: 3.8977370394055186]
	TIME [epoch: 24.9 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.901894489711767		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 4.901894489711767 | validation: 4.518954931824842]
	TIME [epoch: 24.8 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0325096001424985		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 4.0325096001424985 | validation: 3.7531146362571906]
	TIME [epoch: 24.9 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.709254744945314		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 3.709254744945314 | validation: 3.5135060513125946]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6872512494462195		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 3.6872512494462195 | validation: 4.221656026971042]
	TIME [epoch: 24.8 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.073206188081512		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 4.073206188081512 | validation: 4.163692067605482]
	TIME [epoch: 24.8 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9385735652911977		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 3.9385735652911977 | validation: 3.857249920042509]
	TIME [epoch: 24.8 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7744322749704393		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 3.7744322749704393 | validation: 3.3644296341110005]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.085708114631389		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 4.085708114631389 | validation: 8.371069369405225]
	TIME [epoch: 24.8 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.575316914927883		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 7.575316914927883 | validation: 5.458880088617402]
	TIME [epoch: 24.8 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.196054693736308		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 4.196054693736308 | validation: 4.895146586423936]
	TIME [epoch: 24.7 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.553310968470645		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 5.553310968470645 | validation: 4.74137835665371]
	TIME [epoch: 24.8 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.412178161147106		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 4.412178161147106 | validation: 5.844953872160286]
	TIME [epoch: 24.8 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.443341408278467		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 4.443341408278467 | validation: 4.072503759580187]
	TIME [epoch: 24.8 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9953037489480945		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 3.9953037489480945 | validation: 3.759449678803636]
	TIME [epoch: 24.8 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7243103589493898		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 3.7243103589493898 | validation: 3.406484540926847]
	TIME [epoch: 24.8 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.042036189338758		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 4.042036189338758 | validation: 3.5652050799460016]
	TIME [epoch: 24.8 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.463232011572853		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 3.463232011572853 | validation: 3.133803842472826]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_86.pth
	Model improved!!!
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1608049591260716		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 3.1608049591260716 | validation: 3.291625272573242]
	TIME [epoch: 24.9 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.541439106031654		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 3.541439106031654 | validation: 4.165418865491822]
	TIME [epoch: 24.8 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2650762200674324		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 3.2650762200674324 | validation: 2.938057037660988]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_89.pth
	Model improved!!!
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0304697180467377		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 3.0304697180467377 | validation: 3.4199366007897987]
	TIME [epoch: 24.9 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1399126253293677		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 3.1399126253293677 | validation: 3.0391049639643035]
	TIME [epoch: 24.8 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8457150913353293		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 2.8457150913353293 | validation: 2.608184726710342]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_92.pth
	Model improved!!!
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7508912040326203		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 2.7508912040326203 | validation: 2.57039993795264]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_93.pth
	Model improved!!!
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.060911627808143		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 6.060911627808143 | validation: 6.448293831939968]
	TIME [epoch: 24.7 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.123347277122826		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 4.123347277122826 | validation: 2.69896332807288]
	TIME [epoch: 24.8 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6606345232385724		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 2.6606345232385724 | validation: 2.5877791149540927]
	TIME [epoch: 24.8 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6070922987199925		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 2.6070922987199925 | validation: 2.4351769603968725]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.588677850199647		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 2.588677850199647 | validation: 2.6470176889747234]
	TIME [epoch: 24.8 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5219668380288254		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 2.5219668380288254 | validation: 2.9002490460102597]
	TIME [epoch: 24.8 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.678677398121223		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 2.678677398121223 | validation: 2.4015983431575263]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_100.pth
	Model improved!!!
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4321804555898354		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 2.4321804555898354 | validation: 2.3816259504224586]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_101.pth
	Model improved!!!
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9434713154264838		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 2.9434713154264838 | validation: 3.0623253204801397]
	TIME [epoch: 24.9 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.436693698942637		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 2.436693698942637 | validation: 2.0984819055692334]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_103.pth
	Model improved!!!
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7787929585306017		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 3.7787929585306017 | validation: 3.1083847508373523]
	TIME [epoch: 24.8 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.873985256435903		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 2.873985256435903 | validation: 2.238562139152446]
	TIME [epoch: 24.8 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.438788542390965		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 2.438788542390965 | validation: 2.8511139384758986]
	TIME [epoch: 24.8 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8808693419106244		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 2.8808693419106244 | validation: 2.451778186151332]
	TIME [epoch: 24.8 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.675301801903336		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 2.675301801903336 | validation: 2.2054921358504176]
	TIME [epoch: 24.8 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.149759578662317		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 2.149759578662317 | validation: 2.2659691695342876]
	TIME [epoch: 24.8 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4848037477882565		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 2.4848037477882565 | validation: 2.0126407810728155]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_110.pth
	Model improved!!!
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.133564491745913		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 3.133564491745913 | validation: 4.309968820365635]
	TIME [epoch: 24.8 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5494257129509683		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 3.5494257129509683 | validation: 2.1806972445225434]
	TIME [epoch: 24.8 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4432054609420413		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 2.4432054609420413 | validation: 2.050977978260468]
	TIME [epoch: 24.9 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4994614334259455		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 2.4994614334259455 | validation: 3.430238569705669]
	TIME [epoch: 24.8 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.787921993006237		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 2.787921993006237 | validation: 2.7836730633021047]
	TIME [epoch: 24.8 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.398562602572908		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 2.398562602572908 | validation: 2.3825424013467646]
	TIME [epoch: 24.8 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.307883717816276		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 2.307883717816276 | validation: 5.934619428595815]
	TIME [epoch: 24.8 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.89443710470781		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 4.89443710470781 | validation: 2.496584530425962]
	TIME [epoch: 24.8 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4100311293150707		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 2.4100311293150707 | validation: 2.1426375556743773]
	TIME [epoch: 24.9 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.311140815342963		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 2.311140815342963 | validation: 2.30773196385467]
	TIME [epoch: 24.8 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1657566694329953		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 2.1657566694329953 | validation: 2.0458567509792416]
	TIME [epoch: 24.8 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9481119937241245		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 1.9481119937241245 | validation: 1.9462295112914172]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_122.pth
	Model improved!!!
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.428357797800758		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 2.428357797800758 | validation: 3.5898783431867867]
	TIME [epoch: 24.8 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.723329162659803		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 2.723329162659803 | validation: 2.5049267086672007]
	TIME [epoch: 24.8 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9855294641441927		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 1.9855294641441927 | validation: 2.096365424372518]
	TIME [epoch: 24.8 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1542299071194453		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 2.1542299071194453 | validation: 2.334904098771781]
	TIME [epoch: 24.9 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9926726730645052		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 1.9926726730645052 | validation: 2.1858813325973494]
	TIME [epoch: 24.8 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.024437043456022		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 4.024437043456022 | validation: 2.8074103555394534]
	TIME [epoch: 24.8 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9842906516253564		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 2.9842906516253564 | validation: 2.84238525458417]
	TIME [epoch: 24.8 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.218998063423508		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 2.218998063423508 | validation: 2.4241362867291794]
	TIME [epoch: 24.8 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7202652049073444		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 2.7202652049073444 | validation: 2.388962533705814]
	TIME [epoch: 24.8 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.536707563107465		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 2.536707563107465 | validation: 2.859605820745746]
	TIME [epoch: 24.8 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.285459219212103		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 2.285459219212103 | validation: 2.409500870075957]
	TIME [epoch: 24.8 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.991224327006886		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 5.991224327006886 | validation: 6.596645666541238]
	TIME [epoch: 24.8 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.607588045012642		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 5.607588045012642 | validation: 4.498051563310037]
	TIME [epoch: 24.8 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.90853092473816		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 2.90853092473816 | validation: 2.034933444358435]
	TIME [epoch: 24.8 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1404780433070787		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 2.1404780433070787 | validation: 1.5954127951849473]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_137.pth
	Model improved!!!
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.228466974878341		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 2.228466974878341 | validation: 2.1852125530338666]
	TIME [epoch: 24.8 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.048319961974191		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 2.048319961974191 | validation: 1.4946400134563846]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_139.pth
	Model improved!!!
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0354481783614053		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 2.0354481783614053 | validation: 2.0752239024426116]
	TIME [epoch: 24.8 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8267732090772073		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 1.8267732090772073 | validation: 2.2739994446505443]
	TIME [epoch: 24.8 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2461457062965784		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 2.2461457062965784 | validation: 1.6883153949511456]
	TIME [epoch: 24.8 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9687696393935976		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 1.9687696393935976 | validation: 1.5109006218896373]
	TIME [epoch: 24.8 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7878740473442192		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 1.7878740473442192 | validation: 1.4932274684241091]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_144.pth
	Model improved!!!
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8038361517431303		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 1.8038361517431303 | validation: 1.3344326238964102]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_145.pth
	Model improved!!!
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.107763518784061		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 2.107763518784061 | validation: 2.297999079649481]
	TIME [epoch: 24.8 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6424484652917826		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 1.6424484652917826 | validation: 1.4590604589130118]
	TIME [epoch: 24.8 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.511170805425705		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 1.511170805425705 | validation: 1.4213270804370666]
	TIME [epoch: 24.8 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7494910227765155		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 1.7494910227765155 | validation: 1.860541957858214]
	TIME [epoch: 24.9 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7225886037314448		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 1.7225886037314448 | validation: 2.1883531687858504]
	TIME [epoch: 24.9 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9686288739944002		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 1.9686288739944002 | validation: 1.3516897540808597]
	TIME [epoch: 24.8 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9932469656519016		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 1.9932469656519016 | validation: 1.5803099154224822]
	TIME [epoch: 24.9 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5478710158243811		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 1.5478710158243811 | validation: 1.3697515786654035]
	TIME [epoch: 24.9 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.331344868324436		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 2.331344868324436 | validation: 3.7186106656343716]
	TIME [epoch: 24.8 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.62353640285635		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 2.62353640285635 | validation: 1.6559913030555056]
	TIME [epoch: 24.9 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.975829709303924		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 1.975829709303924 | validation: 1.7378854275449755]
	TIME [epoch: 24.9 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8972553800086494		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 1.8972553800086494 | validation: 1.5448108818046047]
	TIME [epoch: 24.8 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.975459300015505		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 1.975459300015505 | validation: 2.1804429392190934]
	TIME [epoch: 24.9 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8338704544156652		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 1.8338704544156652 | validation: 1.4869599184892104]
	TIME [epoch: 24.9 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8561720743196417		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 1.8561720743196417 | validation: 1.6032239591695108]
	TIME [epoch: 24.9 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.839742468614103		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 1.839742468614103 | validation: 1.3697402356787032]
	TIME [epoch: 24.9 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.795770232464002		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 1.795770232464002 | validation: 1.3661407529438756]
	TIME [epoch: 24.9 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.644777869384891		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 1.644777869384891 | validation: 1.863094578419846]
	TIME [epoch: 24.8 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7862583560553882		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 1.7862583560553882 | validation: 1.0717746863171025]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_164.pth
	Model improved!!!
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6698681851296446		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 1.6698681851296446 | validation: 6.082686736192479]
	TIME [epoch: 24.9 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5896959393108627		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 3.5896959393108627 | validation: 1.5850696023177995]
	TIME [epoch: 24.9 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9255422845190961		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 1.9255422845190961 | validation: 1.2322325714286324]
	TIME [epoch: 24.9 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3089679852681628		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 1.3089679852681628 | validation: 1.246258360278346]
	TIME [epoch: 24.9 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.331890241845168		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 1.331890241845168 | validation: 1.0290663093957768]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_169.pth
	Model improved!!!
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1865841131876582		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 1.1865841131876582 | validation: 1.1481832730073578]
	TIME [epoch: 24.9 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3955967234318878		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 1.3955967234318878 | validation: 1.6165309899506508]
	TIME [epoch: 24.9 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.402762509216315		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 1.402762509216315 | validation: 2.4727727767186103]
	TIME [epoch: 24.8 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6134057684380099		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 1.6134057684380099 | validation: 1.225865086787785]
	TIME [epoch: 24.9 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.15287779159457		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 1.15287779159457 | validation: 0.8500999273972074]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_174.pth
	Model improved!!!
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4617559789864143		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 1.4617559789864143 | validation: 0.9695369694696437]
	TIME [epoch: 24.8 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1553679226632532		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 1.1553679226632532 | validation: 1.0449844110680055]
	TIME [epoch: 24.9 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.385590118864632		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 2.385590118864632 | validation: 1.2790322507574703]
	TIME [epoch: 24.9 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.410766058823881		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 1.410766058823881 | validation: 1.068995614097978]
	TIME [epoch: 24.8 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3217803207315644		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 1.3217803207315644 | validation: 0.7745939105581446]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_179.pth
	Model improved!!!
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.104079922197326		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 1.104079922197326 | validation: 0.9583294767746102]
	TIME [epoch: 24.9 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2276965941448788		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 1.2276965941448788 | validation: 3.098801493372904]
	TIME [epoch: 24.8 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.335299287962901		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 2.335299287962901 | validation: 1.5922721245173128]
	TIME [epoch: 24.9 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5775826897516363		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 1.5775826897516363 | validation: 1.000569941629138]
	TIME [epoch: 24.9 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1975640007106367		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 1.1975640007106367 | validation: 1.5682658998833177]
	TIME [epoch: 24.8 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.27748796393758		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 1.27748796393758 | validation: 1.2308682742032675]
	TIME [epoch: 24.9 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2236461979788742		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 1.2236461979788742 | validation: 1.099885387638284]
	TIME [epoch: 24.8 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.367233479204553		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 1.367233479204553 | validation: 1.1225194521893966]
	TIME [epoch: 24.8 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1879827382428694		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 1.1879827382428694 | validation: 0.8384761136190073]
	TIME [epoch: 24.9 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3627904304505525		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 1.3627904304505525 | validation: 0.8757661921884176]
	TIME [epoch: 24.8 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2949068362160308		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 1.2949068362160308 | validation: 1.870114435482305]
	TIME [epoch: 24.8 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5967344829730976		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 1.5967344829730976 | validation: 1.1224603956361472]
	TIME [epoch: 24.9 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9389406897945491		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 1.9389406897945491 | validation: 1.4912400037693387]
	TIME [epoch: 24.8 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2455983744380807		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 1.2455983744380807 | validation: 0.8865128784147104]
	TIME [epoch: 24.8 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1132286914275136		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 1.1132286914275136 | validation: 0.8209407122368393]
	TIME [epoch: 24.9 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.781541114041744		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 1.781541114041744 | validation: 3.334071985880653]
	TIME [epoch: 24.8 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0602543591985296		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 2.0602543591985296 | validation: 1.2412975636900843]
	TIME [epoch: 24.8 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.477661384341773		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 1.477661384341773 | validation: 0.9888485428914952]
	TIME [epoch: 24.9 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0110896762413624		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 1.0110896762413624 | validation: 0.8321777656252684]
	TIME [epoch: 24.8 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2377029424134802		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 1.2377029424134802 | validation: 0.9116966597649023]
	TIME [epoch: 24.8 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0324598240343954		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 1.0324598240343954 | validation: 1.2638790763385315]
	TIME [epoch: 24.9 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0040395636927117		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 1.0040395636927117 | validation: 0.7691022364643123]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_201.pth
	Model improved!!!
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2444562473672571		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 1.2444562473672571 | validation: 0.8262906908906544]
	TIME [epoch: 24.8 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8888601103771154		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.8888601103771154 | validation: 1.1445152761940607]
	TIME [epoch: 24.9 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0570525767849561		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 1.0570525767849561 | validation: 0.8393943325285386]
	TIME [epoch: 24.9 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9960455804589008		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.9960455804589008 | validation: 1.1091203041949953]
	TIME [epoch: 24.8 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8927204739618637		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.8927204739618637 | validation: 0.7534204687195057]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_206.pth
	Model improved!!!
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7496864634408176		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.7496864634408176 | validation: 1.0272220266115275]
	TIME [epoch: 24.8 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8475072572393799		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.8475072572393799 | validation: 1.2022621204824842]
	TIME [epoch: 24.8 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8853526784952156		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.8853526784952156 | validation: 1.169505089715736]
	TIME [epoch: 24.8 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8972677621168001		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.8972677621168001 | validation: 0.7280277556577437]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_210.pth
	Model improved!!!
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7654189230642976		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.7654189230642976 | validation: 0.6854320717307806]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_211.pth
	Model improved!!!
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8497443470442863		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.8497443470442863 | validation: 0.8173420151237442]
	TIME [epoch: 24.8 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6213938119208735		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.6213938119208735 | validation: 0.8793332045324044]
	TIME [epoch: 24.8 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.91318406616496		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.91318406616496 | validation: 1.3721524593635837]
	TIME [epoch: 24.8 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0878718858439673		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 1.0878718858439673 | validation: 0.6974878829590149]
	TIME [epoch: 24.9 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9143614244584182		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.9143614244584182 | validation: 0.5026426846280952]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_216.pth
	Model improved!!!
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7648436482394556		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.7648436482394556 | validation: 0.578841199798093]
	TIME [epoch: 24.8 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7792874368116989		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.7792874368116989 | validation: 0.8919448358129324]
	TIME [epoch: 24.8 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6516650122138195		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.6516650122138195 | validation: 0.8506360899036929]
	TIME [epoch: 24.8 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6457633431851615		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.6457633431851615 | validation: 1.0321874137463751]
	TIME [epoch: 24.8 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9543880608201903		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.9543880608201903 | validation: 2.55962240040358]
	TIME [epoch: 24.8 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.535907392922686		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 2.535907392922686 | validation: 1.183118198340884]
	TIME [epoch: 24.8 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9486678032269663		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.9486678032269663 | validation: 0.6941137566794344]
	TIME [epoch: 24.8 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7642664458663682		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.7642664458663682 | validation: 0.5443630904975572]
	TIME [epoch: 24.8 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5991609875569086		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.5991609875569086 | validation: 0.6020411720142527]
	TIME [epoch: 24.8 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.70174541904446		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.70174541904446 | validation: 3.5139819852250254]
	TIME [epoch: 24.8 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5076800196869777		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 1.5076800196869777 | validation: 1.0519270194975143]
	TIME [epoch: 24.9 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9330711924445255		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.9330711924445255 | validation: 0.9818635963461967]
	TIME [epoch: 24.8 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7485720091630521		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.7485720091630521 | validation: 0.513667130614797]
	TIME [epoch: 24.8 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6712408411064553		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.6712408411064553 | validation: 0.6453598290856443]
	TIME [epoch: 24.8 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6678083248806199		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.6678083248806199 | validation: 0.47497181021038276]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_231.pth
	Model improved!!!
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5726518015384952		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.5726518015384952 | validation: 0.4893503122762299]
	TIME [epoch: 24.8 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.652001051056188		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.652001051056188 | validation: 0.7662304534459736]
	TIME [epoch: 24.8 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7138597852439631		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.7138597852439631 | validation: 0.5927765918374402]
	TIME [epoch: 24.8 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.706436137561031		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.706436137561031 | validation: 0.8700957160887822]
	TIME [epoch: 24.8 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.867063302616345		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.867063302616345 | validation: 0.5414067899800652]
	TIME [epoch: 24.8 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6527240585491705		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.6527240585491705 | validation: 0.34205033842154736]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_237.pth
	Model improved!!!
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6812591820186638		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.6812591820186638 | validation: 0.6165099685758589]
	TIME [epoch: 24.8 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1947031874306937		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 1.1947031874306937 | validation: 2.0969789105373313]
	TIME [epoch: 24.8 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.733571543380969		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 2.733571543380969 | validation: 1.32634646339714]
	TIME [epoch: 24.8 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.004620475872916		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 1.004620475872916 | validation: 0.5115250080780602]
	TIME [epoch: 24.8 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.531410832270657		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.531410832270657 | validation: 0.8019554129578614]
	TIME [epoch: 24.8 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8892145011728977		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.8892145011728977 | validation: 0.6602531598768538]
	TIME [epoch: 24.8 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8032963401562779		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.8032963401562779 | validation: 0.771644568292543]
	TIME [epoch: 24.8 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6691861001898257		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.6691861001898257 | validation: 0.7937936462436832]
	TIME [epoch: 24.8 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7884250466864046		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.7884250466864046 | validation: 0.6191450823921455]
	TIME [epoch: 24.8 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7957319502552298		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.7957319502552298 | validation: 0.9231063216034605]
	TIME [epoch: 24.8 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8436711417065148		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.8436711417065148 | validation: 0.5961818812124929]
	TIME [epoch: 24.8 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7895681666203501		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.7895681666203501 | validation: 0.8445364485933681]
	TIME [epoch: 24.8 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8413091987334207		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 3.8413091987334207 | validation: 4.726135448572648]
	TIME [epoch: 24.8 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7966791884219515		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 2.7966791884219515 | validation: 0.8096442958058573]
	TIME [epoch: 24.8 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8476770692764184		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.8476770692764184 | validation: 1.0568843832332917]
	TIME [epoch: 24.8 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.873673777320892		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.873673777320892 | validation: 1.6949745987999398]
	TIME [epoch: 24.8 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1936988485097806		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 1.1936988485097806 | validation: 0.7417363546186545]
	TIME [epoch: 24.8 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6873465819683496		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.6873465819683496 | validation: 1.0045361932556989]
	TIME [epoch: 24.7 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7585626590840913		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.7585626590840913 | validation: 0.6178534107186716]
	TIME [epoch: 24.8 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6387649136164342		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.6387649136164342 | validation: 0.5720573931582892]
	TIME [epoch: 24.8 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7563338643389379		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.7563338643389379 | validation: 0.9936525103272604]
	TIME [epoch: 24.7 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7606996378027635		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.7606996378027635 | validation: 0.5876897655436225]
	TIME [epoch: 24.8 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6454243742187569		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.6454243742187569 | validation: 0.7086462878395117]
	TIME [epoch: 24.8 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6535741850265734		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.6535741850265734 | validation: 1.4020241486592724]
	TIME [epoch: 24.8 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1266778013307284		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 1.1266778013307284 | validation: 0.6700622061166109]
	TIME [epoch: 24.8 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7824685874168816		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.7824685874168816 | validation: 0.6569466581490467]
	TIME [epoch: 24.8 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7574727264436256		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.7574727264436256 | validation: 0.6311983860439139]
	TIME [epoch: 24.8 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9608728870763723		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.9608728870763723 | validation: 1.0368128006238078]
	TIME [epoch: 24.8 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7756149817177489		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.7756149817177489 | validation: 1.0254762675433946]
	TIME [epoch: 24.8 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6672903359536181		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.6672903359536181 | validation: 0.6377684340200654]
	TIME [epoch: 24.7 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7188768603851574		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.7188768603851574 | validation: 0.6210074529726656]
	TIME [epoch: 24.8 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7279743035571375		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.7279743035571375 | validation: 0.6520498704174043]
	TIME [epoch: 24.8 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5616010978452923		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.5616010978452923 | validation: 0.5540570535503815]
	TIME [epoch: 24.7 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6661285898675626		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.6661285898675626 | validation: 0.47809168235300875]
	TIME [epoch: 24.8 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5584983028220873		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.5584983028220873 | validation: 0.8429446283506136]
	TIME [epoch: 24.8 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6226505761685419		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.6226505761685419 | validation: 0.48657640338696423]
	TIME [epoch: 24.7 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6560223133257002		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.6560223133257002 | validation: 0.4865513881012663]
	TIME [epoch: 24.8 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5863773647822095		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.5863773647822095 | validation: 0.7961334319303168]
	TIME [epoch: 24.8 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7181433775258725		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.7181433775258725 | validation: 0.5810425863865377]
	TIME [epoch: 24.7 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5647809203195788		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.5647809203195788 | validation: 0.7323231438189332]
	TIME [epoch: 24.8 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8724571729792637		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.8724571729792637 | validation: 1.275674791578837]
	TIME [epoch: 24.8 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9596860267764028		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.9596860267764028 | validation: 0.6580385160457456]
	TIME [epoch: 24.7 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5260390711879259		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.5260390711879259 | validation: 0.6962494938873729]
	TIME [epoch: 24.8 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.69630476630718		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.69630476630718 | validation: 0.8611365367185075]
	TIME [epoch: 24.8 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7196945779470993		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.7196945779470993 | validation: 0.6054884468227203]
	TIME [epoch: 24.7 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7861427942604184		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.7861427942604184 | validation: 0.6183772335868021]
	TIME [epoch: 24.8 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.708134160424754		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.708134160424754 | validation: 1.1730600926114971]
	TIME [epoch: 24.8 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1289301639572122		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 1.1289301639572122 | validation: 1.1291959532530007]
	TIME [epoch: 24.7 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7538203246909165		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.7538203246909165 | validation: 0.6469566050960909]
	TIME [epoch: 24.8 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5273343499953564		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.5273343499953564 | validation: 0.7966744612129939]
	TIME [epoch: 24.8 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6029143799546121		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.6029143799546121 | validation: 0.5735219869794493]
	TIME [epoch: 24.8 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9286735701501305		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.9286735701501305 | validation: 0.8195102547655734]
	TIME [epoch: 24.8 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5973950967408443		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.5973950967408443 | validation: 0.9020164470476959]
	TIME [epoch: 24.8 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8294656560086323		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.8294656560086323 | validation: 1.04178298904571]
	TIME [epoch: 24.7 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8013736160306068		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.8013736160306068 | validation: 1.1425195726240898]
	TIME [epoch: 24.8 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.85090631798488		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.85090631798488 | validation: 1.131605388603389]
	TIME [epoch: 24.8 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.024646879874738		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 2.024646879874738 | validation: 1.0467965059553033]
	TIME [epoch: 24.7 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8753540288251767		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.8753540288251767 | validation: 0.481985483420751]
	TIME [epoch: 24.8 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6132319163689804		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.6132319163689804 | validation: 0.5257325218070722]
	TIME [epoch: 24.8 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7227197986226517		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.7227197986226517 | validation: 0.6924539767649838]
	TIME [epoch: 24.7 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8079963428636499		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.8079963428636499 | validation: 0.6430455588626108]
	TIME [epoch: 24.8 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6561395575742385		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.6561395575742385 | validation: 0.5778174633876831]
	TIME [epoch: 24.8 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5817102958489626		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.5817102958489626 | validation: 0.5172977156756481]
	TIME [epoch: 24.7 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5640602296817127		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.5640602296817127 | validation: 0.8519994671159117]
	TIME [epoch: 24.8 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6096911306057636		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.6096911306057636 | validation: 0.7563672524175814]
	TIME [epoch: 24.8 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8069721647135014		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.8069721647135014 | validation: 0.4610390744219713]
	TIME [epoch: 24.7 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6724449642533659		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.6724449642533659 | validation: 0.7194236542891217]
	TIME [epoch: 24.8 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8905193446494236		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.8905193446494236 | validation: 1.0309479526515586]
	TIME [epoch: 24.8 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7814321147675236		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.7814321147675236 | validation: 1.0817326155223228]
	TIME [epoch: 24.8 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0333644114556506		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 1.0333644114556506 | validation: 1.118177949543725]
	TIME [epoch: 24.8 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7731155967366344		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.7731155967366344 | validation: 0.6522584389504178]
	TIME [epoch: 24.8 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6626020293696192		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.6626020293696192 | validation: 0.5771254218793164]
	TIME [epoch: 24.8 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5238154506767755		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.5238154506767755 | validation: 0.3369078845937514]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_310.pth
	Model improved!!!
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48489008057876515		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.48489008057876515 | validation: 0.5129042260802679]
	TIME [epoch: 24.8 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5144284634867073		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.5144284634867073 | validation: 0.5339775924179074]
	TIME [epoch: 24.8 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5466880488639343		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.5466880488639343 | validation: 1.4434225989423743]
	TIME [epoch: 24.8 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1737524789590739		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 1.1737524789590739 | validation: 1.1628757521693325]
	TIME [epoch: 24.7 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1043400184395091		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 1.1043400184395091 | validation: 0.6761745067966979]
	TIME [epoch: 24.8 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7170762915986799		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.7170762915986799 | validation: 0.6323903332712884]
	TIME [epoch: 24.8 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6245653450391293		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.6245653450391293 | validation: 0.5384572363886494]
	TIME [epoch: 24.8 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5937260730128563		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.5937260730128563 | validation: 0.32827397267715575]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_318.pth
	Model improved!!!
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44263370285029535		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.44263370285029535 | validation: 0.43981698309569384]
	TIME [epoch: 24.9 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4734488424140255		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.4734488424140255 | validation: 0.5445325890080767]
	TIME [epoch: 24.8 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1413382760292776		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 1.1413382760292776 | validation: 0.6128309263695684]
	TIME [epoch: 24.8 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.723055062346049		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.723055062346049 | validation: 0.6031251090541716]
	TIME [epoch: 24.8 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5202577052170826		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.5202577052170826 | validation: 0.42237497294671555]
	TIME [epoch: 24.8 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48262038546272545		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.48262038546272545 | validation: 0.8208941112501874]
	TIME [epoch: 24.8 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6904266517841073		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.6904266517841073 | validation: 0.6451798671881804]
	TIME [epoch: 24.9 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5691269000069056		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.5691269000069056 | validation: 2.112723315210051]
	TIME [epoch: 24.8 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.522617855425639		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 1.522617855425639 | validation: 0.582759995634977]
	TIME [epoch: 24.8 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5801331621437547		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.5801331621437547 | validation: 0.7115257553497605]
	TIME [epoch: 24.8 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6077758043552461		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.6077758043552461 | validation: 0.6602527452139688]
	TIME [epoch: 24.8 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47170168933151246		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.47170168933151246 | validation: 0.37370567872230026]
	TIME [epoch: 24.8 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47370556504766054		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.47370556504766054 | validation: 0.5925103179664482]
	TIME [epoch: 24.8 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4428971085684197		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.4428971085684197 | validation: 0.6132593533392146]
	TIME [epoch: 24.8 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4761408749128333		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.4761408749128333 | validation: 0.4103808500026387]
	TIME [epoch: 24.8 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.55670049830095		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.55670049830095 | validation: 0.8274973586251727]
	TIME [epoch: 24.8 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6104224629814626		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.6104224629814626 | validation: 1.1424938405479779]
	TIME [epoch: 24.8 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6613819546259838		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.6613819546259838 | validation: 0.44530049908222374]
	TIME [epoch: 24.8 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44906030907239175		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.44906030907239175 | validation: 0.35924328983064613]
	TIME [epoch: 24.8 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4176076210321939		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.4176076210321939 | validation: 0.4912471569923993]
	TIME [epoch: 24.8 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4651010093598482		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.4651010093598482 | validation: 0.32185571057562484]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_339.pth
	Model improved!!!
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36680804620354757		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.36680804620354757 | validation: 0.3668040651299815]
	TIME [epoch: 24.8 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.58016449559255		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.58016449559255 | validation: 0.7786998912230104]
	TIME [epoch: 24.8 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6735457215323319		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.6735457215323319 | validation: 0.7836728441648083]
	TIME [epoch: 24.8 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6779390706816958		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.6779390706816958 | validation: 0.4589352038998479]
	TIME [epoch: 24.8 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43601898545463647		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.43601898545463647 | validation: 0.5630211426542183]
	TIME [epoch: 24.8 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4853438865971135		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.4853438865971135 | validation: 0.38455829283199]
	TIME [epoch: 24.8 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5589071024735307		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.5589071024735307 | validation: 0.5585813201639896]
	TIME [epoch: 24.8 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5442551427491318		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.5442551427491318 | validation: 0.3193981678509012]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_347.pth
	Model improved!!!
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40765795813912653		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.40765795813912653 | validation: 0.31663637921352417]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_348.pth
	Model improved!!!
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35161527595620135		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.35161527595620135 | validation: 0.6691679776650049]
	TIME [epoch: 24.8 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.584328815691491		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.584328815691491 | validation: 0.38183570894527896]
	TIME [epoch: 24.8 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41510279845738524		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.41510279845738524 | validation: 0.4718905600259704]
	TIME [epoch: 24.8 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4594580459159518		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.4594580459159518 | validation: 0.38703234909109435]
	TIME [epoch: 24.8 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36276493196068493		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.36276493196068493 | validation: 0.371266513548548]
	TIME [epoch: 24.8 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48192023725918276		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.48192023725918276 | validation: 0.6966268161119641]
	TIME [epoch: 24.8 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5251007843718273		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.5251007843718273 | validation: 0.4416186772191555]
	TIME [epoch: 24.8 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43753041335819665		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.43753041335819665 | validation: 0.43414647818330565]
	TIME [epoch: 24.8 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5518979423357249		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.5518979423357249 | validation: 0.9178163566113926]
	TIME [epoch: 24.8 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45851240006311583		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.45851240006311583 | validation: 0.4037151112271294]
	TIME [epoch: 24.8 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4207909336279021		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.4207909336279021 | validation: 0.39821954492237266]
	TIME [epoch: 24.8 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5200374125646293		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.5200374125646293 | validation: 0.551313818081322]
	TIME [epoch: 24.8 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4791560857625333		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.4791560857625333 | validation: 0.27556701565747427]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_361.pth
	Model improved!!!
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43906017890075455		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.43906017890075455 | validation: 0.3299003538795758]
	TIME [epoch: 24.8 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33587618621643617		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.33587618621643617 | validation: 0.3550320945064131]
	TIME [epoch: 24.8 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4405558014171833		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.4405558014171833 | validation: 0.4278079795085454]
	TIME [epoch: 24.8 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4459924789892954		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.4459924789892954 | validation: 0.35520571443150617]
	TIME [epoch: 24.8 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49789368726079547		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.49789368726079547 | validation: 0.4186055643226947]
	TIME [epoch: 24.8 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4269739706490745		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.4269739706490745 | validation: 0.42482534313455544]
	TIME [epoch: 24.9 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4056504018950762		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.4056504018950762 | validation: 0.27776497507868836]
	TIME [epoch: 24.8 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3251476395496902		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.3251476395496902 | validation: 0.2870583163717927]
	TIME [epoch: 24.8 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33060263406651286		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.33060263406651286 | validation: 0.8061601932096938]
	TIME [epoch: 24.8 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5950984106155754		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.5950984106155754 | validation: 0.4288164318215381]
	TIME [epoch: 24.8 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4296943670521225		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.4296943670521225 | validation: 0.6474853487928371]
	TIME [epoch: 24.8 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49018038289003324		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.49018038289003324 | validation: 0.35787973335797546]
	TIME [epoch: 24.9 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3498804869821547		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.3498804869821547 | validation: 0.5299800939481438]
	TIME [epoch: 24.8 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45352990059785964		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.45352990059785964 | validation: 0.4967585334768525]
	TIME [epoch: 24.8 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42561307874147813		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.42561307874147813 | validation: 0.43120677593088774]
	TIME [epoch: 24.8 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4532456622762584		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.4532456622762584 | validation: 0.386818953528656]
	TIME [epoch: 24.8 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48504487543064345		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.48504487543064345 | validation: 0.4347369152039623]
	TIME [epoch: 24.8 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.420531873110673		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.420531873110673 | validation: 0.3946961291794557]
	TIME [epoch: 24.8 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4371390118754069		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.4371390118754069 | validation: 0.3048715655940605]
	TIME [epoch: 24.8 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3858039528320657		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.3858039528320657 | validation: 0.4013606863205241]
	TIME [epoch: 24.8 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5155229385442099		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.5155229385442099 | validation: 0.28771775289215024]
	TIME [epoch: 24.8 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3982977990076712		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.3982977990076712 | validation: 0.381294688477199]
	TIME [epoch: 24.8 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3824419895720006		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.3824419895720006 | validation: 0.6001433103465988]
	TIME [epoch: 24.8 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4226838988793081		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.4226838988793081 | validation: 0.43727225655478036]
	TIME [epoch: 24.8 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3678027157403305		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.3678027157403305 | validation: 0.3559440826763271]
	TIME [epoch: 24.8 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3234294799739071		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.3234294799739071 | validation: 0.31356051223054193]
	TIME [epoch: 24.8 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2679274877478633		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.2679274877478633 | validation: 0.34876187228014566]
	TIME [epoch: 24.8 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33635036081639613		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.33635036081639613 | validation: 0.3290678216490439]
	TIME [epoch: 24.8 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34650444022276117		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.34650444022276117 | validation: 0.2263246676679984]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_390.pth
	Model improved!!!
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2938242606236805		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.2938242606236805 | validation: 0.3110456024216152]
	TIME [epoch: 24.8 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3311624175574606		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.3311624175574606 | validation: 0.23114072457881032]
	TIME [epoch: 24.8 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4478846011880483		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.4478846011880483 | validation: 0.7939355642697374]
	TIME [epoch: 24.8 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5926473968146159		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.5926473968146159 | validation: 0.2574688716397263]
	TIME [epoch: 24.8 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44587812760635254		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.44587812760635254 | validation: 1.998358701694501]
	TIME [epoch: 24.8 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3662329961392932		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 1.3662329961392932 | validation: 0.47852607566053523]
	TIME [epoch: 24.8 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3754208770784773		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.3754208770784773 | validation: 0.8241941882842655]
	TIME [epoch: 24.9 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5995835649464486		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.5995835649464486 | validation: 0.48506158697389956]
	TIME [epoch: 24.8 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3568532630205891		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.3568532630205891 | validation: 0.27010618329003644]
	TIME [epoch: 24.8 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30681292620639644		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.30681292620639644 | validation: 0.486818114612547]
	TIME [epoch: 24.8 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4324490226618465		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.4324490226618465 | validation: 0.5076933159757876]
	TIME [epoch: 24.8 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37489530795550197		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.37489530795550197 | validation: 0.2720185926623875]
	TIME [epoch: 24.8 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2459606610926301		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.2459606610926301 | validation: 0.2288102367435841]
	TIME [epoch: 24.8 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35338163498159786		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.35338163498159786 | validation: 0.4480158737824634]
	TIME [epoch: 24.8 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39639813258525475		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.39639813258525475 | validation: 0.35660903861591464]
	TIME [epoch: 24.8 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44283247320080443		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.44283247320080443 | validation: 0.47897353398184267]
	TIME [epoch: 24.8 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39464646764287786		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.39464646764287786 | validation: 0.19106146708367697]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_407.pth
	Model improved!!!
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.290123049752687		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.290123049752687 | validation: 0.3404172523847519]
	TIME [epoch: 24.8 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3621948221029264		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.3621948221029264 | validation: 0.4086817330597921]
	TIME [epoch: 24.8 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4105426140352268		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.4105426140352268 | validation: 0.34169076573083584]
	TIME [epoch: 24.8 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40029969920263286		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.40029969920263286 | validation: 0.3529572764808509]
	TIME [epoch: 24.8 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3214750949548091		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.3214750949548091 | validation: 0.2709304681952434]
	TIME [epoch: 24.8 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27618566688958834		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.27618566688958834 | validation: 0.27877338529575213]
	TIME [epoch: 24.8 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2848174335958628		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.2848174335958628 | validation: 0.7253169325027184]
	TIME [epoch: 24.8 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5402731357953603		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.5402731357953603 | validation: 0.3208294342886106]
	TIME [epoch: 24.8 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3301425351553808		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.3301425351553808 | validation: 0.23910276048766274]
	TIME [epoch: 24.8 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5607487622143615		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.5607487622143615 | validation: 0.5123741142941299]
	TIME [epoch: 24.8 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5633318017529436		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.5633318017529436 | validation: 0.4469778370361985]
	TIME [epoch: 24.8 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46430230394334004		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.46430230394334004 | validation: 0.3046993849875652]
	TIME [epoch: 24.8 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3371762734628969		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.3371762734628969 | validation: 0.30488587136611434]
	TIME [epoch: 24.8 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36585477264186866		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.36585477264186866 | validation: 0.561344900114839]
	TIME [epoch: 24.8 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39473170379932		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.39473170379932 | validation: 0.33790526533672904]
	TIME [epoch: 24.8 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3378811215407601		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.3378811215407601 | validation: 0.26519447017398895]
	TIME [epoch: 24.8 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5731069785140963		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.5731069785140963 | validation: 0.718110545704848]
	TIME [epoch: 24.8 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44915722026076865		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.44915722026076865 | validation: 0.35369340518015846]
	TIME [epoch: 24.8 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4449215070200858		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.4449215070200858 | validation: 0.36904184114549504]
	TIME [epoch: 24.8 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3378496158627054		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.3378496158627054 | validation: 0.28885878096567824]
	TIME [epoch: 24.8 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3541939918908069		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.3541939918908069 | validation: 0.2986292150054883]
	TIME [epoch: 24.8 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3154096896568834		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.3154096896568834 | validation: 0.2582092709120835]
	TIME [epoch: 24.8 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2731380547024158		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.2731380547024158 | validation: 0.4193431746196943]
	TIME [epoch: 24.8 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3423259818101085		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.3423259818101085 | validation: 0.32828858981739883]
	TIME [epoch: 24.8 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2846322608567587		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.2846322608567587 | validation: 0.554463671228148]
	TIME [epoch: 24.8 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40602398992663274		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.40602398992663274 | validation: 0.2612002079188347]
	TIME [epoch: 24.8 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.346718406196901		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.346718406196901 | validation: 0.3229125161471539]
	TIME [epoch: 24.8 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35367156862638716		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.35367156862638716 | validation: 0.5655331652798833]
	TIME [epoch: 24.9 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5219404174122435		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.5219404174122435 | validation: 0.3777659857777647]
	TIME [epoch: 24.9 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3884895043537667		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.3884895043537667 | validation: 0.2763434080126421]
	TIME [epoch: 24.8 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35834957431028813		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.35834957431028813 | validation: 0.5477890154496824]
	TIME [epoch: 24.8 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3765105678779411		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.3765105678779411 | validation: 0.42001239062432427]
	TIME [epoch: 24.8 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30042812414038134		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.30042812414038134 | validation: 0.4401500387803361]
	TIME [epoch: 24.8 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3741349657178197		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.3741349657178197 | validation: 0.2865399096856719]
	TIME [epoch: 24.8 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33643341193834936		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.33643341193834936 | validation: 0.33570046418017024]
	TIME [epoch: 24.8 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49645138200127953		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.49645138200127953 | validation: 0.8107583833455552]
	TIME [epoch: 24.8 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5246171356116737		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.5246171356116737 | validation: 0.37859294485694805]
	TIME [epoch: 24.8 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5708707955209615		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.5708707955209615 | validation: 0.6030924521686335]
	TIME [epoch: 24.8 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42484308734409687		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.42484308734409687 | validation: 0.33125064766372503]
	TIME [epoch: 24.8 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41418069377306344		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.41418069377306344 | validation: 0.48949197396140387]
	TIME [epoch: 24.8 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4542064879486428		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.4542064879486428 | validation: 0.22418787717137179]
	TIME [epoch: 24.8 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2134986712466507		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.2134986712466507 | validation: 0.1937090285952364]
	TIME [epoch: 24.8 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3330276915817875		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.3330276915817875 | validation: 0.37924280951749056]
	TIME [epoch: 24.8 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4448214337183525		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.4448214337183525 | validation: 0.42765601491779104]
	TIME [epoch: 24.8 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32810967361966037		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.32810967361966037 | validation: 0.25074200237650796]
	TIME [epoch: 24.8 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3373600224319945		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.3373600224319945 | validation: 0.4762547471942006]
	TIME [epoch: 24.8 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34353005537993025		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.34353005537993025 | validation: 0.44562712203834354]
	TIME [epoch: 24.8 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3545123843572857		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.3545123843572857 | validation: 0.25460723074135216]
	TIME [epoch: 24.8 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30269596857980363		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.30269596857980363 | validation: 0.33199839487506866]
	TIME [epoch: 24.8 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2426973747480149		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.2426973747480149 | validation: 0.3918069031539203]
	TIME [epoch: 24.8 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34572577828106954		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.34572577828106954 | validation: 0.2988250832783443]
	TIME [epoch: 24.8 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6288911616977899		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.6288911616977899 | validation: 0.41083604258475276]
	TIME [epoch: 24.8 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4426135153717182		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.4426135153717182 | validation: 0.27784049361073393]
	TIME [epoch: 24.8 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2574341722561595		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.2574341722561595 | validation: 0.3912496451754862]
	TIME [epoch: 24.8 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0130300616747046		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 1.0130300616747046 | validation: 1.0239127600018183]
	TIME [epoch: 24.8 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5103365672463469		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.5103365672463469 | validation: 0.4298915954147061]
	TIME [epoch: 24.8 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40685818894051395		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.40685818894051395 | validation: 0.5563143152105449]
	TIME [epoch: 24.7 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4804826918489032		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.4804826918489032 | validation: 0.42429158125343464]
	TIME [epoch: 24.8 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6570783920358307		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.6570783920358307 | validation: 0.5957775207856033]
	TIME [epoch: 24.7 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5133366251637692		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.5133366251637692 | validation: 0.4130800376360584]
	TIME [epoch: 24.8 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37710941695956846		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.37710941695956846 | validation: 0.27984318014742243]
	TIME [epoch: 24.8 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.253429267842581		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.253429267842581 | validation: 0.3380694867163082]
	TIME [epoch: 24.8 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2991767323583487		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.2991767323583487 | validation: 0.3296651573047973]
	TIME [epoch: 24.8 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28369406857528956		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.28369406857528956 | validation: 0.43791193498392034]
	TIME [epoch: 24.8 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4241365140640854		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.4241365140640854 | validation: 0.31735489971503567]
	TIME [epoch: 24.8 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3119400102429332		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.3119400102429332 | validation: 0.2952338525016069]
	TIME [epoch: 24.8 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31085236328930527		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.31085236328930527 | validation: 0.26844366521953794]
	TIME [epoch: 24.8 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27398789997538653		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.27398789997538653 | validation: 0.3736818993214992]
	TIME [epoch: 24.8 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2943389804071477		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.2943389804071477 | validation: 0.3541241158569373]
	TIME [epoch: 24.8 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29513553365911444		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.29513553365911444 | validation: 0.3618238752406475]
	TIME [epoch: 24.8 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29729854332288114		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.29729854332288114 | validation: 0.33405597328393044]
	TIME [epoch: 24.7 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3132877196391049		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.3132877196391049 | validation: 0.23406722681478298]
	TIME [epoch: 24.8 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2829428462602872		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.2829428462602872 | validation: 0.3657219867104236]
	TIME [epoch: 24.8 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35966891351584607		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.35966891351584607 | validation: 0.32616739219650664]
	TIME [epoch: 24.8 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36800004232550804		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.36800004232550804 | validation: 0.6742746709740465]
	TIME [epoch: 24.8 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3887881815181223		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.3887881815181223 | validation: 0.23140035296958647]
	TIME [epoch: 24.8 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26931998861041706		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.26931998861041706 | validation: 0.3535935928671776]
	TIME [epoch: 24.8 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2565812583519509		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.2565812583519509 | validation: 0.23751143365869254]
	TIME [epoch: 24.8 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23873057762707633		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.23873057762707633 | validation: 0.3495893442418355]
	TIME [epoch: 24.8 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31354570587147035		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.31354570587147035 | validation: 0.5148343004854439]
	TIME [epoch: 24.8 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37480484100887185		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.37480484100887185 | validation: 0.3052265513715932]
	TIME [epoch: 24.8 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31557378771065414		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.31557378771065414 | validation: 0.31832517037649816]
	TIME [epoch: 24.8 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2426143063932839		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.2426143063932839 | validation: 0.2710277105690301]
	TIME [epoch: 24.8 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2701475222673606		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.2701475222673606 | validation: 0.34268766217685775]
	TIME [epoch: 24.8 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23564383429216795		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.23564383429216795 | validation: 0.31242045750453146]
	TIME [epoch: 24.8 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.328376213155684		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.328376213155684 | validation: 0.3126888715993161]
	TIME [epoch: 24.8 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3526618137455439		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.3526618137455439 | validation: 0.39628406555943274]
	TIME [epoch: 24.8 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2984308877428818		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.2984308877428818 | validation: 0.5373066011057954]
	TIME [epoch: 24.8 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3990163412485142		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.3990163412485142 | validation: 0.3502204737597988]
	TIME [epoch: 24.8 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26298788561510744		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.26298788561510744 | validation: 0.32527257158286865]
	TIME [epoch: 24.8 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26373797931673787		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.26373797931673787 | validation: 0.4202243497900771]
	TIME [epoch: 24.8 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.344588043682404		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.344588043682404 | validation: 0.5227376930090639]
	TIME [epoch: 24.8 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41614065710516485		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.41614065710516485 | validation: 0.2818884541033503]
	TIME [epoch: 24.8 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30597325650923346		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.30597325650923346 | validation: 0.30496343316287644]
	TIME [epoch: 24.8 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33281573017877897		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.33281573017877897 | validation: 0.5513045095821398]
	TIME [epoch: 24.8 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35954425905251675		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.35954425905251675 | validation: 0.24484289779590934]
	TIME [epoch: 24.8 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27648115058230077		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.27648115058230077 | validation: 0.23996800428117382]
	TIME [epoch: 24.8 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24394678649201834		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.24394678649201834 | validation: 0.3172103052412569]
	TIME [epoch: 24.8 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29052232311007353		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.29052232311007353 | validation: 0.30054016113608756]
	TIME [epoch: 24.8 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2655920472103491		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.2655920472103491 | validation: 0.2241226510011761]
	TIME [epoch: 24.8 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2781363527997121		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.2781363527997121 | validation: 0.20981235947112822]
	TIME [epoch: 24.8 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21461492991766187		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.21461492991766187 | validation: 0.2109410462421836]
	TIME [epoch: 24.8 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2390409165334368		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.2390409165334368 | validation: 0.24295092827939463]
	TIME [epoch: 24.8 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27990589926662224		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.27990589926662224 | validation: 0.2581015115712983]
	TIME [epoch: 24.7 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24647532547038342		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.24647532547038342 | validation: 0.29589413143716337]
	TIME [epoch: 24.8 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24206435965535805		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.24206435965535805 | validation: 0.22142610622294334]
	TIME [epoch: 24.8 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2339133354901939		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.2339133354901939 | validation: 0.2857585176020882]
	TIME [epoch: 24.7 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23389688275704051		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.23389688275704051 | validation: 0.2479889410538661]
	TIME [epoch: 24.8 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21133405812407766		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.21133405812407766 | validation: 0.22766224749923722]
	TIME [epoch: 24.8 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29026133349320804		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.29026133349320804 | validation: 0.2541503294777082]
	TIME [epoch: 24.7 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2607513756137764		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.2607513756137764 | validation: 0.2547940676936549]
	TIME [epoch: 24.8 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24173518447489573		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.24173518447489573 | validation: 0.32072566930096386]
	TIME [epoch: 24.8 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28693691562353096		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.28693691562353096 | validation: 0.39683007358216527]
	TIME [epoch: 24.8 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34875616714662694		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.34875616714662694 | validation: 0.22915678905674428]
	TIME [epoch: 24.8 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20840041044988017		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.20840041044988017 | validation: 0.2236523111722542]
	TIME [epoch: 24.8 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2250531949890691		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.2250531949890691 | validation: 0.31773801682537867]
	TIME [epoch: 24.7 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2698977112890164		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.2698977112890164 | validation: 0.32041872343302774]
	TIME [epoch: 24.8 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2458990241346713		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.2458990241346713 | validation: 0.23929367518798286]
	TIME [epoch: 24.8 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27399664707771965		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.27399664707771965 | validation: 0.21097658124419597]
	TIME [epoch: 24.7 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22274045934636855		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.22274045934636855 | validation: 0.19563844386679624]
	TIME [epoch: 24.8 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22650461313177264		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.22650461313177264 | validation: 0.26368519534632284]
	TIME [epoch: 24.8 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2580475970710844		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.2580475970710844 | validation: 0.278493754776662]
	TIME [epoch: 24.8 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24472793809636723		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.24472793809636723 | validation: 0.32210075376032166]
	TIME [epoch: 24.8 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4406461090374592		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.4406461090374592 | validation: 0.3773523543944566]
	TIME [epoch: 24.8 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4414091428145528		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.4414091428145528 | validation: 0.44198299910450345]
	TIME [epoch: 24.8 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48609758574851114		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.48609758574851114 | validation: 0.6847945458648874]
	TIME [epoch: 24.8 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5558242058838523		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.5558242058838523 | validation: 0.4161879450985291]
	TIME [epoch: 24.9 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42933094163112817		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.42933094163112817 | validation: 0.35763575959447363]
	TIME [epoch: 24.8 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.294934090253555		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.294934090253555 | validation: 0.2580975598473313]
	TIME [epoch: 24.9 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2635163118624775		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.2635163118624775 | validation: 0.31962269110430336]
	TIME [epoch: 24.8 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3033151169270745		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.3033151169270745 | validation: 0.3140021562989005]
	TIME [epoch: 24.8 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26327514600503343		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.26327514600503343 | validation: 0.2119799999915495]
	TIME [epoch: 24.8 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2607845132015222		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.2607845132015222 | validation: 0.27667709644788996]
	TIME [epoch: 24.8 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2654384156387772		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.2654384156387772 | validation: 0.23099848320737196]
	TIME [epoch: 24.7 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21863582533381337		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.21863582533381337 | validation: 0.2172363844464217]
	TIME [epoch: 24.9 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28766501735779354		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.28766501735779354 | validation: 0.26374614495494525]
	TIME [epoch: 24.8 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33615964959564604		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.33615964959564604 | validation: 0.29141653857772704]
	TIME [epoch: 24.8 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27844675451608325		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.27844675451608325 | validation: 0.3218486434303216]
	TIME [epoch: 24.8 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28510318728994155		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.28510318728994155 | validation: 0.24967477958394127]
	TIME [epoch: 24.8 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28285434944177273		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.28285434944177273 | validation: 0.2842359944012107]
	TIME [epoch: 24.7 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26445641359142824		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.26445641359142824 | validation: 0.21792780900292727]
	TIME [epoch: 24.9 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23390370883072276		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.23390370883072276 | validation: 0.2460682411787007]
	TIME [epoch: 24.8 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26972296041096444		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.26972296041096444 | validation: 0.22824031345045095]
	TIME [epoch: 24.8 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23718768614864055		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.23718768614864055 | validation: 0.19043698806616957]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_551.pth
	Model improved!!!
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24607991797416362		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.24607991797416362 | validation: 0.5478072217477652]
	TIME [epoch: 24.8 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3468967117142103		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.3468967117142103 | validation: 0.23648432145680734]
	TIME [epoch: 24.8 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20756260849051342		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.20756260849051342 | validation: 0.2877711315612625]
	TIME [epoch: 24.8 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26959609832987436		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.26959609832987436 | validation: 0.21293529324683624]
	TIME [epoch: 24.8 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22455052726905594		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.22455052726905594 | validation: 0.1813068930468208]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_556.pth
	Model improved!!!
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3082632799254317		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.3082632799254317 | validation: 0.21986028041075212]
	TIME [epoch: 24.8 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2456505719612594		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.2456505719612594 | validation: 0.307901798971296]
	TIME [epoch: 24.8 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37624851752727684		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.37624851752727684 | validation: 0.2730864375354907]
	TIME [epoch: 24.8 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2674734286970794		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.2674734286970794 | validation: 0.314422028963134]
	TIME [epoch: 24.8 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2857063316474514		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.2857063316474514 | validation: 0.3428353437595947]
	TIME [epoch: 24.8 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2749941687544766		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.2749941687544766 | validation: 0.22009206141856547]
	TIME [epoch: 24.8 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22351629993109154		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.22351629993109154 | validation: 0.18653508714214745]
	TIME [epoch: 24.8 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.216549060641031		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.216549060641031 | validation: 0.35433614263629226]
	TIME [epoch: 24.8 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26845405900633534		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.26845405900633534 | validation: 0.25826103047843896]
	TIME [epoch: 24.8 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2642574714012848		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.2642574714012848 | validation: 0.37924563030591674]
	TIME [epoch: 24.8 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3088622904707992		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.3088622904707992 | validation: 0.35842232235831284]
	TIME [epoch: 24.8 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32686396885618874		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.32686396885618874 | validation: 0.22721775143474335]
	TIME [epoch: 24.8 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27384980087609523		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.27384980087609523 | validation: 0.26898001657364934]
	TIME [epoch: 24.8 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25433484995534544		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.25433484995534544 | validation: 0.35199909093875037]
	TIME [epoch: 24.8 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2938341424716166		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.2938341424716166 | validation: 0.48732328791423696]
	TIME [epoch: 24.8 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3825530358489058		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.3825530358489058 | validation: 0.3048059935320946]
	TIME [epoch: 24.8 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3060871435810743		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.3060871435810743 | validation: 0.31262290549436006]
	TIME [epoch: 24.8 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33959182513897496		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.33959182513897496 | validation: 0.268109544962778]
	TIME [epoch: 24.8 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2430812269203851		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.2430812269203851 | validation: 0.3755615102875041]
	TIME [epoch: 24.8 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28072892014305767		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.28072892014305767 | validation: 0.25706012363061426]
	TIME [epoch: 24.8 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20256474824603096		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.20256474824603096 | validation: 0.1769592786031647]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_577.pth
	Model improved!!!
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1657249803396063		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.1657249803396063 | validation: 0.20507474006831686]
	TIME [epoch: 24.8 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21863749242535296		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.21863749242535296 | validation: 0.17991304419341034]
	TIME [epoch: 24.8 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18378511827642685		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.18378511827642685 | validation: 0.1962692503003071]
	TIME [epoch: 24.8 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16783965444707405		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.16783965444707405 | validation: 0.21963329372251564]
	TIME [epoch: 24.8 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21401764278682978		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.21401764278682978 | validation: 0.28335237022780446]
	TIME [epoch: 24.8 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26072321462876646		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.26072321462876646 | validation: 0.21945874599601944]
	TIME [epoch: 24.8 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26097004132049895		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.26097004132049895 | validation: 0.3888388270329577]
	TIME [epoch: 24.8 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23656759757232043		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.23656759757232043 | validation: 0.20579200057357455]
	TIME [epoch: 24.8 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21804585423225933		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.21804585423225933 | validation: 0.16885270336581867]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_586.pth
	Model improved!!!
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20198318099952384		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.20198318099952384 | validation: 0.22147859766993988]
	TIME [epoch: 24.8 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20773875964734234		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.20773875964734234 | validation: 0.2991558759089224]
	TIME [epoch: 24.8 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2778165649259757		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.2778165649259757 | validation: 0.2774572985697285]
	TIME [epoch: 24.8 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2321449006125107		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.2321449006125107 | validation: 0.17794583486023138]
	TIME [epoch: 24.8 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19687862532758743		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.19687862532758743 | validation: 0.17764896208001874]
	TIME [epoch: 24.8 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20041023334104055		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.20041023334104055 | validation: 0.26309719386274777]
	TIME [epoch: 24.8 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20993636701438464		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.20993636701438464 | validation: 0.19135463886586807]
	TIME [epoch: 24.8 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20011445567983574		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.20011445567983574 | validation: 0.20650883611740917]
	TIME [epoch: 24.8 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19288443620021073		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.19288443620021073 | validation: 0.37992186710567816]
	TIME [epoch: 24.8 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2521957245684551		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.2521957245684551 | validation: 0.17493637045308788]
	TIME [epoch: 24.9 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1509535435032594		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.1509535435032594 | validation: 0.2735375446846748]
	TIME [epoch: 24.8 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23938234655811264		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.23938234655811264 | validation: 0.2236342244806327]
	TIME [epoch: 24.8 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17323980686196214		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.17323980686196214 | validation: 0.24245874330033196]
	TIME [epoch: 24.9 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18552592272599783		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.18552592272599783 | validation: 0.16121691428881973]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_600.pth
	Model improved!!!
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2238211108871625		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.2238211108871625 | validation: 0.3548338159425418]
	TIME [epoch: 24.8 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26511179021147024		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.26511179021147024 | validation: 0.19480580381353987]
	TIME [epoch: 24.8 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25516463601165634		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.25516463601165634 | validation: 0.2194668176880559]
	TIME [epoch: 24.8 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20311181554102478		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.20311181554102478 | validation: 0.1977636015466317]
	TIME [epoch: 24.8 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2088399145101003		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.2088399145101003 | validation: 0.1761905475409233]
	TIME [epoch: 24.8 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30255360167403555		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.30255360167403555 | validation: 0.2933351722284028]
	TIME [epoch: 24.8 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.269373967749147		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.269373967749147 | validation: 0.1664206857452472]
	TIME [epoch: 24.8 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16271828948669947		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.16271828948669947 | validation: 0.20060106627175825]
	TIME [epoch: 24.8 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2317709099909661		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.2317709099909661 | validation: 0.17905679675937325]
	TIME [epoch: 24.8 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20771152701109716		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.20771152701109716 | validation: 0.24966815353398328]
	TIME [epoch: 24.8 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21250200136411226		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.21250200136411226 | validation: 0.19285335639078882]
	TIME [epoch: 24.8 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17922407356370365		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.17922407356370365 | validation: 0.2217180380505228]
	TIME [epoch: 24.8 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22986235237337221		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.22986235237337221 | validation: 0.3268811982326559]
	TIME [epoch: 24.8 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2501235723012866		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.2501235723012866 | validation: 0.35432517101060995]
	TIME [epoch: 24.8 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2885181416047381		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.2885181416047381 | validation: 0.38172098354807765]
	TIME [epoch: 24.7 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3431520423929769		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.3431520423929769 | validation: 0.34775846647681247]
	TIME [epoch: 24.8 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.351065242485781		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.351065242485781 | validation: 0.37327033373559226]
	TIME [epoch: 24.8 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27796032585078756		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.27796032585078756 | validation: 0.1774837764163184]
	TIME [epoch: 24.8 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18568456416714146		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.18568456416714146 | validation: 0.40229442194367276]
	TIME [epoch: 24.8 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2889436663463869		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.2889436663463869 | validation: 0.19038703154801673]
	TIME [epoch: 24.8 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.162664087463393		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.162664087463393 | validation: 0.16109879636037164]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_621.pth
	Model improved!!!
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15200629338423377		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.15200629338423377 | validation: 0.14225834714260674]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_622.pth
	Model improved!!!
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17935707392801226		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.17935707392801226 | validation: 0.17766180506762894]
	TIME [epoch: 24.8 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30633403437431295		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.30633403437431295 | validation: 0.2943192962023331]
	TIME [epoch: 24.8 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21857186462445855		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.21857186462445855 | validation: 0.2275788635401208]
	TIME [epoch: 24.8 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20977276391923702		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.20977276391923702 | validation: 0.15931189109565774]
	TIME [epoch: 24.8 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20153003599095953		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.20153003599095953 | validation: 0.22083407541800235]
	TIME [epoch: 24.8 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22729183362614802		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.22729183362614802 | validation: 0.19871019206931936]
	TIME [epoch: 24.8 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1874047594746665		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.1874047594746665 | validation: 0.14373051769671677]
	TIME [epoch: 24.9 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2171201979773074		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.2171201979773074 | validation: 0.3445970684530038]
	TIME [epoch: 24.8 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22989783966741748		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.22989783966741748 | validation: 0.25871040421243463]
	TIME [epoch: 24.8 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23986554871734578		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.23986554871734578 | validation: 0.21506095353499968]
	TIME [epoch: 24.8 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.204566256941213		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.204566256941213 | validation: 0.23573017574690425]
	TIME [epoch: 24.8 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23033465104079087		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.23033465104079087 | validation: 0.2497580411306438]
	TIME [epoch: 24.8 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22835784156771358		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.22835784156771358 | validation: 0.17322389056426718]
	TIME [epoch: 24.8 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.171106262893246		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.171106262893246 | validation: 0.23820619523438225]
	TIME [epoch: 24.8 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.211696549086697		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.211696549086697 | validation: 0.28219416467930825]
	TIME [epoch: 24.8 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23827611515255462		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.23827611515255462 | validation: 0.24163474214804662]
	TIME [epoch: 24.8 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2137862173534276		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.2137862173534276 | validation: 0.18157840751797238]
	TIME [epoch: 24.8 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2049053863542721		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.2049053863542721 | validation: 0.2443381291885018]
	TIME [epoch: 24.8 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2907532179750135		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.2907532179750135 | validation: 0.4504101111623392]
	TIME [epoch: 24.8 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27006609753905936		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.27006609753905936 | validation: 0.17422203001340963]
	TIME [epoch: 24.7 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20458309501898847		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.20458309501898847 | validation: 0.1894228561367229]
	TIME [epoch: 24.8 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21091857140390546		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.21091857140390546 | validation: 0.2285308142436481]
	TIME [epoch: 24.8 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21833970897820526		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.21833970897820526 | validation: 0.35626579304498507]
	TIME [epoch: 24.8 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24323318099517802		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.24323318099517802 | validation: 0.15298467015071976]
	TIME [epoch: 24.8 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16030603829051437		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.16030603829051437 | validation: 0.17858052666159765]
	TIME [epoch: 24.9 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19447103985325465		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.19447103985325465 | validation: 0.14878520268353784]
	TIME [epoch: 24.8 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18092677032411447		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.18092677032411447 | validation: 0.23336112743830076]
	TIME [epoch: 24.8 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2243876388872765		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.2243876388872765 | validation: 0.21353048091410134]
	TIME [epoch: 24.8 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19517247495492965		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.19517247495492965 | validation: 0.19539987522135677]
	TIME [epoch: 24.8 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1749704167189355		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.1749704167189355 | validation: 0.22379785632602597]
	TIME [epoch: 24.8 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2184321886085842		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.2184321886085842 | validation: 0.14858930698915057]
	TIME [epoch: 24.8 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21310274246944327		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.21310274246944327 | validation: 0.2174449614710377]
	TIME [epoch: 24.8 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21374550365652564		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.21374550365652564 | validation: 0.30239883502267434]
	TIME [epoch: 24.8 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33013461388438076		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.33013461388438076 | validation: 0.33413353486199343]
	TIME [epoch: 24.8 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2192259139603115		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.2192259139603115 | validation: 0.21505520854740048]
	TIME [epoch: 24.8 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19725618857597382		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.19725618857597382 | validation: 0.16008698009839678]
	TIME [epoch: 24.8 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16541715479099256		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.16541715479099256 | validation: 0.19551349605319665]
	TIME [epoch: 24.8 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17346828572054823		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.17346828572054823 | validation: 0.16100517555691482]
	TIME [epoch: 24.8 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17114866172067672		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.17114866172067672 | validation: 0.14585959431677142]
	TIME [epoch: 24.8 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20130729368237515		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.20130729368237515 | validation: 0.22824758182724517]
	TIME [epoch: 24.8 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19216335067723678		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.19216335067723678 | validation: 0.14267733082698209]
	TIME [epoch: 24.8 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2082220581706933		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.2082220581706933 | validation: 0.18050866932974252]
	TIME [epoch: 24.8 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1584488736341085		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.1584488736341085 | validation: 0.10687006481645145]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_665.pth
	Model improved!!!
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15548552549901348		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.15548552549901348 | validation: 0.1807731745201351]
	TIME [epoch: 24.8 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24453683554795652		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.24453683554795652 | validation: 0.14380460328744474]
	TIME [epoch: 24.8 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13633402099075279		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.13633402099075279 | validation: 0.12442823236981657]
	TIME [epoch: 24.8 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15073770587014163		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.15073770587014163 | validation: 0.17723330990448724]
	TIME [epoch: 24.8 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15502785787054443		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.15502785787054443 | validation: 0.25052304835344885]
	TIME [epoch: 24.8 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2084318560174588		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.2084318560174588 | validation: 0.21149539020419045]
	TIME [epoch: 24.9 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17400837794270488		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.17400837794270488 | validation: 0.1862944415913057]
	TIME [epoch: 24.8 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18579876455795286		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.18579876455795286 | validation: 0.16192381205072276]
	TIME [epoch: 24.8 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.157796741486232		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.157796741486232 | validation: 0.18962118006839063]
	TIME [epoch: 24.8 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17201280429299923		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.17201280429299923 | validation: 0.1681836166175949]
	TIME [epoch: 24.8 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.176308109935041		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.176308109935041 | validation: 0.1668372686567386]
	TIME [epoch: 24.8 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2123366790015089		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.2123366790015089 | validation: 0.15675369802269298]
	TIME [epoch: 24.8 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16111663547348187		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.16111663547348187 | validation: 0.22265642473424627]
	TIME [epoch: 24.8 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1698228255896056		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.1698228255896056 | validation: 0.1672262404227552]
	TIME [epoch: 24.8 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19733135222897596		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.19733135222897596 | validation: 0.21733609119163885]
	TIME [epoch: 24.8 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18268141302824925		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.18268141302824925 | validation: 0.21697259742748237]
	TIME [epoch: 24.7 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23603262517026308		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.23603262517026308 | validation: 0.22496827545439751]
	TIME [epoch: 24.8 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1994437791317184		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.1994437791317184 | validation: 0.19169095718111456]
	TIME [epoch: 24.8 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2294263923904474		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.2294263923904474 | validation: 0.21945070324470894]
	TIME [epoch: 24.8 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17058406903899534		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.17058406903899534 | validation: 0.18755488883405977]
	TIME [epoch: 24.8 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18401129776224193		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.18401129776224193 | validation: 0.19770060290107005]
	TIME [epoch: 24.8 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18543518297467337		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.18543518297467337 | validation: 0.15602042633116717]
	TIME [epoch: 24.8 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18012522467757686		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.18012522467757686 | validation: 0.19934910431495664]
	TIME [epoch: 24.8 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19794064114061427		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.19794064114061427 | validation: 0.13450298266171623]
	TIME [epoch: 24.9 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14378680530019883		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.14378680530019883 | validation: 0.1561773087298793]
	TIME [epoch: 24.8 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1618871090425927		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.1618871090425927 | validation: 0.2960722585797997]
	TIME [epoch: 24.8 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32419127041551804		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.32419127041551804 | validation: 0.35349794946833923]
	TIME [epoch: 24.8 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24697084475801656		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.24697084475801656 | validation: 0.2484091226473845]
	TIME [epoch: 24.8 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20551115314598217		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.20551115314598217 | validation: 0.22827860664202732]
	TIME [epoch: 24.8 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24285651736528208		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.24285651736528208 | validation: 0.24369218660763076]
	TIME [epoch: 24.8 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19730865689775198		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.19730865689775198 | validation: 0.13318555460816744]
	TIME [epoch: 24.8 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14425401926686052		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.14425401926686052 | validation: 0.1972791842295603]
	TIME [epoch: 24.8 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20827062997937815		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.20827062997937815 | validation: 0.17226280955623247]
	TIME [epoch: 24.8 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1764786079046297		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.1764786079046297 | validation: 0.18975626094777748]
	TIME [epoch: 24.8 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1630272648559585		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.1630272648559585 | validation: 0.15840916916626077]
	TIME [epoch: 24.8 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20569051459298993		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.20569051459298993 | validation: 0.16501664080360504]
	TIME [epoch: 24.8 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17808048401567753		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.17808048401567753 | validation: 0.1448384415641646]
	TIME [epoch: 24.7 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15513409279784732		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.15513409279784732 | validation: 0.16292848340471963]
	TIME [epoch: 24.8 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17234438724230358		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.17234438724230358 | validation: 0.3496246015634505]
	TIME [epoch: 24.8 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2699782703624653		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.2699782703624653 | validation: 0.1998683649591959]
	TIME [epoch: 24.7 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1835859755348773		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.1835859755348773 | validation: 0.16502360627604518]
	TIME [epoch: 24.8 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1541026564575352		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.1541026564575352 | validation: 0.13550994842779993]
	TIME [epoch: 24.8 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18566675671586608		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.18566675671586608 | validation: 0.15572149267558694]
	TIME [epoch: 24.8 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17581256928328234		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.17581256928328234 | validation: 0.18292613341976363]
	TIME [epoch: 24.8 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1980676241389057		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.1980676241389057 | validation: 0.17157839614909073]
	TIME [epoch: 24.8 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1975009600155464		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.1975009600155464 | validation: 0.16879863765028988]
	TIME [epoch: 24.7 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1361970548940637		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.1361970548940637 | validation: 0.16274310715947657]
	TIME [epoch: 24.8 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1441131302121462		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.1441131302121462 | validation: 0.15204145032292288]
	TIME [epoch: 24.8 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12919876980550804		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.12919876980550804 | validation: 0.1586297105864966]
	TIME [epoch: 24.7 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1665527717265828		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.1665527717265828 | validation: 0.13113926737493203]
	TIME [epoch: 24.8 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15672995576500373		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.15672995576500373 | validation: 0.1694543944171723]
	TIME [epoch: 24.8 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15401503043428338		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.15401503043428338 | validation: 0.14294037266828957]
	TIME [epoch: 24.8 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14032400447066723		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.14032400447066723 | validation: 0.16628153334124676]
	TIME [epoch: 24.8 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17544972232973408		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.17544972232973408 | validation: 0.33483531502743247]
	TIME [epoch: 24.8 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26745380083591913		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.26745380083591913 | validation: 0.1747012353383085]
	TIME [epoch: 24.7 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1861808405331799		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.1861808405331799 | validation: 0.19477780685985432]
	TIME [epoch: 24.8 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17754313940026784		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.17754313940026784 | validation: 0.263333106461807]
	TIME [epoch: 24.8 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2859688634412578		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.2859688634412578 | validation: 0.1832978908493715]
	TIME [epoch: 24.8 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17197557358671584		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.17197557358671584 | validation: 0.2119784040281006]
	TIME [epoch: 24.8 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20090337415625417		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.20090337415625417 | validation: 0.13111565416969734]
	TIME [epoch: 24.9 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19565250214993385		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.19565250214993385 | validation: 0.32686579712457225]
	TIME [epoch: 24.7 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22720383096782046		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.22720383096782046 | validation: 0.16457788894272812]
	TIME [epoch: 24.8 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17610176916188183		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.17610176916188183 | validation: 0.1569523615892154]
	TIME [epoch: 24.8 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16484251957648582		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.16484251957648582 | validation: 0.17387750473165564]
	TIME [epoch: 24.8 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16363476654877324		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.16363476654877324 | validation: 0.23124566749562128]
	TIME [epoch: 24.8 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1841455778349249		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.1841455778349249 | validation: 0.20568684099551782]
	TIME [epoch: 24.8 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20214224522422683		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.20214224522422683 | validation: 0.18257718085226046]
	TIME [epoch: 24.8 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.182032559183853		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.182032559183853 | validation: 0.17826723879789416]
	TIME [epoch: 24.8 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1683575016420122		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.1683575016420122 | validation: 0.1862951080252844]
	TIME [epoch: 24.8 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2042569737669408		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.2042569737669408 | validation: 0.2452052751952359]
	TIME [epoch: 24.8 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22802396038529604		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.22802396038529604 | validation: 0.258238523977399]
	TIME [epoch: 24.8 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20010959211600532		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.20010959211600532 | validation: 0.22268046688986304]
	TIME [epoch: 24.8 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1952118098963022		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.1952118098963022 | validation: 0.17037889446796084]
	TIME [epoch: 24.8 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17309538329786683		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.17309538329786683 | validation: 0.1293517953496327]
	TIME [epoch: 24.8 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13927376347087977		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.13927376347087977 | validation: 0.1590143745279654]
	TIME [epoch: 24.8 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17222004735166846		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.17222004735166846 | validation: 0.19409754782852084]
	TIME [epoch: 24.8 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2057375413591593		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.2057375413591593 | validation: 0.14003959212236836]
	TIME [epoch: 24.8 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14243178616667315		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.14243178616667315 | validation: 0.1516958935753289]
	TIME [epoch: 24.8 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13564542235049443		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.13564542235049443 | validation: 0.1383276780877181]
	TIME [epoch: 24.8 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1498834900362054		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.1498834900362054 | validation: 0.15166808915799992]
	TIME [epoch: 24.8 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15899592076975527		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.15899592076975527 | validation: 0.1314515422857096]
	TIME [epoch: 24.8 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15278746637957222		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.15278746637957222 | validation: 0.16865932220815924]
	TIME [epoch: 24.8 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15038551048820586		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.15038551048820586 | validation: 0.16691245135343605]
	TIME [epoch: 24.8 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15485166332688238		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.15485166332688238 | validation: 0.15932139439591653]
	TIME [epoch: 24.8 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14837154284153364		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.14837154284153364 | validation: 0.11106087084687329]
	TIME [epoch: 24.8 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11948984584426624		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.11948984584426624 | validation: 0.15222920723652844]
	TIME [epoch: 24.8 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12964793680972067		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.12964793680972067 | validation: 0.16470841997763688]
	TIME [epoch: 24.7 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15134424119544118		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.15134424119544118 | validation: 0.1266001861671222]
	TIME [epoch: 24.7 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1421699440152881		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.1421699440152881 | validation: 0.18929269450172065]
	TIME [epoch: 24.8 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16892277038473158		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.16892277038473158 | validation: 0.15509945117074167]
	TIME [epoch: 24.8 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1372872317252788		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.1372872317252788 | validation: 0.15340332306516596]
	TIME [epoch: 24.8 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13815384873898512		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.13815384873898512 | validation: 0.14005880831498282]
	TIME [epoch: 24.9 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1271020971527599		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.1271020971527599 | validation: 0.18526591981992738]
	TIME [epoch: 24.8 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1546393593187652		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.1546393593187652 | validation: 0.16097282784273934]
	TIME [epoch: 24.8 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14703011104536953		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.14703011104536953 | validation: 0.17075163420743544]
	TIME [epoch: 24.8 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17184720569352885		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.17184720569352885 | validation: 0.13390192938267748]
	TIME [epoch: 24.8 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11461596873350283		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.11461596873350283 | validation: 0.12718664651352518]
	TIME [epoch: 24.8 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13300468404799276		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.13300468404799276 | validation: 0.11787477002128957]
	TIME [epoch: 24.8 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1173706098168614		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.1173706098168614 | validation: 0.15846426369876515]
	TIME [epoch: 24.8 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13678019897602622		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.13678019897602622 | validation: 0.1627966196855821]
	TIME [epoch: 24.8 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1996376645992921		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.1996376645992921 | validation: 0.19766458333932352]
	TIME [epoch: 24.9 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19548916679187076		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.19548916679187076 | validation: 0.30927983181191726]
	TIME [epoch: 24.8 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24084352670645703		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.24084352670645703 | validation: 0.1595236658523323]
	TIME [epoch: 24.8 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15958480879641038		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.15958480879641038 | validation: 0.13079933085826034]
	TIME [epoch: 24.9 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1300750674614421		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.1300750674614421 | validation: 0.14708781927715137]
	TIME [epoch: 24.8 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16349933503876649		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.16349933503876649 | validation: 0.20851280065495573]
	TIME [epoch: 24.8 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16204120130390134		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.16204120130390134 | validation: 0.1495719918706107]
	TIME [epoch: 24.8 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16002302617758452		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.16002302617758452 | validation: 0.1577164590022226]
	TIME [epoch: 24.8 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15000188958254895		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.15000188958254895 | validation: 0.14963548403655388]
	TIME [epoch: 24.8 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1314683441487558		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.1314683441487558 | validation: 0.16429054830531095]
	TIME [epoch: 24.8 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1594399347266614		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.1594399347266614 | validation: 0.17923294072750537]
	TIME [epoch: 24.8 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17504213337100227		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.17504213337100227 | validation: 0.15649935087493264]
	TIME [epoch: 24.8 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20517204041709558		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.20517204041709558 | validation: 0.21696732205425104]
	TIME [epoch: 24.8 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15384791596513825		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.15384791596513825 | validation: 0.11946976320576912]
	TIME [epoch: 24.8 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13348487756679128		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.13348487756679128 | validation: 0.14297573915330522]
	TIME [epoch: 24.8 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1799191626674635		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.1799191626674635 | validation: 0.14617551917849012]
	TIME [epoch: 24.8 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17502606799634723		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.17502606799634723 | validation: 0.1820675409356682]
	TIME [epoch: 24.8 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15287375526037458		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.15287375526037458 | validation: 0.11900430569398633]
	TIME [epoch: 24.8 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.154171842240954		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.154171842240954 | validation: 0.14305416723588588]
	TIME [epoch: 24.9 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14254092500807947		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.14254092500807947 | validation: 0.14824977618370558]
	TIME [epoch: 24.8 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17316468083135828		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.17316468083135828 | validation: 0.22833437167040246]
	TIME [epoch: 24.8 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17917477642665045		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.17917477642665045 | validation: 0.18653834960757812]
	TIME [epoch: 24.9 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1813556445413116		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.1813556445413116 | validation: 0.12577778478038704]
	TIME [epoch: 24.8 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13571686883013875		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.13571686883013875 | validation: 0.1516555070579205]
	TIME [epoch: 24.9 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1569318166885895		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.1569318166885895 | validation: 0.16757664521801727]
	TIME [epoch: 24.9 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16883316398227108		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.16883316398227108 | validation: 0.20437763585259752]
	TIME [epoch: 24.8 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2053015802122377		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.2053015802122377 | validation: 0.17785912979577778]
	TIME [epoch: 24.8 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18421347215159092		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.18421347215159092 | validation: 0.19179177308994433]
	TIME [epoch: 24.9 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17729633310407816		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.17729633310407816 | validation: 0.27463811676533945]
	TIME [epoch: 24.8 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21653488326643738		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.21653488326643738 | validation: 0.16993356395506248]
	TIME [epoch: 24.8 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15509371477425538		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.15509371477425538 | validation: 0.1889727956805025]
	TIME [epoch: 24.9 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15533661980670077		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.15533661980670077 | validation: 0.1514695811581806]
	TIME [epoch: 24.7 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12979341936004796		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.12979341936004796 | validation: 0.1094286632300734]
	TIME [epoch: 24.8 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14968662454096168		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.14968662454096168 | validation: 0.21831546973918756]
	TIME [epoch: 24.8 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16427276957349543		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.16427276957349543 | validation: 0.13037807586653974]
	TIME [epoch: 24.7 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1176851674451376		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.1176851674451376 | validation: 0.1327831681416623]
	TIME [epoch: 24.8 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1242135369860329		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.1242135369860329 | validation: 0.14639349582277336]
	TIME [epoch: 24.8 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12734489885947622		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.12734489885947622 | validation: 0.12219941217437714]
	TIME [epoch: 24.7 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17106036510153197		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.17106036510153197 | validation: 0.19607950607068322]
	TIME [epoch: 24.8 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15337835304423902		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.15337835304423902 | validation: 0.1302994037715363]
	TIME [epoch: 24.8 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11854325763602279		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.11854325763602279 | validation: 0.10732404301014166]
	TIME [epoch: 24.7 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11778287885201194		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.11778287885201194 | validation: 0.150688286905496]
	TIME [epoch: 24.8 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1623644933579812		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.1623644933579812 | validation: 0.2301309419437078]
	TIME [epoch: 24.8 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1643965027570168		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.1643965027570168 | validation: 0.13749499068623988]
	TIME [epoch: 24.7 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14540215613651747		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.14540215613651747 | validation: 0.16875957567347846]
	TIME [epoch: 24.8 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17677721140462002		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.17677721140462002 | validation: 0.18158670380697586]
	TIME [epoch: 24.8 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15180339392508102		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.15180339392508102 | validation: 0.1415615891206727]
	TIME [epoch: 24.7 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1353449668127272		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.1353449668127272 | validation: 0.10801873385398404]
	TIME [epoch: 24.8 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11289214037347771		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.11289214037347771 | validation: 0.11631175951686429]
	TIME [epoch: 24.8 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12298844405087152		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.12298844405087152 | validation: 0.15069604064835557]
	TIME [epoch: 24.7 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12740005422743655		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.12740005422743655 | validation: 0.11353972334275175]
	TIME [epoch: 24.8 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11996524711222176		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.11996524711222176 | validation: 0.14749606632259063]
	TIME [epoch: 24.8 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1509819211263743		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.1509819211263743 | validation: 0.17241284697396822]
	TIME [epoch: 24.7 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14326705352849795		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.14326705352849795 | validation: 0.1856045479602471]
	TIME [epoch: 24.8 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1536173568046783		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.1536173568046783 | validation: 0.14236121361961687]
	TIME [epoch: 24.8 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1341629891248386		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.1341629891248386 | validation: 0.16988931050885928]
	TIME [epoch: 24.8 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21626996349462063		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.21626996349462063 | validation: 0.2316381946896579]
	TIME [epoch: 24.8 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14847099714230566		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.14847099714230566 | validation: 0.18621515028831898]
	TIME [epoch: 24.8 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15096346714718176		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.15096346714718176 | validation: 0.12948662647386236]
	TIME [epoch: 24.7 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16802205931447775		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.16802205931447775 | validation: 0.2119655183285471]
	TIME [epoch: 24.8 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1864764383616227		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.1864764383616227 | validation: 0.18241042706858424]
	TIME [epoch: 24.8 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1517094692498066		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.1517094692498066 | validation: 0.13484865899948098]
	TIME [epoch: 24.7 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13504955037652516		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.13504955037652516 | validation: 0.12607372015671725]
	TIME [epoch: 24.8 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13191250877976332		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.13191250877976332 | validation: 0.16250961116440757]
	TIME [epoch: 24.8 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14765805347936378		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.14765805347936378 | validation: 0.15443439589619345]
	TIME [epoch: 24.7 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1500610257132841		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.1500610257132841 | validation: 0.1636756061639634]
	TIME [epoch: 24.8 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13863984521421843		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.13863984521421843 | validation: 0.1033831105005591]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_832.pth
	Model improved!!!
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10574819893760351		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.10574819893760351 | validation: 0.127929527358928]
	TIME [epoch: 24.8 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1228471246712174		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.1228471246712174 | validation: 0.13418329958751218]
	TIME [epoch: 24.8 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12575241072225485		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.12575241072225485 | validation: 0.17390660983820047]
	TIME [epoch: 24.8 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.141930664445312		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.141930664445312 | validation: 0.14302104450483333]
	TIME [epoch: 24.7 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14060490224437114		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.14060490224437114 | validation: 0.13824224901501228]
	TIME [epoch: 24.8 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1322735154650461		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.1322735154650461 | validation: 0.15578080874594488]
	TIME [epoch: 24.8 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15380663229437563		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.15380663229437563 | validation: 0.1765020957158117]
	TIME [epoch: 24.7 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1601483761238397		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.1601483761238397 | validation: 0.18357986180410746]
	TIME [epoch: 24.8 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16455450867713273		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.16455450867713273 | validation: 0.22549029345341395]
	TIME [epoch: 24.8 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17713762959846036		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.17713762959846036 | validation: 0.15776131543135305]
	TIME [epoch: 24.7 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1328050923564775		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.1328050923564775 | validation: 0.10426082444510558]
	TIME [epoch: 24.7 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10914596412278912		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.10914596412278912 | validation: 0.14257174569126768]
	TIME [epoch: 24.7 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12062824647831587		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.12062824647831587 | validation: 0.14066159420548818]
	TIME [epoch: 24.7 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16863361481875583		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.16863361481875583 | validation: 0.1806741290109563]
	TIME [epoch: 24.8 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16965042563372162		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.16965042563372162 | validation: 0.1285201874927419]
	TIME [epoch: 24.7 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12207574825042541		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.12207574825042541 | validation: 0.17066486006564793]
	TIME [epoch: 24.7 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.173127044763047		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.173127044763047 | validation: 0.16738622164812605]
	TIME [epoch: 24.8 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13894382898155858		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.13894382898155858 | validation: 0.1459167904046821]
	TIME [epoch: 24.7 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1402082531970857		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.1402082531970857 | validation: 0.170047670774808]
	TIME [epoch: 24.7 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17660323235409908		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.17660323235409908 | validation: 0.19457685752899345]
	TIME [epoch: 24.8 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17442550793549655		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.17442550793549655 | validation: 0.1612173897986499]
	TIME [epoch: 24.7 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14398930432830734		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.14398930432830734 | validation: 0.16178491900556644]
	TIME [epoch: 24.8 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17331890401307354		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.17331890401307354 | validation: 0.2069042169687471]
	TIME [epoch: 24.8 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14429927015038557		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.14429927015038557 | validation: 0.13711111084754482]
	TIME [epoch: 24.7 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12101656685789534		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.12101656685789534 | validation: 0.12042388026299379]
	TIME [epoch: 24.8 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11987586204397661		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.11987586204397661 | validation: 0.1254097173742585]
	TIME [epoch: 24.8 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12031930411619013		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.12031930411619013 | validation: 0.15047572821022523]
	TIME [epoch: 24.7 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11943496240899236		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.11943496240899236 | validation: 0.1486947914205913]
	TIME [epoch: 24.7 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11568695803013844		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.11568695803013844 | validation: 0.10883797943876626]
	TIME [epoch: 24.8 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13716666595551544		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.13716666595551544 | validation: 0.22992180132202505]
	TIME [epoch: 24.7 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18879996000729402		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.18879996000729402 | validation: 0.1672853200793695]
	TIME [epoch: 24.7 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1524116331553223		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.1524116331553223 | validation: 0.14776460856009624]
	TIME [epoch: 24.7 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15985380269788327		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.15985380269788327 | validation: 0.17269220984627195]
	TIME [epoch: 24.7 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19838638164527267		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.19838638164527267 | validation: 0.1782140434212558]
	TIME [epoch: 24.7 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14965338355776264		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.14965338355776264 | validation: 0.16267278427614465]
	TIME [epoch: 24.8 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14664025681082424		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.14664025681082424 | validation: 0.12707927692002297]
	TIME [epoch: 24.8 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12916368409520554		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.12916368409520554 | validation: 0.15436797539304373]
	TIME [epoch: 24.8 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14825001091545695		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.14825001091545695 | validation: 0.15044581191613385]
	TIME [epoch: 24.8 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15888095030925356		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.15888095030925356 | validation: 0.14688516332204618]
	TIME [epoch: 24.8 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14528343532346424		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.14528343532346424 | validation: 0.1403321400473777]
	TIME [epoch: 24.8 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15686557990168318		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.15686557990168318 | validation: 0.1746297770032002]
	TIME [epoch: 24.8 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17728409990463206		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.17728409990463206 | validation: 0.1277184205028044]
	TIME [epoch: 24.7 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13842978658736443		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.13842978658736443 | validation: 0.13975311575236737]
	TIME [epoch: 24.7 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16018104360205415		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.16018104360205415 | validation: 0.15703733259187086]
	TIME [epoch: 24.8 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1762068320399606		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.1762068320399606 | validation: 0.18457383190242227]
	TIME [epoch: 24.7 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1472735636043666		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.1472735636043666 | validation: 0.13528344958360372]
	TIME [epoch: 24.8 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13735128135815747		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.13735128135815747 | validation: 0.1608758906718176]
	TIME [epoch: 24.8 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13977678169972213		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.13977678169972213 | validation: 0.16108020249175237]
	TIME [epoch: 24.8 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.142063126180996		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.142063126180996 | validation: 0.13285942706602724]
	TIME [epoch: 24.7 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1269621259353022		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.1269621259353022 | validation: 0.14652963976014965]
	TIME [epoch: 24.8 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1533323947029604		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.1533323947029604 | validation: 0.1711814266273921]
	TIME [epoch: 24.7 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13462477679521595		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.13462477679521595 | validation: 0.12750739174346257]
	TIME [epoch: 24.7 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14130349779294898		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.14130349779294898 | validation: 0.14968710466908186]
	TIME [epoch: 24.8 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13167879883045333		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.13167879883045333 | validation: 0.12886576199055308]
	TIME [epoch: 24.7 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1319124888262505		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.1319124888262505 | validation: 0.12770261477003728]
	TIME [epoch: 24.8 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1303725659545409		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.1303725659545409 | validation: 0.1291452557172207]
	TIME [epoch: 24.8 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1259817219632333		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.1259817219632333 | validation: 0.13240525019258736]
	TIME [epoch: 24.7 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11890060754871516		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.11890060754871516 | validation: 0.12359233779058584]
	TIME [epoch: 24.8 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12573435883239129		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.12573435883239129 | validation: 0.11673722046181896]
	TIME [epoch: 24.8 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11595963347663468		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.11595963347663468 | validation: 0.1373693520828488]
	TIME [epoch: 24.7 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13177832510592064		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.13177832510592064 | validation: 0.15580272291850458]
	TIME [epoch: 24.8 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14784469330564692		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.14784469330564692 | validation: 0.14676871971651673]
	TIME [epoch: 24.8 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15015744848599447		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.15015744848599447 | validation: 0.12913943523602464]
	TIME [epoch: 24.8 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13549779614236568		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.13549779614236568 | validation: 0.13981107760488862]
	TIME [epoch: 24.8 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14407641059394422		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.14407641059394422 | validation: 0.13147819901992017]
	TIME [epoch: 24.7 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11184835773449138		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.11184835773449138 | validation: 0.1273437048422783]
	TIME [epoch: 24.7 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1264139337079387		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.1264139337079387 | validation: 0.15322208244659682]
	TIME [epoch: 24.8 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1601298890626878		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.1601298890626878 | validation: 0.17123040372436904]
	TIME [epoch: 24.8 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13814521021672738		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.13814521021672738 | validation: 0.1180448922887868]
	TIME [epoch: 24.8 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12847149504254776		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.12847149504254776 | validation: 0.18194048947059926]
	TIME [epoch: 24.8 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1452972379800705		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.1452972379800705 | validation: 0.13243601196634316]
	TIME [epoch: 24.8 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12540701096070292		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.12540701096070292 | validation: 0.10262594284862255]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_904.pth
	Model improved!!!
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11093439841854821		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.11093439841854821 | validation: 0.18206014577682172]
	TIME [epoch: 24.8 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14140760778268313		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.14140760778268313 | validation: 0.15209256249514713]
	TIME [epoch: 24.8 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13282962536204235		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.13282962536204235 | validation: 0.13004328314788335]
	TIME [epoch: 24.7 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11411515806257688		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.11411515806257688 | validation: 0.13008584612191768]
	TIME [epoch: 24.8 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12728890651660799		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.12728890651660799 | validation: 0.17187767426383116]
	TIME [epoch: 24.8 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14632092778961875		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.14632092778961875 | validation: 0.13338680544432055]
	TIME [epoch: 24.7 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11953144495550325		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.11953144495550325 | validation: 0.12078735478625398]
	TIME [epoch: 24.8 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12038826299349509		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.12038826299349509 | validation: 0.11667431611279405]
	TIME [epoch: 24.8 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11511619180045897		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.11511619180045897 | validation: 0.12663466602177942]
	TIME [epoch: 24.7 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12971781998851367		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.12971781998851367 | validation: 0.12303081391996845]
	TIME [epoch: 24.8 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11627395689948572		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.11627395689948572 | validation: 0.11211105035358411]
	TIME [epoch: 24.8 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10447060872231502		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.10447060872231502 | validation: 0.12815200923898168]
	TIME [epoch: 24.8 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12601430872895542		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.12601430872895542 | validation: 0.1361167712025519]
	TIME [epoch: 24.8 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12126668688775961		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.12126668688775961 | validation: 0.15499099023622942]
	TIME [epoch: 24.8 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11824703907809607		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.11824703907809607 | validation: 0.12507212684793825]
	TIME [epoch: 24.7 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11193445010540878		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.11193445010540878 | validation: 0.12271616124731365]
	TIME [epoch: 24.8 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12127630320537687		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.12127630320537687 | validation: 0.12663379972983635]
	TIME [epoch: 24.8 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12615878096958255		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.12615878096958255 | validation: 0.1459070128698858]
	TIME [epoch: 24.7 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13467297410550777		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.13467297410550777 | validation: 0.1945762393899961]
	TIME [epoch: 24.8 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1697626060337357		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.1697626060337357 | validation: 0.19039646007501654]
	TIME [epoch: 24.8 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13296928306762418		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.13296928306762418 | validation: 0.1541419656857354]
	TIME [epoch: 24.7 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1348107349047124		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.1348107349047124 | validation: 0.1784935117823052]
	TIME [epoch: 24.8 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13765772590366296		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.13765772590366296 | validation: 0.1560015233264316]
	TIME [epoch: 24.8 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12761788483561234		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.12761788483561234 | validation: 0.13562779602536942]
	TIME [epoch: 24.7 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10952308797857367		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.10952308797857367 | validation: 0.14568853791492006]
	TIME [epoch: 24.8 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12591313975535928		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.12591313975535928 | validation: 0.13894169493201516]
	TIME [epoch: 24.8 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12017952663795592		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.12017952663795592 | validation: 0.1262321327391535]
	TIME [epoch: 24.7 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10315631246486578		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.10315631246486578 | validation: 0.11730487520690097]
	TIME [epoch: 24.8 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11766084206669274		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.11766084206669274 | validation: 0.13979103250546612]
	TIME [epoch: 24.8 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12045785898100447		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.12045785898100447 | validation: 0.13483066459924742]
	TIME [epoch: 24.8 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11396952468556942		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.11396952468556942 | validation: 0.12523446214442585]
	TIME [epoch: 24.8 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11170433345664918		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.11170433345664918 | validation: 0.13031789951874506]
	TIME [epoch: 24.8 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10486756872226805		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.10486756872226805 | validation: 0.13723240772713394]
	TIME [epoch: 24.8 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1205475516802762		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.1205475516802762 | validation: 0.15403280168646216]
	TIME [epoch: 24.8 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1297366439919701		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.1297366439919701 | validation: 0.13736107213396065]
	TIME [epoch: 24.8 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10999625470902191		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.10999625470902191 | validation: 0.11727847747579478]
	TIME [epoch: 24.8 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11768522166234731		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.11768522166234731 | validation: 0.13928792015298516]
	TIME [epoch: 24.8 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10508021905840277		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.10508021905840277 | validation: 0.1220827543564279]
	TIME [epoch: 24.8 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11939983370281124		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.11939983370281124 | validation: 0.15675399478478802]
	TIME [epoch: 24.8 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1251937091078801		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.1251937091078801 | validation: 0.1381790119813499]
	TIME [epoch: 24.9 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1488656244205051		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.1488656244205051 | validation: 0.14262759942661993]
	TIME [epoch: 24.8 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10682356631681353		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.10682356631681353 | validation: 0.15041044262703224]
	TIME [epoch: 24.8 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12303721820457834		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.12303721820457834 | validation: 0.13447388633051266]
	TIME [epoch: 24.9 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1136709024303646		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.1136709024303646 | validation: 0.12286521853851971]
	TIME [epoch: 24.8 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1515197371086726		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.1515197371086726 | validation: 0.1973353016362831]
	TIME [epoch: 24.8 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20785451200348		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.20785451200348 | validation: 0.15255800230478223]
	TIME [epoch: 24.8 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1509820985917496		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.1509820985917496 | validation: 0.1618835434967147]
	TIME [epoch: 24.8 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15296644923896593		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.15296644923896593 | validation: 0.13938554036952525]
	TIME [epoch: 24.8 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13703940106628543		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.13703940106628543 | validation: 0.1278301984163363]
	TIME [epoch: 24.8 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10868096705963146		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.10868096705963146 | validation: 0.11831059796943372]
	TIME [epoch: 24.8 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12286960671246751		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.12286960671246751 | validation: 0.18278208369972468]
	TIME [epoch: 24.8 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12386964853279786		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.12386964853279786 | validation: 0.1371258284530805]
	TIME [epoch: 24.8 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11511884156963201		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.11511884156963201 | validation: 0.15186015056257154]
	TIME [epoch: 24.8 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11477497358252006		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.11477497358252006 | validation: 0.12493848982712397]
	TIME [epoch: 24.8 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09826765211433763		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.09826765211433763 | validation: 0.1177444650079512]
	TIME [epoch: 24.8 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12002114885533421		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.12002114885533421 | validation: 0.1331277493022956]
	TIME [epoch: 24.8 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11094543558372971		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.11094543558372971 | validation: 0.11019340534690454]
	TIME [epoch: 24.8 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10896406212422713		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.10896406212422713 | validation: 0.12253841689232027]
	TIME [epoch: 24.9 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1070375444845426		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.1070375444845426 | validation: 0.11430304932289927]
	TIME [epoch: 24.8 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10442143979406202		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.10442143979406202 | validation: 0.11006776465997195]
	TIME [epoch: 24.8 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12368287688463406		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.12368287688463406 | validation: 0.14626979464887435]
	TIME [epoch: 24.8 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10795667583074045		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.10795667583074045 | validation: 0.11083130769090177]
	TIME [epoch: 24.8 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11149778846202762		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.11149778846202762 | validation: 0.126875461158452]
	TIME [epoch: 24.8 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1343689022971693		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.1343689022971693 | validation: 0.11994355876074828]
	TIME [epoch: 24.8 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10584593701533102		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.10584593701533102 | validation: 0.10416591119528397]
	TIME [epoch: 24.8 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10378227314271257		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.10378227314271257 | validation: 0.1306711366505257]
	TIME [epoch: 24.8 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11978935863175028		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.11978935863175028 | validation: 0.13641113542035757]
	TIME [epoch: 24.9 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12146627796651162		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.12146627796651162 | validation: 0.12244291167677386]
	TIME [epoch: 24.8 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13371876246278405		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.13371876246278405 | validation: 0.14503163269942387]
	TIME [epoch: 24.8 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1362891242214558		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.1362891242214558 | validation: 0.19268095564102816]
	TIME [epoch: 24.8 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15050684751925014		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.15050684751925014 | validation: 0.15324587692910194]
	TIME [epoch: 24.8 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13117717895148948		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.13117717895148948 | validation: 0.12842870467815654]
	TIME [epoch: 24.8 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12091481787935424		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.12091481787935424 | validation: 0.12204617458766792]
	TIME [epoch: 24.8 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11618847345653067		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.11618847345653067 | validation: 0.11889511108986035]
	TIME [epoch: 24.8 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11634018300487106		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.11634018300487106 | validation: 0.1232898977507983]
	TIME [epoch: 24.8 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11464977221789366		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.11464977221789366 | validation: 0.13428649147713437]
	TIME [epoch: 24.8 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12307663503519463		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.12307663503519463 | validation: 0.13665308840405582]
	TIME [epoch: 24.8 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1251819740950624		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.1251819740950624 | validation: 0.16743301894874293]
	TIME [epoch: 24.8 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1295706540387948		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.1295706540387948 | validation: 0.12979545516304616]
	TIME [epoch: 24.8 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11159096197635002		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.11159096197635002 | validation: 0.13338125006703072]
	TIME [epoch: 24.8 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11135774214383987		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.11135774214383987 | validation: 0.14817662129656747]
	TIME [epoch: 24.8 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12917456646852968		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.12917456646852968 | validation: 0.13613065770800575]
	TIME [epoch: 24.8 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11551626663323539		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.11551626663323539 | validation: 0.13387394495836866]
	TIME [epoch: 24.8 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12733744179961096		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.12733744179961096 | validation: 0.1545410637412578]
	TIME [epoch: 24.7 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14317061537049863		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.14317061537049863 | validation: 0.12069466279429043]
	TIME [epoch: 24.8 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10926157015300064		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.10926157015300064 | validation: 0.11653865040735245]
	TIME [epoch: 24.8 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10406392162582664		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.10406392162582664 | validation: 0.11877516066987057]
	TIME [epoch: 24.7 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12422737526609799		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.12422737526609799 | validation: 0.17730571335459822]
	TIME [epoch: 24.8 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14373912595945304		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.14373912595945304 | validation: 0.1788348344281705]
	TIME [epoch: 24.8 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14043336807161713		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.14043336807161713 | validation: 0.14306595611830278]
	TIME [epoch: 24.8 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12259726553794521		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.12259726553794521 | validation: 0.12274574116218473]
	TIME [epoch: 24.8 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1215648383030672		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.1215648383030672 | validation: 0.16455164099884434]
	TIME [epoch: 24.7 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13188156727076694		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.13188156727076694 | validation: 0.13652365319382448]
	TIME [epoch: 24.8 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11515816941271731		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.11515816941271731 | validation: 0.16241683185004172]
	TIME [epoch: 24.8 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13807693405148344		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.13807693405148344 | validation: 0.1733218538411142]
	TIME [epoch: 24.7 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12506460527532784		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.12506460527532784 | validation: 0.1463688253145381]
	TIME [epoch: 24.8 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11954114383612988		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.11954114383612988 | validation: 0.13034764122191383]
	TIME [epoch: 24.8 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10744823407588774		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.10744823407588774 | validation: 0.14112097133921503]
	TIME [epoch: 24.8 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1294675394749788		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.1294675394749788 | validation: 0.14434320707630713]
	TIME [epoch: 24.8 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10832151557724876		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.10832151557724876 | validation: 0.11410512053408732]
	TIME [epoch: 24.8 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10578603092337538		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.10578603092337538 | validation: 0.14060205490569933]
	TIME [epoch: 24.8 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11165710270003022		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.11165710270003022 | validation: 0.13068616475854528]
	TIME [epoch: 24.8 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10736359276327509		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.10736359276327509 | validation: 0.12067026182694432]
	TIME [epoch: 24.9 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11426592836954125		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.11426592836954125 | validation: 0.11881755280329309]
	TIME [epoch: 24.8 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.132827300433055		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.132827300433055 | validation: 0.11838954022755427]
	TIME [epoch: 24.8 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10130568431364592		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.10130568431364592 | validation: 0.1362514479823005]
	TIME [epoch: 24.8 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10690423124627482		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.10690423124627482 | validation: 0.10934675002610213]
	TIME [epoch: 24.7 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1193819175493017		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.1193819175493017 | validation: 0.1306709155786041]
	TIME [epoch: 24.8 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12476227347955411		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.12476227347955411 | validation: 0.1102639547691728]
	TIME [epoch: 24.8 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10973122214560915		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.10973122214560915 | validation: 0.1278215640299889]
	TIME [epoch: 24.8 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11516531408168648		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.11516531408168648 | validation: 0.12700965087452126]
	TIME [epoch: 24.8 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12166144779319168		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.12166144779319168 | validation: 0.12026702265450091]
	TIME [epoch: 24.8 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10928374364916552		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.10928374364916552 | validation: 0.13429254938982915]
	TIME [epoch: 24.7 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10356825510719068		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.10356825510719068 | validation: 0.12906121898229653]
	TIME [epoch: 24.8 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1262850802664338		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.1262850802664338 | validation: 0.16399688189324912]
	TIME [epoch: 24.8 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12325842184006443		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.12325842184006443 | validation: 0.13374348836948355]
	TIME [epoch: 24.7 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11235329468739096		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.11235329468739096 | validation: 0.1337915491604926]
	TIME [epoch: 24.8 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10523942786682243		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.10523942786682243 | validation: 0.1109553563357569]
	TIME [epoch: 24.8 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10902654851395262		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.10902654851395262 | validation: 0.14007476237672087]
	TIME [epoch: 24.7 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12563032385110226		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.12563032385110226 | validation: 0.11832775895532387]
	TIME [epoch: 24.8 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10133378219161103		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.10133378219161103 | validation: 0.12088935745890897]
	TIME [epoch: 24.8 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09864881945525308		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.09864881945525308 | validation: 0.11821597299105326]
	TIME [epoch: 24.7 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11047314047707586		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.11047314047707586 | validation: 0.12658117653766357]
	TIME [epoch: 24.8 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11150453382615971		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.11150453382615971 | validation: 0.1484508511703377]
	TIME [epoch: 24.8 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10920008369618929		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.10920008369618929 | validation: 0.11075632559076773]
	TIME [epoch: 24.8 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09228678861001062		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.09228678861001062 | validation: 0.1309697915405957]
	TIME [epoch: 24.8 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11663986014170455		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.11663986014170455 | validation: 0.13236414246871395]
	TIME [epoch: 24.8 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11139649837033447		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.11139649837033447 | validation: 0.1436967736214505]
	TIME [epoch: 24.7 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11973211416905963		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.11973211416905963 | validation: 0.11942294060329058]
	TIME [epoch: 24.8 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12013388441768968		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.12013388441768968 | validation: 0.13164667391649296]
	TIME [epoch: 24.8 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12224232184458865		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.12224232184458865 | validation: 0.1320663007377386]
	TIME [epoch: 24.7 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1149046650274208		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.1149046650274208 | validation: 0.13860906542147813]
	TIME [epoch: 24.8 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09933074884035913		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.09933074884035913 | validation: 0.10676184324132165]
	TIME [epoch: 24.8 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09399875881725275		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.09399875881725275 | validation: 0.10908226647989562]
	TIME [epoch: 24.7 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09526731511146254		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.09526731511146254 | validation: 0.11751817242591962]
	TIME [epoch: 24.8 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11106060983140587		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.11106060983140587 | validation: 0.13363272622564537]
	TIME [epoch: 24.8 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13197674028367534		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.13197674028367534 | validation: 0.12272249166680346]
	TIME [epoch: 24.7 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12459449567046693		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.12459449567046693 | validation: 0.12592813757256455]
	TIME [epoch: 24.8 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11536732238226186		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.11536732238226186 | validation: 0.13249852774047038]
	TIME [epoch: 24.8 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1478476562597063		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.1478476562597063 | validation: 0.16299027437730104]
	TIME [epoch: 24.7 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15985203644307505		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.15985203644307505 | validation: 0.17083273808940683]
	TIME [epoch: 24.8 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13903550162304537		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.13903550162304537 | validation: 0.12601479159506812]
	TIME [epoch: 24.8 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11426156030937777		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.11426156030937777 | validation: 0.12137049913445644]
	TIME [epoch: 24.7 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10967816434338479		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.10967816434338479 | validation: 0.11552439346336497]
	TIME [epoch: 24.8 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10345899157661556		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.10345899157661556 | validation: 0.1279023057965149]
	TIME [epoch: 24.8 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11519007499938051		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.11519007499938051 | validation: 0.13742969155040866]
	TIME [epoch: 24.7 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11214090473823579		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.11214090473823579 | validation: 0.12728850456506785]
	TIME [epoch: 24.8 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11391673127916557		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.11391673127916557 | validation: 0.12296662668218247]
	TIME [epoch: 24.8 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11592137213904495		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.11592137213904495 | validation: 0.11622100733705348]
	TIME [epoch: 24.7 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10809775661601974		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.10809775661601974 | validation: 0.10236010626415859]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_1054.pth
	Model improved!!!
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11038557197567697		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.11038557197567697 | validation: 0.10938607870208163]
	TIME [epoch: 24.8 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10294031139200238		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.10294031139200238 | validation: 0.11746077247386903]
	TIME [epoch: 24.8 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12459670897925382		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.12459670897925382 | validation: 0.1511599861877701]
	TIME [epoch: 24.8 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12979362390995555		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.12979362390995555 | validation: 0.1344110559490375]
	TIME [epoch: 24.8 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11646361090354915		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.11646361090354915 | validation: 0.15572368774598278]
	TIME [epoch: 24.8 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11175755339556043		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.11175755339556043 | validation: 0.10883640734024269]
	TIME [epoch: 24.8 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10413614355673188		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.10413614355673188 | validation: 0.11714838301590647]
	TIME [epoch: 24.8 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10078997534095988		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.10078997534095988 | validation: 0.11614812806402697]
	TIME [epoch: 24.8 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0945543863362232		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.0945543863362232 | validation: 0.11313034032693915]
	TIME [epoch: 24.8 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09248713361237848		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.09248713361237848 | validation: 0.11226235104032804]
	TIME [epoch: 24.8 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10262826553180995		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.10262826553180995 | validation: 0.13531760159659967]
	TIME [epoch: 24.8 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09658990368752901		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.09658990368752901 | validation: 0.1128168800983085]
	TIME [epoch: 24.8 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1013562871251184		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.1013562871251184 | validation: 0.11402767484413089]
	TIME [epoch: 24.8 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10247258684172803		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.10247258684172803 | validation: 0.10969611309377658]
	TIME [epoch: 24.8 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09358965319210752		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.09358965319210752 | validation: 0.12554329786248192]
	TIME [epoch: 24.8 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09703865479663284		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.09703865479663284 | validation: 0.12418536319306486]
	TIME [epoch: 24.8 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1131679014585239		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.1131679014585239 | validation: 0.14677720973556554]
	TIME [epoch: 24.8 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1231805806593504		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.1231805806593504 | validation: 0.15381122814714077]
	TIME [epoch: 24.8 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11518084188130634		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.11518084188130634 | validation: 0.13891646223331436]
	TIME [epoch: 24.8 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11732415355658377		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.11732415355658377 | validation: 0.15829378794258825]
	TIME [epoch: 24.8 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12082329492107072		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.12082329492107072 | validation: 0.12516618518019842]
	TIME [epoch: 24.8 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0993411629425846		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.0993411629425846 | validation: 0.12053024949359126]
	TIME [epoch: 24.8 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10186782519756578		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.10186782519756578 | validation: 0.11798182050475452]
	TIME [epoch: 24.8 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10099365012009535		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.10099365012009535 | validation: 0.12253381267495975]
	TIME [epoch: 24.8 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10352021958880314		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.10352021958880314 | validation: 0.11542170281180657]
	TIME [epoch: 24.8 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10594731122181728		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.10594731122181728 | validation: 0.13354797089716777]
	TIME [epoch: 24.8 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10759122145089273		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.10759122145089273 | validation: 0.12180215311123607]
	TIME [epoch: 24.8 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10019620656476724		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.10019620656476724 | validation: 0.11733998318488459]
	TIME [epoch: 24.8 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10580557142256511		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.10580557142256511 | validation: 0.11684349844762153]
	TIME [epoch: 24.8 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0935862195898276		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.0935862195898276 | validation: 0.10973654985300461]
	TIME [epoch: 24.8 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09655678199022458		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.09655678199022458 | validation: 0.1086110704177462]
	TIME [epoch: 24.8 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09079731225582827		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.09079731225582827 | validation: 0.11026946178111409]
	TIME [epoch: 24.8 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09641740193010157		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.09641740193010157 | validation: 0.10964199785999178]
	TIME [epoch: 24.8 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10888351184479722		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.10888351184479722 | validation: 0.14926204602881463]
	TIME [epoch: 24.8 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13308652863034753		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.13308652863034753 | validation: 0.1459013893902053]
	TIME [epoch: 24.8 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09715112548045793		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.09715112548045793 | validation: 0.10222518271270818]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_1090.pth
	Model improved!!!
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09669796935287853		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.09669796935287853 | validation: 0.10682135045485733]
	TIME [epoch: 24.8 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09277764237498597		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.09277764237498597 | validation: 0.11401647146205836]
	TIME [epoch: 24.8 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10794261435020658		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.10794261435020658 | validation: 0.11869968984630536]
	TIME [epoch: 24.8 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09608887503590882		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.09608887503590882 | validation: 0.11576166905630336]
	TIME [epoch: 24.8 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09102534432218158		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.09102534432218158 | validation: 0.11593363674449186]
	TIME [epoch: 24.8 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10272535239113534		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.10272535239113534 | validation: 0.11493407685145858]
	TIME [epoch: 24.8 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09777468826373294		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.09777468826373294 | validation: 0.09861850096783913]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_1097.pth
	Model improved!!!
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0920648262318573		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.0920648262318573 | validation: 0.10636443108076236]
	TIME [epoch: 24.8 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09328228415936562		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.09328228415936562 | validation: 0.10933010072638848]
	TIME [epoch: 24.8 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09335283236610671		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.09335283236610671 | validation: 0.11051100668250005]
	TIME [epoch: 24.8 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1185477048672664		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.1185477048672664 | validation: 0.1318792525062029]
	TIME [epoch: 24.8 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10167231742289033		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.10167231742289033 | validation: 0.09806377006631678]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_1102.pth
	Model improved!!!
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09483868293520144		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.09483868293520144 | validation: 0.1057047241895275]
	TIME [epoch: 24.8 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09567424930551845		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.09567424930551845 | validation: 0.09592938682896582]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_1104.pth
	Model improved!!!
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09396097007481669		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.09396097007481669 | validation: 0.09824100118805504]
	TIME [epoch: 24.8 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0916890958238111		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.0916890958238111 | validation: 0.11169004422267584]
	TIME [epoch: 24.8 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0935353570569171		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.0935353570569171 | validation: 0.11732922749557442]
	TIME [epoch: 24.8 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10067657124658523		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.10067657124658523 | validation: 0.1237909932801415]
	TIME [epoch: 24.8 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10567821259775675		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.10567821259775675 | validation: 0.12249583607314182]
	TIME [epoch: 24.8 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09473081760071488		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.09473081760071488 | validation: 0.0971822538180106]
	TIME [epoch: 24.8 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08598599406591974		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.08598599406591974 | validation: 0.10424368730486233]
	TIME [epoch: 24.8 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.102925390598109		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.102925390598109 | validation: 0.12229702957425544]
	TIME [epoch: 24.8 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10464499613678796		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.10464499613678796 | validation: 0.10337074389752453]
	TIME [epoch: 24.8 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09362685347636196		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.09362685347636196 | validation: 0.10714715059861149]
	TIME [epoch: 24.8 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10549490915905088		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.10549490915905088 | validation: 0.11569782625278358]
	TIME [epoch: 24.8 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09814453394312873		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.09814453394312873 | validation: 0.10445767844840212]
	TIME [epoch: 24.8 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09359730924103749		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.09359730924103749 | validation: 0.10276318593678482]
	TIME [epoch: 24.8 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0967790019815043		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.0967790019815043 | validation: 0.10948655772582608]
	TIME [epoch: 24.8 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0963795740189995		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.0963795740189995 | validation: 0.11888277032422943]
	TIME [epoch: 24.8 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09174912479548912		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.09174912479548912 | validation: 0.10723181887678687]
	TIME [epoch: 24.8 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09664333877282562		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.09664333877282562 | validation: 0.09842913398984254]
	TIME [epoch: 24.8 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09341084031917346		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.09341084031917346 | validation: 0.11188690102285069]
	TIME [epoch: 24.8 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08986004500727045		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.08986004500727045 | validation: 0.10612370470422888]
	TIME [epoch: 24.8 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0914436901246787		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.0914436901246787 | validation: 0.11549098453111588]
	TIME [epoch: 24.8 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0904225874408088		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.0904225874408088 | validation: 0.11852003027013991]
	TIME [epoch: 24.8 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0993234455411963		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.0993234455411963 | validation: 0.11216204595580954]
	TIME [epoch: 24.8 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10506093941397464		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.10506093941397464 | validation: 0.11140906727192552]
	TIME [epoch: 24.8 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09758043711721495		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.09758043711721495 | validation: 0.1127318573578777]
	TIME [epoch: 24.8 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09037608327724198		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.09037608327724198 | validation: 0.10906937123265185]
	TIME [epoch: 24.8 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09107859824873199		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.09107859824873199 | validation: 0.11411534895936132]
	TIME [epoch: 24.8 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0975175292120975		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.0975175292120975 | validation: 0.10292742851262233]
	TIME [epoch: 24.8 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08696915834218967		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.08696915834218967 | validation: 0.10673315615197587]
	TIME [epoch: 24.8 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08534996700691592		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.08534996700691592 | validation: 0.10854253779607032]
	TIME [epoch: 24.7 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09188260768998088		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.09188260768998088 | validation: 0.10633341337899578]
	TIME [epoch: 24.8 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09051070034542588		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.09051070034542588 | validation: 0.10645877672364464]
	TIME [epoch: 24.8 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09078436865745695		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.09078436865745695 | validation: 0.1307087195627233]
	TIME [epoch: 24.8 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12236511369148675		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.12236511369148675 | validation: 0.12570173049026157]
	TIME [epoch: 24.8 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10119829271179578		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.10119829271179578 | validation: 0.11028847504733244]
	TIME [epoch: 24.8 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0968580894676149		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.0968580894676149 | validation: 0.12793351009480258]
	TIME [epoch: 24.8 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11085273881542118		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.11085273881542118 | validation: 0.138168594279162]
	TIME [epoch: 24.8 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1138398324464523		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.1138398324464523 | validation: 0.1334281634203321]
	TIME [epoch: 24.8 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09946895133590361		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.09946895133590361 | validation: 0.10482231519474508]
	TIME [epoch: 24.7 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0975959920743405		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.0975959920743405 | validation: 0.10742960692595396]
	TIME [epoch: 24.7 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10051990380157776		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.10051990380157776 | validation: 0.0952337324673551]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_1144.pth
	Model improved!!!
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08580198525956578		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.08580198525956578 | validation: 0.09989952703401897]
	TIME [epoch: 24.8 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0838045786989906		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.0838045786989906 | validation: 0.09058508631197676]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_1146.pth
	Model improved!!!
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0880814980844051		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.0880814980844051 | validation: 0.10265854562343826]
	TIME [epoch: 24.8 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08931249499374509		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.08931249499374509 | validation: 0.09437282398243926]
	TIME [epoch: 24.7 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09137899703449967		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.09137899703449967 | validation: 0.10586946091183767]
	TIME [epoch: 24.7 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09212221848870152		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.09212221848870152 | validation: 0.10412436051341914]
	TIME [epoch: 24.8 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09320212020120203		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.09320212020120203 | validation: 0.0894559771655717]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_1151.pth
	Model improved!!!
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09264927143718465		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.09264927143718465 | validation: 0.09806637575191106]
	TIME [epoch: 24.8 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08540185131544648		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.08540185131544648 | validation: 0.10742524529072067]
	TIME [epoch: 24.8 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0954600715319954		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.0954600715319954 | validation: 0.11861692881449117]
	TIME [epoch: 24.8 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11343146274436276		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.11343146274436276 | validation: 0.11649093330675182]
	TIME [epoch: 24.7 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09834653888495996		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.09834653888495996 | validation: 0.11122310579127702]
	TIME [epoch: 24.8 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.085611877060841		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.085611877060841 | validation: 0.10267427059926046]
	TIME [epoch: 24.8 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09372085199646815		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.09372085199646815 | validation: 0.11013867638473653]
	TIME [epoch: 24.7 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09242586489192052		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.09242586489192052 | validation: 0.10139389089946535]
	TIME [epoch: 24.8 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09326655979703521		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.09326655979703521 | validation: 0.11334854267368809]
	TIME [epoch: 24.7 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10031931912189587		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.10031931912189587 | validation: 0.10204723547888697]
	TIME [epoch: 24.8 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08823671564546301		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.08823671564546301 | validation: 0.09497192395168544]
	TIME [epoch: 24.8 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08940975068676907		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.08940975068676907 | validation: 0.09631201035693639]
	TIME [epoch: 24.8 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08898063683573468		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.08898063683573468 | validation: 0.10016784412459825]
	TIME [epoch: 24.7 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08960697269192996		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.08960697269192996 | validation: 0.0895450052689079]
	TIME [epoch: 24.8 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09083275118287139		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.09083275118287139 | validation: 0.10450979487842255]
	TIME [epoch: 24.7 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09188752318727937		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.09188752318727937 | validation: 0.1049311012263417]
	TIME [epoch: 24.8 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09923522440351555		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.09923522440351555 | validation: 0.1104180173312771]
	TIME [epoch: 24.8 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09363859832058427		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.09363859832058427 | validation: 0.10612553930192746]
	TIME [epoch: 24.7 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08897400577893813		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.08897400577893813 | validation: 0.09786705107561576]
	TIME [epoch: 24.8 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0856191100685879		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.0856191100685879 | validation: 0.0895775827470742]
	TIME [epoch: 24.8 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08257453582929525		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.08257453582929525 | validation: 0.09882619368013963]
	TIME [epoch: 24.7 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0942446675476045		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.0942446675476045 | validation: 0.09174474988216078]
	TIME [epoch: 24.8 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09188212622128955		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.09188212622128955 | validation: 0.09891798437152324]
	TIME [epoch: 24.8 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10383064356443572		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.10383064356443572 | validation: 0.10788153178051012]
	TIME [epoch: 24.7 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10272393396974543		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.10272393396974543 | validation: 0.11356454634449083]
	TIME [epoch: 24.8 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09760809625823413		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.09760809625823413 | validation: 0.09867092691935443]
	TIME [epoch: 24.8 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09381313451467546		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.09381313451467546 | validation: 0.09368381257414836]
	TIME [epoch: 24.7 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09376739598796652		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.09376739598796652 | validation: 0.10492640068031678]
	TIME [epoch: 24.8 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10391453966190892		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.10391453966190892 | validation: 0.11807529295289157]
	TIME [epoch: 24.8 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10930412701961705		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.10930412701961705 | validation: 0.10956388006452128]
	TIME [epoch: 24.7 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11322345442642354		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.11322345442642354 | validation: 0.12888293569475168]
	TIME [epoch: 24.8 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1012736395296509		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.1012736395296509 | validation: 0.10240331405558212]
	TIME [epoch: 24.8 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.096147414287871		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.096147414287871 | validation: 0.10836848063503457]
	TIME [epoch: 24.8 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09458254370353676		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.09458254370353676 | validation: 0.10741727951817025]
	TIME [epoch: 24.8 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09125907565504164		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.09125907565504164 | validation: 0.11344803140144745]
	TIME [epoch: 24.8 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09665782404791867		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.09665782404791867 | validation: 0.10956622854776338]
	TIME [epoch: 24.8 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09018946461157909		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.09018946461157909 | validation: 0.0875796237992899]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_1188.pth
	Model improved!!!
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08875945652903743		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.08875945652903743 | validation: 0.0989475031210376]
	TIME [epoch: 24.8 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09919046286440696		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.09919046286440696 | validation: 0.13010947071891013]
	TIME [epoch: 24.8 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09923317405621773		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.09923317405621773 | validation: 0.09927063947381821]
	TIME [epoch: 24.7 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08506369006576811		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.08506369006576811 | validation: 0.10085904659545442]
	TIME [epoch: 24.8 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09361741269218757		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.09361741269218757 | validation: 0.1282984166888101]
	TIME [epoch: 24.7 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11278663810741028		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.11278663810741028 | validation: 0.1146060313938599]
	TIME [epoch: 24.8 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10911568699511273		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.10911568699511273 | validation: 0.11661231941384788]
	TIME [epoch: 24.8 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10246558123151485		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.10246558123151485 | validation: 0.11534712885200704]
	TIME [epoch: 24.7 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10081832499400963		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.10081832499400963 | validation: 0.09362085349219385]
	TIME [epoch: 24.7 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08726411722554461		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.08726411722554461 | validation: 0.09657561261722614]
	TIME [epoch: 24.8 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08888970460935956		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.08888970460935956 | validation: 0.09407512818279638]
	TIME [epoch: 24.7 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09304367015921064		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.09304367015921064 | validation: 0.10615435533617333]
	TIME [epoch: 24.8 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09101978098170754		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.09101978098170754 | validation: 0.10286674786972967]
	TIME [epoch: 24.8 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0908080707882333		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.0908080707882333 | validation: 0.08886434570973144]
	TIME [epoch: 24.8 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08203629880974737		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.08203629880974737 | validation: 0.10004874836462208]
	TIME [epoch: 24.8 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09008471931536131		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.09008471931536131 | validation: 0.112021344300247]
	TIME [epoch: 24.8 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0917555656035933		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.0917555656035933 | validation: 0.08758400179385177]
	TIME [epoch: 24.8 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09050936531987656		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.09050936531987656 | validation: 0.09174373221523183]
	TIME [epoch: 24.8 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09265739093533765		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.09265739093533765 | validation: 0.10141269096339751]
	TIME [epoch: 24.7 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0992553269861249		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.0992553269861249 | validation: 0.11376141288033026]
	TIME [epoch: 24.7 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10149805522022826		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.10149805522022826 | validation: 0.13385834378704278]
	TIME [epoch: 24.8 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12428236901296941		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.12428236901296941 | validation: 0.15265633051575464]
	TIME [epoch: 24.8 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12837157440873923		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.12837157440873923 | validation: 0.1361373846077873]
	TIME [epoch: 24.7 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10728085092383227		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.10728085092383227 | validation: 0.14475114421153776]
	TIME [epoch: 24.8 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10462826633965555		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.10462826633965555 | validation: 0.11694240760086622]
	TIME [epoch: 24.8 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09637025855385997		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.09637025855385997 | validation: 0.11617010890062997]
	TIME [epoch: 24.7 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09705759774374759		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.09705759774374759 | validation: 0.11333273950860875]
	TIME [epoch: 24.8 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09010304558544026		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.09010304558544026 | validation: 0.0997021412343309]
	TIME [epoch: 24.7 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09003844600771956		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.09003844600771956 | validation: 0.09778137490639392]
	TIME [epoch: 24.8 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09667784958491749		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.09667784958491749 | validation: 0.09834534022525036]
	TIME [epoch: 24.8 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09891917809004816		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.09891917809004816 | validation: 0.11255894983935771]
	TIME [epoch: 24.8 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10227731959075818		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.10227731959075818 | validation: 0.11496709700990376]
	TIME [epoch: 24.8 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09818742306590783		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.09818742306590783 | validation: 0.119151338636797]
	TIME [epoch: 24.8 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09637495464786379		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.09637495464786379 | validation: 0.10259195586707603]
	TIME [epoch: 24.8 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0972938076200184		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.0972938076200184 | validation: 0.1075790866988453]
	TIME [epoch: 24.8 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10479555698096842		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.10479555698096842 | validation: 0.13242418536287281]
	TIME [epoch: 24.8 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11254579350988472		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.11254579350988472 | validation: 0.12353988739166873]
	TIME [epoch: 24.8 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10354283841382501		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.10354283841382501 | validation: 0.11542641353416276]
	TIME [epoch: 24.8 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09569537415101248		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.09569537415101248 | validation: 0.1164130610831811]
	TIME [epoch: 24.8 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09991696016212785		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.09991696016212785 | validation: 0.12399399978019418]
	TIME [epoch: 24.7 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09012562300606938		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.09012562300606938 | validation: 0.09625011502961538]
	TIME [epoch: 24.7 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08892437157619607		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.08892437157619607 | validation: 0.11375618454968152]
	TIME [epoch: 24.8 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09526635659117218		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.09526635659117218 | validation: 0.1087260003284832]
	TIME [epoch: 24.7 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10065642374985145		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.10065642374985145 | validation: 0.13274682672528262]
	TIME [epoch: 24.8 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09882961921171758		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.09882961921171758 | validation: 0.09347739404862437]
	TIME [epoch: 24.8 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08821540636705703		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.08821540636705703 | validation: 0.0963713580165289]
	TIME [epoch: 24.8 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08749731713696887		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.08749731713696887 | validation: 0.09359328756567821]
	TIME [epoch: 24.7 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09028546835247332		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.09028546835247332 | validation: 0.1148296368628284]
	TIME [epoch: 24.8 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09481585512884515		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.09481585512884515 | validation: 0.11745082534797494]
	TIME [epoch: 24.7 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09791141930125127		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.09791141930125127 | validation: 0.10868171342924816]
	TIME [epoch: 24.7 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09899065874922698		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.09899065874922698 | validation: 0.13369211684213053]
	TIME [epoch: 24.8 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09748554292568745		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.09748554292568745 | validation: 0.11819510676909284]
	TIME [epoch: 24.8 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09268807420489594		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.09268807420489594 | validation: 0.1162785992383397]
	TIME [epoch: 24.8 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08765792850010844		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.08765792850010844 | validation: 0.10819528747554281]
	TIME [epoch: 24.8 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09384527869976719		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.09384527869976719 | validation: 0.09667575108910803]
	TIME [epoch: 24.8 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08916173852524513		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.08916173852524513 | validation: 0.10478119468380037]
	TIME [epoch: 24.8 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08987584141799755		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.08987584141799755 | validation: 0.1028913418099049]
	TIME [epoch: 24.8 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08644546191399691		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.08644546191399691 | validation: 0.1099862320361548]
	TIME [epoch: 24.8 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08901213544236183		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.08901213544236183 | validation: 0.09659218885401911]
	TIME [epoch: 24.8 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08962092323171186		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.08962092323171186 | validation: 0.10578733225387485]
	TIME [epoch: 24.8 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0960226435807795		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.0960226435807795 | validation: 0.12497176390751691]
	TIME [epoch: 24.8 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.096379635362568		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.096379635362568 | validation: 0.10123875817748848]
	TIME [epoch: 24.8 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08643154582612655		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.08643154582612655 | validation: 0.09981407904447345]
	TIME [epoch: 24.8 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09049458404692153		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.09049458404692153 | validation: 0.10795135213655101]
	TIME [epoch: 24.7 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09810435157878541		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.09810435157878541 | validation: 0.10514076197456078]
	TIME [epoch: 24.8 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09568107654087472		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.09568107654087472 | validation: 0.11769036451556283]
	TIME [epoch: 24.8 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10200885172474852		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.10200885172474852 | validation: 0.12013992949834122]
	TIME [epoch: 24.7 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10791907074175056		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.10791907074175056 | validation: 0.11566472281470269]
	TIME [epoch: 24.8 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09813110264339572		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.09813110264339572 | validation: 0.09987338867885484]
	TIME [epoch: 24.8 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08542274121932007		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.08542274121932007 | validation: 0.09808449413538764]
	TIME [epoch: 24.7 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0868600355987185		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.0868600355987185 | validation: 0.0955881067247238]
	TIME [epoch: 24.8 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08508403095750065		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.08508403095750065 | validation: 0.10087085948618228]
	TIME [epoch: 24.8 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0835163161806399		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.0835163161806399 | validation: 0.09613354522867237]
	TIME [epoch: 24.7 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08164664906045296		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.08164664906045296 | validation: 0.10430097483398995]
	TIME [epoch: 24.8 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08626048008997812		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.08626048008997812 | validation: 0.09967808959726661]
	TIME [epoch: 24.8 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08308005038413248		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.08308005038413248 | validation: 0.09146155274626315]
	TIME [epoch: 24.8 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07905842322183378		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.07905842322183378 | validation: 0.10162241470547477]
	TIME [epoch: 24.8 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09110024208473945		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.09110024208473945 | validation: 0.10130322897893529]
	TIME [epoch: 24.8 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08427453128778524		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.08427453128778524 | validation: 0.09497460465569603]
	TIME [epoch: 24.7 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09696318812651601		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.09696318812651601 | validation: 0.10942641461018272]
	TIME [epoch: 24.7 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08880701363616622		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.08880701363616622 | validation: 0.09787938281014888]
	TIME [epoch: 24.8 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0865307331899155		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.0865307331899155 | validation: 0.10728748142174346]
	TIME [epoch: 24.8 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08820773700423158		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.08820773700423158 | validation: 0.09665009057857668]
	TIME [epoch: 24.8 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08271497572676878		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.08271497572676878 | validation: 0.0912009969055553]
	TIME [epoch: 24.8 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08681135599460169		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.08681135599460169 | validation: 0.09836974408493748]
	TIME [epoch: 24.7 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08716231747870422		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.08716231747870422 | validation: 0.08917297417464512]
	TIME [epoch: 24.8 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08682862298078758		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.08682862298078758 | validation: 0.0975794074364574]
	TIME [epoch: 24.8 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0831680177173489		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.0831680177173489 | validation: 0.09602639153949906]
	TIME [epoch: 24.8 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08470285942410644		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.08470285942410644 | validation: 0.09157477236993039]
	TIME [epoch: 24.8 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07915898634883248		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.07915898634883248 | validation: 0.1060236031380406]
	TIME [epoch: 24.8 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08330014658498838		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.08330014658498838 | validation: 0.09329799642704895]
	TIME [epoch: 24.8 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08565645667018854		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.08565645667018854 | validation: 0.0980016295374088]
	TIME [epoch: 24.8 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08508822542075015		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.08508822542075015 | validation: 0.08621826674878674]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_1281.pth
	Model improved!!!
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0881245429748988		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.0881245429748988 | validation: 0.10356883840300035]
	TIME [epoch: 25 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08699068282403316		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.08699068282403316 | validation: 0.10471696150909644]
	TIME [epoch: 24.8 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08448068423999804		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.08448068423999804 | validation: 0.09761437293637247]
	TIME [epoch: 24.8 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08197606185221154		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.08197606185221154 | validation: 0.09599032992214639]
	TIME [epoch: 24.7 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08101794984607043		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.08101794984607043 | validation: 0.08733519395295701]
	TIME [epoch: 24.8 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08280131151324958		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.08280131151324958 | validation: 0.08243238783899327]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_1287.pth
	Model improved!!!
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08518980203817444		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.08518980203817444 | validation: 0.09925352956002682]
	TIME [epoch: 24.7 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08864861616896999		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.08864861616896999 | validation: 0.09440197236691096]
	TIME [epoch: 24.8 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09510417420726035		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.09510417420726035 | validation: 0.11940770863400768]
	TIME [epoch: 24.8 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10115409699825195		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.10115409699825195 | validation: 0.10654373237732802]
	TIME [epoch: 24.7 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09654898911196115		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.09654898911196115 | validation: 0.11160326206365763]
	TIME [epoch: 24.8 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10724449065049872		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.10724449065049872 | validation: 0.1267892251778727]
	TIME [epoch: 24.8 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10953033572926874		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.10953033572926874 | validation: 0.1080565543740256]
	TIME [epoch: 24.7 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09685453870573857		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.09685453870573857 | validation: 0.1083572609900387]
	TIME [epoch: 24.8 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09923244799892741		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.09923244799892741 | validation: 0.1140431884259392]
	TIME [epoch: 24.8 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10295789578213825		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.10295789578213825 | validation: 0.11598522402626328]
	TIME [epoch: 24.7 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11222099934505327		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.11222099934505327 | validation: 0.12442013339688654]
	TIME [epoch: 24.8 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10824396817558543		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.10824396817558543 | validation: 0.11550562706472631]
	TIME [epoch: 24.8 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10668008950033492		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.10668008950033492 | validation: 0.12990621440096703]
	TIME [epoch: 24.7 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10366840769020205		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.10366840769020205 | validation: 0.11822760781472504]
	TIME [epoch: 24.8 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09793527782341356		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.09793527782341356 | validation: 0.12072844774146664]
	TIME [epoch: 24.8 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09800653694355901		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.09800653694355901 | validation: 0.103667105064929]
	TIME [epoch: 24.7 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09629769497123723		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.09629769497123723 | validation: 0.10336184729884618]
	TIME [epoch: 24.8 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09424286125442491		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.09424286125442491 | validation: 0.09746163708597444]
	TIME [epoch: 24.8 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.094880943933582		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.094880943933582 | validation: 0.11458770017898896]
	TIME [epoch: 24.7 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09612608907701395		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.09612608907701395 | validation: 0.11339274815699697]
	TIME [epoch: 24.8 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09097022079068809		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.09097022079068809 | validation: 0.10228395817694118]
	TIME [epoch: 24.8 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08892881157852522		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.08892881157852522 | validation: 0.11373206996304099]
	TIME [epoch: 24.7 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08998372006688976		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.08998372006688976 | validation: 0.10478701973305231]
	TIME [epoch: 24.8 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0882449078397793		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.0882449078397793 | validation: 0.09475270589376261]
	TIME [epoch: 24.8 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08718584196665213		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.08718584196665213 | validation: 0.10144666359202009]
	TIME [epoch: 24.7 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08675149430450471		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.08675149430450471 | validation: 0.10400878867234462]
	TIME [epoch: 24.8 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08994916936432956		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.08994916936432956 | validation: 0.10113998649350389]
	TIME [epoch: 24.8 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09503227580041762		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.09503227580041762 | validation: 0.11047289087486128]
	TIME [epoch: 24.7 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0928288219551654		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.0928288219551654 | validation: 0.1108390149298258]
	TIME [epoch: 24.8 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09194303460076779		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.09194303460076779 | validation: 0.09773613286172689]
	TIME [epoch: 24.8 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09426009480587716		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.09426009480587716 | validation: 0.10467252529198916]
	TIME [epoch: 24.7 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09362330702206455		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.09362330702206455 | validation: 0.10728373094684107]
	TIME [epoch: 24.8 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0919128157955029		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.0919128157955029 | validation: 0.10013617705774204]
	TIME [epoch: 24.8 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08875722859485041		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.08875722859485041 | validation: 0.11049352428939624]
	TIME [epoch: 24.7 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09326052092750466		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.09326052092750466 | validation: 0.11009867518692135]
	TIME [epoch: 24.8 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08952160004863845		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.08952160004863845 | validation: 0.10555935728065041]
	TIME [epoch: 24.8 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09512400019316954		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.09512400019316954 | validation: 0.10970851695521411]
	TIME [epoch: 24.7 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09762105255297654		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.09762105255297654 | validation: 0.11778611711303758]
	TIME [epoch: 24.8 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10555880581658694		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.10555880581658694 | validation: 0.14099384669180964]
	TIME [epoch: 24.8 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11753403413780227		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.11753403413780227 | validation: 0.14073210855702326]
	TIME [epoch: 24.7 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10682234129779974		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.10682234129779974 | validation: 0.12016847328495535]
	TIME [epoch: 24.8 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09306875319527229		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.09306875319527229 | validation: 0.10169984072871273]
	TIME [epoch: 24.8 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08663863093373644		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.08663863093373644 | validation: 0.09689527005578352]
	TIME [epoch: 24.7 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08545868761152779		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.08545868761152779 | validation: 0.09855271905275434]
	TIME [epoch: 24.8 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08396927231816283		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.08396927231816283 | validation: 0.09539631946180649]
	TIME [epoch: 24.8 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08194358072895322		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.08194358072895322 | validation: 0.10262022882331753]
	TIME [epoch: 24.7 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08543626152557363		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.08543626152557363 | validation: 0.10013024784931968]
	TIME [epoch: 24.8 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08931099082377514		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.08931099082377514 | validation: 0.1020232389614608]
	TIME [epoch: 24.8 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0909521640157159		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.0909521640157159 | validation: 0.10719542241187063]
	TIME [epoch: 24.7 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0866993326874105		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.0866993326874105 | validation: 0.09351950104916039]
	TIME [epoch: 24.8 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08039787469443996		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.08039787469443996 | validation: 0.09576358537349186]
	TIME [epoch: 24.8 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08851257036081848		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.08851257036081848 | validation: 0.10098832982901074]
	TIME [epoch: 24.7 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08521192470764377		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.08521192470764377 | validation: 0.08896279196096366]
	TIME [epoch: 24.8 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08356177792224492		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.08356177792224492 | validation: 0.10430202600361461]
	TIME [epoch: 24.8 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08506698283188549		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.08506698283188549 | validation: 0.10325648422082885]
	TIME [epoch: 24.7 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08917937006584224		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.08917937006584224 | validation: 0.09885018947400079]
	TIME [epoch: 24.8 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09070966411860137		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.09070966411860137 | validation: 0.10924100785611901]
	TIME [epoch: 24.8 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08664564561246167		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.08664564561246167 | validation: 0.10193488539320499]
	TIME [epoch: 24.7 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08874576421782952		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.08874576421782952 | validation: 0.09832705088056364]
	TIME [epoch: 24.8 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08977143188640185		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.08977143188640185 | validation: 0.09821157088263185]
	TIME [epoch: 24.8 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08574456364192182		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.08574456364192182 | validation: 0.10578168008715565]
	TIME [epoch: 24.8 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09311709016759737		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.09311709016759737 | validation: 0.0987425277392926]
	TIME [epoch: 24.8 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09356516853135692		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.09356516853135692 | validation: 0.11631038690548408]
	TIME [epoch: 24.8 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09329239760425584		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.09329239760425584 | validation: 0.10272804732777127]
	TIME [epoch: 24.8 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0912075874905698		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.0912075874905698 | validation: 0.09025799031239949]
	TIME [epoch: 24.8 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08832529175558065		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.08832529175558065 | validation: 0.08719966076582879]
	TIME [epoch: 24.8 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08693968489215789		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.08693968489215789 | validation: 0.09910761911880343]
	TIME [epoch: 24.8 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08431110968136057		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.08431110968136057 | validation: 0.08898540781127728]
	TIME [epoch: 24.8 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08719111239119584		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.08719111239119584 | validation: 0.10133094048566545]
	TIME [epoch: 24.8 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08819154259342889		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.08819154259342889 | validation: 0.0981301615450867]
	TIME [epoch: 24.8 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08724593157736635		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.08724593157736635 | validation: 0.09598286409623377]
	TIME [epoch: 24.8 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08621097622885227		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.08621097622885227 | validation: 0.09641800552979925]
	TIME [epoch: 24.8 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08349022261002684		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.08349022261002684 | validation: 0.09986992071017885]
	TIME [epoch: 24.8 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08023000033685214		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.08023000033685214 | validation: 0.09461869853174065]
	TIME [epoch: 24.8 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08456733089528298		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.08456733089528298 | validation: 0.09810287277796935]
	TIME [epoch: 24.8 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08133763467955513		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.08133763467955513 | validation: 0.09760041735785537]
	TIME [epoch: 24.8 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08249444017435034		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.08249444017435034 | validation: 0.08537664407550065]
	TIME [epoch: 24.8 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08216370659695424		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.08216370659695424 | validation: 0.1038378476497547]
	TIME [epoch: 24.8 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08850633317635077		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.08850633317635077 | validation: 0.08810009141079393]
	TIME [epoch: 24.8 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08889031140876551		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.08889031140876551 | validation: 0.09733104018056618]
	TIME [epoch: 24.8 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09000206159379147		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.09000206159379147 | validation: 0.0949501542832704]
	TIME [epoch: 24.8 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08931376480287362		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.08931376480287362 | validation: 0.09607604830949829]
	TIME [epoch: 24.8 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09462467408068106		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.09462467408068106 | validation: 0.10726281102106984]
	TIME [epoch: 24.8 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08666807806924544		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.08666807806924544 | validation: 0.09211894313328285]
	TIME [epoch: 24.7 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08640173866134838		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.08640173866134838 | validation: 0.10937977882973159]
	TIME [epoch: 24.8 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08867818943738662		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.08867818943738662 | validation: 0.09304722525633703]
	TIME [epoch: 24.8 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08376970933045289		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.08376970933045289 | validation: 0.09324915491495865]
	TIME [epoch: 24.8 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08310351836899209		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.08310351836899209 | validation: 0.0903133169605624]
	TIME [epoch: 24.8 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08250517335588653		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.08250517335588653 | validation: 0.1014041378384107]
	TIME [epoch: 24.8 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08741644246325345		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.08741644246325345 | validation: 0.10233404815314172]
	TIME [epoch: 24.7 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08522033759002731		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.08522033759002731 | validation: 0.09854703902630377]
	TIME [epoch: 24.8 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08671939232396167		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.08671939232396167 | validation: 0.09953448051275927]
	TIME [epoch: 24.8 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08689532294915973		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.08689532294915973 | validation: 0.08832284755185485]
	TIME [epoch: 24.7 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08077157529090373		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.08077157529090373 | validation: 0.08580781257248254]
	TIME [epoch: 24.8 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08007589207976679		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.08007589207976679 | validation: 0.09591154275497928]
	TIME [epoch: 24.8 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08218754394724959		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.08218754394724959 | validation: 0.08399829476917284]
	TIME [epoch: 24.7 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08603762010073078		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.08603762010073078 | validation: 0.08534278592876927]
	TIME [epoch: 24.8 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08062047238058473		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.08062047238058473 | validation: 0.09014212740584561]
	TIME [epoch: 24.8 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08177224024592178		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.08177224024592178 | validation: 0.09762129878006284]
	TIME [epoch: 24.7 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08188525951991277		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.08188525951991277 | validation: 0.09788046269495052]
	TIME [epoch: 24.8 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07698729071408197		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.07698729071408197 | validation: 0.09293786729409231]
	TIME [epoch: 24.8 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0775754340237049		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.0775754340237049 | validation: 0.09214215856633146]
	TIME [epoch: 24.7 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08123773184852741		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.08123773184852741 | validation: 0.0856478449389161]
	TIME [epoch: 24.8 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08045896984020176		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.08045896984020176 | validation: 0.08430032319837193]
	TIME [epoch: 24.8 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07993155468892807		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.07993155468892807 | validation: 0.09144285985885167]
	TIME [epoch: 24.7 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08391187077210192		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.08391187077210192 | validation: 0.0866487848021839]
	TIME [epoch: 24.8 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08433195042705043		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.08433195042705043 | validation: 0.0969045069923159]
	TIME [epoch: 24.8 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08594427266346823		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.08594427266346823 | validation: 0.10710771225318809]
	TIME [epoch: 24.7 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09176925727020194		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.09176925727020194 | validation: 0.10554152628822859]
	TIME [epoch: 24.8 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0882012575898087		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.0882012575898087 | validation: 0.11030026595690562]
	TIME [epoch: 24.8 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08422348411609638		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.08422348411609638 | validation: 0.11493823795738281]
	TIME [epoch: 24.7 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08867478516781273		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.08867478516781273 | validation: 0.10142559462824949]
	TIME [epoch: 24.8 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08216875962039444		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.08216875962039444 | validation: 0.09465655615206937]
	TIME [epoch: 24.8 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07960392231826202		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.07960392231826202 | validation: 0.09459425089050544]
	TIME [epoch: 24.7 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08098959764547026		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.08098959764547026 | validation: 0.08881837174447306]
	TIME [epoch: 24.8 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0782275164775242		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.0782275164775242 | validation: 0.10253538673064175]
	TIME [epoch: 24.8 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08111392978438273		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.08111392978438273 | validation: 0.08677415413680596]
	TIME [epoch: 24.7 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07947792915511517		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.07947792915511517 | validation: 0.0970773941980172]
	TIME [epoch: 24.8 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08123877439650563		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.08123877439650563 | validation: 0.07884761448432262]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_1406.pth
	Model improved!!!
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0888783846219178		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.0888783846219178 | validation: 0.08712263280518631]
	TIME [epoch: 24.7 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08651957475421128		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.08651957475421128 | validation: 0.08639295451608035]
	TIME [epoch: 24.8 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08164334329074585		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.08164334329074585 | validation: 0.09353337942621423]
	TIME [epoch: 24.8 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08167474814240602		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.08167474814240602 | validation: 0.09783494453176964]
	TIME [epoch: 24.7 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08404503418965731		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.08404503418965731 | validation: 0.10174848630772712]
	TIME [epoch: 24.8 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09169980560428412		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.09169980560428412 | validation: 0.09471051269882551]
	TIME [epoch: 24.8 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08747770996272897		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.08747770996272897 | validation: 0.09889702376086607]
	TIME [epoch: 24.7 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09086937927621955		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.09086937927621955 | validation: 0.10969504081616255]
	TIME [epoch: 24.8 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09051354853629046		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.09051354853629046 | validation: 0.10670823873955099]
	TIME [epoch: 24.8 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0903738723471625		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.0903738723471625 | validation: 0.09265846601932569]
	TIME [epoch: 24.7 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08620507870529148		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.08620507870529148 | validation: 0.09950591421214366]
	TIME [epoch: 24.8 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08576502903364805		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.08576502903364805 | validation: 0.09545837745972989]
	TIME [epoch: 24.8 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07989464825742246		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.07989464825742246 | validation: 0.09833861141107615]
	TIME [epoch: 24.7 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08557339412140057		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.08557339412140057 | validation: 0.09289228260176455]
	TIME [epoch: 24.8 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08341524562641624		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.08341524562641624 | validation: 0.08670574336499147]
	TIME [epoch: 24.8 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07683530306498326		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.07683530306498326 | validation: 0.09119501701011239]
	TIME [epoch: 24.7 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07876790941758063		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.07876790941758063 | validation: 0.09239085300823587]
	TIME [epoch: 24.8 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08082766483605795		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.08082766483605795 | validation: 0.09606554392973865]
	TIME [epoch: 24.8 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07830166676899414		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.07830166676899414 | validation: 0.09827211714579677]
	TIME [epoch: 24.7 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07629338222884184		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.07629338222884184 | validation: 0.08804873163553203]
	TIME [epoch: 24.8 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08267620656572165		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.08267620656572165 | validation: 0.0898528189233259]
	TIME [epoch: 24.8 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07850520999194202		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.07850520999194202 | validation: 0.09973608631631171]
	TIME [epoch: 24.7 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07824087333135392		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.07824087333135392 | validation: 0.09350268531161766]
	TIME [epoch: 24.8 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08382588058202484		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.08382588058202484 | validation: 0.09209161970235583]
	TIME [epoch: 24.8 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08655902194782969		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.08655902194782969 | validation: 0.0965900565548845]
	TIME [epoch: 24.7 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08412948163887772		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.08412948163887772 | validation: 0.1033421715783642]
	TIME [epoch: 24.8 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07749046042752426		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.07749046042752426 | validation: 0.10297699524136734]
	TIME [epoch: 24.8 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08167472507118868		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.08167472507118868 | validation: 0.10441308395847482]
	TIME [epoch: 24.7 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08640173894610012		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.08640173894610012 | validation: 0.10856730690566858]
	TIME [epoch: 24.8 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09313403877629506		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.09313403877629506 | validation: 0.13147172498532556]
	TIME [epoch: 24.8 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09428522275674138		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.09428522275674138 | validation: 0.10970583468957433]
	TIME [epoch: 24.7 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09150760713406042		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.09150760713406042 | validation: 0.09890139671908582]
	TIME [epoch: 24.8 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09122805999004133		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.09122805999004133 | validation: 0.09649443355495718]
	TIME [epoch: 24.8 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08798077941238099		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.08798077941238099 | validation: 0.09897936035314889]
	TIME [epoch: 24.7 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08417331332125602		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.08417331332125602 | validation: 0.09753402053834384]
	TIME [epoch: 24.8 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0847942702068413		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.0847942702068413 | validation: 0.09673119151102615]
	TIME [epoch: 24.8 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08058989459710393		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.08058989459710393 | validation: 0.10066858856303515]
	TIME [epoch: 24.7 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0857598891581563		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.0857598891581563 | validation: 0.09239593624435735]
	TIME [epoch: 24.8 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08385211674468479		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.08385211674468479 | validation: 0.10556389999756399]
	TIME [epoch: 24.8 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0826255055712429		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.0826255055712429 | validation: 0.10492399203887626]
	TIME [epoch: 24.7 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08674038846166887		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.08674038846166887 | validation: 0.1008279022505402]
	TIME [epoch: 24.8 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0860862299391578		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.0860862299391578 | validation: 0.09765335919127335]
	TIME [epoch: 24.8 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08294752230280757		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.08294752230280757 | validation: 0.09806134396185531]
	TIME [epoch: 24.7 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08581406353460053		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.08581406353460053 | validation: 0.09603379519710759]
	TIME [epoch: 24.8 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08385903096881756		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.08385903096881756 | validation: 0.0971553328623427]
	TIME [epoch: 24.8 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08653835101348228		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.08653835101348228 | validation: 0.09377377773174914]
	TIME [epoch: 24.7 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08082952485807528		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.08082952485807528 | validation: 0.10512270482135921]
	TIME [epoch: 24.8 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08263783417148576		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.08263783417148576 | validation: 0.10656560455260905]
	TIME [epoch: 24.7 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0813163263101119		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.0813163263101119 | validation: 0.10789415696498797]
	TIME [epoch: 24.7 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08406051313285781		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.08406051313285781 | validation: 0.10864144585621296]
	TIME [epoch: 24.8 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08790085351425807		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.08790085351425807 | validation: 0.10772895120329938]
	TIME [epoch: 24.8 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08363061445607776		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.08363061445607776 | validation: 0.10111401530791245]
	TIME [epoch: 24.7 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08541385675604814		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.08541385675604814 | validation: 0.08756899257008804]
	TIME [epoch: 24.8 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08811964658757282		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.08811964658757282 | validation: 0.11134716949904462]
	TIME [epoch: 24.8 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08676948619318173		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.08676948619318173 | validation: 0.10338360544021413]
	TIME [epoch: 24.7 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08056965773820607		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.08056965773820607 | validation: 0.09283095355122715]
	TIME [epoch: 24.8 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08486576079211827		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.08486576079211827 | validation: 0.09509663488233563]
	TIME [epoch: 24.7 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08539909385325602		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.08539909385325602 | validation: 0.08858363534595821]
	TIME [epoch: 24.7 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08555628624107388		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.08555628624107388 | validation: 0.09645840253894751]
	TIME [epoch: 24.8 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08624542373868166		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.08624542373868166 | validation: 0.09855983926463814]
	TIME [epoch: 24.8 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0852597694601884		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.0852597694601884 | validation: 0.09907447056700526]
	TIME [epoch: 24.7 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07891200232385587		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.07891200232385587 | validation: 0.08486961222709566]
	TIME [epoch: 24.8 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08272675269631886		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.08272675269631886 | validation: 0.10542077962019328]
	TIME [epoch: 24.7 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08394735898030038		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.08394735898030038 | validation: 0.09912884050535052]
	TIME [epoch: 24.8 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08843989347438591		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.08843989347438591 | validation: 0.09388938560583363]
	TIME [epoch: 24.8 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08514445190803287		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.08514445190803287 | validation: 0.09530579291504143]
	TIME [epoch: 24.8 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08300206260724091		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.08300206260724091 | validation: 0.09950221640518064]
	TIME [epoch: 24.7 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08729865025181027		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.08729865025181027 | validation: 0.10096758200067239]
	TIME [epoch: 24.8 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08660624126820765		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.08660624126820765 | validation: 0.10641192288880401]
	TIME [epoch: 24.8 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08585802644920454		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.08585802644920454 | validation: 0.10399136920260924]
	TIME [epoch: 24.8 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08742267749841331		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.08742267749841331 | validation: 0.10550082780533922]
	TIME [epoch: 24.8 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09143428143378501		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.09143428143378501 | validation: 0.11425758615439463]
	TIME [epoch: 24.7 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09203452086106627		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.09203452086106627 | validation: 0.10453713457305354]
	TIME [epoch: 24.7 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08828744861084775		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.08828744861084775 | validation: 0.08550054208408918]
	TIME [epoch: 24.8 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08401023041847719		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.08401023041847719 | validation: 0.08802176078683355]
	TIME [epoch: 24.7 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08550256586490762		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.08550256586490762 | validation: 0.10123596206254051]
	TIME [epoch: 24.8 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07918595831590079		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.07918595831590079 | validation: 0.08459528866692204]
	TIME [epoch: 24.8 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07988441349295083		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.07988441349295083 | validation: 0.08409272428670928]
	TIME [epoch: 24.7 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08005433382516525		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.08005433382516525 | validation: 0.09992358303583984]
	TIME [epoch: 24.8 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08297247522336203		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.08297247522336203 | validation: 0.10030454306398304]
	TIME [epoch: 24.8 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0837456357808325		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.0837456357808325 | validation: 0.08788971932894661]
	TIME [epoch: 24.7 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07916367515515609		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.07916367515515609 | validation: 0.08761519657447679]
	TIME [epoch: 24.8 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07876147431703272		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.07876147431703272 | validation: 0.09444904676597879]
	TIME [epoch: 24.8 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08115639598876244		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.08115639598876244 | validation: 0.09254946720051332]
	TIME [epoch: 24.8 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08472742475038364		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.08472742475038364 | validation: 0.09269112995987427]
	TIME [epoch: 24.8 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08068467833822977		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.08068467833822977 | validation: 0.09617010634654079]
	TIME [epoch: 24.8 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07921779079428311		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.07921779079428311 | validation: 0.10384063682095553]
	TIME [epoch: 24.8 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08154945879516111		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.08154945879516111 | validation: 0.08890894873962474]
	TIME [epoch: 24.8 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08201191904182471		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.08201191904182471 | validation: 0.08549864928476815]
	TIME [epoch: 24.8 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07822153634108184		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.07822153634108184 | validation: 0.08431380261841519]
	TIME [epoch: 24.8 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08061320585765082		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.08061320585765082 | validation: 0.08581729185124877]
	TIME [epoch: 24.8 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08388435431560297		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.08388435431560297 | validation: 0.091857497521168]
	TIME [epoch: 24.8 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08119853944444895		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.08119853944444895 | validation: 0.09816967021131873]
	TIME [epoch: 24.8 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08345907443302678		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.08345907443302678 | validation: 0.10090977781341394]
	TIME [epoch: 24.8 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08360927326659794		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.08360927326659794 | validation: 0.09223885178853682]
	TIME [epoch: 24.8 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0832795177697552		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.0832795177697552 | validation: 0.08926414094280141]
	TIME [epoch: 24.8 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07635587878064634		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.07635587878064634 | validation: 0.10480052802965173]
	TIME [epoch: 24.8 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08273544712681247		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.08273544712681247 | validation: 0.08814603042301826]
	TIME [epoch: 24.8 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08133394960257337		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.08133394960257337 | validation: 0.0977860620758545]
	TIME [epoch: 24.8 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08075144465985976		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.08075144465985976 | validation: 0.08608600401743705]
	TIME [epoch: 24.8 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08203466703593316		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.08203466703593316 | validation: 0.08482178644966325]
	TIME [epoch: 24.9 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07773469478451978		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.07773469478451978 | validation: 0.08470359962559712]
	TIME [epoch: 24.8 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08110346603916824		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.08110346603916824 | validation: 0.09820879955307488]
	TIME [epoch: 24.8 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08060397945375887		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.08060397945375887 | validation: 0.0878187412086069]
	TIME [epoch: 24.8 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07848398029818898		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.07848398029818898 | validation: 0.09102844679849896]
	TIME [epoch: 24.8 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07905681899512265		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.07905681899512265 | validation: 0.09437327339149977]
	TIME [epoch: 24.8 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08669857072756537		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.08669857072756537 | validation: 0.09931785116068484]
	TIME [epoch: 24.8 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07751663602305364		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.07751663602305364 | validation: 0.0895893275361275]
	TIME [epoch: 24.8 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07993650616896084		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.07993650616896084 | validation: 0.08641596767808536]
	TIME [epoch: 24.8 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08289924465451498		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.08289924465451498 | validation: 0.08658745001169031]
	TIME [epoch: 24.8 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08059953410586863		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.08059953410586863 | validation: 0.09218370100713888]
	TIME [epoch: 24.8 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07878596056975509		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.07878596056975509 | validation: 0.09525580206909809]
	TIME [epoch: 24.8 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08195674227676941		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.08195674227676941 | validation: 0.08854970991002332]
	TIME [epoch: 24.8 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08009843258457634		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.08009843258457634 | validation: 0.08437786824420616]
	TIME [epoch: 24.7 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07767818353289158		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.07767818353289158 | validation: 0.09826215231608337]
	TIME [epoch: 24.7 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07353314270950058		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.07353314270950058 | validation: 0.0902326043618029]
	TIME [epoch: 24.8 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07690772494354917		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.07690772494354917 | validation: 0.08014318373660732]
	TIME [epoch: 24.8 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07790500586973795		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.07790500586973795 | validation: 0.09506157359997924]
	TIME [epoch: 24.8 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07746589257567552		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.07746589257567552 | validation: 0.08759796536618096]
	TIME [epoch: 24.9 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08202637423915682		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.08202637423915682 | validation: 0.09282348606839114]
	TIME [epoch: 24.7 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08231377435244652		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.08231377435244652 | validation: 0.09021067978776685]
	TIME [epoch: 24.8 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08008008246932873		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.08008008246932873 | validation: 0.08079571758946806]
	TIME [epoch: 24.8 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08303598588744712		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.08303598588744712 | validation: 0.09486172912920914]
	TIME [epoch: 24.8 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08142938129389576		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.08142938129389576 | validation: 0.09143706910938307]
	TIME [epoch: 24.8 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07689696059312391		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.07689696059312391 | validation: 0.08999260833967103]
	TIME [epoch: 24.8 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0773825929949424		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.0773825929949424 | validation: 0.0992917846356311]
	TIME [epoch: 24.8 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07640383253944572		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.07640383253944572 | validation: 0.09021821619427497]
	TIME [epoch: 24.8 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08245404637650323		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.08245404637650323 | validation: 0.0857387950098493]
	TIME [epoch: 24.8 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08483276447416208		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.08483276447416208 | validation: 0.09853214506018976]
	TIME [epoch: 24.8 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08353459751851448		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.08353459751851448 | validation: 0.09147524773118614]
	TIME [epoch: 24.8 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08357462807476393		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.08357462807476393 | validation: 0.0923004982870767]
	TIME [epoch: 24.8 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08408275082217705		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.08408275082217705 | validation: 0.09263497285267354]
	TIME [epoch: 24.8 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07957377801457456		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.07957377801457456 | validation: 0.08829044565081835]
	TIME [epoch: 24.8 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08615774715171728		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.08615774715171728 | validation: 0.09814625173535603]
	TIME [epoch: 24.8 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08901874853974126		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.08901874853974126 | validation: 0.09520130599219925]
	TIME [epoch: 24.8 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09093009803593946		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.09093009803593946 | validation: 0.10036933174369239]
	TIME [epoch: 24.8 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08857310551791286		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.08857310551791286 | validation: 0.09858573665157788]
	TIME [epoch: 24.8 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08800371595533982		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.08800371595533982 | validation: 0.11035593288943275]
	TIME [epoch: 24.8 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08760228660701026		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.08760228660701026 | validation: 0.09480321738164867]
	TIME [epoch: 24.8 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08537154794255403		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.08537154794255403 | validation: 0.09635681033514101]
	TIME [epoch: 24.8 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08054281049543066		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.08054281049543066 | validation: 0.09587583564493805]
	TIME [epoch: 24.8 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09058914462576952		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.09058914462576952 | validation: 0.11961300825041882]
	TIME [epoch: 24.8 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08578838653456226		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.08578838653456226 | validation: 0.10127187941401503]
	TIME [epoch: 24.8 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08828544037991999		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.08828544037991999 | validation: 0.11094118488500172]
	TIME [epoch: 24.8 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09018650237995407		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.09018650237995407 | validation: 0.10473565629070318]
	TIME [epoch: 24.8 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0858298441650314		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.0858298441650314 | validation: 0.10087334814915291]
	TIME [epoch: 24.8 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08848481059341351		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.08848481059341351 | validation: 0.11472876731190859]
	TIME [epoch: 24.8 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08539313093211036		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.08539313093211036 | validation: 0.09346653295270564]
	TIME [epoch: 24.8 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08725846726540812		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.08725846726540812 | validation: 0.10720203741399224]
	TIME [epoch: 24.8 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0856480772565642		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.0856480772565642 | validation: 0.09873342757229547]
	TIME [epoch: 24.8 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08282437897771647		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.08282437897771647 | validation: 0.10197184122356351]
	TIME [epoch: 24.8 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08262588733093242		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.08262588733093242 | validation: 0.10010057629785502]
	TIME [epoch: 24.8 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08443979408358762		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.08443979408358762 | validation: 0.09629268807970004]
	TIME [epoch: 24.8 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.087871449090345		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.087871449090345 | validation: 0.09074153643680492]
	TIME [epoch: 24.8 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08475559851690197		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.08475559851690197 | validation: 0.08933613137076389]
	TIME [epoch: 24.8 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08461841110594306		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.08461841110594306 | validation: 0.10286388852137313]
	TIME [epoch: 24.8 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08446958590006912		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.08446958590006912 | validation: 0.08936898522851597]
	TIME [epoch: 24.8 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08256088072459165		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.08256088072459165 | validation: 0.09243229816540531]
	TIME [epoch: 24.8 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08035546676565625		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.08035546676565625 | validation: 0.09300046096326427]
	TIME [epoch: 24.8 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08202558811473107		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.08202558811473107 | validation: 0.09002084811155088]
	TIME [epoch: 24.8 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08017720790864542		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.08017720790864542 | validation: 0.09510723355655966]
	TIME [epoch: 24.8 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08232422608393902		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.08232422608393902 | validation: 0.092538094285814]
	TIME [epoch: 24.8 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08141725834039595		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.08141725834039595 | validation: 0.09451173136333102]
	TIME [epoch: 24.8 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08273299106033492		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.08273299106033492 | validation: 0.09449982790202878]
	TIME [epoch: 24.8 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08137590185853061		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.08137590185853061 | validation: 0.0951593651698612]
	TIME [epoch: 24.8 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08230837935100235		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.08230837935100235 | validation: 0.0944297356073524]
	TIME [epoch: 24.8 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07864721844490942		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.07864721844490942 | validation: 0.0962176596293586]
	TIME [epoch: 24.8 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08035308367370504		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.08035308367370504 | validation: 0.09232905343380038]
	TIME [epoch: 24.8 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08120075025743721		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.08120075025743721 | validation: 0.08912255165066736]
	TIME [epoch: 24.8 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08069892005595825		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.08069892005595825 | validation: 0.08667166264173763]
	TIME [epoch: 24.8 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07935479929235423		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.07935479929235423 | validation: 0.08948155504185511]
	TIME [epoch: 24.7 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08057799300188116		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.08057799300188116 | validation: 0.09207042561290411]
	TIME [epoch: 24.8 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08064278213887331		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.08064278213887331 | validation: 0.08915910238030664]
	TIME [epoch: 24.8 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07971899385811554		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.07971899385811554 | validation: 0.08691355646142947]
	TIME [epoch: 24.7 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08103060098553813		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.08103060098553813 | validation: 0.0879585962607178]
	TIME [epoch: 24.8 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08221851468455899		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.08221851468455899 | validation: 0.09660887742944606]
	TIME [epoch: 24.8 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07968390255628514		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.07968390255628514 | validation: 0.0953705178881081]
	TIME [epoch: 24.8 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08235888947271049		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.08235888947271049 | validation: 0.09288364070836216]
	TIME [epoch: 24.8 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07970235595183581		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.07970235595183581 | validation: 0.08973939769331063]
	TIME [epoch: 24.8 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07919404043427919		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.07919404043427919 | validation: 0.08791203841899886]
	TIME [epoch: 24.8 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08001874408732132		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.08001874408732132 | validation: 0.08723017146732012]
	TIME [epoch: 24.8 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08101031843258902		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.08101031843258902 | validation: 0.08982718186591108]
	TIME [epoch: 24.8 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07831968221304093		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.07831968221304093 | validation: 0.10079093638760038]
	TIME [epoch: 24.8 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07723276837775869		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.07723276837775869 | validation: 0.08441789954983946]
	TIME [epoch: 24.8 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07778769622976126		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.07778769622976126 | validation: 0.09127399056062327]
	TIME [epoch: 24.8 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07874614551679207		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.07874614551679207 | validation: 0.09959457573343743]
	TIME [epoch: 24.8 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07732876156816647		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.07732876156816647 | validation: 0.09398168519632347]
	TIME [epoch: 24.8 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08084724393950929		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.08084724393950929 | validation: 0.0925230973356207]
	TIME [epoch: 24.8 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07718987688957818		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.07718987688957818 | validation: 0.09818750918934012]
	TIME [epoch: 24.7 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07671311476475046		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.07671311476475046 | validation: 0.09233171119516666]
	TIME [epoch: 24.8 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07713034976403246		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.07713034976403246 | validation: 0.08817785364073971]
	TIME [epoch: 24.8 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07888811469445431		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.07888811469445431 | validation: 0.08891252862074303]
	TIME [epoch: 24.7 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0795427632867476		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.0795427632867476 | validation: 0.080414998072029]
	TIME [epoch: 24.8 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07965838122809402		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.07965838122809402 | validation: 0.08553577662144775]
	TIME [epoch: 24.8 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07967446619257454		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.07967446619257454 | validation: 0.0834611687328939]
	TIME [epoch: 24.7 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08117495611530809		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.08117495611530809 | validation: 0.08713360616345081]
	TIME [epoch: 24.8 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07657022542384592		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.07657022542384592 | validation: 0.08142748620659646]
	TIME [epoch: 24.8 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0753483716095178		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.0753483716095178 | validation: 0.09020194876873461]
	TIME [epoch: 24.7 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08303922231470316		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.08303922231470316 | validation: 0.08930962260677962]
	TIME [epoch: 24.8 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0782075434800287		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.0782075434800287 | validation: 0.1006681196339545]
	TIME [epoch: 24.7 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07943282767706435		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.07943282767706435 | validation: 0.09813063781085166]
	TIME [epoch: 24.8 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08111028484969791		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.08111028484969791 | validation: 0.09481272177969491]
	TIME [epoch: 24.8 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08354246747203417		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.08354246747203417 | validation: 0.09506797815934613]
	TIME [epoch: 24.7 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07753895292344132		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.07753895292344132 | validation: 0.0948562532544559]
	TIME [epoch: 24.7 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07662158575875964		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.07662158575875964 | validation: 0.08907096780861144]
	TIME [epoch: 24.8 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07744638680632181		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.07744638680632181 | validation: 0.08391799468326219]
	TIME [epoch: 24.7 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08073857410897944		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.08073857410897944 | validation: 0.09111126624146489]
	TIME [epoch: 24.7 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07825815080886464		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.07825815080886464 | validation: 0.09212184293208074]
	TIME [epoch: 24.8 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07700378093330794		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.07700378093330794 | validation: 0.09215903430310302]
	TIME [epoch: 24.8 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07677292170902676		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.07677292170902676 | validation: 0.10230388798507627]
	TIME [epoch: 24.7 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08097826821601749		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.08097826821601749 | validation: 0.09051531630144995]
	TIME [epoch: 24.8 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08130808090628895		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.08130808090628895 | validation: 0.08766708150562284]
	TIME [epoch: 24.7 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0811946184872041		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.0811946184872041 | validation: 0.08256386817494328]
	TIME [epoch: 24.8 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07953703456309894		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.07953703456309894 | validation: 0.08963020968625088]
	TIME [epoch: 24.8 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08056374865706073		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.08056374865706073 | validation: 0.09205733867916475]
	TIME [epoch: 24.7 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07873966350897182		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.07873966350897182 | validation: 0.09232262895929445]
	TIME [epoch: 24.7 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07926419442604245		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.07926419442604245 | validation: 0.0878043645773787]
	TIME [epoch: 24.8 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07684033405621522		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.07684033405621522 | validation: 0.08819044949033249]
	TIME [epoch: 24.7 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08299347523201905		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.08299347523201905 | validation: 0.08227445625823909]
	TIME [epoch: 24.7 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08276469555965234		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.08276469555965234 | validation: 0.08808069883933328]
	TIME [epoch: 24.8 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08273779736002061		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.08273779736002061 | validation: 0.09254926505578524]
	TIME [epoch: 24.7 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07919895557534175		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.07919895557534175 | validation: 0.08583971956678058]
	TIME [epoch: 24.8 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07968640479149514		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.07968640479149514 | validation: 0.0888306766080866]
	TIME [epoch: 24.8 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.078340223634157		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.078340223634157 | validation: 0.08806968921502151]
	TIME [epoch: 24.8 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08137626155206377		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.08137626155206377 | validation: 0.08153561807426599]
	TIME [epoch: 24.7 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07641908491760306		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.07641908491760306 | validation: 0.07807593598177792]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_1632.pth
	Model improved!!!
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0819189006493383		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.0819189006493383 | validation: 0.08118615360567594]
	TIME [epoch: 24.8 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08203916992541048		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.08203916992541048 | validation: 0.09694675739695784]
	TIME [epoch: 24.7 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07868786088740082		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.07868786088740082 | validation: 0.08262925441137708]
	TIME [epoch: 24.8 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08163604204236187		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.08163604204236187 | validation: 0.09367201183566325]
	TIME [epoch: 24.8 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07689891558147624		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.07689891558147624 | validation: 0.09103862939234202]
	TIME [epoch: 24.7 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08392496671851796		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.08392496671851796 | validation: 0.09173907125999392]
	TIME [epoch: 24.8 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08016293893410986		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.08016293893410986 | validation: 0.08938249444650755]
	TIME [epoch: 24.7 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07527321059431163		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.07527321059431163 | validation: 0.0892321382848133]
	TIME [epoch: 24.8 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0748828744180349		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.0748828744180349 | validation: 0.08371210385434778]
	TIME [epoch: 24.9 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07716345220834939		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.07716345220834939 | validation: 0.08907339856640022]
	TIME [epoch: 24.8 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07522016591838747		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.07522016591838747 | validation: 0.09540448436216156]
	TIME [epoch: 24.8 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07877034572550427		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.07877034572550427 | validation: 0.09245081146501122]
	TIME [epoch: 24.8 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07948458536998783		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.07948458536998783 | validation: 0.08617911221678837]
	TIME [epoch: 24.8 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07862556656142686		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.07862556656142686 | validation: 0.08810564460176577]
	TIME [epoch: 24.8 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07786038253079051		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.07786038253079051 | validation: 0.08600000837996503]
	TIME [epoch: 24.8 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07815130069554324		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.07815130069554324 | validation: 0.09591349716520675]
	TIME [epoch: 24.7 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07875143507798671		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.07875143507798671 | validation: 0.09109492932244562]
	TIME [epoch: 24.8 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07845532159778154		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.07845532159778154 | validation: 0.08976258776097948]
	TIME [epoch: 24.8 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07810006674304872		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.07810006674304872 | validation: 0.09611074300408316]
	TIME [epoch: 24.8 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.076732084914795		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.076732084914795 | validation: 0.09516435309494652]
	TIME [epoch: 24.8 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07724070343961585		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.07724070343961585 | validation: 0.08635476336090633]
	TIME [epoch: 24.8 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07796030581036427		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.07796030581036427 | validation: 0.08267817486339096]
	TIME [epoch: 24.8 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07921315192359836		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.07921315192359836 | validation: 0.09462773175703112]
	TIME [epoch: 24.8 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08062658537338716		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.08062658537338716 | validation: 0.09034967782043869]
	TIME [epoch: 24.8 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07955441675480229		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.07955441675480229 | validation: 0.08893527280647578]
	TIME [epoch: 24.8 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0785098240871108		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.0785098240871108 | validation: 0.09035187435365558]
	TIME [epoch: 24.8 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08081344089876041		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.08081344089876041 | validation: 0.09688199522562166]
	TIME [epoch: 24.8 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08044794529184648		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.08044794529184648 | validation: 0.09254407494890124]
	TIME [epoch: 24.8 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08048225752883945		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.08048225752883945 | validation: 0.09451999640026733]
	TIME [epoch: 24.8 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08065222145284759		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.08065222145284759 | validation: 0.09137933222551421]
	TIME [epoch: 24.9 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07978697578482909		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.07978697578482909 | validation: 0.07568534665599208]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_1663.pth
	Model improved!!!
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07891230375309871		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.07891230375309871 | validation: 0.08201591099225838]
	TIME [epoch: 24.8 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07958976146411771		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.07958976146411771 | validation: 0.08231784816192705]
	TIME [epoch: 24.8 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0775231505428971		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.0775231505428971 | validation: 0.07992545162678281]
	TIME [epoch: 24.8 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07419978920415407		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.07419978920415407 | validation: 0.08588691118946393]
	TIME [epoch: 24.7 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07563986666600177		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.07563986666600177 | validation: 0.08953536255744769]
	TIME [epoch: 24.8 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08062615313259613		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.08062615313259613 | validation: 0.08493683516415232]
	TIME [epoch: 24.7 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07664425048853947		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.07664425048853947 | validation: 0.097702522500873]
	TIME [epoch: 24.8 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07967325781014614		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.07967325781014614 | validation: 0.08523626609626041]
	TIME [epoch: 24.8 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07919823548868693		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.07919823548868693 | validation: 0.0823709014922675]
	TIME [epoch: 24.8 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0792451698468559		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.0792451698468559 | validation: 0.09231468186635548]
	TIME [epoch: 24.8 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.074806498250696		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.074806498250696 | validation: 0.08737444682199669]
	TIME [epoch: 24.8 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08055539284997518		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.08055539284997518 | validation: 0.08537513033140692]
	TIME [epoch: 24.8 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07801270828956314		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.07801270828956314 | validation: 0.09110768400987074]
	TIME [epoch: 24.8 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08294216537313552		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.08294216537313552 | validation: 0.07574292275179155]
	TIME [epoch: 24.8 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07778508745874448		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.07778508745874448 | validation: 0.08703978383363686]
	TIME [epoch: 24.7 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07920709836805086		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.07920709836805086 | validation: 0.08738006122673017]
	TIME [epoch: 24.8 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07806920833731325		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.07806920833731325 | validation: 0.08610675364016945]
	TIME [epoch: 24.8 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07851082619888336		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.07851082619888336 | validation: 0.0933961265038531]
	TIME [epoch: 24.8 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08142346532684865		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.08142346532684865 | validation: 0.08994437974252328]
	TIME [epoch: 24.8 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08020561838030742		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.08020561838030742 | validation: 0.08256859213646067]
	TIME [epoch: 24.8 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07823821083854347		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.07823821083854347 | validation: 0.08785283413499738]
	TIME [epoch: 24.8 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07692009571306903		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.07692009571306903 | validation: 0.09004990616290556]
	TIME [epoch: 24.8 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07764229983932745		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.07764229983932745 | validation: 0.080303138404914]
	TIME [epoch: 24.8 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07665733809588515		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.07665733809588515 | validation: 0.08355808810781543]
	TIME [epoch: 24.8 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07740364061708915		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.07740364061708915 | validation: 0.08859772339714227]
	TIME [epoch: 24.8 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07367779812954928		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.07367779812954928 | validation: 0.09461769810759764]
	TIME [epoch: 24.8 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0778749873477208		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.0778749873477208 | validation: 0.08966642405967498]
	TIME [epoch: 24.7 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08243484847181441		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.08243484847181441 | validation: 0.08403153332906257]
	TIME [epoch: 24.8 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08368754841722148		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.08368754841722148 | validation: 0.09083330439362353]
	TIME [epoch: 24.8 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08119517814558674		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.08119517814558674 | validation: 0.08748828293963108]
	TIME [epoch: 24.7 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07931025813004527		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.07931025813004527 | validation: 0.09123838293828417]
	TIME [epoch: 24.8 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07675296050753683		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.07675296050753683 | validation: 0.09872906697801064]
	TIME [epoch: 24.8 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07830654717335807		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.07830654717335807 | validation: 0.08832152963298633]
	TIME [epoch: 24.7 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08344301084945009		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.08344301084945009 | validation: 0.0890009284300307]
	TIME [epoch: 24.8 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07861211987576955		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.07861211987576955 | validation: 0.08540090676809513]
	TIME [epoch: 24.8 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0784418799849482		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.0784418799849482 | validation: 0.08670601268428914]
	TIME [epoch: 24.8 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07389313754561833		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.07389313754561833 | validation: 0.08379453992478593]
	TIME [epoch: 24.8 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07869961756627536		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.07869961756627536 | validation: 0.09169557132858025]
	TIME [epoch: 24.8 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08060458840629484		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.08060458840629484 | validation: 0.0888045296821214]
	TIME [epoch: 24.8 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08034371181767735		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.08034371181767735 | validation: 0.08691608040361316]
	TIME [epoch: 24.8 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07786108605328347		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.07786108605328347 | validation: 0.09020541981530458]
	TIME [epoch: 24.8 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08182763986306416		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.08182763986306416 | validation: 0.08370005048874694]
	TIME [epoch: 24.8 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07975549596219418		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.07975549596219418 | validation: 0.07910517576336769]
	TIME [epoch: 24.8 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07643970059282883		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.07643970059282883 | validation: 0.0902659722169927]
	TIME [epoch: 24.8 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07711675610536176		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.07711675610536176 | validation: 0.08953138225070763]
	TIME [epoch: 24.8 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07589627667240657		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.07589627667240657 | validation: 0.08545508622563772]
	TIME [epoch: 24.8 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07633084183669087		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.07633084183669087 | validation: 0.08265127834438596]
	TIME [epoch: 24.8 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07795629350590165		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.07795629350590165 | validation: 0.09094428925818267]
	TIME [epoch: 24.8 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08061773874291714		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.08061773874291714 | validation: 0.08578279269977448]
	TIME [epoch: 24.8 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07711298682832966		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.07711298682832966 | validation: 0.09227961594181121]
	TIME [epoch: 24.8 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07909016994928879		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.07909016994928879 | validation: 0.08000320495823977]
	TIME [epoch: 24.8 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08126142042819316		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.08126142042819316 | validation: 0.0913112838154997]
	TIME [epoch: 24.8 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07668377557583203		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.07668377557583203 | validation: 0.08414208850787043]
	TIME [epoch: 24.8 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07806497392711981		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.07806497392711981 | validation: 0.07881334695266917]
	TIME [epoch: 24.8 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07331195943564142		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.07331195943564142 | validation: 0.08443085496896055]
	TIME [epoch: 24.8 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07483285238268253		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.07483285238268253 | validation: 0.08421607427678712]
	TIME [epoch: 24.8 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07961256439630669		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.07961256439630669 | validation: 0.0826273731296354]
	TIME [epoch: 24.8 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07845237320853457		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.07845237320853457 | validation: 0.07978388892442684]
	TIME [epoch: 24.8 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07241714061638749		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.07241714061638749 | validation: 0.07805231183840487]
	TIME [epoch: 24.8 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07866006538930348		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.07866006538930348 | validation: 0.08355094854415533]
	TIME [epoch: 24.8 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07805468203381902		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.07805468203381902 | validation: 0.0845926834309517]
	TIME [epoch: 24.8 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0762217505761405		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.0762217505761405 | validation: 0.08358182276983922]
	TIME [epoch: 24.8 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07810466398109497		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.07810466398109497 | validation: 0.0842505800966314]
	TIME [epoch: 24.7 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08045284616796529		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.08045284616796529 | validation: 0.0873230665406662]
	TIME [epoch: 24.8 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07475762212769381		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.07475762212769381 | validation: 0.08504942022436823]
	TIME [epoch: 24.8 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07515756009957492		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.07515756009957492 | validation: 0.0895418543854752]
	TIME [epoch: 24.8 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0831094786100667		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.0831094786100667 | validation: 0.09206308148166549]
	TIME [epoch: 24.8 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08019427984850291		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.08019427984850291 | validation: 0.09597678677678285]
	TIME [epoch: 24.8 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0771811825077475		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.0771811825077475 | validation: 0.0926166150989743]
	TIME [epoch: 24.7 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07957150519027154		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.07957150519027154 | validation: 0.09078157658010395]
	TIME [epoch: 24.8 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07594438201771582		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.07594438201771582 | validation: 0.09252670814998468]
	TIME [epoch: 24.7 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07769800941320484		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.07769800941320484 | validation: 0.08852310397907835]
	TIME [epoch: 24.7 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07794266586677687		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.07794266586677687 | validation: 0.07783531859237011]
	TIME [epoch: 24.7 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07496336918009759		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.07496336918009759 | validation: 0.08327828681987988]
	TIME [epoch: 24.8 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07848378771737156		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.07848378771737156 | validation: 0.09260235656682425]
	TIME [epoch: 24.8 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07684556007973214		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.07684556007973214 | validation: 0.09761616640773578]
	TIME [epoch: 24.8 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07554841779735709		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.07554841779735709 | validation: 0.08448637897686752]
	TIME [epoch: 24.7 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0757839656228522		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.0757839656228522 | validation: 0.0816806548551502]
	TIME [epoch: 24.7 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0729164804386929		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.0729164804386929 | validation: 0.0864091834494107]
	TIME [epoch: 24.8 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07545768211119955		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.07545768211119955 | validation: 0.08382876401300518]
	TIME [epoch: 24.8 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07677146263182899		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.07677146263182899 | validation: 0.08808970000806753]
	TIME [epoch: 24.7 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07990900053501687		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.07990900053501687 | validation: 0.09056210287994207]
	TIME [epoch: 24.8 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07691049670568607		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.07691049670568607 | validation: 0.08506489714366314]
	TIME [epoch: 24.8 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07703928569255183		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.07703928569255183 | validation: 0.08518240100603416]
	TIME [epoch: 24.8 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07906407641550468		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.07906407641550468 | validation: 0.08350013915910473]
	TIME [epoch: 24.8 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08020494047135333		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.08020494047135333 | validation: 0.08202979449691776]
	TIME [epoch: 24.8 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07657933906865104		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.07657933906865104 | validation: 0.09649536059909389]
	TIME [epoch: 24.8 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07818744957993377		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.07818744957993377 | validation: 0.08063523389460758]
	TIME [epoch: 24.8 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07744231463432244		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.07744231463432244 | validation: 0.09123586533639057]
	TIME [epoch: 24.8 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07910776121973095		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.07910776121973095 | validation: 0.08932458082234135]
	TIME [epoch: 24.8 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07672875397894814		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.07672875397894814 | validation: 0.08856941788905431]
	TIME [epoch: 24.8 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07984461514974954		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.07984461514974954 | validation: 0.08542981863181268]
	TIME [epoch: 24.8 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07872744927381572		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.07872744927381572 | validation: 0.09076820319759431]
	TIME [epoch: 24.8 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08137782063677185		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.08137782063677185 | validation: 0.09420206576868115]
	TIME [epoch: 24.8 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07792387038396614		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.07792387038396614 | validation: 0.08777144190063262]
	TIME [epoch: 24.8 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07378782907761666		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.07378782907761666 | validation: 0.09359084483852646]
	TIME [epoch: 24.8 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07478001753529206		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.07478001753529206 | validation: 0.0833745362064029]
	TIME [epoch: 24.8 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07902036381868975		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.07902036381868975 | validation: 0.08528790712668537]
	TIME [epoch: 24.8 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07531456778640647		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.07531456778640647 | validation: 0.08742232678805904]
	TIME [epoch: 24.8 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07748110778794846		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.07748110778794846 | validation: 0.08409957852695131]
	TIME [epoch: 24.8 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07536536792604465		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.07536536792604465 | validation: 0.08804657402350201]
	TIME [epoch: 24.8 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07460760893436884		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.07460760893436884 | validation: 0.08751298336942906]
	TIME [epoch: 24.7 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.077130844575834		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.077130844575834 | validation: 0.09349801395910667]
	TIME [epoch: 24.8 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07295277275326624		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.07295277275326624 | validation: 0.08125705804732819]
	TIME [epoch: 24.8 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07763051626814514		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.07763051626814514 | validation: 0.07780945300825487]
	TIME [epoch: 24.8 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07574436236481286		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.07574436236481286 | validation: 0.08114143526299407]
	TIME [epoch: 24.8 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07843673534751683		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.07843673534751683 | validation: 0.09421104404660316]
	TIME [epoch: 24.8 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07760650537150392		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.07760650537150392 | validation: 0.08534018249315743]
	TIME [epoch: 24.8 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07373529150463856		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.07373529150463856 | validation: 0.09066834758571295]
	TIME [epoch: 24.8 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07484694808327395		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.07484694808327395 | validation: 0.08761326481728027]
	TIME [epoch: 24.8 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0762989236615777		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.0762989236615777 | validation: 0.08174515488991306]
	TIME [epoch: 24.7 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07881743461281335		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.07881743461281335 | validation: 0.08497047212195545]
	TIME [epoch: 24.8 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07431516217611177		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.07431516217611177 | validation: 0.09062614662270133]
	TIME [epoch: 24.8 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07685247180543311		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.07685247180543311 | validation: 0.08980824979276854]
	TIME [epoch: 24.8 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07607268742156949		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.07607268742156949 | validation: 0.0878541519297353]
	TIME [epoch: 24.7 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07524739125702895		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.07524739125702895 | validation: 0.08440987897901456]
	TIME [epoch: 24.7 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07845372736784174		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.07845372736784174 | validation: 0.08125727589601951]
	TIME [epoch: 24.7 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07500478755873571		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.07500478755873571 | validation: 0.09080808068791486]
	TIME [epoch: 24.8 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07602972457945385		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.07602972457945385 | validation: 0.08990229745561394]
	TIME [epoch: 24.8 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07390299061017265		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.07390299061017265 | validation: 0.09061836703899676]
	TIME [epoch: 24.7 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07579880317591761		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.07579880317591761 | validation: 0.08324575291945668]
	TIME [epoch: 24.8 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07751606849658105		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.07751606849658105 | validation: 0.09195100452102647]
	TIME [epoch: 24.8 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07511862645079598		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.07511862645079598 | validation: 0.08186995882130425]
	TIME [epoch: 24.8 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07637289260288992		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.07637289260288992 | validation: 0.07824289977966259]
	TIME [epoch: 24.8 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07937834625459562		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.07937834625459562 | validation: 0.0860458087657386]
	TIME [epoch: 24.8 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07806289670070304		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.07806289670070304 | validation: 0.08719787649328478]
	TIME [epoch: 24.7 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07293600051730217		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.07293600051730217 | validation: 0.08594782426710557]
	TIME [epoch: 24.8 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0764281373795737		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.0764281373795737 | validation: 0.08788259030597928]
	TIME [epoch: 24.8 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07567159779013416		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.07567159779013416 | validation: 0.08423648149829244]
	TIME [epoch: 24.8 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07562492375660929		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.07562492375660929 | validation: 0.08278628415067385]
	TIME [epoch: 24.8 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07884642719454964		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.07884642719454964 | validation: 0.08329964225439226]
	TIME [epoch: 24.7 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07718621996319674		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.07718621996319674 | validation: 0.0884004385330022]
	TIME [epoch: 24.7 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07418006674728853		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.07418006674728853 | validation: 0.08526201010658514]
	TIME [epoch: 24.8 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07467635032110895		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.07467635032110895 | validation: 0.0911002587652005]
	TIME [epoch: 24.8 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07509491164734303		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.07509491164734303 | validation: 0.09224436518957935]
	TIME [epoch: 24.8 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08093187090535257		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.08093187090535257 | validation: 0.09405986821632635]
	TIME [epoch: 24.8 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07757851945352343		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.07757851945352343 | validation: 0.08193868853984199]
	TIME [epoch: 24.8 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07731549365830417		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.07731549365830417 | validation: 0.08560086227670458]
	TIME [epoch: 24.8 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0755375070330717		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.0755375070330717 | validation: 0.08410496964177369]
	TIME [epoch: 24.8 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0735883010542444		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.0735883010542444 | validation: 0.08439334791309096]
	TIME [epoch: 24.7 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07322037678051112		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.07322037678051112 | validation: 0.08823498302494424]
	TIME [epoch: 24.8 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07904732951710872		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.07904732951710872 | validation: 0.09505289011430407]
	TIME [epoch: 24.8 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08073891457727088		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.08073891457727088 | validation: 0.09335617551843126]
	TIME [epoch: 24.7 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07973952760468565		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.07973952760468565 | validation: 0.09199239475989864]
	TIME [epoch: 24.8 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07560050222767176		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.07560050222767176 | validation: 0.09000735178778449]
	TIME [epoch: 24.8 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07750712819611336		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.07750712819611336 | validation: 0.08613363743884442]
	TIME [epoch: 24.7 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07683453763877209		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.07683453763877209 | validation: 0.08621321696190563]
	TIME [epoch: 24.8 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07862734062868118		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.07862734062868118 | validation: 0.09421674182158693]
	TIME [epoch: 24.8 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07373240399868192		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.07373240399868192 | validation: 0.09214767480963224]
	TIME [epoch: 24.8 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07504276547104347		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.07504276547104347 | validation: 0.09207869654198979]
	TIME [epoch: 24.8 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07470661230773555		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.07470661230773555 | validation: 0.08782409119646475]
	TIME [epoch: 24.8 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07983262740557545		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.07983262740557545 | validation: 0.08968279872115474]
	TIME [epoch: 24.8 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08195638880702186		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.08195638880702186 | validation: 0.08310674958601705]
	TIME [epoch: 24.7 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08156348633233064		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.08156348633233064 | validation: 0.09296357884827586]
	TIME [epoch: 24.8 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07872856546569233		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.07872856546569233 | validation: 0.08017248195547183]
	TIME [epoch: 24.8 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07796342979766603		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.07796342979766603 | validation: 0.08248294166618876]
	TIME [epoch: 24.8 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0770816041931448		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.0770816041931448 | validation: 0.09405503595825966]
	TIME [epoch: 24.8 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08013988438651348		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.08013988438651348 | validation: 0.0862359251179016]
	TIME [epoch: 24.7 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07948558356317137		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.07948558356317137 | validation: 0.08408063345402746]
	TIME [epoch: 24.7 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07682234353225986		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.07682234353225986 | validation: 0.09162241868062161]
	TIME [epoch: 24.8 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07725386313336378		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.07725386313336378 | validation: 0.08453370240715634]
	TIME [epoch: 24.7 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07789600632075505		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.07789600632075505 | validation: 0.08690155874700611]
	TIME [epoch: 24.8 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07894459949973621		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.07894459949973621 | validation: 0.09115759697370837]
	TIME [epoch: 24.8 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07458386522330059		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.07458386522330059 | validation: 0.0925763068678061]
	TIME [epoch: 24.8 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07725127661231264		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.07725127661231264 | validation: 0.09305330773884872]
	TIME [epoch: 24.8 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07736240894808516		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.07736240894808516 | validation: 0.08925131892335549]
	TIME [epoch: 24.8 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0775386789234964		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.0775386789234964 | validation: 0.0958019946159628]
	TIME [epoch: 24.7 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07821063353801755		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.07821063353801755 | validation: 0.09207184369820214]
	TIME [epoch: 24.8 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07586397437862699		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.07586397437862699 | validation: 0.08305317159515432]
	TIME [epoch: 24.8 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07566322390375771		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.07566322390375771 | validation: 0.08286676895142499]
	TIME [epoch: 24.7 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0773411955228881		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.0773411955228881 | validation: 0.08962559997740083]
	TIME [epoch: 24.7 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07571902678905107		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.07571902678905107 | validation: 0.0899170929966875]
	TIME [epoch: 24.8 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08149104577383695		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.08149104577383695 | validation: 0.0880283743413895]
	TIME [epoch: 24.8 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.074622153939674		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.074622153939674 | validation: 0.0790385389407003]
	TIME [epoch: 24.8 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.076283225144352		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.076283225144352 | validation: 0.08382378026228449]
	TIME [epoch: 24.8 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07596965663367902		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.07596965663367902 | validation: 0.07788563814937359]
	TIME [epoch: 24.8 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07679741536262633		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.07679741536262633 | validation: 0.08347507212053117]
	TIME [epoch: 24.8 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07569748662927003		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.07569748662927003 | validation: 0.08399965831563495]
	TIME [epoch: 24.8 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07987693902935955		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.07987693902935955 | validation: 0.08725525672108787]
	TIME [epoch: 24.8 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07525809485676974		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.07525809485676974 | validation: 0.08528424546681486]
	TIME [epoch: 24.8 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07807399086594269		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.07807399086594269 | validation: 0.08074804508968672]
	TIME [epoch: 24.8 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07459885753051321		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.07459885753051321 | validation: 0.08661937604772436]
	TIME [epoch: 24.8 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08067174372033517		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.08067174372033517 | validation: 0.08135545634286938]
	TIME [epoch: 24.8 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07725637447176403		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.07725637447176403 | validation: 0.08023033828394498]
	TIME [epoch: 24.8 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07740381069489088		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.07740381069489088 | validation: 0.08248388596332243]
	TIME [epoch: 24.8 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07939480626448535		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.07939480626448535 | validation: 0.09030014956654953]
	TIME [epoch: 24.8 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07303720826513077		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.07303720826513077 | validation: 0.08225544674722172]
	TIME [epoch: 24.8 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07756846606334218		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.07756846606334218 | validation: 0.08798024899445754]
	TIME [epoch: 24.7 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07619750029618597		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.07619750029618597 | validation: 0.08289475389061604]
	TIME [epoch: 24.8 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0796375368029029		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.0796375368029029 | validation: 0.08646226834888253]
	TIME [epoch: 24.8 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0747206969332568		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.0747206969332568 | validation: 0.0811129225279135]
	TIME [epoch: 24.8 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07908920041443125		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.07908920041443125 | validation: 0.07853295644465016]
	TIME [epoch: 24.8 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07483632715041216		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.07483632715041216 | validation: 0.09345614107739657]
	TIME [epoch: 24.8 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0760403112596661		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.0760403112596661 | validation: 0.090479796613446]
	TIME [epoch: 24.7 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07440952307180149		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.07440952307180149 | validation: 0.0790283846782026]
	TIME [epoch: 24.8 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08202718242979193		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.08202718242979193 | validation: 0.08583458739887435]
	TIME [epoch: 24.8 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07761611756307774		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.07761611756307774 | validation: 0.09097070566199515]
	TIME [epoch: 24.8 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08107446580600597		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.08107446580600597 | validation: 0.08772273223786474]
	TIME [epoch: 24.8 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07740696708984661		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.07740696708984661 | validation: 0.08228438479062707]
	TIME [epoch: 24.8 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07951992421419155		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.07951992421419155 | validation: 0.09668838269289644]
	TIME [epoch: 24.7 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07641593275588575		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.07641593275588575 | validation: 0.08525207986094584]
	TIME [epoch: 24.8 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0810677143844536		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.0810677143844536 | validation: 0.08800418088133434]
	TIME [epoch: 24.8 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07657591074735126		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.07657591074735126 | validation: 0.0765004638314253]
	TIME [epoch: 24.7 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0745600835982209		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.0745600835982209 | validation: 0.08148438376077173]
	TIME [epoch: 24.8 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07541772728312494		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.07541772728312494 | validation: 0.08938332398808818]
	TIME [epoch: 24.8 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07750386372351223		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.07750386372351223 | validation: 0.08351374290722596]
	TIME [epoch: 24.8 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08039216519151968		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.08039216519151968 | validation: 0.08085936658618793]
	TIME [epoch: 24.8 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07602128358613663		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.07602128358613663 | validation: 0.08612145480090255]
	TIME [epoch: 24.8 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0779817952930491		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.0779817952930491 | validation: 0.08690456947920427]
	TIME [epoch: 24.7 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07940957858990876		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.07940957858990876 | validation: 0.08977694052790419]
	TIME [epoch: 24.8 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07603974279849193		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.07603974279849193 | validation: 0.09627966744615792]
	TIME [epoch: 24.8 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0771277173764862		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.0771277173764862 | validation: 0.0810258813338354]
	TIME [epoch: 24.8 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07997171868072263		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.07997171868072263 | validation: 0.07825992477043768]
	TIME [epoch: 24.7 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07852712483841168		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.07852712483841168 | validation: 0.09016648161864599]
	TIME [epoch: 24.8 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07445136007538133		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.07445136007538133 | validation: 0.08843605392148522]
	TIME [epoch: 24.7 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0755643156409688		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.0755643156409688 | validation: 0.08397576132581712]
	TIME [epoch: 24.8 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07872585407098073		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.07872585407098073 | validation: 0.08763982313409187]
	TIME [epoch: 24.8 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07548219733432202		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.07548219733432202 | validation: 0.0847709912161081]
	TIME [epoch: 24.7 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07740305136743164		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.07740305136743164 | validation: 0.08559616986874084]
	TIME [epoch: 24.8 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07851048806246053		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.07851048806246053 | validation: 0.08136483784748634]
	TIME [epoch: 24.8 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0721660073290083		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.0721660073290083 | validation: 0.08803760095019172]
	TIME [epoch: 24.8 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0774168358791082		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.0774168358791082 | validation: 0.09016309413904759]
	TIME [epoch: 24.8 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07868885313974813		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.07868885313974813 | validation: 0.08578642409627843]
	TIME [epoch: 24.8 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07753295448252187		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.07753295448252187 | validation: 0.09607687988185276]
	TIME [epoch: 24.8 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0785065259714591		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.0785065259714591 | validation: 0.08209158825161077]
	TIME [epoch: 24.8 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07592992489207599		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.07592992489207599 | validation: 0.08391584786502268]
	TIME [epoch: 24.8 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07697464503629783		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.07697464503629783 | validation: 0.08501572999429488]
	TIME [epoch: 24.7 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07802908230321026		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.07802908230321026 | validation: 0.0869246789181876]
	TIME [epoch: 24.8 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07633050082669364		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.07633050082669364 | validation: 0.0856780760928092]
	TIME [epoch: 24.8 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07839751611721071		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.07839751611721071 | validation: 0.08557151893035696]
	TIME [epoch: 24.8 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07685518343002637		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.07685518343002637 | validation: 0.08408769519654452]
	TIME [epoch: 24.8 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07429311475310053		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.07429311475310053 | validation: 0.08021401136054233]
	TIME [epoch: 24.8 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07703886678004238		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.07703886678004238 | validation: 0.08532775220899279]
	TIME [epoch: 24.7 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07636496486017677		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.07636496486017677 | validation: 0.08635528115401815]
	TIME [epoch: 24.8 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07713676824463596		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.07713676824463596 | validation: 0.08257893203189781]
	TIME [epoch: 24.8 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07855552760658802		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.07855552760658802 | validation: 0.08707993039655466]
	TIME [epoch: 24.7 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0782212566487452		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.0782212566487452 | validation: 0.0927793056167929]
	TIME [epoch: 24.8 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07703470904126303		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.07703470904126303 | validation: 0.09025523917757611]
	TIME [epoch: 24.8 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07788042793436672		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.07788042793436672 | validation: 0.0842603503075755]
	TIME [epoch: 24.8 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07825300103892871		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.07825300103892871 | validation: 0.09565276014360397]
	TIME [epoch: 24.8 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08134632535826133		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.08134632535826133 | validation: 0.0865420791589049]
	TIME [epoch: 24.8 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07649621352805408		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.07649621352805408 | validation: 0.08923109705486253]
	TIME [epoch: 24.7 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07842783762722624		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.07842783762722624 | validation: 0.08794110615142606]
	TIME [epoch: 24.8 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07689951082816926		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.07689951082816926 | validation: 0.08935557953472682]
	TIME [epoch: 24.8 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07768456183086717		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.07768456183086717 | validation: 0.08489731049238955]
	TIME [epoch: 24.7 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07305437802937836		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.07305437802937836 | validation: 0.09062395331499255]
	TIME [epoch: 24.8 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07951903290509207		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.07951903290509207 | validation: 0.08958524537917743]
	TIME [epoch: 24.8 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07560774289450718		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.07560774289450718 | validation: 0.0847901866485587]
	TIME [epoch: 24.7 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0810155590343059		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.0810155590343059 | validation: 0.0879217672315649]
	TIME [epoch: 24.8 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0764081294848968		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.0764081294848968 | validation: 0.09070715960141998]
	TIME [epoch: 24.8 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07789090600025855		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.07789090600025855 | validation: 0.08784104293991238]
	TIME [epoch: 24.7 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07708729589624498		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.07708729589624498 | validation: 0.08379457395883241]
	TIME [epoch: 24.8 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07550328069504197		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.07550328069504197 | validation: 0.09254830831768619]
	TIME [epoch: 24.8 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07898347774193147		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.07898347774193147 | validation: 0.08925768715752065]
	TIME [epoch: 24.8 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07590456643235248		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.07590456643235248 | validation: 0.07996925633621774]
	TIME [epoch: 24.8 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07789475325274944		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.07789475325274944 | validation: 0.08329576451202492]
	TIME [epoch: 24.8 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07622242725936375		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.07622242725936375 | validation: 0.08608878718520557]
	TIME [epoch: 24.7 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07946151713187716		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.07946151713187716 | validation: 0.08835715036756608]
	TIME [epoch: 24.8 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07783420984649383		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.07783420984649383 | validation: 0.08257768370575812]
	TIME [epoch: 24.8 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0759011781072832		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.0759011781072832 | validation: 0.08982220048374963]
	TIME [epoch: 24.7 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08150853978129938		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.08150853978129938 | validation: 0.09388390322112641]
	TIME [epoch: 24.8 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07636027971909773		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.07636027971909773 | validation: 0.08067785940784412]
	TIME [epoch: 24.8 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07803338283483502		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.07803338283483502 | validation: 0.08836758136090302]
	TIME [epoch: 24.8 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0792866307325513		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.0792866307325513 | validation: 0.08765546616459403]
	TIME [epoch: 24.8 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08000616385890492		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.08000616385890492 | validation: 0.08227619053226526]
	TIME [epoch: 24.8 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07446057301694702		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.07446057301694702 | validation: 0.0883688328277437]
	TIME [epoch: 24.8 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07401553891793773		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.07401553891793773 | validation: 0.08960076298552742]
	TIME [epoch: 24.8 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07825731816054046		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.07825731816054046 | validation: 0.091873808986808]
	TIME [epoch: 24.8 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07450436978336412		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.07450436978336412 | validation: 0.09304787678079053]
	TIME [epoch: 24.8 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07571364440976028		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.07571364440976028 | validation: 0.08760531879815646]
	TIME [epoch: 24.8 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07993262351741666		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.07993262351741666 | validation: 0.08320472442258366]
	TIME [epoch: 24.8 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07600713921895108		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.07600713921895108 | validation: 0.08796489781555905]
	TIME [epoch: 24.7 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08089487716581231		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.08089487716581231 | validation: 0.08671861102356758]
	TIME [epoch: 24.8 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07701119726360633		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.07701119726360633 | validation: 0.0774634810281633]
	TIME [epoch: 24.8 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07617540200618056		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.07617540200618056 | validation: 0.08759053585171936]
	TIME [epoch: 24.8 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07535118010557959		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.07535118010557959 | validation: 0.09083723166931745]
	TIME [epoch: 24.8 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07830577205163693		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.07830577205163693 | validation: 0.0906299204578907]
	TIME [epoch: 24.7 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07924538886701628		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.07924538886701628 | validation: 0.08660338067218522]
	TIME [epoch: 24.8 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08073213587073443		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.08073213587073443 | validation: 0.09238531597243292]
	TIME [epoch: 24.8 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08007372216701697		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.08007372216701697 | validation: 0.08211202045216202]
	TIME [epoch: 24.8 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07652259282744862		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.07652259282744862 | validation: 0.08656938557278294]
	TIME [epoch: 24.8 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07534635273533552		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.07534635273533552 | validation: 0.08759224287514913]
	TIME [epoch: 24.8 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07700744149108099		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.07700744149108099 | validation: 0.08864136437571174]
	TIME [epoch: 24.8 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0767761832138386		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.0767761832138386 | validation: 0.08457905507010244]
	TIME [epoch: 24.8 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07397893521947572		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.07397893521947572 | validation: 0.08890223057474217]
	TIME [epoch: 24.8 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07520738287745102		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.07520738287745102 | validation: 0.08488418390979156]
	TIME [epoch: 24.8 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07479294172922435		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.07479294172922435 | validation: 0.08442790804424184]
	TIME [epoch: 24.8 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0776615469419908		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.0776615469419908 | validation: 0.07781765379917822]
	TIME [epoch: 24.8 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07629470663575158		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.07629470663575158 | validation: 0.08255558449639765]
	TIME [epoch: 24.8 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07633384444134869		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.07633384444134869 | validation: 0.08195358880399856]
	TIME [epoch: 24.8 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08104355506913427		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.08104355506913427 | validation: 0.0873609333323796]
	TIME [epoch: 24.8 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07986156860948665		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.07986156860948665 | validation: 0.0862579698111446]
	TIME [epoch: 24.8 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07718281553869881		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.07718281553869881 | validation: 0.09168582677835112]
	TIME [epoch: 24.8 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07838437914947778		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.07838437914947778 | validation: 0.08812770874404731]
	TIME [epoch: 24.8 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07743208062899612		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.07743208062899612 | validation: 0.08528280599836892]
	TIME [epoch: 24.8 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07600993677289165		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.07600993677289165 | validation: 0.07707722905587212]
	TIME [epoch: 24.8 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08065023851447568		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.08065023851447568 | validation: 0.08170844924198037]
	TIME [epoch: 24.8 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07834889053627817		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.07834889053627817 | validation: 0.07950848263412745]
	TIME [epoch: 24.8 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07823546599737083		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.07823546599737083 | validation: 0.08966472093591303]
	TIME [epoch: 24.8 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07692575450510605		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.07692575450510605 | validation: 0.07308038128461816]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240424_132548/states/model_tr_study5_1963.pth
	Model improved!!!
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08107756085736555		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.08107756085736555 | validation: 0.08359361106657842]
	TIME [epoch: 24.7 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07813066148589867		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.07813066148589867 | validation: 0.0859544198036129]
	TIME [epoch: 24.7 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07701970720731768		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.07701970720731768 | validation: 0.0850355685957296]
	TIME [epoch: 24.7 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07711772784845614		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.07711772784845614 | validation: 0.08902280599797964]
	TIME [epoch: 24.7 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07500663418790854		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.07500663418790854 | validation: 0.09163887003780095]
	TIME [epoch: 24.7 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07611722808716206		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.07611722808716206 | validation: 0.08339778058254087]
	TIME [epoch: 24.8 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08311559177957883		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.08311559177957883 | validation: 0.08700307848252999]
	TIME [epoch: 24.7 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0743376280371914		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.0743376280371914 | validation: 0.08224215425149761]
	TIME [epoch: 24.8 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07878917182307689		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.07878917182307689 | validation: 0.08636802910796025]
	TIME [epoch: 24.8 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07812778623621412		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.07812778623621412 | validation: 0.0879471910738904]
	TIME [epoch: 24.7 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07908135868018877		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.07908135868018877 | validation: 0.07789943017764168]
	TIME [epoch: 24.7 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07431639634726579		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.07431639634726579 | validation: 0.08413074759728531]
	TIME [epoch: 24.8 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07679681318662679		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.07679681318662679 | validation: 0.08329282360114448]
	TIME [epoch: 24.7 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07780972586685375		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.07780972586685375 | validation: 0.08390210237908123]
	TIME [epoch: 24.7 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07955322581100496		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.07955322581100496 | validation: 0.08755150124597945]
	TIME [epoch: 24.7 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0770615946341119		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.0770615946341119 | validation: 0.08908894355291891]
	TIME [epoch: 24.7 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.076676597790379		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.076676597790379 | validation: 0.079326599917379]
	TIME [epoch: 24.7 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07448429927039164		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.07448429927039164 | validation: 0.08713864150961023]
	TIME [epoch: 24.7 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07690869728189746		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.07690869728189746 | validation: 0.08409784761456753]
	TIME [epoch: 24.7 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07883942607822367		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.07883942607822367 | validation: 0.07785346201728573]
	TIME [epoch: 24.7 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07414022891776613		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.07414022891776613 | validation: 0.07725507450843928]
	TIME [epoch: 24.8 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07693032940047778		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.07693032940047778 | validation: 0.08919184950485595]
	TIME [epoch: 24.7 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0757484118611484		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.0757484118611484 | validation: 0.08779525887258637]
	TIME [epoch: 24.7 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0774132428208472		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.0774132428208472 | validation: 0.08476476374437335]
	TIME [epoch: 24.8 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07475090099342288		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.07475090099342288 | validation: 0.08457275097856823]
	TIME [epoch: 24.8 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07841354932726552		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.07841354932726552 | validation: 0.0872229436881085]
	TIME [epoch: 24.8 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0759726860966439		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.0759726860966439 | validation: 0.09532174282952227]
	TIME [epoch: 24.8 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07521815828538221		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.07521815828538221 | validation: 0.08899139346086081]
	TIME [epoch: 24.8 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07629725370041696		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.07629725370041696 | validation: 0.08350591104806883]
	TIME [epoch: 24.8 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07704070689394404		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.07704070689394404 | validation: 0.08800203857985697]
	TIME [epoch: 24.8 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07833668864616866		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.07833668864616866 | validation: 0.08840833178881098]
	TIME [epoch: 24.7 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07952890282623504		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.07952890282623504 | validation: 0.09536496154080869]
	TIME [epoch: 24.8 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07617154428146287		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.07617154428146287 | validation: 0.09202549329476634]
	TIME [epoch: 24.8 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07867325472208384		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.07867325472208384 | validation: 0.08489741952243708]
	TIME [epoch: 24.7 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07613660369450238		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.07613660369450238 | validation: 0.0859409302289056]
	TIME [epoch: 24.8 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07679704208626642		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.07679704208626642 | validation: 0.08498636485394069]
	TIME [epoch: 24.8 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07676943096534716		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.07676943096534716 | validation: 0.09322958276644552]
	TIME [epoch: 24.8 sec]
Finished training in 49806.025 seconds.
