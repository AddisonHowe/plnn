Args:
Namespace(name='model_tr_study5', outdir='out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1', training_data='data/transition_rate_studies/tr_study5/tr_study5_training/r1', validation_data='data/transition_rate_studies/tr_study5/tr_study5_validation/r1', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2315939789

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 12.710793525011875		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 12.710793525011875 | validation: 12.16180408103489]
	TIME [epoch: 109 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.415237011676544		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.415237011676544 | validation: 11.320120337708975]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.588510363722214		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.588510363722214 | validation: 10.66681722868365]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.877380638893623		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.877380638893623 | validation: 10.305175633306526]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.605536909573388		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.605536909573388 | validation: 9.75756742087629]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.134568522947571		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.134568522947571 | validation: 9.452614609171386]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.839452338291533		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.839452338291533 | validation: 9.088216243430034]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.550763638014745		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.550763638014745 | validation: 8.409332034124018]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.193006572857465		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.193006572857465 | validation: 8.0139386001964]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.806445427676067		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.806445427676067 | validation: 7.715295033992629]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.5045005453924345		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.5045005453924345 | validation: 7.330263292746756]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.036126348438296		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.036126348438296 | validation: 6.7181621432356495]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.585733271193872		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.585733271193872 | validation: 6.433260158961607]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.329330813986505		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.329330813986505 | validation: 6.261556721112207]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.198818201235763		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.198818201235763 | validation: 6.095244817710895]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.092882696902265		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.092882696902265 | validation: 6.099994897664092]
	TIME [epoch: 27.7 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.101828397135204		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.101828397135204 | validation: 5.963689728033094]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.9884740617774		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.9884740617774 | validation: 5.826547719871228]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.981112870573787		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.981112870573787 | validation: 5.966272907127147]
	TIME [epoch: 27.6 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.950251926717496		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.950251926717496 | validation: 5.718881448234891]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.785390046961169		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.785390046961169 | validation: 5.729092854842495]
	TIME [epoch: 27.7 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.81298132114808		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.81298132114808 | validation: 5.729955744527079]
	TIME [epoch: 27.6 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.700841660965447		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.700841660965447 | validation: 5.670078711227304]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.644241613028383		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.644241613028383 | validation: 5.502492970115425]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7306477943106575		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.7306477943106575 | validation: 5.631090209604734]
	TIME [epoch: 27.7 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.80200324821189		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.80200324821189 | validation: 5.584157048592031]
	TIME [epoch: 27.6 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.939313702237827		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.939313702237827 | validation: 5.90408078240471]
	TIME [epoch: 27.6 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.861529986508809		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.861529986508809 | validation: 5.537562130200779]
	TIME [epoch: 27.7 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.697301250673743		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.697301250673743 | validation: 5.489778272251133]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.602392500158477		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.602392500158477 | validation: 5.456908247158346]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.632473600104445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.632473600104445 | validation: 5.569045234645338]
	TIME [epoch: 27.6 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.534141711922354		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.534141711922354 | validation: 5.531000083305517]
	TIME [epoch: 27.7 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.583723606316583		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.583723606316583 | validation: 5.55679703735749]
	TIME [epoch: 27.7 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.6470892475889265		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.6470892475889265 | validation: 5.52896003545101]
	TIME [epoch: 27.7 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.464365925059287		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.464365925059287 | validation: 5.979945947621282]
	TIME [epoch: 27.7 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.843045617787446		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.843045617787446 | validation: 5.3614345128910665]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.468937678764222		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.468937678764222 | validation: 5.426604533030431]
	TIME [epoch: 27.7 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.5827884216229275		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.5827884216229275 | validation: 5.542670914126782]
	TIME [epoch: 27.7 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.536495184085871		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.536495184085871 | validation: 5.633962690320734]
	TIME [epoch: 27.7 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.438941797877164		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.438941797877164 | validation: 5.29279054140823]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.47565941218848		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.47565941218848 | validation: 5.2414023134712036]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.546617794595978		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.546617794595978 | validation: 5.498160771985534]
	TIME [epoch: 27.6 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.490565951646198		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.490565951646198 | validation: 5.48418600379214]
	TIME [epoch: 27.7 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.42329053254438		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.42329053254438 | validation: 5.093798234931496]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.277178347539136		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.277178347539136 | validation: 5.197026702759498]
	TIME [epoch: 27.7 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.324490458285661		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.324490458285661 | validation: 5.091205523184031]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.159781106789809		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.159781106789809 | validation: 5.014032660570203]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.0889725043366525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.0889725043366525 | validation: 5.573996096042527]
	TIME [epoch: 27.7 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.401084807014847		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.401084807014847 | validation: 9.383210947504185]
	TIME [epoch: 27.6 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.469387875781242		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.469387875781242 | validation: 5.95971256248867]
	TIME [epoch: 27.7 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.365694472144661		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 5.365694472144661 | validation: 4.894103522093677]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.350860818180881		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 5.350860818180881 | validation: 7.100563912353173]
	TIME [epoch: 27.6 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.14066191182064		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 6.14066191182064 | validation: 5.346311723429535]
	TIME [epoch: 27.6 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.45454616973537		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 6.45454616973537 | validation: 6.350411783838695]
	TIME [epoch: 27.7 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.899112992925903		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 5.899112992925903 | validation: 5.280597446568216]
	TIME [epoch: 27.6 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.03493380627013		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 5.03493380627013 | validation: 4.9790856719143255]
	TIME [epoch: 27.7 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.04339960574321		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 5.04339960574321 | validation: 5.151111739535996]
	TIME [epoch: 27.6 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.3538186090732935		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 5.3538186090732935 | validation: 5.05738296430389]
	TIME [epoch: 27.7 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.151314561388997		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 5.151314561388997 | validation: 4.84444817173452]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.985019740932302		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 4.985019740932302 | validation: 5.22797555277534]
	TIME [epoch: 27.7 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.06520319230699		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 5.06520319230699 | validation: 5.587581849082141]
	TIME [epoch: 27.6 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.437840706145767		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 5.437840706145767 | validation: 5.733742770209722]
	TIME [epoch: 27.6 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.578118561049566		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 5.578118561049566 | validation: 5.640065026710225]
	TIME [epoch: 27.7 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.738496593725213		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 6.738496593725213 | validation: 6.320623811954956]
	TIME [epoch: 27.6 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.6676023797723385		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 5.6676023797723385 | validation: 5.593139000554782]
	TIME [epoch: 27.6 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.226128130681746		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 5.226128130681746 | validation: 5.002273250692629]
	TIME [epoch: 27.7 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.09614682519502		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 6.09614682519502 | validation: 7.070606542707534]
	TIME [epoch: 27.6 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.251985898871156		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 6.251985898871156 | validation: 5.134627787900363]
	TIME [epoch: 27.6 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.241321426046035		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 5.241321426046035 | validation: 5.0930023217898315]
	TIME [epoch: 27.6 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.1783158950656265		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 5.1783158950656265 | validation: 5.1359511425657205]
	TIME [epoch: 27.6 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.9908506110364685		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 4.9908506110364685 | validation: 5.275890719015629]
	TIME [epoch: 27.7 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.318438726399096		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 5.318438726399096 | validation: 5.129732581576125]
	TIME [epoch: 27.6 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.982695703740621		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 4.982695703740621 | validation: 4.804401745501647]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.495294649600815		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 5.495294649600815 | validation: 4.914349313436368]
	TIME [epoch: 27.7 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.631301825328312		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 5.631301825328312 | validation: 5.499070179888715]
	TIME [epoch: 27.6 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.528330714568117		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 6.528330714568117 | validation: 6.518677008664485]
	TIME [epoch: 27.7 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.0109169199043135		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 6.0109169199043135 | validation: 4.615322094381407]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.783565587912236		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 4.783565587912236 | validation: 4.571577661574263]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.641352039219897		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 4.641352039219897 | validation: 4.877216221591716]
	TIME [epoch: 27.6 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.707041971002107		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 4.707041971002107 | validation: 4.2575643237848855]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_80.pth
	Model improved!!!
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.552034032484912		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 4.552034032484912 | validation: 4.475901249469074]
	TIME [epoch: 27.7 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5406386970664885		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 4.5406386970664885 | validation: 4.517357907934747]
	TIME [epoch: 27.6 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.317955018327796		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 4.317955018327796 | validation: 3.952457654060106]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_83.pth
	Model improved!!!
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.116777351726568		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 4.116777351726568 | validation: 5.2269754883954445]
	TIME [epoch: 27.6 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.355292455256661		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 5.355292455256661 | validation: 5.564608213932068]
	TIME [epoch: 27.6 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.608462447119489		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 4.608462447119489 | validation: 3.826789646416014]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_86.pth
	Model improved!!!
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.629968495138657		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 3.629968495138657 | validation: 5.198733882688973]
	TIME [epoch: 27.7 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.771310301530397		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 4.771310301530397 | validation: 3.5099038557290156]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_88.pth
	Model improved!!!
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.320690219754843		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 4.320690219754843 | validation: 4.177086830739065]
	TIME [epoch: 27.6 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.13384858575063		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 4.13384858575063 | validation: 3.542746658537045]
	TIME [epoch: 27.6 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.886885643359746		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 4.886885643359746 | validation: 4.847244904495169]
	TIME [epoch: 27.7 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.009611777621042		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 6.009611777621042 | validation: 3.499910735978302]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_92.pth
	Model improved!!!
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.047037658821496		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 4.047037658821496 | validation: 5.632646098311328]
	TIME [epoch: 27.6 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.5331162887226455		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 7.5331162887226455 | validation: 7.259836245962546]
	TIME [epoch: 27.7 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.026351745527198		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 7.026351745527198 | validation: 5.071980120048777]
	TIME [epoch: 27.6 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.786238292590651		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 4.786238292590651 | validation: 3.9714029620513718]
	TIME [epoch: 27.7 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8239792060654656		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 3.8239792060654656 | validation: 3.624352666396334]
	TIME [epoch: 27.6 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.881105474539501		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 4.881105474539501 | validation: 4.169714347374105]
	TIME [epoch: 27.7 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.733179673278056		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 3.733179673278056 | validation: 4.014337608568184]
	TIME [epoch: 27.7 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.101755523683503		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 6.101755523683503 | validation: 7.828503003523158]
	TIME [epoch: 27.7 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.143297170141788		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 6.143297170141788 | validation: 5.067621934052934]
	TIME [epoch: 27.7 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.184069988855684		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 4.184069988855684 | validation: 3.566271780669051]
	TIME [epoch: 27.7 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6535663328939556		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 3.6535663328939556 | validation: 3.3157985217977375]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_103.pth
	Model improved!!!
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.273965809149197		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 3.273965809149197 | validation: 4.69446381064954]
	TIME [epoch: 27.7 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.409669888098022		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 4.409669888098022 | validation: 6.783974647185243]
	TIME [epoch: 27.6 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.035817020986483		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 5.035817020986483 | validation: 4.433356249346136]
	TIME [epoch: 27.7 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.340453719624167		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 3.340453719624167 | validation: 2.982284830155348]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_107.pth
	Model improved!!!
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.247119043576186		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 3.247119043576186 | validation: 2.8674130211067625]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_108.pth
	Model improved!!!
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.0070196967653615		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 6.0070196967653615 | validation: 6.514855180108256]
	TIME [epoch: 27.6 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.444255830335743		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 6.444255830335743 | validation: 6.389066282738961]
	TIME [epoch: 27.6 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.088349888191382		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 7.088349888191382 | validation: 6.3589524594724525]
	TIME [epoch: 27.6 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.020154907859146		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 7.020154907859146 | validation: 6.32554873599786]
	TIME [epoch: 27.6 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.670493176523841		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 6.670493176523841 | validation: 6.785677514338857]
	TIME [epoch: 27.6 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.558778575483878		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 7.558778575483878 | validation: 6.55975637292212]
	TIME [epoch: 27.6 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.509774542900749		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 6.509774542900749 | validation: 6.694384520426543]
	TIME [epoch: 27.6 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.714762218379524		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 6.714762218379524 | validation: 5.566862360562665]
	TIME [epoch: 27.6 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.862991478924998		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 4.862991478924998 | validation: 4.764881874345416]
	TIME [epoch: 27.6 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.3128231918182145		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 6.3128231918182145 | validation: 6.3245694483403785]
	TIME [epoch: 27.6 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.755078992592745		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 6.755078992592745 | validation: 5.744511581925954]
	TIME [epoch: 27.6 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.2840372129414765		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 5.2840372129414765 | validation: 4.471755236996006]
	TIME [epoch: 27.6 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.454118326964448		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 4.454118326964448 | validation: 4.450265493182335]
	TIME [epoch: 27.6 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.572596009584127		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 4.572596009584127 | validation: 3.944360264808356]
	TIME [epoch: 27.6 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.716848781873016		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 3.716848781873016 | validation: 3.3767804416908827]
	TIME [epoch: 27.7 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.327979747801975		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 3.327979747801975 | validation: 4.143128211651394]
	TIME [epoch: 27.6 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.210722936160784		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 4.210722936160784 | validation: 3.160900199890257]
	TIME [epoch: 27.6 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2848470330612836		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 3.2848470330612836 | validation: 3.247991862967465]
	TIME [epoch: 27.6 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7854542200276047		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 3.7854542200276047 | validation: 3.835941193917508]
	TIME [epoch: 27.6 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.450335217916905		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 4.450335217916905 | validation: 4.610746214851468]
	TIME [epoch: 27.7 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.128850497436495		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 4.128850497436495 | validation: 3.4646507900287946]
	TIME [epoch: 27.6 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.488009253382397		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 3.488009253382397 | validation: 3.2566435021537483]
	TIME [epoch: 27.7 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3681663466991596		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 3.3681663466991596 | validation: 3.7798607634331867]
	TIME [epoch: 27.7 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5847823344483416		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 3.5847823344483416 | validation: 3.2610498023375807]
	TIME [epoch: 27.6 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.968896785958247		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 2.968896785958247 | validation: 2.8197688254000584]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_133.pth
	Model improved!!!
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6662185937538094		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 2.6662185937538094 | validation: 2.7448044225005517]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_134.pth
	Model improved!!!
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7756435056428503		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 2.7756435056428503 | validation: 2.4525457168680527]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_135.pth
	Model improved!!!
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2418013335007947		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 3.2418013335007947 | validation: 4.040212904116912]
	TIME [epoch: 27.7 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8078177092216023		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 3.8078177092216023 | validation: 2.9387774245459894]
	TIME [epoch: 27.7 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9462997036929677		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 2.9462997036929677 | validation: 3.22240603523496]
	TIME [epoch: 27.7 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0874284152813285		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 3.0874284152813285 | validation: 4.571499271280899]
	TIME [epoch: 27.7 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.074688742193937		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 3.074688742193937 | validation: 3.6787843087447767]
	TIME [epoch: 27.6 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.163073365185484		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 3.163073365185484 | validation: 2.4343083754205317]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_141.pth
	Model improved!!!
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8835154730946897		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 2.8835154730946897 | validation: 3.7074834869470634]
	TIME [epoch: 27.6 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.61348566851869		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 3.61348566851869 | validation: 3.3236114232172373]
	TIME [epoch: 27.7 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2490739490444036		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 3.2490739490444036 | validation: 2.343057792246266]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_144.pth
	Model improved!!!
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.184961534296751		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 2.184961534296751 | validation: 2.25069109210791]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_145.pth
	Model improved!!!
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.247947930402372		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 2.247947930402372 | validation: 2.264524721074097]
	TIME [epoch: 27.7 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1424528305446846		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 3.1424528305446846 | validation: 3.265109972800406]
	TIME [epoch: 27.6 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0278294024276797		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 3.0278294024276797 | validation: 4.843265177807049]
	TIME [epoch: 27.7 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1869439809357147		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 3.1869439809357147 | validation: 2.0609120695487126]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_149.pth
	Model improved!!!
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.305096438349777		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 2.305096438349777 | validation: 2.6456802673592166]
	TIME [epoch: 27.6 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6888657431451755		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 2.6888657431451755 | validation: 2.9478430749309634]
	TIME [epoch: 27.7 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7075023148645085		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 2.7075023148645085 | validation: 2.7382498564196807]
	TIME [epoch: 27.6 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2108315613884435		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 2.2108315613884435 | validation: 1.9174800770277716]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_153.pth
	Model improved!!!
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0004223117791082		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 2.0004223117791082 | validation: 2.0192851766060778]
	TIME [epoch: 27.7 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.960826718068701		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 1.960826718068701 | validation: 2.916876084475317]
	TIME [epoch: 27.6 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.860721656748168		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 2.860721656748168 | validation: 1.7793002278128927]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_156.pth
	Model improved!!!
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4229652922921003		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 2.4229652922921003 | validation: 2.2342149675572665]
	TIME [epoch: 27.6 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4593285567239027		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 2.4593285567239027 | validation: 1.8881581989658738]
	TIME [epoch: 27.7 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3030310951629813		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 2.3030310951629813 | validation: 2.147599547948314]
	TIME [epoch: 27.7 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8192886055104496		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 2.8192886055104496 | validation: 2.4835816012761818]
	TIME [epoch: 27.6 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9815012688602818		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 1.9815012688602818 | validation: 2.490869091448741]
	TIME [epoch: 27.7 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.069713079165392		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 2.069713079165392 | validation: 3.409946680678302]
	TIME [epoch: 27.6 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2812418983646467		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 2.2812418983646467 | validation: 1.9534111699089736]
	TIME [epoch: 27.7 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1179670625329563		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 2.1179670625329563 | validation: 1.9773947690906977]
	TIME [epoch: 27.7 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7825619241328248		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 1.7825619241328248 | validation: 3.1958385921091104]
	TIME [epoch: 27.6 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.165064423150606		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 2.165064423150606 | validation: 2.271986064570881]
	TIME [epoch: 27.7 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.686913905053892		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 1.686913905053892 | validation: 4.5797808567098]
	TIME [epoch: 27.6 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4166882068911915		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 2.4166882068911915 | validation: 1.7439063426639536]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_168.pth
	Model improved!!!
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5070517687710403		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 1.5070517687710403 | validation: 1.8314723718051233]
	TIME [epoch: 27.7 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8704923426133475		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 1.8704923426133475 | validation: 3.265453053059732]
	TIME [epoch: 27.6 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2728566368017153		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 2.2728566368017153 | validation: 1.7303641435804826]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_171.pth
	Model improved!!!
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.800860577235981		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 1.800860577235981 | validation: 1.6084840317962512]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_172.pth
	Model improved!!!
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6972615204922883		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 1.6972615204922883 | validation: 1.913154335615027]
	TIME [epoch: 27.6 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8822361391925861		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 1.8822361391925861 | validation: 1.6547693265496808]
	TIME [epoch: 27.7 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.539483508703597		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 3.539483508703597 | validation: 3.7515285550747697]
	TIME [epoch: 27.6 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.468183447089883		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 3.468183447089883 | validation: 3.0072397653142775]
	TIME [epoch: 27.7 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.952895878586469		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 2.952895878586469 | validation: 2.5387992975681484]
	TIME [epoch: 27.6 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0670706537162657		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 2.0670706537162657 | validation: 1.6875035956511106]
	TIME [epoch: 27.6 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7696528615614593		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 1.7696528615614593 | validation: 1.958213806775928]
	TIME [epoch: 27.7 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1560773352936793		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 2.1560773352936793 | validation: 3.918356603244193]
	TIME [epoch: 27.6 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.224043987391557		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 3.224043987391557 | validation: 2.2008229929334138]
	TIME [epoch: 27.7 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.082975760329168		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 2.082975760329168 | validation: 1.989331158585959]
	TIME [epoch: 27.6 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5407734913034221		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 1.5407734913034221 | validation: 1.4067607542019152]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_183.pth
	Model improved!!!
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5153170268188358		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 1.5153170268188358 | validation: 2.0319597273252725]
	TIME [epoch: 27.7 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.632830910912942		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 1.632830910912942 | validation: 2.1599757071888446]
	TIME [epoch: 27.6 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9108315178799784		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 1.9108315178799784 | validation: 2.5069406121584406]
	TIME [epoch: 27.7 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.284091449920809		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 3.284091449920809 | validation: 4.872412245317712]
	TIME [epoch: 27.6 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3218288119149246		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 3.3218288119149246 | validation: 2.0535331396997627]
	TIME [epoch: 27.7 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7988094503875927		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 1.7988094503875927 | validation: 2.8391909441767393]
	TIME [epoch: 27.6 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.373359791158003		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 2.373359791158003 | validation: 1.6322125956009967]
	TIME [epoch: 27.6 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.51864483550564		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 1.51864483550564 | validation: 1.504727083847256]
	TIME [epoch: 27.6 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3844252267692838		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 1.3844252267692838 | validation: 1.9301658798341714]
	TIME [epoch: 27.6 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5254676103050446		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 1.5254676103050446 | validation: 1.458656666031184]
	TIME [epoch: 27.6 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4051368458060158		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 1.4051368458060158 | validation: 1.5959198058744044]
	TIME [epoch: 27.6 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3635139873081021		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 1.3635139873081021 | validation: 1.4495092006906578]
	TIME [epoch: 27.6 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.910064203757489		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 1.910064203757489 | validation: 2.137032960718966]
	TIME [epoch: 27.6 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.65677781665625		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 2.65677781665625 | validation: 2.8784897878452704]
	TIME [epoch: 27.6 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1769375505554924		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 2.1769375505554924 | validation: 1.6101756545087886]
	TIME [epoch: 27.7 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1126901021566136		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 2.1126901021566136 | validation: 2.4913795192747843]
	TIME [epoch: 27.7 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.537330964761656		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 2.537330964761656 | validation: 3.3538632922370972]
	TIME [epoch: 27.6 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.35238770684741		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 3.35238770684741 | validation: 2.917766517424237]
	TIME [epoch: 27.6 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.822920884991999		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 2.822920884991999 | validation: 1.5600957091665586]
	TIME [epoch: 27.6 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4494131315592145		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 1.4494131315592145 | validation: 1.8672226558996545]
	TIME [epoch: 27.7 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5072246099190538		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 1.5072246099190538 | validation: 1.893753555763368]
	TIME [epoch: 27.6 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2732832935993326		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 1.2732832935993326 | validation: 3.033023132541477]
	TIME [epoch: 27.6 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.222925408928567		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 2.222925408928567 | validation: 2.7186077850916455]
	TIME [epoch: 27.6 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.603869893879241		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 4.603869893879241 | validation: 2.862411077465658]
	TIME [epoch: 27.6 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9170060345559365		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 1.9170060345559365 | validation: 1.9454523785509406]
	TIME [epoch: 27.6 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9004331000288035		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 1.9004331000288035 | validation: 2.9041877199746353]
	TIME [epoch: 27.6 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7922873531088102		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 1.7922873531088102 | validation: 1.3782121366749498]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_210.pth
	Model improved!!!
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4180970848522008		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 1.4180970848522008 | validation: 1.3345945412128242]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_211.pth
	Model improved!!!
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.253326145490809		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 1.253326145490809 | validation: 1.8604991169801282]
	TIME [epoch: 27.6 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7482307424220949		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 1.7482307424220949 | validation: 1.7033216891736342]
	TIME [epoch: 27.6 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2852649818557151		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 1.2852649818557151 | validation: 1.631878563670161]
	TIME [epoch: 27.7 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0564126394360676		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 2.0564126394360676 | validation: 2.485745894197999]
	TIME [epoch: 27.6 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6262380289982237		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 1.6262380289982237 | validation: 1.3343631449616056]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_216.pth
	Model improved!!!
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3117023709772424		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 1.3117023709772424 | validation: 2.0015312756422294]
	TIME [epoch: 27.6 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3619047741071566		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 1.3619047741071566 | validation: 2.969443390138423]
	TIME [epoch: 27.7 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6172657766360863		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 2.6172657766360863 | validation: 3.8804449524726325]
	TIME [epoch: 27.6 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1060635495530624		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 2.1060635495530624 | validation: 1.3221472191511812]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_220.pth
	Model improved!!!
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.902678750750482		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 4.902678750750482 | validation: 5.589242130478931]
	TIME [epoch: 27.6 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.331456685223387		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 6.331456685223387 | validation: 5.5747003717379595]
	TIME [epoch: 27.6 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.239992151212613		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 6.239992151212613 | validation: 5.493426230490368]
	TIME [epoch: 27.7 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.181118109375908		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 6.181118109375908 | validation: 5.46194778963238]
	TIME [epoch: 27.6 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.324586803916048		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 6.324586803916048 | validation: 5.504160358797817]
	TIME [epoch: 27.6 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.201066954303678		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 6.201066954303678 | validation: 5.400750351242057]
	TIME [epoch: 27.6 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.196067740041751		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 6.196067740041751 | validation: 5.403387679141718]
	TIME [epoch: 27.6 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.186539772307223		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 6.186539772307223 | validation: 5.43716420037455]
	TIME [epoch: 27.6 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.211285289259518		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 6.211285289259518 | validation: 5.439426115054369]
	TIME [epoch: 27.6 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.317452440832991		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 6.317452440832991 | validation: 5.7393839632827985]
	TIME [epoch: 27.6 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.304744846107937		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 6.304744846107937 | validation: 5.5177752860704254]
	TIME [epoch: 27.7 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.181117611319777		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 6.181117611319777 | validation: 5.55696045507556]
	TIME [epoch: 27.6 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.1590790072514725		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 6.1590790072514725 | validation: 5.3864845726408825]
	TIME [epoch: 27.6 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.188233335098393		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 6.188233335098393 | validation: 5.377405190036987]
	TIME [epoch: 27.6 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.15956483486381		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 6.15956483486381 | validation: 5.4263712122312215]
	TIME [epoch: 27.6 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.260942683166036		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 6.260942683166036 | validation: 5.448617957079258]
	TIME [epoch: 27.7 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.307706855880806		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 6.307706855880806 | validation: 5.3707398102801385]
	TIME [epoch: 27.6 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.283096090767922		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 6.283096090767922 | validation: 5.378007675878745]
	TIME [epoch: 27.6 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.252377055497989		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 6.252377055497989 | validation: 5.3671562231198235]
	TIME [epoch: 27.7 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.267321394672447		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 6.267321394672447 | validation: 5.888719870947892]
	TIME [epoch: 27.6 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.422371547349336		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 6.422371547349336 | validation: 5.529917819835969]
	TIME [epoch: 27.6 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.242044890682028		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 6.242044890682028 | validation: 5.713050346771227]
	TIME [epoch: 27.6 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.312476284912826		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 6.312476284912826 | validation: 5.73325358085094]
	TIME [epoch: 27.6 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.36889073814696		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 6.36889073814696 | validation: 5.457342275646073]
	TIME [epoch: 27.6 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.171837708303075		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 6.171837708303075 | validation: 5.400227462410656]
	TIME [epoch: 27.6 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.346785992193597		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 6.346785992193597 | validation: 5.723852616179695]
	TIME [epoch: 27.6 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.34111733359642		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 6.34111733359642 | validation: 5.28413190082504]
	TIME [epoch: 27.6 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.128129000055456		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 6.128129000055456 | validation: 5.301793605652671]
	TIME [epoch: 27.6 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.0986354838993275		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 6.0986354838993275 | validation: 5.393434554775581]
	TIME [epoch: 27.6 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.135150296068682		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 6.135150296068682 | validation: 5.289097409713658]
	TIME [epoch: 27.6 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.333622450494967		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 6.333622450494967 | validation: 5.345372133297844]
	TIME [epoch: 27.6 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.453276360017679		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 6.453276360017679 | validation: 5.734705995970296]
	TIME [epoch: 27.6 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.25290894190212		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 6.25290894190212 | validation: 5.737750098550621]
	TIME [epoch: 27.7 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.255712066196621		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 6.255712066196621 | validation: 5.5143270547420045]
	TIME [epoch: 27.6 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.146107052400036		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 6.146107052400036 | validation: 5.463686617058778]
	TIME [epoch: 27.6 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.225464437875552		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 6.225464437875552 | validation: 5.971934205347874]
	TIME [epoch: 27.6 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.311470510168682		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 6.311470510168682 | validation: 5.369064646440042]
	TIME [epoch: 27.6 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.043660087991318		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 6.043660087991318 | validation: 5.295319848156746]
	TIME [epoch: 27.6 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.046935930529655		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 6.046935930529655 | validation: 5.386296772228639]
	TIME [epoch: 27.6 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.2386509440857685		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 6.2386509440857685 | validation: 5.311407634898315]
	TIME [epoch: 27.6 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.070419720239263		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 6.070419720239263 | validation: 5.393924461431184]
	TIME [epoch: 27.6 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.030764943857481		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 6.030764943857481 | validation: 5.4546241508170805]
	TIME [epoch: 27.6 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.070656446976965		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 6.070656446976965 | validation: 5.472605040835613]
	TIME [epoch: 27.6 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.158258783028009		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 6.158258783028009 | validation: 5.324600225247354]
	TIME [epoch: 27.6 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.128891273477395		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 6.128891273477395 | validation: 5.276348876962811]
	TIME [epoch: 27.6 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.069917529650972		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 6.069917529650972 | validation: 5.567218508215818]
	TIME [epoch: 27.6 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.280436398065871		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 6.280436398065871 | validation: 5.3773569946316355]
	TIME [epoch: 27.6 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.360623264907507		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 6.360623264907507 | validation: 5.7967366393785085]
	TIME [epoch: 27.6 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.158379895713536		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 6.158379895713536 | validation: 5.309643473993852]
	TIME [epoch: 27.6 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.074717811116694		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 6.074717811116694 | validation: 5.3769877969317195]
	TIME [epoch: 27.6 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.069773129072295		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 6.069773129072295 | validation: 5.368264775202891]
	TIME [epoch: 27.7 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.0626463575704115		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 6.0626463575704115 | validation: 5.389557287172507]
	TIME [epoch: 27.6 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.052707890847218		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 6.052707890847218 | validation: 5.349742708390188]
	TIME [epoch: 27.7 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.1172995154159056		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 6.1172995154159056 | validation: 5.404045318322529]
	TIME [epoch: 27.6 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.061245118292092		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 6.061245118292092 | validation: 5.303795374540055]
	TIME [epoch: 27.6 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.009729981753658		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 6.009729981753658 | validation: 5.413127060939074]
	TIME [epoch: 27.6 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.114103707628518		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 6.114103707628518 | validation: 5.342876196238806]
	TIME [epoch: 27.6 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.07028907641863		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 6.07028907641863 | validation: 5.418854562222341]
	TIME [epoch: 27.6 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.163547806298123		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 6.163547806298123 | validation: 5.306154878491084]
	TIME [epoch: 27.7 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.0177172654009645		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 6.0177172654009645 | validation: 5.410398154878855]
	TIME [epoch: 27.6 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.114526213328407		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 6.114526213328407 | validation: 6.441298863808052]
	TIME [epoch: 27.6 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.924757133636418		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 6.924757133636418 | validation: 5.359116991518118]
	TIME [epoch: 27.6 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.118147847142845		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 6.118147847142845 | validation: 5.424914998041875]
	TIME [epoch: 27.6 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.071553891518659		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 6.071553891518659 | validation: 5.300654371977087]
	TIME [epoch: 27.7 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.083466768147709		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 6.083466768147709 | validation: 5.338377295097704]
	TIME [epoch: 27.6 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.03144267484382		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 6.03144267484382 | validation: 5.3238046221147695]
	TIME [epoch: 27.6 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.994653763062703		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 5.994653763062703 | validation: 5.357919533550857]
	TIME [epoch: 27.6 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.045438750840889		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 6.045438750840889 | validation: 5.381408831537672]
	TIME [epoch: 27.6 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.133097205925348		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 6.133097205925348 | validation: 5.598250846880503]
	TIME [epoch: 27.6 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.213289725640556		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 6.213289725640556 | validation: 5.488939129876346]
	TIME [epoch: 27.6 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.192412567893776		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 6.192412567893776 | validation: 5.847970361552798]
	TIME [epoch: 27.6 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.3355845780757925		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 6.3355845780757925 | validation: 5.558848212864821]
	TIME [epoch: 27.6 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.194721048852796		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 6.194721048852796 | validation: 5.602893198000627]
	TIME [epoch: 27.6 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.20227926258719		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 6.20227926258719 | validation: 5.566183678399132]
	TIME [epoch: 27.6 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.163782010482427		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 6.163782010482427 | validation: 5.685008058515697]
	TIME [epoch: 27.6 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.218392883175265		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 6.218392883175265 | validation: 5.433929500611215]
	TIME [epoch: 27.6 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.150152436745486		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 6.150152436745486 | validation: 5.547122442725501]
	TIME [epoch: 27.6 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.148924541249008		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 6.148924541249008 | validation: 5.606466280107465]
	TIME [epoch: 27.6 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.152034337963313		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 6.152034337963313 | validation: 5.6407126131408765]
	TIME [epoch: 27.6 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.178386060980877		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 6.178386060980877 | validation: 5.3513438478085344]
	TIME [epoch: 27.6 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.1448704727471615		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 6.1448704727471615 | validation: 5.399280317979056]
	TIME [epoch: 27.6 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.171776832517241		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 6.171776832517241 | validation: 5.4269192161053095]
	TIME [epoch: 27.6 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.276535304869519		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 6.276535304869519 | validation: 5.942283330654829]
	TIME [epoch: 27.6 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.276554324313988		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 6.276554324313988 | validation: 5.509071439997468]
	TIME [epoch: 27.6 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.25027646841027		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 6.25027646841027 | validation: 5.569017274567389]
	TIME [epoch: 27.6 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.7595920462366905		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 6.7595920462366905 | validation: 6.056613894913811]
	TIME [epoch: 27.6 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.891300439500123		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 6.891300439500123 | validation: 5.873553131670015]
	TIME [epoch: 27.6 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.845887463204934		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 6.845887463204934 | validation: 5.853041114727944]
	TIME [epoch: 27.7 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.903199834832328		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 6.903199834832328 | validation: 5.852981822930729]
	TIME [epoch: 27.6 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.7625130504041575		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 6.7625130504041575 | validation: 6.033892885233479]
	TIME [epoch: 27.7 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.7717391242204705		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 6.7717391242204705 | validation: 5.862094754239384]
	TIME [epoch: 27.6 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.675510509050265		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 6.675510509050265 | validation: 6.104654699737575]
	TIME [epoch: 27.6 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.844480097779665		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 6.844480097779665 | validation: 5.913080422611325]
	TIME [epoch: 27.6 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.8216255281246845		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 6.8216255281246845 | validation: 5.847270206808353]
	TIME [epoch: 27.6 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.7456675111763955		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 6.7456675111763955 | validation: 5.896992715951415]
	TIME [epoch: 27.6 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.839452568792525		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 6.839452568792525 | validation: 5.820500395002232]
	TIME [epoch: 27.7 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.812199459534949		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 6.812199459534949 | validation: 5.905646875451591]
	TIME [epoch: 27.6 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.782582802943975		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 6.782582802943975 | validation: 5.794676379748589]
	TIME [epoch: 27.7 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.673415572934567		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 6.673415572934567 | validation: 5.92748243722599]
	TIME [epoch: 27.6 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.874984638648557		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 6.874984638648557 | validation: 6.285952816069759]
	TIME [epoch: 27.7 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.951581740382719		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 6.951581740382719 | validation: 6.097154197436928]
	TIME [epoch: 27.6 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.884355545671301		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 6.884355545671301 | validation: 6.014809181331684]
	TIME [epoch: 27.6 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.8729224271473734		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 6.8729224271473734 | validation: 6.0625391658520424]
	TIME [epoch: 27.6 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.928622713539168		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 6.928622713539168 | validation: 6.10677438221597]
	TIME [epoch: 27.6 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.932631924385085		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 6.932631924385085 | validation: 6.06157273066052]
	TIME [epoch: 27.6 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.8932821559133055		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 6.8932821559133055 | validation: 6.067488382172716]
	TIME [epoch: 27.7 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.8639463242625105		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 6.8639463242625105 | validation: 6.017552912352684]
	TIME [epoch: 27.7 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.94034427790354		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 6.94034427790354 | validation: 6.007602413810537]
	TIME [epoch: 27.7 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.897051772504321		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 6.897051772504321 | validation: 5.9712546046012545]
	TIME [epoch: 27.6 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.853301018688228		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 6.853301018688228 | validation: 6.101122110640647]
	TIME [epoch: 27.7 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.897128817763653		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 6.897128817763653 | validation: 6.094070181934256]
	TIME [epoch: 27.7 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.913429877522605		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 6.913429877522605 | validation: 6.051479455337021]
	TIME [epoch: 27.6 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.866057036353725		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 6.866057036353725 | validation: 6.157435280289972]
	TIME [epoch: 27.7 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.887181874811722		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 6.887181874811722 | validation: 5.9083305507831145]
	TIME [epoch: 27.6 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.877116273261888		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 6.877116273261888 | validation: 6.094829857842682]
	TIME [epoch: 27.7 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.854180135677139		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 6.854180135677139 | validation: 6.0306784667144875]
	TIME [epoch: 27.7 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.888389421333253		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 6.888389421333253 | validation: 6.124719196853325]
	TIME [epoch: 27.6 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.8745721288082		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 6.8745721288082 | validation: 6.022046000111475]
	TIME [epoch: 27.6 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.862734753117559		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 6.862734753117559 | validation: 5.996463501808864]
	TIME [epoch: 27.6 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.857461124802561		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 6.857461124802561 | validation: 6.11383732315398]
	TIME [epoch: 27.7 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.878517824883608		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 6.878517824883608 | validation: 6.136357767644]
	TIME [epoch: 27.6 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.955715809937909		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 6.955715809937909 | validation: 6.108673953050152]
	TIME [epoch: 27.6 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.8421697633013965		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 6.8421697633013965 | validation: 5.995799434606306]
	TIME [epoch: 27.6 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.853294410041695		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 6.853294410041695 | validation: 6.086662427481943]
	TIME [epoch: 27.6 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.919742599210929		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 6.919742599210929 | validation: 6.073942864197006]
	TIME [epoch: 27.6 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.831354021144		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 6.831354021144 | validation: 6.1366288945638985]
	TIME [epoch: 27.6 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.891863142220769		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 6.891863142220769 | validation: 6.038936039900343]
	TIME [epoch: 27.6 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.87327278795		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 6.87327278795 | validation: 6.066190857654433]
	TIME [epoch: 27.7 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.873150878168795		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 6.873150878168795 | validation: 6.091081233576005]
	TIME [epoch: 27.6 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.857453171287008		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 6.857453171287008 | validation: 6.237964323167461]
	TIME [epoch: 27.6 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.882515498214959		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 6.882515498214959 | validation: 5.946963348322998]
	TIME [epoch: 27.6 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.850209375314799		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 6.850209375314799 | validation: 6.009851687177296]
	TIME [epoch: 27.6 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.831485005117165		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 6.831485005117165 | validation: 6.004016093486669]
	TIME [epoch: 27.6 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.905452690173493		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 6.905452690173493 | validation: 5.982156968272581]
	TIME [epoch: 27.6 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.91639519570501		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 6.91639519570501 | validation: 5.87055806061353]
	TIME [epoch: 27.6 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.807635149019078		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 6.807635149019078 | validation: 5.865514060928586]
	TIME [epoch: 27.6 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.924199433236954		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 6.924199433236954 | validation: 6.257882349966019]
	TIME [epoch: 27.6 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.688434571349207		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 6.688434571349207 | validation: 5.773791692945467]
	TIME [epoch: 27.7 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.607288974565305		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 6.607288974565305 | validation: 5.848512963860576]
	TIME [epoch: 27.6 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.586727982871828		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 6.586727982871828 | validation: 5.897081759360725]
	TIME [epoch: 27.7 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.65127161048399		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 6.65127161048399 | validation: 5.822455186780577]
	TIME [epoch: 27.6 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.664922967527694		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 6.664922967527694 | validation: 5.706113323955509]
	TIME [epoch: 27.7 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.631251201882257		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 6.631251201882257 | validation: 5.773717672922998]
	TIME [epoch: 27.6 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.701249293732822		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 6.701249293732822 | validation: 5.708125635657923]
	TIME [epoch: 27.6 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.648722223087516		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 6.648722223087516 | validation: 5.719204806724543]
	TIME [epoch: 27.6 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.710205945895328		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 6.710205945895328 | validation: 5.792714746449347]
	TIME [epoch: 27.7 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.710781755097808		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 6.710781755097808 | validation: 5.831817246212843]
	TIME [epoch: 27.6 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.707666352632749		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 6.707666352632749 | validation: 5.836883382971518]
	TIME [epoch: 27.7 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.843099406310675		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 6.843099406310675 | validation: 5.938662228945964]
	TIME [epoch: 27.6 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.789769285020579		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 6.789769285020579 | validation: 6.046040199026739]
	TIME [epoch: 27.6 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.849822130621418		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 6.849822130621418 | validation: 5.963053116955366]
	TIME [epoch: 27.7 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.867218606539108		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 6.867218606539108 | validation: 6.065062874488151]
	TIME [epoch: 27.7 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.8702161546525025		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 6.8702161546525025 | validation: 5.8727548886231515]
	TIME [epoch: 27.6 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.882291145991898		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 6.882291145991898 | validation: 5.847038986881525]
	TIME [epoch: 27.6 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.8088157235137485		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 6.8088157235137485 | validation: 5.923595932867552]
	TIME [epoch: 27.6 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.813762515654602		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 6.813762515654602 | validation: 5.875106648968961]
	TIME [epoch: 27.6 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.8965410989716736		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 6.8965410989716736 | validation: 5.8485027620484145]
	TIME [epoch: 27.7 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.831912557173515		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 6.831912557173515 | validation: 5.889951816042254]
	TIME [epoch: 27.6 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.790550000808986		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 6.790550000808986 | validation: 5.934620261396197]
	TIME [epoch: 27.6 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.7805479410910685		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 6.7805479410910685 | validation: 5.883428781887995]
	TIME [epoch: 27.6 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.932020238038387		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 6.932020238038387 | validation: 5.955066997720653]
	TIME [epoch: 27.7 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.783054789640501		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 6.783054789640501 | validation: 5.862726830485673]
	TIME [epoch: 27.7 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.759179562564295		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 6.759179562564295 | validation: 5.872499434545751]
	TIME [epoch: 27.6 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.832773936754352		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 6.832773936754352 | validation: 5.950081927134229]
	TIME [epoch: 27.6 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.8086817001312685		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 6.8086817001312685 | validation: 5.829880275423477]
	TIME [epoch: 27.6 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.787361029262439		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 6.787361029262439 | validation: 5.909270451298007]
	TIME [epoch: 27.7 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.768728474895317		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 6.768728474895317 | validation: 6.000804872840359]
	TIME [epoch: 27.6 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.8674535038864155		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 6.8674535038864155 | validation: 5.793639531253121]
	TIME [epoch: 27.7 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.778789807457789		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 6.778789807457789 | validation: 5.952084355440489]
	TIME [epoch: 27.7 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.876780705305646		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 6.876780705305646 | validation: 5.858543165389871]
	TIME [epoch: 27.7 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.547759772461191		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 6.547759772461191 | validation: 5.657760625060619]
	TIME [epoch: 27.7 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.212469057121216		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 6.212469057121216 | validation: 5.694010591553502]
	TIME [epoch: 27.7 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.156087973764955		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 6.156087973764955 | validation: 5.571678847753593]
	TIME [epoch: 27.6 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.678486939829836		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 6.678486939829836 | validation: 6.165552566207435]
	TIME [epoch: 27.6 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.902566988573294		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 6.902566988573294 | validation: 6.029798969258597]
	TIME [epoch: 27.6 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.26857784794786		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 6.26857784794786 | validation: 5.2968860823019]
	TIME [epoch: 27.7 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.878948301249414		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 5.878948301249414 | validation: 5.590363707364588]
	TIME [epoch: 27.7 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.064032209470412		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 6.064032209470412 | validation: 5.728172351901858]
	TIME [epoch: 27.7 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.296683758284206		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 6.296683758284206 | validation: 5.93905959368155]
	TIME [epoch: 27.6 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.199348554044497		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 6.199348554044497 | validation: 5.370295692088503]
	TIME [epoch: 27.7 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.99231471687689		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 5.99231471687689 | validation: 5.331994723897635]
	TIME [epoch: 27.6 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.978662395867347		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 5.978662395867347 | validation: 5.423245257478438]
	TIME [epoch: 27.6 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.141834359631952		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 6.141834359631952 | validation: 5.7023956043761155]
	TIME [epoch: 27.7 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.84079300456562		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 6.84079300456562 | validation: 5.804449967178478]
	TIME [epoch: 27.6 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.671994574446968		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 6.671994574446968 | validation: 5.995293670319311]
	TIME [epoch: 27.7 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.855709546479902		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 6.855709546479902 | validation: 5.867315701780601]
	TIME [epoch: 27.7 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.802731169507203		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 6.802731169507203 | validation: 5.993543995109214]
	TIME [epoch: 27.7 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.866428441120291		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 6.866428441120291 | validation: 5.9235361568404965]
	TIME [epoch: 27.7 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.8016631378732955		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 6.8016631378732955 | validation: 5.885970646577958]
	TIME [epoch: 27.6 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.804076659968075		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 6.804076659968075 | validation: 5.964305433175626]
	TIME [epoch: 27.7 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.750656261502733		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 6.750656261502733 | validation: 5.779018642243041]
	TIME [epoch: 27.7 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.6536463963817996		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 6.6536463963817996 | validation: 5.853501680300797]
	TIME [epoch: 27.7 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.755453462160633		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 6.755453462160633 | validation: 5.712982024247433]
	TIME [epoch: 27.7 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.613313794364989		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 6.613313794364989 | validation: 5.727127681644004]
	TIME [epoch: 27.6 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.6545381451812515		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 6.6545381451812515 | validation: 5.810691200610377]
	TIME [epoch: 27.7 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.628994190287273		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 6.628994190287273 | validation: 5.701741637276803]
	TIME [epoch: 27.7 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.484390306540247		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 6.484390306540247 | validation: 5.643368723477416]
	TIME [epoch: 27.6 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.529618100604686		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 6.529618100604686 | validation: 5.670094433630111]
	TIME [epoch: 27.7 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.557711320101564		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 6.557711320101564 | validation: 5.670894874675086]
	TIME [epoch: 27.6 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.580550839824501		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 6.580550839824501 | validation: 6.303987927791561]
	TIME [epoch: 27.7 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.987483121970337		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 6.987483121970337 | validation: 6.525046626389218]
	TIME [epoch: 27.6 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.817882129065751		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 6.817882129065751 | validation: 5.960628691085727]
	TIME [epoch: 27.7 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.351396298102403		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 6.351396298102403 | validation: 5.373801088820394]
	TIME [epoch: 27.7 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.102307216729085		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 6.102307216729085 | validation: 5.342315984777761]
	TIME [epoch: 27.7 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.056352683059787		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 6.056352683059787 | validation: 5.328531817906985]
	TIME [epoch: 27.7 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.0421670423068745		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 6.0421670423068745 | validation: 5.27569492341843]
	TIME [epoch: 27.7 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.006249826253181		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 6.006249826253181 | validation: 5.340846673485321]
	TIME [epoch: 27.7 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.122579674991168		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 6.122579674991168 | validation: 5.408100056114655]
	TIME [epoch: 27.7 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.976538486946002		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 5.976538486946002 | validation: 5.36692628348585]
	TIME [epoch: 27.7 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.1352688318383946		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 6.1352688318383946 | validation: 5.380337500365811]
	TIME [epoch: 27.6 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.12053487293651		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 6.12053487293651 | validation: 5.951404706209378]
	TIME [epoch: 27.6 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.6685272454880895		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 6.6685272454880895 | validation: 5.618341958061799]
	TIME [epoch: 27.6 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.332852323237831		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 6.332852323237831 | validation: 5.369940630098642]
	TIME [epoch: 27.6 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.237562532077942		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 6.237562532077942 | validation: 5.519911787327346]
	TIME [epoch: 27.6 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.278449523866857		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 6.278449523866857 | validation: 5.471573916172599]
	TIME [epoch: 27.7 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.2686644962598095		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 6.2686644962598095 | validation: 5.80870245422998]
	TIME [epoch: 27.7 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.5302286793748685		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 6.5302286793748685 | validation: 5.7170417563384]
	TIME [epoch: 27.7 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.530854581023677		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 6.530854581023677 | validation: 5.636561227822195]
	TIME [epoch: 27.7 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.49834800023009		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 6.49834800023009 | validation: 5.624222781145813]
	TIME [epoch: 27.7 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.3881713965837665		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 6.3881713965837665 | validation: 5.728963592265114]
	TIME [epoch: 27.7 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.655322755597869		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 6.655322755597869 | validation: 5.660228874445757]
	TIME [epoch: 27.6 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.589646922271545		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 6.589646922271545 | validation: 5.779748874697264]
	TIME [epoch: 27.6 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.595887455133011		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 6.595887455133011 | validation: 5.635287464342343]
	TIME [epoch: 27.7 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.554270088578411		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 6.554270088578411 | validation: 5.6964840952419715]
	TIME [epoch: 27.6 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.677019409393464		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 6.677019409393464 | validation: 5.906786491243623]
	TIME [epoch: 27.7 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.67679697663236		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 6.67679697663236 | validation: 5.623257228476809]
	TIME [epoch: 27.6 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.635272521821458		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 6.635272521821458 | validation: 6.124824169977241]
	TIME [epoch: 27.7 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.7059711472330115		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 6.7059711472330115 | validation: 5.734670747219009]
	TIME [epoch: 27.7 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.625459362507976		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 6.625459362507976 | validation: 6.068839608107018]
	TIME [epoch: 27.7 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.877349934893893		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 6.877349934893893 | validation: 6.00800562943326]
	TIME [epoch: 27.6 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.8868769254748825		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 6.8868769254748825 | validation: 6.034202503595518]
	TIME [epoch: 27.6 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.843933811256999		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 6.843933811256999 | validation: 5.934103607877989]
	TIME [epoch: 27.6 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.7983703015159165		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 6.7983703015159165 | validation: 5.999209983629076]
	TIME [epoch: 27.7 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.820864948277831		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 6.820864948277831 | validation: 6.067520947971702]
	TIME [epoch: 27.6 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.874187331763185		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 6.874187331763185 | validation: 6.138230051346907]
	TIME [epoch: 27.6 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.889956737949854		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 6.889956737949854 | validation: 6.109569756571188]
	TIME [epoch: 27.6 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.924902246205226		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 6.924902246205226 | validation: 6.094532588620764]
	TIME [epoch: 27.6 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.891671901675752		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 6.891671901675752 | validation: 6.022423599483451]
	TIME [epoch: 27.7 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.888612920266026		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 6.888612920266026 | validation: 6.129881978028672]
	TIME [epoch: 27.6 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.833927435811592		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 6.833927435811592 | validation: 5.9311670554331]
	TIME [epoch: 27.7 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.815519315572959		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 6.815519315572959 | validation: 5.880108020977453]
	TIME [epoch: 27.6 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.730111407998539		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 6.730111407998539 | validation: 5.740152458189457]
	TIME [epoch: 27.6 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.797010595878879		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 6.797010595878879 | validation: 5.932154236359168]
	TIME [epoch: 27.6 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.906519628287361		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 6.906519628287361 | validation: 6.1528164745714164]
	TIME [epoch: 27.6 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.028356626773671		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 7.028356626773671 | validation: 6.086714611851328]
	TIME [epoch: 27.7 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.999817208155506		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 6.999817208155506 | validation: 6.071659981458786]
	TIME [epoch: 27.6 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.97897676109443		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 6.97897676109443 | validation: 6.0733565345438585]
	TIME [epoch: 27.6 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.988628726461939		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 6.988628726461939 | validation: 6.087726331936949]
	TIME [epoch: 27.6 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.978283619952893		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 6.978283619952893 | validation: 6.070932587435395]
	TIME [epoch: 27.6 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.870456524265413		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 6.870456524265413 | validation: 5.882253798258514]
	TIME [epoch: 27.6 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.854871820251528		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 6.854871820251528 | validation: 6.042548266266342]
	TIME [epoch: 27.6 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.844967954208724		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 6.844967954208724 | validation: 5.9657123163423895]
	TIME [epoch: 27.7 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.885001786396206		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 6.885001786396206 | validation: 5.91957765354367]
	TIME [epoch: 27.6 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.82113971600676		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 6.82113971600676 | validation: 5.8820486782979176]
	TIME [epoch: 27.6 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.801584660357227		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 6.801584660357227 | validation: 5.835227320079373]
	TIME [epoch: 27.6 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.75599292032107		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 6.75599292032107 | validation: 5.8046290936033085]
	TIME [epoch: 27.6 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.765992013945482		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 6.765992013945482 | validation: 5.889079249587489]
	TIME [epoch: 27.6 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.706152120913343		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 6.706152120913343 | validation: 5.920580308555055]
	TIME [epoch: 27.7 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.860961071426304		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 6.860961071426304 | validation: 6.1232933872860125]
	TIME [epoch: 27.6 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.905298996924328		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 6.905298996924328 | validation: 5.9960729351544275]
	TIME [epoch: 27.7 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.852245939274855		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 6.852245939274855 | validation: 5.868466504288569]
	TIME [epoch: 27.6 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.781100689256133		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 6.781100689256133 | validation: 5.829085616373657]
	TIME [epoch: 27.7 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.745213815773996		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 6.745213815773996 | validation: 5.871931779172843]
	TIME [epoch: 27.7 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.869725966527244		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 6.869725966527244 | validation: 6.026624695693695]
	TIME [epoch: 27.7 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.919460151911596		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 6.919460151911596 | validation: 6.003781860867389]
	TIME [epoch: 27.6 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.960897191477138		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 6.960897191477138 | validation: 6.138505479325884]
	TIME [epoch: 27.7 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.941464375568597		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 6.941464375568597 | validation: 6.3112126701266655]
	TIME [epoch: 27.7 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.023902939439326		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 7.023902939439326 | validation: 6.050254505261546]
	TIME [epoch: 27.7 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.918471973984773		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 6.918471973984773 | validation: 6.015499461595084]
	TIME [epoch: 27.7 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.9279518862449905		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 6.9279518862449905 | validation: 5.967184108676878]
	TIME [epoch: 27.7 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.866019628507139		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 6.866019628507139 | validation: 5.758796782517359]
	TIME [epoch: 27.7 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.500551027783342		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 6.500551027783342 | validation: 5.534356033344706]
	TIME [epoch: 27.7 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.349223435673011		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 6.349223435673011 | validation: 5.431221968381624]
	TIME [epoch: 27.7 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.297773065357664		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 6.297773065357664 | validation: 5.445302756518531]
	TIME [epoch: 27.7 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.250299145527489		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 6.250299145527489 | validation: 5.356173057061915]
	TIME [epoch: 27.7 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.261772525887666		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 6.261772525887666 | validation: 5.351624203392009]
	TIME [epoch: 27.6 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.243273754294804		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 6.243273754294804 | validation: 5.6798711711714285]
	TIME [epoch: 27.6 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.407298569696926		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 6.407298569696926 | validation: 6.01260332871751]
	TIME [epoch: 27.6 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.887121461400462		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 5.887121461400462 | validation: 4.873479507572407]
	TIME [epoch: 27.6 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.211896686258105		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 5.211896686258105 | validation: 4.280343591769248]
	TIME [epoch: 27.7 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.480934753557855		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 4.480934753557855 | validation: 3.8112345673394294]
	TIME [epoch: 27.6 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.022094050385822		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 4.022094050385822 | validation: 3.3985504775573863]
	TIME [epoch: 27.6 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.256666592966708		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 3.256666592966708 | validation: 2.8146186441214205]
	TIME [epoch: 27.6 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7971265320275105		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 2.7971265320275105 | validation: 2.8013610411245122]
	TIME [epoch: 27.6 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5664459063003746		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 2.5664459063003746 | validation: 2.3693409898567923]
	TIME [epoch: 27.7 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2638844726145377		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 2.2638844726145377 | validation: 2.073549178802344]
	TIME [epoch: 27.7 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9436329485773989		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 1.9436329485773989 | validation: 1.975637983521748]
	TIME [epoch: 27.7 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7057854426117696		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 1.7057854426117696 | validation: 1.6211668995950737]
	TIME [epoch: 27.7 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3563460202333244		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 1.3563460202333244 | validation: 1.3578802173893896]
	TIME [epoch: 27.7 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.414749092510326		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 1.414749092510326 | validation: 1.3251484408321192]
	TIME [epoch: 27.7 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1658301048126865		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 1.1658301048126865 | validation: 1.1889725199483945]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_511.pth
	Model improved!!!
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.13752586754192		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 1.13752586754192 | validation: 1.2519325680628988]
	TIME [epoch: 27.6 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0597353992929401		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 1.0597353992929401 | validation: 1.10654939060454]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_513.pth
	Model improved!!!
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.256504132676966		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 1.256504132676966 | validation: 2.411171897025469]
	TIME [epoch: 27.7 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5616716255154408		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 1.5616716255154408 | validation: 1.173532571227297]
	TIME [epoch: 27.7 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0505807420493127		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 1.0505807420493127 | validation: 1.0429863214319068]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_516.pth
	Model improved!!!
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0113302770776997		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 1.0113302770776997 | validation: 1.4995042380705579]
	TIME [epoch: 27.8 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1344092818603344		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 1.1344092818603344 | validation: 1.421964590598185]
	TIME [epoch: 27.7 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0043711686765864		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 1.0043711686765864 | validation: 1.0800919952162107]
	TIME [epoch: 27.7 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0643512214982809		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 1.0643512214982809 | validation: 1.0114518689265812]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_520.pth
	Model improved!!!
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9777468169806333		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.9777468169806333 | validation: 1.6472614258657774]
	TIME [epoch: 27.7 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2125697646470046		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 1.2125697646470046 | validation: 1.04413146791478]
	TIME [epoch: 27.7 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9238716238464889		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.9238716238464889 | validation: 1.1550942597801723]
	TIME [epoch: 27.8 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8876098838925272		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.8876098838925272 | validation: 0.9662427791322248]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_524.pth
	Model improved!!!
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.951137908645877		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.951137908645877 | validation: 0.9652461546412459]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_525.pth
	Model improved!!!
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9142115079414673		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.9142115079414673 | validation: 1.238650648576361]
	TIME [epoch: 27.7 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8732484736681643		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.8732484736681643 | validation: 1.326791398550714]
	TIME [epoch: 27.8 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0001243344990651		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 1.0001243344990651 | validation: 1.0794851484959178]
	TIME [epoch: 27.8 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9455337062900506		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.9455337062900506 | validation: 0.9183719240816206]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_529.pth
	Model improved!!!
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8915668850054355		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.8915668850054355 | validation: 0.9320221492397711]
	TIME [epoch: 27.7 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9456104146409455		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.9456104146409455 | validation: 0.9292284439964877]
	TIME [epoch: 27.7 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1034537171343966		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 1.1034537171343966 | validation: 1.7210689114214637]
	TIME [epoch: 27.7 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1315103679786527		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 1.1315103679786527 | validation: 0.917319189916247]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_533.pth
	Model improved!!!
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8763880412391826		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.8763880412391826 | validation: 0.9557986984119025]
	TIME [epoch: 27.7 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8135709077426143		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.8135709077426143 | validation: 0.8916222302321771]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_535.pth
	Model improved!!!
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8563384493825961		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.8563384493825961 | validation: 0.8621341079756863]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_536.pth
	Model improved!!!
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8083344138585851		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.8083344138585851 | validation: 0.9920019519966218]
	TIME [epoch: 27.7 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1583343113964708		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 1.1583343113964708 | validation: 0.9834748768063537]
	TIME [epoch: 27.7 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8303061440665336		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.8303061440665336 | validation: 0.8516144747519782]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_539.pth
	Model improved!!!
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7902071657996805		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.7902071657996805 | validation: 1.1906397279208014]
	TIME [epoch: 27.7 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8858213895032181		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.8858213895032181 | validation: 0.8070956126016421]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_541.pth
	Model improved!!!
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7592839767723562		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.7592839767723562 | validation: 0.8159160979321596]
	TIME [epoch: 27.7 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7708035335846033		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.7708035335846033 | validation: 1.0107374526026742]
	TIME [epoch: 27.7 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8867796285633098		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.8867796285633098 | validation: 1.0297646856531748]
	TIME [epoch: 27.7 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8113182998303616		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.8113182998303616 | validation: 1.1101929139741435]
	TIME [epoch: 27.7 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8403653859705589		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.8403653859705589 | validation: 0.8927559695577512]
	TIME [epoch: 27.7 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7650247637904964		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.7650247637904964 | validation: 0.9649833528653503]
	TIME [epoch: 27.7 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7708926825773739		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.7708926825773739 | validation: 0.8021816509193497]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_548.pth
	Model improved!!!
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7787369562282485		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.7787369562282485 | validation: 1.201077140195394]
	TIME [epoch: 27.7 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7956769698843131		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.7956769698843131 | validation: 0.9534433658896402]
	TIME [epoch: 27.7 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7615116542369582		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.7615116542369582 | validation: 1.1548202474368028]
	TIME [epoch: 27.7 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8587383478296924		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.8587383478296924 | validation: 0.8302851384237565]
	TIME [epoch: 27.7 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7790891424552833		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.7790891424552833 | validation: 0.8539182779734452]
	TIME [epoch: 27.7 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7503954836138098		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.7503954836138098 | validation: 0.8377788763941927]
	TIME [epoch: 27.7 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7472337352787194		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.7472337352787194 | validation: 1.1100960392388033]
	TIME [epoch: 27.7 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.116179407144509		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 1.116179407144509 | validation: 0.9216964345920338]
	TIME [epoch: 27.7 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9500703504341488		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.9500703504341488 | validation: 0.9595601519507088]
	TIME [epoch: 27.7 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8041352272631663		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.8041352272631663 | validation: 0.9969837927308638]
	TIME [epoch: 27.7 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8108006421220864		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.8108006421220864 | validation: 0.8800433216637213]
	TIME [epoch: 27.7 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.806679950301102		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.806679950301102 | validation: 0.9186587606655278]
	TIME [epoch: 27.7 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6755294446792867		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.6755294446792867 | validation: 0.77275162194229]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_561.pth
	Model improved!!!
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6766365572192485		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.6766365572192485 | validation: 0.8806497628049202]
	TIME [epoch: 27.7 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8565560831323713		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.8565560831323713 | validation: 0.8918941140909803]
	TIME [epoch: 27.8 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7123959402456533		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.7123959402456533 | validation: 0.7422409128360772]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_564.pth
	Model improved!!!
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6574617084815098		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.6574617084815098 | validation: 0.8248559453728994]
	TIME [epoch: 27.7 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6776323487833744		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.6776323487833744 | validation: 0.716787362603834]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_566.pth
	Model improved!!!
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9525964481951341		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.9525964481951341 | validation: 0.6976250505723494]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_567.pth
	Model improved!!!
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.614505497322517		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.614505497322517 | validation: 0.7782991070308807]
	TIME [epoch: 27.7 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6677664316785679		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.6677664316785679 | validation: 0.7291706372646902]
	TIME [epoch: 27.7 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6647199407546267		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.6647199407546267 | validation: 0.7471767377287154]
	TIME [epoch: 27.7 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7502052598338397		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.7502052598338397 | validation: 1.062894883599901]
	TIME [epoch: 27.7 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8434298563140501		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.8434298563140501 | validation: 0.7421628715875472]
	TIME [epoch: 27.7 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7060611606881148		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.7060611606881148 | validation: 0.7569992521235926]
	TIME [epoch: 27.7 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7258394672851319		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.7258394672851319 | validation: 1.0087409064032757]
	TIME [epoch: 27.7 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7593713080684101		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.7593713080684101 | validation: 0.9101354068999301]
	TIME [epoch: 27.8 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.793410663906594		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.793410663906594 | validation: 1.148124596104941]
	TIME [epoch: 27.7 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.765800357345101		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.765800357345101 | validation: 0.8313395224325746]
	TIME [epoch: 27.7 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7324002684870478		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.7324002684870478 | validation: 0.8673563527788983]
	TIME [epoch: 27.7 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7584830186987581		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.7584830186987581 | validation: 0.8256459165161356]
	TIME [epoch: 27.7 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8638310548975423		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.8638310548975423 | validation: 0.7489800635201167]
	TIME [epoch: 27.7 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7773352171824488		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.7773352171824488 | validation: 0.7019444921784798]
	TIME [epoch: 27.7 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6899986547633944		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.6899986547633944 | validation: 0.8625236758340065]
	TIME [epoch: 27.7 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7742533268702086		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.7742533268702086 | validation: 0.7489685985847693]
	TIME [epoch: 27.7 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6914869438898765		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.6914869438898765 | validation: 0.769694719808694]
	TIME [epoch: 27.7 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.072378049145848		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 1.072378049145848 | validation: 0.7236789304376459]
	TIME [epoch: 27.7 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7708512714699463		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.7708512714699463 | validation: 0.9087973186153593]
	TIME [epoch: 27.7 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6665249892160829		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.6665249892160829 | validation: 0.6782685499373357]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_587.pth
	Model improved!!!
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7051597469803423		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.7051597469803423 | validation: 0.7441287435714539]
	TIME [epoch: 27.8 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6536256149204305		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.6536256149204305 | validation: 0.7503647289147173]
	TIME [epoch: 27.7 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6860014067412223		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.6860014067412223 | validation: 0.7939982376970361]
	TIME [epoch: 27.8 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6977758360056182		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.6977758360056182 | validation: 1.0168646240074595]
	TIME [epoch: 27.7 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7159075419501779		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.7159075419501779 | validation: 0.6966850273602685]
	TIME [epoch: 27.7 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6676288020475586		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.6676288020475586 | validation: 0.7117004111266542]
	TIME [epoch: 27.7 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9313988437680658		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.9313988437680658 | validation: 1.1931793737721788]
	TIME [epoch: 27.7 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8408147975216385		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.8408147975216385 | validation: 0.8176199503696325]
	TIME [epoch: 27.7 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6787402221024034		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.6787402221024034 | validation: 1.1091630565298072]
	TIME [epoch: 27.7 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9053627121274497		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.9053627121274497 | validation: 0.8279443263210631]
	TIME [epoch: 27.7 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6795044502302784		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.6795044502302784 | validation: 0.8985170699998932]
	TIME [epoch: 27.7 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8651160754986825		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.8651160754986825 | validation: 0.7695222710658173]
	TIME [epoch: 27.7 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6588416623018862		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.6588416623018862 | validation: 0.697668481865316]
	TIME [epoch: 27.7 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7127488821484307		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.7127488821484307 | validation: 0.6741802587300693]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_601.pth
	Model improved!!!
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6911433793208296		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.6911433793208296 | validation: 0.6892875234818832]
	TIME [epoch: 27.7 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6379876029982229		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.6379876029982229 | validation: 0.8463427407111259]
	TIME [epoch: 27.8 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6800451983051061		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.6800451983051061 | validation: 0.6423984862516351]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_604.pth
	Model improved!!!
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8370011671178088		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.8370011671178088 | validation: 0.8461459783151162]
	TIME [epoch: 27.8 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6872067462051878		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.6872067462051878 | validation: 0.7363041731796613]
	TIME [epoch: 27.8 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6158013462280407		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.6158013462280407 | validation: 0.7181944761845414]
	TIME [epoch: 27.8 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7431374001838528		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.7431374001838528 | validation: 0.7017487318985881]
	TIME [epoch: 27.8 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6054677727825236		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.6054677727825236 | validation: 0.8750781292323171]
	TIME [epoch: 27.7 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7532373773191487		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.7532373773191487 | validation: 1.0066520089194015]
	TIME [epoch: 27.8 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7141211184193031		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.7141211184193031 | validation: 0.8183420328931569]
	TIME [epoch: 27.8 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7931852979041185		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.7931852979041185 | validation: 0.7097852583470757]
	TIME [epoch: 27.7 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6013802996952126		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.6013802996952126 | validation: 1.1286705747556356]
	TIME [epoch: 27.8 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3340236341516045		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 1.3340236341516045 | validation: 0.6678237545281417]
	TIME [epoch: 27.7 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6185379287218544		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.6185379287218544 | validation: 0.797554526385616]
	TIME [epoch: 27.8 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6972724899264807		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.6972724899264807 | validation: 0.7961745269945365]
	TIME [epoch: 27.8 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6560263220211069		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.6560263220211069 | validation: 0.9116255453482396]
	TIME [epoch: 27.7 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6585532933152696		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.6585532933152696 | validation: 0.7123881284528707]
	TIME [epoch: 27.8 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5918125655886821		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.5918125655886821 | validation: 0.7810743252028679]
	TIME [epoch: 27.8 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7075326722320754		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.7075326722320754 | validation: 0.6284169569355714]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_620.pth
	Model improved!!!
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7204332300517479		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.7204332300517479 | validation: 0.8354344753180425]
	TIME [epoch: 27.7 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6273753861443161		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.6273753861443161 | validation: 0.6452967473884503]
	TIME [epoch: 27.7 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5861759095128363		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.5861759095128363 | validation: 0.7566221525929813]
	TIME [epoch: 27.7 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6189162205932082		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.6189162205932082 | validation: 0.749585449129674]
	TIME [epoch: 27.7 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6176067273292358		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.6176067273292358 | validation: 0.6352532123423354]
	TIME [epoch: 27.7 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.599064421287366		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.599064421287366 | validation: 0.6519350270586094]
	TIME [epoch: 27.8 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6084940845990974		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.6084940845990974 | validation: 0.7758365199786877]
	TIME [epoch: 27.7 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7804250411633802		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.7804250411633802 | validation: 0.946504478285475]
	TIME [epoch: 27.7 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6960870881567597		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.6960870881567597 | validation: 0.6143240880259773]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_629.pth
	Model improved!!!
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.538646266996381		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.538646266996381 | validation: 0.9590973563681664]
	TIME [epoch: 27.7 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6389827763112687		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.6389827763112687 | validation: 0.6559793498497468]
	TIME [epoch: 27.7 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6490696950064814		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.6490696950064814 | validation: 0.7291453359695504]
	TIME [epoch: 27.8 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8160279137933377		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.8160279137933377 | validation: 0.8415387982986724]
	TIME [epoch: 27.8 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6507316233780247		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.6507316233780247 | validation: 0.6342411078225386]
	TIME [epoch: 27.7 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.65710415720097		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.65710415720097 | validation: 0.9841685288852287]
	TIME [epoch: 27.7 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8184746075536495		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.8184746075536495 | validation: 0.8768523155888533]
	TIME [epoch: 27.8 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6231177280221031		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.6231177280221031 | validation: 0.6295114984467566]
	TIME [epoch: 27.7 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6049965472834054		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.6049965472834054 | validation: 0.7448044824118597]
	TIME [epoch: 27.8 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6523163071747977		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.6523163071747977 | validation: 0.9426227681423732]
	TIME [epoch: 27.7 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.645146553316559		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.645146553316559 | validation: 0.7366851769234535]
	TIME [epoch: 27.7 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6527107686582102		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.6527107686582102 | validation: 0.745962860285109]
	TIME [epoch: 27.7 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6251208820714341		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.6251208820714341 | validation: 0.6907202047748768]
	TIME [epoch: 27.7 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5694686500224736		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.5694686500224736 | validation: 0.6353890352694529]
	TIME [epoch: 27.7 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5542584199663263		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.5542584199663263 | validation: 0.9037029346383275]
	TIME [epoch: 27.8 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.607468712384446		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.607468712384446 | validation: 0.6434977416681446]
	TIME [epoch: 27.7 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.733785400581592		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.733785400581592 | validation: 0.687432613245076]
	TIME [epoch: 27.7 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6599716451755642		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.6599716451755642 | validation: 0.6456367509457647]
	TIME [epoch: 27.7 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8221979753750652		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.8221979753750652 | validation: 0.6447077759587861]
	TIME [epoch: 27.7 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6134697742242857		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.6134697742242857 | validation: 0.6156795834984137]
	TIME [epoch: 27.7 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6280352362479353		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.6280352362479353 | validation: 0.6606543889487505]
	TIME [epoch: 27.7 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5675734736258935		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.5675734736258935 | validation: 0.6829220668005219]
	TIME [epoch: 27.7 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5577032539849532		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.5577032539849532 | validation: 0.6183187667920512]
	TIME [epoch: 27.7 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5644714716253061		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.5644714716253061 | validation: 0.5659508130094878]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_653.pth
	Model improved!!!
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.55838615869795		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.55838615869795 | validation: 0.8130484295502899]
	TIME [epoch: 27.7 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7209078199172384		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.7209078199172384 | validation: 0.6198547084898998]
	TIME [epoch: 27.7 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6891788190356114		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.6891788190356114 | validation: 0.6111949132938699]
	TIME [epoch: 27.8 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5873978113456543		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.5873978113456543 | validation: 0.6985722400509661]
	TIME [epoch: 27.6 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5668942078079888		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.5668942078079888 | validation: 0.8570626383968966]
	TIME [epoch: 27.7 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6373762505153848		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.6373762505153848 | validation: 0.7944290488083436]
	TIME [epoch: 27.7 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6590662930663278		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.6590662930663278 | validation: 0.6285652692013871]
	TIME [epoch: 27.6 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5577263511925663		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.5577263511925663 | validation: 0.6635650145132863]
	TIME [epoch: 27.6 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7934740583665651		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.7934740583665651 | validation: 0.7040601512814264]
	TIME [epoch: 27.6 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.745304098742667		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.745304098742667 | validation: 0.7114727752379038]
	TIME [epoch: 27.7 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6520409458504487		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.6520409458504487 | validation: 0.6305632687244749]
	TIME [epoch: 27.7 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5459778744815953		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.5459778744815953 | validation: 0.9243377916012128]
	TIME [epoch: 27.8 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7296815408884249		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.7296815408884249 | validation: 0.6239702577044731]
	TIME [epoch: 27.8 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9049048257750607		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.9049048257750607 | validation: 0.6439932558434828]
	TIME [epoch: 27.6 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5449976171133998		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.5449976171133998 | validation: 1.2938520600278438]
	TIME [epoch: 27.7 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8021431473013806		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.8021431473013806 | validation: 0.9584694654753737]
	TIME [epoch: 27.7 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.716818028864765		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.716818028864765 | validation: 0.9630389345366507]
	TIME [epoch: 27.7 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7534564505769196		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.7534564505769196 | validation: 0.7455880043661973]
	TIME [epoch: 27.8 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6008505130007267		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.6008505130007267 | validation: 0.6114443676106526]
	TIME [epoch: 27.8 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7689094015398448		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.7689094015398448 | validation: 0.956918580977827]
	TIME [epoch: 27.7 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8113604769937927		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.8113604769937927 | validation: 0.6385580381467992]
	TIME [epoch: 27.7 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5745292261459445		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.5745292261459445 | validation: 0.5959057520663155]
	TIME [epoch: 27.7 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6315715621197042		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.6315715621197042 | validation: 0.5858689302846678]
	TIME [epoch: 27.7 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5843762343804159		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.5843762343804159 | validation: 0.6107970781332317]
	TIME [epoch: 27.7 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5453154599797787		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.5453154599797787 | validation: 0.6151240041569728]
	TIME [epoch: 27.8 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5450947454434583		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.5450947454434583 | validation: 0.7074103885823734]
	TIME [epoch: 27.7 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5753828054556149		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.5753828054556149 | validation: 0.6849653193980142]
	TIME [epoch: 27.7 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5944901455041387		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.5944901455041387 | validation: 0.5473847269576331]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_681.pth
	Model improved!!!
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5937613438113254		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.5937613438113254 | validation: 0.5563961484302634]
	TIME [epoch: 27.7 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.827679317013466		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.827679317013466 | validation: 0.6658940404523248]
	TIME [epoch: 27.8 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5418910800641847		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.5418910800641847 | validation: 0.5687872165524026]
	TIME [epoch: 27.8 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5663215061391601		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.5663215061391601 | validation: 0.5769097454326834]
	TIME [epoch: 27.7 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1942352883301273		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 1.1942352883301273 | validation: 0.8030834153048416]
	TIME [epoch: 27.7 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6911970547818714		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.6911970547818714 | validation: 0.7024999522263282]
	TIME [epoch: 27.8 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7930997729702711		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.7930997729702711 | validation: 0.7085685719329459]
	TIME [epoch: 27.7 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6555795655109709		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.6555795655109709 | validation: 0.6870698095079811]
	TIME [epoch: 27.8 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5506706023043235		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.5506706023043235 | validation: 0.5968578996690935]
	TIME [epoch: 27.7 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5578396621167391		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.5578396621167391 | validation: 0.5671486126584265]
	TIME [epoch: 27.8 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6014757935325926		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.6014757935325926 | validation: 0.8480088700916741]
	TIME [epoch: 27.8 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.714317192647437		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.714317192647437 | validation: 0.9131753486732151]
	TIME [epoch: 27.7 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7183813532197272		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.7183813532197272 | validation: 0.8396860613794956]
	TIME [epoch: 27.7 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5976887067788472		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.5976887067788472 | validation: 0.5758961928065942]
	TIME [epoch: 27.7 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5315455751917106		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.5315455751917106 | validation: 0.8978411339071855]
	TIME [epoch: 27.8 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6205338482488055		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.6205338482488055 | validation: 0.5741643899369265]
	TIME [epoch: 27.7 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5684713147929943		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.5684713147929943 | validation: 0.5427279346501118]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_698.pth
	Model improved!!!
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5480673699985353		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.5480673699985353 | validation: 0.5392605573698078]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_699.pth
	Model improved!!!
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5590107589882829		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.5590107589882829 | validation: 0.5788190100381755]
	TIME [epoch: 27.7 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5688087630058727		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.5688087630058727 | validation: 0.5961062257394838]
	TIME [epoch: 27.8 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5540966643507657		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.5540966643507657 | validation: 0.6436060168626748]
	TIME [epoch: 27.8 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5711702340416706		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.5711702340416706 | validation: 0.5631325903707971]
	TIME [epoch: 27.8 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7255074835212444		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.7255074835212444 | validation: 0.6084316972890516]
	TIME [epoch: 27.8 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7300342838960631		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.7300342838960631 | validation: 0.632390180504706]
	TIME [epoch: 27.8 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5299587502795143		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.5299587502795143 | validation: 0.7473954006931729]
	TIME [epoch: 27.8 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6727260839389142		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.6727260839389142 | validation: 0.8108154426133174]
	TIME [epoch: 27.8 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6805639709577589		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.6805639709577589 | validation: 0.5955011258156034]
	TIME [epoch: 27.8 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.569933742091282		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.569933742091282 | validation: 0.7978375187706809]
	TIME [epoch: 27.8 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5609585736376584		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.5609585736376584 | validation: 0.7791765228397884]
	TIME [epoch: 27.7 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.704691322438636		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.704691322438636 | validation: 0.586222196385917]
	TIME [epoch: 27.7 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5781297416036262		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.5781297416036262 | validation: 1.5119423648446313]
	TIME [epoch: 27.7 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9950370234167979		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.9950370234167979 | validation: 0.5910687375385807]
	TIME [epoch: 27.7 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5540342404861899		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.5540342404861899 | validation: 0.6239895883477623]
	TIME [epoch: 27.7 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5598028265359921		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.5598028265359921 | validation: 0.5649496624301246]
	TIME [epoch: 27.8 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5311855080228102		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.5311855080228102 | validation: 0.7915210794684944]
	TIME [epoch: 27.7 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6974272121804382		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.6974272121804382 | validation: 0.7342486484247813]
	TIME [epoch: 27.8 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6225682811889109		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.6225682811889109 | validation: 0.7686087014811999]
	TIME [epoch: 27.8 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5958171601651309		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.5958171601651309 | validation: 0.5946133301350047]
	TIME [epoch: 27.7 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5665790164959434		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.5665790164959434 | validation: 0.7173417891449865]
	TIME [epoch: 27.6 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6689811062699388		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.6689811062699388 | validation: 0.8057176253765659]
	TIME [epoch: 27.8 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6425947968116624		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.6425947968116624 | validation: 0.6039748594933455]
	TIME [epoch: 27.8 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5604346898450421		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.5604346898450421 | validation: 0.583536157713092]
	TIME [epoch: 27.7 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6811101838149335		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.6811101838149335 | validation: 0.8654042342110907]
	TIME [epoch: 27.7 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.646803545281868		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.646803545281868 | validation: 0.6177979210780741]
	TIME [epoch: 27.6 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5944987029336138		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.5944987029336138 | validation: 0.69360992737634]
	TIME [epoch: 27.7 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5735510426287581		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.5735510426287581 | validation: 0.6245021942330719]
	TIME [epoch: 27.7 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6328706833708806		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.6328706833708806 | validation: 0.5340965745802925]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_728.pth
	Model improved!!!
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5320636073503339		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.5320636073503339 | validation: 0.6526506020262598]
	TIME [epoch: 27.8 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.653823796623445		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.653823796623445 | validation: 1.2067743291085737]
	TIME [epoch: 27.8 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7045994386690234		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.7045994386690234 | validation: 0.6791412218587232]
	TIME [epoch: 27.8 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5413828642036271		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.5413828642036271 | validation: 0.5814962412759616]
	TIME [epoch: 27.7 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5140913973822221		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.5140913973822221 | validation: 0.5901331930981719]
	TIME [epoch: 27.8 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5534152330228425		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.5534152330228425 | validation: 0.7108409535863257]
	TIME [epoch: 27.8 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5049760871551923		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.5049760871551923 | validation: 0.6355098535943982]
	TIME [epoch: 27.7 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4830667122224572		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.4830667122224572 | validation: 0.5925369342539445]
	TIME [epoch: 27.8 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6239398511988568		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.6239398511988568 | validation: 0.5282097445289932]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_737.pth
	Model improved!!!
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5030412238824242		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.5030412238824242 | validation: 0.6182758796596522]
	TIME [epoch: 27.8 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6520420121675647		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.6520420121675647 | validation: 0.5582879922987769]
	TIME [epoch: 27.8 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49253477880150187		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.49253477880150187 | validation: 0.5769692299875192]
	TIME [epoch: 27.7 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.549870087691573		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.549870087691573 | validation: 0.7834049467838125]
	TIME [epoch: 27.8 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6601413529518697		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.6601413529518697 | validation: 0.6788446551344407]
	TIME [epoch: 27.7 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6619935109713174		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.6619935109713174 | validation: 0.5537894262101156]
	TIME [epoch: 27.8 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5663048168590823		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.5663048168590823 | validation: 0.5632771241281228]
	TIME [epoch: 27.8 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5595270421812626		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.5595270421812626 | validation: 0.6138931576464529]
	TIME [epoch: 27.8 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6837687616982564		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.6837687616982564 | validation: 0.6721931044955588]
	TIME [epoch: 27.8 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5443728885899651		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.5443728885899651 | validation: 0.5780569729121059]
	TIME [epoch: 27.8 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49432145821519746		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.49432145821519746 | validation: 0.6450273435656538]
	TIME [epoch: 27.8 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5397691252476415		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.5397691252476415 | validation: 0.6293976147750059]
	TIME [epoch: 27.8 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5033108365308004		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.5033108365308004 | validation: 0.6868987311556126]
	TIME [epoch: 27.7 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5435882872817367		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.5435882872817367 | validation: 0.6090223764846074]
	TIME [epoch: 27.8 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5244719937715769		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.5244719937715769 | validation: 0.6685378360370156]
	TIME [epoch: 27.7 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5507564990884791		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.5507564990884791 | validation: 0.5644472737702725]
	TIME [epoch: 27.8 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5423933543400299		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.5423933543400299 | validation: 0.5587679139046021]
	TIME [epoch: 27.8 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49154130784264904		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.49154130784264904 | validation: 0.5494720999041397]
	TIME [epoch: 27.7 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5123316667021706		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.5123316667021706 | validation: 0.5753937522654698]
	TIME [epoch: 27.8 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5474036554283976		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.5474036554283976 | validation: 0.6001116775813712]
	TIME [epoch: 27.7 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6498509011662652		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.6498509011662652 | validation: 0.5519788426584162]
	TIME [epoch: 27.8 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5256188698317235		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.5256188698317235 | validation: 0.5259069246624332]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_759.pth
	Model improved!!!
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5243863771304921		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.5243863771304921 | validation: 0.5555728972612107]
	TIME [epoch: 27.7 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4843958393009475		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.4843958393009475 | validation: 0.6042387645062971]
	TIME [epoch: 27.8 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6361830398322367		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.6361830398322367 | validation: 0.5947973200215564]
	TIME [epoch: 27.7 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5647167786217203		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.5647167786217203 | validation: 0.5726667139323033]
	TIME [epoch: 27.8 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5210288366363616		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.5210288366363616 | validation: 0.642034341145706]
	TIME [epoch: 27.8 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7486544439289051		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.7486544439289051 | validation: 0.5586197244448105]
	TIME [epoch: 27.7 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48013671733204405		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.48013671733204405 | validation: 0.7390491519173078]
	TIME [epoch: 27.8 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5442003328943912		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.5442003328943912 | validation: 0.5822644297152962]
	TIME [epoch: 27.7 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5748006804763044		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.5748006804763044 | validation: 0.5255889037024303]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_768.pth
	Model improved!!!
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5543380001652386		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.5543380001652386 | validation: 1.0082256201197026]
	TIME [epoch: 27.8 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6743422056663373		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.6743422056663373 | validation: 0.6358309179243673]
	TIME [epoch: 27.8 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5803149466423698		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.5803149466423698 | validation: 0.6401848446649495]
	TIME [epoch: 27.7 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5255296467229781		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.5255296467229781 | validation: 0.510920100019431]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_772.pth
	Model improved!!!
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47071915930896613		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.47071915930896613 | validation: 0.5563314696211108]
	TIME [epoch: 27.8 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48912776500020255		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.48912776500020255 | validation: 0.5582213662424712]
	TIME [epoch: 27.7 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4885074548917897		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.4885074548917897 | validation: 0.7607528535613195]
	TIME [epoch: 27.7 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5657310336270903		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.5657310336270903 | validation: 0.5895983945100755]
	TIME [epoch: 27.8 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6945582586956867		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.6945582586956867 | validation: 0.5465124824908519]
	TIME [epoch: 27.7 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5070117738602117		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.5070117738602117 | validation: 0.5933488653688083]
	TIME [epoch: 27.8 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5228422210868969		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.5228422210868969 | validation: 0.5638058011552661]
	TIME [epoch: 27.8 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5835570914398216		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.5835570914398216 | validation: 0.7706598402000858]
	TIME [epoch: 27.7 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5304737369798201		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.5304737369798201 | validation: 0.6577710667465146]
	TIME [epoch: 27.8 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5205425766287		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.5205425766287 | validation: 0.5746018438794148]
	TIME [epoch: 27.8 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5118418631254453		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.5118418631254453 | validation: 0.5608091960695513]
	TIME [epoch: 27.8 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5311538270555456		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.5311538270555456 | validation: 0.5225277369391325]
	TIME [epoch: 27.8 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49127735313869203		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.49127735313869203 | validation: 0.5280010111656631]
	TIME [epoch: 27.7 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47129050123767025		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.47129050123767025 | validation: 0.5455367110029874]
	TIME [epoch: 27.7 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5215620361747944		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.5215620361747944 | validation: 0.6005218343944433]
	TIME [epoch: 27.7 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5506145617633209		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.5506145617633209 | validation: 0.5889737019346214]
	TIME [epoch: 27.7 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5047638045875922		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.5047638045875922 | validation: 0.625715876434984]
	TIME [epoch: 27.7 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8115439423870502		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.8115439423870502 | validation: 1.0154475284842248]
	TIME [epoch: 27.7 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7100191313059302		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.7100191313059302 | validation: 0.696245079066833]
	TIME [epoch: 27.8 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5499430410222805		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.5499430410222805 | validation: 0.5455126666215583]
	TIME [epoch: 27.7 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47090414715456536		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.47090414715456536 | validation: 0.5831941872531361]
	TIME [epoch: 27.7 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5242275082571791		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.5242275082571791 | validation: 0.577906124777617]
	TIME [epoch: 27.7 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5204361749045767		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.5204361749045767 | validation: 0.5152877416759535]
	TIME [epoch: 27.7 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4802870746936434		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.4802870746936434 | validation: 0.5289071598430239]
	TIME [epoch: 27.7 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5014748663539144		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.5014748663539144 | validation: 0.7212913451893832]
	TIME [epoch: 27.7 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5757142747787035		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.5757142747787035 | validation: 0.567290294029949]
	TIME [epoch: 27.7 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5474764662611622		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.5474764662611622 | validation: 0.6329439747065722]
	TIME [epoch: 27.8 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5525300675245416		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.5525300675245416 | validation: 0.6801175353857681]
	TIME [epoch: 27.7 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5492444945941364		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.5492444945941364 | validation: 0.632952925212037]
	TIME [epoch: 27.8 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5657805485815051		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.5657805485815051 | validation: 0.6230491724739216]
	TIME [epoch: 27.7 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49401928976833676		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.49401928976833676 | validation: 0.5698182725532265]
	TIME [epoch: 27.8 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4710302324637663		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.4710302324637663 | validation: 0.5106642082547158]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_804.pth
	Model improved!!!
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.538934065749605		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.538934065749605 | validation: 0.6664780601117234]
	TIME [epoch: 27.8 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5505509911233392		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.5505509911233392 | validation: 0.6556692447247718]
	TIME [epoch: 27.7 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5238689490937861		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.5238689490937861 | validation: 0.677897133195591]
	TIME [epoch: 27.8 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.604364218951113		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.604364218951113 | validation: 0.5454539684738754]
	TIME [epoch: 27.7 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5080555729053726		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.5080555729053726 | validation: 0.5937121125160723]
	TIME [epoch: 27.8 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6815217698969362		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.6815217698969362 | validation: 0.6074192499001214]
	TIME [epoch: 27.7 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5143491628176259		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.5143491628176259 | validation: 0.6079493076951208]
	TIME [epoch: 27.8 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4833989510180061		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.4833989510180061 | validation: 0.5759113640328808]
	TIME [epoch: 27.8 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5366797298562354		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.5366797298562354 | validation: 0.6766711184068203]
	TIME [epoch: 27.7 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5295299037112288		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.5295299037112288 | validation: 0.6364849010624741]
	TIME [epoch: 27.8 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5454146807977382		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.5454146807977382 | validation: 0.5581436098885459]
	TIME [epoch: 27.7 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5137274127568436		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.5137274127568436 | validation: 0.552160526854749]
	TIME [epoch: 27.8 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5347037479455495		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.5347037479455495 | validation: 0.609087676152559]
	TIME [epoch: 27.8 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5328669141333554		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.5328669141333554 | validation: 0.5805513257895507]
	TIME [epoch: 27.7 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5216218633369286		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.5216218633369286 | validation: 0.5112293169545121]
	TIME [epoch: 27.7 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6497331995975821		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.6497331995975821 | validation: 0.6736144551230524]
	TIME [epoch: 27.7 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5770999767417104		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.5770999767417104 | validation: 0.5311918293191276]
	TIME [epoch: 27.7 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47899100299657593		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.47899100299657593 | validation: 0.5415856445540925]
	TIME [epoch: 27.7 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4917628186821608		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.4917628186821608 | validation: 0.5546158962238262]
	TIME [epoch: 27.7 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5057643426710913		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.5057643426710913 | validation: 0.5468633189177053]
	TIME [epoch: 27.8 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4948921997862878		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.4948921997862878 | validation: 0.8050793548860044]
	TIME [epoch: 27.7 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5802947238164428		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.5802947238164428 | validation: 0.5027173790940216]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_826.pth
	Model improved!!!
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4839980138558378		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.4839980138558378 | validation: 0.5164796083991425]
	TIME [epoch: 27.7 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.491568232039002		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.491568232039002 | validation: 0.5103070607699458]
	TIME [epoch: 27.7 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5518444402731719		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.5518444402731719 | validation: 0.5188665081358299]
	TIME [epoch: 27.7 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4751261357300486		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.4751261357300486 | validation: 0.5252555543035062]
	TIME [epoch: 27.8 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4785718620448227		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.4785718620448227 | validation: 0.5140346177444972]
	TIME [epoch: 27.8 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45852557789033094		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.45852557789033094 | validation: 0.5433684786969594]
	TIME [epoch: 27.8 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5267771010596504		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.5267771010596504 | validation: 0.5221494348300574]
	TIME [epoch: 27.7 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4577685177869728		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.4577685177869728 | validation: 0.6215990275484968]
	TIME [epoch: 27.8 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5387272088408999		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.5387272088408999 | validation: 0.5562219454439412]
	TIME [epoch: 27.7 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4993893357735382		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.4993893357735382 | validation: 0.6962164081202445]
	TIME [epoch: 27.7 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5161364054876758		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.5161364054876758 | validation: 0.49345613436085617]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_837.pth
	Model improved!!!
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44816053607714407		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.44816053607714407 | validation: 0.49065061326044074]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_838.pth
	Model improved!!!
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.455516684217911		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.455516684217911 | validation: 0.5249594797060991]
	TIME [epoch: 27.8 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.592446679768606		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.592446679768606 | validation: 0.6104467310971049]
	TIME [epoch: 27.7 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.611623456786492		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.611623456786492 | validation: 0.540486940231866]
	TIME [epoch: 27.7 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5022065372704012		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.5022065372704012 | validation: 0.5377054450568044]
	TIME [epoch: 27.8 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4759381332337096		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.4759381332337096 | validation: 0.5487101165444318]
	TIME [epoch: 27.8 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4808562168329806		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.4808562168329806 | validation: 0.6379962689107114]
	TIME [epoch: 27.8 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5707198806619981		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.5707198806619981 | validation: 0.6162483447060471]
	TIME [epoch: 27.7 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49119507437396487		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.49119507437396487 | validation: 0.5286715014239957]
	TIME [epoch: 27.8 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45050795698367807		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.45050795698367807 | validation: 0.5145271749888556]
	TIME [epoch: 27.8 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46386534857470596		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.46386534857470596 | validation: 0.5361000485828411]
	TIME [epoch: 27.7 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5020154095865076		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.5020154095865076 | validation: 0.5668768066196198]
	TIME [epoch: 27.8 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4881956066009126		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.4881956066009126 | validation: 0.5313045223399324]
	TIME [epoch: 27.8 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4749545703028399		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.4749545703028399 | validation: 0.5427945701010922]
	TIME [epoch: 27.8 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47191455161473883		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.47191455161473883 | validation: 0.5172440757483698]
	TIME [epoch: 27.8 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4468261858792913		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.4468261858792913 | validation: 0.6692313388354205]
	TIME [epoch: 27.8 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5151184486931064		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.5151184486931064 | validation: 0.6876843076922555]
	TIME [epoch: 27.8 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.700675679956887		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.700675679956887 | validation: 0.5670081358482577]
	TIME [epoch: 27.8 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5037353990879095		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.5037353990879095 | validation: 0.5924500627852956]
	TIME [epoch: 27.8 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5126616469945641		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.5126616469945641 | validation: 0.6077275408278354]
	TIME [epoch: 27.8 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4711463086359296		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.4711463086359296 | validation: 0.7101357047208984]
	TIME [epoch: 27.7 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5341195510349035		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.5341195510349035 | validation: 0.5196686575878535]
	TIME [epoch: 27.8 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4678018863850105		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.4678018863850105 | validation: 0.4983542141168124]
	TIME [epoch: 27.8 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4420829156566494		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.4420829156566494 | validation: 0.5419852992500735]
	TIME [epoch: 27.8 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48848763760468583		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.48848763760468583 | validation: 0.5762740986345786]
	TIME [epoch: 27.7 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.587604353875447		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.587604353875447 | validation: 0.5720280221377942]
	TIME [epoch: 27.7 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5035936234296386		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.5035936234296386 | validation: 0.5233499526920772]
	TIME [epoch: 27.8 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46174976076675966		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.46174976076675966 | validation: 0.5630572805668651]
	TIME [epoch: 27.8 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4738164743950776		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.4738164743950776 | validation: 0.5098637034206744]
	TIME [epoch: 27.7 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5854184636303129		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.5854184636303129 | validation: 0.5574928540459999]
	TIME [epoch: 27.8 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45883906907025374		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.45883906907025374 | validation: 0.5525931818600822]
	TIME [epoch: 27.8 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47949715530755466		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.47949715530755466 | validation: 0.5112918031162266]
	TIME [epoch: 27.8 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49292872520097397		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.49292872520097397 | validation: 0.4925905273376961]
	TIME [epoch: 27.7 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4693789626590952		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.4693789626590952 | validation: 0.6380531540895662]
	TIME [epoch: 27.7 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5384975798477606		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.5384975798477606 | validation: 0.8983874100173901]
	TIME [epoch: 27.8 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6223669945138118		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.6223669945138118 | validation: 0.5201978487737887]
	TIME [epoch: 27.7 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5335495933417165		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.5335495933417165 | validation: 0.8329074196426551]
	TIME [epoch: 27.8 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7035052449499382		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.7035052449499382 | validation: 0.6593853264618648]
	TIME [epoch: 27.7 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5382514868446151		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.5382514868446151 | validation: 0.540277979097225]
	TIME [epoch: 27.8 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4554760639076648		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.4554760639076648 | validation: 0.6104456108910686]
	TIME [epoch: 27.8 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5270053701119087		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.5270053701119087 | validation: 0.5975354416835372]
	TIME [epoch: 27.8 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4894502700276072		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.4894502700276072 | validation: 0.5078729879622051]
	TIME [epoch: 27.7 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44956696132286755		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.44956696132286755 | validation: 0.5054188696890423]
	TIME [epoch: 27.7 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48558033250806276		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.48558033250806276 | validation: 0.567652306529473]
	TIME [epoch: 27.8 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5033700706345525		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.5033700706345525 | validation: 0.5287288064226576]
	TIME [epoch: 27.8 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5109538468796175		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.5109538468796175 | validation: 0.567790481278638]
	TIME [epoch: 27.8 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45632092298421156		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.45632092298421156 | validation: 0.6403282729658727]
	TIME [epoch: 27.8 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6512246579364488		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.6512246579364488 | validation: 0.4942996497776106]
	TIME [epoch: 27.8 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4370424189146529		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.4370424189146529 | validation: 0.6278333496125051]
	TIME [epoch: 27.8 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5014516798817081		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.5014516798817081 | validation: 0.48506902794648504]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_887.pth
	Model improved!!!
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43681777752792766		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.43681777752792766 | validation: 0.5706963420486341]
	TIME [epoch: 27.7 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4966711086899642		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.4966711086899642 | validation: 0.7730815683238907]
	TIME [epoch: 27.8 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5557064970847373		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.5557064970847373 | validation: 0.5600439001339621]
	TIME [epoch: 27.8 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4514947060359984		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.4514947060359984 | validation: 0.574564292681795]
	TIME [epoch: 27.8 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4632313637232438		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.4632313637232438 | validation: 0.5000858640993063]
	TIME [epoch: 27.7 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.54128702043726		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.54128702043726 | validation: 0.5503008894715571]
	TIME [epoch: 27.8 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4729451447167377		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.4729451447167377 | validation: 0.5930123455544031]
	TIME [epoch: 27.8 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6017736425910389		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.6017736425910389 | validation: 0.5557836689184861]
	TIME [epoch: 27.8 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4690808823081399		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.4690808823081399 | validation: 0.5247875614833933]
	TIME [epoch: 27.7 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.464301485052134		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.464301485052134 | validation: 0.5334804631237277]
	TIME [epoch: 27.7 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4788378583674797		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.4788378583674797 | validation: 0.5524910317764551]
	TIME [epoch: 27.7 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47489779504008767		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.47489779504008767 | validation: 0.5481469673191003]
	TIME [epoch: 27.8 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49209797682201534		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.49209797682201534 | validation: 0.582507696162566]
	TIME [epoch: 27.8 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45504473647038207		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.45504473647038207 | validation: 0.5901682415070387]
	TIME [epoch: 27.8 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4641596138071671		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.4641596138071671 | validation: 0.5033415477431815]
	TIME [epoch: 27.8 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5331503156999144		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.5331503156999144 | validation: 1.1661093573841677]
	TIME [epoch: 27.8 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7306712462430828		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.7306712462430828 | validation: 0.5209008478779091]
	TIME [epoch: 27.8 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.622037720088828		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.622037720088828 | validation: 0.5151953219784922]
	TIME [epoch: 27.7 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4450773552830567		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.4450773552830567 | validation: 0.5168209064737966]
	TIME [epoch: 27.8 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5351863256384133		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.5351863256384133 | validation: 0.515951420779378]
	TIME [epoch: 27.8 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44381340177923917		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.44381340177923917 | validation: 0.5434703422618291]
	TIME [epoch: 27.7 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45254083915597554		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.45254083915597554 | validation: 0.5596198122032826]
	TIME [epoch: 27.7 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5028446293726325		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.5028446293726325 | validation: 0.9203990647689544]
	TIME [epoch: 27.7 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6587427771520217		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.6587427771520217 | validation: 0.6185519036456532]
	TIME [epoch: 27.7 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5200352921800248		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.5200352921800248 | validation: 0.5527649175929805]
	TIME [epoch: 27.8 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46242052899028807		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.46242052899028807 | validation: 0.5343823614852419]
	TIME [epoch: 27.7 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4809573612623173		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.4809573612623173 | validation: 0.5439677917190824]
	TIME [epoch: 27.8 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45077739434262815		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.45077739434262815 | validation: 0.640489762944703]
	TIME [epoch: 27.8 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5428985607370493		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.5428985607370493 | validation: 0.6604157710021478]
	TIME [epoch: 27.8 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5026163898327748		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.5026163898327748 | validation: 0.5395263035535846]
	TIME [epoch: 27.8 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4668099624477986		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.4668099624477986 | validation: 0.4953428739398685]
	TIME [epoch: 27.8 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4689160919676471		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.4689160919676471 | validation: 0.5221522970028102]
	TIME [epoch: 27.7 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4612393724149896		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.4612393724149896 | validation: 0.5629430116288738]
	TIME [epoch: 27.7 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46637411659401884		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.46637411659401884 | validation: 0.600737272585893]
	TIME [epoch: 27.8 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49583609078485136		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.49583609078485136 | validation: 0.5224102602905861]
	TIME [epoch: 27.7 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45155591417448887		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.45155591417448887 | validation: 0.5159670115702479]
	TIME [epoch: 27.7 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49271949678443694		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.49271949678443694 | validation: 0.6183904148576465]
	TIME [epoch: 27.8 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5108508194032355		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.5108508194032355 | validation: 0.5396096825291302]
	TIME [epoch: 27.7 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4680229705628616		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.4680229705628616 | validation: 0.6065818972592812]
	TIME [epoch: 27.7 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4824341915296396		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.4824341915296396 | validation: 0.5746685982074363]
	TIME [epoch: 27.8 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4796923233146267		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.4796923233146267 | validation: 0.5444678911062683]
	TIME [epoch: 27.8 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46019461051779087		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.46019461051779087 | validation: 0.6215157914681805]
	TIME [epoch: 27.8 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5132466450848798		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.5132466450848798 | validation: 0.5187697853982854]
	TIME [epoch: 27.8 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4416441324044554		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.4416441324044554 | validation: 0.5138840362805794]
	TIME [epoch: 27.7 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47343800461032004		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.47343800461032004 | validation: 0.5634173180599684]
	TIME [epoch: 27.8 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48633774637202903		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.48633774637202903 | validation: 0.5936104996683018]
	TIME [epoch: 27.8 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4874628962093168		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.4874628962093168 | validation: 0.5868192035524893]
	TIME [epoch: 27.8 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46726963362476726		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.46726963362476726 | validation: 0.48513254912041065]
	TIME [epoch: 27.8 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44876305957423257		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.44876305957423257 | validation: 0.5136458576963335]
	TIME [epoch: 27.8 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45606744549847206		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.45606744549847206 | validation: 0.4872255461998915]
	TIME [epoch: 27.8 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4469251367277735		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.4469251367277735 | validation: 0.5182435455180275]
	TIME [epoch: 27.8 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5059180576967447		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.5059180576967447 | validation: 0.6645126779761467]
	TIME [epoch: 27.8 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.490620817973086		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.490620817973086 | validation: 0.7307074455167858]
	TIME [epoch: 27.8 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5272624088863079		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.5272624088863079 | validation: 0.6206344518950405]
	TIME [epoch: 27.8 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5018077312255468		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.5018077312255468 | validation: 0.5100026476147187]
	TIME [epoch: 27.8 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4458895535674439		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.4458895535674439 | validation: 0.5052144402813877]
	TIME [epoch: 27.7 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4327336142198799		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.4327336142198799 | validation: 0.503550917780967]
	TIME [epoch: 27.8 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4312660108127816		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.4312660108127816 | validation: 0.5121575402286347]
	TIME [epoch: 27.7 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5262939592807303		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.5262939592807303 | validation: 0.5210661966865431]
	TIME [epoch: 27.8 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5181157836450138		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.5181157836450138 | validation: 0.5586625540165442]
	TIME [epoch: 27.8 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45606655796777307		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.45606655796777307 | validation: 0.4919684714228502]
	TIME [epoch: 27.8 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6069794561691343		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.6069794561691343 | validation: 0.8329948351279833]
	TIME [epoch: 27.8 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5593665178231702		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.5593665178231702 | validation: 0.5482300610600549]
	TIME [epoch: 27.8 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4628767541459894		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.4628767541459894 | validation: 0.5866553295651789]
	TIME [epoch: 27.8 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4776325031410051		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.4776325031410051 | validation: 0.5328656208663385]
	TIME [epoch: 27.8 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5467723012290451		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.5467723012290451 | validation: 0.5164569848013877]
	TIME [epoch: 27.7 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4367159875427644		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.4367159875427644 | validation: 0.5279313516921053]
	TIME [epoch: 27.8 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4555546455180266		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.4555546455180266 | validation: 0.7142836732903272]
	TIME [epoch: 27.8 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5547855748366963		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.5547855748366963 | validation: 0.5101976714314844]
	TIME [epoch: 27.8 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4550366376222249		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.4550366376222249 | validation: 0.8520592827182714]
	TIME [epoch: 27.9 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.598292973013119		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.598292973013119 | validation: 0.6027403839121374]
	TIME [epoch: 27.8 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5145097620730539		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.5145097620730539 | validation: 0.521029201990193]
	TIME [epoch: 27.8 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4746613335439087		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.4746613335439087 | validation: 0.5246976419759429]
	TIME [epoch: 27.8 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44443409377304827		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.44443409377304827 | validation: 0.49780523867605087]
	TIME [epoch: 27.8 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43942182104579863		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.43942182104579863 | validation: 0.5119208712537341]
	TIME [epoch: 27.8 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44974940572154476		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.44974940572154476 | validation: 0.5921321623008832]
	TIME [epoch: 27.7 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4812637955552383		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.4812637955552383 | validation: 0.606144424485173]
	TIME [epoch: 27.9 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48829438039162243		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.48829438039162243 | validation: 0.5520887165933338]
	TIME [epoch: 27.8 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5154924947528792		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.5154924947528792 | validation: 0.7191343103091742]
	TIME [epoch: 27.8 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5858539066631347		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.5858539066631347 | validation: 0.6722460377558099]
	TIME [epoch: 27.8 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5322105087268905		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.5322105087268905 | validation: 0.6178267712918133]
	TIME [epoch: 27.8 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47750742107705585		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.47750742107705585 | validation: 0.5480917183423466]
	TIME [epoch: 27.9 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5571112428475161		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.5571112428475161 | validation: 0.5750895266343957]
	TIME [epoch: 27.8 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4979841993542555		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.4979841993542555 | validation: 0.635701745448824]
	TIME [epoch: 27.8 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48532048755523194		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.48532048755523194 | validation: 0.5551457899919089]
	TIME [epoch: 27.9 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47287762289310487		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.47287762289310487 | validation: 0.5668449753726107]
	TIME [epoch: 27.8 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4826985860552137		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.4826985860552137 | validation: 0.5426188229691026]
	TIME [epoch: 27.8 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4479386867205154		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.4479386867205154 | validation: 0.5016438613090697]
	TIME [epoch: 27.8 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42691469047485775		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.42691469047485775 | validation: 0.541524583476246]
	TIME [epoch: 27.8 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4447936844659227		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.4447936844659227 | validation: 0.5784171950219873]
	TIME [epoch: 27.8 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44704706305615205		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.44704706305615205 | validation: 0.5344525289181411]
	TIME [epoch: 27.8 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4588497573698814		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.4588497573698814 | validation: 0.615342047278736]
	TIME [epoch: 27.8 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4571613960339066		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.4571613960339066 | validation: 0.4969218728711134]
	TIME [epoch: 27.8 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5962452695516511		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.5962452695516511 | validation: 0.6214481850598544]
	TIME [epoch: 27.7 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4743173386253546		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.4743173386253546 | validation: 0.6527336663375571]
	TIME [epoch: 27.9 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5334166170157428		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.5334166170157428 | validation: 0.48559785827766383]
	TIME [epoch: 27.8 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4412265701767589		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.4412265701767589 | validation: 0.48558051373290356]
	TIME [epoch: 27.7 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43434914291553517		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.43434914291553517 | validation: 0.4984859116216758]
	TIME [epoch: 27.7 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41895457862173113		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.41895457862173113 | validation: 0.4847264312407134]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_986.pth
	Model improved!!!
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4230731900507524		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.4230731900507524 | validation: 0.5603304431005803]
	TIME [epoch: 27.7 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5218062682049218		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.5218062682049218 | validation: 0.5010030432935193]
	TIME [epoch: 28 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4252215692715842		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.4252215692715842 | validation: 0.4870175685223015]
	TIME [epoch: 27.7 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41556519151683535		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.41556519151683535 | validation: 0.47998796815315414]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_990.pth
	Model improved!!!
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4149520545315969		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.4149520545315969 | validation: 0.47718105089015284]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_991.pth
	Model improved!!!
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47287159542683277		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.47287159542683277 | validation: 0.5549051490415293]
	TIME [epoch: 27.7 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4552979354334659		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.4552979354334659 | validation: 0.4978361762601108]
	TIME [epoch: 27.7 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42127513785176607		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.42127513785176607 | validation: 0.5296273068379371]
	TIME [epoch: 27.7 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5307592863310256		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.5307592863310256 | validation: 0.4703931095772832]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_995.pth
	Model improved!!!
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4213044176228925		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.4213044176228925 | validation: 0.7073841967180478]
	TIME [epoch: 27.7 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5188617314343331		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.5188617314343331 | validation: 0.5067998630763507]
	TIME [epoch: 27.7 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49327691543045593		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.49327691543045593 | validation: 0.5090644217044951]
	TIME [epoch: 27.7 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42864067062067757		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.42864067062067757 | validation: 0.5137196780765337]
	TIME [epoch: 27.7 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4637184766012049		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.4637184766012049 | validation: 0.4752239631201375]
	TIME [epoch: 27.7 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4218929733528556		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.4218929733528556 | validation: 0.4970810704063239]
	TIME [epoch: 27.7 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42802517427486086		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.42802517427486086 | validation: 0.5125617525923477]
	TIME [epoch: 27.7 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4399578798019903		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.4399578798019903 | validation: 0.4811229565483721]
	TIME [epoch: 27.7 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.414484378599433		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.414484378599433 | validation: 0.5006883175439242]
	TIME [epoch: 27.7 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4426772644548309		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.4426772644548309 | validation: 0.5187569879092861]
	TIME [epoch: 27.7 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4340170281605953		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.4340170281605953 | validation: 0.48851717781635673]
	TIME [epoch: 27.7 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44263901350948653		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.44263901350948653 | validation: 0.520947433182306]
	TIME [epoch: 27.7 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44002586513926184		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.44002586513926184 | validation: 0.49014873682540994]
	TIME [epoch: 27.7 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4166588947319898		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.4166588947319898 | validation: 0.5455144230184986]
	TIME [epoch: 27.7 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42900251233742653		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.42900251233742653 | validation: 0.4780589273943474]
	TIME [epoch: 27.7 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4128961190383474		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.4128961190383474 | validation: 0.5117487251812282]
	TIME [epoch: 27.7 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43568413983499327		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.43568413983499327 | validation: 0.4829264559444549]
	TIME [epoch: 27.7 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.436730044636863		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.436730044636863 | validation: 0.5245353976535492]
	TIME [epoch: 27.7 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43178459519934326		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.43178459519934326 | validation: 0.5613371478162426]
	TIME [epoch: 27.7 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44982012854053977		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.44982012854053977 | validation: 0.5000574614173278]
	TIME [epoch: 27.7 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4252384983220355		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.4252384983220355 | validation: 0.4822058585295308]
	TIME [epoch: 27.7 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4191884098876931		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.4191884098876931 | validation: 0.48332008784358516]
	TIME [epoch: 27.8 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5115717635368742		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.5115717635368742 | validation: 0.48428959633193985]
	TIME [epoch: 27.8 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4114108862873839		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.4114108862873839 | validation: 0.5112677808422823]
	TIME [epoch: 27.7 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4173653347127428		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.4173653347127428 | validation: 0.47763160828054607]
	TIME [epoch: 27.7 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40452157607655437		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.40452157607655437 | validation: 0.48028658200735175]
	TIME [epoch: 27.7 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.438343177209788		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.438343177209788 | validation: 0.528014520335075]
	TIME [epoch: 27.8 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4448059901790575		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.4448059901790575 | validation: 0.513354998123109]
	TIME [epoch: 27.7 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4688207453658957		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.4688207453658957 | validation: 0.521047093107462]
	TIME [epoch: 27.7 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4696131560952909		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.4696131560952909 | validation: 0.497100994866797]
	TIME [epoch: 27.8 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44180021727827246		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.44180021727827246 | validation: 0.5021442988495709]
	TIME [epoch: 27.7 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44411477597995414		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.44411477597995414 | validation: 0.5119514844741164]
	TIME [epoch: 27.8 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.468972353200102		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.468972353200102 | validation: 0.5282735690824681]
	TIME [epoch: 27.8 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.440805648333692		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.440805648333692 | validation: 0.627836969294866]
	TIME [epoch: 27.7 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.506818441844306		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.506818441844306 | validation: 0.551212761835767]
	TIME [epoch: 27.7 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4903220541689736		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.4903220541689736 | validation: 0.5007179032527784]
	TIME [epoch: 27.7 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4383968542308184		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.4383968542308184 | validation: 0.4945621591045759]
	TIME [epoch: 27.8 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4376500367052737		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.4376500367052737 | validation: 0.6820177195399252]
	TIME [epoch: 27.8 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5426421883403937		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.5426421883403937 | validation: 0.5883630152783283]
	TIME [epoch: 27.7 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45243165191892515		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.45243165191892515 | validation: 0.4754436515285039]
	TIME [epoch: 27.8 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40988376150408107		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.40988376150408107 | validation: 0.4955537048143564]
	TIME [epoch: 27.7 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4157237858843179		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.4157237858843179 | validation: 0.4751367377128237]
	TIME [epoch: 27.8 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44902120089277897		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.44902120089277897 | validation: 0.48559693373620927]
	TIME [epoch: 27.8 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43086191331894097		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.43086191331894097 | validation: 0.6885545832842113]
	TIME [epoch: 27.7 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5412883534931519		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.5412883534931519 | validation: 0.49437119497280163]
	TIME [epoch: 27.8 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45883934527494		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.45883934527494 | validation: 0.4760117383892012]
	TIME [epoch: 27.7 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45959276224320517		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.45959276224320517 | validation: 0.580107705244115]
	TIME [epoch: 27.8 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4639376505959131		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.4639376505959131 | validation: 0.4751359574657995]
	TIME [epoch: 27.8 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4262696606899391		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.4262696606899391 | validation: 0.481751108586343]
	TIME [epoch: 27.8 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43903478359204096		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.43903478359204096 | validation: 0.5047532681738796]
	TIME [epoch: 27.8 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5130592486789521		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.5130592486789521 | validation: 0.5343838425250919]
	TIME [epoch: 27.7 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43484958053065115		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.43484958053065115 | validation: 0.5013618257557753]
	TIME [epoch: 27.8 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4301847468815926		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.4301847468815926 | validation: 0.4927463191550937]
	TIME [epoch: 27.8 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4372238543562149		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.4372238543562149 | validation: 0.4877196347764336]
	TIME [epoch: 27.7 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4598403151784324		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.4598403151784324 | validation: 0.5568717245793566]
	TIME [epoch: 27.8 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.439898408522071		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.439898408522071 | validation: 0.5393431754297932]
	TIME [epoch: 27.7 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4590293214568955		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.4590293214568955 | validation: 0.5242567766661701]
	TIME [epoch: 27.7 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4318240576419353		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.4318240576419353 | validation: 0.5985229001559262]
	TIME [epoch: 27.8 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4971832542693344		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.4971832542693344 | validation: 0.4978883664686778]
	TIME [epoch: 27.7 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.417670657110713		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.417670657110713 | validation: 0.47981215379403624]
	TIME [epoch: 27.7 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42090677781352703		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.42090677781352703 | validation: 0.47414331108524976]
	TIME [epoch: 27.7 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4101603622367864		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.4101603622367864 | validation: 0.5443717298291073]
	TIME [epoch: 27.7 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43217867014864686		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.43217867014864686 | validation: 0.5785575857345449]
	TIME [epoch: 27.7 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44180901136641504		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.44180901136641504 | validation: 0.530311766085851]
	TIME [epoch: 27.7 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4206708484009129		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.4206708484009129 | validation: 0.5290744555111667]
	TIME [epoch: 27.7 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4373107013204035		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.4373107013204035 | validation: 0.47579511819592724]
	TIME [epoch: 27.7 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4267389062093407		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.4267389062093407 | validation: 0.48765176301318675]
	TIME [epoch: 27.7 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4072267270080615		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.4072267270080615 | validation: 0.46646038557505054]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_1063.pth
	Model improved!!!
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4072597445802572		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.4072597445802572 | validation: 0.45731040874207185]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_1064.pth
	Model improved!!!
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4139715195298074		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.4139715195298074 | validation: 0.4794970067515609]
	TIME [epoch: 27.8 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40134256211499886		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.40134256211499886 | validation: 0.47572338400509984]
	TIME [epoch: 27.8 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4143402931047766		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.4143402931047766 | validation: 0.46577663830212723]
	TIME [epoch: 27.8 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4011406846232102		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.4011406846232102 | validation: 0.44590302185274266]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_1068.pth
	Model improved!!!
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44350296959866775		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.44350296959866775 | validation: 0.4765406370425906]
	TIME [epoch: 27.8 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40409364349149635		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.40409364349149635 | validation: 0.46628324995893283]
	TIME [epoch: 27.8 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4115889041708126		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.4115889041708126 | validation: 0.5385209579523753]
	TIME [epoch: 27.8 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4786823036144997		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.4786823036144997 | validation: 0.4719496660899127]
	TIME [epoch: 27.8 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4152758200252226		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.4152758200252226 | validation: 0.46586861130434626]
	TIME [epoch: 27.8 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4213317040735402		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.4213317040735402 | validation: 0.473754599443984]
	TIME [epoch: 27.7 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4273766048415684		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.4273766048415684 | validation: 0.4822038277040494]
	TIME [epoch: 27.8 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4291596026138226		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.4291596026138226 | validation: 0.5256342962718358]
	TIME [epoch: 27.7 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43113429883716503		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.43113429883716503 | validation: 0.48685080018327564]
	TIME [epoch: 27.8 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4154656519349018		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.4154656519349018 | validation: 0.4788846299344009]
	TIME [epoch: 27.8 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4128819145354223		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.4128819145354223 | validation: 0.4716186794664196]
	TIME [epoch: 27.7 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4583698352075685		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.4583698352075685 | validation: 0.4839370959927326]
	TIME [epoch: 27.8 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4238761242731728		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.4238761242731728 | validation: 0.49713044289275216]
	TIME [epoch: 27.7 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41679508356812056		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.41679508356812056 | validation: 0.6336432511540984]
	TIME [epoch: 27.8 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5129100092451859		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.5129100092451859 | validation: 0.4751275360835613]
	TIME [epoch: 27.8 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40862336686696277		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.40862336686696277 | validation: 0.4702358133900084]
	TIME [epoch: 27.8 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4049314942462404		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.4049314942462404 | validation: 0.488978006766222]
	TIME [epoch: 27.8 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47451839611784846		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.47451839611784846 | validation: 0.46837867042473535]
	TIME [epoch: 27.7 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41288333207301364		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.41288333207301364 | validation: 0.47643110503163516]
	TIME [epoch: 27.8 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.422838124567322		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.422838124567322 | validation: 0.4650316072891926]
	TIME [epoch: 27.8 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3931706919612494		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.3931706919612494 | validation: 0.44834760190067935]
	TIME [epoch: 27.7 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3977858324479135		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.3977858324479135 | validation: 0.4609717931730316]
	TIME [epoch: 27.8 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4045829948670317		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.4045829948670317 | validation: 0.5013159842672846]
	TIME [epoch: 27.7 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4371690936868071		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.4371690936868071 | validation: 0.44656194655414566]
	TIME [epoch: 27.8 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45398546544599744		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.45398546544599744 | validation: 0.6626125938646934]
	TIME [epoch: 27.8 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.636561228024676		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.636561228024676 | validation: 0.5146309816478342]
	TIME [epoch: 27.8 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4267892974857798		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.4267892974857798 | validation: 0.4675025217311773]
	TIME [epoch: 27.8 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46366700502264513		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.46366700502264513 | validation: 0.6015439359626678]
	TIME [epoch: 27.8 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46269691049600237		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.46269691049600237 | validation: 0.5270497107711708]
	TIME [epoch: 27.8 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4266107196414721		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.4266107196414721 | validation: 0.5107048917224722]
	TIME [epoch: 27.8 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4201517238412261		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.4201517238412261 | validation: 0.5145393342591429]
	TIME [epoch: 27.7 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45883051078679193		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.45883051078679193 | validation: 0.5103219776047009]
	TIME [epoch: 27.8 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.421948379916643		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.421948379916643 | validation: 0.48975639867327003]
	TIME [epoch: 27.8 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4337203376842711		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.4337203376842711 | validation: 0.5555285489596931]
	TIME [epoch: 27.8 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45230840549686613		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.45230840549686613 | validation: 0.4918758907400873]
	TIME [epoch: 27.8 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41334566634705555		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.41334566634705555 | validation: 0.48618712443802636]
	TIME [epoch: 27.7 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4496472625791249		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.4496472625791249 | validation: 0.4609509488928327]
	TIME [epoch: 27.8 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4194167417816654		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.4194167417816654 | validation: 0.4737715152742434]
	TIME [epoch: 27.8 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40443879919869574		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.40443879919869574 | validation: 0.46266340264918593]
	TIME [epoch: 27.8 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4022370556493027		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.4022370556493027 | validation: 0.4773556886717422]
	TIME [epoch: 27.8 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4092305895412333		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.4092305895412333 | validation: 0.45539470804219895]
	TIME [epoch: 27.8 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4058539668684552		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.4058539668684552 | validation: 0.4937846640733365]
	TIME [epoch: 27.8 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4061456766429947		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.4061456766429947 | validation: 0.4619781164189066]
	TIME [epoch: 27.8 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4143733887498884		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.4143733887498884 | validation: 0.4616979551779174]
	TIME [epoch: 27.7 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.426318079803816		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.426318079803816 | validation: 0.4647294515684434]
	TIME [epoch: 27.8 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4017300148858042		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.4017300148858042 | validation: 0.45034726161416544]
	TIME [epoch: 27.8 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3978426945050021		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.3978426945050021 | validation: 0.46873406696992703]
	TIME [epoch: 27.8 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4253188435766201		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.4253188435766201 | validation: 0.4660069777271286]
	TIME [epoch: 27.7 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4031073245640013		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.4031073245640013 | validation: 0.45039940663312633]
	TIME [epoch: 27.8 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4187296851384427		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.4187296851384427 | validation: 0.45997363048151685]
	TIME [epoch: 27.8 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4031485247214731		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.4031485247214731 | validation: 0.4550453395484672]
	TIME [epoch: 27.7 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41868624839728635		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.41868624839728635 | validation: 0.46042930499872703]
	TIME [epoch: 27.8 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4145093893943819		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.4145093893943819 | validation: 0.5505810902203471]
	TIME [epoch: 27.8 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4207352969739207		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.4207352969739207 | validation: 0.4648533943679435]
	TIME [epoch: 27.8 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4049924276638763		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.4049924276638763 | validation: 0.4473081393249169]
	TIME [epoch: 27.8 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3980039344768604		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.3980039344768604 | validation: 0.46205140217252594]
	TIME [epoch: 27.7 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40113501208575464		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.40113501208575464 | validation: 0.45266228125272795]
	TIME [epoch: 27.7 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4062207387868618		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.4062207387868618 | validation: 0.5976690640541721]
	TIME [epoch: 27.8 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4431981735742836		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.4431981735742836 | validation: 0.4612399808436498]
	TIME [epoch: 27.8 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45791426189536333		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.45791426189536333 | validation: 0.4991103193398992]
	TIME [epoch: 27.8 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41156383231332855		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.41156383231332855 | validation: 0.4406266484713985]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_1129.pth
	Model improved!!!
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3973555420007476		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.3973555420007476 | validation: 0.5229910475368611]
	TIME [epoch: 27.8 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44443426558511334		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.44443426558511334 | validation: 0.45921308375519415]
	TIME [epoch: 27.8 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4192126564841717		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.4192126564841717 | validation: 0.4468460003395231]
	TIME [epoch: 27.8 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3954879010922959		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.3954879010922959 | validation: 0.4630007844624594]
	TIME [epoch: 27.9 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4093078744122537		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.4093078744122537 | validation: 0.5162543701640254]
	TIME [epoch: 27.9 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4042038056293034		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.4042038056293034 | validation: 0.4468814766600801]
	TIME [epoch: 27.9 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3934156011358789		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.3934156011358789 | validation: 0.45643157125571976]
	TIME [epoch: 27.9 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42093447520895544		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.42093447520895544 | validation: 0.5182291824049782]
	TIME [epoch: 27.8 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4166954398995958		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.4166954398995958 | validation: 0.4581281507969571]
	TIME [epoch: 27.8 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4612404915739023		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.4612404915739023 | validation: 0.4684525227490619]
	TIME [epoch: 27.8 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4045813733223862		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.4045813733223862 | validation: 0.4581953871180655]
	TIME [epoch: 27.8 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3899636878143382		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.3899636878143382 | validation: 0.5220246678625194]
	TIME [epoch: 27.8 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4215548549231295		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.4215548549231295 | validation: 0.46496768576077147]
	TIME [epoch: 27.7 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40102919757318		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.40102919757318 | validation: 0.4775934059059217]
	TIME [epoch: 27.8 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4059619325002824		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.4059619325002824 | validation: 0.5259027015846671]
	TIME [epoch: 27.7 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.517984392352218		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.517984392352218 | validation: 0.5377501295061985]
	TIME [epoch: 27.7 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42880227566215423		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.42880227566215423 | validation: 0.4393933315165042]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_1146.pth
	Model improved!!!
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39759366114534284		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.39759366114534284 | validation: 0.44136249534030697]
	TIME [epoch: 27.7 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4250071650869075		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.4250071650869075 | validation: 0.5732257061299919]
	TIME [epoch: 27.8 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5218008782801657		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.5218008782801657 | validation: 0.4617319286863089]
	TIME [epoch: 27.8 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4082308176661261		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.4082308176661261 | validation: 0.46839357884346805]
	TIME [epoch: 27.8 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44585477271690666		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.44585477271690666 | validation: 0.5728593794306102]
	TIME [epoch: 27.8 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4755002646108276		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.4755002646108276 | validation: 0.4370300918172154]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_1152.pth
	Model improved!!!
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40757778070772555		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.40757778070772555 | validation: 0.519978111726928]
	TIME [epoch: 27.8 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43553602208651726		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.43553602208651726 | validation: 0.45292479883989933]
	TIME [epoch: 27.7 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40439503858019854		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.40439503858019854 | validation: 0.45326093593228656]
	TIME [epoch: 27.8 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3992920980322044		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.3992920980322044 | validation: 0.4555593105546833]
	TIME [epoch: 27.8 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40097137196445953		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.40097137196445953 | validation: 0.4560038184546404]
	TIME [epoch: 27.8 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40000163474507366		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.40000163474507366 | validation: 0.4456168433803275]
	TIME [epoch: 27.8 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3976009211665227		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.3976009211665227 | validation: 0.44981583145826143]
	TIME [epoch: 27.8 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40477370177587657		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.40477370177587657 | validation: 0.42865409149724437]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_1160.pth
	Model improved!!!
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39747335768495656		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.39747335768495656 | validation: 0.44148356119848847]
	TIME [epoch: 27.8 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39829467898264465		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.39829467898264465 | validation: 0.43953709217645154]
	TIME [epoch: 27.8 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4278322798989598		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.4278322798989598 | validation: 0.51031817126563]
	TIME [epoch: 27.8 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48032213119076006		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.48032213119076006 | validation: 0.4504204722296713]
	TIME [epoch: 27.8 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40851844863342657		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.40851844863342657 | validation: 0.4241514940384694]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_1165.pth
	Model improved!!!
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42384794100954354		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.42384794100954354 | validation: 0.5754288435929569]
	TIME [epoch: 27.8 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46623928403780834		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.46623928403780834 | validation: 0.49062151325308234]
	TIME [epoch: 27.8 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41515659355782597		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.41515659355782597 | validation: 0.4550155528939628]
	TIME [epoch: 27.8 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40842978183377104		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.40842978183377104 | validation: 0.4561080921792262]
	TIME [epoch: 27.8 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40352445033228523		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.40352445033228523 | validation: 0.4530471789087025]
	TIME [epoch: 27.9 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39417783968377507		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.39417783968377507 | validation: 0.4410781652256598]
	TIME [epoch: 27.9 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.427001317442932		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.427001317442932 | validation: 0.529128249451371]
	TIME [epoch: 27.8 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4222417819313595		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.4222417819313595 | validation: 0.4432872874804589]
	TIME [epoch: 27.9 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39693030829349674		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.39693030829349674 | validation: 0.4425231296024644]
	TIME [epoch: 27.9 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40185216268405227		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.40185216268405227 | validation: 0.4739338813768501]
	TIME [epoch: 27.8 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4389329988842171		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.4389329988842171 | validation: 0.44970072219448937]
	TIME [epoch: 27.9 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3851101630897135		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.3851101630897135 | validation: 0.43846458811745076]
	TIME [epoch: 27.8 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4007751872255372		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.4007751872255372 | validation: 0.48007598905381726]
	TIME [epoch: 27.9 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4025756629805409		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.4025756629805409 | validation: 0.467571795824812]
	TIME [epoch: 27.8 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3954379178375923		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.3954379178375923 | validation: 0.44891485236494816]
	TIME [epoch: 27.8 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39846416759309067		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.39846416759309067 | validation: 0.44470232255048314]
	TIME [epoch: 27.8 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3889996767152365		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.3889996767152365 | validation: 0.46475777914145683]
	TIME [epoch: 27.8 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39141192248798845		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.39141192248798845 | validation: 0.4496649895743123]
	TIME [epoch: 27.8 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3902437741181811		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.3902437741181811 | validation: 0.46576637315881875]
	TIME [epoch: 27.8 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4164552852278985		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.4164552852278985 | validation: 0.4721512347685435]
	TIME [epoch: 27.8 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3989240585790985		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.3989240585790985 | validation: 0.44132490230781957]
	TIME [epoch: 27.8 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38668120974778397		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.38668120974778397 | validation: 0.4403855722592161]
	TIME [epoch: 27.8 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39977810606213793		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.39977810606213793 | validation: 0.5856205556257874]
	TIME [epoch: 27.8 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49283248988142425		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.49283248988142425 | validation: 0.48323665605371774]
	TIME [epoch: 27.8 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44444952805632065		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.44444952805632065 | validation: 0.4858166523241431]
	TIME [epoch: 27.8 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3997402703896036		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.3997402703896036 | validation: 0.43142801239686357]
	TIME [epoch: 27.8 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37930519019384157		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.37930519019384157 | validation: 0.44410049670774626]
	TIME [epoch: 27.8 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4678632510916839		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.4678632510916839 | validation: 0.6073748540082541]
	TIME [epoch: 27.8 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4734752783029429		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.4734752783029429 | validation: 0.45267493801455777]
	TIME [epoch: 27.8 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3934789764156729		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.3934789764156729 | validation: 0.43798313929503513]
	TIME [epoch: 27.7 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3907252326104017		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.3907252326104017 | validation: 0.43737810180041364]
	TIME [epoch: 27.8 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38087078642315586		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.38087078642315586 | validation: 0.46001618974715786]
	TIME [epoch: 27.7 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3898270971612992		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.3898270971612992 | validation: 0.4479209860640225]
	TIME [epoch: 27.8 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3869675753480052		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.3869675753480052 | validation: 0.4440159515548937]
	TIME [epoch: 27.8 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39327447452173936		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.39327447452173936 | validation: 0.4457765223389906]
	TIME [epoch: 27.8 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40489023725567097		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.40489023725567097 | validation: 0.4893792904330046]
	TIME [epoch: 27.8 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4075884876404376		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.4075884876404376 | validation: 0.46379129028263194]
	TIME [epoch: 27.7 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3969016421358951		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.3969016421358951 | validation: 0.4509244531285995]
	TIME [epoch: 27.8 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39158438771407417		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.39158438771407417 | validation: 0.4689145853780311]
	TIME [epoch: 27.8 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3937454316749563		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.3937454316749563 | validation: 0.47379825593313113]
	TIME [epoch: 27.8 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3944940628930742		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.3944940628930742 | validation: 0.4628086718054975]
	TIME [epoch: 27.9 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3911394109263453		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.3911394109263453 | validation: 0.4495368511874282]
	TIME [epoch: 27.7 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3849395933332917		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.3849395933332917 | validation: 0.4444821625970809]
	TIME [epoch: 27.8 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3890956649902698		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.3890956649902698 | validation: 0.45249720978391483]
	TIME [epoch: 27.8 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3841516255017749		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.3841516255017749 | validation: 0.4345099963645372]
	TIME [epoch: 27.7 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39901670800458655		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.39901670800458655 | validation: 0.522547647993605]
	TIME [epoch: 27.7 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4315417809170167		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.4315417809170167 | validation: 0.4489649624723161]
	TIME [epoch: 27.7 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3810058052519954		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.3810058052519954 | validation: 0.4379978565660106]
	TIME [epoch: 27.8 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3849115564802179		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.3849115564802179 | validation: 0.4429882899606766]
	TIME [epoch: 27.8 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3801525013914		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.3801525013914 | validation: 0.43152507917451555]
	TIME [epoch: 27.7 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3911434108005231		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.3911434108005231 | validation: 0.4365511554181298]
	TIME [epoch: 27.8 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38517700486334383		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.38517700486334383 | validation: 0.433118872204374]
	TIME [epoch: 27.7 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3860084315363405		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.3860084315363405 | validation: 0.42244651467423955]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_1218.pth
	Model improved!!!
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37672447625712413		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.37672447625712413 | validation: 0.4392649614972563]
	TIME [epoch: 27.8 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38730713426015356		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.38730713426015356 | validation: 0.4522788254705534]
	TIME [epoch: 27.8 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4275614275366701		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.4275614275366701 | validation: 0.5006819417779224]
	TIME [epoch: 27.8 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4035778120267037		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.4035778120267037 | validation: 0.4353335400588998]
	TIME [epoch: 27.8 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38430676734324504		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.38430676734324504 | validation: 0.43217207833387244]
	TIME [epoch: 27.8 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38201207812490345		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.38201207812490345 | validation: 0.4344138083794439]
	TIME [epoch: 27.7 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39377908657886407		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.39377908657886407 | validation: 0.45462608936834203]
	TIME [epoch: 27.7 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3899122908565494		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.3899122908565494 | validation: 0.44769871510169895]
	TIME [epoch: 27.8 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4060463107677597		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.4060463107677597 | validation: 0.579166560152459]
	TIME [epoch: 27.7 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4470333181522883		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.4470333181522883 | validation: 0.49038159577199003]
	TIME [epoch: 27.8 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.401380986689239		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.401380986689239 | validation: 0.45475214557692495]
	TIME [epoch: 27.8 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3849929619143816		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.3849929619143816 | validation: 0.4470376343573062]
	TIME [epoch: 27.8 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38816355859523166		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.38816355859523166 | validation: 0.45452581201511777]
	TIME [epoch: 27.8 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38031976022007435		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.38031976022007435 | validation: 0.4508679896269311]
	TIME [epoch: 27.7 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38022409931056167		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.38022409931056167 | validation: 0.45555946330159586]
	TIME [epoch: 27.7 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38107428116707265		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.38107428116707265 | validation: 0.46342231785395827]
	TIME [epoch: 27.7 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3781552712346677		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.3781552712346677 | validation: 0.45722812419599934]
	TIME [epoch: 27.8 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40171938964394693		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.40171938964394693 | validation: 0.47693841628037076]
	TIME [epoch: 27.8 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4296309514157728		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.4296309514157728 | validation: 0.5229114478326626]
	TIME [epoch: 27.7 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45082884348956925		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.45082884348956925 | validation: 0.45672193126139243]
	TIME [epoch: 27.7 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3785299781822749		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.3785299781822749 | validation: 0.4462029756747454]
	TIME [epoch: 27.8 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38424862310971963		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.38424862310971963 | validation: 0.4867980375397832]
	TIME [epoch: 27.7 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4044247822936808		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.4044247822936808 | validation: 0.4646333844987154]
	TIME [epoch: 27.8 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39152164016952373		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.39152164016952373 | validation: 0.4611654930445011]
	TIME [epoch: 27.7 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3901185217996876		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.3901185217996876 | validation: 0.4688248722138384]
	TIME [epoch: 27.8 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3886237987642478		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.3886237987642478 | validation: 0.4542172671058152]
	TIME [epoch: 27.9 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3755736787881033		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.3755736787881033 | validation: 0.44703258810679275]
	TIME [epoch: 27.7 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3819123353498501		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.3819123353498501 | validation: 0.44099844925345955]
	TIME [epoch: 27.8 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38050753084102723		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.38050753084102723 | validation: 0.4533332033353451]
	TIME [epoch: 27.8 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3768603834314246		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.3768603834314246 | validation: 0.43835861659021613]
	TIME [epoch: 27.8 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3869654737148832		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.3869654737148832 | validation: 0.4436157480989187]
	TIME [epoch: 27.8 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3978498434303298		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.3978498434303298 | validation: 0.43897551140502394]
	TIME [epoch: 27.8 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38830271243590436		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.38830271243590436 | validation: 0.46309296908831216]
	TIME [epoch: 27.9 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3944928392330261		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.3944928392330261 | validation: 0.4371892868913924]
	TIME [epoch: 27.8 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3841874294543401		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.3841874294543401 | validation: 0.4474358915112277]
	TIME [epoch: 27.8 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3917433944825669		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.3917433944825669 | validation: 0.44833582647403786]
	TIME [epoch: 27.9 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3840015111280462		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.3840015111280462 | validation: 0.44829578942364]
	TIME [epoch: 27.7 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38750033310986587		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.38750033310986587 | validation: 0.44259626129050395]
	TIME [epoch: 27.8 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38321573931589076		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.38321573931589076 | validation: 0.4608132997935413]
	TIME [epoch: 27.8 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37703929602592284		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.37703929602592284 | validation: 0.4357031764039804]
	TIME [epoch: 27.7 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38434217875297844		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.38434217875297844 | validation: 0.49082837248671934]
	TIME [epoch: 27.8 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4074655841938385		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.4074655841938385 | validation: 0.4445775148975588]
	TIME [epoch: 27.8 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38432224368479845		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.38432224368479845 | validation: 0.42859299041107735]
	TIME [epoch: 27.8 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3776614460496108		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.3776614460496108 | validation: 0.42995736833451825]
	TIME [epoch: 27.7 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41567248509000304		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.41567248509000304 | validation: 0.4491989727443406]
	TIME [epoch: 27.7 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4035724981800869		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.4035724981800869 | validation: 0.4959873187863877]
	TIME [epoch: 27.8 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42284894388940847		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.42284894388940847 | validation: 0.4473386979296462]
	TIME [epoch: 27.7 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3864636743173584		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.3864636743173584 | validation: 0.4459743481814483]
	TIME [epoch: 27.8 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3821142886462662		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.3821142886462662 | validation: 0.4511301604916612]
	TIME [epoch: 27.7 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37386033821574083		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.37386033821574083 | validation: 0.4336363145689406]
	TIME [epoch: 27.8 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37945170163729336		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.37945170163729336 | validation: 0.45208591231037604]
	TIME [epoch: 27.7 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37806659377587076		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.37806659377587076 | validation: 0.4677346259019784]
	TIME [epoch: 27.7 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39457649433815933		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.39457649433815933 | validation: 0.44320548969509205]
	TIME [epoch: 27.8 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3855976302008062		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.3855976302008062 | validation: 0.4376114912765042]
	TIME [epoch: 27.8 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38689325208573794		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.38689325208573794 | validation: 0.4504120369139675]
	TIME [epoch: 27.8 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39209922612312526		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.39209922612312526 | validation: 0.4801718077611979]
	TIME [epoch: 27.9 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4334385374026422		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.4334385374026422 | validation: 0.5109600468137783]
	TIME [epoch: 27.8 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43645489624055134		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.43645489624055134 | validation: 0.4600638046392571]
	TIME [epoch: 27.8 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.393725053718874		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.393725053718874 | validation: 0.44965509209142596]
	TIME [epoch: 27.8 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39492074881249706		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.39492074881249706 | validation: 0.45562050258474485]
	TIME [epoch: 27.8 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4232452517235941		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.4232452517235941 | validation: 0.4778521717529985]
	TIME [epoch: 27.8 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4030030668827784		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.4030030668827784 | validation: 0.4460747036403461]
	TIME [epoch: 27.8 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40047567429957676		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.40047567429957676 | validation: 0.5133132637386355]
	TIME [epoch: 27.8 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45565544592330004		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.45565544592330004 | validation: 0.48560152636303194]
	TIME [epoch: 27.8 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39789383461577843		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.39789383461577843 | validation: 0.4487863601030746]
	TIME [epoch: 27.8 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3834315350725883		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.3834315350725883 | validation: 0.45906734178425496]
	TIME [epoch: 27.9 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39888314375003653		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.39888314375003653 | validation: 0.4661536897126379]
	TIME [epoch: 27.8 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37919752456053923		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.37919752456053923 | validation: 0.45667879465015604]
	TIME [epoch: 27.9 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3824402101673317		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.3824402101673317 | validation: 0.4586232411313722]
	TIME [epoch: 27.8 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38423986670281735		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.38423986670281735 | validation: 0.4717305012160821]
	TIME [epoch: 27.8 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4055558284870729		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.4055558284870729 | validation: 0.46533853037722006]
	TIME [epoch: 27.9 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3890803397632858		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.3890803397632858 | validation: 0.469110595479698]
	TIME [epoch: 27.8 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4118956649124343		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.4118956649124343 | validation: 0.48001685175345665]
	TIME [epoch: 27.8 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3768412524354417		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.3768412524354417 | validation: 0.46813781126719173]
	TIME [epoch: 27.8 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4058934541049569		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.4058934541049569 | validation: 0.4819578970093698]
	TIME [epoch: 27.7 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42689616819982185		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.42689616819982185 | validation: 0.45616663826477033]
	TIME [epoch: 27.8 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37811026261998215		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.37811026261998215 | validation: 0.43638599772745085]
	TIME [epoch: 27.8 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37523532119928305		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.37523532119928305 | validation: 0.422408163926408]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_1296.pth
	Model improved!!!
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3753285382060027		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.3753285382060027 | validation: 0.44656698000886863]
	TIME [epoch: 27.8 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3808491787143637		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.3808491787143637 | validation: 0.4240266017391766]
	TIME [epoch: 27.8 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37893082078016355		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.37893082078016355 | validation: 0.4433778506143946]
	TIME [epoch: 27.8 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.391198832507075		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.391198832507075 | validation: 0.48183053592772207]
	TIME [epoch: 27.8 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4075477254057738		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.4075477254057738 | validation: 0.4302785819488932]
	TIME [epoch: 27.9 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38072841435750654		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.38072841435750654 | validation: 0.4574919333426055]
	TIME [epoch: 27.8 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37856467132475385		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.37856467132475385 | validation: 0.4593516903691618]
	TIME [epoch: 27.8 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3842925677655533		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.3842925677655533 | validation: 0.4499544249495874]
	TIME [epoch: 27.9 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3928146792933592		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.3928146792933592 | validation: 0.4365545742335686]
	TIME [epoch: 27.8 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.377589172049267		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.377589172049267 | validation: 0.43563470116584346]
	TIME [epoch: 27.8 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3774707477291381		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.3774707477291381 | validation: 0.44298049671484435]
	TIME [epoch: 27.8 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38140719481012353		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.38140719481012353 | validation: 0.4332689880355885]
	TIME [epoch: 27.8 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37659321481008695		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.37659321481008695 | validation: 0.4365684780410861]
	TIME [epoch: 27.9 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3937881289317229		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.3937881289317229 | validation: 0.4636400653764773]
	TIME [epoch: 27.8 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3873391152981077		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.3873391152981077 | validation: 0.4568228746977222]
	TIME [epoch: 27.8 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3974570076688863		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.3974570076688863 | validation: 0.45444475915322513]
	TIME [epoch: 27.8 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3977787326890597		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.3977787326890597 | validation: 0.4657310550340759]
	TIME [epoch: 27.8 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3906314989909875		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.3906314989909875 | validation: 0.4410500430115863]
	TIME [epoch: 27.8 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3722619953344266		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.3722619953344266 | validation: 0.4487388327031615]
	TIME [epoch: 27.8 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38331044995322533		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.38331044995322533 | validation: 0.4356341166383679]
	TIME [epoch: 27.9 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3736304930099329		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.3736304930099329 | validation: 0.4408311839434602]
	TIME [epoch: 27.8 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37191138459435025		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.37191138459435025 | validation: 0.4449154172344869]
	TIME [epoch: 27.9 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3771326146166826		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.3771326146166826 | validation: 0.43649111329044343]
	TIME [epoch: 27.8 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3740062938035522		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.3740062938035522 | validation: 0.4333345326337649]
	TIME [epoch: 27.9 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3779941855799161		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.3779941855799161 | validation: 0.4470284908641651]
	TIME [epoch: 27.8 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37377479395305513		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.37377479395305513 | validation: 0.4372532661597505]
	TIME [epoch: 27.9 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3795928074971538		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.3795928074971538 | validation: 0.4384978878561144]
	TIME [epoch: 27.8 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3780867680997183		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.3780867680997183 | validation: 0.4274896391458423]
	TIME [epoch: 27.9 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37948533105754173		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.37948533105754173 | validation: 0.4285640655482932]
	TIME [epoch: 27.8 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3820333690349093		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.3820333690349093 | validation: 0.45274174807289547]
	TIME [epoch: 27.9 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39071163636881806		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.39071163636881806 | validation: 0.428205458839506]
	TIME [epoch: 27.8 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.377913382145028		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.377913382145028 | validation: 0.4496167279541232]
	TIME [epoch: 27.8 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3786986483154768		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.3786986483154768 | validation: 0.4549594601165955]
	TIME [epoch: 27.9 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38934599317369045		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.38934599317369045 | validation: 0.4334650898126683]
	TIME [epoch: 27.8 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3768729458396066		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.3768729458396066 | validation: 0.43050238721386463]
	TIME [epoch: 27.8 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38351436712146153		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.38351436712146153 | validation: 0.4452293956596992]
	TIME [epoch: 27.9 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4043124534525608		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.4043124534525608 | validation: 0.49055680830471915]
	TIME [epoch: 27.8 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4055477787259139		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.4055477787259139 | validation: 0.42522943601180985]
	TIME [epoch: 27.9 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3713750844163164		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.3713750844163164 | validation: 0.4327257585507172]
	TIME [epoch: 27.9 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39504963641017476		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.39504963641017476 | validation: 0.4390605678720233]
	TIME [epoch: 27.8 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3809999619160234		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.3809999619160234 | validation: 0.4377346199586113]
	TIME [epoch: 27.9 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3817578180627652		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.3817578180627652 | validation: 0.4183058374071782]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_1338.pth
	Model improved!!!
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3811419572660595		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.3811419572660595 | validation: 0.41828926608758055]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_1339.pth
	Model improved!!!
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37524039458991104		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.37524039458991104 | validation: 0.4505956529413973]
	TIME [epoch: 27.8 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41096268850315915		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.41096268850315915 | validation: 0.487858939264714]
	TIME [epoch: 27.7 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4006977360068659		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.4006977360068659 | validation: 0.42988027796876505]
	TIME [epoch: 27.8 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3781781096374434		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.3781781096374434 | validation: 0.4295152060744137]
	TIME [epoch: 27.7 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3757379096260811		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.3757379096260811 | validation: 0.4282316342425624]
	TIME [epoch: 27.8 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3717376937727187		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.3717376937727187 | validation: 0.43412115671750523]
	TIME [epoch: 27.7 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3844289583871962		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.3844289583871962 | validation: 0.43590137966426595]
	TIME [epoch: 27.7 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.374581838004054		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.374581838004054 | validation: 0.4255320831429383]
	TIME [epoch: 27.7 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3806118651846436		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.3806118651846436 | validation: 0.4614540213214133]
	TIME [epoch: 27.8 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41213428522646695		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.41213428522646695 | validation: 0.4449866222802962]
	TIME [epoch: 27.8 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3773812693298877		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.3773812693298877 | validation: 0.4519898648673001]
	TIME [epoch: 27.8 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3835819491589074		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.3835819491589074 | validation: 0.44127530844289214]
	TIME [epoch: 27.7 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3824555889960121		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.3824555889960121 | validation: 0.4846393394249581]
	TIME [epoch: 27.8 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42222221149582495		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.42222221149582495 | validation: 0.5000238795272792]
	TIME [epoch: 27.8 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43815521305425026		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.43815521305425026 | validation: 0.45790681598024235]
	TIME [epoch: 27.8 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38738848500640644		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.38738848500640644 | validation: 0.4344933751382584]
	TIME [epoch: 27.8 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4014349645556993		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.4014349645556993 | validation: 0.47840303560062053]
	TIME [epoch: 27.7 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39280544000692674		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.39280544000692674 | validation: 0.4436782923538115]
	TIME [epoch: 27.8 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3750980905985989		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.3750980905985989 | validation: 0.4331126206630603]
	TIME [epoch: 27.8 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3726553753195258		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.3726553753195258 | validation: 0.43226214271089985]
	TIME [epoch: 27.8 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3743766587001178		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.3743766587001178 | validation: 0.44694957177422295]
	TIME [epoch: 27.8 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3720884651391244		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.3720884651391244 | validation: 0.4286425826314886]
	TIME [epoch: 27.7 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.374275319711449		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.374275319711449 | validation: 0.44848694146855594]
	TIME [epoch: 27.8 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37324951022704983		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.37324951022704983 | validation: 0.44742627913100225]
	TIME [epoch: 27.7 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37754204244351186		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.37754204244351186 | validation: 0.4486322610410987]
	TIME [epoch: 27.7 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37786179018050925		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.37786179018050925 | validation: 0.4354132671951214]
	TIME [epoch: 27.8 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3754829514687038		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.3754829514687038 | validation: 0.42806109677814563]
	TIME [epoch: 27.7 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37775952237677823		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.37775952237677823 | validation: 0.4588573339165775]
	TIME [epoch: 27.8 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4039219670988467		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.4039219670988467 | validation: 0.4435228148382062]
	TIME [epoch: 27.7 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37134017936210784		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.37134017936210784 | validation: 0.4236422040508816]
	TIME [epoch: 27.8 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3738201321675566		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.3738201321675566 | validation: 0.4282022155274576]
	TIME [epoch: 27.7 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3713700154872167		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.3713700154872167 | validation: 0.43630766791133097]
	TIME [epoch: 27.8 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3684872062688156		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.3684872062688156 | validation: 0.4456849254432511]
	TIME [epoch: 27.8 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38338268863148994		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.38338268863148994 | validation: 0.4405120015575754]
	TIME [epoch: 27.8 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37120427712523607		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.37120427712523607 | validation: 0.4546231836534784]
	TIME [epoch: 27.8 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3846897723377484		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.3846897723377484 | validation: 0.4590207202808936]
	TIME [epoch: 27.8 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38439758251679246		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.38439758251679246 | validation: 0.45587062951744595]
	TIME [epoch: 27.8 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3971022374315398		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.3971022374315398 | validation: 0.45191188925590875]
	TIME [epoch: 27.8 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3729789128304001		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.3729789128304001 | validation: 0.4453612981481699]
	TIME [epoch: 27.8 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3765736383532657		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.3765736383532657 | validation: 0.43120816637580334]
	TIME [epoch: 27.8 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38862194300373665		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.38862194300373665 | validation: 0.444725757715631]
	TIME [epoch: 27.8 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3884683071769795		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.3884683071769795 | validation: 0.44234149329959255]
	TIME [epoch: 27.7 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.390805751020086		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.390805751020086 | validation: 0.4649352494762545]
	TIME [epoch: 27.7 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3939216037220795		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.3939216037220795 | validation: 0.43272841318540034]
	TIME [epoch: 27.8 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.378696417160335		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.378696417160335 | validation: 0.43649861991814076]
	TIME [epoch: 27.8 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3682585522948907		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.3682585522948907 | validation: 0.436237069670769]
	TIME [epoch: 27.8 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37455751774535373		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.37455751774535373 | validation: 0.4308563686434287]
	TIME [epoch: 27.8 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36876825758470233		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.36876825758470233 | validation: 0.42723661218522974]
	TIME [epoch: 27.8 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.372424641943345		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.372424641943345 | validation: 0.42584307243551095]
	TIME [epoch: 27.8 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3732121229645807		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.3732121229645807 | validation: 0.43225645983893823]
	TIME [epoch: 27.9 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36748559669178826		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.36748559669178826 | validation: 0.4284323120392001]
	TIME [epoch: 27.8 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37861532637238393		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.37861532637238393 | validation: 0.4385959987891587]
	TIME [epoch: 27.8 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3731687630108049		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.3731687630108049 | validation: 0.426658843438952]
	TIME [epoch: 27.8 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3651832856502615		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.3651832856502615 | validation: 0.4282154847546002]
	TIME [epoch: 27.8 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38374879846061355		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.38374879846061355 | validation: 0.46613396394052187]
	TIME [epoch: 27.8 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41889564589003125		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.41889564589003125 | validation: 0.4787119911417695]
	TIME [epoch: 27.8 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40075279663821883		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.40075279663821883 | validation: 0.4674699542314399]
	TIME [epoch: 27.7 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37463765310258385		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.37463765310258385 | validation: 0.44624913576391406]
	TIME [epoch: 27.8 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38013346936961195		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.38013346936961195 | validation: 0.43763619049614927]
	TIME [epoch: 27.8 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3792069035551243		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.3792069035551243 | validation: 0.4405406548519701]
	TIME [epoch: 27.7 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3886539617647523		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.3886539617647523 | validation: 0.4761314293985505]
	TIME [epoch: 27.8 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38089122187246494		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.38089122187246494 | validation: 0.45453285450741576]
	TIME [epoch: 27.8 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3854606551214006		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.3854606551214006 | validation: 0.43910147272264033]
	TIME [epoch: 27.8 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3787781427783319		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.3787781427783319 | validation: 0.4696885303031645]
	TIME [epoch: 27.8 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39057601321445845		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.39057601321445845 | validation: 0.45987936766143356]
	TIME [epoch: 27.8 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37688892178021566		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.37688892178021566 | validation: 0.4314062623838232]
	TIME [epoch: 27.8 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3713296666836496		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.3713296666836496 | validation: 0.4359462800402855]
	TIME [epoch: 27.7 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3658883810902478		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.3658883810902478 | validation: 0.44404489800885244]
	TIME [epoch: 27.7 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3787958956758683		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.3787958956758683 | validation: 0.4450541839100828]
	TIME [epoch: 27.7 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37388346135488404		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.37388346135488404 | validation: 0.43065934484805396]
	TIME [epoch: 27.8 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3720563875151429		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.3720563875151429 | validation: 0.46443467017547874]
	TIME [epoch: 27.8 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4010401112793081		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.4010401112793081 | validation: 0.46668919568508443]
	TIME [epoch: 27.7 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38189097432066754		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.38189097432066754 | validation: 0.4319681907892281]
	TIME [epoch: 27.8 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36921937957467404		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.36921937957467404 | validation: 0.4265701710854982]
	TIME [epoch: 27.8 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37198561662297014		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.37198561662297014 | validation: 0.42734444402208227]
	TIME [epoch: 27.9 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37602943726253496		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.37602943726253496 | validation: 0.4309072501145079]
	TIME [epoch: 27.9 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37338915154325536		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.37338915154325536 | validation: 0.42672511336968344]
	TIME [epoch: 27.8 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38415957437792925		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.38415957437792925 | validation: 0.4628241862649789]
	TIME [epoch: 27.8 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39481589922850063		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.39481589922850063 | validation: 0.43800458187817365]
	TIME [epoch: 27.8 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3777474328580152		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.3777474328580152 | validation: 0.4273929067665022]
	TIME [epoch: 27.8 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38650150332899197		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.38650150332899197 | validation: 0.4448529293974455]
	TIME [epoch: 27.8 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38057293378445234		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.38057293378445234 | validation: 0.41822534347709633]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_1421.pth
	Model improved!!!
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36887840097899577		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.36887840097899577 | validation: 0.4218574601456814]
	TIME [epoch: 27.9 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3715161146531394		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.3715161146531394 | validation: 0.4308630228748537]
	TIME [epoch: 27.8 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3718013931827687		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.3718013931827687 | validation: 0.41958194131057797]
	TIME [epoch: 27.8 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3767893525718581		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.3767893525718581 | validation: 0.42465079050856874]
	TIME [epoch: 27.8 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37352391379932515		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.37352391379932515 | validation: 0.44702448134201433]
	TIME [epoch: 27.8 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39571950768250486		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.39571950768250486 | validation: 0.41711946214985335]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_1427.pth
	Model improved!!!
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3713407224443587		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.3713407224443587 | validation: 0.4343273565304973]
	TIME [epoch: 27.8 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3753789672621948		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.3753789672621948 | validation: 0.44174458306256215]
	TIME [epoch: 27.7 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39002761898007665		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.39002761898007665 | validation: 0.4422024951829182]
	TIME [epoch: 27.9 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.376850862609729		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.376850862609729 | validation: 0.41906903000163925]
	TIME [epoch: 27.7 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37332841369283		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.37332841369283 | validation: 0.43692256199793633]
	TIME [epoch: 27.8 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36859048435129077		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.36859048435129077 | validation: 0.4157462843435104]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_1433.pth
	Model improved!!!
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3685188896006404		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.3685188896006404 | validation: 0.4497385539219814]
	TIME [epoch: 27.7 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3964524382337187		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.3964524382337187 | validation: 0.4713310895943124]
	TIME [epoch: 27.8 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3970343615114578		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.3970343615114578 | validation: 0.4385421369193509]
	TIME [epoch: 27.9 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3814706413115304		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.3814706413115304 | validation: 0.4270841427560796]
	TIME [epoch: 27.9 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3733709873139862		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.3733709873139862 | validation: 0.4257470542444976]
	TIME [epoch: 27.8 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37211004312856977		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.37211004312856977 | validation: 0.4414332708303418]
	TIME [epoch: 27.7 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38466364915167567		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.38466364915167567 | validation: 0.4401378004684597]
	TIME [epoch: 27.8 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3784371448223211		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.3784371448223211 | validation: 0.42611294265598054]
	TIME [epoch: 27.7 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36601583490964174		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.36601583490964174 | validation: 0.46417652749948574]
	TIME [epoch: 27.8 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38919930989611057		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.38919930989611057 | validation: 0.439922024535303]
	TIME [epoch: 27.8 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3661541424959194		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.3661541424959194 | validation: 0.4256706104738963]
	TIME [epoch: 27.8 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37456191838072217		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.37456191838072217 | validation: 0.4612688615743471]
	TIME [epoch: 27.8 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3874019170857569		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.3874019170857569 | validation: 0.46824695214188317]
	TIME [epoch: 27.7 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41115978344409887		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.41115978344409887 | validation: 0.5053027062370868]
	TIME [epoch: 27.8 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3996535243189738		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.3996535243189738 | validation: 0.44783015491915223]
	TIME [epoch: 27.8 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37103384254156657		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.37103384254156657 | validation: 0.44181651931854393]
	TIME [epoch: 27.8 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3708013833203896		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.3708013833203896 | validation: 0.4388760841375606]
	TIME [epoch: 27.9 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3658962637942801		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.3658962637942801 | validation: 0.4232058392339743]
	TIME [epoch: 27.8 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3737680491748835		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.3737680491748835 | validation: 0.44936243914211055]
	TIME [epoch: 27.9 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3782657321325895		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.3782657321325895 | validation: 0.4246647717196716]
	TIME [epoch: 27.8 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37439414202240545		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.37439414202240545 | validation: 0.4280619451626202]
	TIME [epoch: 27.8 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3747001611476985		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.3747001611476985 | validation: 0.43828614729850857]
	TIME [epoch: 27.9 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3759409398767429		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.3759409398767429 | validation: 0.4389068083453714]
	TIME [epoch: 27.8 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38172889077830957		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.38172889077830957 | validation: 0.44986072222508255]
	TIME [epoch: 27.9 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3698203591464329		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.3698203591464329 | validation: 0.4433446635853862]
	TIME [epoch: 27.9 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37127035900253075		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.37127035900253075 | validation: 0.447892863096956]
	TIME [epoch: 27.8 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3868241069286662		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.3868241069286662 | validation: 0.47588597442224634]
	TIME [epoch: 27.8 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3815735148100523		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.3815735148100523 | validation: 0.4402163060468594]
	TIME [epoch: 27.8 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36983482091878794		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.36983482091878794 | validation: 0.42770679303501047]
	TIME [epoch: 27.8 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3701337150251176		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.3701337150251176 | validation: 0.44012201296447273]
	TIME [epoch: 27.8 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38136221097236717		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.38136221097236717 | validation: 0.46177376745685667]
	TIME [epoch: 27.8 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41623991712055114		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.41623991712055114 | validation: 0.49662667661345267]
	TIME [epoch: 27.9 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40987779674260655		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.40987779674260655 | validation: 0.45532270562451715]
	TIME [epoch: 27.8 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3819669887877635		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.3819669887877635 | validation: 0.4291331488949932]
	TIME [epoch: 27.8 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36929352469440146		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.36929352469440146 | validation: 0.44824375616262385]
	TIME [epoch: 27.8 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3736308926966871		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.3736308926966871 | validation: 0.43503348601109426]
	TIME [epoch: 27.8 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3667560397561356		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.3667560397561356 | validation: 0.4233254443892333]
	TIME [epoch: 27.8 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3665773230774605		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.3665773230774605 | validation: 0.4320438630887459]
	TIME [epoch: 27.8 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.366482269466812		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.366482269466812 | validation: 0.4192387776883602]
	TIME [epoch: 27.8 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36410462278025796		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.36410462278025796 | validation: 0.4394087437461306]
	TIME [epoch: 27.8 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36230672620032567		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.36230672620032567 | validation: 0.4382709354882895]
	TIME [epoch: 27.8 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36647450138847376		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.36647450138847376 | validation: 0.42606292785305117]
	TIME [epoch: 27.9 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3739412285780431		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.3739412285780431 | validation: 0.4364939095902331]
	TIME [epoch: 27.8 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38488234458077936		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.38488234458077936 | validation: 0.43948249573474696]
	TIME [epoch: 27.8 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.373222351084749		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.373222351084749 | validation: 0.43513079147299294]
	TIME [epoch: 27.8 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.364970715618102		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.364970715618102 | validation: 0.42823084720619065]
	TIME [epoch: 27.7 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.362678538213689		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.362678538213689 | validation: 0.4340688361738906]
	TIME [epoch: 27.8 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36680269241676616		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.36680269241676616 | validation: 0.4277140058220783]
	TIME [epoch: 27.8 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3656442548332597		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.3656442548332597 | validation: 0.43660329998330966]
	TIME [epoch: 27.8 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3769788619830056		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.3769788619830056 | validation: 0.42638905001648975]
	TIME [epoch: 27.8 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36554401096173267		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.36554401096173267 | validation: 0.4338239757770462]
	TIME [epoch: 27.8 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3601093490981078		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.3601093490981078 | validation: 0.4243426173205252]
	TIME [epoch: 27.9 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35937684137440185		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.35937684137440185 | validation: 0.4276268237175859]
	TIME [epoch: 27.8 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3692482376789153		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.3692482376789153 | validation: 0.41824057960831523]
	TIME [epoch: 27.8 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3705136302552209		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.3705136302552209 | validation: 0.42678567661385786]
	TIME [epoch: 27.7 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.368298467784401		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.368298467784401 | validation: 0.41559311899373447]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_1489.pth
	Model improved!!!
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37377035136582426		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.37377035136582426 | validation: 0.42801959037022536]
	TIME [epoch: 27.8 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3740673079159303		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.3740673079159303 | validation: 0.4210701466989722]
	TIME [epoch: 27.8 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3594011062708383		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.3594011062708383 | validation: 0.4148486440578578]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_1492.pth
	Model improved!!!
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3759971449555431		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.3759971449555431 | validation: 0.4440716872296548]
	TIME [epoch: 27.7 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3739752987492717		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.3739752987492717 | validation: 0.4219716175875407]
	TIME [epoch: 27.7 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36839789760400876		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.36839789760400876 | validation: 0.4149114390891259]
	TIME [epoch: 27.9 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3633494475345715		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.3633494475345715 | validation: 0.4194976238835633]
	TIME [epoch: 27.7 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.359614324369531		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.359614324369531 | validation: 0.43023162334559345]
	TIME [epoch: 27.7 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3655634432054554		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.3655634432054554 | validation: 0.4249158328023334]
	TIME [epoch: 27.8 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3601708125451594		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.3601708125451594 | validation: 0.4185711112168575]
	TIME [epoch: 27.7 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35684092402593637		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.35684092402593637 | validation: 0.4251926385495432]
	TIME [epoch: 27.9 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36804188709357516		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.36804188709357516 | validation: 0.43325655272470215]
	TIME [epoch: 27.8 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36396308532654154		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.36396308532654154 | validation: 0.4252948449529133]
	TIME [epoch: 27.8 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3627215771360273		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.3627215771360273 | validation: 0.4374361260896696]
	TIME [epoch: 27.8 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3797668210277443		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.3797668210277443 | validation: 0.4499191215671081]
	TIME [epoch: 27.7 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36800496579534875		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.36800496579534875 | validation: 0.41761077407132813]
	TIME [epoch: 27.8 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36246007793635704		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.36246007793635704 | validation: 0.41833250107980013]
	TIME [epoch: 27.9 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36674315704053095		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.36674315704053095 | validation: 0.4279300731828184]
	TIME [epoch: 27.7 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36510312446597293		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.36510312446597293 | validation: 0.42829061116031897]
	TIME [epoch: 27.9 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3631283081715137		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.3631283081715137 | validation: 0.430852738676526]
	TIME [epoch: 27.7 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3609469651791422		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.3609469651791422 | validation: 0.4429585284898958]
	TIME [epoch: 27.8 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3674787944708172		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.3674787944708172 | validation: 0.4302998850662407]
	TIME [epoch: 27.8 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3676126391775749		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.3676126391775749 | validation: 0.42458995451432685]
	TIME [epoch: 27.8 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3666455614903694		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.3666455614903694 | validation: 0.4334724319420944]
	TIME [epoch: 27.8 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3684032163741479		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.3684032163741479 | validation: 0.42571317825912575]
	TIME [epoch: 27.8 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3728665734337145		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.3728665734337145 | validation: 0.45348670170454725]
	TIME [epoch: 27.8 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3935315136269354		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.3935315136269354 | validation: 0.44521241555502555]
	TIME [epoch: 27.8 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3759801542806048		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.3759801542806048 | validation: 0.4418148912409582]
	TIME [epoch: 27.8 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3628927384634564		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.3628927384634564 | validation: 0.4178183723947318]
	TIME [epoch: 27.9 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3638165310999372		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.3638165310999372 | validation: 0.42927223838252365]
	TIME [epoch: 27.7 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3615300846799569		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.3615300846799569 | validation: 0.4375167870119546]
	TIME [epoch: 27.8 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36735281450922613		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.36735281450922613 | validation: 0.43569267371761927]
	TIME [epoch: 27.8 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36758389689175186		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.36758389689175186 | validation: 0.43615187850044423]
	TIME [epoch: 27.8 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36951442614705804		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.36951442614705804 | validation: 0.41469010267136514]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_1523.pth
	Model improved!!!
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3620219203191325		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.3620219203191325 | validation: 0.41353638191921266]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_1524.pth
	Model improved!!!
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3628621644221162		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.3628621644221162 | validation: 0.4359788557163748]
	TIME [epoch: 27.8 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38052757459674347		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.38052757459674347 | validation: 0.4561660168722619]
	TIME [epoch: 27.8 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37540081024108385		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.37540081024108385 | validation: 0.4215673954900512]
	TIME [epoch: 27.8 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3715286037509916		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.3715286037509916 | validation: 0.4427915498207598]
	TIME [epoch: 27.8 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37065373222363757		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.37065373222363757 | validation: 0.4385470653635432]
	TIME [epoch: 27.8 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36082107453005596		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.36082107453005596 | validation: 0.4222303715910471]
	TIME [epoch: 27.8 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35859538910579464		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.35859538910579464 | validation: 0.425657941038367]
	TIME [epoch: 27.8 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35909546852101665		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.35909546852101665 | validation: 0.4161648169445819]
	TIME [epoch: 27.8 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3602190577799522		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.3602190577799522 | validation: 0.42040542913956475]
	TIME [epoch: 27.8 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3603995567213924		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.3603995567213924 | validation: 0.4237195281119459]
	TIME [epoch: 27.8 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35874486135574046		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.35874486135574046 | validation: 0.4334990578392146]
	TIME [epoch: 27.8 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36422386926535133		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.36422386926535133 | validation: 0.4230850238839987]
	TIME [epoch: 27.8 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3705214393578554		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.3705214393578554 | validation: 0.42691482571582356]
	TIME [epoch: 27.8 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3705542479915721		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.3705542479915721 | validation: 0.4197424549499117]
	TIME [epoch: 27.8 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3744222666253273		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.3744222666253273 | validation: 0.4282372005558278]
	TIME [epoch: 27.8 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36533649939972485		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.36533649939972485 | validation: 0.41628698806587927]
	TIME [epoch: 27.8 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3660352581574974		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.3660352581574974 | validation: 0.41361058633209125]
	TIME [epoch: 27.8 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3653181126138355		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.3653181126138355 | validation: 0.4126848585468346]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_1542.pth
	Model improved!!!
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3581575486319225		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.3581575486319225 | validation: 0.4103228749883917]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_1543.pth
	Model improved!!!
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36071360635935246		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.36071360635935246 | validation: 0.4162420592316552]
	TIME [epoch: 27.8 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3605047232714288		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.3605047232714288 | validation: 0.4180434247063059]
	TIME [epoch: 27.8 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35914391390923034		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.35914391390923034 | validation: 0.4317004533366237]
	TIME [epoch: 27.8 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37667032747531853		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.37667032747531853 | validation: 0.42941146380700285]
	TIME [epoch: 27.8 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3663152313241388		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.3663152313241388 | validation: 0.4266976033242396]
	TIME [epoch: 27.9 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3642381126144207		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.3642381126144207 | validation: 0.4218145787635888]
	TIME [epoch: 27.8 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36294724766047914		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.36294724766047914 | validation: 0.4206202146586352]
	TIME [epoch: 27.8 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3650455670253204		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.3650455670253204 | validation: 0.4283115000549866]
	TIME [epoch: 27.8 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3779294107861339		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.3779294107861339 | validation: 0.43933041701121406]
	TIME [epoch: 27.8 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38499200255034965		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.38499200255034965 | validation: 0.42447430389859736]
	TIME [epoch: 27.8 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3582886094499029		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.3582886094499029 | validation: 0.40174696077776445]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_1554.pth
	Model improved!!!
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36460566365604985		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.36460566365604985 | validation: 0.42071017892000384]
	TIME [epoch: 27.8 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36834672532222257		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.36834672532222257 | validation: 0.4126564581498869]
	TIME [epoch: 27.9 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36640623498121716		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.36640623498121716 | validation: 0.4274256750120071]
	TIME [epoch: 27.8 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.368677060592522		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.368677060592522 | validation: 0.4174959180510067]
	TIME [epoch: 27.9 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3585905761593994		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.3585905761593994 | validation: 0.4354248019307514]
	TIME [epoch: 27.9 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.366600933821538		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.366600933821538 | validation: 0.42090186265343044]
	TIME [epoch: 27.8 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36122754809878443		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.36122754809878443 | validation: 0.434566037047072]
	TIME [epoch: 27.9 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3626537529683676		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.3626537529683676 | validation: 0.42556120240917567]
	TIME [epoch: 27.8 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3605590059579363		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.3605590059579363 | validation: 0.4219428231380165]
	TIME [epoch: 27.9 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3607875086272041		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.3607875086272041 | validation: 0.4345714650017826]
	TIME [epoch: 27.9 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3658932842975154		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.3658932842975154 | validation: 0.42915786063924943]
	TIME [epoch: 27.8 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36955586891572256		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.36955586891572256 | validation: 0.41900575230553705]
	TIME [epoch: 27.9 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3567711460678636		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.3567711460678636 | validation: 0.4179130886732838]
	TIME [epoch: 27.8 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37179589191287776		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.37179589191287776 | validation: 0.4337780449179445]
	TIME [epoch: 27.8 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36604720906232047		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.36604720906232047 | validation: 0.43264615717433175]
	TIME [epoch: 27.9 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3720363458459177		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.3720363458459177 | validation: 0.4329111788335301]
	TIME [epoch: 27.8 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36335501009955745		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.36335501009955745 | validation: 0.4283661176132458]
	TIME [epoch: 27.9 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3636502615914957		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.3636502615914957 | validation: 0.4346112299315735]
	TIME [epoch: 27.8 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36158037912049235		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.36158037912049235 | validation: 0.43875915350788547]
	TIME [epoch: 27.9 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3656496743367794		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.3656496743367794 | validation: 0.43277963925167506]
	TIME [epoch: 27.9 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36559196776770503		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.36559196776770503 | validation: 0.43716973838443096]
	TIME [epoch: 27.8 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3673577998005185		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.3673577998005185 | validation: 0.4378748567252666]
	TIME [epoch: 27.9 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3652582054239653		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.3652582054239653 | validation: 0.4334200721665297]
	TIME [epoch: 27.9 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3635220794643078		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.3635220794643078 | validation: 0.4350961961444431]
	TIME [epoch: 27.8 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35953463487727166		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.35953463487727166 | validation: 0.423977258355783]
	TIME [epoch: 27.9 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36401841180014244		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.36401841180014244 | validation: 0.42338631728019394]
	TIME [epoch: 27.8 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35985952635165236		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.35985952635165236 | validation: 0.4221581135003696]
	TIME [epoch: 27.8 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.358605265112621		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.358605265112621 | validation: 0.41741105629316866]
	TIME [epoch: 27.8 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3623974043655665		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.3623974043655665 | validation: 0.4245095109809529]
	TIME [epoch: 27.8 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.362245608346331		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.362245608346331 | validation: 0.4168737863596912]
	TIME [epoch: 27.8 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35854385747915063		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.35854385747915063 | validation: 0.420499288940877]
	TIME [epoch: 27.8 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3661937449453151		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.3661937449453151 | validation: 0.4296549184916678]
	TIME [epoch: 27.9 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3721401301174796		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.3721401301174796 | validation: 0.43419723846562674]
	TIME [epoch: 27.8 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37633203921181135		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.37633203921181135 | validation: 0.4357919284738788]
	TIME [epoch: 27.8 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37717488100938046		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.37717488100938046 | validation: 0.43729788910479633]
	TIME [epoch: 27.8 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3591978652954093		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.3591978652954093 | validation: 0.4293786950836698]
	TIME [epoch: 27.8 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36550338663116266		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.36550338663116266 | validation: 0.4306528175201726]
	TIME [epoch: 27.9 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3763398666383677		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.3763398666383677 | validation: 0.44842678396763985]
	TIME [epoch: 27.8 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3823001807156466		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.3823001807156466 | validation: 0.425799822341323]
	TIME [epoch: 27.8 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3675640693729376		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.3675640693729376 | validation: 0.4337773816786994]
	TIME [epoch: 27.9 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36304624865258894		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.36304624865258894 | validation: 0.4169870180303535]
	TIME [epoch: 27.8 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3628715544803567		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.3628715544803567 | validation: 0.4131634198371954]
	TIME [epoch: 27.8 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35816630164870367		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.35816630164870367 | validation: 0.4250310532897626]
	TIME [epoch: 27.8 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.362987842511391		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.362987842511391 | validation: 0.42045957813496015]
	TIME [epoch: 27.8 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36015123388897685		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.36015123388897685 | validation: 0.4255757454637181]
	TIME [epoch: 27.8 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3580269489941718		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.3580269489941718 | validation: 0.43013869521154446]
	TIME [epoch: 27.8 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3601453699513479		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.3601453699513479 | validation: 0.41488883087926587]
	TIME [epoch: 27.8 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3623615279555893		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.3623615279555893 | validation: 0.40755224281534796]
	TIME [epoch: 27.8 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3606967414558051		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.3606967414558051 | validation: 0.4184437788260578]
	TIME [epoch: 27.8 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3690956627687199		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.3690956627687199 | validation: 0.4279863040532418]
	TIME [epoch: 27.9 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3803615852198947		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.3803615852198947 | validation: 0.43769542358179425]
	TIME [epoch: 27.8 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36988892486036384		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.36988892486036384 | validation: 0.43609270712023235]
	TIME [epoch: 27.8 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3712139315975347		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.3712139315975347 | validation: 0.4291866956110982]
	TIME [epoch: 27.8 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3586151779193563		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.3586151779193563 | validation: 0.42662376425075776]
	TIME [epoch: 27.8 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3626055585025534		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.3626055585025534 | validation: 0.41736121817183597]
	TIME [epoch: 27.8 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3558522670985679		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.3558522670985679 | validation: 0.4119837899969497]
	TIME [epoch: 27.7 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35944555451522364		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.35944555451522364 | validation: 0.4170960218985792]
	TIME [epoch: 27.8 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35346153962086624		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.35346153962086624 | validation: 0.42659222443109446]
	TIME [epoch: 27.8 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35744984635584637		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.35744984635584637 | validation: 0.4258181841983222]
	TIME [epoch: 27.8 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36133097720543594		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.36133097720543594 | validation: 0.41756151245618583]
	TIME [epoch: 27.8 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36918245053212095		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.36918245053212095 | validation: 0.41335164510087224]
	TIME [epoch: 27.8 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36165840679983324		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.36165840679983324 | validation: 0.4116378688948637]
	TIME [epoch: 27.9 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35825059858936015		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.35825059858936015 | validation: 0.41454212796014234]
	TIME [epoch: 27.9 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3582833478220091		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.3582833478220091 | validation: 0.42071407290034724]
	TIME [epoch: 27.8 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3556626991570915		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.3556626991570915 | validation: 0.4070534509242781]
	TIME [epoch: 27.9 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3537843404618536		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.3537843404618536 | validation: 0.408960861272396]
	TIME [epoch: 27.8 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3580973491020818		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.3580973491020818 | validation: 0.4196737845524657]
	TIME [epoch: 27.9 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3664573962371992		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.3664573962371992 | validation: 0.430146171290534]
	TIME [epoch: 27.9 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3782027508545781		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.3782027508545781 | validation: 0.4217199183502996]
	TIME [epoch: 27.8 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3667185587510674		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.3667185587510674 | validation: 0.42532740727608725]
	TIME [epoch: 27.8 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3628178168577277		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.3628178168577277 | validation: 0.42085853767953135]
	TIME [epoch: 27.8 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35733817169241633		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.35733817169241633 | validation: 0.410639560288348]
	TIME [epoch: 27.8 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3539643819883552		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.3539643819883552 | validation: 0.4157910593415743]
	TIME [epoch: 27.8 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35513860601551295		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.35513860601551295 | validation: 0.4281870839375359]
	TIME [epoch: 27.8 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3635367025925543		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.3635367025925543 | validation: 0.42988053310078156]
	TIME [epoch: 27.8 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.373153590280259		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.373153590280259 | validation: 0.4367419245166788]
	TIME [epoch: 27.8 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3700109807313303		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.3700109807313303 | validation: 0.42059745563167356]
	TIME [epoch: 27.8 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.363256041432313		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.363256041432313 | validation: 0.43075065420076397]
	TIME [epoch: 27.8 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3646750898316726		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.3646750898316726 | validation: 0.41796609001833496]
	TIME [epoch: 27.8 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35751954810213715		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.35751954810213715 | validation: 0.4286444270196202]
	TIME [epoch: 27.8 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38085367209749244		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.38085367209749244 | validation: 0.46556426024757214]
	TIME [epoch: 27.8 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3776331878701023		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.3776331878701023 | validation: 0.442719526204846]
	TIME [epoch: 27.8 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3679615675438247		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.3679615675438247 | validation: 0.4321954373256299]
	TIME [epoch: 27.8 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36400558356385937		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.36400558356385937 | validation: 0.42673229954424735]
	TIME [epoch: 27.8 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3550930215525038		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.3550930215525038 | validation: 0.4223931297213737]
	TIME [epoch: 27.8 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3572959763087327		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.3572959763087327 | validation: 0.4100215725904731]
	TIME [epoch: 27.8 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35352798994580664		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.35352798994580664 | validation: 0.41457700213744086]
	TIME [epoch: 27.8 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35826101784765263		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.35826101784765263 | validation: 0.4195650823612458]
	TIME [epoch: 27.9 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3612902687037263		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.3612902687037263 | validation: 0.41960714985372144]
	TIME [epoch: 27.8 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36651335803487467		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.36651335803487467 | validation: 0.4308368724961432]
	TIME [epoch: 27.9 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.357357487508714		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.357357487508714 | validation: 0.41940330925587843]
	TIME [epoch: 27.8 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35966251500638025		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.35966251500638025 | validation: 0.4326099289114849]
	TIME [epoch: 27.8 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35642190129998413		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.35642190129998413 | validation: 0.4241675925451881]
	TIME [epoch: 27.9 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3574759031609754		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.3574759031609754 | validation: 0.41164833217358193]
	TIME [epoch: 27.8 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3526856636275582		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.3526856636275582 | validation: 0.41568165974514415]
	TIME [epoch: 27.8 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3570804782987178		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.3570804782987178 | validation: 0.42565380979104506]
	TIME [epoch: 27.8 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3595066449475164		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.3595066449475164 | validation: 0.41285739189786974]
	TIME [epoch: 27.8 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3620036171135917		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.3620036171135917 | validation: 0.4133624423239964]
	TIME [epoch: 27.8 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35747850822326027		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.35747850822326027 | validation: 0.42334522597670066]
	TIME [epoch: 27.8 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35649947982283037		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.35649947982283037 | validation: 0.42097052615026853]
	TIME [epoch: 27.8 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3559293622228348		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.3559293622228348 | validation: 0.4221723726071366]
	TIME [epoch: 27.8 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3647491091315409		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.3647491091315409 | validation: 0.42954151932558005]
	TIME [epoch: 27.8 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3647800785922279		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.3647800785922279 | validation: 0.42614397905919293]
	TIME [epoch: 27.9 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3639010153092336		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.3639010153092336 | validation: 0.4252569799599358]
	TIME [epoch: 27.8 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3646070768049947		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.3646070768049947 | validation: 0.4239102567837362]
	TIME [epoch: 27.9 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3564173546728342		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.3564173546728342 | validation: 0.42168913504618344]
	TIME [epoch: 27.9 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3543215557547518		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.3543215557547518 | validation: 0.4220001044077422]
	TIME [epoch: 27.8 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36119980956157555		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.36119980956157555 | validation: 0.4228674499510494]
	TIME [epoch: 27.8 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35595951621961247		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.35595951621961247 | validation: 0.4284411835190908]
	TIME [epoch: 27.8 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3568096213901626		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.3568096213901626 | validation: 0.4093951748925803]
	TIME [epoch: 27.9 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3543800362138257		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.3543800362138257 | validation: 0.4246716723521756]
	TIME [epoch: 27.8 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3631169601131		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.3631169601131 | validation: 0.42998458603145734]
	TIME [epoch: 27.8 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35996130904496926		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.35996130904496926 | validation: 0.41289805095910115]
	TIME [epoch: 27.8 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36164016073833277		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.36164016073833277 | validation: 0.4186392677267763]
	TIME [epoch: 27.8 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35391619759596626		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.35391619759596626 | validation: 0.42580820913684037]
	TIME [epoch: 27.8 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3586339783743698		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.3586339783743698 | validation: 0.4285636642010954]
	TIME [epoch: 27.8 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36174283851892675		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.36174283851892675 | validation: 0.42054483318968283]
	TIME [epoch: 27.8 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36352013368908853		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.36352013368908853 | validation: 0.41729240818809415]
	TIME [epoch: 27.9 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36897600923339774		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.36897600923339774 | validation: 0.4232549453110175]
	TIME [epoch: 27.8 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3635112976104874		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.3635112976104874 | validation: 0.42498394708499193]
	TIME [epoch: 27.9 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3595046543108381		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.3595046543108381 | validation: 0.42423304186815286]
	TIME [epoch: 27.8 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.360147424980331		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.360147424980331 | validation: 0.4253375530233343]
	TIME [epoch: 27.8 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36138858669413887		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.36138858669413887 | validation: 0.42722770430779916]
	TIME [epoch: 27.9 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35610982024661725		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.35610982024661725 | validation: 0.42520905662463626]
	TIME [epoch: 27.9 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3607659618181425		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.3607659618181425 | validation: 0.4303668520896454]
	TIME [epoch: 27.8 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3619522994600572		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.3619522994600572 | validation: 0.43098807265050765]
	TIME [epoch: 27.8 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36050120525656215		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.36050120525656215 | validation: 0.42649169612556476]
	TIME [epoch: 27.8 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36636296391549916		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.36636296391549916 | validation: 0.43828797983166257]
	TIME [epoch: 27.9 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.364212203012109		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.364212203012109 | validation: 0.4242287542466276]
	TIME [epoch: 27.8 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.362445248148454		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.362445248148454 | validation: 0.4232650627922855]
	TIME [epoch: 27.8 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3616328997420809		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.3616328997420809 | validation: 0.4234446762299453]
	TIME [epoch: 27.9 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3646851298576414		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.3646851298576414 | validation: 0.43895887965497227]
	TIME [epoch: 27.8 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.366747409135594		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.366747409135594 | validation: 0.441754042353097]
	TIME [epoch: 27.9 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37761959193249683		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.37761959193249683 | validation: 0.43481265701507343]
	TIME [epoch: 27.8 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36325094578019046		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.36325094578019046 | validation: 0.42827832560787826]
	TIME [epoch: 27.8 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36262485478921347		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.36262485478921347 | validation: 0.43188019181301]
	TIME [epoch: 27.9 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36260804692453824		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.36260804692453824 | validation: 0.42246220120784456]
	TIME [epoch: 27.8 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35981461724423525		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.35981461724423525 | validation: 0.42279444026827906]
	TIME [epoch: 27.8 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36139784417014587		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.36139784417014587 | validation: 0.4178240244858945]
	TIME [epoch: 27.8 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3559078252162328		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.3559078252162328 | validation: 0.4170648721963174]
	TIME [epoch: 27.9 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3589299775837964		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.3589299775837964 | validation: 0.4200682691620574]
	TIME [epoch: 27.9 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.362625325478731		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.362625325478731 | validation: 0.42199158306664275]
	TIME [epoch: 27.8 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36244067981758943		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.36244067981758943 | validation: 0.4276156365196523]
	TIME [epoch: 27.8 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3572803155505728		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.3572803155505728 | validation: 0.4186969877246136]
	TIME [epoch: 27.8 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3529080072914799		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.3529080072914799 | validation: 0.41432167653632745]
	TIME [epoch: 27.8 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35882780588640617		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.35882780588640617 | validation: 0.4181973654598752]
	TIME [epoch: 27.8 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3543698485284412		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.3543698485284412 | validation: 0.4220863601311961]
	TIME [epoch: 27.8 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.361058704556612		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.361058704556612 | validation: 0.42288359814987614]
	TIME [epoch: 27.8 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35532795958631547		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.35532795958631547 | validation: 0.4246063175024506]
	TIME [epoch: 27.9 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35850973832700767		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.35850973832700767 | validation: 0.4175184810667087]
	TIME [epoch: 27.8 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3612126884300112		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.3612126884300112 | validation: 0.42585006512661266]
	TIME [epoch: 27.9 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35460125314967705		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.35460125314967705 | validation: 0.41856496047904096]
	TIME [epoch: 27.8 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.357606025110897		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.357606025110897 | validation: 0.42329628039483413]
	TIME [epoch: 27.9 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3577257372217631		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.3577257372217631 | validation: 0.4241472397661864]
	TIME [epoch: 27.8 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35648266382752747		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.35648266382752747 | validation: 0.41666031832249717]
	TIME [epoch: 27.8 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3550155121670363		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.3550155121670363 | validation: 0.4214536014656814]
	TIME [epoch: 27.9 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35547365774606443		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.35547365774606443 | validation: 0.4304132913497616]
	TIME [epoch: 27.8 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3564239262763968		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.3564239262763968 | validation: 0.4244694814272494]
	TIME [epoch: 27.9 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35593139815689356		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.35593139815689356 | validation: 0.41196253154100093]
	TIME [epoch: 27.9 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3562324621098601		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.3562324621098601 | validation: 0.42465011842178824]
	TIME [epoch: 27.9 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35764984614110146		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.35764984614110146 | validation: 0.4202772990482641]
	TIME [epoch: 27.9 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35992114097313593		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.35992114097313593 | validation: 0.4154912947180637]
	TIME [epoch: 27.8 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35882168935414527		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.35882168935414527 | validation: 0.4215206835863154]
	TIME [epoch: 27.9 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35317479116399614		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.35317479116399614 | validation: 0.4086662275000535]
	TIME [epoch: 27.8 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35334880780255484		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.35334880780255484 | validation: 0.4147926696212862]
	TIME [epoch: 27.8 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3520671091486395		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.3520671091486395 | validation: 0.4293721923051023]
	TIME [epoch: 27.9 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3656499360323211		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.3656499360323211 | validation: 0.4195149888689441]
	TIME [epoch: 27.8 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35699054790681056		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.35699054790681056 | validation: 0.41305441316713826]
	TIME [epoch: 27.9 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35349993065917296		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.35349993065917296 | validation: 0.4148767662333853]
	TIME [epoch: 27.8 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3528907239094688		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.3528907239094688 | validation: 0.41600219959220885]
	TIME [epoch: 27.8 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35569911804859816		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.35569911804859816 | validation: 0.42017608434729753]
	TIME [epoch: 27.9 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36063772066910094		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.36063772066910094 | validation: 0.41032263675935526]
	TIME [epoch: 27.8 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35901801553049123		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.35901801553049123 | validation: 0.41982319465308027]
	TIME [epoch: 27.9 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35366307368132777		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.35366307368132777 | validation: 0.40966309987728267]
	TIME [epoch: 27.8 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3554657265113633		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.3554657265113633 | validation: 0.425052536612764]
	TIME [epoch: 27.8 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35546363332471376		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.35546363332471376 | validation: 0.40709498174582065]
	TIME [epoch: 27.8 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35482732916587584		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.35482732916587584 | validation: 0.41391782170222313]
	TIME [epoch: 27.8 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35712882325288986		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.35712882325288986 | validation: 0.40480902422148035]
	TIME [epoch: 27.8 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3575308291163126		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.3575308291163126 | validation: 0.41539655868731795]
	TIME [epoch: 27.9 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3563280650628479		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.3563280650628479 | validation: 0.4178752330903906]
	TIME [epoch: 27.8 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.355285570034015		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.355285570034015 | validation: 0.41537987126231907]
	TIME [epoch: 27.9 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3597225511600814		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.3597225511600814 | validation: 0.42010031682394494]
	TIME [epoch: 27.8 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36542255300488236		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.36542255300488236 | validation: 0.4263027758345504]
	TIME [epoch: 27.9 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.363869489364296		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.363869489364296 | validation: 0.409368543490533]
	TIME [epoch: 27.9 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3569509181704912		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.3569509181704912 | validation: 0.4103872394571176]
	TIME [epoch: 27.8 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3588641551314215		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.3588641551314215 | validation: 0.4155064122124199]
	TIME [epoch: 27.9 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3573991925575615		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.3573991925575615 | validation: 0.41465680472736255]
	TIME [epoch: 27.8 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3589743252973995		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.3589743252973995 | validation: 0.42225188931097507]
	TIME [epoch: 27.8 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35383870747211477		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.35383870747211477 | validation: 0.4178815710737068]
	TIME [epoch: 27.8 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35259785727501125		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.35259785727501125 | validation: 0.4115155169931856]
	TIME [epoch: 27.8 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35470501331579607		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.35470501331579607 | validation: 0.4125243216901426]
	TIME [epoch: 27.8 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35764006908556706		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.35764006908556706 | validation: 0.41383701441414533]
	TIME [epoch: 27.8 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3544591975120556		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.3544591975120556 | validation: 0.41829159874455885]
	TIME [epoch: 27.8 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3568558826188017		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.3568558826188017 | validation: 0.40723037780247284]
	TIME [epoch: 27.8 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3543683207071864		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.3543683207071864 | validation: 0.40388118207058726]
	TIME [epoch: 27.8 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35198242488014286		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.35198242488014286 | validation: 0.40846647096980654]
	TIME [epoch: 27.8 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3538261655133256		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.3538261655133256 | validation: 0.4114411800872324]
	TIME [epoch: 27.8 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.359785448313098		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.359785448313098 | validation: 0.41063173317166085]
	TIME [epoch: 27.9 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35116384862976796		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.35116384862976796 | validation: 0.41592658758170353]
	TIME [epoch: 27.8 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36062950179168807		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.36062950179168807 | validation: 0.42394396589652766]
	TIME [epoch: 27.7 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3579527003098995		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.3579527003098995 | validation: 0.4149502008957907]
	TIME [epoch: 27.9 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35029188162591157		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.35029188162591157 | validation: 0.4064451420776719]
	TIME [epoch: 27.8 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.353282417374256		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.353282417374256 | validation: 0.41017731079894104]
	TIME [epoch: 27.8 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3553171642560403		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.3553171642560403 | validation: 0.4114341024636049]
	TIME [epoch: 27.8 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3551222975087982		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.3551222975087982 | validation: 0.4055433586864973]
	TIME [epoch: 27.8 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3575294848577018		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.3575294848577018 | validation: 0.40462573658197754]
	TIME [epoch: 27.8 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35542614355326874		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.35542614355326874 | validation: 0.4169445438321069]
	TIME [epoch: 27.8 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3587943219829688		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.3587943219829688 | validation: 0.41906426689685633]
	TIME [epoch: 27.8 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35817870077868236		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.35817870077868236 | validation: 0.4181087404385737]
	TIME [epoch: 27.8 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35850347794213155		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.35850347794213155 | validation: 0.4316136828315092]
	TIME [epoch: 27.7 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3619168230589145		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.3619168230589145 | validation: 0.42425383980003906]
	TIME [epoch: 27.8 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35921644412928966		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.35921644412928966 | validation: 0.4223735728309799]
	TIME [epoch: 27.7 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3653061466247181		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.3653061466247181 | validation: 0.4331454773033799]
	TIME [epoch: 27.8 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36500196998191003		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.36500196998191003 | validation: 0.4345264885171683]
	TIME [epoch: 27.8 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3622554084172024		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.3622554084172024 | validation: 0.42067182439336853]
	TIME [epoch: 27.7 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3579428741028781		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.3579428741028781 | validation: 0.41010580058276125]
	TIME [epoch: 27.8 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3537525127850142		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.3537525127850142 | validation: 0.4057031726751888]
	TIME [epoch: 27.8 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35211888823921245		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.35211888823921245 | validation: 0.41526838123677623]
	TIME [epoch: 27.8 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3571101394300232		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.3571101394300232 | validation: 0.40682949517944267]
	TIME [epoch: 27.8 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3530214974470761		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.3530214974470761 | validation: 0.41936169510754967]
	TIME [epoch: 27.8 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3575141006772158		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.3575141006772158 | validation: 0.40489776992562154]
	TIME [epoch: 27.7 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35801232258594784		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.35801232258594784 | validation: 0.4071526874582285]
	TIME [epoch: 27.7 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3534448137630564		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.3534448137630564 | validation: 0.41284940965806444]
	TIME [epoch: 27.7 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35343563655154814		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.35343563655154814 | validation: 0.41504872216421973]
	TIME [epoch: 27.8 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35589553374385857		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.35589553374385857 | validation: 0.4203364242275628]
	TIME [epoch: 27.7 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35864646943223827		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.35864646943223827 | validation: 0.4240891644756799]
	TIME [epoch: 27.9 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35637143726855525		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.35637143726855525 | validation: 0.41923374564780075]
	TIME [epoch: 27.8 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3582759880257437		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.3582759880257437 | validation: 0.43026268255967154]
	TIME [epoch: 27.8 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36159814412740454		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.36159814412740454 | validation: 0.43442372372571153]
	TIME [epoch: 27.8 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36261379056594384		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.36261379056594384 | validation: 0.43287869169963805]
	TIME [epoch: 27.8 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3591473812003233		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.3591473812003233 | validation: 0.4170656111058918]
	TIME [epoch: 27.8 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35915734774850167		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.35915734774850167 | validation: 0.4148286986963866]
	TIME [epoch: 27.8 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3586019086409218		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.3586019086409218 | validation: 0.41852964344276816]
	TIME [epoch: 27.7 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3563635777673631		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.3563635777673631 | validation: 0.4136662540126797]
	TIME [epoch: 27.8 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3589515420103902		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.3589515420103902 | validation: 0.405929906933122]
	TIME [epoch: 27.8 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3587558658351686		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.3587558658351686 | validation: 0.42717818894190795]
	TIME [epoch: 27.8 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36135594999913667		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.36135594999913667 | validation: 0.4106561983057747]
	TIME [epoch: 27.8 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35849339298345695		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.35849339298345695 | validation: 0.42677919201251596]
	TIME [epoch: 27.8 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3591677785983015		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.3591677785983015 | validation: 0.4310105841564469]
	TIME [epoch: 27.8 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36361193535435354		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.36361193535435354 | validation: 0.4276995085421572]
	TIME [epoch: 27.8 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3640494555696879		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.3640494555696879 | validation: 0.4159496135221989]
	TIME [epoch: 27.8 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36168137659026284		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.36168137659026284 | validation: 0.4218534946166889]
	TIME [epoch: 27.8 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36297262193436153		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.36297262193436153 | validation: 0.4187983670204096]
	TIME [epoch: 27.7 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3585762596584138		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.3585762596584138 | validation: 0.42194980442382146]
	TIME [epoch: 27.8 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35670204090046415		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.35670204090046415 | validation: 0.4218813279109418]
	TIME [epoch: 27.8 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35783631641995123		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.35783631641995123 | validation: 0.41550666771991956]
	TIME [epoch: 27.8 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35438127705795486		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.35438127705795486 | validation: 0.4282826380755983]
	TIME [epoch: 27.8 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3583782350235689		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.3583782350235689 | validation: 0.4085984837485249]
	TIME [epoch: 27.7 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3551382953387472		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.3551382953387472 | validation: 0.41660199684609844]
	TIME [epoch: 27.8 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3534338590275113		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.3534338590275113 | validation: 0.41328989772796293]
	TIME [epoch: 27.7 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3549717274238281		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.3549717274238281 | validation: 0.4057369869948489]
	TIME [epoch: 27.8 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3574856514775244		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.3574856514775244 | validation: 0.4189669698423031]
	TIME [epoch: 27.8 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35840711156890703		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.35840711156890703 | validation: 0.4240863536127155]
	TIME [epoch: 27.7 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35291906380374816		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.35291906380374816 | validation: 0.40609517341113527]
	TIME [epoch: 27.8 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35576575556265516		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.35576575556265516 | validation: 0.43102721778984304]
	TIME [epoch: 27.7 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.355864415697515		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.355864415697515 | validation: 0.4233539897705685]
	TIME [epoch: 27.8 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3567990485245015		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.3567990485245015 | validation: 0.4196973793720304]
	TIME [epoch: 27.9 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35851291458166495		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.35851291458166495 | validation: 0.40212347476074733]
	TIME [epoch: 27.8 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.357771187531015		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.357771187531015 | validation: 0.4249652563351086]
	TIME [epoch: 27.8 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35382865490597587		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.35382865490597587 | validation: 0.4093582056858204]
	TIME [epoch: 27.8 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35313671416493975		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.35313671416493975 | validation: 0.41317880995363604]
	TIME [epoch: 27.8 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35289767161149893		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.35289767161149893 | validation: 0.413432286526056]
	TIME [epoch: 27.9 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.360063629626149		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.360063629626149 | validation: 0.4165856130449174]
	TIME [epoch: 27.8 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3582513306284356		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.3582513306284356 | validation: 0.4204519407759372]
	TIME [epoch: 27.9 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3543360647861984		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.3543360647861984 | validation: 0.41463107544515143]
	TIME [epoch: 27.8 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35720255031635945		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.35720255031635945 | validation: 0.41345596564918735]
	TIME [epoch: 27.9 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3542973936658078		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.3542973936658078 | validation: 0.42091470937581277]
	TIME [epoch: 27.8 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.358826941484751		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.358826941484751 | validation: 0.41951358474091693]
	TIME [epoch: 27.8 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3533504487583562		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.3533504487583562 | validation: 0.4182268211750432]
	TIME [epoch: 27.9 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3519737636424895		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.3519737636424895 | validation: 0.41673270597264256]
	TIME [epoch: 27.8 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3531411588259715		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.3531411588259715 | validation: 0.4125750525851672]
	TIME [epoch: 27.8 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35296767708596083		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.35296767708596083 | validation: 0.4216075206883796]
	TIME [epoch: 27.8 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3617291691762445		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.3617291691762445 | validation: 0.4172455975699416]
	TIME [epoch: 27.8 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3521118936303097		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.3521118936303097 | validation: 0.4107636080574265]
	TIME [epoch: 27.8 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3551029817985088		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.3551029817985088 | validation: 0.4123559079048673]
	TIME [epoch: 27.7 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3559336937380721		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.3559336937380721 | validation: 0.42251706386007876]
	TIME [epoch: 27.8 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3496226552123659		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.3496226552123659 | validation: 0.4087261316422823]
	TIME [epoch: 27.8 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35368214951978943		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.35368214951978943 | validation: 0.41404653282740794]
	TIME [epoch: 27.8 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35724286165406205		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.35724286165406205 | validation: 0.41469834526143684]
	TIME [epoch: 27.8 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35559663094503785		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.35559663094503785 | validation: 0.41657541120123215]
	TIME [epoch: 27.7 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35289424224406574		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.35289424224406574 | validation: 0.4179269816536349]
	TIME [epoch: 27.7 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35152227346454656		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.35152227346454656 | validation: 0.4147329285565445]
	TIME [epoch: 27.9 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3533607626586406		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.3533607626586406 | validation: 0.41060181111551336]
	TIME [epoch: 27.8 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35593397381979336		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.35593397381979336 | validation: 0.41646797455081197]
	TIME [epoch: 27.8 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3545340069772762		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.3545340069772762 | validation: 0.4154924564201691]
	TIME [epoch: 27.7 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3543204549992697		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.3543204549992697 | validation: 0.41654052614290193]
	TIME [epoch: 27.8 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.353391095475559		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.353391095475559 | validation: 0.41946652469747997]
	TIME [epoch: 27.8 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35150314086270773		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.35150314086270773 | validation: 0.42422715542911266]
	TIME [epoch: 27.7 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35532597678585653		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.35532597678585653 | validation: 0.4203533541823233]
	TIME [epoch: 27.8 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3597117687120111		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.3597117687120111 | validation: 0.4098746396052241]
	TIME [epoch: 27.8 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3524201579695122		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.3524201579695122 | validation: 0.4124350008053762]
	TIME [epoch: 27.8 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35174661023350334		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.35174661023350334 | validation: 0.41042238819647914]
	TIME [epoch: 27.8 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3600881246359306		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.3600881246359306 | validation: 0.42998068640004616]
	TIME [epoch: 27.8 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3607189558025273		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.3607189558025273 | validation: 0.4239892018713779]
	TIME [epoch: 27.8 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36437222368496835		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.36437222368496835 | validation: 0.41832751635150445]
	TIME [epoch: 27.8 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3589812862770443		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.3589812862770443 | validation: 0.41681560180311095]
	TIME [epoch: 27.8 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35621911345547064		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.35621911345547064 | validation: 0.42643560191994817]
	TIME [epoch: 27.8 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3575502304204494		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.3575502304204494 | validation: 0.4038447280600481]
	TIME [epoch: 27.8 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35737277561786207		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.35737277561786207 | validation: 0.40942556834094734]
	TIME [epoch: 27.8 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3576866867181313		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.3576866867181313 | validation: 0.41499011341174663]
	TIME [epoch: 27.8 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.352418802166793		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.352418802166793 | validation: 0.40168534266691786]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_1855.pth
	Model improved!!!
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3512931599603585		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.3512931599603585 | validation: 0.415309473206659]
	TIME [epoch: 27.8 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35264797310674073		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.35264797310674073 | validation: 0.4131012536038924]
	TIME [epoch: 27.8 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35428392899783473		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.35428392899783473 | validation: 0.41403493901449273]
	TIME [epoch: 27.8 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3559439102361059		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.3559439102361059 | validation: 0.4096750781427605]
	TIME [epoch: 27.8 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3533131158496691		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.3533131158496691 | validation: 0.4127166883401654]
	TIME [epoch: 27.7 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3533303787548026		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.3533303787548026 | validation: 0.4184186616224542]
	TIME [epoch: 27.9 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.353325062836		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.353325062836 | validation: 0.4151014381123499]
	TIME [epoch: 27.7 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35301969647122944		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.35301969647122944 | validation: 0.4146036050270663]
	TIME [epoch: 27.9 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3528112988753297		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.3528112988753297 | validation: 0.4157322348101172]
	TIME [epoch: 27.8 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35713141490965417		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.35713141490965417 | validation: 0.404364688078732]
	TIME [epoch: 27.8 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3560318043365383		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.3560318043365383 | validation: 0.42449870287009495]
	TIME [epoch: 27.8 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35340333993684825		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.35340333993684825 | validation: 0.4073288023267394]
	TIME [epoch: 27.8 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3523086890302932		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.3523086890302932 | validation: 0.4120019579201143]
	TIME [epoch: 27.8 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35263032626145385		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.35263032626145385 | validation: 0.4240663981370617]
	TIME [epoch: 27.8 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3558751613302995		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.3558751613302995 | validation: 0.41633774528168743]
	TIME [epoch: 27.7 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35089931459593854		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.35089931459593854 | validation: 0.4278398599503369]
	TIME [epoch: 27.7 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3536081492783868		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.3536081492783868 | validation: 0.41025805781005853]
	TIME [epoch: 27.7 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35575066090532426		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.35575066090532426 | validation: 0.4195812944090758]
	TIME [epoch: 27.7 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3534702999278172		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.3534702999278172 | validation: 0.41704286248327477]
	TIME [epoch: 27.8 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35545255826469213		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.35545255826469213 | validation: 0.4037523262111655]
	TIME [epoch: 27.8 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3575611512378237		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.3575611512378237 | validation: 0.4150475873073642]
	TIME [epoch: 27.8 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3572191789162251		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.3572191789162251 | validation: 0.40886706275010376]
	TIME [epoch: 27.8 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3514751041861342		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.3514751041861342 | validation: 0.4110213550960073]
	TIME [epoch: 27.8 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3507339166847666		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.3507339166847666 | validation: 0.4145658424489278]
	TIME [epoch: 27.8 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3522200990415436		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.3522200990415436 | validation: 0.4080626232833858]
	TIME [epoch: 27.8 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35354937412398246		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.35354937412398246 | validation: 0.4234265102365589]
	TIME [epoch: 27.8 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3548269047599095		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.3548269047599095 | validation: 0.424177056593535]
	TIME [epoch: 27.7 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3509494115168533		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.3509494115168533 | validation: 0.4153650350231392]
	TIME [epoch: 27.8 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3528822835050276		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.3528822835050276 | validation: 0.4173868563589024]
	TIME [epoch: 27.8 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34950827764252357		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.34950827764252357 | validation: 0.41202033267972143]
	TIME [epoch: 27.7 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3524998624382255		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.3524998624382255 | validation: 0.4237387096634839]
	TIME [epoch: 27.7 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3525633903353367		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.3525633903353367 | validation: 0.42138919273530195]
	TIME [epoch: 27.7 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35329152894370275		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.35329152894370275 | validation: 0.419337808507257]
	TIME [epoch: 27.7 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35051969171775904		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.35051969171775904 | validation: 0.41396553966870175]
	TIME [epoch: 27.8 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35294108253035866		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.35294108253035866 | validation: 0.41732761304004656]
	TIME [epoch: 27.8 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3552913237254412		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.3552913237254412 | validation: 0.4200165640220578]
	TIME [epoch: 27.8 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34951960056923015		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.34951960056923015 | validation: 0.4161189514634404]
	TIME [epoch: 27.7 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35429059372242605		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.35429059372242605 | validation: 0.4091295364516617]
	TIME [epoch: 27.8 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3534514263873274		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.3534514263873274 | validation: 0.40754955357093764]
	TIME [epoch: 27.8 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.352726872538063		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.352726872538063 | validation: 0.40845606483513935]
	TIME [epoch: 27.8 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3573804948930566		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.3573804948930566 | validation: 0.41422569712239765]
	TIME [epoch: 27.9 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3565929967430485		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.3565929967430485 | validation: 0.4147401026917063]
	TIME [epoch: 27.8 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35557742424211425		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.35557742424211425 | validation: 0.42085039422548504]
	TIME [epoch: 27.9 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3559576176795589		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.3559576176795589 | validation: 0.41056056557451104]
	TIME [epoch: 27.9 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3521088103492649		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.3521088103492649 | validation: 0.41748926066191416]
	TIME [epoch: 27.9 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3505141596507017		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.3505141596507017 | validation: 0.40105901048171844]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_1901.pth
	Model improved!!!
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35759064828885834		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.35759064828885834 | validation: 0.4228785744325556]
	TIME [epoch: 27.8 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3503391448163329		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.3503391448163329 | validation: 0.41161671277935463]
	TIME [epoch: 27.8 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35320938981621075		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.35320938981621075 | validation: 0.4236232834088565]
	TIME [epoch: 27.8 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35819967144462983		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.35819967144462983 | validation: 0.41957248712013284]
	TIME [epoch: 27.7 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35264228465519726		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.35264228465519726 | validation: 0.4175389623479869]
	TIME [epoch: 27.8 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.352855734876309		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.352855734876309 | validation: 0.4189914498223166]
	TIME [epoch: 27.7 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35346671265547724		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.35346671265547724 | validation: 0.4227431602302355]
	TIME [epoch: 27.8 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3534860519499002		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.3534860519499002 | validation: 0.4063559568338894]
	TIME [epoch: 27.9 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.355440551120182		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.355440551120182 | validation: 0.40475493889529945]
	TIME [epoch: 27.8 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35118227030854976		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.35118227030854976 | validation: 0.4176132847422526]
	TIME [epoch: 27.9 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35408367932044293		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.35408367932044293 | validation: 0.40656283954003597]
	TIME [epoch: 27.8 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3567626934977573		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.3567626934977573 | validation: 0.4201387490188753]
	TIME [epoch: 27.8 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3560715519502548		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.3560715519502548 | validation: 0.4086243505490016]
	TIME [epoch: 27.8 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.355611159359002		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.355611159359002 | validation: 0.4172402064333367]
	TIME [epoch: 27.8 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35597020584979805		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.35597020584979805 | validation: 0.41059466483396995]
	TIME [epoch: 27.8 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35536798936335906		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.35536798936335906 | validation: 0.41497871061922154]
	TIME [epoch: 27.8 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35799176574305236		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.35799176574305236 | validation: 0.41545390121248604]
	TIME [epoch: 27.8 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35345489092729687		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.35345489092729687 | validation: 0.4123714286907644]
	TIME [epoch: 27.8 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35718806882850157		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.35718806882850157 | validation: 0.412833921624589]
	TIME [epoch: 27.7 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3594414356289328		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.3594414356289328 | validation: 0.4236147634261067]
	TIME [epoch: 27.9 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35363495159875996		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.35363495159875996 | validation: 0.41063277662331615]
	TIME [epoch: 27.8 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3573748015460477		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.3573748015460477 | validation: 0.40995586917170584]
	TIME [epoch: 27.7 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35868878775774016		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.35868878775774016 | validation: 0.41678045500821126]
	TIME [epoch: 27.8 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3563138149002558		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.3563138149002558 | validation: 0.42447523061508435]
	TIME [epoch: 27.8 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3545593404841265		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.3545593404841265 | validation: 0.40687196764894445]
	TIME [epoch: 27.9 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35582728827314003		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.35582728827314003 | validation: 0.41317430141099115]
	TIME [epoch: 27.8 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3537575916374921		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.3537575916374921 | validation: 0.40882952837837594]
	TIME [epoch: 27.8 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3564087274991316		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.3564087274991316 | validation: 0.4124358528724736]
	TIME [epoch: 27.8 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3476881811373186		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.3476881811373186 | validation: 0.4128115608204556]
	TIME [epoch: 27.7 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3534679573045444		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.3534679573045444 | validation: 0.4264536698526189]
	TIME [epoch: 27.8 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35577782947911674		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.35577782947911674 | validation: 0.4075631974016747]
	TIME [epoch: 27.8 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3591553369773104		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.3591553369773104 | validation: 0.41255758634661166]
	TIME [epoch: 27.8 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35553040619986176		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.35553040619986176 | validation: 0.4094850827639471]
	TIME [epoch: 27.9 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.356821657264935		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.356821657264935 | validation: 0.4079022979577432]
	TIME [epoch: 27.8 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35449238197459526		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.35449238197459526 | validation: 0.41461217047154025]
	TIME [epoch: 27.8 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34755323174589525		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.34755323174589525 | validation: 0.4182598825165864]
	TIME [epoch: 27.8 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3552035550888527		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.3552035550888527 | validation: 0.4197375479029063]
	TIME [epoch: 27.8 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3539373815264655		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.3539373815264655 | validation: 0.4084516260492508]
	TIME [epoch: 27.8 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35460895609721443		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.35460895609721443 | validation: 0.4115330389284631]
	TIME [epoch: 27.8 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3498077840448719		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.3498077840448719 | validation: 0.4119811872891338]
	TIME [epoch: 27.8 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35502938885883134		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.35502938885883134 | validation: 0.4190946920684385]
	TIME [epoch: 27.8 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3535388942031934		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.3535388942031934 | validation: 0.39946485048079994]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240424_132548/states/model_tr_study5_1943.pth
	Model improved!!!
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3524975828805645		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.3524975828805645 | validation: 0.4155074247631311]
	TIME [epoch: 27.8 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35433547972567786		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.35433547972567786 | validation: 0.41242594750840356]
	TIME [epoch: 27.8 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3566684091951187		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.3566684091951187 | validation: 0.41544751263624446]
	TIME [epoch: 27.8 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34916423202404645		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.34916423202404645 | validation: 0.415514380839697]
	TIME [epoch: 27.8 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3558495680973324		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.3558495680973324 | validation: 0.41163947880413887]
	TIME [epoch: 27.7 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3535209724171057		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.3535209724171057 | validation: 0.416677240817435]
	TIME [epoch: 27.8 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35670126308830497		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.35670126308830497 | validation: 0.4206368807951247]
	TIME [epoch: 27.8 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3541327183212123		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.3541327183212123 | validation: 0.40949656753108044]
	TIME [epoch: 27.8 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3518292705122203		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.3518292705122203 | validation: 0.40431279977523177]
	TIME [epoch: 27.8 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3539811738274842		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.3539811738274842 | validation: 0.41583166485451073]
	TIME [epoch: 27.8 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35291120400696063		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.35291120400696063 | validation: 0.42402829903803463]
	TIME [epoch: 27.9 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3501659605027806		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.3501659605027806 | validation: 0.412778383935184]
	TIME [epoch: 27.8 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35558229646693473		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.35558229646693473 | validation: 0.4265389933646205]
	TIME [epoch: 27.9 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3542597503295211		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.3542597503295211 | validation: 0.4220422667968326]
	TIME [epoch: 27.8 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35054771952975783		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.35054771952975783 | validation: 0.41318572433637235]
	TIME [epoch: 27.8 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35261314083155176		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.35261314083155176 | validation: 0.4012291389130649]
	TIME [epoch: 27.8 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34960025333232325		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.34960025333232325 | validation: 0.41218559099982444]
	TIME [epoch: 27.8 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3545896371760583		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.3545896371760583 | validation: 0.4164469491096931]
	TIME [epoch: 27.8 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3501512845454318		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.3501512845454318 | validation: 0.4112110845859526]
	TIME [epoch: 27.8 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35198502246226016		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.35198502246226016 | validation: 0.4180806351725093]
	TIME [epoch: 27.7 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35461023478237835		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.35461023478237835 | validation: 0.41113228580744365]
	TIME [epoch: 27.8 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3574564764339777		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.3574564764339777 | validation: 0.40377036609247074]
	TIME [epoch: 27.8 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35266289968575953		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.35266289968575953 | validation: 0.4050680025388347]
	TIME [epoch: 27.8 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34852125631058845		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.34852125631058845 | validation: 0.42792925255789244]
	TIME [epoch: 27.8 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35328348236803897		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.35328348236803897 | validation: 0.41151044775101986]
	TIME [epoch: 27.8 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3495171236106922		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.3495171236106922 | validation: 0.4203665477400905]
	TIME [epoch: 27.8 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35227413913915373		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.35227413913915373 | validation: 0.40894886060391]
	TIME [epoch: 27.7 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3508888259440842		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.3508888259440842 | validation: 0.40700922536603307]
	TIME [epoch: 27.8 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3518679320149301		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.3518679320149301 | validation: 0.4247791690450387]
	TIME [epoch: 27.8 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35467395780109284		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.35467395780109284 | validation: 0.4143001061521558]
	TIME [epoch: 27.8 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3507771483876413		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.3507771483876413 | validation: 0.4004243169612858]
	TIME [epoch: 27.9 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3548499247548729		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.3548499247548729 | validation: 0.41975583316870696]
	TIME [epoch: 27.8 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34867559476477306		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.34867559476477306 | validation: 0.4163386238622629]
	TIME [epoch: 27.8 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.351087126738119		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.351087126738119 | validation: 0.4195919352712252]
	TIME [epoch: 27.8 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3540233531905685		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.3540233531905685 | validation: 0.4178886647340678]
	TIME [epoch: 27.7 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3532532542978639		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.3532532542978639 | validation: 0.41240361092248423]
	TIME [epoch: 27.8 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3532003581372664		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.3532003581372664 | validation: 0.418936829075494]
	TIME [epoch: 27.8 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3519456430563373		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.3519456430563373 | validation: 0.4066222880603121]
	TIME [epoch: 27.8 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35447501594100284		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.35447501594100284 | validation: 0.4214915209401701]
	TIME [epoch: 27.8 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3577826420313748		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.3577826420313748 | validation: 0.4090153617975673]
	TIME [epoch: 27.8 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3530444397232674		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.3530444397232674 | validation: 0.4143430590697815]
	TIME [epoch: 27.9 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35115008069049175		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.35115008069049175 | validation: 0.4218621203379298]
	TIME [epoch: 27.8 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35515933356994916		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.35515933356994916 | validation: 0.41262187482122104]
	TIME [epoch: 27.8 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3527040342144388		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.3527040342144388 | validation: 0.4158578045779463]
	TIME [epoch: 27.9 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3494345471781345		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.3494345471781345 | validation: 0.41879843668973465]
	TIME [epoch: 27.8 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3509862923392291		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.3509862923392291 | validation: 0.4135613112791592]
	TIME [epoch: 27.9 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3511201156772021		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.3511201156772021 | validation: 0.41516926231066636]
	TIME [epoch: 27.8 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3524875607196686		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.3524875607196686 | validation: 0.41170888917076764]
	TIME [epoch: 27.8 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35184925945785694		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.35184925945785694 | validation: 0.4074120101158361]
	TIME [epoch: 27.8 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35145470690325653		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.35145470690325653 | validation: 0.4070737309526476]
	TIME [epoch: 27.8 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35322847662425505		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.35322847662425505 | validation: 0.4125296686083702]
	TIME [epoch: 27.8 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35690713117360356		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.35690713117360356 | validation: 0.4172074205685851]
	TIME [epoch: 27.8 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.351676652896709		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.351676652896709 | validation: 0.4115087803033061]
	TIME [epoch: 27.8 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35310916891927513		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.35310916891927513 | validation: 0.40919081780792355]
	TIME [epoch: 27.8 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3450886934566341		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.3450886934566341 | validation: 0.41955207372975567]
	TIME [epoch: 27.8 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3525995155384063		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.3525995155384063 | validation: 0.4088571431758236]
	TIME [epoch: 27.9 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3515574771740004		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.3515574771740004 | validation: 0.4132285721942074]
	TIME [epoch: 27.8 sec]
Finished training in 55779.039 seconds.
