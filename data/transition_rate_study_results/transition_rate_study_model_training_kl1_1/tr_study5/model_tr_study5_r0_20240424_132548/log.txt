Args:
Namespace(name='model_tr_study5', outdir='out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0', training_data='data/transition_rate_studies/tr_study5/tr_study5_training/r0', validation_data='data/transition_rate_studies/tr_study5/tr_study5_validation/r0', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1030330225

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.908700283448068		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.908700283448068 | validation: 9.004373293763562]
	TIME [epoch: 110 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.740403639801496		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.740403639801496 | validation: 9.165338170625601]
	TIME [epoch: 27.6 sec]
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.261548193931704		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.261548193931704 | validation: 8.236994989092484]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.545485774794663		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.545485774794663 | validation: 8.158860431020857]
	TIME [epoch: 27.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.942748916922405		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.942748916922405 | validation: 6.997234207688036]
	TIME [epoch: 27.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.3646379029919755		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.3646379029919755 | validation: 6.710293540566376]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.241105967172038		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.241105967172038 | validation: 6.974419016948631]
	TIME [epoch: 27.6 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.9793532534050895		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.9793532534050895 | validation: 6.267639319013608]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.713258588499551		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.713258588499551 | validation: 6.604394096331145]
	TIME [epoch: 27.6 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.3613731707438435		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.3613731707438435 | validation: 5.941812775331888]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.161978830356884		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.161978830356884 | validation: 6.215389919900531]
	TIME [epoch: 27.6 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.181530513630466		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.181530513630466 | validation: 5.759182704259732]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.302852472323247		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.302852472323247 | validation: 5.762500955324462]
	TIME [epoch: 27.6 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.80997602864758		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.80997602864758 | validation: 5.887869170983704]
	TIME [epoch: 27.6 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.727574485880206		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.727574485880206 | validation: 5.717999328638937]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.682848065134568		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.682848065134568 | validation: 5.654167034783098]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.609289542429989		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.609289542429989 | validation: 5.7384008393433374]
	TIME [epoch: 27.6 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.613826441441749		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.613826441441749 | validation: 5.641840492840808]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.519455001218334		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.519455001218334 | validation: 5.8561809301505106]
	TIME [epoch: 27.6 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.500255677903483		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.500255677903483 | validation: 6.15205828822194]
	TIME [epoch: 27.7 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.629730635770685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.629730635770685 | validation: 5.614342065719327]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.433082183556856		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.433082183556856 | validation: 5.7525787583803405]
	TIME [epoch: 27.6 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.437170889853805		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.437170889853805 | validation: 5.534654685078571]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.373545049893862		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.373545049893862 | validation: 5.568810356023427]
	TIME [epoch: 27.7 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.427712225635529		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.427712225635529 | validation: 5.582132695579235]
	TIME [epoch: 27.7 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.2861855235934385		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.2861855235934385 | validation: 5.814114585415907]
	TIME [epoch: 27.7 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.51972866881012		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.51972866881012 | validation: 5.958905455021433]
	TIME [epoch: 27.6 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.824070094691519		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.824070094691519 | validation: 5.625829920992146]
	TIME [epoch: 27.6 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.401352001058692		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.401352001058692 | validation: 5.523197934809864]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.322666993982464		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.322666993982464 | validation: 5.536793889090368]
	TIME [epoch: 27.6 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.449867923927738		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.449867923927738 | validation: 5.5431795147202]
	TIME [epoch: 27.6 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.3242860800040175		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.3242860800040175 | validation: 5.658923432842892]
	TIME [epoch: 27.6 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.353397033500658		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.353397033500658 | validation: 5.700945087873031]
	TIME [epoch: 27.6 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.408203302228502		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.408203302228502 | validation: 5.873367601800867]
	TIME [epoch: 27.6 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.479495530343919		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.479495530343919 | validation: 5.516346674472998]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.2716115494773845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.2716115494773845 | validation: 5.790719663478367]
	TIME [epoch: 27.6 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.398449937007466		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.398449937007466 | validation: 5.911154100848021]
	TIME [epoch: 27.6 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.356256271432059		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.356256271432059 | validation: 8.043898871457591]
	TIME [epoch: 27.6 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.189033082217507		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.189033082217507 | validation: 5.547314454627384]
	TIME [epoch: 27.6 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.320237130327678		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.320237130327678 | validation: 5.295642553705627]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.172845552322295		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.172845552322295 | validation: 5.2830423340164545]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.307380929976149		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.307380929976149 | validation: 5.568020468313008]
	TIME [epoch: 27.5 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.174692836157002		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.174692836157002 | validation: 5.4456669623780405]
	TIME [epoch: 27.6 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.194130990239065		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.194130990239065 | validation: 5.517768266526548]
	TIME [epoch: 27.6 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.140151415592001		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.140151415592001 | validation: 5.355561703029337]
	TIME [epoch: 27.5 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.028060379871588		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.028060379871588 | validation: 5.177633269020195]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.141064255869486		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.141064255869486 | validation: 5.43887708035332]
	TIME [epoch: 27.6 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.001414528243592		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.001414528243592 | validation: 5.4238959656258094]
	TIME [epoch: 27.6 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.0218609918514625		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.0218609918514625 | validation: 5.184636674054584]
	TIME [epoch: 27.6 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.050794866518499		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.050794866518499 | validation: 5.659450953620035]
	TIME [epoch: 27.6 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.347500871349986		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 5.347500871349986 | validation: 5.594900137101109]
	TIME [epoch: 27.6 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.082433269082764		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 5.082433269082764 | validation: 5.126022805793384]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.933439685802239		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 4.933439685802239 | validation: 5.022795566884148]
	TIME [epoch: 27.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.950630018988496		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 4.950630018988496 | validation: 5.683073630611987]
	TIME [epoch: 27.7 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.103380952409518		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 5.103380952409518 | validation: 4.969827159537804]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.874610097553295		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 4.874610097553295 | validation: 5.423333375509974]
	TIME [epoch: 27.6 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.869580901623972		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 4.869580901623972 | validation: 4.93888325400067]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.84041581628748		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 4.84041581628748 | validation: 4.973432510538794]
	TIME [epoch: 27.6 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.7413504969278		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 4.7413504969278 | validation: 5.218089645095063]
	TIME [epoch: 27.5 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.616893660942877		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 5.616893660942877 | validation: 8.951928474907982]
	TIME [epoch: 27.6 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.146559960650693		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 7.146559960650693 | validation: 5.235005506940677]
	TIME [epoch: 27.6 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.297113832103211		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 5.297113832103211 | validation: 5.441147690804297]
	TIME [epoch: 27.5 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.965207074218074		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 4.965207074218074 | validation: 4.772075354900143]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.7332213797878575		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 4.7332213797878575 | validation: 4.827926921939881]
	TIME [epoch: 27.6 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.653503440875998		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 4.653503440875998 | validation: 5.316379299036523]
	TIME [epoch: 27.5 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.742191543920177		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 4.742191543920177 | validation: 4.453341874873136]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.763899170152822		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 4.763899170152822 | validation: 4.7449238694139035]
	TIME [epoch: 27.6 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5643459539094		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 4.5643459539094 | validation: 4.304925004211084]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.311004291587389		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 4.311004291587389 | validation: 4.958859177185448]
	TIME [epoch: 27.6 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4964302459348815		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 4.4964302459348815 | validation: 5.092328418866954]
	TIME [epoch: 27.6 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.97434270107038		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 4.97434270107038 | validation: 4.050293510953569]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.93432576838285		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 4.93432576838285 | validation: 4.034396814459089]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9701333862905797		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 3.9701333862905797 | validation: 3.891683241092552]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9802406231813356		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 3.9802406231813356 | validation: 3.680079902532981]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_74.pth
	Model improved!!!
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7268797885505505		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 3.7268797885505505 | validation: 4.222476550057452]
	TIME [epoch: 27.6 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7665991100671277		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 3.7665991100671277 | validation: 3.347949632901558]
	TIME [epoch: 27.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.33911998248148		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 3.33911998248148 | validation: 3.7339488183984333]
	TIME [epoch: 27.6 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4569827828453024		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 3.4569827828453024 | validation: 4.552524959684117]
	TIME [epoch: 27.6 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.348675225980206		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 3.348675225980206 | validation: 3.870282674366964]
	TIME [epoch: 27.5 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.232688958713899		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 3.232688958713899 | validation: 2.9277655962876485]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_80.pth
	Model improved!!!
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0197130576154385		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 3.0197130576154385 | validation: 3.36301059486258]
	TIME [epoch: 27.6 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9050104922404514		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 2.9050104922404514 | validation: 3.251766585148534]
	TIME [epoch: 27.6 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.979598433769405		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 2.979598433769405 | validation: 2.7230202771165897]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_83.pth
	Model improved!!!
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.748370044970075		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 3.748370044970075 | validation: 3.8056468388701705]
	TIME [epoch: 27.6 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.277140436173005		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 4.277140436173005 | validation: 4.042297302626389]
	TIME [epoch: 27.6 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7431297612725887		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 3.7431297612725887 | validation: 2.9371184913936714]
	TIME [epoch: 27.6 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.678817577282742		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 2.678817577282742 | validation: 2.543851594041605]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_87.pth
	Model improved!!!
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.627624825479671		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 2.627624825479671 | validation: 2.79347704282193]
	TIME [epoch: 27.6 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5003745410314684		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 2.5003745410314684 | validation: 2.360686475439374]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_89.pth
	Model improved!!!
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9971565430720046		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 2.9971565430720046 | validation: 3.3548970331612384]
	TIME [epoch: 27.6 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.176433543563766		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 3.176433543563766 | validation: 4.1191680520161755]
	TIME [epoch: 27.6 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3206090579091634		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 3.3206090579091634 | validation: 2.3498620691041734]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_92.pth
	Model improved!!!
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.440716224175345		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 2.440716224175345 | validation: 4.967136986025638]
	TIME [epoch: 27.6 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.484437577481096		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 3.484437577481096 | validation: 2.25824651176892]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_94.pth
	Model improved!!!
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3697960657537926		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 2.3697960657537926 | validation: 2.480351573257896]
	TIME [epoch: 27.6 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2890227853933873		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 2.2890227853933873 | validation: 2.2219257543244466]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_96.pth
	Model improved!!!
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1318944594581404		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 2.1318944594581404 | validation: 1.8146373510294767]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9334037677750615		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 1.9334037677750615 | validation: 2.5074801581893724]
	TIME [epoch: 27.6 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.618793059083015		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 2.618793059083015 | validation: 2.21291631619316]
	TIME [epoch: 27.6 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.45518296046797		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 3.45518296046797 | validation: 2.1302914664818675]
	TIME [epoch: 27.6 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0135555033482895		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 3.0135555033482895 | validation: 2.153502059301327]
	TIME [epoch: 27.6 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4160280827108163		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 2.4160280827108163 | validation: 1.9631969557167817]
	TIME [epoch: 27.6 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2069982242395776		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 2.2069982242395776 | validation: 1.917335171373743]
	TIME [epoch: 27.6 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.279930255601513		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 2.279930255601513 | validation: 1.9631794097641484]
	TIME [epoch: 27.6 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5351126582593295		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 2.5351126582593295 | validation: 4.175408122045612]
	TIME [epoch: 27.6 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.13938066542601		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 3.13938066542601 | validation: 2.2668519140469345]
	TIME [epoch: 27.6 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6556382729748944		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 2.6556382729748944 | validation: 2.131945084739972]
	TIME [epoch: 27.6 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0865671936098056		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 2.0865671936098056 | validation: 1.9709028985293828]
	TIME [epoch: 27.6 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9060598490138074		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 1.9060598490138074 | validation: 1.9840767650785258]
	TIME [epoch: 27.6 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8652172745847106		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 1.8652172745847106 | validation: 2.076632596410821]
	TIME [epoch: 27.6 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.272913959090351		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 2.272913959090351 | validation: 2.3471354514644505]
	TIME [epoch: 27.6 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8921685706437787		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 1.8921685706437787 | validation: 1.5356386170299083]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_112.pth
	Model improved!!!
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7498059192082294		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 2.7498059192082294 | validation: 1.8649178237734225]
	TIME [epoch: 27.6 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0275099279363173		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 2.0275099279363173 | validation: 4.567230571410664]
	TIME [epoch: 27.6 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.062793385670488		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 3.062793385670488 | validation: 2.812601453460612]
	TIME [epoch: 27.6 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2149609768362164		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 2.2149609768362164 | validation: 2.685274268715093]
	TIME [epoch: 27.6 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.91253731097171		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 1.91253731097171 | validation: 1.7163313436351342]
	TIME [epoch: 27.6 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.071489935940094		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 2.071489935940094 | validation: 2.5048685327084463]
	TIME [epoch: 27.6 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.267916204041839		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 2.267916204041839 | validation: 2.1158860960359296]
	TIME [epoch: 27.5 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.170443089222431		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 2.170443089222431 | validation: 1.5656307690027416]
	TIME [epoch: 27.6 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.134446930776908		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 3.134446930776908 | validation: 1.7627159116438684]
	TIME [epoch: 27.6 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2389710482626124		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 2.2389710482626124 | validation: 2.078208275514757]
	TIME [epoch: 27.6 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.18626147881737		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 2.18626147881737 | validation: 2.1318062965941977]
	TIME [epoch: 27.6 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3206877325157564		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 2.3206877325157564 | validation: 2.2197503887689285]
	TIME [epoch: 27.6 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.630541340225043		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 2.630541340225043 | validation: 2.3906531805451285]
	TIME [epoch: 27.5 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1565844156023677		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 2.1565844156023677 | validation: 2.1362662181197427]
	TIME [epoch: 27.6 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8331641709987614		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 1.8331641709987614 | validation: 2.22946838871341]
	TIME [epoch: 27.5 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8084332765663649		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 1.8084332765663649 | validation: 2.284900224870099]
	TIME [epoch: 27.6 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1897751052715204		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 3.1897751052715204 | validation: 1.7056631401944724]
	TIME [epoch: 27.6 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9323067570900856		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 1.9323067570900856 | validation: 1.5758009749323953]
	TIME [epoch: 27.6 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8380603288465327		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 1.8380603288465327 | validation: 1.7449335561768504]
	TIME [epoch: 27.6 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.435845094017159		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 2.435845094017159 | validation: 2.9877931234883093]
	TIME [epoch: 27.6 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1837957925725653		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 2.1837957925725653 | validation: 3.0486923811937348]
	TIME [epoch: 27.6 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9536868755928065		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 1.9536868755928065 | validation: 1.4246967515419908]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_134.pth
	Model improved!!!
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8599261763332322		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 1.8599261763332322 | validation: 1.5894946243934518]
	TIME [epoch: 27.6 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6440125597478532		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 1.6440125597478532 | validation: 4.1176026586981935]
	TIME [epoch: 27.6 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8383027248143344		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 2.8383027248143344 | validation: 2.245803033703025]
	TIME [epoch: 27.6 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9653161607630223		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 1.9653161607630223 | validation: 2.698304027905881]
	TIME [epoch: 27.6 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.127091058295401		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 2.127091058295401 | validation: 1.4619154402893508]
	TIME [epoch: 27.6 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2785266751250486		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 2.2785266751250486 | validation: 1.8766962575080317]
	TIME [epoch: 27.6 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.038179563273567		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 2.038179563273567 | validation: 2.9425515310129664]
	TIME [epoch: 27.6 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2030488390096155		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 2.2030488390096155 | validation: 1.5839179865124677]
	TIME [epoch: 27.6 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.067105142722523		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 2.067105142722523 | validation: 1.7735680104408946]
	TIME [epoch: 27.6 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.292203866471507		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 2.292203866471507 | validation: 1.9167958527533155]
	TIME [epoch: 27.5 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8422272232765664		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 1.8422272232765664 | validation: 1.7271046733705226]
	TIME [epoch: 27.6 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0731455573629374		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 2.0731455573629374 | validation: 1.513727289064861]
	TIME [epoch: 27.6 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7966767579863052		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 1.7966767579863052 | validation: 1.493081914775867]
	TIME [epoch: 27.6 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.019049733602903		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 2.019049733602903 | validation: 1.7913568376345723]
	TIME [epoch: 27.7 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.714508268948032		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 2.714508268948032 | validation: 3.0479897920506045]
	TIME [epoch: 27.6 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3927083794023023		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 2.3927083794023023 | validation: 1.6268469832416352]
	TIME [epoch: 27.5 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.643408219112977		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 1.643408219112977 | validation: 1.4517840161631252]
	TIME [epoch: 27.6 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6570294632163916		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 1.6570294632163916 | validation: 3.255000349759332]
	TIME [epoch: 27.6 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5140940625005315		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 2.5140940625005315 | validation: 1.6632939392478694]
	TIME [epoch: 27.5 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8731123885869243		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 1.8731123885869243 | validation: 1.3735606393209059]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_154.pth
	Model improved!!!
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5799877823676494		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 1.5799877823676494 | validation: 1.6427706531357031]
	TIME [epoch: 27.5 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.998357868017929		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 1.998357868017929 | validation: 1.40755089476236]
	TIME [epoch: 27.5 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0306376304991334		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 2.0306376304991334 | validation: 1.3972203893837287]
	TIME [epoch: 27.6 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9603315086255033		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 1.9603315086255033 | validation: 1.9909865446659933]
	TIME [epoch: 27.6 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8170830718922522		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 1.8170830718922522 | validation: 1.463268977749982]
	TIME [epoch: 27.5 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5779182093965742		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 1.5779182093965742 | validation: 1.5814851089064659]
	TIME [epoch: 27.6 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6034850738715867		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 1.6034850738715867 | validation: 1.387384382979168]
	TIME [epoch: 27.5 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6028828920533162		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 1.6028828920533162 | validation: 1.9778569909558223]
	TIME [epoch: 27.6 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7934683920727457		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 1.7934683920727457 | validation: 1.2007790207965625]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_163.pth
	Model improved!!!
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0055150980184213		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 3.0055150980184213 | validation: 5.345172206971595]
	TIME [epoch: 27.6 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.787925499728799		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 2.787925499728799 | validation: 2.4611745954067303]
	TIME [epoch: 27.6 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1324702485285685		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 2.1324702485285685 | validation: 1.3832956605452364]
	TIME [epoch: 27.6 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6238435169844188		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 1.6238435169844188 | validation: 1.3260978403009187]
	TIME [epoch: 27.6 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6592559880586373		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 1.6592559880586373 | validation: 1.414676049131529]
	TIME [epoch: 27.6 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.011323066731231		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 2.011323066731231 | validation: 1.6567429993821838]
	TIME [epoch: 27.6 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4913935165881886		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 1.4913935165881886 | validation: 1.4773842505883612]
	TIME [epoch: 27.6 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5197931426098459		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 1.5197931426098459 | validation: 1.4901367872239846]
	TIME [epoch: 27.6 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.071612652527178		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 2.071612652527178 | validation: 2.0206676180219216]
	TIME [epoch: 27.6 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8169864403911435		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 1.8169864403911435 | validation: 1.3005102900067107]
	TIME [epoch: 27.6 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4755368861031612		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 1.4755368861031612 | validation: 1.1663769600806824]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_174.pth
	Model improved!!!
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7420284126899184		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 1.7420284126899184 | validation: 2.1371575616125513]
	TIME [epoch: 27.6 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7347110395096967		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 3.7347110395096967 | validation: 6.566153913962198]
	TIME [epoch: 27.6 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.892878593233113		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 4.892878593233113 | validation: 1.5890325952267563]
	TIME [epoch: 27.6 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5161235805391042		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 1.5161235805391042 | validation: 1.6307858430979998]
	TIME [epoch: 27.5 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7265442095453876		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 1.7265442095453876 | validation: 1.9484462950518477]
	TIME [epoch: 27.6 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7789421070368203		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 1.7789421070368203 | validation: 1.5297571129992429]
	TIME [epoch: 27.6 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9322914403147144		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 1.9322914403147144 | validation: 2.6349659089700403]
	TIME [epoch: 27.5 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0573649263415246		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 2.0573649263415246 | validation: 1.4598778344125682]
	TIME [epoch: 27.6 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6698249371621423		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 1.6698249371621423 | validation: 1.4592359549907974]
	TIME [epoch: 27.6 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.363473164272684		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 1.363473164272684 | validation: 1.3954879566142555]
	TIME [epoch: 27.6 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.432372394505412		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 1.432372394505412 | validation: 1.3727901395609234]
	TIME [epoch: 27.6 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3474819927570434		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 1.3474819927570434 | validation: 1.747354320759856]
	TIME [epoch: 27.6 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.660683387420058		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 1.660683387420058 | validation: 2.172788717593065]
	TIME [epoch: 27.6 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6707828145238584		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 1.6707828145238584 | validation: 1.9142841130152983]
	TIME [epoch: 27.6 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0737690567896596		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 2.0737690567896596 | validation: 1.5127041210459573]
	TIME [epoch: 27.6 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.893655481313079		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 1.893655481313079 | validation: 1.8129715662910815]
	TIME [epoch: 27.6 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4785911225698785		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 1.4785911225698785 | validation: 1.5255058800785537]
	TIME [epoch: 27.6 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4823415139530043		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 1.4823415139530043 | validation: 1.5006181756611847]
	TIME [epoch: 27.6 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5073143030718126		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 1.5073143030718126 | validation: 1.0564475167983192]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_193.pth
	Model improved!!!
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.440274021181167		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 1.440274021181167 | validation: 1.7612787079084333]
	TIME [epoch: 27.6 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9431464512704013		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 1.9431464512704013 | validation: 2.273459107967765]
	TIME [epoch: 27.5 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5137739952410496		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 1.5137739952410496 | validation: 2.1516751602975037]
	TIME [epoch: 27.6 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2472626439472294		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 2.2472626439472294 | validation: 2.7916979189677202]
	TIME [epoch: 27.6 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.135388327313283		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 2.135388327313283 | validation: 2.174582514418073]
	TIME [epoch: 27.5 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.886743373138966		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 1.886743373138966 | validation: 1.4157514633117]
	TIME [epoch: 27.6 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2886851701949573		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 1.2886851701949573 | validation: 1.1864116829594056]
	TIME [epoch: 27.6 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.236149012643963		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 1.236149012643963 | validation: 1.7361827568638533]
	TIME [epoch: 27.6 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.074346513836952		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 2.074346513836952 | validation: 1.5635597545185607]
	TIME [epoch: 27.6 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9123493021572096		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 1.9123493021572096 | validation: 2.2670771646241854]
	TIME [epoch: 27.6 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8781903823779507		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 1.8781903823779507 | validation: 1.4107530960138868]
	TIME [epoch: 27.5 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6766517818970144		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 1.6766517818970144 | validation: 1.310342458553759]
	TIME [epoch: 27.6 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.818083073346778		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 1.818083073346778 | validation: 1.4486713218725242]
	TIME [epoch: 27.6 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.295053583760753		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 1.295053583760753 | validation: 1.649504566484456]
	TIME [epoch: 27.6 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2930689767354333		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 1.2930689767354333 | validation: 2.5642727626842676]
	TIME [epoch: 27.6 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7533523747590158		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 1.7533523747590158 | validation: 1.1441183774923105]
	TIME [epoch: 27.5 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2423445666432826		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 1.2423445666432826 | validation: 1.2677616537148564]
	TIME [epoch: 27.6 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6117492347874598		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 1.6117492347874598 | validation: 2.7837170865640304]
	TIME [epoch: 27.6 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.135679118711885		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 2.135679118711885 | validation: 2.14775057831989]
	TIME [epoch: 27.5 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5682477951178875		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 1.5682477951178875 | validation: 1.2050983350757394]
	TIME [epoch: 27.6 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.322596050293523		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 1.322596050293523 | validation: 1.4397425620695132]
	TIME [epoch: 27.6 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3582795486580845		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 1.3582795486580845 | validation: 2.3937358746038546]
	TIME [epoch: 27.6 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7718565830820134		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 1.7718565830820134 | validation: 1.5683826950362272]
	TIME [epoch: 27.6 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8824449634791893		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 1.8824449634791893 | validation: 1.4070863766578139]
	TIME [epoch: 27.6 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4047415642644112		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 1.4047415642644112 | validation: 1.5570665997360533]
	TIME [epoch: 27.6 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4524876905269009		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 1.4524876905269009 | validation: 1.6954948640139507]
	TIME [epoch: 27.6 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5716730661950844		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 1.5716730661950844 | validation: 1.2916086859282967]
	TIME [epoch: 27.6 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3706698926219745		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 1.3706698926219745 | validation: 1.6420920504757144]
	TIME [epoch: 27.6 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6435210542773908		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 1.6435210542773908 | validation: 2.2799685226318274]
	TIME [epoch: 27.6 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1036891955865022		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 2.1036891955865022 | validation: 2.12443446321676]
	TIME [epoch: 27.6 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.128252848177074		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 2.128252848177074 | validation: 1.4247552578697396]
	TIME [epoch: 27.5 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.41551127020731		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 1.41551127020731 | validation: 1.2740878911749127]
	TIME [epoch: 27.6 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5602983697642352		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 1.5602983697642352 | validation: 1.3247576417581497]
	TIME [epoch: 27.5 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.476432307686107		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 1.476432307686107 | validation: 1.3215269559127065]
	TIME [epoch: 27.6 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1954065372760065		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 1.1954065372760065 | validation: 1.4196719606657766]
	TIME [epoch: 27.6 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.345893810798696		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 1.345893810798696 | validation: 1.3820404964295556]
	TIME [epoch: 27.6 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4338504135836692		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 1.4338504135836692 | validation: 1.2515898696390626]
	TIME [epoch: 27.6 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6124956811292173		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 1.6124956811292173 | validation: 2.005569961932203]
	TIME [epoch: 27.6 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9038007600949411		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 1.9038007600949411 | validation: 1.6663022312837124]
	TIME [epoch: 27.5 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6551920624778524		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 1.6551920624778524 | validation: 1.3306315870183087]
	TIME [epoch: 27.6 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3528797434355893		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 1.3528797434355893 | validation: 1.7551984628114783]
	TIME [epoch: 27.6 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.840134315269879		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 1.840134315269879 | validation: 1.4503557621774334]
	TIME [epoch: 27.5 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.357510681371964		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 1.357510681371964 | validation: 1.3926199494054499]
	TIME [epoch: 27.6 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.354710453545615		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 1.354710453545615 | validation: 1.3316111087203746]
	TIME [epoch: 27.6 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6620673186978232		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 1.6620673186978232 | validation: 1.2725722275422668]
	TIME [epoch: 27.5 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.274614061911064		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 1.274614061911064 | validation: 1.4817901780590177]
	TIME [epoch: 27.6 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2971016441446297		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 1.2971016441446297 | validation: 1.4608648771671184]
	TIME [epoch: 27.6 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.601100184818474		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 1.601100184818474 | validation: 1.1674450310504385]
	TIME [epoch: 27.6 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2916107776072256		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 1.2916107776072256 | validation: 1.4374151346116901]
	TIME [epoch: 27.6 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2143359011466812		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 1.2143359011466812 | validation: 1.274329467096931]
	TIME [epoch: 27.5 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2733112835047389		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 1.2733112835047389 | validation: 1.354212088027757]
	TIME [epoch: 27.6 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5096913245473265		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 1.5096913245473265 | validation: 1.022100542636075]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_245.pth
	Model improved!!!
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1379418206308844		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 1.1379418206308844 | validation: 1.128811170011427]
	TIME [epoch: 27.5 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2132395559130846		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 1.2132395559130846 | validation: 1.1792209173926742]
	TIME [epoch: 27.6 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3434999084835286		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 1.3434999084835286 | validation: 1.1202564708263787]
	TIME [epoch: 27.6 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0584674759007735		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 1.0584674759007735 | validation: 1.084795716139582]
	TIME [epoch: 27.6 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3691560146512847		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 1.3691560146512847 | validation: 1.4711636061464515]
	TIME [epoch: 27.6 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2645592675968715		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 1.2645592675968715 | validation: 1.0074894754273582]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_251.pth
	Model improved!!!
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1719246791842974		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 1.1719246791842974 | validation: 2.6732048302413274]
	TIME [epoch: 27.6 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7632256577314411		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 1.7632256577314411 | validation: 1.4855502257177806]
	TIME [epoch: 27.6 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.146607334170513		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 1.146607334170513 | validation: 1.4962521498513315]
	TIME [epoch: 27.6 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2702688697572735		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 1.2702688697572735 | validation: 1.775081085944188]
	TIME [epoch: 27.6 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5638177605143238		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 1.5638177605143238 | validation: 1.3292624816031764]
	TIME [epoch: 27.6 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3351495676051914		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 1.3351495676051914 | validation: 1.269750988540225]
	TIME [epoch: 27.5 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0896577338458955		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 1.0896577338458955 | validation: 1.0945815260298424]
	TIME [epoch: 27.6 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3429456610752761		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 1.3429456610752761 | validation: 1.318184323700301]
	TIME [epoch: 27.6 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3596642727669668		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 1.3596642727669668 | validation: 1.1599370943451277]
	TIME [epoch: 27.5 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1713502636175301		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 1.1713502636175301 | validation: 1.7993113334593551]
	TIME [epoch: 27.6 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3384746530212228		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 1.3384746530212228 | validation: 1.5540525181519553]
	TIME [epoch: 27.6 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2335027081781116		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 1.2335027081781116 | validation: 1.4062364570694572]
	TIME [epoch: 27.5 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0764902532335612		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 1.0764902532335612 | validation: 1.6282231370286808]
	TIME [epoch: 27.6 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.18325397810088		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 1.18325397810088 | validation: 1.5240934570844058]
	TIME [epoch: 27.6 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1997788110808099		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 1.1997788110808099 | validation: 1.1375869623944859]
	TIME [epoch: 27.6 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.174595874588037		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 1.174595874588037 | validation: 1.1413604520093548]
	TIME [epoch: 27.6 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5728578532576065		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 1.5728578532576065 | validation: 1.3283878975760945]
	TIME [epoch: 27.6 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2816051570342726		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 1.2816051570342726 | validation: 2.675817170968338]
	TIME [epoch: 27.6 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9501601186072302		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 1.9501601186072302 | validation: 1.035575066864866]
	TIME [epoch: 27.6 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1228623095946217		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 1.1228623095946217 | validation: 0.9561793244617061]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_271.pth
	Model improved!!!
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3472767696266243		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 1.3472767696266243 | validation: 1.1988379852831283]
	TIME [epoch: 27.5 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4264970687063134		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 1.4264970687063134 | validation: 1.8092257013268118]
	TIME [epoch: 27.6 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2731709933241617		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 1.2731709933241617 | validation: 1.10223492976438]
	TIME [epoch: 27.6 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1381373600925566		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 1.1381373600925566 | validation: 1.3884614102795707]
	TIME [epoch: 27.6 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2050725500637691		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 1.2050725500637691 | validation: 1.2043830653689185]
	TIME [epoch: 27.6 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0911953600949653		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 1.0911953600949653 | validation: 1.1051634873668734]
	TIME [epoch: 27.6 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2854921010208353		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 1.2854921010208353 | validation: 1.2536104365134568]
	TIME [epoch: 27.6 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1944584307283663		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 1.1944584307283663 | validation: 1.0133108571594287]
	TIME [epoch: 27.6 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2069173302563638		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 1.2069173302563638 | validation: 1.4987593537296204]
	TIME [epoch: 27.6 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.123058456273123		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 1.123058456273123 | validation: 1.2779036660171632]
	TIME [epoch: 27.6 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.209637960175347		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 1.209637960175347 | validation: 0.9527268752268439]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_282.pth
	Model improved!!!
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.382554312479583		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 1.382554312479583 | validation: 1.0548578642717077]
	TIME [epoch: 27.6 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2147522797265213		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 1.2147522797265213 | validation: 1.3552271752852953]
	TIME [epoch: 27.6 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1494918751671686		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 1.1494918751671686 | validation: 1.1780062274728358]
	TIME [epoch: 27.5 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0707001593888679		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 1.0707001593888679 | validation: 1.0066057517315576]
	TIME [epoch: 27.6 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9398693318563098		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.9398693318563098 | validation: 0.9355869013785543]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_287.pth
	Model improved!!!
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0511873432671237		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 1.0511873432671237 | validation: 1.066589700398774]
	TIME [epoch: 27.6 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.292105378616176		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 1.292105378616176 | validation: 2.093811775999879]
	TIME [epoch: 27.6 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0474966249005184		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 1.0474966249005184 | validation: 1.6624494575047737]
	TIME [epoch: 27.6 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.203214381797646		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 1.203214381797646 | validation: 1.3097535765991495]
	TIME [epoch: 27.5 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9150856183704662		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.9150856183704662 | validation: 2.1142656953643746]
	TIME [epoch: 27.6 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1295043960444702		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 1.1295043960444702 | validation: 1.5902422037196693]
	TIME [epoch: 27.6 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3109019568473521		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 1.3109019568473521 | validation: 1.0099470385107259]
	TIME [epoch: 27.5 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9629651420911619		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.9629651420911619 | validation: 2.154295006476533]
	TIME [epoch: 27.7 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3366273970125337		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 1.3366273970125337 | validation: 0.8800422059897006]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_296.pth
	Model improved!!!
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5304284996707822		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 1.5304284996707822 | validation: 1.0643209654739725]
	TIME [epoch: 27.6 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.963455115339772		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.963455115339772 | validation: 0.9062857597766981]
	TIME [epoch: 27.6 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2511506124775025		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 1.2511506124775025 | validation: 1.390490930043225]
	TIME [epoch: 27.6 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1094989958337227		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 1.1094989958337227 | validation: 1.1298883133487412]
	TIME [epoch: 27.6 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9641663760600911		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.9641663760600911 | validation: 0.8022831943659725]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_301.pth
	Model improved!!!
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0690548658243457		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 1.0690548658243457 | validation: 1.038258660836663]
	TIME [epoch: 27.6 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9472537618659612		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.9472537618659612 | validation: 2.8097283237897672]
	TIME [epoch: 27.6 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.56241624747008		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 1.56241624747008 | validation: 1.0124385813672454]
	TIME [epoch: 27.6 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3546294953509828		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 1.3546294953509828 | validation: 1.3406135924747609]
	TIME [epoch: 27.6 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2994404402029027		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 1.2994404402029027 | validation: 0.9399166009817498]
	TIME [epoch: 27.6 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7510974934897592		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 1.7510974934897592 | validation: 1.383814059208963]
	TIME [epoch: 27.6 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5092376034486366		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 1.5092376034486366 | validation: 1.0893224048052437]
	TIME [epoch: 27.6 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1911806771312539		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 1.1911806771312539 | validation: 0.9897481367614434]
	TIME [epoch: 27.6 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0104466521480955		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 1.0104466521480955 | validation: 2.3550947419490718]
	TIME [epoch: 27.7 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8200590166245247		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 1.8200590166245247 | validation: 3.404823863743271]
	TIME [epoch: 27.6 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.165169438434543		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 2.165169438434543 | validation: 1.1947696648230524]
	TIME [epoch: 27.6 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2327746909716586		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 1.2327746909716586 | validation: 1.0187952419991806]
	TIME [epoch: 27.6 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1798782753201165		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 1.1798782753201165 | validation: 0.9235876985953572]
	TIME [epoch: 27.6 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8613141223029148		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.8613141223029148 | validation: 0.904359965949855]
	TIME [epoch: 27.6 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1406592207562865		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 2.1406592207562865 | validation: 1.5823249767559855]
	TIME [epoch: 27.6 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3737736403667067		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 1.3737736403667067 | validation: 0.974762629457687]
	TIME [epoch: 27.5 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.269956694167342		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 1.269956694167342 | validation: 1.3023759762561395]
	TIME [epoch: 27.6 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0735371432537484		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 1.0735371432537484 | validation: 1.211490913385814]
	TIME [epoch: 27.6 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0968464089771799		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 1.0968464089771799 | validation: 0.9225843180415791]
	TIME [epoch: 27.6 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.23041509911633		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 1.23041509911633 | validation: 0.9371941356646852]
	TIME [epoch: 27.6 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9993446622712683		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.9993446622712683 | validation: 1.0586094414956961]
	TIME [epoch: 27.6 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.212895604661977		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 1.212895604661977 | validation: 0.9177561454380052]
	TIME [epoch: 27.6 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2275491481065968		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 1.2275491481065968 | validation: 0.900275975693356]
	TIME [epoch: 27.6 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9514472059849552		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.9514472059849552 | validation: 0.9273464681059593]
	TIME [epoch: 27.5 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8920539387248294		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.8920539387248294 | validation: 1.1335828287030492]
	TIME [epoch: 27.7 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.326513391055861		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 1.326513391055861 | validation: 1.0485215357739894]
	TIME [epoch: 27.6 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0333100155025456		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 1.0333100155025456 | validation: 0.9410434049310787]
	TIME [epoch: 27.6 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9206849417996851		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.9206849417996851 | validation: 1.135545146547889]
	TIME [epoch: 27.7 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0253262664359613		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 1.0253262664359613 | validation: 0.8502898711531348]
	TIME [epoch: 27.7 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.184941120790756		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 1.184941120790756 | validation: 1.410654287751605]
	TIME [epoch: 27.6 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.09733831534944		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 1.09733831534944 | validation: 0.8678765569052665]
	TIME [epoch: 27.7 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.583595807638068		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 1.583595807638068 | validation: 1.5152608778267849]
	TIME [epoch: 27.6 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0534335436419566		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 1.0534335436419566 | validation: 0.9764454269532529]
	TIME [epoch: 27.6 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2673095843542295		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 1.2673095843542295 | validation: 1.1849404501027179]
	TIME [epoch: 27.6 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1204414923526977		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 1.1204414923526977 | validation: 2.16388602412586]
	TIME [epoch: 27.6 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4527985771054222		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 1.4527985771054222 | validation: 1.187495752859659]
	TIME [epoch: 27.6 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0187534893502084		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 1.0187534893502084 | validation: 1.0460133135984842]
	TIME [epoch: 27.6 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.90080557434924		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.90080557434924 | validation: 0.9714072949520519]
	TIME [epoch: 27.6 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1468188183893127		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 1.1468188183893127 | validation: 0.9820643622855286]
	TIME [epoch: 27.6 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9849397601092438		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.9849397601092438 | validation: 1.3307818240637652]
	TIME [epoch: 27.7 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9483020310734592		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.9483020310734592 | validation: 1.2168482032741028]
	TIME [epoch: 27.6 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1274058143216061		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 1.1274058143216061 | validation: 0.9379630080356239]
	TIME [epoch: 27.7 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.947997499888689		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.947997499888689 | validation: 0.9248505679835307]
	TIME [epoch: 27.7 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8246094294474589		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 1.8246094294474589 | validation: 6.102343361242734]
	TIME [epoch: 27.6 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.348368945753783		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 6.348368945753783 | validation: 5.511085865572138]
	TIME [epoch: 27.6 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.305675956173514		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 6.305675956173514 | validation: 5.580031827444948]
	TIME [epoch: 27.6 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.26620012279871		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 6.26620012279871 | validation: 5.7229423911981145]
	TIME [epoch: 27.5 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.325085276919853		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 6.325085276919853 | validation: 5.622974608576495]
	TIME [epoch: 27.6 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.3091004639618165		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 6.3091004639618165 | validation: 5.558117288539515]
	TIME [epoch: 27.5 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.2873653002325005		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 6.2873653002325005 | validation: 5.574212071989055]
	TIME [epoch: 27.6 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.305205195547321		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 6.305205195547321 | validation: 5.627145297598599]
	TIME [epoch: 27.6 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.367050473099852		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 6.367050473099852 | validation: 5.635277947665785]
	TIME [epoch: 27.5 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.312272869593933		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 6.312272869593933 | validation: 5.536540284339524]
	TIME [epoch: 27.5 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.227987753558097		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 6.227987753558097 | validation: 5.665256288238728]
	TIME [epoch: 27.6 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.2617582123533815		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 6.2617582123533815 | validation: 5.508513218258433]
	TIME [epoch: 27.5 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.300359815636537		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 6.300359815636537 | validation: 5.628578951727987]
	TIME [epoch: 27.6 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.333719885633643		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 6.333719885633643 | validation: 5.5652923368512415]
	TIME [epoch: 27.6 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.2689247054916235		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 6.2689247054916235 | validation: 5.514836603766715]
	TIME [epoch: 27.6 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.2661182792196986		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 6.2661182792196986 | validation: 5.572468390255274]
	TIME [epoch: 27.6 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.253847561113577		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 6.253847561113577 | validation: 5.635961489751747]
	TIME [epoch: 27.6 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.276161905871037		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 6.276161905871037 | validation: 5.586532345803871]
	TIME [epoch: 27.6 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.262776598324096		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 6.262776598324096 | validation: 5.564951814895185]
	TIME [epoch: 27.6 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.243759218051675		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 6.243759218051675 | validation: 5.522178029234168]
	TIME [epoch: 27.6 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.3483203970317135		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 6.3483203970317135 | validation: 5.5356614917508455]
	TIME [epoch: 27.5 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.297967733675012		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 6.297967733675012 | validation: 5.5203805652731965]
	TIME [epoch: 27.6 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.285905390291235		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 6.285905390291235 | validation: 5.508085749490581]
	TIME [epoch: 27.6 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.30828480838798		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 6.30828480838798 | validation: 5.5408342009976925]
	TIME [epoch: 27.6 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.303299227609663		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 6.303299227609663 | validation: 5.650443222468103]
	TIME [epoch: 27.6 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.268712032979535		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 6.268712032979535 | validation: 5.557534331708264]
	TIME [epoch: 27.6 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.250824909939599		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 6.250824909939599 | validation: 5.464929608288844]
	TIME [epoch: 27.5 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.254004339386258		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 6.254004339386258 | validation: 5.331950454775868]
	TIME [epoch: 27.6 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.2014035149109334		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 6.2014035149109334 | validation: 5.516380759205119]
	TIME [epoch: 27.6 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.2731071984194475		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 6.2731071984194475 | validation: 5.6258142023123625]
	TIME [epoch: 27.6 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.2951246796876195		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 6.2951246796876195 | validation: 5.62669242650235]
	TIME [epoch: 27.6 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.34104721722974		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 6.34104721722974 | validation: 5.533732374500038]
	TIME [epoch: 27.6 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.283461103889182		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 6.283461103889182 | validation: 5.686870671095871]
	TIME [epoch: 27.6 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.351820534452036		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 6.351820534452036 | validation: 5.49454670419201]
	TIME [epoch: 27.6 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.316971357499822		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 6.316971357499822 | validation: 5.559704862274925]
	TIME [epoch: 27.6 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.286104986455215		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 6.286104986455215 | validation: 5.56318229826575]
	TIME [epoch: 27.6 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.299277253469164		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 6.299277253469164 | validation: 6.5237890699957175]
	TIME [epoch: 27.6 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.544195986034959		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 6.544195986034959 | validation: 5.540435723632531]
	TIME [epoch: 27.6 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.280345108896606		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 6.280345108896606 | validation: 5.583332104949716]
	TIME [epoch: 27.6 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.236793971750741		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 6.236793971750741 | validation: 5.613933018465608]
	TIME [epoch: 27.5 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.341229504558357		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 6.341229504558357 | validation: 5.686165534069691]
	TIME [epoch: 27.6 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.409326073504836		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 6.409326073504836 | validation: 5.577106086834249]
	TIME [epoch: 27.5 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.334304205744937		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 6.334304205744937 | validation: 5.712643180127161]
	TIME [epoch: 27.6 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.37134961270934		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 6.37134961270934 | validation: 5.539657869042584]
	TIME [epoch: 27.6 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.366588337649898		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 6.366588337649898 | validation: 5.689322432026276]
	TIME [epoch: 27.6 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.358238885293688		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 6.358238885293688 | validation: 5.68264619004667]
	TIME [epoch: 27.5 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.352550444505553		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 6.352550444505553 | validation: 5.614290171792057]
	TIME [epoch: 27.6 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.345664855544164		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 6.345664855544164 | validation: 5.657838947177355]
	TIME [epoch: 27.6 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.311139285203019		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 6.311139285203019 | validation: 5.499237092770236]
	TIME [epoch: 27.5 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.360999715812733		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 6.360999715812733 | validation: 5.628692651104601]
	TIME [epoch: 27.6 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.32544357670768		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 6.32544357670768 | validation: 5.498435702889971]
	TIME [epoch: 27.6 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.369287371378698		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 6.369287371378698 | validation: 5.576543696212577]
	TIME [epoch: 27.5 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.308104481502592		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 6.308104481502592 | validation: 5.501699354307954]
	TIME [epoch: 27.6 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.341825724562296		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 6.341825724562296 | validation: 5.456929919502374]
	TIME [epoch: 27.5 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.2969026876333505		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 6.2969026876333505 | validation: 5.596502490782938]
	TIME [epoch: 27.5 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.2962911577356335		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 6.2962911577356335 | validation: 5.530879734183388]
	TIME [epoch: 27.5 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.278254800190108		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 6.278254800190108 | validation: 5.582507097806406]
	TIME [epoch: 27.5 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.290440254640872		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 6.290440254640872 | validation: 5.818664910676317]
	TIME [epoch: 27.5 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.386304788101061		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 6.386304788101061 | validation: 5.641605930944815]
	TIME [epoch: 27.5 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.43458151245208		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 6.43458151245208 | validation: 5.515406988704581]
	TIME [epoch: 27.5 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.320924541529127		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 6.320924541529127 | validation: 5.49668575511526]
	TIME [epoch: 27.5 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.34801130726698		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 6.34801130726698 | validation: 5.548324195996505]
	TIME [epoch: 27.5 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.421436769595781		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 6.421436769595781 | validation: 5.782184069375571]
	TIME [epoch: 27.5 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.484635358065934		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 6.484635358065934 | validation: 5.718132289044913]
	TIME [epoch: 27.6 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.564483906230205		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 6.564483906230205 | validation: 5.6018583268969575]
	TIME [epoch: 27.5 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.547987066252146		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 6.547987066252146 | validation: 5.592052383732793]
	TIME [epoch: 27.6 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.522330209935797		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 6.522330209935797 | validation: 5.656402739456819]
	TIME [epoch: 27.6 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.593711566647313		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 6.593711566647313 | validation: 5.771149429403968]
	TIME [epoch: 27.6 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.568607879927567		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 6.568607879927567 | validation: 5.7989281115941145]
	TIME [epoch: 27.6 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.54212754875425		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 6.54212754875425 | validation: 5.735896286461728]
	TIME [epoch: 27.6 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.516761882580412		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 6.516761882580412 | validation: 5.6686884258555805]
	TIME [epoch: 27.5 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.517600227341471		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 6.517600227341471 | validation: 5.749199468012629]
	TIME [epoch: 27.5 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.49949663190122		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 6.49949663190122 | validation: 5.713662739836297]
	TIME [epoch: 27.5 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.5330609089787455		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 6.5330609089787455 | validation: 5.6948254950197805]
	TIME [epoch: 27.6 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.507100943698546		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 6.507100943698546 | validation: 5.722814855823332]
	TIME [epoch: 27.6 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.535946924354709		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 6.535946924354709 | validation: 6.629814140677229]
	TIME [epoch: 27.5 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.812005831429666		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 6.812005831429666 | validation: 5.60066720071509]
	TIME [epoch: 27.5 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.386114880308667		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 6.386114880308667 | validation: 5.705775327827332]
	TIME [epoch: 27.6 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.506859754246299		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 6.506859754246299 | validation: 5.661565908012224]
	TIME [epoch: 27.6 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.493879079468251		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 6.493879079468251 | validation: 5.892086656916739]
	TIME [epoch: 27.5 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.546675843143491		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 6.546675843143491 | validation: 5.656985787819716]
	TIME [epoch: 27.6 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.554270504930447		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 6.554270504930447 | validation: 6.10648131818843]
	TIME [epoch: 27.5 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.577511044210887		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 6.577511044210887 | validation: 5.6288228812984995]
	TIME [epoch: 27.5 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.8187750180035485		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 6.8187750180035485 | validation: 6.232163974933297]
	TIME [epoch: 27.6 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.904552383982097		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 6.904552383982097 | validation: 5.886090396899257]
	TIME [epoch: 27.5 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.813657302676555		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 6.813657302676555 | validation: 5.925129744583315]
	TIME [epoch: 27.5 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.809609182018177		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 6.809609182018177 | validation: 6.035337125751505]
	TIME [epoch: 27.6 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.906171074678713		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 6.906171074678713 | validation: 5.942593356735038]
	TIME [epoch: 27.6 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.656179587555151		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 6.656179587555151 | validation: 5.6936143144512155]
	TIME [epoch: 27.6 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.610131221606437		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 6.610131221606437 | validation: 5.8365199993622]
	TIME [epoch: 27.5 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.580646934876434		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 6.580646934876434 | validation: 5.605811581230461]
	TIME [epoch: 27.5 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.532911948132912		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 6.532911948132912 | validation: 5.509182481331838]
	TIME [epoch: 27.6 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.446330661189956		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 6.446330661189956 | validation: 5.63273425754207]
	TIME [epoch: 27.6 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.42697298724295		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 6.42697298724295 | validation: 5.731408859170724]
	TIME [epoch: 27.5 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.578667341147237		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 6.578667341147237 | validation: 5.746266000039384]
	TIME [epoch: 27.5 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.496429609558234		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 6.496429609558234 | validation: 5.619633519780535]
	TIME [epoch: 27.6 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.483537963539726		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 6.483537963539726 | validation: 5.656935950532208]
	TIME [epoch: 27.5 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.594554888481423		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 6.594554888481423 | validation: 5.681135466328051]
	TIME [epoch: 27.6 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.6414196999874235		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 6.6414196999874235 | validation: 5.75083581002556]
	TIME [epoch: 27.5 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.595879263430588		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 6.595879263430588 | validation: 5.704440266312183]
	TIME [epoch: 27.5 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.57159746721665		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 6.57159746721665 | validation: 5.689077118376607]
	TIME [epoch: 27.6 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.560073900989958		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 6.560073900989958 | validation: 5.619673790974498]
	TIME [epoch: 27.5 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.59612746002555		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 6.59612746002555 | validation: 5.80736148268654]
	TIME [epoch: 27.5 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.567819891563881		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 6.567819891563881 | validation: 5.777745474368287]
	TIME [epoch: 27.5 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.593509240554074		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 6.593509240554074 | validation: 5.840099827167023]
	TIME [epoch: 27.5 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.66339787385047		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 6.66339787385047 | validation: 5.792058783671818]
	TIME [epoch: 27.5 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.567572349588149		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 6.567572349588149 | validation: 5.677255543441527]
	TIME [epoch: 27.6 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.508542183232544		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 6.508542183232544 | validation: 5.69710702950759]
	TIME [epoch: 27.5 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.545649027394599		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 6.545649027394599 | validation: 5.63858991419437]
	TIME [epoch: 27.6 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.545970757860641		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 6.545970757860641 | validation: 5.648500310137888]
	TIME [epoch: 27.6 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.54166173288667		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 6.54166173288667 | validation: 5.617821030337537]
	TIME [epoch: 27.5 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.567940747056084		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 6.567940747056084 | validation: 5.693399075006494]
	TIME [epoch: 27.6 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.602242627768183		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 6.602242627768183 | validation: 5.794454584085817]
	TIME [epoch: 27.5 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.584212341904472		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 6.584212341904472 | validation: 6.097336033305883]
	TIME [epoch: 27.5 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.683729566596062		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 6.683729566596062 | validation: 5.874221310457907]
	TIME [epoch: 27.6 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.721558930416644		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 6.721558930416644 | validation: 5.8681215308615435]
	TIME [epoch: 27.5 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.7183861722583975		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 6.7183861722583975 | validation: 5.881272112135965]
	TIME [epoch: 27.5 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.815352776791537		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 6.815352776791537 | validation: 6.095452455316302]
	TIME [epoch: 27.6 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.7604074701060295		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 6.7604074701060295 | validation: 5.958065309949884]
	TIME [epoch: 27.5 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.734993894160357		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 6.734993894160357 | validation: 6.000200535203858]
	TIME [epoch: 27.6 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.741554336965772		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 6.741554336965772 | validation: 5.921382002844561]
	TIME [epoch: 27.6 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.711900939709876		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 6.711900939709876 | validation: 5.690508451999923]
	TIME [epoch: 27.5 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.615561757333143		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 6.615561757333143 | validation: 5.710605018280751]
	TIME [epoch: 27.5 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.6493386047633445		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 6.6493386047633445 | validation: 5.763170030211927]
	TIME [epoch: 27.6 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.627393127612217		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 6.627393127612217 | validation: 5.776807276486045]
	TIME [epoch: 27.5 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.740348844833378		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 6.740348844833378 | validation: 6.181791771112135]
	TIME [epoch: 27.5 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.695880519105417		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 6.695880519105417 | validation: 5.770332347371124]
	TIME [epoch: 27.5 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.664917805368081		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 6.664917805368081 | validation: 5.885106061471617]
	TIME [epoch: 27.5 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.749809494803866		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 6.749809494803866 | validation: 5.905040109780156]
	TIME [epoch: 27.6 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.792652595826066		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 6.792652595826066 | validation: 5.967894322703873]
	TIME [epoch: 27.5 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.6820860164200955		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 6.6820860164200955 | validation: 5.837476836064561]
	TIME [epoch: 27.6 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.6804552407051725		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 6.6804552407051725 | validation: 5.8048030274508085]
	TIME [epoch: 27.5 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.651193659401545		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 6.651193659401545 | validation: 5.78717724726551]
	TIME [epoch: 27.6 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.692739357337792		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 6.692739357337792 | validation: 5.7952876170996594]
	TIME [epoch: 27.5 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.808845994710191		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 6.808845994710191 | validation: 5.942805214251527]
	TIME [epoch: 27.6 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.761766619534146		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 6.761766619534146 | validation: 5.895712561749715]
	TIME [epoch: 27.6 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.802371238473893		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 6.802371238473893 | validation: 5.81385332438944]
	TIME [epoch: 27.6 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.839156875409631		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 6.839156875409631 | validation: 5.812314397952827]
	TIME [epoch: 27.6 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.680506737405382		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 6.680506737405382 | validation: 5.8809567615567175]
	TIME [epoch: 27.5 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.7731259611726395		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 6.7731259611726395 | validation: 5.78730977769173]
	TIME [epoch: 27.5 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.66382324355876		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 6.66382324355876 | validation: 6.00233423794577]
	TIME [epoch: 27.6 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.878323069627336		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 6.878323069627336 | validation: 6.100917683638313]
	TIME [epoch: 27.5 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.936448334428672		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 6.936448334428672 | validation: 6.069551497139448]
	TIME [epoch: 27.6 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.872966816426851		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 6.872966816426851 | validation: 5.966028458221076]
	TIME [epoch: 27.5 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.8658893459345425		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 6.8658893459345425 | validation: 5.9724326598558015]
	TIME [epoch: 27.5 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.885697938959053		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 6.885697938959053 | validation: 6.0403633322413794]
	TIME [epoch: 27.5 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.8734749206851165		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 6.8734749206851165 | validation: 5.984363246670039]
	TIME [epoch: 27.5 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.813488608729564		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 6.813488608729564 | validation: 5.843941878787489]
	TIME [epoch: 27.5 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.828140507366961		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 6.828140507366961 | validation: 5.926113441048858]
	TIME [epoch: 27.6 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.8350707739201315		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 6.8350707739201315 | validation: 5.933047984389248]
	TIME [epoch: 27.5 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.832140995489284		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 6.832140995489284 | validation: 5.889989284859378]
	TIME [epoch: 27.6 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.915823972971021		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 6.915823972971021 | validation: 5.932177168683633]
	TIME [epoch: 27.6 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.810984108815381		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 6.810984108815381 | validation: 5.996691677586851]
	TIME [epoch: 27.6 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.8982195891355875		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 6.8982195891355875 | validation: 5.958494652169653]
	TIME [epoch: 27.6 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.851328177421334		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 6.851328177421334 | validation: 6.027305922078726]
	TIME [epoch: 27.6 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.835794008418197		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 6.835794008418197 | validation: 5.887461361918691]
	TIME [epoch: 27.6 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.876025998166457		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 6.876025998166457 | validation: 5.959313264709]
	TIME [epoch: 27.6 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.798257728560453		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 6.798257728560453 | validation: 5.9125970528557374]
	TIME [epoch: 27.6 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.769322671785877		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 6.769322671785877 | validation: 5.867130035415894]
	TIME [epoch: 27.5 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.834594168737683		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 6.834594168737683 | validation: 5.8632143495780245]
	TIME [epoch: 27.6 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.823321057906168		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 6.823321057906168 | validation: 5.887003510503562]
	TIME [epoch: 27.6 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.822954415344537		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 6.822954415344537 | validation: 5.988394435026675]
	TIME [epoch: 27.7 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.857992228126339		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 6.857992228126339 | validation: 5.9634115026614225]
	TIME [epoch: 27.6 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.836365934465901		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 6.836365934465901 | validation: 5.886136979110498]
	TIME [epoch: 27.6 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.8398386349819145		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 6.8398386349819145 | validation: 5.8192388942556885]
	TIME [epoch: 27.6 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.760932886168682		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 6.760932886168682 | validation: 5.835506719973041]
	TIME [epoch: 27.6 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.768416469779482		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 6.768416469779482 | validation: 5.843132153042346]
	TIME [epoch: 27.6 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.84279871941664		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 6.84279871941664 | validation: 5.907820436960558]
	TIME [epoch: 27.6 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.863744255534264		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 6.863744255534264 | validation: 6.015418082407308]
	TIME [epoch: 27.5 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.857899433733673		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 6.857899433733673 | validation: 5.946415037950057]
	TIME [epoch: 27.5 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.844971676785249		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 6.844971676785249 | validation: 5.955788629637855]
	TIME [epoch: 27.6 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.957727772987722		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 6.957727772987722 | validation: 5.941785066592151]
	TIME [epoch: 27.6 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.904675413451976		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 6.904675413451976 | validation: 6.063490051356369]
	TIME [epoch: 27.6 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.977294044298304		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 6.977294044298304 | validation: 5.939198836668233]
	TIME [epoch: 27.6 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.908344918425537		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 6.908344918425537 | validation: 5.93150593462689]
	TIME [epoch: 27.6 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.902503882652992		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 6.902503882652992 | validation: 5.990761883643184]
	TIME [epoch: 27.6 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.924571460691369		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 6.924571460691369 | validation: 6.066927371931201]
	TIME [epoch: 27.6 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.911303750760237		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 6.911303750760237 | validation: 5.995653355677948]
	TIME [epoch: 27.6 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.949648661342746		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 6.949648661342746 | validation: 5.914131341890148]
	TIME [epoch: 27.6 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.924070599744505		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 6.924070599744505 | validation: 5.90715614032848]
	TIME [epoch: 27.6 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.937317242347422		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 6.937317242347422 | validation: 5.925941350866106]
	TIME [epoch: 27.5 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.955185084506683		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 6.955185084506683 | validation: 6.158033773260868]
	TIME [epoch: 27.6 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.972799189209179		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 6.972799189209179 | validation: 5.953086922904403]
	TIME [epoch: 27.6 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.9350651819291596		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 6.9350651819291596 | validation: 5.937310244058823]
	TIME [epoch: 27.6 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.90013052948454		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 6.90013052948454 | validation: 5.9253802818111305]
	TIME [epoch: 27.6 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.8906983668638615		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 6.8906983668638615 | validation: 6.066251464018976]
	TIME [epoch: 27.6 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.920099255380032		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 6.920099255380032 | validation: 6.029193299526441]
	TIME [epoch: 27.6 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.8754367098862765		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 6.8754367098862765 | validation: 6.173472279493649]
	TIME [epoch: 27.6 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.995034261955489		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 6.995034261955489 | validation: 5.915805253644188]
	TIME [epoch: 27.6 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.906952862811581		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 6.906952862811581 | validation: 5.977061309633448]
	TIME [epoch: 27.5 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.900030407424213		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 6.900030407424213 | validation: 5.912982712878541]
	TIME [epoch: 27.6 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.885264474186376		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 6.885264474186376 | validation: 5.915532950060022]
	TIME [epoch: 27.6 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.099897595409644		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 7.099897595409644 | validation: 5.942847483561012]
	TIME [epoch: 27.5 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.699282712685198		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 6.699282712685198 | validation: 5.873671492644426]
	TIME [epoch: 27.6 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.5817524063929564		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 6.5817524063929564 | validation: 5.669842934887981]
	TIME [epoch: 27.5 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.812558062845818		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 6.812558062845818 | validation: 5.860723495279964]
	TIME [epoch: 27.5 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.766421949943382		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 6.766421949943382 | validation: 5.860129276219685]
	TIME [epoch: 27.6 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.744837543182575		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 6.744837543182575 | validation: 5.812012010656317]
	TIME [epoch: 27.6 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.783457563703582		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 6.783457563703582 | validation: 5.905643756671719]
	TIME [epoch: 27.6 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.763318382430051		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 6.763318382430051 | validation: 5.819860452507657]
	TIME [epoch: 27.6 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.7423403470943395		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 6.7423403470943395 | validation: 5.8254543804084316]
	TIME [epoch: 27.5 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.806009226615542		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 6.806009226615542 | validation: 5.75157788957169]
	TIME [epoch: 27.6 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.769112405632044		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 6.769112405632044 | validation: 5.968954080650247]
	TIME [epoch: 27.6 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.864190093874965		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 6.864190093874965 | validation: 5.949354205104824]
	TIME [epoch: 27.5 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.85896660497094		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 6.85896660497094 | validation: 6.019666543408873]
	TIME [epoch: 27.6 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.8703311493962165		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 6.8703311493962165 | validation: 5.965162812441645]
	TIME [epoch: 27.5 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.887049777529319		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 6.887049777529319 | validation: 5.967147326744654]
	TIME [epoch: 27.5 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.876556704926046		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 6.876556704926046 | validation: 6.021272913293021]
	TIME [epoch: 27.5 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.919134593571177		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 6.919134593571177 | validation: 5.935287614029344]
	TIME [epoch: 27.6 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.891455416651119		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 6.891455416651119 | validation: 5.964451350058119]
	TIME [epoch: 27.6 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.934252179692809		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 6.934252179692809 | validation: 6.00712883561651]
	TIME [epoch: 27.6 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.882993639611171		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 6.882993639611171 | validation: 5.92171997138117]
	TIME [epoch: 27.5 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.88920932715975		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 6.88920932715975 | validation: 6.022297719738274]
	TIME [epoch: 27.5 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.955979678338008		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 6.955979678338008 | validation: 6.138214351160051]
	TIME [epoch: 27.6 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.892433989552408		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 6.892433989552408 | validation: 5.95104846815162]
	TIME [epoch: 27.5 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.950023973085639		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 6.950023973085639 | validation: 5.917320077557815]
	TIME [epoch: 27.5 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.891571350943261		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 6.891571350943261 | validation: 5.918120549841656]
	TIME [epoch: 27.5 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.859175144087198		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 6.859175144087198 | validation: 6.040983051986707]
	TIME [epoch: 27.5 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.929415347282913		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 6.929415347282913 | validation: 5.9070092803540515]
	TIME [epoch: 27.5 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.907397326633687		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 6.907397326633687 | validation: 5.9440003187700485]
	TIME [epoch: 27.5 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.860195449881779		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 6.860195449881779 | validation: 5.88020122800265]
	TIME [epoch: 27.6 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.832034936523324		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 6.832034936523324 | validation: 5.859447669593021]
	TIME [epoch: 27.5 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.871016381290743		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 6.871016381290743 | validation: 5.882416863356053]
	TIME [epoch: 27.6 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.848374668513299		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 6.848374668513299 | validation: 5.973705107338749]
	TIME [epoch: 27.5 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.8832733849845456		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 6.8832733849845456 | validation: 6.005077636410635]
	TIME [epoch: 27.5 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.854525996751785		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 6.854525996751785 | validation: 5.921417451680034]
	TIME [epoch: 27.5 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.850728649415826		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 6.850728649415826 | validation: 5.978524871051559]
	TIME [epoch: 27.5 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.859227079311031		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 6.859227079311031 | validation: 6.17514081403237]
	TIME [epoch: 27.5 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.945852603661557		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 6.945852603661557 | validation: 5.918817576723483]
	TIME [epoch: 27.6 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.8885028061237925		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 6.8885028061237925 | validation: 5.942926291420739]
	TIME [epoch: 27.5 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.86003525748461		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 6.86003525748461 | validation: 5.8921306887547145]
	TIME [epoch: 27.5 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.926177198617076		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 6.926177198617076 | validation: 5.966012704657369]
	TIME [epoch: 27.6 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.887536412048011		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 6.887536412048011 | validation: 5.909350832190792]
	TIME [epoch: 27.5 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.8484886586781135		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 6.8484886586781135 | validation: 5.983541540976512]
	TIME [epoch: 27.6 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.8662269081300344		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 6.8662269081300344 | validation: 5.939786680451105]
	TIME [epoch: 27.5 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.840428404457184		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 6.840428404457184 | validation: 5.894508331278242]
	TIME [epoch: 27.7 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.8384860413938515		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 6.8384860413938515 | validation: 5.946471244022196]
	TIME [epoch: 27.5 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.829278057036362		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 6.829278057036362 | validation: 6.022626822323448]
	TIME [epoch: 27.6 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.8525988798836615		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 6.8525988798836615 | validation: 5.985645176082303]
	TIME [epoch: 27.6 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.902683465112232		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 6.902683465112232 | validation: 5.920665647820536]
	TIME [epoch: 27.6 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.8189100024289395		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 6.8189100024289395 | validation: 6.046283244323823]
	TIME [epoch: 27.6 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.904196670971787		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 6.904196670971787 | validation: 5.955440499715167]
	TIME [epoch: 27.6 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.852684720147723		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 6.852684720147723 | validation: 5.908528230469769]
	TIME [epoch: 27.6 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.918265470381864		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 6.918265470381864 | validation: 5.968617041089283]
	TIME [epoch: 27.6 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.930674098879407		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 6.930674098879407 | validation: 5.950100960626514]
	TIME [epoch: 27.6 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.928247992831026		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 6.928247992831026 | validation: 5.94874796979765]
	TIME [epoch: 27.6 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.869916963457443		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 6.869916963457443 | validation: 5.893955377428178]
	TIME [epoch: 27.6 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.898206442111064		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 6.898206442111064 | validation: 5.895986995213362]
	TIME [epoch: 27.6 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.88454368622692		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 6.88454368622692 | validation: 5.923892598095005]
	TIME [epoch: 27.6 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.9028620908148355		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 6.9028620908148355 | validation: 5.919847635616884]
	TIME [epoch: 27.6 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.795768473011293		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 6.795768473011293 | validation: 5.897135387333184]
	TIME [epoch: 27.6 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.805844158280298		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 6.805844158280298 | validation: 5.918127978132695]
	TIME [epoch: 27.5 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.8707505369240724		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 6.8707505369240724 | validation: 5.913440738195564]
	TIME [epoch: 27.7 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.802080888124847		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 6.802080888124847 | validation: 5.8524380331327]
	TIME [epoch: 27.6 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.800000892250239		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 6.800000892250239 | validation: 5.934511641894687]
	TIME [epoch: 27.6 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.865423054263492		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 6.865423054263492 | validation: 5.96389396778059]
	TIME [epoch: 27.6 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.978818363658985		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 6.978818363658985 | validation: 6.06880501307116]
	TIME [epoch: 27.5 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.912739442141942		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 6.912739442141942 | validation: 6.001003515706491]
	TIME [epoch: 27.5 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.821797461734181		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 6.821797461734181 | validation: 6.059879478208552]
	TIME [epoch: 27.6 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.952305083126202		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 6.952305083126202 | validation: 5.915128992358441]
	TIME [epoch: 27.6 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.8532585393280145		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 6.8532585393280145 | validation: 5.948247961502114]
	TIME [epoch: 27.6 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.898830804970688		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 6.898830804970688 | validation: 5.910573694810635]
	TIME [epoch: 27.5 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.8704875913186125		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 6.8704875913186125 | validation: 5.884394367823072]
	TIME [epoch: 27.6 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.8516548538469735		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 6.8516548538469735 | validation: 5.866230698483105]
	TIME [epoch: 27.5 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.835103881109104		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 6.835103881109104 | validation: 5.859545115133367]
	TIME [epoch: 27.6 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.889429440549537		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 6.889429440549537 | validation: 6.0632322114123784]
	TIME [epoch: 27.5 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.950651804343172		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 6.950651804343172 | validation: 5.929461036575197]
	TIME [epoch: 27.6 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.9117226303506		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 6.9117226303506 | validation: 5.880306712013276]
	TIME [epoch: 27.6 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.912201596040767		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 6.912201596040767 | validation: 6.1088364376289475]
	TIME [epoch: 27.6 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.98739796367778		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 6.98739796367778 | validation: 5.894112137016648]
	TIME [epoch: 27.6 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.921503241838584		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 6.921503241838584 | validation: 6.066624998580818]
	TIME [epoch: 27.6 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.956659785242916		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 6.956659785242916 | validation: 6.060222629371293]
	TIME [epoch: 27.5 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.994904624626649		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 6.994904624626649 | validation: 5.8935880305988535]
	TIME [epoch: 27.6 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.944042657587868		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 6.944042657587868 | validation: 6.053485074273906]
	TIME [epoch: 27.5 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.950186352141772		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 6.950186352141772 | validation: 5.920564367822253]
	TIME [epoch: 27.6 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.947246501107621		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 6.947246501107621 | validation: 5.903739315461594]
	TIME [epoch: 27.6 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.983912909838046		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 6.983912909838046 | validation: 5.889075257034183]
	TIME [epoch: 27.5 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.919221650945369		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 6.919221650945369 | validation: 5.93464590110712]
	TIME [epoch: 27.6 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.9173047802938505		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 6.9173047802938505 | validation: 5.888355344734812]
	TIME [epoch: 27.6 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.906955216424044		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 6.906955216424044 | validation: 5.90019751094879]
	TIME [epoch: 27.6 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.903871377846154		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 6.903871377846154 | validation: 5.934622920179781]
	TIME [epoch: 27.6 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.9343517668992956		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 6.9343517668992956 | validation: 5.894077778162354]
	TIME [epoch: 27.6 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.956329934628313		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 6.956329934628313 | validation: 5.9116327159071735]
	TIME [epoch: 27.5 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.937701852854321		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 6.937701852854321 | validation: 6.040133903170688]
	TIME [epoch: 27.6 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.9578764511668005		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 6.9578764511668005 | validation: 5.930611123999572]
	TIME [epoch: 27.6 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.996178041615438		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 6.996178041615438 | validation: 5.866829069110202]
	TIME [epoch: 27.5 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.924289457427834		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 6.924289457427834 | validation: 5.901451739234075]
	TIME [epoch: 27.6 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.950666641782423		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 6.950666641782423 | validation: 5.902883473786439]
	TIME [epoch: 27.5 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.904840980731169		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 6.904840980731169 | validation: 5.911628994272662]
	TIME [epoch: 27.5 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.930749728012417		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 6.930749728012417 | validation: 5.898562658889871]
	TIME [epoch: 27.6 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.925632025707027		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 6.925632025707027 | validation: 5.891984035769183]
	TIME [epoch: 27.5 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.9489866458277785		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 6.9489866458277785 | validation: 5.904280638337702]
	TIME [epoch: 27.6 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.895172745493073		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 6.895172745493073 | validation: 5.901473433993774]
	TIME [epoch: 27.6 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.894326548468806		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 6.894326548468806 | validation: 5.899951510453329]
	TIME [epoch: 27.6 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.899449760743358		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 6.899449760743358 | validation: 5.925695635513453]
	TIME [epoch: 27.6 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.920173098251894		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 6.920173098251894 | validation: 5.90895347150836]
	TIME [epoch: 27.6 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.923058097821851		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 6.923058097821851 | validation: 5.868602652755157]
	TIME [epoch: 27.5 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.905206477382384		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 6.905206477382384 | validation: 5.887575857680729]
	TIME [epoch: 27.6 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.912664473532085		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 6.912664473532085 | validation: 5.871183710011417]
	TIME [epoch: 27.6 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.911994212114788		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 6.911994212114788 | validation: 5.892563249682342]
	TIME [epoch: 27.6 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.946447461904369		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 6.946447461904369 | validation: 5.919518531790492]
	TIME [epoch: 27.6 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.905640928199576		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 6.905640928199576 | validation: 5.8482829430802665]
	TIME [epoch: 27.6 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.920197094634444		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 6.920197094634444 | validation: 6.222567439822942]
	TIME [epoch: 27.6 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.011536005323221		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 7.011536005323221 | validation: 6.081045681156293]
	TIME [epoch: 27.6 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.005391832495941		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 7.005391832495941 | validation: 5.848126142638073]
	TIME [epoch: 27.6 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.924535139666103		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 6.924535139666103 | validation: 5.871689738354972]
	TIME [epoch: 27.6 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.908393962681461		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 6.908393962681461 | validation: 5.885086951936617]
	TIME [epoch: 27.6 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.903526721330513		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 6.903526721330513 | validation: 5.970645682648739]
	TIME [epoch: 27.5 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.011155651430436		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 7.011155651430436 | validation: 5.8286070960590255]
	TIME [epoch: 27.6 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.895834736836208		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 6.895834736836208 | validation: 5.85507955131248]
	TIME [epoch: 27.6 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.896773845966299		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 6.896773845966299 | validation: 5.88486997236945]
	TIME [epoch: 27.6 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.909287012745331		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 6.909287012745331 | validation: 5.892370682923801]
	TIME [epoch: 27.6 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.906700024935246		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 6.906700024935246 | validation: 5.883180680883712]
	TIME [epoch: 27.6 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.910932770132178		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 6.910932770132178 | validation: 5.822698527277655]
	TIME [epoch: 27.6 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.887363466093454		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 6.887363466093454 | validation: 5.925937537749672]
	TIME [epoch: 27.6 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.902300975016394		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 6.902300975016394 | validation: 5.843164943933269]
	TIME [epoch: 27.6 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.880022739668767		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 6.880022739668767 | validation: 5.823098033147682]
	TIME [epoch: 27.5 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.886592889452693		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 6.886592889452693 | validation: 5.94198906604273]
	TIME [epoch: 27.6 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.901506906665428		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 6.901506906665428 | validation: 5.8312198356437195]
	TIME [epoch: 27.5 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.890792854085249		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 6.890792854085249 | validation: 5.883403653515966]
	TIME [epoch: 27.5 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.900142594771144		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 6.900142594771144 | validation: 5.913643219219789]
	TIME [epoch: 27.6 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.907717198064219		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 6.907717198064219 | validation: 5.84113404163373]
	TIME [epoch: 27.6 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.966477969418149		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 6.966477969418149 | validation: 5.8751870616747555]
	TIME [epoch: 27.6 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.923008326984824		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 6.923008326984824 | validation: 5.83052830207962]
	TIME [epoch: 27.6 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.887303176412916		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 6.887303176412916 | validation: 5.877993540695792]
	TIME [epoch: 27.6 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.9295150484036085		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 6.9295150484036085 | validation: 5.961864135561743]
	TIME [epoch: 27.6 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.921812092588212		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 6.921812092588212 | validation: 5.851950572238667]
	TIME [epoch: 27.6 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.883366941837355		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 6.883366941837355 | validation: 5.876695277129868]
	TIME [epoch: 27.5 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.904736276847297		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 6.904736276847297 | validation: 5.878324703672308]
	TIME [epoch: 27.5 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.918892224178165		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 6.918892224178165 | validation: 5.828660678069787]
	TIME [epoch: 27.6 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.903966834929125		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 6.903966834929125 | validation: 5.8374711726499156]
	TIME [epoch: 27.6 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.9240654918041304		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 6.9240654918041304 | validation: 5.85140806017256]
	TIME [epoch: 27.6 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.898295853557096		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 6.898295853557096 | validation: 5.845413518201836]
	TIME [epoch: 27.6 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.900899011248032		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 6.900899011248032 | validation: 5.81428015676715]
	TIME [epoch: 27.5 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.8891521842819765		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 6.8891521842819765 | validation: 5.911222851075221]
	TIME [epoch: 27.6 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.90410189971221		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 6.90410189971221 | validation: 5.820937453021499]
	TIME [epoch: 27.6 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.886701986878803		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 6.886701986878803 | validation: 5.85519924316702]
	TIME [epoch: 27.5 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.904454728718757		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 6.904454728718757 | validation: 5.915095024082246]
	TIME [epoch: 27.6 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.909478617502554		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 6.909478617502554 | validation: 5.936616034705009]
	TIME [epoch: 27.5 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.915391023527851		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 6.915391023527851 | validation: 5.799208717945412]
	TIME [epoch: 27.6 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.903388095221606		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 6.903388095221606 | validation: 5.878389749782348]
	TIME [epoch: 27.6 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.8900752834317345		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 6.8900752834317345 | validation: 5.917840152495727]
	TIME [epoch: 27.6 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.8811574188594165		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 6.8811574188594165 | validation: 5.853250655906768]
	TIME [epoch: 27.6 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.884039493515261		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 6.884039493515261 | validation: 5.89541602493302]
	TIME [epoch: 27.6 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.886513932685242		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 6.886513932685242 | validation: 5.870395967091069]
	TIME [epoch: 27.5 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.928902872887358		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 6.928902872887358 | validation: 5.857850676177679]
	TIME [epoch: 27.6 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.888704170737628		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 6.888704170737628 | validation: 5.904256892941505]
	TIME [epoch: 27.6 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.889799700249944		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 6.889799700249944 | validation: 5.844460216900525]
	TIME [epoch: 27.6 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.892661595172351		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 6.892661595172351 | validation: 5.942894715025216]
	TIME [epoch: 27.6 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.912488430013882		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 6.912488430013882 | validation: 5.809129525634192]
	TIME [epoch: 27.5 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.889000137564734		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 6.889000137564734 | validation: 5.867313677828833]
	TIME [epoch: 27.6 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.87940210967473		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 6.87940210967473 | validation: 5.8087961531867265]
	TIME [epoch: 27.6 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.88249164875957		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 6.88249164875957 | validation: 5.814287513265611]
	TIME [epoch: 27.6 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.860967821390092		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 6.860967821390092 | validation: 5.801724268315565]
	TIME [epoch: 27.6 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.889195068298309		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 6.889195068298309 | validation: 6.003598288066439]
	TIME [epoch: 27.6 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.892254418536454		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 6.892254418536454 | validation: 5.792428110790869]
	TIME [epoch: 27.6 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.9234622353648465		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 6.9234622353648465 | validation: 5.880512587275346]
	TIME [epoch: 27.6 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.887340101042841		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 6.887340101042841 | validation: 5.962634060649018]
	TIME [epoch: 27.6 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.897647956176326		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 6.897647956176326 | validation: 5.876638259804838]
	TIME [epoch: 27.5 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.88538108324464		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 6.88538108324464 | validation: 5.906015923521604]
	TIME [epoch: 27.6 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.90899295977908		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 6.90899295977908 | validation: 5.851015878075244]
	TIME [epoch: 27.5 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.863915764889963		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 6.863915764889963 | validation: 5.824461195009081]
	TIME [epoch: 27.6 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.882250394105672		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 6.882250394105672 | validation: 6.001049390403469]
	TIME [epoch: 27.5 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.9257519576613475		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 6.9257519576613475 | validation: 5.842109158717697]
	TIME [epoch: 27.5 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.900726149411456		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 6.900726149411456 | validation: 5.845325954716314]
	TIME [epoch: 27.6 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.916664445991543		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 6.916664445991543 | validation: 5.899044386295109]
	TIME [epoch: 27.6 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.942953696754196		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 6.942953696754196 | validation: 5.858415799414356]
	TIME [epoch: 27.5 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.870361179524575		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 6.870361179524575 | validation: 5.827715083143251]
	TIME [epoch: 27.5 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.903722759423669		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 6.903722759423669 | validation: 5.8580264309971515]
	TIME [epoch: 27.5 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.884471736898058		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 6.884471736898058 | validation: 5.85945132090326]
	TIME [epoch: 27.5 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.852493343340175		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 6.852493343340175 | validation: 5.84522461560894]
	TIME [epoch: 27.5 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.873977324236953		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 6.873977324236953 | validation: 5.83107647054894]
	TIME [epoch: 27.5 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.871212434434549		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 6.871212434434549 | validation: 5.810065106263193]
	TIME [epoch: 27.5 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.8621137363724864		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 6.8621137363724864 | validation: 5.888380282914553]
	TIME [epoch: 27.5 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.933804030642168		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 6.933804030642168 | validation: 5.84743588331593]
	TIME [epoch: 27.6 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.8771200154841905		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 6.8771200154841905 | validation: 5.9622063867977975]
	TIME [epoch: 27.5 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.879476124850487		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 6.879476124850487 | validation: 5.82788478058483]
	TIME [epoch: 27.5 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.865940286729065		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 6.865940286729065 | validation: 5.810633659358654]
	TIME [epoch: 27.5 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.881206268432249		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 6.881206268432249 | validation: 5.869513492984338]
	TIME [epoch: 27.5 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.86173605304813		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 6.86173605304813 | validation: 5.893934746402528]
	TIME [epoch: 27.5 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.865639963842872		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 6.865639963842872 | validation: 5.82071634663032]
	TIME [epoch: 27.5 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.865953612729254		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 6.865953612729254 | validation: 5.843913963156024]
	TIME [epoch: 27.5 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.89029283445452		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 6.89029283445452 | validation: 5.920091123269003]
	TIME [epoch: 27.5 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.861725721064598		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 6.861725721064598 | validation: 5.813402707030664]
	TIME [epoch: 27.5 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.852157722282449		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 6.852157722282449 | validation: 5.837612658359895]
	TIME [epoch: 27.5 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.855314154233623		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 6.855314154233623 | validation: 5.90901965163672]
	TIME [epoch: 27.5 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.875164544940912		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 6.875164544940912 | validation: 5.838698125556297]
	TIME [epoch: 27.6 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.868799861206817		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 6.868799861206817 | validation: 5.935001217077839]
	TIME [epoch: 27.6 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.877406972992688		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 6.877406972992688 | validation: 5.828135191904274]
	TIME [epoch: 27.5 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.861300989957875		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 6.861300989957875 | validation: 5.844288375111829]
	TIME [epoch: 27.5 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.859191219598613		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 6.859191219598613 | validation: 5.818821910602496]
	TIME [epoch: 27.6 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.839151407840115		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 6.839151407840115 | validation: 5.813776806167413]
	TIME [epoch: 27.6 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.849871965766406		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 6.849871965766406 | validation: 5.811593510023234]
	TIME [epoch: 27.5 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.855261377546098		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 6.855261377546098 | validation: 5.838628229640222]
	TIME [epoch: 27.5 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.878859172413347		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 6.878859172413347 | validation: 5.913885290282008]
	TIME [epoch: 27.5 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.867790085358516		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 6.867790085358516 | validation: 5.80288456418097]
	TIME [epoch: 27.5 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.837757250704024		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 6.837757250704024 | validation: 5.801858546457309]
	TIME [epoch: 27.5 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.839842042166562		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 6.839842042166562 | validation: 5.805485942818755]
	TIME [epoch: 27.5 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.847283852750172		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 6.847283852750172 | validation: 5.927404129105212]
	TIME [epoch: 27.5 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.904792175284897		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 6.904792175284897 | validation: 5.818891119397795]
	TIME [epoch: 27.6 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.847345237836419		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 6.847345237836419 | validation: 5.837459325254247]
	TIME [epoch: 27.6 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.837094810853745		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 6.837094810853745 | validation: 5.877191185578946]
	TIME [epoch: 27.6 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.8422604821548445		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 6.8422604821548445 | validation: 5.809569809610133]
	TIME [epoch: 27.5 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.882316331204103		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 6.882316331204103 | validation: 5.830620354808632]
	TIME [epoch: 27.5 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.833810994408506		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 6.833810994408506 | validation: 5.8669872232954745]
	TIME [epoch: 27.5 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.878645212491492		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 6.878645212491492 | validation: 5.855618077606632]
	TIME [epoch: 27.5 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.844411968069642		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 6.844411968069642 | validation: 5.810800523726296]
	TIME [epoch: 27.5 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.829301793515223		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 6.829301793515223 | validation: 5.80354146237946]
	TIME [epoch: 27.5 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.850283186468204		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 6.850283186468204 | validation: 5.855377466587762]
	TIME [epoch: 27.5 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.868611885258959		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 6.868611885258959 | validation: 5.8128014126660545]
	TIME [epoch: 27.5 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.856083412743052		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 6.856083412743052 | validation: 5.804081262439606]
	TIME [epoch: 27.5 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.831895529465835		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 6.831895529465835 | validation: 5.877353556920602]
	TIME [epoch: 27.6 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.842277866803171		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 6.842277866803171 | validation: 5.948578605799378]
	TIME [epoch: 27.5 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.887884844705938		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 6.887884844705938 | validation: 5.974606080722144]
	TIME [epoch: 27.5 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.888088106154505		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 6.888088106154505 | validation: 5.8124796502246205]
	TIME [epoch: 27.5 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.850127539942076		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 6.850127539942076 | validation: 5.851934111240805]
	TIME [epoch: 27.5 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.862017615744445		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 6.862017615744445 | validation: 5.956349166584211]
	TIME [epoch: 27.6 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.902073659904854		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 6.902073659904854 | validation: 5.877812666978664]
	TIME [epoch: 27.5 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.890896543273893		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 6.890896543273893 | validation: 5.857527665434118]
	TIME [epoch: 27.5 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.839274243201559		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 6.839274243201559 | validation: 5.784388081486354]
	TIME [epoch: 27.5 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.8472220962430494		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 6.8472220962430494 | validation: 6.05818464842492]
	TIME [epoch: 27.5 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.914128993296849		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 6.914128993296849 | validation: 5.900504364543149]
	TIME [epoch: 27.5 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.854431683696848		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 6.854431683696848 | validation: 5.791481108154751]
	TIME [epoch: 27.5 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.824834365421842		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 6.824834365421842 | validation: 5.82195934572528]
	TIME [epoch: 27.5 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.846944528558856		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 6.846944528558856 | validation: 5.928289152807982]
	TIME [epoch: 27.5 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.859659784307405		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 6.859659784307405 | validation: 5.811555433793318]
	TIME [epoch: 27.5 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.861869919624761		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 6.861869919624761 | validation: 5.811087552889433]
	TIME [epoch: 27.5 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.8442244470322064		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 6.8442244470322064 | validation: 5.793374216629973]
	TIME [epoch: 27.5 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.823994812345557		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 6.823994812345557 | validation: 5.818694380330676]
	TIME [epoch: 27.5 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.813992135397974		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 6.813992135397974 | validation: 5.796440057263149]
	TIME [epoch: 27.5 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.8258894080935395		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 6.8258894080935395 | validation: 5.786868504542479]
	TIME [epoch: 27.5 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.816250499481075		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 6.816250499481075 | validation: 5.889055066416654]
	TIME [epoch: 27.5 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.828701073910005		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 6.828701073910005 | validation: 5.775768668878263]
	TIME [epoch: 27.6 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.862780905879966		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 6.862780905879966 | validation: 5.851301806628375]
	TIME [epoch: 27.5 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.822859243940816		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 6.822859243940816 | validation: 5.810684149679592]
	TIME [epoch: 27.5 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.834048255133863		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 6.834048255133863 | validation: 5.794813577856512]
	TIME [epoch: 27.5 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.81102424532084		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 6.81102424532084 | validation: 5.79328772346407]
	TIME [epoch: 27.5 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.85571926849499		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 6.85571926849499 | validation: 5.8428194749551725]
	TIME [epoch: 27.5 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.830698370330111		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 6.830698370330111 | validation: 5.8175304488947015]
	TIME [epoch: 27.5 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.8297611494350186		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 6.8297611494350186 | validation: 5.804280310439781]
	TIME [epoch: 27.5 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.819700400141768		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 6.819700400141768 | validation: 5.891017063779329]
	TIME [epoch: 27.5 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.8428293264589986		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 6.8428293264589986 | validation: 5.7645124576999915]
	TIME [epoch: 27.5 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.820324078660648		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 6.820324078660648 | validation: 5.951634814769991]
	TIME [epoch: 27.5 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.859203849158994		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 6.859203849158994 | validation: 5.764824934267317]
	TIME [epoch: 27.5 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.828550331665078		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 6.828550331665078 | validation: 5.781545289524224]
	TIME [epoch: 27.5 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.813199029485949		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 6.813199029485949 | validation: 5.916919004410158]
	TIME [epoch: 27.5 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.844456137455891		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 6.844456137455891 | validation: 5.922058497780063]
	TIME [epoch: 27.6 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.8493364876400005		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 6.8493364876400005 | validation: 5.829081927592928]
	TIME [epoch: 27.6 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.810486687059308		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 6.810486687059308 | validation: 5.8541755024156625]
	TIME [epoch: 27.5 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.801323082554127		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 6.801323082554127 | validation: 5.788230947403381]
	TIME [epoch: 27.5 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.8241781415777165		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 6.8241781415777165 | validation: 5.796380844495525]
	TIME [epoch: 27.5 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.792593906562762		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 6.792593906562762 | validation: 5.83155909287812]
	TIME [epoch: 27.5 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.812289174571207		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 6.812289174571207 | validation: 5.798339078141841]
	TIME [epoch: 27.6 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.810249544577868		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 6.810249544577868 | validation: 5.868157131855189]
	TIME [epoch: 27.5 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.859287501810922		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 6.859287501810922 | validation: 6.002551316833209]
	TIME [epoch: 27.5 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.831439297044228		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 6.831439297044228 | validation: 5.847856963828388]
	TIME [epoch: 27.5 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.804831331704454		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 6.804831331704454 | validation: 5.804636014481839]
	TIME [epoch: 27.5 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.803742933419219		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 6.803742933419219 | validation: 5.789305708917641]
	TIME [epoch: 27.5 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.794445763098119		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 6.794445763098119 | validation: 5.779787310421581]
	TIME [epoch: 27.5 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.777680286583314		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 6.777680286583314 | validation: 5.945024760761827]
	TIME [epoch: 27.5 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.859623290838407		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 6.859623290838407 | validation: 5.766441635850916]
	TIME [epoch: 27.6 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.808975041664047		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 6.808975041664047 | validation: 5.806247671464214]
	TIME [epoch: 27.5 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.802190984733164		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 6.802190984733164 | validation: 5.835207914405007]
	TIME [epoch: 27.5 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.831218952319697		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 6.831218952319697 | validation: 5.850720874863932]
	TIME [epoch: 27.5 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.7812370530899955		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 6.7812370530899955 | validation: 5.775501203033287]
	TIME [epoch: 27.5 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.816172009652915		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 6.816172009652915 | validation: 5.8938708571559975]
	TIME [epoch: 27.5 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.790522942960124		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 6.790522942960124 | validation: 5.776940396900038]
	TIME [epoch: 27.5 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.772353392689696		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 6.772353392689696 | validation: 5.82096501787805]
	TIME [epoch: 27.5 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.7982360289272705		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 6.7982360289272705 | validation: 5.8629071899116685]
	TIME [epoch: 27.5 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.800103467425783		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 6.800103467425783 | validation: 5.793818277129515]
	TIME [epoch: 27.5 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.8402596692474145		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 6.8402596692474145 | validation: 5.780314872127908]
	TIME [epoch: 27.5 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.76938361694998		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 6.76938361694998 | validation: 5.759392978741223]
	TIME [epoch: 27.5 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.766106232567979		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 6.766106232567979 | validation: 5.756687352486903]
	TIME [epoch: 27.5 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.769515883848192		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 6.769515883848192 | validation: 5.951957907724922]
	TIME [epoch: 27.5 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.823182252029007		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 6.823182252029007 | validation: 6.00493663015829]
	TIME [epoch: 27.5 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.843258987366179		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 6.843258987366179 | validation: 5.905311060056081]
	TIME [epoch: 27.5 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.763676370656973		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 6.763676370656973 | validation: 5.752571854599294]
	TIME [epoch: 27.5 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.765386277671845		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 6.765386277671845 | validation: 5.720376738453695]
	TIME [epoch: 27.5 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.725208042047038		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 6.725208042047038 | validation: 5.774486472042197]
	TIME [epoch: 27.6 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.705107582216997		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 6.705107582216997 | validation: 5.8917093288155575]
	TIME [epoch: 27.5 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.7178107663572835		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 6.7178107663572835 | validation: 5.831682106629393]
	TIME [epoch: 27.5 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.716937967709856		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 6.716937967709856 | validation: 5.725637659513419]
	TIME [epoch: 27.5 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.588530978688069		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 6.588530978688069 | validation: 5.795737210313586]
	TIME [epoch: 27.5 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.52435412619537		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 6.52435412619537 | validation: 5.517005545089027]
	TIME [epoch: 27.5 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.343073968303595		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 6.343073968303595 | validation: 5.3505205870023635]
	TIME [epoch: 27.5 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.091156493425999		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 6.091156493425999 | validation: 5.066866842316906]
	TIME [epoch: 27.5 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.755987020262356		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 5.755987020262356 | validation: 4.765076189129241]
	TIME [epoch: 27.5 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.475224227133905		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 5.475224227133905 | validation: 4.614829654523066]
	TIME [epoch: 27.5 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.261263645423268		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 5.261263645423268 | validation: 4.360391413496638]
	TIME [epoch: 27.5 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.91644656774375		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 4.91644656774375 | validation: 3.8843740134930376]
	TIME [epoch: 27.5 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7714413624908283		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 3.7714413624908283 | validation: 2.8264781352409942]
	TIME [epoch: 27.5 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.718841395143997		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 2.718841395143997 | validation: 2.252075796799254]
	TIME [epoch: 27.5 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.306853805170284		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 2.306853805170284 | validation: 2.0362881218042825]
	TIME [epoch: 27.6 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.097938871430474		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 2.097938871430474 | validation: 1.7375721093961936]
	TIME [epoch: 27.5 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9459729186860235		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 1.9459729186860235 | validation: 1.6857409784926205]
	TIME [epoch: 27.6 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9475942981212955		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 1.9475942981212955 | validation: 1.737323346430429]
	TIME [epoch: 27.6 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9115698955773097		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 1.9115698955773097 | validation: 1.584331870493644]
	TIME [epoch: 27.6 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7888345587178143		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 1.7888345587178143 | validation: 1.5392984796880214]
	TIME [epoch: 27.6 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8073529198534177		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 1.8073529198534177 | validation: 1.558532050613402]
	TIME [epoch: 27.6 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7759817826580986		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 1.7759817826580986 | validation: 1.4517003926585879]
	TIME [epoch: 27.5 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7769437734549993		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 1.7769437734549993 | validation: 1.5287080595920994]
	TIME [epoch: 27.6 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7122199205305217		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 1.7122199205305217 | validation: 1.558607331723879]
	TIME [epoch: 27.6 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7163699852725085		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 1.7163699852725085 | validation: 1.404651971153968]
	TIME [epoch: 27.6 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6897649965270958		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 1.6897649965270958 | validation: 1.5029736089589312]
	TIME [epoch: 27.6 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6884061889223396		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 1.6884061889223396 | validation: 1.4997732057127708]
	TIME [epoch: 27.5 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7283901022451433		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 1.7283901022451433 | validation: 1.4205473857092432]
	TIME [epoch: 27.6 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.666195450496948		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 1.666195450496948 | validation: 1.3544194810299115]
	TIME [epoch: 27.6 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6096219662398872		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 1.6096219662398872 | validation: 1.366880242090663]
	TIME [epoch: 27.6 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6324541831809305		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 1.6324541831809305 | validation: 1.4467986886192958]
	TIME [epoch: 27.7 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6211575486176923		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 1.6211575486176923 | validation: 1.298552601040297]
	TIME [epoch: 27.7 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5820437073698446		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 1.5820437073698446 | validation: 1.4849685230061471]
	TIME [epoch: 27.5 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6170792108515415		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 1.6170792108515415 | validation: 1.3113899854622917]
	TIME [epoch: 27.6 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5438580359797665		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 1.5438580359797665 | validation: 1.2851479794155198]
	TIME [epoch: 27.6 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5443888661082392		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 1.5443888661082392 | validation: 1.3116943163632095]
	TIME [epoch: 27.6 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5359973542665795		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 1.5359973542665795 | validation: 1.2937390702862337]
	TIME [epoch: 27.6 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5422256646957693		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 1.5422256646957693 | validation: 1.259933410457342]
	TIME [epoch: 27.6 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.528226974419733		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 1.528226974419733 | validation: 1.2238190396270363]
	TIME [epoch: 27.6 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4832476451371863		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 1.4832476451371863 | validation: 1.2986387103777621]
	TIME [epoch: 27.6 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.533017254126267		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 1.533017254126267 | validation: 1.2364281881852237]
	TIME [epoch: 27.6 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4949071159193048		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 1.4949071159193048 | validation: 1.2176979397564385]
	TIME [epoch: 27.6 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5283040872676323		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 1.5283040872676323 | validation: 1.2324754343105913]
	TIME [epoch: 27.6 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.479389977639352		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 1.479389977639352 | validation: 1.174398856250513]
	TIME [epoch: 27.5 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4710980348170526		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 1.4710980348170526 | validation: 1.2607964091123105]
	TIME [epoch: 27.6 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4764446332291985		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 1.4764446332291985 | validation: 1.2990153553707242]
	TIME [epoch: 27.6 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4617399069762798		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 1.4617399069762798 | validation: 1.2149012960999304]
	TIME [epoch: 27.5 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4584758306299463		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 1.4584758306299463 | validation: 1.1465091729729997]
	TIME [epoch: 27.6 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5771461210888273		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 1.5771461210888273 | validation: 1.2012224351632195]
	TIME [epoch: 27.6 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4598280867041278		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 1.4598280867041278 | validation: 1.1161793888702416]
	TIME [epoch: 27.5 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4398062645676455		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 1.4398062645676455 | validation: 1.228286334589827]
	TIME [epoch: 27.6 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4461797598052577		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 1.4461797598052577 | validation: 1.1543791945466337]
	TIME [epoch: 27.6 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4795220577577064		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 1.4795220577577064 | validation: 1.2389774942829634]
	TIME [epoch: 27.7 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4266098416983213		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 1.4266098416983213 | validation: 1.2006928595797057]
	TIME [epoch: 27.7 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4579287390285463		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 1.4579287390285463 | validation: 1.126738994919364]
	TIME [epoch: 27.6 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.43693855224488		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 1.43693855224488 | validation: 1.1189084743477131]
	TIME [epoch: 27.6 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.390982300375963		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 1.390982300375963 | validation: 1.1407764358596755]
	TIME [epoch: 27.6 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4085990157925323		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 1.4085990157925323 | validation: 1.2629942733796622]
	TIME [epoch: 27.6 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4102208996704635		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 1.4102208996704635 | validation: 1.119643935890126]
	TIME [epoch: 27.7 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4200835430921053		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 1.4200835430921053 | validation: 1.1728931559546347]
	TIME [epoch: 27.6 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3682106644494925		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 1.3682106644494925 | validation: 1.1287516372782955]
	TIME [epoch: 27.6 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3752584360725943		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 1.3752584360725943 | validation: 1.0678277716949856]
	TIME [epoch: 27.7 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3972950669010373		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 1.3972950669010373 | validation: 1.1449983901227645]
	TIME [epoch: 27.7 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4048857322561314		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 1.4048857322561314 | validation: 1.0826102679527652]
	TIME [epoch: 27.6 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3802365324069132		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 1.3802365324069132 | validation: 1.1385829284518554]
	TIME [epoch: 27.6 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3662982578033331		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 1.3662982578033331 | validation: 1.0822947910661578]
	TIME [epoch: 27.6 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3375003685005464		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 1.3375003685005464 | validation: 1.1152675816820656]
	TIME [epoch: 27.6 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3471262201503187		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 1.3471262201503187 | validation: 1.0842783873224284]
	TIME [epoch: 27.7 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.322765846503271		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 1.322765846503271 | validation: 1.0331162636461886]
	TIME [epoch: 27.6 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3096276028525164		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 1.3096276028525164 | validation: 1.021533576012992]
	TIME [epoch: 27.6 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.276783052463312		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 1.276783052463312 | validation: 1.0445854271613897]
	TIME [epoch: 27.7 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3149956898424755		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 1.3149956898424755 | validation: 1.1639123706611612]
	TIME [epoch: 27.6 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3069329297107146		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 1.3069329297107146 | validation: 1.0952544183264616]
	TIME [epoch: 27.7 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3217841995626478		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 1.3217841995626478 | validation: 1.1006762060195527]
	TIME [epoch: 27.6 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2752920097977807		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 1.2752920097977807 | validation: 1.080227995996312]
	TIME [epoch: 27.6 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2764208808809587		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 1.2764208808809587 | validation: 1.0629170512401058]
	TIME [epoch: 27.7 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.179105293628553		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 1.179105293628553 | validation: 0.9907280404156242]
	TIME [epoch: 27.7 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1346587299196877		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 1.1346587299196877 | validation: 1.016854780753163]
	TIME [epoch: 27.6 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.108959777945672		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 1.108959777945672 | validation: 0.9554076599271858]
	TIME [epoch: 27.7 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0328988371891332		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 1.0328988371891332 | validation: 0.9285737314284979]
	TIME [epoch: 27.6 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9513646407866984		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.9513646407866984 | validation: 0.8265824425336268]
	TIME [epoch: 27.6 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9095970086633635		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.9095970086633635 | validation: 0.8663421771350339]
	TIME [epoch: 27.6 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8443802670514144		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.8443802670514144 | validation: 0.7837673672785157]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_905.pth
	Model improved!!!
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7744721507877599		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.7744721507877599 | validation: 0.7052349830977669]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_906.pth
	Model improved!!!
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7348636568326885		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.7348636568326885 | validation: 0.666414335137656]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_907.pth
	Model improved!!!
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7677649381723393		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.7677649381723393 | validation: 0.6916654950562567]
	TIME [epoch: 27.6 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6939253429217611		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.6939253429217611 | validation: 0.7624769209742631]
	TIME [epoch: 27.6 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.646270239252755		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.646270239252755 | validation: 0.6377839976637694]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_910.pth
	Model improved!!!
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6447172383994246		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.6447172383994246 | validation: 0.592842399767071]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_911.pth
	Model improved!!!
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6228946280100667		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.6228946280100667 | validation: 0.5819084363451219]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_912.pth
	Model improved!!!
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.634006597029712		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.634006597029712 | validation: 0.6337284596489089]
	TIME [epoch: 27.6 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6451156080937259		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.6451156080937259 | validation: 0.6353739780958908]
	TIME [epoch: 27.6 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5924480146516153		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.5924480146516153 | validation: 0.5967906847289882]
	TIME [epoch: 27.6 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6480671373409352		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.6480671373409352 | validation: 0.6540748498735387]
	TIME [epoch: 27.6 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5818793060610163		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.5818793060610163 | validation: 0.5645134654231394]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_917.pth
	Model improved!!!
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5470447175009266		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.5470447175009266 | validation: 0.5211639938376408]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_918.pth
	Model improved!!!
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5060403408970499		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.5060403408970499 | validation: 0.5349905416410348]
	TIME [epoch: 27.6 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5275222910585194		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.5275222910585194 | validation: 0.5258772666947621]
	TIME [epoch: 27.6 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5071074019691055		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.5071074019691055 | validation: 0.572142238307295]
	TIME [epoch: 27.6 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5203025393034927		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.5203025393034927 | validation: 0.5038222749656519]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_922.pth
	Model improved!!!
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4907145532485374		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.4907145532485374 | validation: 0.5049661923400348]
	TIME [epoch: 27.6 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5356408020251174		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.5356408020251174 | validation: 0.5445706557685249]
	TIME [epoch: 27.7 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49996535503722844		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.49996535503722844 | validation: 0.4808150990753805]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_925.pth
	Model improved!!!
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4569829121084439		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.4569829121084439 | validation: 0.5906364591748247]
	TIME [epoch: 27.6 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5570038816635271		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.5570038816635271 | validation: 0.4610001036007694]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_927.pth
	Model improved!!!
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4454568802134281		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.4454568802134281 | validation: 0.47152904464800816]
	TIME [epoch: 27.7 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47133430021353184		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.47133430021353184 | validation: 0.49556767387752365]
	TIME [epoch: 27.6 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49960008506653986		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.49960008506653986 | validation: 0.5101219934881003]
	TIME [epoch: 27.7 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4779496055788061		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.4779496055788061 | validation: 0.443361593437825]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_931.pth
	Model improved!!!
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45234486275918595		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.45234486275918595 | validation: 0.4522517106248521]
	TIME [epoch: 27.6 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48192795387150855		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.48192795387150855 | validation: 0.531262320065183]
	TIME [epoch: 27.7 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.481193332627556		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.481193332627556 | validation: 0.5025326519214608]
	TIME [epoch: 27.6 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4415541192265313		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.4415541192265313 | validation: 0.4588412349960937]
	TIME [epoch: 27.6 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42972594901279343		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.42972594901279343 | validation: 0.46522199776668716]
	TIME [epoch: 27.7 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4301666864078083		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.4301666864078083 | validation: 0.430250867397651]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_937.pth
	Model improved!!!
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.422141805293453		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.422141805293453 | validation: 0.4520805033729172]
	TIME [epoch: 27.6 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43944477753899525		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.43944477753899525 | validation: 0.5594962083590881]
	TIME [epoch: 27.7 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49227812994083037		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.49227812994083037 | validation: 0.45338493391034107]
	TIME [epoch: 27.6 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5430819786398293		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.5430819786398293 | validation: 0.5376007721232188]
	TIME [epoch: 27.6 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5291122485471341		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.5291122485471341 | validation: 0.46587928879006113]
	TIME [epoch: 27.6 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4522812340687046		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.4522812340687046 | validation: 0.43230766605740684]
	TIME [epoch: 27.6 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46621947886956283		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.46621947886956283 | validation: 0.44466331401322423]
	TIME [epoch: 27.7 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43166361976491163		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.43166361976491163 | validation: 0.43090066937766636]
	TIME [epoch: 27.6 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41635500022149763		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.41635500022149763 | validation: 0.39386204030290134]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_946.pth
	Model improved!!!
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37382267774628397		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.37382267774628397 | validation: 0.40033339600708895]
	TIME [epoch: 27.6 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3911898645356954		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.3911898645356954 | validation: 0.46458671429399445]
	TIME [epoch: 27.6 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41272751462271895		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.41272751462271895 | validation: 0.40934281240384174]
	TIME [epoch: 27.6 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40947505220407354		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.40947505220407354 | validation: 0.3964272646485978]
	TIME [epoch: 27.7 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36957831818999975		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.36957831818999975 | validation: 0.38522941778664027]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_951.pth
	Model improved!!!
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4157852184635474		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.4157852184635474 | validation: 0.47173857701240257]
	TIME [epoch: 27.6 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41351556666749456		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.41351556666749456 | validation: 0.40211759002606634]
	TIME [epoch: 27.7 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37942597398630085		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.37942597398630085 | validation: 0.3828459204793807]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_954.pth
	Model improved!!!
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4151810333130241		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.4151810333130241 | validation: 0.3894032722330296]
	TIME [epoch: 27.6 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43967287751727213		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.43967287751727213 | validation: 0.459307739440684]
	TIME [epoch: 27.7 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4264260359768522		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.4264260359768522 | validation: 0.412349229496106]
	TIME [epoch: 27.6 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3765350633389517		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.3765350633389517 | validation: 0.3856697677162512]
	TIME [epoch: 27.7 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41240050446455817		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.41240050446455817 | validation: 0.4153882957382217]
	TIME [epoch: 27.7 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.395007959481518		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.395007959481518 | validation: 0.389057873620553]
	TIME [epoch: 27.6 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35067312963099634		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.35067312963099634 | validation: 0.4248467582382034]
	TIME [epoch: 27.7 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3976108216005555		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.3976108216005555 | validation: 0.3959568346649104]
	TIME [epoch: 27.7 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38457426062581884		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.38457426062581884 | validation: 0.39577682385384394]
	TIME [epoch: 27.6 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37066382494448913		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.37066382494448913 | validation: 0.4408509905276812]
	TIME [epoch: 27.7 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44501641377902146		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.44501641377902146 | validation: 0.40423885724363073]
	TIME [epoch: 27.6 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34935356928347255		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.34935356928347255 | validation: 0.34269848366775596]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_966.pth
	Model improved!!!
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35499552146793056		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.35499552146793056 | validation: 0.3576331243035814]
	TIME [epoch: 27.6 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3408165334358727		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.3408165334358727 | validation: 0.35950341684346127]
	TIME [epoch: 27.7 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3469080346323853		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.3469080346323853 | validation: 0.44137629339226436]
	TIME [epoch: 27.6 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.359832211687428		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.359832211687428 | validation: 0.36861890446045026]
	TIME [epoch: 27.7 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3253669895093143		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.3253669895093143 | validation: 0.42554209184537883]
	TIME [epoch: 27.6 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3683277137664136		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.3683277137664136 | validation: 0.3334508626843011]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_972.pth
	Model improved!!!
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3301441922485927		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.3301441922485927 | validation: 0.352960955671782]
	TIME [epoch: 27.7 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3404115338222904		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.3404115338222904 | validation: 0.4085611690007914]
	TIME [epoch: 27.6 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3393360174129705		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.3393360174129705 | validation: 0.3653680427846557]
	TIME [epoch: 27.6 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36622681875015045		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.36622681875015045 | validation: 0.3581961630074513]
	TIME [epoch: 27.6 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3681299562674337		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.3681299562674337 | validation: 0.3331311102440539]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_977.pth
	Model improved!!!
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34885998198043267		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.34885998198043267 | validation: 0.3579720980568682]
	TIME [epoch: 27.7 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3567521969340921		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.3567521969340921 | validation: 0.3627871379893483]
	TIME [epoch: 27.7 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3620643212537923		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.3620643212537923 | validation: 0.37889056157441686]
	TIME [epoch: 27.6 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38699592984554815		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.38699592984554815 | validation: 0.4023664340541187]
	TIME [epoch: 27.7 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4128543134079542		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.4128543134079542 | validation: 0.4108780762258454]
	TIME [epoch: 27.7 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44646172684856905		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.44646172684856905 | validation: 0.3859920518041412]
	TIME [epoch: 27.6 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36106276805106674		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.36106276805106674 | validation: 0.3821432528317497]
	TIME [epoch: 27.7 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33857109210189273		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.33857109210189273 | validation: 0.3862922453221937]
	TIME [epoch: 27.7 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37426004503463406		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.37426004503463406 | validation: 0.3630353142459491]
	TIME [epoch: 27.7 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37151437839147605		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.37151437839147605 | validation: 0.44002434951558356]
	TIME [epoch: 27.7 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36263328528318384		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.36263328528318384 | validation: 0.375505183725094]
	TIME [epoch: 27.7 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34109056394797366		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.34109056394797366 | validation: 0.32201361530480604]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_989.pth
	Model improved!!!
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.399178491419516		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.399178491419516 | validation: 0.5210261477145977]
	TIME [epoch: 27.7 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38530734646988857		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.38530734646988857 | validation: 0.3227846407114494]
	TIME [epoch: 27.6 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32719364233756054		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.32719364233756054 | validation: 0.337568682932271]
	TIME [epoch: 27.7 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33831115143458956		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.33831115143458956 | validation: 0.5148539615402388]
	TIME [epoch: 27.7 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.373733365533171		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.373733365533171 | validation: 0.3834976679879978]
	TIME [epoch: 27.6 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36696594729291737		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.36696594729291737 | validation: 0.3297973233831191]
	TIME [epoch: 27.6 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3242421803188143		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.3242421803188143 | validation: 0.3363261944969809]
	TIME [epoch: 27.7 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3000074241383273		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.3000074241383273 | validation: 0.342197931856565]
	TIME [epoch: 27.6 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36754501589647043		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.36754501589647043 | validation: 0.3789099723767045]
	TIME [epoch: 27.7 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3178658561365211		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.3178658561365211 | validation: 0.3212617041680987]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_999.pth
	Model improved!!!
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2956456452408338		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.2956456452408338 | validation: 0.3274607602751952]
	TIME [epoch: 27.6 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2998681446265089		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.2998681446265089 | validation: 0.35257307102896795]
	TIME [epoch: 27.7 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3424352307316267		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.3424352307316267 | validation: 0.3473614581744571]
	TIME [epoch: 27.7 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.340716951640606		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.340716951640606 | validation: 0.2946279480648511]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_1003.pth
	Model improved!!!
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32823133399246723		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.32823133399246723 | validation: 0.34704359642570043]
	TIME [epoch: 27.6 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33625597522553163		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.33625597522553163 | validation: 0.3874475765377153]
	TIME [epoch: 27.7 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30592649950311346		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.30592649950311346 | validation: 0.3111135391707481]
	TIME [epoch: 27.6 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3231391586528999		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.3231391586528999 | validation: 0.34236212026105933]
	TIME [epoch: 27.6 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3358500170432127		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.3358500170432127 | validation: 0.34042329825154044]
	TIME [epoch: 27.6 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3567693131958848		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.3567693131958848 | validation: 0.373899626462352]
	TIME [epoch: 27.6 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3941900490310571		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.3941900490310571 | validation: 0.3299888985319454]
	TIME [epoch: 27.6 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3295407133896797		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.3295407133896797 | validation: 0.42976784183139577]
	TIME [epoch: 27.6 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32987931458424563		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.32987931458424563 | validation: 0.3619055432244398]
	TIME [epoch: 27.6 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32843864546560453		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.32843864546560453 | validation: 0.31633787782854295]
	TIME [epoch: 27.7 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30635732198802046		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.30635732198802046 | validation: 0.2932605592202679]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_1014.pth
	Model improved!!!
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29072951502678795		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.29072951502678795 | validation: 0.32230732095419207]
	TIME [epoch: 27.6 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30057303355588183		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.30057303355588183 | validation: 0.35175476492363117]
	TIME [epoch: 27.7 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.368108347991692		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.368108347991692 | validation: 0.3520046694003843]
	TIME [epoch: 27.6 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33302730728248964		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.33302730728248964 | validation: 0.4069532088470318]
	TIME [epoch: 27.7 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3415848067477358		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.3415848067477358 | validation: 0.3394961382179812]
	TIME [epoch: 27.7 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30482858108114647		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.30482858108114647 | validation: 0.35391476056471405]
	TIME [epoch: 27.6 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39548227743165704		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.39548227743165704 | validation: 0.46782378032774985]
	TIME [epoch: 27.6 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3464462407842256		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.3464462407842256 | validation: 0.31991985004871626]
	TIME [epoch: 27.7 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2926918635925572		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.2926918635925572 | validation: 0.29318555833225624]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_1023.pth
	Model improved!!!
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27862598446565057		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.27862598446565057 | validation: 0.3447681915417838]
	TIME [epoch: 27.7 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3486152995583327		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.3486152995583327 | validation: 0.339738256965815]
	TIME [epoch: 27.6 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2949175921975533		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.2949175921975533 | validation: 0.2847533716296459]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_1026.pth
	Model improved!!!
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2952826025272115		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.2952826025272115 | validation: 0.3204918165061242]
	TIME [epoch: 27.7 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32920729935489024		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.32920729935489024 | validation: 0.37746810504326433]
	TIME [epoch: 27.7 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34945553796456486		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.34945553796456486 | validation: 0.3477914259901268]
	TIME [epoch: 27.6 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32782468162516915		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.32782468162516915 | validation: 0.2899494717954123]
	TIME [epoch: 27.7 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2777135889011472		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.2777135889011472 | validation: 0.29605406876289414]
	TIME [epoch: 27.7 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27967192349872283		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.27967192349872283 | validation: 0.31134225934100795]
	TIME [epoch: 27.7 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3436800248865066		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.3436800248865066 | validation: 0.28713504737218637]
	TIME [epoch: 27.7 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30766731855308593		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.30766731855308593 | validation: 0.2727412308397682]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_1034.pth
	Model improved!!!
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26677137185924865		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.26677137185924865 | validation: 0.34852862392288175]
	TIME [epoch: 27.7 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29117688953452286		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.29117688953452286 | validation: 0.28511468117549077]
	TIME [epoch: 27.6 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27070899556477845		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.27070899556477845 | validation: 0.38495904730071173]
	TIME [epoch: 27.6 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32000335617549214		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.32000335617549214 | validation: 0.35236994102171665]
	TIME [epoch: 27.6 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27797575275973213		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.27797575275973213 | validation: 0.3088494788220402]
	TIME [epoch: 27.7 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28161252149704885		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.28161252149704885 | validation: 0.3154973263795261]
	TIME [epoch: 27.6 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28544325496630596		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.28544325496630596 | validation: 0.2761214717829142]
	TIME [epoch: 27.7 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25859083294379265		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.25859083294379265 | validation: 0.2929846414330018]
	TIME [epoch: 27.6 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2958339075161662		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.2958339075161662 | validation: 0.3537743989515017]
	TIME [epoch: 27.6 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32372502616933063		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.32372502616933063 | validation: 0.36223108175700014]
	TIME [epoch: 27.6 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3025798769706184		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.3025798769706184 | validation: 0.3135110869469092]
	TIME [epoch: 27.6 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27665982058210215		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.27665982058210215 | validation: 0.31103457522164696]
	TIME [epoch: 27.6 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2978053256162402		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.2978053256162402 | validation: 0.37010931075118947]
	TIME [epoch: 27.7 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33899487261954553		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.33899487261954553 | validation: 0.32693756048160494]
	TIME [epoch: 27.6 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3044345923930623		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.3044345923930623 | validation: 0.3012507298045636]
	TIME [epoch: 27.6 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27062117409692665		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.27062117409692665 | validation: 0.2764821184038027]
	TIME [epoch: 27.7 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2598841780747832		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.2598841780747832 | validation: 0.2930201130316175]
	TIME [epoch: 27.6 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2686718483135198		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.2686718483135198 | validation: 0.2925015636733549]
	TIME [epoch: 27.6 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26574841009752287		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.26574841009752287 | validation: 0.26971010255505634]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_1053.pth
	Model improved!!!
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26906005188685017		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.26906005188685017 | validation: 0.26731183479135984]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_1054.pth
	Model improved!!!
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2619016787145075		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.2619016787145075 | validation: 0.2632654817678632]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_1055.pth
	Model improved!!!
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26216692606973097		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.26216692606973097 | validation: 0.29199400183591856]
	TIME [epoch: 27.6 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3029580903196236		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.3029580903196236 | validation: 0.2871942649836484]
	TIME [epoch: 27.6 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27341013300036954		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.27341013300036954 | validation: 0.45544338595649064]
	TIME [epoch: 27.6 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39102157125366027		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.39102157125366027 | validation: 0.3199731045292962]
	TIME [epoch: 27.6 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28131945078386933		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.28131945078386933 | validation: 0.3184115427954744]
	TIME [epoch: 27.6 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29924039331007585		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.29924039331007585 | validation: 0.3773658001114568]
	TIME [epoch: 27.7 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37833424710694347		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.37833424710694347 | validation: 0.29304283617689697]
	TIME [epoch: 27.6 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31847439084102724		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.31847439084102724 | validation: 0.3250678376860397]
	TIME [epoch: 27.6 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2945502675206423		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.2945502675206423 | validation: 0.27215346840892507]
	TIME [epoch: 27.7 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2914808850936613		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.2914808850936613 | validation: 0.31029008720412615]
	TIME [epoch: 27.6 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27900957478302335		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.27900957478302335 | validation: 0.28374741533599446]
	TIME [epoch: 27.6 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2724119300040688		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.2724119300040688 | validation: 0.28331041037114085]
	TIME [epoch: 27.7 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25610238112824707		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.25610238112824707 | validation: 0.26091561255673834]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_1068.pth
	Model improved!!!
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24550936780844743		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.24550936780844743 | validation: 0.2945972807396328]
	TIME [epoch: 27.6 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26356266773605835		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.26356266773605835 | validation: 0.3062733466528983]
	TIME [epoch: 27.7 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2987803919530679		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.2987803919530679 | validation: 0.2650525674824635]
	TIME [epoch: 27.6 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.274347387642513		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.274347387642513 | validation: 0.3156656991706432]
	TIME [epoch: 27.6 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.288309613986708		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.288309613986708 | validation: 0.3317033150137283]
	TIME [epoch: 27.7 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2644591933203515		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.2644591933203515 | validation: 0.2953892462885968]
	TIME [epoch: 27.6 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2703099068263402		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.2703099068263402 | validation: 0.3148231072616436]
	TIME [epoch: 27.7 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2782994959104206		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.2782994959104206 | validation: 0.33904773819018486]
	TIME [epoch: 27.7 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2622748514492338		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.2622748514492338 | validation: 0.2989615079330715]
	TIME [epoch: 27.6 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30238203955311505		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.30238203955311505 | validation: 0.3341160897406565]
	TIME [epoch: 27.6 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2697071663439484		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.2697071663439484 | validation: 0.2913321076946528]
	TIME [epoch: 27.7 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25362117458687733		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.25362117458687733 | validation: 0.2870857473003424]
	TIME [epoch: 27.6 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25030672111467045		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.25030672111467045 | validation: 0.26610631909140514]
	TIME [epoch: 27.7 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26286986808864027		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.26286986808864027 | validation: 0.2951738559493613]
	TIME [epoch: 27.6 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26090600310144807		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.26090600310144807 | validation: 0.2799731895917497]
	TIME [epoch: 27.7 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2566746928235604		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.2566746928235604 | validation: 0.29947969023988913]
	TIME [epoch: 27.7 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25596487941255924		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.25596487941255924 | validation: 0.24553245718357106]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_1085.pth
	Model improved!!!
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25317472087454596		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.25317472087454596 | validation: 0.41216462180637564]
	TIME [epoch: 27.7 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30558088346725737		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.30558088346725737 | validation: 0.3171670362504732]
	TIME [epoch: 27.7 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2693114458460268		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.2693114458460268 | validation: 0.32236510078214337]
	TIME [epoch: 27.7 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26836909688843363		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.26836909688843363 | validation: 0.28760296241219613]
	TIME [epoch: 27.6 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24803975748082846		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.24803975748082846 | validation: 0.26161837267687765]
	TIME [epoch: 27.8 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26105979007036717		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.26105979007036717 | validation: 0.28420629205767645]
	TIME [epoch: 27.7 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26677076426685353		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.26677076426685353 | validation: 0.2634852624607249]
	TIME [epoch: 27.7 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24369828144881506		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.24369828144881506 | validation: 0.2620924345922987]
	TIME [epoch: 27.7 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.270739874413011		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.270739874413011 | validation: 0.26874053588762137]
	TIME [epoch: 27.7 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2974330505188636		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.2974330505188636 | validation: 0.3254502419438745]
	TIME [epoch: 27.6 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2821001177032923		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.2821001177032923 | validation: 0.317369041501859]
	TIME [epoch: 27.7 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32164365091251373		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.32164365091251373 | validation: 0.32324077334351414]
	TIME [epoch: 27.7 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3109661250542959		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.3109661250542959 | validation: 0.32342757419382523]
	TIME [epoch: 27.8 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2933002870174627		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.2933002870174627 | validation: 0.29439117655226227]
	TIME [epoch: 27.7 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3115356158265148		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.3115356158265148 | validation: 0.3945745865286776]
	TIME [epoch: 27.7 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3012015163869435		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.3012015163869435 | validation: 0.3142866393198149]
	TIME [epoch: 27.7 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29021863319567837		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.29021863319567837 | validation: 0.31699268601945524]
	TIME [epoch: 27.7 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2921010038718366		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.2921010038718366 | validation: 0.28860629549280936]
	TIME [epoch: 27.7 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29507454505864233		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.29507454505864233 | validation: 0.36212506660144755]
	TIME [epoch: 27.7 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30134902641313754		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.30134902641313754 | validation: 0.26408810499176294]
	TIME [epoch: 27.7 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25952484207901144		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.25952484207901144 | validation: 0.2641884064693566]
	TIME [epoch: 27.7 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2770359270750477		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.2770359270750477 | validation: 0.25612515111795225]
	TIME [epoch: 27.7 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26927703799557434		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.26927703799557434 | validation: 0.33967349029783706]
	TIME [epoch: 27.7 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2674733052311319		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.2674733052311319 | validation: 0.2768022722082862]
	TIME [epoch: 27.7 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23903660209260658		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.23903660209260658 | validation: 0.24060511367030166]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_1110.pth
	Model improved!!!
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2613434084694559		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.2613434084694559 | validation: 0.3638857785605437]
	TIME [epoch: 27.6 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27387216356481564		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.27387216356481564 | validation: 0.2507250860791488]
	TIME [epoch: 27.7 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2782139689169389		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.2782139689169389 | validation: 0.25351528201231704]
	TIME [epoch: 27.7 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2587149451177224		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.2587149451177224 | validation: 0.24644810067161033]
	TIME [epoch: 27.7 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24026233279491535		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.24026233279491535 | validation: 0.24976771955061058]
	TIME [epoch: 27.7 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2346336448546097		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.2346336448546097 | validation: 0.2629486777024217]
	TIME [epoch: 27.6 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23074654645560774		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.23074654645560774 | validation: 0.2744811229266301]
	TIME [epoch: 27.7 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24847185435563246		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.24847185435563246 | validation: 0.2873417442931353]
	TIME [epoch: 27.7 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24871760196534354		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.24871760196534354 | validation: 0.30532776124000915]
	TIME [epoch: 27.7 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2416104777324872		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.2416104777324872 | validation: 0.2492309174439257]
	TIME [epoch: 27.7 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2946457190931441		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.2946457190931441 | validation: 0.38280454692026156]
	TIME [epoch: 27.7 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.282464840285513		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.282464840285513 | validation: 0.3070569696387879]
	TIME [epoch: 27.6 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2431665050079006		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.2431665050079006 | validation: 0.2829821542052502]
	TIME [epoch: 27.7 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2455342297531888		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.2455342297531888 | validation: 0.26334131762995827]
	TIME [epoch: 27.7 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24922895696609942		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.24922895696609942 | validation: 0.39230204172101013]
	TIME [epoch: 27.7 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34584639822166313		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.34584639822166313 | validation: 0.3361929219228011]
	TIME [epoch: 27.6 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2912102316302766		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.2912102316302766 | validation: 0.30730272580531726]
	TIME [epoch: 27.7 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2772005013317007		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.2772005013317007 | validation: 0.27355484350315723]
	TIME [epoch: 27.6 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2558600237658678		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.2558600237658678 | validation: 0.2759843141091108]
	TIME [epoch: 27.7 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25049881644768773		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.25049881644768773 | validation: 0.26127160824100626]
	TIME [epoch: 27.7 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25156634297630026		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.25156634297630026 | validation: 0.2517367618715219]
	TIME [epoch: 27.7 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24509743057151934		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.24509743057151934 | validation: 0.2752880606579051]
	TIME [epoch: 27.7 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25406492545223075		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.25406492545223075 | validation: 0.24368579587389444]
	TIME [epoch: 27.7 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2579373396208747		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.2579373396208747 | validation: 0.3051387107133281]
	TIME [epoch: 27.7 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29517397325818706		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.29517397325818706 | validation: 0.30877120705439515]
	TIME [epoch: 27.7 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.275628386328825		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.275628386328825 | validation: 0.2455142919765554]
	TIME [epoch: 27.6 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22612239593608155		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.22612239593608155 | validation: 0.2296359718595714]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_1137.pth
	Model improved!!!
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23323421786068627		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.23323421786068627 | validation: 0.24576460966110106]
	TIME [epoch: 27.7 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3148870078596637		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.3148870078596637 | validation: 0.24362765122605975]
	TIME [epoch: 27.6 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22663742642292728		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.22663742642292728 | validation: 0.22783830514904513]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_1140.pth
	Model improved!!!
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24526948694978193		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.24526948694978193 | validation: 0.2699438102702845]
	TIME [epoch: 27.6 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25480590243914597		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.25480590243914597 | validation: 0.2886468052227742]
	TIME [epoch: 27.6 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26503411135572996		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.26503411135572996 | validation: 0.24582199041295627]
	TIME [epoch: 27.6 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22908755529852845		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.22908755529852845 | validation: 0.22296163994605958]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_1144.pth
	Model improved!!!
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22145730937626804		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.22145730937626804 | validation: 0.2629045618438325]
	TIME [epoch: 27.6 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23870332060203595		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.23870332060203595 | validation: 0.2463183400314601]
	TIME [epoch: 27.6 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2141494388726914		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.2141494388726914 | validation: 0.2541540103049226]
	TIME [epoch: 27.6 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2243619773056961		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.2243619773056961 | validation: 0.23183121143405383]
	TIME [epoch: 27.6 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23005725598463428		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.23005725598463428 | validation: 0.24017914691853948]
	TIME [epoch: 27.6 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24416798039331583		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.24416798039331583 | validation: 0.25475412630215555]
	TIME [epoch: 27.7 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2495882793399259		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.2495882793399259 | validation: 0.225692843035034]
	TIME [epoch: 27.6 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22275838805192472		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.22275838805192472 | validation: 0.24671783089383909]
	TIME [epoch: 27.7 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23693313518152914		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.23693313518152914 | validation: 0.23986030715617518]
	TIME [epoch: 27.7 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2439965891069909		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.2439965891069909 | validation: 0.280580576684872]
	TIME [epoch: 27.6 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25862387265209136		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.25862387265209136 | validation: 0.24157443723575622]
	TIME [epoch: 27.7 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22217718315676102		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.22217718315676102 | validation: 0.2475716249035159]
	TIME [epoch: 27.7 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2887644283195194		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.2887644283195194 | validation: 0.22507829932001375]
	TIME [epoch: 27.6 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22159623958942182		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.22159623958942182 | validation: 0.23906254080297096]
	TIME [epoch: 27.7 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21342638132131553		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.21342638132131553 | validation: 0.2345738870230467]
	TIME [epoch: 27.6 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2247108515254141		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.2247108515254141 | validation: 0.2279121494115587]
	TIME [epoch: 27.6 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24337143087810365		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.24337143087810365 | validation: 0.25282613478582877]
	TIME [epoch: 27.6 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2239360882384418		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.2239360882384418 | validation: 0.22592103763630986]
	TIME [epoch: 27.6 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21667433207077932		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.21667433207077932 | validation: 0.23690280741688924]
	TIME [epoch: 27.6 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23904523720343782		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.23904523720343782 | validation: 0.2445360803958381]
	TIME [epoch: 27.6 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2335237463366568		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.2335237463366568 | validation: 0.2423592990974624]
	TIME [epoch: 27.6 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23219289603416698		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.23219289603416698 | validation: 0.269738076344279]
	TIME [epoch: 27.6 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23665250105604088		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.23665250105604088 | validation: 0.2623137413056048]
	TIME [epoch: 27.7 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25390094126602714		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.25390094126602714 | validation: 0.2337071461815266]
	TIME [epoch: 27.6 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23064530852403653		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.23064530852403653 | validation: 0.2554490798035461]
	TIME [epoch: 27.7 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2223735221494146		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.2223735221494146 | validation: 0.2406819449866381]
	TIME [epoch: 27.6 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24305208559252395		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.24305208559252395 | validation: 0.22788707321900725]
	TIME [epoch: 27.6 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22012219724464072		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.22012219724464072 | validation: 0.2614145118315465]
	TIME [epoch: 27.7 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23394720976413808		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.23394720976413808 | validation: 0.26901394797625294]
	TIME [epoch: 27.7 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22939895159288176		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.22939895159288176 | validation: 0.25293553739280006]
	TIME [epoch: 27.6 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23804451775304075		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.23804451775304075 | validation: 0.25420918645075263]
	TIME [epoch: 27.7 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2558437619490538		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.2558437619490538 | validation: 0.27718814096331107]
	TIME [epoch: 27.7 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2453356242110849		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.2453356242110849 | validation: 0.2423341289968823]
	TIME [epoch: 27.6 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2387452631075347		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.2387452631075347 | validation: 0.25507013790450117]
	TIME [epoch: 27.7 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2294531853781992		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.2294531853781992 | validation: 0.22040490252413988]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_1179.pth
	Model improved!!!
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.232399367290403		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.232399367290403 | validation: 0.21367656758443698]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_1180.pth
	Model improved!!!
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22829210509372144		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.22829210509372144 | validation: 0.2757574398213648]
	TIME [epoch: 27.6 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2357117426715974		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.2357117426715974 | validation: 0.2557857518282129]
	TIME [epoch: 27.6 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2215705328842133		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.2215705328842133 | validation: 0.2643255666116345]
	TIME [epoch: 27.7 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2626420751921016		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.2626420751921016 | validation: 0.3268088864085396]
	TIME [epoch: 27.6 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2635269052596855		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.2635269052596855 | validation: 0.2686100813723997]
	TIME [epoch: 27.6 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24288919318713767		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.24288919318713767 | validation: 0.23892675004548236]
	TIME [epoch: 27.6 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23446978405149427		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.23446978405149427 | validation: 0.2575193076270188]
	TIME [epoch: 27.6 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22919685379594065		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.22919685379594065 | validation: 0.25390063086494147]
	TIME [epoch: 27.6 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23468171509345426		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.23468171509345426 | validation: 0.24992529436707167]
	TIME [epoch: 27.6 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23150858847775868		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.23150858847775868 | validation: 0.27949408434159856]
	TIME [epoch: 27.6 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23877059545035034		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.23877059545035034 | validation: 0.2764569646375753]
	TIME [epoch: 27.6 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26003428434923825		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.26003428434923825 | validation: 0.29926334253597175]
	TIME [epoch: 27.6 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24416614148266028		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.24416614148266028 | validation: 0.24534513276891617]
	TIME [epoch: 27.6 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22656806694822532		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.22656806694822532 | validation: 0.24466685881697864]
	TIME [epoch: 27.5 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2376156662205315		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.2376156662205315 | validation: 0.27366769388860085]
	TIME [epoch: 27.7 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26653732468418373		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.26653732468418373 | validation: 0.31781049614260154]
	TIME [epoch: 27.6 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2830958758371242		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.2830958758371242 | validation: 0.2808050591711991]
	TIME [epoch: 27.7 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24678892779905218		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.24678892779905218 | validation: 0.2524745268027621]
	TIME [epoch: 27.7 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2402598170042364		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.2402598170042364 | validation: 0.23473191051412737]
	TIME [epoch: 27.6 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25998822613550165		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.25998822613550165 | validation: 0.3403618073481103]
	TIME [epoch: 27.6 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2655779714696438		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.2655779714696438 | validation: 0.2435936713286132]
	TIME [epoch: 27.7 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23011046082087122		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.23011046082087122 | validation: 0.2251858212959456]
	TIME [epoch: 27.6 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21133136154429782		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.21133136154429782 | validation: 0.21647189529126376]
	TIME [epoch: 27.7 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21153614534618442		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.21153614534618442 | validation: 0.241879001172439]
	TIME [epoch: 27.7 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23018866951568795		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.23018866951568795 | validation: 0.2311990757716308]
	TIME [epoch: 27.7 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23305812537754303		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.23305812537754303 | validation: 0.23663640611217382]
	TIME [epoch: 27.7 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23388257543900862		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.23388257543900862 | validation: 0.27816689129155464]
	TIME [epoch: 27.7 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26285022376066564		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.26285022376066564 | validation: 0.27145245240168253]
	TIME [epoch: 27.7 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22787233953959884		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.22787233953959884 | validation: 0.2240587501458532]
	TIME [epoch: 27.7 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2116052173156965		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.2116052173156965 | validation: 0.21819642440676618]
	TIME [epoch: 27.7 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20752111362507739		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.20752111362507739 | validation: 0.23626645926546938]
	TIME [epoch: 27.7 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2005541801698144		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.2005541801698144 | validation: 0.24321606475960664]
	TIME [epoch: 27.7 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2196536546377965		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.2196536546377965 | validation: 0.23245890324925042]
	TIME [epoch: 27.6 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21103199959288488		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.21103199959288488 | validation: 0.23905353149539083]
	TIME [epoch: 27.7 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22113407533901092		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.22113407533901092 | validation: 0.21902186433577492]
	TIME [epoch: 27.7 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20761850136112128		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.20761850136112128 | validation: 0.2167957687411029]
	TIME [epoch: 27.7 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20058352882728828		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.20058352882728828 | validation: 0.2202224228898555]
	TIME [epoch: 27.6 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2032878598352869		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.2032878598352869 | validation: 0.20652584475971555]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_1218.pth
	Model improved!!!
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20823450311195385		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.20823450311195385 | validation: 0.2251385486484688]
	TIME [epoch: 27.6 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22374572637447418		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.22374572637447418 | validation: 0.2389085607383301]
	TIME [epoch: 27.6 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2071968739056629		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.2071968739056629 | validation: 0.24577235057959365]
	TIME [epoch: 27.7 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21352437034117724		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.21352437034117724 | validation: 0.23986439695342945]
	TIME [epoch: 27.6 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20580723321824645		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.20580723321824645 | validation: 0.21400206372552716]
	TIME [epoch: 27.7 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.219824901510296		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.219824901510296 | validation: 0.2333288592053444]
	TIME [epoch: 27.7 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20743752358000056		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.20743752358000056 | validation: 0.21816950409390573]
	TIME [epoch: 27.6 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20303234985166974		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.20303234985166974 | validation: 0.22052067879130807]
	TIME [epoch: 27.6 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21295325071996485		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.21295325071996485 | validation: 0.2596367084995288]
	TIME [epoch: 27.7 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23437250054349573		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.23437250054349573 | validation: 0.23362871445704264]
	TIME [epoch: 27.6 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21934236884472139		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.21934236884472139 | validation: 0.23846555110776702]
	TIME [epoch: 27.7 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23282720591909653		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.23282720591909653 | validation: 0.23119080377137988]
	TIME [epoch: 27.6 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22917814429125108		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.22917814429125108 | validation: 0.25260731000609943]
	TIME [epoch: 27.7 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21446562646279474		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.21446562646279474 | validation: 0.20654108539116778]
	TIME [epoch: 27.7 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21052163727615728		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.21052163727615728 | validation: 0.22386356517770103]
	TIME [epoch: 27.6 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2048280737984328		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.2048280737984328 | validation: 0.22290952904324357]
	TIME [epoch: 27.7 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21951871554229563		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.21951871554229563 | validation: 0.2230075410705934]
	TIME [epoch: 27.7 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2222193655350753		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.2222193655350753 | validation: 0.2028335366357049]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_1236.pth
	Model improved!!!
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20836808525861195		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.20836808525861195 | validation: 0.22604461669285314]
	TIME [epoch: 27.7 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19417876104437815		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.19417876104437815 | validation: 0.23572453826572523]
	TIME [epoch: 27.7 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2054600832532029		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.2054600832532029 | validation: 0.22071086555840716]
	TIME [epoch: 27.7 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21485770044273667		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.21485770044273667 | validation: 0.2962732248238157]
	TIME [epoch: 27.7 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26081099522151335		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.26081099522151335 | validation: 0.2496503238388774]
	TIME [epoch: 27.7 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23032698696964046		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.23032698696964046 | validation: 0.23537687341493413]
	TIME [epoch: 27.6 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22675741992909187		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.22675741992909187 | validation: 0.2216287199441841]
	TIME [epoch: 27.7 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20408470566681208		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.20408470566681208 | validation: 0.23053418624665228]
	TIME [epoch: 27.6 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2081652824256895		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.2081652824256895 | validation: 0.2833609421853753]
	TIME [epoch: 27.7 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22940735333557602		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.22940735333557602 | validation: 0.2145305903865191]
	TIME [epoch: 27.6 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2096470677945798		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.2096470677945798 | validation: 0.21638306921685874]
	TIME [epoch: 27.7 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20509900315386312		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.20509900315386312 | validation: 0.22810346919426294]
	TIME [epoch: 27.7 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2189635876163667		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.2189635876163667 | validation: 0.21226778755874445]
	TIME [epoch: 27.7 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2084402820302382		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.2084402820302382 | validation: 0.2222605672570686]
	TIME [epoch: 27.7 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20111270052047656		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.20111270052047656 | validation: 0.21751435058682056]
	TIME [epoch: 27.7 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19968287738104082		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.19968287738104082 | validation: 0.197812998347015]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_1252.pth
	Model improved!!!
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20673320776472254		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.20673320776472254 | validation: 0.25580112229866214]
	TIME [epoch: 27.7 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20898402966344504		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.20898402966344504 | validation: 0.22355931063415885]
	TIME [epoch: 27.7 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22828557380559616		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.22828557380559616 | validation: 0.2481899829010195]
	TIME [epoch: 27.7 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2107517377286239		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.2107517377286239 | validation: 0.21851125471779406]
	TIME [epoch: 27.7 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23494739098335787		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.23494739098335787 | validation: 0.28401517165940365]
	TIME [epoch: 27.7 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22385803573838237		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.22385803573838237 | validation: 0.21330574717046638]
	TIME [epoch: 27.7 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20027682240544423		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.20027682240544423 | validation: 0.23733916803910682]
	TIME [epoch: 27.6 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22165102104247061		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.22165102104247061 | validation: 0.23511893316880234]
	TIME [epoch: 27.7 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21731216895028707		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.21731216895028707 | validation: 0.2536765234274515]
	TIME [epoch: 27.6 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20928417166606036		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.20928417166606036 | validation: 0.252783915627563]
	TIME [epoch: 27.6 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2066393401450394		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.2066393401450394 | validation: 0.2212077910057203]
	TIME [epoch: 27.7 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21168354479406343		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.21168354479406343 | validation: 0.23759183066585954]
	TIME [epoch: 27.7 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22368996066050487		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.22368996066050487 | validation: 0.20640813976710753]
	TIME [epoch: 27.6 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19776271016737226		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.19776271016737226 | validation: 0.21654804696072574]
	TIME [epoch: 27.7 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20136069699944492		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.20136069699944492 | validation: 0.23815067593288045]
	TIME [epoch: 27.7 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20707883303160626		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.20707883303160626 | validation: 0.2199781174915374]
	TIME [epoch: 27.7 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21199520775408587		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.21199520775408587 | validation: 0.2407692170886203]
	TIME [epoch: 27.7 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21611082904109735		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.21611082904109735 | validation: 0.20751273165911976]
	TIME [epoch: 27.7 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2134763380405459		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.2134763380405459 | validation: 0.21978067418116656]
	TIME [epoch: 27.6 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.225347117205656		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.225347117205656 | validation: 0.23669605968332838]
	TIME [epoch: 27.7 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2207418749051936		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.2207418749051936 | validation: 0.23903356151947805]
	TIME [epoch: 27.7 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21977857492349848		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.21977857492349848 | validation: 0.21903404799251924]
	TIME [epoch: 27.6 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21033475391041628		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.21033475391041628 | validation: 0.22070737665110154]
	TIME [epoch: 27.7 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2203266625135431		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.2203266625135431 | validation: 0.2193145944565446]
	TIME [epoch: 27.6 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25494573978085133		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.25494573978085133 | validation: 0.23942284945928496]
	TIME [epoch: 27.6 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24332163475810253		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.24332163475810253 | validation: 0.21432379433087223]
	TIME [epoch: 27.7 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2218392568830947		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.2218392568830947 | validation: 0.20498849682146422]
	TIME [epoch: 27.6 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21708619134161095		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.21708619134161095 | validation: 0.21038043245485274]
	TIME [epoch: 27.6 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2123624192661437		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.2123624192661437 | validation: 0.24557734521519856]
	TIME [epoch: 27.7 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22134196016611557		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.22134196016611557 | validation: 0.22721097452178401]
	TIME [epoch: 27.6 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2328857191050498		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.2328857191050498 | validation: 0.3019254163480926]
	TIME [epoch: 27.7 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28055570803829843		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.28055570803829843 | validation: 0.2516599214395828]
	TIME [epoch: 27.7 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21409930210427097		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.21409930210427097 | validation: 0.22486723295612698]
	TIME [epoch: 27.7 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20599999544955688		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.20599999544955688 | validation: 0.23766273821370512]
	TIME [epoch: 27.8 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21268299699947554		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.21268299699947554 | validation: 0.21583654354947748]
	TIME [epoch: 27.7 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21069718948626837		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.21069718948626837 | validation: 0.21798304079821912]
	TIME [epoch: 27.7 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2199633444925737		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.2199633444925737 | validation: 0.22200241002565563]
	TIME [epoch: 27.8 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2172530747024917		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.2172530747024917 | validation: 0.23028339604364612]
	TIME [epoch: 27.7 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21225695510581363		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.21225695510581363 | validation: 0.22191256908802465]
	TIME [epoch: 27.7 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22002949005115374		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.22002949005115374 | validation: 0.2959345960326359]
	TIME [epoch: 27.7 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2801026359494755		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.2801026359494755 | validation: 0.29503277119529625]
	TIME [epoch: 27.7 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23676727458304248		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.23676727458304248 | validation: 0.21849789452750798]
	TIME [epoch: 27.6 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19714729499361264		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.19714729499361264 | validation: 0.212011844089163]
	TIME [epoch: 27.7 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19998993530444464		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.19998993530444464 | validation: 0.24613520101593758]
	TIME [epoch: 27.7 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21986886253443758		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.21986886253443758 | validation: 0.2659268577001698]
	TIME [epoch: 27.7 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23576796507572864		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.23576796507572864 | validation: 0.26389624756865415]
	TIME [epoch: 27.7 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2210824594771169		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.2210824594771169 | validation: 0.24370789440131674]
	TIME [epoch: 27.7 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2131719638066504		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.2131719638066504 | validation: 0.23287247132842875]
	TIME [epoch: 27.7 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20543421498642417		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.20543421498642417 | validation: 0.20463324930921695]
	TIME [epoch: 27.7 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18521587014919488		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.18521587014919488 | validation: 0.23639881355115122]
	TIME [epoch: 27.6 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2165165795323119		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.2165165795323119 | validation: 0.27449520340036015]
	TIME [epoch: 27.7 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2822329457694065		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.2822329457694065 | validation: 0.2691839833720318]
	TIME [epoch: 27.6 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22362146465109567		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.22362146465109567 | validation: 0.266640652258088]
	TIME [epoch: 27.6 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22123508296096034		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.22123508296096034 | validation: 0.25445520312736203]
	TIME [epoch: 27.7 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2119333874474769		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.2119333874474769 | validation: 0.2404293661112767]
	TIME [epoch: 27.6 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2067419236962174		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.2067419236962174 | validation: 0.2162814217228193]
	TIME [epoch: 27.7 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19773891530835508		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.19773891530835508 | validation: 0.20444604703257724]
	TIME [epoch: 27.7 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1941934384695862		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.1941934384695862 | validation: 0.223461929466023]
	TIME [epoch: 27.7 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1915378912894572		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.1915378912894572 | validation: 0.22295463342292776]
	TIME [epoch: 27.7 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20223652645063342		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.20223652645063342 | validation: 0.2213654610297999]
	TIME [epoch: 27.7 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19499241769863912		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.19499241769863912 | validation: 0.22829352016794321]
	TIME [epoch: 27.6 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20947757278290427		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.20947757278290427 | validation: 0.2247423576628492]
	TIME [epoch: 27.7 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2007657988677396		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.2007657988677396 | validation: 0.25048715030805707]
	TIME [epoch: 27.7 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20284768916975485		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.20284768916975485 | validation: 0.2164483711556017]
	TIME [epoch: 27.7 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2023299833747096		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.2023299833747096 | validation: 0.22110887071698324]
	TIME [epoch: 27.7 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23136137242882612		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.23136137242882612 | validation: 0.21695749641212964]
	TIME [epoch: 27.7 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1976835814652989		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.1976835814652989 | validation: 0.2228603406126355]
	TIME [epoch: 27.6 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1893780949198614		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.1893780949198614 | validation: 0.2089041393973173]
	TIME [epoch: 27.7 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18843595228406285		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.18843595228406285 | validation: 0.21709409729910797]
	TIME [epoch: 27.7 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19619819171540068		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.19619819171540068 | validation: 0.22857718813224012]
	TIME [epoch: 27.7 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19189915781976735		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.19189915781976735 | validation: 0.21207638023095954]
	TIME [epoch: 27.7 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19273730473915052		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.19273730473915052 | validation: 0.20511375925511469]
	TIME [epoch: 27.7 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19567924146659205		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.19567924146659205 | validation: 0.22014746721172584]
	TIME [epoch: 27.7 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1990880542067125		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.1990880542067125 | validation: 0.26346679273082496]
	TIME [epoch: 27.7 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21906952211317687		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.21906952211317687 | validation: 0.21657225102129565]
	TIME [epoch: 27.7 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1900328649992207		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.1900328649992207 | validation: 0.19676961485083566]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_1328.pth
	Model improved!!!
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1974986490770728		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.1974986490770728 | validation: 0.20903019834814374]
	TIME [epoch: 27.7 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19650247424948833		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.19650247424948833 | validation: 0.22005708640918897]
	TIME [epoch: 27.7 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20661453489083365		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.20661453489083365 | validation: 0.2083393658551546]
	TIME [epoch: 27.6 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19668737170512118		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.19668737170512118 | validation: 0.1993962139382033]
	TIME [epoch: 27.7 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2044684985615465		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.2044684985615465 | validation: 0.21071137794321843]
	TIME [epoch: 27.6 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20456095778660713		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.20456095778660713 | validation: 0.21279497527233432]
	TIME [epoch: 27.7 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19867902008396088		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.19867902008396088 | validation: 0.22409872098479247]
	TIME [epoch: 27.7 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21353968784820357		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.21353968784820357 | validation: 0.26758955842797283]
	TIME [epoch: 27.7 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2131901122341712		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.2131901122341712 | validation: 0.2207904280597422]
	TIME [epoch: 27.7 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18808279729057528		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.18808279729057528 | validation: 0.20798863038491874]
	TIME [epoch: 27.7 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18496255011085808		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.18496255011085808 | validation: 0.19342658493189036]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_1339.pth
	Model improved!!!
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18713929780510047		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.18713929780510047 | validation: 0.20139756732472755]
	TIME [epoch: 27.7 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1953707445286089		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.1953707445286089 | validation: 0.23632760262213331]
	TIME [epoch: 27.6 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20034099016914705		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.20034099016914705 | validation: 0.23911103533994907]
	TIME [epoch: 27.7 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20903276594584363		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.20903276594584363 | validation: 0.2305454486943831]
	TIME [epoch: 27.7 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19808737064710602		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.19808737064710602 | validation: 0.21559911052343655]
	TIME [epoch: 27.7 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19025495397396514		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.19025495397396514 | validation: 0.2351839246895696]
	TIME [epoch: 27.7 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20481751733997156		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.20481751733997156 | validation: 0.2141820986164766]
	TIME [epoch: 27.7 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18529164328140593		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.18529164328140593 | validation: 0.21432411645734673]
	TIME [epoch: 27.7 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19128765009888188		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.19128765009888188 | validation: 0.21747300588696467]
	TIME [epoch: 27.6 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19708975268881004		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.19708975268881004 | validation: 0.2119105305693021]
	TIME [epoch: 27.7 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19831322811747487		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.19831322811747487 | validation: 0.2285609843995287]
	TIME [epoch: 27.6 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20446455297792968		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.20446455297792968 | validation: 0.21555094624111742]
	TIME [epoch: 27.7 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1909320921289207		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.1909320921289207 | validation: 0.21350762524058545]
	TIME [epoch: 27.6 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18585013527880015		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.18585013527880015 | validation: 0.21167262999486205]
	TIME [epoch: 27.6 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18240343590253538		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.18240343590253538 | validation: 0.19110270974055407]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_1354.pth
	Model improved!!!
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19152362187609642		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.19152362187609642 | validation: 0.19986347281944328]
	TIME [epoch: 27.7 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18476479870422882		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.18476479870422882 | validation: 0.198240560578774]
	TIME [epoch: 27.7 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1812086133797258		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.1812086133797258 | validation: 0.19371096127739088]
	TIME [epoch: 27.7 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18852239520096914		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.18852239520096914 | validation: 0.20953678294306458]
	TIME [epoch: 27.7 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18239486969052274		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.18239486969052274 | validation: 0.20456866869031792]
	TIME [epoch: 27.7 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18664131020452085		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.18664131020452085 | validation: 0.1885129896537843]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_1360.pth
	Model improved!!!
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18924710805991485		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.18924710805991485 | validation: 0.19674864165915615]
	TIME [epoch: 27.7 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19789678116271342		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.19789678116271342 | validation: 0.19236056434452897]
	TIME [epoch: 27.7 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20529547587065564		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.20529547587065564 | validation: 0.20782563969654477]
	TIME [epoch: 27.7 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18057170942953768		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.18057170942953768 | validation: 0.2169123789166204]
	TIME [epoch: 27.7 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1922488296061379		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.1922488296061379 | validation: 0.21929146573082642]
	TIME [epoch: 27.7 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20193026722044383		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.20193026722044383 | validation: 0.2248268516034727]
	TIME [epoch: 27.7 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19079120047830966		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.19079120047830966 | validation: 0.20863950513803786]
	TIME [epoch: 27.7 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1879301907075501		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.1879301907075501 | validation: 0.20167209778430398]
	TIME [epoch: 27.7 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21154916664936338		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.21154916664936338 | validation: 0.21410954591697015]
	TIME [epoch: 27.7 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19363439871430557		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.19363439871430557 | validation: 0.20660879946928248]
	TIME [epoch: 27.7 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1877449308059253		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.1877449308059253 | validation: 0.23549950179847748]
	TIME [epoch: 27.7 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20517875564177024		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.20517875564177024 | validation: 0.19880127003762194]
	TIME [epoch: 27.7 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19417111211308793		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.19417111211308793 | validation: 0.24078041615916854]
	TIME [epoch: 27.7 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.210229211055107		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.210229211055107 | validation: 0.2037963213837002]
	TIME [epoch: 27.7 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19820343955510336		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.19820343955510336 | validation: 0.1958811127040535]
	TIME [epoch: 27.7 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20629201922829968		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.20629201922829968 | validation: 0.21608609140431034]
	TIME [epoch: 27.7 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19904628364408272		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.19904628364408272 | validation: 0.21965552422762913]
	TIME [epoch: 27.7 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22089690949814347		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.22089690949814347 | validation: 0.2807493995769774]
	TIME [epoch: 27.7 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2367380740116193		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.2367380740116193 | validation: 0.23074632382030938]
	TIME [epoch: 27.7 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20553597657393377		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.20553597657393377 | validation: 0.21326417904854453]
	TIME [epoch: 27.7 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19358804238506166		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.19358804238506166 | validation: 0.21363264685808647]
	TIME [epoch: 27.7 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19892698075546036		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.19892698075546036 | validation: 0.2241980929019384]
	TIME [epoch: 27.7 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20876931801888565		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.20876931801888565 | validation: 0.20644113781908277]
	TIME [epoch: 27.7 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18900792685878698		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.18900792685878698 | validation: 0.21059638169651615]
	TIME [epoch: 27.7 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18188921689911844		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.18188921689911844 | validation: 0.20251124641431467]
	TIME [epoch: 27.7 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19854743504323116		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.19854743504323116 | validation: 0.20406352379370155]
	TIME [epoch: 27.7 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19860095607260123		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.19860095607260123 | validation: 0.20801083187553374]
	TIME [epoch: 27.7 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.212060195078496		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.212060195078496 | validation: 0.2120331419499473]
	TIME [epoch: 27.7 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2124547313656454		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.2124547313656454 | validation: 0.19919946063918303]
	TIME [epoch: 27.7 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1927404199789058		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.1927404199789058 | validation: 0.22500046475267127]
	TIME [epoch: 27.7 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20297057314863215		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.20297057314863215 | validation: 0.22471863701038985]
	TIME [epoch: 27.7 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20646490020470362		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.20646490020470362 | validation: 0.21682431611926198]
	TIME [epoch: 27.7 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21202149283497104		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.21202149283497104 | validation: 0.20305192733491687]
	TIME [epoch: 27.7 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1926658320433654		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.1926658320433654 | validation: 0.20302586385369523]
	TIME [epoch: 27.7 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19066180771094182		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.19066180771094182 | validation: 0.19377412786450052]
	TIME [epoch: 27.7 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18621972107754847		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.18621972107754847 | validation: 0.20627482785351106]
	TIME [epoch: 27.7 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19109262230173824		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.19109262230173824 | validation: 0.20063295672374842]
	TIME [epoch: 27.7 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18378589678439722		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.18378589678439722 | validation: 0.20822090348108815]
	TIME [epoch: 27.7 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18575953549384724		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.18575953549384724 | validation: 0.2074604267941369]
	TIME [epoch: 27.7 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18521242798498955		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.18521242798498955 | validation: 0.19720003716579768]
	TIME [epoch: 27.7 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18458215826162397		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.18458215826162397 | validation: 0.22371997946773514]
	TIME [epoch: 27.7 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20175092403500838		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.20175092403500838 | validation: 0.25625826933300594]
	TIME [epoch: 27.7 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23256905654650928		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.23256905654650928 | validation: 0.2345031891897371]
	TIME [epoch: 27.7 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20477962864129123		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.20477962864129123 | validation: 0.22961269681935953]
	TIME [epoch: 27.6 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20802406167414408		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.20802406167414408 | validation: 0.21463335428851246]
	TIME [epoch: 27.6 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20168043175721057		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.20168043175721057 | validation: 0.23658133752151272]
	TIME [epoch: 27.7 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20006753742572558		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.20006753742572558 | validation: 0.2241745518008279]
	TIME [epoch: 27.6 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19054636929737098		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.19054636929737098 | validation: 0.22536753498831735]
	TIME [epoch: 27.7 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18764150604356616		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.18764150604356616 | validation: 0.20424840206648295]
	TIME [epoch: 27.7 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18071140206529024		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.18071140206529024 | validation: 0.18630068551897183]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_1410.pth
	Model improved!!!
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17970508977684427		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.17970508977684427 | validation: 0.2098537221045998]
	TIME [epoch: 27.7 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18546710771444977		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.18546710771444977 | validation: 0.2103452244517935]
	TIME [epoch: 27.7 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1801695794253486		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.1801695794253486 | validation: 0.19046777332271475]
	TIME [epoch: 27.7 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17927771394978104		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.17927771394978104 | validation: 0.17889525859627262]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_1414.pth
	Model improved!!!
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18039477964235923		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.18039477964235923 | validation: 0.19938295489693136]
	TIME [epoch: 27.7 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18405122931518578		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.18405122931518578 | validation: 0.20455926285714365]
	TIME [epoch: 27.7 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19320375128530864		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.19320375128530864 | validation: 0.18932824069239523]
	TIME [epoch: 27.7 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18234140234742335		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.18234140234742335 | validation: 0.2031039102742856]
	TIME [epoch: 27.7 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18754551277569598		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.18754551277569598 | validation: 0.21686597554146742]
	TIME [epoch: 27.7 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19356552045834033		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.19356552045834033 | validation: 0.21877177161035039]
	TIME [epoch: 27.7 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19357293741680898		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.19357293741680898 | validation: 0.22047267786114236]
	TIME [epoch: 27.6 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1873545660876747		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.1873545660876747 | validation: 0.20209455336649335]
	TIME [epoch: 27.7 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18280795505872624		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.18280795505872624 | validation: 0.19274784195377034]
	TIME [epoch: 27.7 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1773728629409838		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.1773728629409838 | validation: 0.20184183999557653]
	TIME [epoch: 27.7 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18539546867271198		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.18539546867271198 | validation: 0.2101336257591137]
	TIME [epoch: 27.7 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18236698664750178		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.18236698664750178 | validation: 0.1909787048448672]
	TIME [epoch: 27.7 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1814229738580065		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.1814229738580065 | validation: 0.20187916390283114]
	TIME [epoch: 27.7 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18784971828389457		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.18784971828389457 | validation: 0.22042143532280295]
	TIME [epoch: 27.7 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20198292698407566		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.20198292698407566 | validation: 0.24441632735180843]
	TIME [epoch: 27.7 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19636607108932735		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.19636607108932735 | validation: 0.21089818502283883]
	TIME [epoch: 27.7 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18234671446319403		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.18234671446319403 | validation: 0.2024260104334183]
	TIME [epoch: 27.7 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1796587655358523		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.1796587655358523 | validation: 0.19818283577721538]
	TIME [epoch: 27.7 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18273932476402097		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.18273932476402097 | validation: 0.21517452291566236]
	TIME [epoch: 27.7 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18392985838232148		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.18392985838232148 | validation: 0.20915750403687589]
	TIME [epoch: 27.7 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18451299078937253		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.18451299078937253 | validation: 0.2013887065759014]
	TIME [epoch: 27.7 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17947348420440656		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.17947348420440656 | validation: 0.21936511436887948]
	TIME [epoch: 27.7 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18369580161874247		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.18369580161874247 | validation: 0.20402662991050755]
	TIME [epoch: 27.7 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18854026413904806		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.18854026413904806 | validation: 0.19004481729006797]
	TIME [epoch: 27.7 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18615558403444316		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.18615558403444316 | validation: 0.19554065859481104]
	TIME [epoch: 27.7 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18267545551265432		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.18267545551265432 | validation: 0.18577114971865363]
	TIME [epoch: 27.7 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1799609030753288		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.1799609030753288 | validation: 0.19609998319893618]
	TIME [epoch: 27.7 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18666015629380928		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.18666015629380928 | validation: 0.20651044146798042]
	TIME [epoch: 27.7 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18076335779896985		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.18076335779896985 | validation: 0.20008806905869578]
	TIME [epoch: 27.7 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17984712149734564		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.17984712149734564 | validation: 0.194691036159296]
	TIME [epoch: 27.7 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18773725948338446		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.18773725948338446 | validation: 0.20278425514736545]
	TIME [epoch: 27.7 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18214396884586942		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.18214396884586942 | validation: 0.2088952596597376]
	TIME [epoch: 27.7 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18467844946953615		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.18467844946953615 | validation: 0.2025423143523673]
	TIME [epoch: 27.7 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.188889777477411		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.188889777477411 | validation: 0.21286467466606887]
	TIME [epoch: 27.7 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19046199524348265		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.19046199524348265 | validation: 0.19625726762261003]
	TIME [epoch: 27.7 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18526889475875075		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.18526889475875075 | validation: 0.21369249453557312]
	TIME [epoch: 27.7 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20045634225778322		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.20045634225778322 | validation: 0.22346152985759205]
	TIME [epoch: 27.7 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19796244896032528		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.19796244896032528 | validation: 0.22615278962420818]
	TIME [epoch: 27.7 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19286919846522696		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.19286919846522696 | validation: 0.20347497465311398]
	TIME [epoch: 27.7 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19676530206583115		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.19676530206583115 | validation: 0.21644017369346402]
	TIME [epoch: 27.7 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20327490885035232		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.20327490885035232 | validation: 0.21097631267043457]
	TIME [epoch: 27.7 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19589992125826958		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.19589992125826958 | validation: 0.20635000739501547]
	TIME [epoch: 27.7 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1907856260470586		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.1907856260470586 | validation: 0.21565389272915805]
	TIME [epoch: 27.7 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1936233773786625		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.1936233773786625 | validation: 0.2229182750285498]
	TIME [epoch: 27.7 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19451859371746394		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.19451859371746394 | validation: 0.22581906340766383]
	TIME [epoch: 27.7 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19883128937931138		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.19883128937931138 | validation: 0.2086488008522742]
	TIME [epoch: 27.7 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19116194445360765		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.19116194445360765 | validation: 0.1989922512129758]
	TIME [epoch: 27.7 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18696741151947566		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.18696741151947566 | validation: 0.20595430455204244]
	TIME [epoch: 27.7 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18366138691890188		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.18366138691890188 | validation: 0.21996894142152118]
	TIME [epoch: 27.7 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.194697944954147		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.194697944954147 | validation: 0.19639395966558085]
	TIME [epoch: 27.7 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18730507701792015		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.18730507701792015 | validation: 0.19833804395696944]
	TIME [epoch: 27.7 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19096029234090733		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.19096029234090733 | validation: 0.2054446319161206]
	TIME [epoch: 27.7 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1841051006401993		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.1841051006401993 | validation: 0.2071022790327222]
	TIME [epoch: 27.7 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1883150368762986		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.1883150368762986 | validation: 0.20324436629705872]
	TIME [epoch: 27.7 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18607535172232983		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.18607535172232983 | validation: 0.20802104684189318]
	TIME [epoch: 27.7 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18863086082525427		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.18863086082525427 | validation: 0.20890502821290008]
	TIME [epoch: 27.7 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1863995836483061		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.1863995836483061 | validation: 0.21030691588726633]
	TIME [epoch: 27.7 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17550898302521045		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.17550898302521045 | validation: 0.19888585502078332]
	TIME [epoch: 27.7 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18721705207390443		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.18721705207390443 | validation: 0.22204799281775636]
	TIME [epoch: 27.7 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19066185711551353		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.19066185711551353 | validation: 0.20728326809437284]
	TIME [epoch: 27.7 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18669359066633773		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.18669359066633773 | validation: 0.2170930986310191]
	TIME [epoch: 27.7 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19266763077273902		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.19266763077273902 | validation: 0.2143554309798172]
	TIME [epoch: 27.7 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18275040531768016		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.18275040531768016 | validation: 0.18736592720537487]
	TIME [epoch: 27.7 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1751357241263765		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.1751357241263765 | validation: 0.18283996756489054]
	TIME [epoch: 27.7 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17990190262851752		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.17990190262851752 | validation: 0.1865922158561452]
	TIME [epoch: 27.7 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18176570696959		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.18176570696959 | validation: 0.19136556458704035]
	TIME [epoch: 27.7 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.176745145293435		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.176745145293435 | validation: 0.1923476738097354]
	TIME [epoch: 27.7 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18335167588553328		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.18335167588553328 | validation: 0.2023138623484444]
	TIME [epoch: 27.7 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17732727570193196		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.17732727570193196 | validation: 0.19321068916285053]
	TIME [epoch: 27.7 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17953675619282794		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.17953675619282794 | validation: 0.18081309711585555]
	TIME [epoch: 27.7 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1793453077757588		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.1793453077757588 | validation: 0.19932354147177492]
	TIME [epoch: 27.7 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1803123887873592		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.1803123887873592 | validation: 0.1981884959320156]
	TIME [epoch: 27.7 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17767667328725945		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.17767667328725945 | validation: 0.200937882944583]
	TIME [epoch: 27.7 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18733086099033558		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.18733086099033558 | validation: 0.20566656546583573]
	TIME [epoch: 27.7 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18100467174922463		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.18100467174922463 | validation: 0.19063068921325665]
	TIME [epoch: 27.7 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17914970437539696		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.17914970437539696 | validation: 0.19308320070182589]
	TIME [epoch: 27.6 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1804820632212806		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.1804820632212806 | validation: 0.19922084209251498]
	TIME [epoch: 27.7 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18300380239996317		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.18300380239996317 | validation: 0.20700367349528426]
	TIME [epoch: 27.7 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17693209933452736		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.17693209933452736 | validation: 0.20701770774123934]
	TIME [epoch: 27.7 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17804910719634257		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.17804910719634257 | validation: 0.19149807715719924]
	TIME [epoch: 27.7 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17270901174835385		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.17270901174835385 | validation: 0.18488220170544029]
	TIME [epoch: 27.7 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1736299867462655		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.1736299867462655 | validation: 0.1806942369334726]
	TIME [epoch: 27.7 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17320607940587265		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.17320607940587265 | validation: 0.19529825020635977]
	TIME [epoch: 27.7 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17692155779410693		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.17692155779410693 | validation: 0.18317628030050925]
	TIME [epoch: 27.7 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17111814033337736		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.17111814033337736 | validation: 0.18963081092901157]
	TIME [epoch: 27.7 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17685242625455086		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.17685242625455086 | validation: 0.18457192906491654]
	TIME [epoch: 27.7 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17648523227415658		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.17648523227415658 | validation: 0.17346510414558203]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_1501.pth
	Model improved!!!
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17637257068864354		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.17637257068864354 | validation: 0.18818574080984113]
	TIME [epoch: 27.7 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17970545860376214		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.17970545860376214 | validation: 0.1958415623205753]
	TIME [epoch: 27.7 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1751557517584427		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.1751557517584427 | validation: 0.20848871372484368]
	TIME [epoch: 27.7 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17585471106333012		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.17585471106333012 | validation: 0.1861013680894866]
	TIME [epoch: 27.7 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17461049187520963		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.17461049187520963 | validation: 0.19889156235534927]
	TIME [epoch: 27.7 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17577091562628158		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.17577091562628158 | validation: 0.197568959745864]
	TIME [epoch: 27.7 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18032632211040794		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.18032632211040794 | validation: 0.20173956263683976]
	TIME [epoch: 27.7 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1844245497025674		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.1844245497025674 | validation: 0.19577770695422358]
	TIME [epoch: 27.7 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1739893013522198		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.1739893013522198 | validation: 0.2098458833276985]
	TIME [epoch: 27.7 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18945621363653262		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.18945621363653262 | validation: 0.2126389880194764]
	TIME [epoch: 27.7 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18683828856085072		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.18683828856085072 | validation: 0.22184304452948994]
	TIME [epoch: 27.7 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20458510186465517		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.20458510186465517 | validation: 0.23720485779932854]
	TIME [epoch: 27.7 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20099176007897346		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.20099176007897346 | validation: 0.20885515455998105]
	TIME [epoch: 27.7 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1886376756749368		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.1886376756749368 | validation: 0.19099896997954197]
	TIME [epoch: 27.7 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18275336164150144		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.18275336164150144 | validation: 0.17957788018378992]
	TIME [epoch: 27.7 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1766384206901187		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.1766384206901187 | validation: 0.18829330842398695]
	TIME [epoch: 27.7 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17650300891870296		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.17650300891870296 | validation: 0.17782309765642276]
	TIME [epoch: 27.7 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17970822274676262		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.17970822274676262 | validation: 0.19621048995455526]
	TIME [epoch: 27.7 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18320069820051998		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.18320069820051998 | validation: 0.21214103580583515]
	TIME [epoch: 27.7 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1951321559788136		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.1951321559788136 | validation: 0.20640351429437048]
	TIME [epoch: 27.7 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18076147584746094		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.18076147584746094 | validation: 0.20257655383585782]
	TIME [epoch: 27.7 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17432493780914662		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.17432493780914662 | validation: 0.20318198713832827]
	TIME [epoch: 27.7 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18044906796302065		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.18044906796302065 | validation: 0.23900538856651565]
	TIME [epoch: 27.7 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19245777581480034		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.19245777581480034 | validation: 0.21225397543825694]
	TIME [epoch: 27.7 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18706582355985715		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.18706582355985715 | validation: 0.20359031918563117]
	TIME [epoch: 27.7 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18522657292029177		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.18522657292029177 | validation: 0.21019191580289182]
	TIME [epoch: 27.7 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17501715404272572		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.17501715404272572 | validation: 0.1840641706929502]
	TIME [epoch: 27.7 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18214642523243574		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.18214642523243574 | validation: 0.19067844467697043]
	TIME [epoch: 27.7 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2032218411749197		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.2032218411749197 | validation: 0.1960767207000432]
	TIME [epoch: 27.6 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1857063342510303		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.1857063342510303 | validation: 0.17856339183792858]
	TIME [epoch: 27.7 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1749659166214706		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.1749659166214706 | validation: 0.18896061030782904]
	TIME [epoch: 27.7 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17478654698521576		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.17478654698521576 | validation: 0.18119285523480186]
	TIME [epoch: 27.7 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1874653626830941		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.1874653626830941 | validation: 0.19180504582269386]
	TIME [epoch: 27.7 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18252309213310727		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.18252309213310727 | validation: 0.18433213332736295]
	TIME [epoch: 27.7 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17563394753411016		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.17563394753411016 | validation: 0.1740739016133038]
	TIME [epoch: 27.7 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17748719971463991		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.17748719971463991 | validation: 0.18850052494140335]
	TIME [epoch: 27.7 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18220401331427383		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.18220401331427383 | validation: 0.18348237646710824]
	TIME [epoch: 27.6 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17482720098189927		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.17482720098189927 | validation: 0.18433130100068237]
	TIME [epoch: 27.7 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17592090814274708		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.17592090814274708 | validation: 0.18826184235785381]
	TIME [epoch: 27.7 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17364089819022643		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.17364089819022643 | validation: 0.1810819377874507]
	TIME [epoch: 27.6 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17378447721975762		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.17378447721975762 | validation: 0.19391322882204848]
	TIME [epoch: 27.7 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1829270047970244		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.1829270047970244 | validation: 0.19065417804063367]
	TIME [epoch: 27.7 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1832117538815552		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.1832117538815552 | validation: 0.19069847621925576]
	TIME [epoch: 27.6 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18010909870471847		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.18010909870471847 | validation: 0.18460083108081624]
	TIME [epoch: 27.6 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17521873981374536		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.17521873981374536 | validation: 0.18850629080220382]
	TIME [epoch: 27.7 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18124628505265955		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.18124628505265955 | validation: 0.18726816688291117]
	TIME [epoch: 27.6 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17849203408380743		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.17849203408380743 | validation: 0.18204105657438546]
	TIME [epoch: 27.7 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18125453472470743		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.18125453472470743 | validation: 0.18859166253156223]
	TIME [epoch: 27.7 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18242048132537797		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.18242048132537797 | validation: 0.19901087290144467]
	TIME [epoch: 27.7 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1830003410421695		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.1830003410421695 | validation: 0.19138849254828863]
	TIME [epoch: 27.7 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.188666568198691		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.188666568198691 | validation: 0.21688889338372414]
	TIME [epoch: 27.7 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18518067102839292		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.18518067102839292 | validation: 0.1968025558344038]
	TIME [epoch: 27.7 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.176715938759955		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.176715938759955 | validation: 0.1825569701698469]
	TIME [epoch: 27.7 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18532522652892794		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.18532522652892794 | validation: 0.2011066243132092]
	TIME [epoch: 27.7 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17730327874794471		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.17730327874794471 | validation: 0.17754698234865315]
	TIME [epoch: 27.7 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16885148944491152		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.16885148944491152 | validation: 0.17645730467559279]
	TIME [epoch: 27.7 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17604637708653514		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.17604637708653514 | validation: 0.18913255122581737]
	TIME [epoch: 27.7 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1726478364375789		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.1726478364375789 | validation: 0.19359735151220875]
	TIME [epoch: 27.7 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17772527918414088		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.17772527918414088 | validation: 0.20064317102212847]
	TIME [epoch: 27.7 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1840085364956846		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.1840085364956846 | validation: 0.1948724030061031]
	TIME [epoch: 27.7 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17821248710372328		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.17821248710372328 | validation: 0.19077716300979972]
	TIME [epoch: 27.7 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17915690032610695		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.17915690032610695 | validation: 0.20264731471451933]
	TIME [epoch: 27.7 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1942129264155108		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.1942129264155108 | validation: 0.23238301306197115]
	TIME [epoch: 27.7 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19919173192705317		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.19919173192705317 | validation: 0.2012772038927783]
	TIME [epoch: 27.7 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18306503617555236		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.18306503617555236 | validation: 0.189432258105327]
	TIME [epoch: 27.7 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17059704804885512		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.17059704804885512 | validation: 0.17567908612249497]
	TIME [epoch: 27.7 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1718888407001964		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.1718888407001964 | validation: 0.18137020945033436]
	TIME [epoch: 27.7 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17986186735813733		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.17986186735813733 | validation: 0.18182485731128598]
	TIME [epoch: 27.7 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1779860043422533		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.1779860043422533 | validation: 0.1925203316274272]
	TIME [epoch: 27.7 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17884167656287325		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.17884167656287325 | validation: 0.1843891716980766]
	TIME [epoch: 27.7 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18644154329366536		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.18644154329366536 | validation: 0.1769739520758088]
	TIME [epoch: 27.7 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18059084873767525		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.18059084873767525 | validation: 0.18198434532525595]
	TIME [epoch: 27.7 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.177186960400919		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.177186960400919 | validation: 0.182681155860206]
	TIME [epoch: 27.7 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1800858318157665		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.1800858318157665 | validation: 0.18818950339938537]
	TIME [epoch: 27.7 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1799762204326346		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.1799762204326346 | validation: 0.19624931005111587]
	TIME [epoch: 27.7 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17785811217911707		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.17785811217911707 | validation: 0.17915909009930667]
	TIME [epoch: 27.8 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16965997032017874		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.16965997032017874 | validation: 0.19059140329449092]
	TIME [epoch: 27.7 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1836901294656309		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.1836901294656309 | validation: 0.19048911735482332]
	TIME [epoch: 27.7 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1790524622158377		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.1790524622158377 | validation: 0.18893014715578024]
	TIME [epoch: 27.7 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1762971848932013		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.1762971848932013 | validation: 0.18227200258345336]
	TIME [epoch: 27.7 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17653218520940217		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.17653218520940217 | validation: 0.19614054978422046]
	TIME [epoch: 27.7 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17936559279333897		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.17936559279333897 | validation: 0.18556776463113045]
	TIME [epoch: 27.7 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1728093432907465		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.1728093432907465 | validation: 0.18349457455083834]
	TIME [epoch: 27.7 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16839854901259022		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.16839854901259022 | validation: 0.18685335057594488]
	TIME [epoch: 27.7 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17016740634507152		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.17016740634507152 | validation: 0.1917962684464194]
	TIME [epoch: 27.7 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17352429367314998		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.17352429367314998 | validation: 0.17492653045783016]
	TIME [epoch: 27.7 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17567841217138258		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.17567841217138258 | validation: 0.18179217291393568]
	TIME [epoch: 27.7 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17472308715363277		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.17472308715363277 | validation: 0.17473180341882064]
	TIME [epoch: 27.7 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1732442816723273		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.1732442816723273 | validation: 0.17799458473365776]
	TIME [epoch: 27.7 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1707547038192485		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.1707547038192485 | validation: 0.18227361321317279]
	TIME [epoch: 27.7 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16820597612345492		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.16820597612345492 | validation: 0.19910312472204286]
	TIME [epoch: 27.7 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1791907726241641		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.1791907726241641 | validation: 0.20299327674836704]
	TIME [epoch: 27.7 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1783000863698847		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.1783000863698847 | validation: 0.20071789379517996]
	TIME [epoch: 27.7 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18318449060288738		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.18318449060288738 | validation: 0.19122340532510798]
	TIME [epoch: 27.7 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17569438024546746		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.17569438024546746 | validation: 0.18347502306557814]
	TIME [epoch: 27.7 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17552490821445577		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.17552490821445577 | validation: 0.20071711365683173]
	TIME [epoch: 27.7 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17823283298538214		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.17823283298538214 | validation: 0.19249391734744542]
	TIME [epoch: 27.7 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1747275533631128		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.1747275533631128 | validation: 0.1785693618915792]
	TIME [epoch: 27.7 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17593897155302723		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.17593897155302723 | validation: 0.18041533251255396]
	TIME [epoch: 27.7 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1686611231133831		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.1686611231133831 | validation: 0.18732467702798056]
	TIME [epoch: 27.7 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1760088979599691		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.1760088979599691 | validation: 0.18414938799399405]
	TIME [epoch: 27.7 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18252545227280212		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.18252545227280212 | validation: 0.1852606916517466]
	TIME [epoch: 27.7 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.169086907012879		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.169086907012879 | validation: 0.19878764732236637]
	TIME [epoch: 27.7 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17208154906615392		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.17208154906615392 | validation: 0.1886634726355194]
	TIME [epoch: 27.7 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1696808266905072		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.1696808266905072 | validation: 0.18139191422536377]
	TIME [epoch: 27.7 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17545203119249586		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.17545203119249586 | validation: 0.20237881256778525]
	TIME [epoch: 27.7 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18011607958997888		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.18011607958997888 | validation: 0.18735519820742055]
	TIME [epoch: 27.7 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16890169115289574		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.16890169115289574 | validation: 0.17930532941726854]
	TIME [epoch: 27.7 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17773497684084943		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.17773497684084943 | validation: 0.1746019332791436]
	TIME [epoch: 27.7 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17122016732388157		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.17122016732388157 | validation: 0.18250652977647328]
	TIME [epoch: 27.7 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16942293564759592		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.16942293564759592 | validation: 0.18621186124063865]
	TIME [epoch: 27.7 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17982091815590018		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.17982091815590018 | validation: 0.2006040606079707]
	TIME [epoch: 27.6 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18284997981891235		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.18284997981891235 | validation: 0.18399304020822602]
	TIME [epoch: 27.7 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17355737875239685		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.17355737875239685 | validation: 0.16995103222529082]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_1615.pth
	Model improved!!!
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.169357231141873		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.169357231141873 | validation: 0.16995374948849498]
	TIME [epoch: 27.7 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17062760451426087		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.17062760451426087 | validation: 0.19536079908343368]
	TIME [epoch: 27.7 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17314171904468706		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.17314171904468706 | validation: 0.18952197421870304]
	TIME [epoch: 27.7 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17379237547001478		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.17379237547001478 | validation: 0.20241501158369857]
	TIME [epoch: 27.7 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1896874699183647		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.1896874699183647 | validation: 0.19106886222579533]
	TIME [epoch: 27.7 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18595507798419134		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.18595507798419134 | validation: 0.19101734177604499]
	TIME [epoch: 27.6 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18177846231256314		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.18177846231256314 | validation: 0.17994290807323432]
	TIME [epoch: 27.7 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18191526430898763		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.18191526430898763 | validation: 0.1889089380044209]
	TIME [epoch: 27.7 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1842125623196512		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.1842125623196512 | validation: 0.19433771777843692]
	TIME [epoch: 27.7 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17901599451457567		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.17901599451457567 | validation: 0.18752299952086218]
	TIME [epoch: 27.7 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1829254008519448		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.1829254008519448 | validation: 0.1839053949135442]
	TIME [epoch: 27.7 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1849445025994369		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.1849445025994369 | validation: 0.18571925938806608]
	TIME [epoch: 27.6 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18087349300744787		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.18087349300744787 | validation: 0.1793070728734325]
	TIME [epoch: 27.7 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18042306111735423		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.18042306111735423 | validation: 0.17934699976423546]
	TIME [epoch: 27.7 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1944759242801994		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.1944759242801994 | validation: 0.1887487164309677]
	TIME [epoch: 27.7 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17946139117948492		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.17946139117948492 | validation: 0.18339125239702214]
	TIME [epoch: 27.7 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1759008220397545		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.1759008220397545 | validation: 0.18862653243614605]
	TIME [epoch: 27.7 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17671156622784082		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.17671156622784082 | validation: 0.1850540828057467]
	TIME [epoch: 27.7 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17922629457833078		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.17922629457833078 | validation: 0.17990025519986944]
	TIME [epoch: 27.7 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18297540636389664		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.18297540636389664 | validation: 0.18394807678531444]
	TIME [epoch: 27.7 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17549029006531142		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.17549029006531142 | validation: 0.18376891148572694]
	TIME [epoch: 27.7 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17472001855510166		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.17472001855510166 | validation: 0.18366628196941243]
	TIME [epoch: 27.7 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17620859699154476		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.17620859699154476 | validation: 0.19465285577613195]
	TIME [epoch: 27.6 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17944570681881322		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.17944570681881322 | validation: 0.1873049264558399]
	TIME [epoch: 27.7 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17840905060709444		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.17840905060709444 | validation: 0.1880582098385625]
	TIME [epoch: 27.7 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17265441514894275		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.17265441514894275 | validation: 0.1929171122162079]
	TIME [epoch: 27.6 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17542516168114042		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.17542516168114042 | validation: 0.19680096298459546]
	TIME [epoch: 27.7 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17335694107767957		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.17335694107767957 | validation: 0.18568428685361937]
	TIME [epoch: 27.7 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17934548288383592		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.17934548288383592 | validation: 0.1788633417262622]
	TIME [epoch: 27.7 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17300047729344992		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.17300047729344992 | validation: 0.19417481604252732]
	TIME [epoch: 27.7 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1712642279367148		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.1712642279367148 | validation: 0.18853757389148437]
	TIME [epoch: 27.7 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16949686878214676		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.16949686878214676 | validation: 0.1876323779670209]
	TIME [epoch: 27.6 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17316583786283082		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.17316583786283082 | validation: 0.19989280728705403]
	TIME [epoch: 27.7 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1762954318812042		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.1762954318812042 | validation: 0.2015303039562212]
	TIME [epoch: 27.7 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1780045595036146		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.1780045595036146 | validation: 0.19222127497316385]
	TIME [epoch: 27.6 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17320558641880734		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.17320558641880734 | validation: 0.19672314506854677]
	TIME [epoch: 27.7 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1726655771841773		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.1726655771841773 | validation: 0.19519725875244567]
	TIME [epoch: 27.7 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17177891380353438		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.17177891380353438 | validation: 0.19480579486132613]
	TIME [epoch: 27.7 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17252066674005184		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.17252066674005184 | validation: 0.18387778350945]
	TIME [epoch: 27.7 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16791128341586503		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.16791128341586503 | validation: 0.17816840931985678]
	TIME [epoch: 27.7 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17551201272845127		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.17551201272845127 | validation: 0.18296240863173943]
	TIME [epoch: 27.6 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17214385492511766		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.17214385492511766 | validation: 0.1861710098170984]
	TIME [epoch: 27.7 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17079258700032485		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.17079258700032485 | validation: 0.1761379409551109]
	TIME [epoch: 27.6 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17161130268628524		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.17161130268628524 | validation: 0.1855152052929043]
	TIME [epoch: 27.7 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17808843149528808		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.17808843149528808 | validation: 0.1718652567618662]
	TIME [epoch: 27.7 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17049510962896144		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.17049510962896144 | validation: 0.17575826583728585]
	TIME [epoch: 27.6 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1656592000362581		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.1656592000362581 | validation: 0.1744606641627243]
	TIME [epoch: 27.7 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1694365641493645		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.1694365641493645 | validation: 0.17084714578332388]
	TIME [epoch: 27.7 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17237380865881194		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.17237380865881194 | validation: 0.1976321364484823]
	TIME [epoch: 27.6 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17486716123732046		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.17486716123732046 | validation: 0.1915455056751037]
	TIME [epoch: 27.7 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17005892026319314		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.17005892026319314 | validation: 0.1875048901303719]
	TIME [epoch: 27.7 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17321121303965475		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.17321121303965475 | validation: 0.18672881947223707]
	TIME [epoch: 27.6 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16871787806814026		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.16871787806814026 | validation: 0.19109737714097047]
	TIME [epoch: 27.7 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1703908977163039		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.1703908977163039 | validation: 0.181044985124895]
	TIME [epoch: 27.7 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17291384413217978		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.17291384413217978 | validation: 0.17469220989155762]
	TIME [epoch: 27.7 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17157900565634138		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.17157900565634138 | validation: 0.18474998657618869]
	TIME [epoch: 27.7 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1716059979391157		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.1716059979391157 | validation: 0.1901945719899596]
	TIME [epoch: 27.7 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16962847737623427		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.16962847737623427 | validation: 0.1758695399930923]
	TIME [epoch: 27.7 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1677115872588836		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.1677115872588836 | validation: 0.17927485710027496]
	TIME [epoch: 27.8 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16970892663023646		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.16970892663023646 | validation: 0.17338435418524065]
	TIME [epoch: 27.6 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17291721490218886		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.17291721490218886 | validation: 0.18371508997589525]
	TIME [epoch: 27.8 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17158864523938244		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.17158864523938244 | validation: 0.1844705582955303]
	TIME [epoch: 27.6 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17325694777967424		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.17325694777967424 | validation: 0.18463492425538455]
	TIME [epoch: 27.7 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1734198400385139		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.1734198400385139 | validation: 0.19943961005985011]
	TIME [epoch: 27.7 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17514447165064456		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.17514447165064456 | validation: 0.18789140330791484]
	TIME [epoch: 27.8 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17264106481835856		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.17264106481835856 | validation: 0.1873060072699648]
	TIME [epoch: 27.6 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1737926654771627		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.1737926654771627 | validation: 0.1906657188323122]
	TIME [epoch: 27.8 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17710149546795556		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.17710149546795556 | validation: 0.20177012657069734]
	TIME [epoch: 27.7 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1733584166484466		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.1733584166484466 | validation: 0.19217097503157868]
	TIME [epoch: 27.7 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17606978471448156		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.17606978471448156 | validation: 0.18201186236612552]
	TIME [epoch: 27.8 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17644283291671375		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.17644283291671375 | validation: 0.18627480519917713]
	TIME [epoch: 27.7 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1744872831333646		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.1744872831333646 | validation: 0.19819688365039206]
	TIME [epoch: 27.7 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18207953359487605		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.18207953359487605 | validation: 0.19355647541894389]
	TIME [epoch: 27.8 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1770152679524442		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.1770152679524442 | validation: 0.19816501707859197]
	TIME [epoch: 27.8 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18756616134597032		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.18756616134597032 | validation: 0.20816180215452101]
	TIME [epoch: 27.7 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18459267030738374		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.18459267030738374 | validation: 0.20357800060084927]
	TIME [epoch: 27.7 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.186088270922036		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.186088270922036 | validation: 0.2004048092279732]
	TIME [epoch: 27.7 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1910011739180694		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.1910011739180694 | validation: 0.21142188448029198]
	TIME [epoch: 27.8 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19043741968170938		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.19043741968170938 | validation: 0.2141148774386401]
	TIME [epoch: 27.8 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18422773762571526		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.18422773762571526 | validation: 0.2015358777367325]
	TIME [epoch: 27.7 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1840361023378126		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.1840361023378126 | validation: 0.2041249872048667]
	TIME [epoch: 27.8 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17738626602938717		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.17738626602938717 | validation: 0.19364580257964772]
	TIME [epoch: 27.7 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1727754430881326		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.1727754430881326 | validation: 0.19814496787131325]
	TIME [epoch: 27.7 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17588684414075234		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.17588684414075234 | validation: 0.19586745988475027]
	TIME [epoch: 27.7 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17857968166220728		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.17857968166220728 | validation: 0.18383553835819363]
	TIME [epoch: 27.7 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1745457686009268		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.1745457686009268 | validation: 0.19202845161678792]
	TIME [epoch: 27.7 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17599030879015753		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.17599030879015753 | validation: 0.20215670820752324]
	TIME [epoch: 27.7 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18131168240201248		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.18131168240201248 | validation: 0.20351598957650452]
	TIME [epoch: 27.7 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18011405303039918		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.18011405303039918 | validation: 0.20259637600481537]
	TIME [epoch: 27.7 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1766899690730406		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.1766899690730406 | validation: 0.1978985493630085]
	TIME [epoch: 27.7 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1734390202153471		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.1734390202153471 | validation: 0.1952915876167278]
	TIME [epoch: 27.8 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1760688548932019		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.1760688548932019 | validation: 0.18960077041075893]
	TIME [epoch: 27.7 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17239692388703476		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.17239692388703476 | validation: 0.18960582637350526]
	TIME [epoch: 27.8 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17889707639945618		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.17889707639945618 | validation: 0.19021759766290308]
	TIME [epoch: 27.7 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1767591633073026		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.1767591633073026 | validation: 0.1848775412018606]
	TIME [epoch: 27.8 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1702259185372966		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.1702259185372966 | validation: 0.17991843415107867]
	TIME [epoch: 27.7 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16991873725990703		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.16991873725990703 | validation: 0.18454939473068213]
	TIME [epoch: 27.7 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17187048427652765		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.17187048427652765 | validation: 0.18789345830805754]
	TIME [epoch: 27.8 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17281692884951427		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.17281692884951427 | validation: 0.17242043303649152]
	TIME [epoch: 27.8 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17152382955542134		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.17152382955542134 | validation: 0.18244725277607823]
	TIME [epoch: 27.7 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1714554091712269		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.1714554091712269 | validation: 0.18737841928302415]
	TIME [epoch: 27.8 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17267477762663427		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.17267477762663427 | validation: 0.19586549794123792]
	TIME [epoch: 27.8 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17407415077508606		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.17407415077508606 | validation: 0.19454072499424527]
	TIME [epoch: 27.7 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17341394433670304		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.17341394433670304 | validation: 0.18925686681504394]
	TIME [epoch: 27.7 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1664573118311508		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.1664573118311508 | validation: 0.1849960800367954]
	TIME [epoch: 27.7 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1714823779143044		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.1714823779143044 | validation: 0.17860841733673916]
	TIME [epoch: 27.6 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16851099000940112		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.16851099000940112 | validation: 0.17455965081965719]
	TIME [epoch: 27.7 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16925724415128632		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.16925724415128632 | validation: 0.18021011096141834]
	TIME [epoch: 27.7 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17263889142595357		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.17263889142595357 | validation: 0.18164413743999291]
	TIME [epoch: 27.6 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16928632004693242		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.16928632004693242 | validation: 0.1848059850641596]
	TIME [epoch: 27.7 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16560979622101907		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.16560979622101907 | validation: 0.1872847993300914]
	TIME [epoch: 27.6 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.171093604751574		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.171093604751574 | validation: 0.1908400498296144]
	TIME [epoch: 27.7 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1728179740865035		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.1728179740865035 | validation: 0.1922079461121216]
	TIME [epoch: 27.7 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17111251937559668		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.17111251937559668 | validation: 0.19266686586479684]
	TIME [epoch: 27.6 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17653749611624045		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.17653749611624045 | validation: 0.20378006579823513]
	TIME [epoch: 27.7 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17646825061036767		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.17646825061036767 | validation: 0.19403171276136477]
	TIME [epoch: 27.7 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17409350395991757		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.17409350395991757 | validation: 0.18420314167395344]
	TIME [epoch: 27.7 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1726465020700306		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.1726465020700306 | validation: 0.18730525402024273]
	TIME [epoch: 27.7 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1696861189307787		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.1696861189307787 | validation: 0.18635721298430416]
	TIME [epoch: 27.7 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16790017249752867		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.16790017249752867 | validation: 0.19054244474235738]
	TIME [epoch: 27.7 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17293354569281127		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.17293354569281127 | validation: 0.18718595712149633]
	TIME [epoch: 27.7 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16558642441144197		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.16558642441144197 | validation: 0.18805186344602975]
	TIME [epoch: 27.7 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17121541369842197		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.17121541369842197 | validation: 0.18823621679379599]
	TIME [epoch: 27.6 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16915564583634884		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.16915564583634884 | validation: 0.18489319504933974]
	TIME [epoch: 27.6 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16722333382877763		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.16722333382877763 | validation: 0.17818372767474977]
	TIME [epoch: 27.6 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16707132772515884		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.16707132772515884 | validation: 0.19331524497967598]
	TIME [epoch: 27.6 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17073176641036428		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.17073176641036428 | validation: 0.18193004676504831]
	TIME [epoch: 27.7 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1645201565385356		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.1645201565385356 | validation: 0.18022333002041954]
	TIME [epoch: 27.7 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16699189130070483		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.16699189130070483 | validation: 0.16933025349214645]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_1744.pth
	Model improved!!!
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16597852306176086		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.16597852306176086 | validation: 0.18346012817974214]
	TIME [epoch: 27.6 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16428074553688826		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.16428074553688826 | validation: 0.18278177836003842]
	TIME [epoch: 27.7 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1652429065570162		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.1652429065570162 | validation: 0.18057791337415857]
	TIME [epoch: 27.6 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1706697864168933		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.1706697864168933 | validation: 0.1838623718145106]
	TIME [epoch: 27.7 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17137508904449072		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.17137508904449072 | validation: 0.1760773195367527]
	TIME [epoch: 27.6 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1658678798007314		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.1658678798007314 | validation: 0.17825433612632396]
	TIME [epoch: 27.7 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17182931543160312		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.17182931543160312 | validation: 0.17103725397989292]
	TIME [epoch: 27.7 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16459120564273888		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.16459120564273888 | validation: 0.18190316641492899]
	TIME [epoch: 27.6 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16517431338910357		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.16517431338910357 | validation: 0.16806536049207674]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_1753.pth
	Model improved!!!
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16711022323966074		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.16711022323966074 | validation: 0.1746835672215229]
	TIME [epoch: 27.7 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16927017675116443		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.16927017675116443 | validation: 0.18051819408623387]
	TIME [epoch: 27.6 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16687143001436985		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.16687143001436985 | validation: 0.18382106734159578]
	TIME [epoch: 27.7 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16408224567894517		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.16408224567894517 | validation: 0.18808660432706942]
	TIME [epoch: 27.7 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1681801300727661		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.1681801300727661 | validation: 0.1860768624049389]
	TIME [epoch: 27.7 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16944323502397368		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.16944323502397368 | validation: 0.18249847010177853]
	TIME [epoch: 27.7 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1689590803429236		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.1689590803429236 | validation: 0.19121949665838064]
	TIME [epoch: 27.7 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16490466088493633		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.16490466088493633 | validation: 0.17439881860325862]
	TIME [epoch: 27.7 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17183471187822444		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.17183471187822444 | validation: 0.18990133227520353]
	TIME [epoch: 27.7 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16965066272791685		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.16965066272791685 | validation: 0.18652353871150923]
	TIME [epoch: 27.7 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16771312608949826		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.16771312608949826 | validation: 0.17285088914847713]
	TIME [epoch: 27.7 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16953018625503147		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.16953018625503147 | validation: 0.1757901448733108]
	TIME [epoch: 27.7 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16355886911068784		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.16355886911068784 | validation: 0.1792764320585652]
	TIME [epoch: 27.6 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16499024583516875		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.16499024583516875 | validation: 0.17805825406412368]
	TIME [epoch: 27.7 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16952285783993465		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.16952285783993465 | validation: 0.1812441188303522]
	TIME [epoch: 27.7 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16814995431091204		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.16814995431091204 | validation: 0.18555305183404308]
	TIME [epoch: 27.7 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16405480261562713		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.16405480261562713 | validation: 0.19060643689064713]
	TIME [epoch: 27.8 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1669559364009523		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.1669559364009523 | validation: 0.18295652648043922]
	TIME [epoch: 27.8 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17327613168396655		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.17327613168396655 | validation: 0.17510093193565923]
	TIME [epoch: 27.7 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16937961790851358		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.16937961790851358 | validation: 0.18234897517283002]
	TIME [epoch: 27.7 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.165148663167317		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.165148663167317 | validation: 0.18178130207510923]
	TIME [epoch: 27.8 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16357655686404743		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.16357655686404743 | validation: 0.17371038420468124]
	TIME [epoch: 27.7 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16544856261089463		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.16544856261089463 | validation: 0.18180743797308802]
	TIME [epoch: 27.8 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16968597267588903		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.16968597267588903 | validation: 0.19442172688749218]
	TIME [epoch: 27.7 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1721301847615815		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.1721301847615815 | validation: 0.19715645290994205]
	TIME [epoch: 27.7 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1767655080170582		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.1767655080170582 | validation: 0.18926039019458066]
	TIME [epoch: 27.7 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17390337788926336		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.17390337788926336 | validation: 0.18561630923765854]
	TIME [epoch: 27.7 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1775030023858214		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.1775030023858214 | validation: 0.1795229297002353]
	TIME [epoch: 27.7 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1722221377874597		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.1722221377874597 | validation: 0.18626944387051786]
	TIME [epoch: 27.8 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17198985797098182		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.17198985797098182 | validation: 0.16839947080610082]
	TIME [epoch: 27.7 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16537268155262844		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.16537268155262844 | validation: 0.18189081259860865]
	TIME [epoch: 27.7 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16824040387623		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.16824040387623 | validation: 0.17144739384704077]
	TIME [epoch: 27.7 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1677946388574885		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.1677946388574885 | validation: 0.1798376240483678]
	TIME [epoch: 27.7 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1674754868024434		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.1674754868024434 | validation: 0.18083588728742506]
	TIME [epoch: 27.6 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16625037386430846		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.16625037386430846 | validation: 0.1897291126374712]
	TIME [epoch: 27.8 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17146256033442075		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.17146256033442075 | validation: 0.18638480637826946]
	TIME [epoch: 27.6 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16852689834908488		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.16852689834908488 | validation: 0.18702184269235445]
	TIME [epoch: 27.8 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1700834600520095		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.1700834600520095 | validation: 0.18126023561632337]
	TIME [epoch: 27.6 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1657666129539946		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.1657666129539946 | validation: 0.18357335814177966]
	TIME [epoch: 27.6 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17023639127742976		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.17023639127742976 | validation: 0.18287429852196646]
	TIME [epoch: 27.7 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1743997352622264		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.1743997352622264 | validation: 0.18556325385536654]
	TIME [epoch: 27.7 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16922076068090713		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.16922076068090713 | validation: 0.18359416018268032]
	TIME [epoch: 27.7 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17103295639371283		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.17103295639371283 | validation: 0.19743371731731543]
	TIME [epoch: 27.8 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17149083331475184		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.17149083331475184 | validation: 0.18846283906894434]
	TIME [epoch: 27.8 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16937397852307778		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.16937397852307778 | validation: 0.1801168631471078]
	TIME [epoch: 27.7 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17079666536867244		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.17079666536867244 | validation: 0.1809770697183692]
	TIME [epoch: 27.8 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17414170298713194		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.17414170298713194 | validation: 0.19137357150300582]
	TIME [epoch: 27.8 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16819202172644182		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.16819202172644182 | validation: 0.18124245223028787]
	TIME [epoch: 27.7 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16930231042274585		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.16930231042274585 | validation: 0.18470416472450965]
	TIME [epoch: 27.7 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16477798314559158		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.16477798314559158 | validation: 0.18288826271168496]
	TIME [epoch: 27.7 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16329523855678546		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.16329523855678546 | validation: 0.17885507645269605]
	TIME [epoch: 27.7 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16752827570243126		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.16752827570243126 | validation: 0.1815904607942219]
	TIME [epoch: 27.7 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1712023228863685		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.1712023228863685 | validation: 0.1810304453346454]
	TIME [epoch: 27.7 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16877525155693252		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.16877525155693252 | validation: 0.19146610088127478]
	TIME [epoch: 27.7 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16778349501676382		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.16778349501676382 | validation: 0.18975357185721842]
	TIME [epoch: 27.8 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17074797949985285		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.17074797949985285 | validation: 0.19396970669512087]
	TIME [epoch: 27.7 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17315347983872376		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.17315347983872376 | validation: 0.19219099064677395]
	TIME [epoch: 27.7 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17054367546897725		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.17054367546897725 | validation: 0.19149239199507015]
	TIME [epoch: 27.8 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17261735262925704		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.17261735262925704 | validation: 0.1862903991634429]
	TIME [epoch: 27.7 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1683159321562651		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.1683159321562651 | validation: 0.18996021604728833]
	TIME [epoch: 27.7 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1659980622612155		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.1659980622612155 | validation: 0.17967703489994333]
	TIME [epoch: 27.8 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16762439179000982		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.16762439179000982 | validation: 0.18097774834316588]
	TIME [epoch: 27.6 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1685277686048403		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.1685277686048403 | validation: 0.18984659109526342]
	TIME [epoch: 27.7 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16942897549133695		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.16942897549133695 | validation: 0.18445307342772935]
	TIME [epoch: 27.7 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16302327194485972		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.16302327194485972 | validation: 0.19173926645898406]
	TIME [epoch: 27.6 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16802533101285583		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.16802533101285583 | validation: 0.1844932290139007]
	TIME [epoch: 27.7 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1642668616832642		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.1642668616832642 | validation: 0.1783212602699141]
	TIME [epoch: 27.7 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16531108916876588		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.16531108916876588 | validation: 0.17885091202911396]
	TIME [epoch: 27.7 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16833535380861808		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.16833535380861808 | validation: 0.17791610559555623]
	TIME [epoch: 27.8 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16230907188287502		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.16230907188287502 | validation: 0.1805886336854179]
	TIME [epoch: 27.7 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1637153552102779		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.1637153552102779 | validation: 0.17949695523664422]
	TIME [epoch: 27.8 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16701455457841222		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.16701455457841222 | validation: 0.18375373247268129]
	TIME [epoch: 27.8 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1636152064031018		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.1636152064031018 | validation: 0.1773174167119405]
	TIME [epoch: 27.7 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16731529919610838		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.16731529919610838 | validation: 0.17871407891283583]
	TIME [epoch: 27.7 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1626599073218671		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.1626599073218671 | validation: 0.177623730861349]
	TIME [epoch: 27.7 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1645877506703966		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.1645877506703966 | validation: 0.17707948409149804]
	TIME [epoch: 27.6 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16551980336659977		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.16551980336659977 | validation: 0.17384488434831638]
	TIME [epoch: 27.7 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1655265150396937		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.1655265150396937 | validation: 0.17685737735366597]
	TIME [epoch: 27.7 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16230445271652966		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.16230445271652966 | validation: 0.18287084332752016]
	TIME [epoch: 27.6 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16528226774409766		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.16528226774409766 | validation: 0.17571325987831787]
	TIME [epoch: 27.7 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16315415320102722		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.16315415320102722 | validation: 0.17899083220442483]
	TIME [epoch: 27.7 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1657489303568988		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.1657489303568988 | validation: 0.18549019358197144]
	TIME [epoch: 27.6 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16532347107739673		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.16532347107739673 | validation: 0.18380219625995878]
	TIME [epoch: 27.7 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1676192714806859		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.1676192714806859 | validation: 0.1829521225290266]
	TIME [epoch: 27.7 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1637414484501728		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.1637414484501728 | validation: 0.18888589718082208]
	TIME [epoch: 27.6 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1626395114766102		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.1626395114766102 | validation: 0.1837490545745206]
	TIME [epoch: 27.7 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16672419508268513		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.16672419508268513 | validation: 0.18159970449292942]
	TIME [epoch: 27.6 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16920597996597025		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.16920597996597025 | validation: 0.17659928106095849]
	TIME [epoch: 27.6 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16755298006558042		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.16755298006558042 | validation: 0.18417569909723258]
	TIME [epoch: 27.7 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16174357600026137		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.16174357600026137 | validation: 0.18888175082931236]
	TIME [epoch: 27.6 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1646555735843766		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.1646555735843766 | validation: 0.17966696848079244]
	TIME [epoch: 27.7 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16761193871765168		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.16761193871765168 | validation: 0.18141621267381675]
	TIME [epoch: 27.7 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16713290364706695		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.16713290364706695 | validation: 0.1811760265235972]
	TIME [epoch: 27.6 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16296072991718202		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.16296072991718202 | validation: 0.16575431520953485]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_1847.pth
	Model improved!!!
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16743920971180176		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.16743920971180176 | validation: 0.18437908576906964]
	TIME [epoch: 27.7 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16833080558754804		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.16833080558754804 | validation: 0.18202709990554752]
	TIME [epoch: 27.5 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16539151574610328		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.16539151574610328 | validation: 0.17794242532946578]
	TIME [epoch: 27.6 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16583874900682208		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.16583874900682208 | validation: 0.17606597031268162]
	TIME [epoch: 27.7 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.164427340797507		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.164427340797507 | validation: 0.1881354637389029]
	TIME [epoch: 27.7 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16977845169382655		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.16977845169382655 | validation: 0.17677743678031516]
	TIME [epoch: 27.7 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1620026951463514		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.1620026951463514 | validation: 0.17855797857016995]
	TIME [epoch: 27.7 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1666412244311209		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.1666412244311209 | validation: 0.1742764718031654]
	TIME [epoch: 27.7 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16605342907828705		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.16605342907828705 | validation: 0.17265098604179394]
	TIME [epoch: 27.7 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1699736930951144		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.1699736930951144 | validation: 0.1649228412991992]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_1857.pth
	Model improved!!!
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1667123862183853		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.1667123862183853 | validation: 0.1713996218550799]
	TIME [epoch: 27.7 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16747389798768403		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.16747389798768403 | validation: 0.16549933153853746]
	TIME [epoch: 27.7 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16191600382889781		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.16191600382889781 | validation: 0.17920947144486682]
	TIME [epoch: 27.7 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16723449153039427		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.16723449153039427 | validation: 0.1745813228413257]
	TIME [epoch: 27.7 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16340977089992773		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.16340977089992773 | validation: 0.1761455661931302]
	TIME [epoch: 27.8 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16273872341994025		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.16273872341994025 | validation: 0.1818841791217747]
	TIME [epoch: 27.7 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16321839197717783		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.16321839197717783 | validation: 0.16949813743021852]
	TIME [epoch: 27.7 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1644533239278765		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.1644533239278765 | validation: 0.16262397570984774]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240424_132548/states/model_tr_study5_1865.pth
	Model improved!!!
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16481213308581216		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.16481213308581216 | validation: 0.17061651677048573]
	TIME [epoch: 27.6 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17206894503868575		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.17206894503868575 | validation: 0.17241097524506024]
	TIME [epoch: 27.7 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17225788689789162		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.17225788689789162 | validation: 0.17783552364398592]
	TIME [epoch: 27.7 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16846043879435876		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.16846043879435876 | validation: 0.17498331858347954]
	TIME [epoch: 27.6 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17053305660340828		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.17053305660340828 | validation: 0.17735121130199857]
	TIME [epoch: 27.6 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1662037387396279		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.1662037387396279 | validation: 0.1763685079294237]
	TIME [epoch: 27.7 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.162020721841515		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.162020721841515 | validation: 0.17739040653853694]
	TIME [epoch: 27.6 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16887526509617534		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.16887526509617534 | validation: 0.17095055861686112]
	TIME [epoch: 27.7 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16754519619474956		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.16754519619474956 | validation: 0.1725650011451404]
	TIME [epoch: 27.6 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16452407081210269		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.16452407081210269 | validation: 0.18632667752122908]
	TIME [epoch: 27.6 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16622684911138846		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.16622684911138846 | validation: 0.18380504283481153]
	TIME [epoch: 27.6 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16425196995010055		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.16425196995010055 | validation: 0.18216671486996178]
	TIME [epoch: 27.6 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1676206401322656		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.1676206401322656 | validation: 0.18482481586658484]
	TIME [epoch: 27.6 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1703357514203772		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.1703357514203772 | validation: 0.19538983981328645]
	TIME [epoch: 27.7 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1673396075799805		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.1673396075799805 | validation: 0.19202767856754932]
	TIME [epoch: 27.6 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16978383899993416		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.16978383899993416 | validation: 0.18914342404730633]
	TIME [epoch: 27.7 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16959281026535064		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.16959281026535064 | validation: 0.18651841511113193]
	TIME [epoch: 27.7 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16619585471672035		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.16619585471672035 | validation: 0.18329476419634563]
	TIME [epoch: 27.6 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16734976651725614		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.16734976651725614 | validation: 0.1852918990555544]
	TIME [epoch: 27.6 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16564982790505772		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.16564982790505772 | validation: 0.19301513790575972]
	TIME [epoch: 27.7 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16267908243113316		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.16267908243113316 | validation: 0.18287717199484413]
	TIME [epoch: 27.6 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1645021826745603		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.1645021826745603 | validation: 0.18972903536534347]
	TIME [epoch: 27.7 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1630531896934201		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.1630531896934201 | validation: 0.18110649391382436]
	TIME [epoch: 27.6 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1614192056144582		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.1614192056144582 | validation: 0.18495807000873496]
	TIME [epoch: 27.6 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16803356042239456		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.16803356042239456 | validation: 0.1937284311978336]
	TIME [epoch: 27.7 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16903640495509967		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.16903640495509967 | validation: 0.1802285725354998]
	TIME [epoch: 27.6 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.168731876602142		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.168731876602142 | validation: 0.18924745276834176]
	TIME [epoch: 27.6 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16921899698852777		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.16921899698852777 | validation: 0.18742720490040207]
	TIME [epoch: 27.7 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16549184891199567		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.16549184891199567 | validation: 0.18383716572000425]
	TIME [epoch: 27.6 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16135292713259758		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.16135292713259758 | validation: 0.18040711322595684]
	TIME [epoch: 27.6 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16109188274140754		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.16109188274140754 | validation: 0.18187901441080065]
	TIME [epoch: 27.7 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16722574418244593		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.16722574418244593 | validation: 0.17730168093263157]
	TIME [epoch: 27.6 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16280720256376988		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.16280720256376988 | validation: 0.1803791757589226]
	TIME [epoch: 27.6 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16566885349851884		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.16566885349851884 | validation: 0.17483239319336427]
	TIME [epoch: 27.7 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16730251336933907		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.16730251336933907 | validation: 0.17946892050415666]
	TIME [epoch: 27.6 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16325347801063886		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.16325347801063886 | validation: 0.17226094084723712]
	TIME [epoch: 27.7 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16818398496001016		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.16818398496001016 | validation: 0.17738309062525898]
	TIME [epoch: 27.7 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16513172450879113		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.16513172450879113 | validation: 0.17419703422267674]
	TIME [epoch: 27.7 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16885668121447966		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.16885668121447966 | validation: 0.17204735816741573]
	TIME [epoch: 27.7 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1684550565544247		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.1684550565544247 | validation: 0.17813658827757478]
	TIME [epoch: 27.7 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16392958471900856		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.16392958471900856 | validation: 0.1744039331385433]
	TIME [epoch: 27.6 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16390268577712858		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.16390268577712858 | validation: 0.1730976623295335]
	TIME [epoch: 27.7 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1627076310819973		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.1627076310819973 | validation: 0.17109502123229953]
	TIME [epoch: 27.7 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16626473391649282		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.16626473391649282 | validation: 0.18371915060845162]
	TIME [epoch: 27.7 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17029763141551335		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.17029763141551335 | validation: 0.17714917293850918]
	TIME [epoch: 27.7 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17044345165437239		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.17044345165437239 | validation: 0.17575829495923906]
	TIME [epoch: 27.7 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1659439029920483		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.1659439029920483 | validation: 0.17571725519121018]
	TIME [epoch: 27.7 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16370102726827532		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.16370102726827532 | validation: 0.18302017779272825]
	TIME [epoch: 27.7 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16400332296092773		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.16400332296092773 | validation: 0.17981266585174674]
	TIME [epoch: 27.7 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16386247207991705		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.16386247207991705 | validation: 0.17884377919845848]
	TIME [epoch: 27.7 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.164038582243033		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.164038582243033 | validation: 0.17294914044994308]
	TIME [epoch: 27.7 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16478049026424552		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.16478049026424552 | validation: 0.17602118912831746]
	TIME [epoch: 27.7 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16745383096333916		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.16745383096333916 | validation: 0.18165943570538162]
	TIME [epoch: 27.6 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16514537456334427		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.16514537456334427 | validation: 0.17807295734964185]
	TIME [epoch: 27.7 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15951614885311874		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.15951614885311874 | validation: 0.1773076752188905]
	TIME [epoch: 27.7 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16223502580186006		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.16223502580186006 | validation: 0.17681562465920828]
	TIME [epoch: 27.7 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16487981572874694		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.16487981572874694 | validation: 0.17534655299458807]
	TIME [epoch: 27.7 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1603921331341196		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.1603921331341196 | validation: 0.1751463923683499]
	TIME [epoch: 27.7 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16191956715296701		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.16191956715296701 | validation: 0.17711496733629153]
	TIME [epoch: 27.7 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16112302593193595		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.16112302593193595 | validation: 0.17640449241892822]
	TIME [epoch: 27.7 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16260041635869776		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.16260041635869776 | validation: 0.16752461702853436]
	TIME [epoch: 27.7 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.168231050604459		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.168231050604459 | validation: 0.1821111412167051]
	TIME [epoch: 27.7 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16320277710626147		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.16320277710626147 | validation: 0.1740640822964371]
	TIME [epoch: 27.7 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16112183859690432		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.16112183859690432 | validation: 0.1774226207311618]
	TIME [epoch: 27.7 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16333451721790393		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.16333451721790393 | validation: 0.1864115426941662]
	TIME [epoch: 27.7 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1632659350550587		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.1632659350550587 | validation: 0.18315060855335538]
	TIME [epoch: 27.7 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16518279244365092		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.16518279244365092 | validation: 0.17914969346628268]
	TIME [epoch: 27.7 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16157953696380079		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.16157953696380079 | validation: 0.18366940907406967]
	TIME [epoch: 27.8 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16582456709777169		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.16582456709777169 | validation: 0.1835443981041928]
	TIME [epoch: 27.7 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16291919195453866		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.16291919195453866 | validation: 0.1779494514580901]
	TIME [epoch: 27.7 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16774768985904787		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.16774768985904787 | validation: 0.17338004500956136]
	TIME [epoch: 27.7 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1643348126288437		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.1643348126288437 | validation: 0.18038400910635102]
	TIME [epoch: 27.7 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.162278077882426		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.162278077882426 | validation: 0.18022118680032634]
	TIME [epoch: 27.7 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16477282255577058		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.16477282255577058 | validation: 0.17632072681153405]
	TIME [epoch: 27.7 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16831592671023915		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.16831592671023915 | validation: 0.18521356121564192]
	TIME [epoch: 27.7 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.164859355424264		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.164859355424264 | validation: 0.18341315959627844]
	TIME [epoch: 27.7 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16637645920388006		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.16637645920388006 | validation: 0.17780779064593333]
	TIME [epoch: 27.7 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16748380342835636		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.16748380342835636 | validation: 0.17275437040185426]
	TIME [epoch: 27.7 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16585060198121818		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.16585060198121818 | validation: 0.17033779765610518]
	TIME [epoch: 27.7 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17038507881323403		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.17038507881323403 | validation: 0.17480737681615025]
	TIME [epoch: 27.7 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16451587119503236		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.16451587119503236 | validation: 0.17597323513553392]
	TIME [epoch: 27.7 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16620559179057642		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.16620559179057642 | validation: 0.1828246085670245]
	TIME [epoch: 27.7 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16829673800949288		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.16829673800949288 | validation: 0.1798101819196792]
	TIME [epoch: 27.8 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16743065309209654		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.16743065309209654 | validation: 0.17903644827051665]
	TIME [epoch: 27.7 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16393127039625965		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.16393127039625965 | validation: 0.17936220723542406]
	TIME [epoch: 27.7 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16589719558552815		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.16589719558552815 | validation: 0.17923851241877078]
	TIME [epoch: 27.7 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16450590770966889		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.16450590770966889 | validation: 0.1860326029425032]
	TIME [epoch: 27.6 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1648985995032342		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.1648985995032342 | validation: 0.18688304784289955]
	TIME [epoch: 27.7 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16582193890420965		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.16582193890420965 | validation: 0.1774763222426619]
	TIME [epoch: 27.6 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16643569359974425		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.16643569359974425 | validation: 0.18014042979649145]
	TIME [epoch: 27.6 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16126912750920727		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.16126912750920727 | validation: 0.1794836871808856]
	TIME [epoch: 27.7 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16438390327247726		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.16438390327247726 | validation: 0.17986382140050935]
	TIME [epoch: 27.7 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16252667732943435		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.16252667732943435 | validation: 0.17712305309176762]
	TIME [epoch: 27.6 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16403824811738377		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.16403824811738377 | validation: 0.17954407307643608]
	TIME [epoch: 27.7 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1592303581105252		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.1592303581105252 | validation: 0.17729951901425064]
	TIME [epoch: 27.6 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16662664177540232		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.16662664177540232 | validation: 0.17926974055567435]
	TIME [epoch: 27.7 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16396138301049498		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.16396138301049498 | validation: 0.18195300245151175]
	TIME [epoch: 27.6 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.162028482738124		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.162028482738124 | validation: 0.17690442431677522]
	TIME [epoch: 27.6 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16254999687055793		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.16254999687055793 | validation: 0.16971203541753282]
	TIME [epoch: 27.7 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16342875817478175		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.16342875817478175 | validation: 0.17374372679604033]
	TIME [epoch: 27.7 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1638806000723142		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.1638806000723142 | validation: 0.17131031277618117]
	TIME [epoch: 27.7 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16556486500825374		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.16556486500825374 | validation: 0.18224218640414996]
	TIME [epoch: 27.7 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16597302669517977		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.16597302669517977 | validation: 0.17438827176596175]
	TIME [epoch: 27.7 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16232233139112145		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.16232233139112145 | validation: 0.1789571606645503]
	TIME [epoch: 27.6 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16192958888349174		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.16192958888349174 | validation: 0.1783024703450318]
	TIME [epoch: 27.7 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16140087791217303		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.16140087791217303 | validation: 0.18736433228085125]
	TIME [epoch: 27.7 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1629463189930747		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.1629463189930747 | validation: 0.17285551469351046]
	TIME [epoch: 27.7 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16518985650635915		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.16518985650635915 | validation: 0.18456574008628426]
	TIME [epoch: 27.7 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16356712916044275		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.16356712916044275 | validation: 0.16642105789681746]
	TIME [epoch: 27.7 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16313199074665816		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.16313199074665816 | validation: 0.1785434282220131]
	TIME [epoch: 27.7 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15979307507043883		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.15979307507043883 | validation: 0.1707620357921271]
	TIME [epoch: 27.8 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1647275373160516		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.1647275373160516 | validation: 0.17583954903844237]
	TIME [epoch: 27.7 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1608023200983151		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.1608023200983151 | validation: 0.1754495334215345]
	TIME [epoch: 27.8 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16374726103656118		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.16374726103656118 | validation: 0.17499884732320267]
	TIME [epoch: 27.8 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16262058621513947		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.16262058621513947 | validation: 0.1752267309260012]
	TIME [epoch: 27.7 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16218133463165513		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.16218133463165513 | validation: 0.180825545928827]
	TIME [epoch: 27.8 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.165020718512085		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.165020718512085 | validation: 0.17437484118616567]
	TIME [epoch: 27.7 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1636736774370497		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.1636736774370497 | validation: 0.17717020654618013]
	TIME [epoch: 27.7 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16367611637713073		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.16367611637713073 | validation: 0.17700337966886562]
	TIME [epoch: 27.8 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16363423524174053		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.16363423524174053 | validation: 0.1828715327379846]
	TIME [epoch: 27.7 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1615778506340986		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.1615778506340986 | validation: 0.17973520399100312]
	TIME [epoch: 27.7 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16406775981267252		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.16406775981267252 | validation: 0.17222671643990375]
	TIME [epoch: 27.8 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16169980079640156		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.16169980079640156 | validation: 0.177403830263385]
	TIME [epoch: 27.8 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16732590074585357		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.16732590074585357 | validation: 0.17445814526815084]
	TIME [epoch: 27.7 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1623676457320451		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.1623676457320451 | validation: 0.17862060993921383]
	TIME [epoch: 27.7 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1630925368539715		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.1630925368539715 | validation: 0.18310895700407556]
	TIME [epoch: 27.7 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1574308651117068		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.1574308651117068 | validation: 0.17193314472479915]
	TIME [epoch: 27.7 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16191457743682994		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.16191457743682994 | validation: 0.17804504632717444]
	TIME [epoch: 27.7 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16570136036278843		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.16570136036278843 | validation: 0.17729154723611415]
	TIME [epoch: 27.7 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16439977238363035		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.16439977238363035 | validation: 0.1704229253545232]
	TIME [epoch: 27.6 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16335513083360523		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.16335513083360523 | validation: 0.1799576771641903]
	TIME [epoch: 27.7 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1654392345969764		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.1654392345969764 | validation: 0.1747832147556037]
	TIME [epoch: 27.6 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1669322995138041		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.1669322995138041 | validation: 0.17254493543201144]
	TIME [epoch: 27.6 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.165263452624767		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.165263452624767 | validation: 0.17970057648263477]
	TIME [epoch: 27.7 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16344025730635642		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.16344025730635642 | validation: 0.18502624613688462]
	TIME [epoch: 27.6 sec]
Finished training in 55525.790 seconds.
