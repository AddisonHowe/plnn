Args:
Namespace(name='model_tr_study5', outdir='out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5', training_data='data/transition_rate_studies/tr_study5/tr_study5_training/r5', validation_data='data/transition_rate_studies/tr_study5/tr_study5_validation/r5', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 316583511

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.594443584112145		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.594443584112145 | validation: 9.860125886602134]
	TIME [epoch: 102 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.65638689592044		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.65638689592044 | validation: 9.164762181327667]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.234258520864582		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.234258520864582 | validation: 8.615559510693473]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.740678372705863		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.740678372705863 | validation: 8.320094119741858]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.16015233789729		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.16015233789729 | validation: 7.687427956445016]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.599797461135322		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.599797461135322 | validation: 7.212623627677062]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.949805899426214		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.949805899426214 | validation: 6.673368410314825]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.536033135987026		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.536033135987026 | validation: 6.227283433806802]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.474154982463558		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.474154982463558 | validation: 6.5033413308562205]
	TIME [epoch: 27.9 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.349791180625549		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.349791180625549 | validation: 6.867391214171655]
	TIME [epoch: 27.9 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.2475403100829885		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.2475403100829885 | validation: 6.020049122653837]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.044395773974367		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.044395773974367 | validation: 6.033368643799167]
	TIME [epoch: 27.9 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.030161698246962		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.030161698246962 | validation: 5.961336479559666]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.983675226887334		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.983675226887334 | validation: 5.827461528210067]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.0465748513204804		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.0465748513204804 | validation: 6.050125527543221]
	TIME [epoch: 27.9 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.906958655374179		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.906958655374179 | validation: 5.889639202416172]
	TIME [epoch: 27.9 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.843167109484231		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.843167109484231 | validation: 7.810195141664792]
	TIME [epoch: 28 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.586800805263408		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.586800805263408 | validation: 5.874947998767189]
	TIME [epoch: 28 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.1232865691739535		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.1232865691739535 | validation: 6.319276373238933]
	TIME [epoch: 27.9 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.102747731763114		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.102747731763114 | validation: 5.86071535853001]
	TIME [epoch: 28 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.939222921141868		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.939222921141868 | validation: 5.806448236382636]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.940062976096725		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.940062976096725 | validation: 5.887125710922069]
	TIME [epoch: 27.9 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.872046156875441		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.872046156875441 | validation: 5.710003160799791]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8938079028254755		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.8938079028254755 | validation: 6.00710281076955]
	TIME [epoch: 27.9 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.852309482771714		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.852309482771714 | validation: 5.901464090770044]
	TIME [epoch: 28 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.861051704929903		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.861051704929903 | validation: 6.0757878243554355]
	TIME [epoch: 27.9 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.065745876971935		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.065745876971935 | validation: 5.86617911827279]
	TIME [epoch: 27.9 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.835267249472613		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.835267249472613 | validation: 5.690422288304214]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.822202972694562		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.822202972694562 | validation: 5.672049992158493]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.695880844994507		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.695880844994507 | validation: 5.582935156975471]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.716599827136719		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.716599827136719 | validation: 5.7307688690893315]
	TIME [epoch: 27.9 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.667652581525459		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.667652581525459 | validation: 5.827516693426276]
	TIME [epoch: 27.9 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.752700142740924		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.752700142740924 | validation: 5.780538849635361]
	TIME [epoch: 27.9 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.506800401044075		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.506800401044075 | validation: 5.352807125227781]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.451336664732439		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.451336664732439 | validation: 5.63345106733697]
	TIME [epoch: 28 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.620420890120199		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.620420890120199 | validation: 5.491707934575909]
	TIME [epoch: 27.9 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.890576916691877		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.890576916691877 | validation: 6.18702277249994]
	TIME [epoch: 27.9 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.834577425422523		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.834577425422523 | validation: 5.57147903625583]
	TIME [epoch: 27.9 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.34322937329016		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.34322937329016 | validation: 5.374708161718884]
	TIME [epoch: 27.9 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.230419531182182		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.230419531182182 | validation: 5.371674456029787]
	TIME [epoch: 27.9 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.165866867132815		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.165866867132815 | validation: 5.317905764866639]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.263690569443931		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.263690569443931 | validation: 5.164702201935371]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.082384203826358		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.082384203826358 | validation: 7.099153115662079]
	TIME [epoch: 27.9 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.665699349484841		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.665699349484841 | validation: 6.625951278171133]
	TIME [epoch: 27.8 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.876336913660769		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.876336913660769 | validation: 5.476064464243284]
	TIME [epoch: 27.9 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.199558751030879		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.199558751030879 | validation: 6.856398767110301]
	TIME [epoch: 27.9 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.348146766529688		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.348146766529688 | validation: 5.753510245619146]
	TIME [epoch: 27.9 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.123814349931104		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.123814349931104 | validation: 6.468909720141765]
	TIME [epoch: 27.9 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.388737299925554		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.388737299925554 | validation: 5.6195620771118024]
	TIME [epoch: 27.9 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.382499388964334		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.382499388964334 | validation: 5.3728711386717105]
	TIME [epoch: 27.9 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.234260009587093		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 5.234260009587093 | validation: 5.343936709652114]
	TIME [epoch: 27.9 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.22280887684916		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 5.22280887684916 | validation: 5.139597129173683]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.102187653766239		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 5.102187653766239 | validation: 5.128154170844157]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.202681382765265		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 5.202681382765265 | validation: 5.395648253329871]
	TIME [epoch: 27.9 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.979593626844361		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 4.979593626844361 | validation: 5.055721802816969]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.172623014945279		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 5.172623014945279 | validation: 5.1436387403383925]
	TIME [epoch: 27.9 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.0479536268983445		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 5.0479536268983445 | validation: 4.85612098928331]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.916337011848863		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 4.916337011848863 | validation: 4.76180292533522]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.940356333789346		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 4.940356333789346 | validation: 5.505499853135186]
	TIME [epoch: 27.9 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.122446656720095		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 5.122446656720095 | validation: 4.640832022100239]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.615689973507694		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 4.615689973507694 | validation: 4.497892656297037]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6516435410602845		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 4.6516435410602845 | validation: 4.557808519129457]
	TIME [epoch: 27.9 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.536525331101835		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 4.536525331101835 | validation: 5.113713570851785]
	TIME [epoch: 27.9 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.386345628434422		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 5.386345628434422 | validation: 5.532219447574575]
	TIME [epoch: 27.9 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6986814429711385		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 4.6986814429711385 | validation: 4.826444831552074]
	TIME [epoch: 27.9 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.5802389236892775		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 5.5802389236892775 | validation: 5.479027807981238]
	TIME [epoch: 27.9 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.058548240827999		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 5.058548240827999 | validation: 4.566068449787681]
	TIME [epoch: 27.9 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.910285150117522		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 4.910285150117522 | validation: 4.902513483707345]
	TIME [epoch: 27.9 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.623888955359563		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 4.623888955359563 | validation: 4.444818053890689]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.387906882992093		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 4.387906882992093 | validation: 4.32439882509059]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_70.pth
	Model improved!!!
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.836039387659743		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 4.836039387659743 | validation: 4.934866076386714]
	TIME [epoch: 27.9 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.713203803641178		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 4.713203803641178 | validation: 4.523661582902091]
	TIME [epoch: 27.8 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.209158105516326		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 4.209158105516326 | validation: 4.308472415195238]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.222689449804361		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 4.222689449804361 | validation: 4.475911751547849]
	TIME [epoch: 27.9 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.234117930067456		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 4.234117930067456 | validation: 4.234165344622072]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_75.pth
	Model improved!!!
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.029094424952148		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 4.029094424952148 | validation: 3.813374830883035]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.814247023504555		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 3.814247023504555 | validation: 3.784440744252561]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.520191154950172		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 4.520191154950172 | validation: 4.0851078670335434]
	TIME [epoch: 27.9 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9669106133887206		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 3.9669106133887206 | validation: 3.655836203951143]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.648469482851043		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 3.648469482851043 | validation: 3.776982630264397]
	TIME [epoch: 27.9 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.692540053830215		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 3.692540053830215 | validation: 5.01959958630225]
	TIME [epoch: 27.9 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.512755809837126		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 4.512755809837126 | validation: 4.709958287075704]
	TIME [epoch: 27.9 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9693387896969075		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 3.9693387896969075 | validation: 4.415052055016168]
	TIME [epoch: 27.9 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.838162736953428		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 3.838162736953428 | validation: 3.473994549986083]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_84.pth
	Model improved!!!
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.495693451317737		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 3.495693451317737 | validation: 4.0790224608389485]
	TIME [epoch: 27.8 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.595156834668826		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 3.595156834668826 | validation: 3.6011173649250208]
	TIME [epoch: 27.8 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8012308405628734		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 3.8012308405628734 | validation: 3.2402699443261715]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_87.pth
	Model improved!!!
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.237432232138334		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 3.237432232138334 | validation: 3.9492436079852484]
	TIME [epoch: 27.8 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3571455146751763		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 3.3571455146751763 | validation: 3.5229388674400774]
	TIME [epoch: 27.9 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1893994700400885		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 3.1893994700400885 | validation: 2.9913536673480103]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_90.pth
	Model improved!!!
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8607120508215953		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 2.8607120508215953 | validation: 2.739128090980714]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_91.pth
	Model improved!!!
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3668250059557816		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 3.3668250059557816 | validation: 3.237986537358166]
	TIME [epoch: 27.9 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3177239331051567		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 3.3177239331051567 | validation: 3.542259592448482]
	TIME [epoch: 27.9 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.366167481985199		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 3.366167481985199 | validation: 3.212064933477982]
	TIME [epoch: 27.9 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.933350659975668		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 2.933350659975668 | validation: 2.9352398383967433]
	TIME [epoch: 27.9 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.886725096802473		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 2.886725096802473 | validation: 2.584588150388505]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_96.pth
	Model improved!!!
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6923056160582934		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 2.6923056160582934 | validation: 3.185405358859555]
	TIME [epoch: 27.9 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7137026312443693		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 2.7137026312443693 | validation: 2.4476660791809257]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_98.pth
	Model improved!!!
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8259364749412534		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 2.8259364749412534 | validation: 2.5252985971764765]
	TIME [epoch: 27.9 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5159641983967975		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 2.5159641983967975 | validation: 2.3998451704055155]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_100.pth
	Model improved!!!
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2900908888901585		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 3.2900908888901585 | validation: 2.9687991538438796]
	TIME [epoch: 27.9 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.354113055577968		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 2.354113055577968 | validation: 2.2296116928855985]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_102.pth
	Model improved!!!
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1475468594765896		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 2.1475468594765896 | validation: 2.33735020305566]
	TIME [epoch: 27.9 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3536148681685596		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 2.3536148681685596 | validation: 2.700668458861102]
	TIME [epoch: 27.9 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.230854461586457		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 2.230854461586457 | validation: 2.5084983050950416]
	TIME [epoch: 28 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2161580632202176		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 2.2161580632202176 | validation: 2.5868102292425488]
	TIME [epoch: 28 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.285020398973887		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 2.285020398973887 | validation: 4.494760619695744]
	TIME [epoch: 28 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.178477264356869		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 3.178477264356869 | validation: 2.3922280090764962]
	TIME [epoch: 28 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2386853008228638		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 2.2386853008228638 | validation: 2.2153698640699493]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_109.pth
	Model improved!!!
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9463800370688444		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 1.9463800370688444 | validation: 2.210926283581069]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_110.pth
	Model improved!!!
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.962168015373829		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 1.962168015373829 | validation: 2.1643462428404705]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_111.pth
	Model improved!!!
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.358991221709064		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 2.358991221709064 | validation: 2.9808463001341625]
	TIME [epoch: 28 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3444606428717827		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 2.3444606428717827 | validation: 1.9910000512469646]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_113.pth
	Model improved!!!
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0770503483631453		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 2.0770503483631453 | validation: 2.0469644798004616]
	TIME [epoch: 28 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9636849032433		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 1.9636849032433 | validation: 2.4670426312108296]
	TIME [epoch: 28.1 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9459767342185046		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 1.9459767342185046 | validation: 1.9277752497469534]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_116.pth
	Model improved!!!
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.433145915086497		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 2.433145915086497 | validation: 3.832867841913117]
	TIME [epoch: 28 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8112085475657342		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 2.8112085475657342 | validation: 1.9473135862656217]
	TIME [epoch: 28 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.133400419845508		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 2.133400419845508 | validation: 2.407191678332564]
	TIME [epoch: 28 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0849739542549672		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 2.0849739542549672 | validation: 2.0206367575144957]
	TIME [epoch: 28 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3291393249059094		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 2.3291393249059094 | validation: 2.387906880340616]
	TIME [epoch: 28 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2402955349214464		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 2.2402955349214464 | validation: 2.793767080852855]
	TIME [epoch: 28 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.400924679212253		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 2.400924679212253 | validation: 2.5136209310533584]
	TIME [epoch: 28 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0089864880135053		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 2.0089864880135053 | validation: 1.91751756266815]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_124.pth
	Model improved!!!
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7869105441089448		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 1.7869105441089448 | validation: 1.8071431166223402]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_125.pth
	Model improved!!!
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3140648758271922		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 2.3140648758271922 | validation: 2.3601093016838313]
	TIME [epoch: 28 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.161912743037669		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 2.161912743037669 | validation: 2.6669366528444027]
	TIME [epoch: 28 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2396448471962036		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 2.2396448471962036 | validation: 2.1608714368538875]
	TIME [epoch: 28 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.911962278952229		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 1.911962278952229 | validation: 2.190241979824583]
	TIME [epoch: 28 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9704361976486613		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 1.9704361976486613 | validation: 2.195422289194736]
	TIME [epoch: 28 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7553215259223933		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 1.7553215259223933 | validation: 1.8566084824261742]
	TIME [epoch: 28 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8120130337082363		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 1.8120130337082363 | validation: 2.2045501058149837]
	TIME [epoch: 28 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9295146753076187		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 1.9295146753076187 | validation: 2.377064583954723]
	TIME [epoch: 28 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.971822935086411		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 1.971822935086411 | validation: 2.646428463628]
	TIME [epoch: 28 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3204356062870035		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 2.3204356062870035 | validation: 2.510591768287163]
	TIME [epoch: 28 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9969048238405112		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 1.9969048238405112 | validation: 2.332615327982367]
	TIME [epoch: 28 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1045832768406925		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 2.1045832768406925 | validation: 2.2187350537151547]
	TIME [epoch: 28 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0454597736219577		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 2.0454597736219577 | validation: 2.183173874471212]
	TIME [epoch: 28 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8873765310956752		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 1.8873765310956752 | validation: 2.061171532749625]
	TIME [epoch: 28 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8765982819231084		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 1.8765982819231084 | validation: 2.2239185191746254]
	TIME [epoch: 28 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8036763490438625		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 1.8036763490438625 | validation: 2.15128548246178]
	TIME [epoch: 28 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7932640217004847		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 1.7932640217004847 | validation: 1.812621081516064]
	TIME [epoch: 28 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7458283012534184		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 1.7458283012534184 | validation: 2.299633944051975]
	TIME [epoch: 28 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.090598343667896		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 2.090598343667896 | validation: 1.965481900499299]
	TIME [epoch: 28 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6801675467675858		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 1.6801675467675858 | validation: 1.7144090077080116]
	TIME [epoch: 28.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_145.pth
	Model improved!!!
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8217040592681981		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 1.8217040592681981 | validation: 1.8757558069517444]
	TIME [epoch: 28 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8439020925107048		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 1.8439020925107048 | validation: 2.2873231636122746]
	TIME [epoch: 28 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7994807702817126		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 1.7994807702817126 | validation: 1.5637113643382499]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_148.pth
	Model improved!!!
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5775241892750513		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 1.5775241892750513 | validation: 1.7416770695154418]
	TIME [epoch: 28 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7281767408387547		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 1.7281767408387547 | validation: 2.0768730219122022]
	TIME [epoch: 27.9 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.846924620775946		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 1.846924620775946 | validation: 1.582408804560988]
	TIME [epoch: 28 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.592848823690903		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 1.592848823690903 | validation: 1.6139586851443364]
	TIME [epoch: 27.9 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4967376707756461		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 1.4967376707756461 | validation: 3.044558346954129]
	TIME [epoch: 28 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4951820005107903		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 2.4951820005107903 | validation: 2.1187977912047034]
	TIME [epoch: 27.9 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8246933658311573		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 1.8246933658311573 | validation: 1.6172010750186234]
	TIME [epoch: 27.9 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4568935014259559		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 1.4568935014259559 | validation: 1.4631178578003097]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_156.pth
	Model improved!!!
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7842475063713092		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 1.7842475063713092 | validation: 2.129043878863613]
	TIME [epoch: 27.9 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8963522242503688		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 1.8963522242503688 | validation: 1.5408368295402948]
	TIME [epoch: 27.9 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5927843431406241		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 1.5927843431406241 | validation: 2.191046484603549]
	TIME [epoch: 28 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.010586998113498		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 2.010586998113498 | validation: 1.5509674830274571]
	TIME [epoch: 28 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6399898463797153		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 1.6399898463797153 | validation: 1.7326940731745861]
	TIME [epoch: 28 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.659232667703698		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 1.659232667703698 | validation: 1.6861188801109663]
	TIME [epoch: 28 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2028195712367813		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 2.2028195712367813 | validation: 1.4933159507780436]
	TIME [epoch: 28 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7063544585503956		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 1.7063544585503956 | validation: 2.00173629086333]
	TIME [epoch: 28 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.40180315570335		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 2.40180315570335 | validation: 3.120700973218309]
	TIME [epoch: 27.9 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1699514695395252		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 2.1699514695395252 | validation: 1.7147074952191685]
	TIME [epoch: 28 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5057087196710541		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 1.5057087196710541 | validation: 1.535655081434513]
	TIME [epoch: 28 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3836362862509854		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 1.3836362862509854 | validation: 1.9318977573588598]
	TIME [epoch: 28 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7650290994305167		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 1.7650290994305167 | validation: 2.311455553130876]
	TIME [epoch: 28 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8690699583955022		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 1.8690699583955022 | validation: 3.3066094593994455]
	TIME [epoch: 28 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.655539301586209		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 2.655539301586209 | validation: 1.830648934637519]
	TIME [epoch: 28 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6361150097098829		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 1.6361150097098829 | validation: 1.7146203200202574]
	TIME [epoch: 28 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7387764275339674		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 1.7387764275339674 | validation: 1.5013793712063552]
	TIME [epoch: 27.9 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1915375134367756		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 2.1915375134367756 | validation: 1.861504528987471]
	TIME [epoch: 27.9 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6187153417221056		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 1.6187153417221056 | validation: 1.633021944357024]
	TIME [epoch: 27.9 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6047977904270498		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 1.6047977904270498 | validation: 1.737565691896167]
	TIME [epoch: 28 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8435514034460194		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 1.8435514034460194 | validation: 1.6057709470432]
	TIME [epoch: 28 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5279429075654374		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 1.5279429075654374 | validation: 1.702414001944083]
	TIME [epoch: 28 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8307102653648633		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 2.8307102653648633 | validation: 1.8755770577567705]
	TIME [epoch: 28 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.848753110799286		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 1.848753110799286 | validation: 2.7920012762330964]
	TIME [epoch: 27.9 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1490716202816276		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 2.1490716202816276 | validation: 2.052799132694994]
	TIME [epoch: 28 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.123800298139559		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 2.123800298139559 | validation: 1.941550247540622]
	TIME [epoch: 27.9 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.469535547239456		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 2.469535547239456 | validation: 3.1387800527700285]
	TIME [epoch: 28 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.255227436946392		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 2.255227436946392 | validation: 1.8581907285958215]
	TIME [epoch: 27.9 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.010625590856371		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 2.010625590856371 | validation: 1.9152990309083362]
	TIME [epoch: 28 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5629466123799665		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 1.5629466123799665 | validation: 1.9968661250997308]
	TIME [epoch: 27.9 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5656984207906683		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 2.5656984207906683 | validation: 1.862569776349421]
	TIME [epoch: 27.9 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7320505863688138		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 1.7320505863688138 | validation: 1.6136578299689512]
	TIME [epoch: 28 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4790443539264115		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 1.4790443539264115 | validation: 1.648589541065178]
	TIME [epoch: 28 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5908289446547461		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 1.5908289446547461 | validation: 2.8495564088567735]
	TIME [epoch: 28 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.192890521513811		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 2.192890521513811 | validation: 2.2374645568835136]
	TIME [epoch: 28 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0777292743662823		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 2.0777292743662823 | validation: 1.9782231077819972]
	TIME [epoch: 28 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0780709168440747		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 2.0780709168440747 | validation: 6.417335203448721]
	TIME [epoch: 27.9 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8953400266790927		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 3.8953400266790927 | validation: 1.9085578757617265]
	TIME [epoch: 28 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7024154559912485		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 1.7024154559912485 | validation: 1.6832126100225466]
	TIME [epoch: 27.9 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9618820276258975		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 1.9618820276258975 | validation: 2.704052363961523]
	TIME [epoch: 28 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.967115660157804		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 1.967115660157804 | validation: 1.9508557631542311]
	TIME [epoch: 27.9 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9499340009387551		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 1.9499340009387551 | validation: 1.508526207275396]
	TIME [epoch: 28 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.049742568743504		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 2.049742568743504 | validation: 2.622089450751026]
	TIME [epoch: 28 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0957561827951294		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 2.0957561827951294 | validation: 1.6365510339193332]
	TIME [epoch: 28 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6001518722688706		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 1.6001518722688706 | validation: 1.8162087774747897]
	TIME [epoch: 28 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4546752298600718		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 1.4546752298600718 | validation: 1.761681699155386]
	TIME [epoch: 27.9 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5251209670127974		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 1.5251209670127974 | validation: 2.3375658630681677]
	TIME [epoch: 27.9 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7203875959893882		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 1.7203875959893882 | validation: 1.7646950938804298]
	TIME [epoch: 27.9 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4797391530557351		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 1.4797391530557351 | validation: 2.597892155378712]
	TIME [epoch: 27.9 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8944380723347212		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 1.8944380723347212 | validation: 2.2549932673583992]
	TIME [epoch: 27.9 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0635623530125144		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 2.0635623530125144 | validation: 1.545123869284215]
	TIME [epoch: 27.9 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0014939403903913		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 2.0014939403903913 | validation: 1.6901255458487032]
	TIME [epoch: 27.9 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8321192129966113		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 1.8321192129966113 | validation: 1.6431477028675199]
	TIME [epoch: 27.9 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.43212880815204		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 1.43212880815204 | validation: 1.432301776512199]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_210.pth
	Model improved!!!
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4381099682874776		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 1.4381099682874776 | validation: 1.5058676803389477]
	TIME [epoch: 28 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.962901316683142		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 1.962901316683142 | validation: 1.8665094074007096]
	TIME [epoch: 28 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.527433599135745		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 1.527433599135745 | validation: 1.3828758162232404]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_213.pth
	Model improved!!!
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2873383692590086		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 1.2873383692590086 | validation: 1.245366473156176]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_214.pth
	Model improved!!!
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3155358781638626		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 1.3155358781638626 | validation: 1.4704456739033693]
	TIME [epoch: 27.9 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.317471984585108		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 3.317471984585108 | validation: 5.201838086653206]
	TIME [epoch: 27.9 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.821773111222234		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 2.821773111222234 | validation: 1.368921897248046]
	TIME [epoch: 27.9 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8622073547896334		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 1.8622073547896334 | validation: 2.1622728495442547]
	TIME [epoch: 27.9 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.737841343037179		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 1.737841343037179 | validation: 1.4504472000690967]
	TIME [epoch: 28 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.391355151333462		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 1.391355151333462 | validation: 3.0182307929205456]
	TIME [epoch: 28 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0522789202344787		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 2.0522789202344787 | validation: 1.5046767829406127]
	TIME [epoch: 28 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8935816191552468		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 1.8935816191552468 | validation: 1.8640324388557958]
	TIME [epoch: 28 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5328526937205473		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 1.5328526937205473 | validation: 1.3227373343051414]
	TIME [epoch: 27.9 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4451598226834241		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 1.4451598226834241 | validation: 1.2638306692021744]
	TIME [epoch: 28 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2921882006351275		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 1.2921882006351275 | validation: 1.326385128809773]
	TIME [epoch: 28 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.419843873038787		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 1.419843873038787 | validation: 1.5069676261307319]
	TIME [epoch: 28 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2026578632120284		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 2.2026578632120284 | validation: 1.88441566924416]
	TIME [epoch: 28 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0820679000185223		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 2.0820679000185223 | validation: 1.754851949657642]
	TIME [epoch: 27.9 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.377488358158572		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 1.377488358158572 | validation: 1.5345371927173126]
	TIME [epoch: 28 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0546195897721087		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 2.0546195897721087 | validation: 2.42607745416222]
	TIME [epoch: 28 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0601494962221345		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 2.0601494962221345 | validation: 1.8296484556717025]
	TIME [epoch: 27.9 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4780922134252452		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 1.4780922134252452 | validation: 1.3233782329125634]
	TIME [epoch: 28 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3424004703301988		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 1.3424004703301988 | validation: 1.291484613718499]
	TIME [epoch: 27.9 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.165715486067589		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 1.165715486067589 | validation: 1.3330741899229537]
	TIME [epoch: 28 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2398492854956886		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 1.2398492854956886 | validation: 1.1326916633869395]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_235.pth
	Model improved!!!
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4539541750528635		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 1.4539541750528635 | validation: 4.294290400363211]
	TIME [epoch: 27.9 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.585934112446986		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 2.585934112446986 | validation: 1.3791214286060218]
	TIME [epoch: 28 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3565881569622587		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 1.3565881569622587 | validation: 1.777070922205856]
	TIME [epoch: 28 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2560387739521601		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 1.2560387739521601 | validation: 1.0469705469299906]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_239.pth
	Model improved!!!
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2067078597852896		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 1.2067078597852896 | validation: 2.123440993174756]
	TIME [epoch: 28 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.122619091870035		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 2.122619091870035 | validation: 1.9551459939144673]
	TIME [epoch: 27.9 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.76955337279029		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 1.76955337279029 | validation: 1.1914553341200251]
	TIME [epoch: 28 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1954320523562243		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 1.1954320523562243 | validation: 1.3788221817541515]
	TIME [epoch: 28 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8018464229995579		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 1.8018464229995579 | validation: 5.701861181964855]
	TIME [epoch: 27.9 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2236767657796244		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 3.2236767657796244 | validation: 1.4640137387896954]
	TIME [epoch: 27.9 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2011151530393989		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 1.2011151530393989 | validation: 1.2147336062166267]
	TIME [epoch: 27.9 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2195685802342724		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 1.2195685802342724 | validation: 3.1576218950571504]
	TIME [epoch: 28 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9769934567267207		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 1.9769934567267207 | validation: 2.009816437661517]
	TIME [epoch: 27.9 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5139721105078865		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 1.5139721105078865 | validation: 1.3224190766530322]
	TIME [epoch: 27.9 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2248977216560448		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 1.2248977216560448 | validation: 1.317980199858759]
	TIME [epoch: 28 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5351022546116369		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 1.5351022546116369 | validation: 1.6210606990349499]
	TIME [epoch: 27.9 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2812234966417577		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 1.2812234966417577 | validation: 1.2209026068382474]
	TIME [epoch: 28 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1802217449059946		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 1.1802217449059946 | validation: 1.3244021543918674]
	TIME [epoch: 28 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2893433307283109		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 1.2893433307283109 | validation: 1.1163318609854713]
	TIME [epoch: 28 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1194298190635796		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 1.1194298190635796 | validation: 1.1241263094874419]
	TIME [epoch: 28 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0603901610836877		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 1.0603901610836877 | validation: 1.4664592679914195]
	TIME [epoch: 27.9 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9339427614628404		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 1.9339427614628404 | validation: 3.29217044614025]
	TIME [epoch: 28 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8148041273221982		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 1.8148041273221982 | validation: 1.3908309040173805]
	TIME [epoch: 27.9 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2369108804186388		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 1.2369108804186388 | validation: 1.1934105865283133]
	TIME [epoch: 27.9 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1668360148928476		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 1.1668360148928476 | validation: 1.5361845992713328]
	TIME [epoch: 28 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3672510662181014		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 1.3672510662181014 | validation: 1.1210269591571103]
	TIME [epoch: 27.9 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1125028716687582		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 1.1125028716687582 | validation: 1.8625597131519698]
	TIME [epoch: 28 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7039902812916181		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 1.7039902812916181 | validation: 1.728593497132862]
	TIME [epoch: 27.9 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2271526877979735		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 1.2271526877979735 | validation: 1.655785110379836]
	TIME [epoch: 27.9 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4546212452356686		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 1.4546212452356686 | validation: 1.0729277270399624]
	TIME [epoch: 28 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4028119227772757		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 1.4028119227772757 | validation: 1.6418855377649422]
	TIME [epoch: 27.9 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4734710370763313		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 1.4734710370763313 | validation: 2.54181647898718]
	TIME [epoch: 27.9 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.74795068674633		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 1.74795068674633 | validation: 1.2669169522327637]
	TIME [epoch: 28 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1931895637179832		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 1.1931895637179832 | validation: 1.4696241627746525]
	TIME [epoch: 27.9 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1537640033741345		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 1.1537640033741345 | validation: 1.4192546519901073]
	TIME [epoch: 28 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.346627478877573		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 1.346627478877573 | validation: 1.0284083606850916]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_271.pth
	Model improved!!!
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.080201164605557		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 1.080201164605557 | validation: 1.131780418345449]
	TIME [epoch: 28 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.643314843565486		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 1.643314843565486 | validation: 2.150523074964097]
	TIME [epoch: 28 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.399458706797019		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 2.399458706797019 | validation: 1.422234640296741]
	TIME [epoch: 27.9 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3433531224553996		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 1.3433531224553996 | validation: 1.5827670170169925]
	TIME [epoch: 28 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5689462822276328		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 1.5689462822276328 | validation: 3.322552632042076]
	TIME [epoch: 27.9 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.263732808531354		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 2.263732808531354 | validation: 1.654932479659499]
	TIME [epoch: 27.9 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3786511462116526		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 1.3786511462116526 | validation: 1.2594153792316831]
	TIME [epoch: 28 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2495152711151665		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 1.2495152711151665 | validation: 1.1427433866266288]
	TIME [epoch: 27.9 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.271215743066724		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 1.271215743066724 | validation: 1.6497361888711868]
	TIME [epoch: 28 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3004552787989176		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 1.3004552787989176 | validation: 1.2603927253236937]
	TIME [epoch: 28 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1603582310486489		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 1.1603582310486489 | validation: 3.0771434960599686]
	TIME [epoch: 28 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.496100783846155		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 2.496100783846155 | validation: 1.6878553252828001]
	TIME [epoch: 28 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2689459696813195		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 1.2689459696813195 | validation: 1.3130338613203234]
	TIME [epoch: 28 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1926081808442694		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 1.1926081808442694 | validation: 1.0764982264201899]
	TIME [epoch: 28 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9974532090821453		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.9974532090821453 | validation: 0.9497128810552835]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_286.pth
	Model improved!!!
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0408855283569847		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 1.0408855283569847 | validation: 1.0407413259003921]
	TIME [epoch: 28 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.173515588044594		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 1.173515588044594 | validation: 1.729806067975219]
	TIME [epoch: 28 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0541005313413436		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 1.0541005313413436 | validation: 0.9444175564513653]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_289.pth
	Model improved!!!
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9456802575024631		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.9456802575024631 | validation: 1.1203491989364611]
	TIME [epoch: 28 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2086907425677687		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 1.2086907425677687 | validation: 2.0188185984095055]
	TIME [epoch: 28 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.314676258151986		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 1.314676258151986 | validation: 1.6395335276903678]
	TIME [epoch: 28 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9649643819995872		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 1.9649643819995872 | validation: 1.2127587747915773]
	TIME [epoch: 28 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.301428635290216		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 1.301428635290216 | validation: 1.1707244423965755]
	TIME [epoch: 28 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3127209454698097		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 1.3127209454698097 | validation: 1.454233482413413]
	TIME [epoch: 28 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2237165761013546		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 1.2237165761013546 | validation: 0.9098987975774451]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_296.pth
	Model improved!!!
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.898850803576133		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.898850803576133 | validation: 1.1073526122453174]
	TIME [epoch: 28 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0998097338843655		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 1.0998097338843655 | validation: 1.9985603652256203]
	TIME [epoch: 28 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4634992141783059		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 1.4634992141783059 | validation: 1.190633794972982]
	TIME [epoch: 28 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.138466988103712		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 1.138466988103712 | validation: 1.1414710273640225]
	TIME [epoch: 28 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1147258221466183		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 1.1147258221466183 | validation: 1.5958282016437104]
	TIME [epoch: 28 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0619629332766367		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 2.0619629332766367 | validation: 1.1880094599964737]
	TIME [epoch: 28 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0456639090799886		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 1.0456639090799886 | validation: 1.3206798087337899]
	TIME [epoch: 28 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9048294028416848		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 1.9048294028416848 | validation: 1.5923847077174431]
	TIME [epoch: 28 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0995246119981836		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 1.0995246119981836 | validation: 1.2103687931517504]
	TIME [epoch: 28 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.076455763017524		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 1.076455763017524 | validation: 1.0249621048520154]
	TIME [epoch: 28 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.957720292848689		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.957720292848689 | validation: 1.3490972076233079]
	TIME [epoch: 28 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2466824715291267		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 1.2466824715291267 | validation: 3.3905305419206715]
	TIME [epoch: 28 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.324149836914611		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 2.324149836914611 | validation: 1.3369320041122565]
	TIME [epoch: 28 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2870891896491439		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 1.2870891896491439 | validation: 1.1172420219940427]
	TIME [epoch: 28 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1449626067423888		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 1.1449626067423888 | validation: 1.2347247603719083]
	TIME [epoch: 28 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.180026752497788		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 1.180026752497788 | validation: 1.0438446344411587]
	TIME [epoch: 28 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7684235139545834		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 1.7684235139545834 | validation: 1.781355619548363]
	TIME [epoch: 28 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3575699429211368		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 1.3575699429211368 | validation: 1.2817498607168611]
	TIME [epoch: 28 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.201755621086609		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 1.201755621086609 | validation: 1.0633147657735895]
	TIME [epoch: 28 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9463229574225206		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.9463229574225206 | validation: 0.9500738097117238]
	TIME [epoch: 28 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2590924603834166		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 1.2590924603834166 | validation: 1.3393331416677503]
	TIME [epoch: 28 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2085566217095098		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 1.2085566217095098 | validation: 2.551776794255782]
	TIME [epoch: 28 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8300141897090474		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 1.8300141897090474 | validation: 1.3285363329550788]
	TIME [epoch: 28 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9430717559049029		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 1.9430717559049029 | validation: 2.299917889287025]
	TIME [epoch: 27.9 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4840188719160108		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 1.4840188719160108 | validation: 1.1644638155003149]
	TIME [epoch: 28 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0253000579907063		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 1.0253000579907063 | validation: 1.1411005901352238]
	TIME [epoch: 28 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.239902168610241		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 1.239902168610241 | validation: 1.096860080966821]
	TIME [epoch: 28 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1154218446844166		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 1.1154218446844166 | validation: 1.0562127255836304]
	TIME [epoch: 28 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9734411763582802		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.9734411763582802 | validation: 1.0843066204130598]
	TIME [epoch: 28 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.133994668991161		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 1.133994668991161 | validation: 1.0582803302593151]
	TIME [epoch: 28 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0597930181094752		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 1.0597930181094752 | validation: 0.9247924903691953]
	TIME [epoch: 28.1 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1992273319731481		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 1.1992273319731481 | validation: 1.4049787679274766]
	TIME [epoch: 28 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1148432873576724		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 1.1148432873576724 | validation: 1.1930171413067963]
	TIME [epoch: 28 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0869305808697305		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 1.0869305808697305 | validation: 1.1481093668891378]
	TIME [epoch: 28 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.009986244485241		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 1.009986244485241 | validation: 1.0603725632522096]
	TIME [epoch: 28 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0995556512195246		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 1.0995556512195246 | validation: 0.9666101667424707]
	TIME [epoch: 28 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.361008838145257		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 1.361008838145257 | validation: 2.098163004120013]
	TIME [epoch: 28 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5550533735248435		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 1.5550533735248435 | validation: 1.155134406512415]
	TIME [epoch: 28 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1172702128791565		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 1.1172702128791565 | validation: 0.9337802882740266]
	TIME [epoch: 28 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9666436136821106		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.9666436136821106 | validation: 1.1318177271539598]
	TIME [epoch: 28 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1693060865712086		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 1.1693060865712086 | validation: 1.1950076200140138]
	TIME [epoch: 28 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1362821423382727		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 1.1362821423382727 | validation: 1.0124680815282971]
	TIME [epoch: 28 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9920400200444025		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.9920400200444025 | validation: 1.0281572202007803]
	TIME [epoch: 28.1 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1523417110658327		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 1.1523417110658327 | validation: 1.6146713177858982]
	TIME [epoch: 28 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5247331709420642		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 1.5247331709420642 | validation: 1.3038517575946622]
	TIME [epoch: 28 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0248945488118923		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 1.0248945488118923 | validation: 1.0471145650338463]
	TIME [epoch: 28 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1113176958774589		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 1.1113176958774589 | validation: 1.0725212098731003]
	TIME [epoch: 28 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5252808744733937		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 1.5252808744733937 | validation: 1.0943363394656545]
	TIME [epoch: 28 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9212157916038592		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.9212157916038592 | validation: 0.966996986706873]
	TIME [epoch: 28 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9859710586344872		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.9859710586344872 | validation: 1.1604036308158339]
	TIME [epoch: 28 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0752778632484665		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 1.0752778632484665 | validation: 1.0791948081922607]
	TIME [epoch: 28 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3938929600764938		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 1.3938929600764938 | validation: 1.4845494001560797]
	TIME [epoch: 28 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2280968775170533		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 1.2280968775170533 | validation: 1.4120581512132548]
	TIME [epoch: 28 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3948073364562024		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 1.3948073364562024 | validation: 1.1056576873422737]
	TIME [epoch: 28 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.976007879964186		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.976007879964186 | validation: 1.0374949562105196]
	TIME [epoch: 28 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9718263472977018		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.9718263472977018 | validation: 0.8699584955992025]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_352.pth
	Model improved!!!
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7607433410379623		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.7607433410379623 | validation: 1.0076691936653956]
	TIME [epoch: 27.9 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0469056983461866		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 1.0469056983461866 | validation: 2.360106564226601]
	TIME [epoch: 28 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9013116764358606		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 1.9013116764358606 | validation: 1.0620881412861187]
	TIME [epoch: 28 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.360573122737335		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 1.360573122737335 | validation: 1.1326312305401134]
	TIME [epoch: 28 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9950008157989509		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.9950008157989509 | validation: 1.4631172615007786]
	TIME [epoch: 28.1 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.200247536135302		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 1.200247536135302 | validation: 1.1454349648003914]
	TIME [epoch: 28 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9565257329131476		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.9565257329131476 | validation: 1.525646617394233]
	TIME [epoch: 28.1 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4251535150918002		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 1.4251535150918002 | validation: 2.1283300607536773]
	TIME [epoch: 28 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5038833656276713		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 1.5038833656276713 | validation: 1.531407020502859]
	TIME [epoch: 27.9 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6093863788608809		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 1.6093863788608809 | validation: 2.0990953985878944]
	TIME [epoch: 28 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.272302495510083		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 1.272302495510083 | validation: 1.0582847232337125]
	TIME [epoch: 27.9 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9798922027933055		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.9798922027933055 | validation: 0.8752994629395262]
	TIME [epoch: 28 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9303624955627634		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.9303624955627634 | validation: 1.3124106467337506]
	TIME [epoch: 28 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6813644675353712		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 1.6813644675353712 | validation: 2.4513083650312764]
	TIME [epoch: 27.9 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6668556787734503		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 1.6668556787734503 | validation: 1.2979425706053942]
	TIME [epoch: 28 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3842731606323815		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 1.3842731606323815 | validation: 1.0475402173555028]
	TIME [epoch: 27.9 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9788633998499522		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.9788633998499522 | validation: 1.0356723033161128]
	TIME [epoch: 28 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0598830875233822		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 1.0598830875233822 | validation: 2.1884022604287185]
	TIME [epoch: 28 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3518533245327848		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 1.3518533245327848 | validation: 0.8000234337461322]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_371.pth
	Model improved!!!
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.970509555068642		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.970509555068642 | validation: 0.8586533731026275]
	TIME [epoch: 28 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0386635504591228		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 1.0386635504591228 | validation: 0.8537805086977427]
	TIME [epoch: 27.9 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9791775077472269		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.9791775077472269 | validation: 0.9795777956182713]
	TIME [epoch: 28 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.950627114157901		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.950627114157901 | validation: 0.9735972790233299]
	TIME [epoch: 28 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9238836685957849		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.9238836685957849 | validation: 1.605314896979753]
	TIME [epoch: 28 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.190343970531489		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 1.190343970531489 | validation: 0.9019207540127749]
	TIME [epoch: 28 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.357286333911834		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 1.357286333911834 | validation: 1.0523899006796442]
	TIME [epoch: 28 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9234884625654921		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.9234884625654921 | validation: 1.1869277670851792]
	TIME [epoch: 27.9 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.530013821282585		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 1.530013821282585 | validation: 1.41315814918055]
	TIME [epoch: 28 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4558017454600796		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 1.4558017454600796 | validation: 0.9268066134851194]
	TIME [epoch: 27.9 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8979792019415396		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.8979792019415396 | validation: 0.9039068388887606]
	TIME [epoch: 28 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1338123017697919		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 1.1338123017697919 | validation: 0.9588015249506897]
	TIME [epoch: 28 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9538848386627357		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.9538848386627357 | validation: 1.087381355508926]
	TIME [epoch: 28 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9136521736406886		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.9136521736406886 | validation: 1.4514483156978975]
	TIME [epoch: 28 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1905997603607705		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 1.1905997603607705 | validation: 0.9305362489969476]
	TIME [epoch: 28 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.468151608056346		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 1.468151608056346 | validation: 1.6565167246018797]
	TIME [epoch: 28 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3528558247542894		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 1.3528558247542894 | validation: 0.9857323665763212]
	TIME [epoch: 28 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9956593379823901		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.9956593379823901 | validation: 1.1541560122801975]
	TIME [epoch: 28 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2461880194088957		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 1.2461880194088957 | validation: 1.632860747176907]
	TIME [epoch: 28 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1643586765871123		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 1.1643586765871123 | validation: 1.0951419715594812]
	TIME [epoch: 27.9 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0355695833461904		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 1.0355695833461904 | validation: 1.0680790043625579]
	TIME [epoch: 28 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.912434591533276		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.912434591533276 | validation: 1.0279257689527033]
	TIME [epoch: 28 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3599555632412699		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 1.3599555632412699 | validation: 0.9818130508215643]
	TIME [epoch: 27.9 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9629872058066632		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.9629872058066632 | validation: 0.8875755464589367]
	TIME [epoch: 28 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7222829158911765		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 1.7222829158911765 | validation: 0.9231062467567727]
	TIME [epoch: 27.9 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9553191826747189		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.9553191826747189 | validation: 1.200997946750944]
	TIME [epoch: 27.9 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9420478118096265		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.9420478118096265 | validation: 1.173538454869223]
	TIME [epoch: 28 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.934909942742816		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.934909942742816 | validation: 0.9976355502928722]
	TIME [epoch: 28 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.984593709459693		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.984593709459693 | validation: 0.9448995487362999]
	TIME [epoch: 28 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0467150225974349		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 1.0467150225974349 | validation: 1.0710173835706713]
	TIME [epoch: 27.9 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9197016522473936		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.9197016522473936 | validation: 1.7905712808164964]
	TIME [epoch: 28 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.038187931748786		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 1.038187931748786 | validation: 0.9899376649665578]
	TIME [epoch: 28 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8067282676632034		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.8067282676632034 | validation: 0.9564810956811752]
	TIME [epoch: 28 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0425613477975944		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 1.0425613477975944 | validation: 0.8277636733471565]
	TIME [epoch: 28 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9477895888642116		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.9477895888642116 | validation: 1.0413396501303336]
	TIME [epoch: 27.9 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2493298933504153		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 1.2493298933504153 | validation: 1.8526738148386301]
	TIME [epoch: 28 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.140881636720916		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 1.140881636720916 | validation: 1.8213321156857183]
	TIME [epoch: 28 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1992275534305865		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 1.1992275534305865 | validation: 1.1687205222569272]
	TIME [epoch: 28 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9606216916408813		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.9606216916408813 | validation: 0.8240374736593326]
	TIME [epoch: 28 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7653680044199842		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.7653680044199842 | validation: 1.51842288639428]
	TIME [epoch: 28 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8509580863353743		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 1.8509580863353743 | validation: 0.9161569389011309]
	TIME [epoch: 28 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0684409058590996		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 1.0684409058590996 | validation: 1.6364171769915317]
	TIME [epoch: 28 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2257511051245065		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 1.2257511051245065 | validation: 1.2982228149963921]
	TIME [epoch: 27.9 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.935004485008522		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.935004485008522 | validation: 0.9146262880811733]
	TIME [epoch: 28.1 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8758515455302969		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.8758515455302969 | validation: 1.084230498363149]
	TIME [epoch: 28 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8517511737411111		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.8517511737411111 | validation: 1.1550118945773864]
	TIME [epoch: 28 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.031435250678058		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 1.031435250678058 | validation: 0.9059334212417376]
	TIME [epoch: 28 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.916216242811853		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.916216242811853 | validation: 0.9036352630576674]
	TIME [epoch: 27.9 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.019630192328081		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 1.019630192328081 | validation: 1.0408799681476049]
	TIME [epoch: 28 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.004940783145876		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 1.004940783145876 | validation: 0.9568681678205258]
	TIME [epoch: 28 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0108676269882388		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 1.0108676269882388 | validation: 0.8769166463029974]
	TIME [epoch: 28 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.001565201787946		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 1.001565201787946 | validation: 0.8524386197752817]
	TIME [epoch: 28 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8597164922854469		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.8597164922854469 | validation: 1.0140100574048097]
	TIME [epoch: 28 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.000610453999323		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 1.000610453999323 | validation: 0.8985976770943119]
	TIME [epoch: 28 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8813879062630476		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.8813879062630476 | validation: 1.1332140591727697]
	TIME [epoch: 28 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.212971196473939		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 1.212971196473939 | validation: 0.9632743566054347]
	TIME [epoch: 28 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8341645753531874		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.8341645753531874 | validation: 1.2156596407032092]
	TIME [epoch: 28 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0203754361796382		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 1.0203754361796382 | validation: 0.8948108034848725]
	TIME [epoch: 28 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0797381249922937		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 1.0797381249922937 | validation: 0.908171982516968]
	TIME [epoch: 28 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8499115906312624		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.8499115906312624 | validation: 2.801726915828202]
	TIME [epoch: 28 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9776967126969769		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 1.9776967126969769 | validation: 1.0972271292684348]
	TIME [epoch: 27.9 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0060468690561084		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 1.0060468690561084 | validation: 0.8158738140213717]
	TIME [epoch: 28 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7811218936969508		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.7811218936969508 | validation: 1.0101660391988188]
	TIME [epoch: 28 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8420121936934571		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.8420121936934571 | validation: 1.1461416936434015]
	TIME [epoch: 28 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0756766097636272		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 1.0756766097636272 | validation: 0.9633323914814923]
	TIME [epoch: 28 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8092047942037804		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.8092047942037804 | validation: 1.0369106431487396]
	TIME [epoch: 28 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8484557821421359		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.8484557821421359 | validation: 1.0494859649355213]
	TIME [epoch: 28 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9449022488200761		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.9449022488200761 | validation: 0.7918522365878958]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_439.pth
	Model improved!!!
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8385834979208862		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.8385834979208862 | validation: 0.9097203960836442]
	TIME [epoch: 27.9 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8112018008686552		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.8112018008686552 | validation: 0.8186664742712506]
	TIME [epoch: 27.9 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7959876299318636		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.7959876299318636 | validation: 1.1223038520516726]
	TIME [epoch: 27.9 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.795044097627843		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.795044097627843 | validation: 0.8349859945808311]
	TIME [epoch: 28 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6927904141079937		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.6927904141079937 | validation: 0.8786484266501705]
	TIME [epoch: 28 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9836071413004785		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.9836071413004785 | validation: 0.9105358845967351]
	TIME [epoch: 28 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7452669329220107		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.7452669329220107 | validation: 0.7666934598275734]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_446.pth
	Model improved!!!
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1031576635768519		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 1.1031576635768519 | validation: 1.5829000442816061]
	TIME [epoch: 28 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4734505078685824		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 1.4734505078685824 | validation: 1.3653227617297115]
	TIME [epoch: 28 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.070947844780454		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 1.070947844780454 | validation: 1.3314333120203907]
	TIME [epoch: 28 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0333881752194587		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 1.0333881752194587 | validation: 1.7122943666281083]
	TIME [epoch: 28 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3405810797667286		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 1.3405810797667286 | validation: 0.9027480614251236]
	TIME [epoch: 28 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9335606162510575		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.9335606162510575 | validation: 1.3712659195013652]
	TIME [epoch: 28 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1517346079646311		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 1.1517346079646311 | validation: 0.9818694706367146]
	TIME [epoch: 28 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8551275495745316		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.8551275495745316 | validation: 1.4285264350838371]
	TIME [epoch: 28 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2601628725473126		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 1.2601628725473126 | validation: 1.3271394116516262]
	TIME [epoch: 28 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.98133838714399		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.98133838714399 | validation: 0.9996419397427166]
	TIME [epoch: 28 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.938367897644212		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.938367897644212 | validation: 1.5049466342837194]
	TIME [epoch: 28 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9783155410076164		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.9783155410076164 | validation: 0.8933932033768689]
	TIME [epoch: 28 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7926290589133309		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.7926290589133309 | validation: 0.8975098205219407]
	TIME [epoch: 28 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7939880691347935		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.7939880691347935 | validation: 0.8965706713209349]
	TIME [epoch: 28 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8470116701953861		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.8470116701953861 | validation: 0.8287544520635686]
	TIME [epoch: 28 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7703260976825259		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.7703260976825259 | validation: 0.9308112889683369]
	TIME [epoch: 28 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8390214698805785		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.8390214698805785 | validation: 1.5568066470451738]
	TIME [epoch: 28 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1604392415138416		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 1.1604392415138416 | validation: 1.1039919530703421]
	TIME [epoch: 28 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7832885028321459		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.7832885028321459 | validation: 0.6674237707177457]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_465.pth
	Model improved!!!
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7563957538318513		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.7563957538318513 | validation: 1.0214253417425578]
	TIME [epoch: 28 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8203404223018479		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.8203404223018479 | validation: 0.7024837400429812]
	TIME [epoch: 28 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.735437630845767		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.735437630845767 | validation: 1.1100796881900694]
	TIME [epoch: 28 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8455976513620228		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.8455976513620228 | validation: 0.892999908471059]
	TIME [epoch: 28 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9252540021884252		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.9252540021884252 | validation: 1.0906706551361538]
	TIME [epoch: 28 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9648997383498606		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.9648997383498606 | validation: 0.8320272033384875]
	TIME [epoch: 28 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8884306752018911		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.8884306752018911 | validation: 1.081208112856263]
	TIME [epoch: 28 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8588811376026567		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.8588811376026567 | validation: 0.8894649903921754]
	TIME [epoch: 28 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7132166255493253		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.7132166255493253 | validation: 0.7659790131607855]
	TIME [epoch: 28 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6344907996212203		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.6344907996212203 | validation: 0.7951142224813612]
	TIME [epoch: 28 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.798411700523884		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.798411700523884 | validation: 0.947169952598063]
	TIME [epoch: 28 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0458880187122235		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 1.0458880187122235 | validation: 1.6085707032702907]
	TIME [epoch: 28 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8291675381158775		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.8291675381158775 | validation: 0.7309702570137118]
	TIME [epoch: 28 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.722177769432642		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.722177769432642 | validation: 1.076759269599538]
	TIME [epoch: 28 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9788903499777658		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.9788903499777658 | validation: 0.7784874104740024]
	TIME [epoch: 28 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8107134532781257		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.8107134532781257 | validation: 1.1291397703555068]
	TIME [epoch: 28 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0757546068273651		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 1.0757546068273651 | validation: 0.9838676446971059]
	TIME [epoch: 28 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9730810149887816		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.9730810149887816 | validation: 1.3194491643037178]
	TIME [epoch: 28 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8242921031468127		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.8242921031468127 | validation: 1.3360377745323337]
	TIME [epoch: 28 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0052170797877387		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 1.0052170797877387 | validation: 0.9932971409434508]
	TIME [epoch: 28 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7729672744216307		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.7729672744216307 | validation: 1.0307689842030323]
	TIME [epoch: 28 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8067075012318371		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.8067075012318371 | validation: 1.0579245674892928]
	TIME [epoch: 28 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9694381287327114		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.9694381287327114 | validation: 0.877364013540069]
	TIME [epoch: 28 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9643543495986951		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.9643543495986951 | validation: 0.8592213913005387]
	TIME [epoch: 28 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.763067792024353		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.763067792024353 | validation: 1.4369756884226008]
	TIME [epoch: 28 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8509787319431832		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.8509787319431832 | validation: 0.6605562766767628]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_491.pth
	Model improved!!!
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6660572333704545		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.6660572333704545 | validation: 0.9372793595069696]
	TIME [epoch: 28 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8547687896476297		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.8547687896476297 | validation: 0.7689442192528309]
	TIME [epoch: 28 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7481437574913445		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.7481437574913445 | validation: 0.6891757981774752]
	TIME [epoch: 28 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7076329589885946		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.7076329589885946 | validation: 0.7125656985088662]
	TIME [epoch: 28 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6481292934581738		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.6481292934581738 | validation: 0.7182617628585718]
	TIME [epoch: 28 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6673086112739689		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.6673086112739689 | validation: 0.7212662373948657]
	TIME [epoch: 28 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.814181890441072		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.814181890441072 | validation: 0.8175643193377923]
	TIME [epoch: 28 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7669849329097378		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.7669849329097378 | validation: 0.790980813352096]
	TIME [epoch: 28 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7494462599384095		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.7494462599384095 | validation: 0.6545240557622052]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_500.pth
	Model improved!!!
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9060946446876036		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.9060946446876036 | validation: 0.6136519105957925]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_501.pth
	Model improved!!!
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6737851555096294		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.6737851555096294 | validation: 0.9494038573028871]
	TIME [epoch: 28 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.749773668211456		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.749773668211456 | validation: 0.8594175719321507]
	TIME [epoch: 28 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6462474707775229		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.6462474707775229 | validation: 0.9557021803338259]
	TIME [epoch: 28 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8655465570311196		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.8655465570311196 | validation: 1.2607245589755245]
	TIME [epoch: 28 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.947366425876502		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.947366425876502 | validation: 0.6811245243946626]
	TIME [epoch: 27.9 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6915059235182064		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.6915059235182064 | validation: 0.793873307800233]
	TIME [epoch: 28 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8142656312846523		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.8142656312846523 | validation: 0.9919312151292716]
	TIME [epoch: 28 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.66002880732326		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.66002880732326 | validation: 0.6570732972546246]
	TIME [epoch: 28 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6275528648184585		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.6275528648184585 | validation: 1.0137580349029602]
	TIME [epoch: 28 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6645642888920338		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.6645642888920338 | validation: 0.6188103028238302]
	TIME [epoch: 28 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6941190515026898		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.6941190515026898 | validation: 0.9324354843771883]
	TIME [epoch: 28 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.837436205802559		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.837436205802559 | validation: 0.9867962970241878]
	TIME [epoch: 28 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8376352462381209		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.8376352462381209 | validation: 0.7937654537263792]
	TIME [epoch: 28 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0944931346041613		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 1.0944931346041613 | validation: 0.8006420605472231]
	TIME [epoch: 28 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0223896778340076		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 1.0223896778340076 | validation: 1.4322804766722734]
	TIME [epoch: 27.9 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.534804039686084		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 1.534804039686084 | validation: 1.1309846598239552]
	TIME [epoch: 28.1 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8829589716100511		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.8829589716100511 | validation: 0.6449727972283607]
	TIME [epoch: 28 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6886668211641533		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.6886668211641533 | validation: 0.8483740658300286]
	TIME [epoch: 28 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8865901030453093		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.8865901030453093 | validation: 1.6652018316085673]
	TIME [epoch: 28 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9264080171573301		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.9264080171573301 | validation: 0.8262345927503529]
	TIME [epoch: 28 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6937645471244043		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.6937645471244043 | validation: 1.053873687705671]
	TIME [epoch: 28 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8498506905904435		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.8498506905904435 | validation: 0.7087731311272125]
	TIME [epoch: 28 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.621915440725676		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.621915440725676 | validation: 1.180770688687823]
	TIME [epoch: 27.9 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8307984490374004		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.8307984490374004 | validation: 0.6312589764016846]
	TIME [epoch: 28 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7831993742813064		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.7831993742813064 | validation: 0.6469041824820019]
	TIME [epoch: 28 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5553930793827622		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.5553930793827622 | validation: 0.7199422639280617]
	TIME [epoch: 28 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7215080060530858		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.7215080060530858 | validation: 0.7632614554786801]
	TIME [epoch: 28 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6251818066457882		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.6251818066457882 | validation: 0.6457043855313337]
	TIME [epoch: 28 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6855725011487368		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.6855725011487368 | validation: 0.6538504142786039]
	TIME [epoch: 28 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6604198994756946		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.6604198994756946 | validation: 1.0241200036486036]
	TIME [epoch: 28 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7111799066775886		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.7111799066775886 | validation: 0.6775240379735096]
	TIME [epoch: 28.1 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8085494800711416		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.8085494800711416 | validation: 0.9212175759068721]
	TIME [epoch: 28 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8401048853274841		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.8401048853274841 | validation: 0.8666734452501852]
	TIME [epoch: 27.9 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5921080066902513		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.5921080066902513 | validation: 0.6663622111891445]
	TIME [epoch: 28 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6453437899767648		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.6453437899767648 | validation: 1.2838595285609555]
	TIME [epoch: 28 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.75887270067354		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.75887270067354 | validation: 0.7481697607627722]
	TIME [epoch: 28 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6699124930810022		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.6699124930810022 | validation: 0.637642017013835]
	TIME [epoch: 28 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6514876396990955		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.6514876396990955 | validation: 0.7267284234727158]
	TIME [epoch: 27.9 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7225260903248443		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.7225260903248443 | validation: 0.8264977972240811]
	TIME [epoch: 28 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9270723081852419		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.9270723081852419 | validation: 0.928651898911514]
	TIME [epoch: 28 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7119717462349854		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.7119717462349854 | validation: 0.7396524625659389]
	TIME [epoch: 28 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6074790567942006		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 1.6074790567942006 | validation: 1.6150367174695577]
	TIME [epoch: 28 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.870787201926893		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.870787201926893 | validation: 0.9640471803808182]
	TIME [epoch: 27.9 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6638364462046691		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.6638364462046691 | validation: 0.599311681625896]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_545.pth
	Model improved!!!
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5335652377607842		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.5335652377607842 | validation: 0.8210375759412765]
	TIME [epoch: 28 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9954118120997837		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.9954118120997837 | validation: 0.8523257893335862]
	TIME [epoch: 28 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7064362201688201		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.7064362201688201 | validation: 1.17588278633216]
	TIME [epoch: 28 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.276405740612184		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 1.276405740612184 | validation: 1.3946465594511477]
	TIME [epoch: 27.9 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.172206586869296		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 1.172206586869296 | validation: 1.2179426540872904]
	TIME [epoch: 28 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8796584820864533		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.8796584820864533 | validation: 0.939880316628396]
	TIME [epoch: 28 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7279201333324531		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.7279201333324531 | validation: 1.0976628014037413]
	TIME [epoch: 28 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9102110179544816		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.9102110179544816 | validation: 0.7627386737039298]
	TIME [epoch: 28 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7664302397805497		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.7664302397805497 | validation: 0.6878746141563044]
	TIME [epoch: 28 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6107657719729753		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.6107657719729753 | validation: 0.6774013755412485]
	TIME [epoch: 28 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9153178047453947		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.9153178047453947 | validation: 1.0526166080073707]
	TIME [epoch: 28 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7225011950377304		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.7225011950377304 | validation: 0.6706658205018172]
	TIME [epoch: 27.9 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.103761490290283		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 1.103761490290283 | validation: 0.7380180917542019]
	TIME [epoch: 28 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0134800770357808		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 1.0134800770357808 | validation: 1.2513913161499006]
	TIME [epoch: 28 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8609258439604879		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.8609258439604879 | validation: 0.6556815112682333]
	TIME [epoch: 28 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8131540438389636		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.8131540438389636 | validation: 1.2674230573416023]
	TIME [epoch: 28 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7487515907188773		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.7487515907188773 | validation: 0.730246964091046]
	TIME [epoch: 28 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7345866739669639		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.7345866739669639 | validation: 0.9987288253838047]
	TIME [epoch: 28 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8334569933478325		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.8334569933478325 | validation: 0.5484564308157036]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_564.pth
	Model improved!!!
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7467294950562735		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.7467294950562735 | validation: 0.6899103097687115]
	TIME [epoch: 28 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6113656393999036		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.6113656393999036 | validation: 0.5705957278206476]
	TIME [epoch: 28 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5506278131756859		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.5506278131756859 | validation: 0.5517179987511183]
	TIME [epoch: 28 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6132640897047735		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.6132640897047735 | validation: 0.8034150443815289]
	TIME [epoch: 28.1 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8910561449171779		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.8910561449171779 | validation: 0.9557276220691895]
	TIME [epoch: 28 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7532265815441763		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.7532265815441763 | validation: 0.7585239576399602]
	TIME [epoch: 28 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7676798838393004		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.7676798838393004 | validation: 1.0229446512330214]
	TIME [epoch: 28 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.69702655751602		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.69702655751602 | validation: 0.6020580539651469]
	TIME [epoch: 28 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5147440086530304		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.5147440086530304 | validation: 0.8799885612335424]
	TIME [epoch: 28 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.65347830953554		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.65347830953554 | validation: 1.1192430291458153]
	TIME [epoch: 28 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7029606611441109		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.7029606611441109 | validation: 0.7530802664990196]
	TIME [epoch: 28 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7568694317957247		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.7568694317957247 | validation: 0.7140108818432914]
	TIME [epoch: 28 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6147444738425484		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.6147444738425484 | validation: 0.6199545584824753]
	TIME [epoch: 28 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5410379659710906		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.5410379659710906 | validation: 0.7407631513413888]
	TIME [epoch: 28 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7840096688720846		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.7840096688720846 | validation: 0.6372015637445101]
	TIME [epoch: 28 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6056312094566498		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.6056312094566498 | validation: 0.59485927606262]
	TIME [epoch: 28 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5450600819684587		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.5450600819684587 | validation: 0.6273775190339322]
	TIME [epoch: 28.1 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6449044294855792		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.6449044294855792 | validation: 0.6545532795229737]
	TIME [epoch: 28 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6882633194342389		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.6882633194342389 | validation: 0.7020642120424404]
	TIME [epoch: 28.1 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5621743610352827		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.5621743610352827 | validation: 0.784797437919003]
	TIME [epoch: 28.1 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7508484026680721		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.7508484026680721 | validation: 0.8745974375321574]
	TIME [epoch: 27.9 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7319250235730017		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.7319250235730017 | validation: 1.4504301994121238]
	TIME [epoch: 28 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8858099472724145		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.8858099472724145 | validation: 0.7490510977579291]
	TIME [epoch: 28 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6033317320843992		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.6033317320843992 | validation: 0.945336571385646]
	TIME [epoch: 28 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6183366966909484		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.6183366966909484 | validation: 0.6835681700058478]
	TIME [epoch: 28 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8127940883058127		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.8127940883058127 | validation: 0.8031895608881462]
	TIME [epoch: 28 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8790708413665753		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.8790708413665753 | validation: 0.6653794732508669]
	TIME [epoch: 28 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6493421776241733		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.6493421776241733 | validation: 0.8470349985117196]
	TIME [epoch: 27.9 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6893646367003448		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.6893646367003448 | validation: 0.5748709712226664]
	TIME [epoch: 28 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6809434645607971		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.6809434645607971 | validation: 0.8587871917401144]
	TIME [epoch: 28 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7384870702639481		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.7384870702639481 | validation: 0.7304632722098939]
	TIME [epoch: 27.9 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.823066160142423		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.823066160142423 | validation: 1.3010180182152313]
	TIME [epoch: 28 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7165185325105012		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.7165185325105012 | validation: 0.5810866278425717]
	TIME [epoch: 28.1 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.555529002325911		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.555529002325911 | validation: 0.5541460185312935]
	TIME [epoch: 28 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4830978441673288		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.4830978441673288 | validation: 0.7777324245450555]
	TIME [epoch: 28.1 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6215036421224654		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.6215036421224654 | validation: 0.5242336775231462]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_600.pth
	Model improved!!!
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4569174165572878		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.4569174165572878 | validation: 0.6142048808199728]
	TIME [epoch: 28 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5526961374212069		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.5526961374212069 | validation: 0.5797489965263585]
	TIME [epoch: 28 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6090302893889867		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.6090302893889867 | validation: 2.283471211798364]
	TIME [epoch: 28 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.280755143214739		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 1.280755143214739 | validation: 0.572630795262272]
	TIME [epoch: 28 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6604617476390491		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.6604617476390491 | validation: 0.5508638955619207]
	TIME [epoch: 28 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6889688779055714		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.6889688779055714 | validation: 0.8532186618620822]
	TIME [epoch: 28 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6276426722748774		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.6276426722748774 | validation: 0.6779502657647316]
	TIME [epoch: 28 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.519111300775596		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.519111300775596 | validation: 0.84427625145506]
	TIME [epoch: 28 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7533590953224231		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.7533590953224231 | validation: 1.0229997129197057]
	TIME [epoch: 28.1 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6673658816272097		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.6673658816272097 | validation: 0.525194989199898]
	TIME [epoch: 28 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6647144098165121		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.6647144098165121 | validation: 0.656931237207075]
	TIME [epoch: 28 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5150560954216117		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.5150560954216117 | validation: 0.680932048835951]
	TIME [epoch: 28 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5709393366418122		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.5709393366418122 | validation: 0.597344047995055]
	TIME [epoch: 28 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.674937288857039		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.674937288857039 | validation: 0.7369921480192209]
	TIME [epoch: 28 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5900364220018386		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.5900364220018386 | validation: 0.5090562119711819]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_615.pth
	Model improved!!!
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5486544917642027		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.5486544917642027 | validation: 0.5579527977071403]
	TIME [epoch: 28 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6755134151198788		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.6755134151198788 | validation: 0.8301126836149891]
	TIME [epoch: 28.1 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6127666406452726		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.6127666406452726 | validation: 0.47091173710277945]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_618.pth
	Model improved!!!
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.512431079313659		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.512431079313659 | validation: 0.4730068244803479]
	TIME [epoch: 28.3 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5242200180405514		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.5242200180405514 | validation: 0.8555596630214217]
	TIME [epoch: 28.1 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6108422729954502		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.6108422729954502 | validation: 0.673196593057311]
	TIME [epoch: 28.1 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6224860083375069		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.6224860083375069 | validation: 1.7189935922364794]
	TIME [epoch: 28.1 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.140723913868933		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 1.140723913868933 | validation: 0.6868574628239725]
	TIME [epoch: 28.1 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.652313503475809		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.652313503475809 | validation: 0.8485198225009587]
	TIME [epoch: 28.1 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6095005473508562		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.6095005473508562 | validation: 0.6634410053571094]
	TIME [epoch: 28.1 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.621357343610613		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.621357343610613 | validation: 0.5647257012557759]
	TIME [epoch: 28 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5169258533200533		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.5169258533200533 | validation: 0.5425652018455065]
	TIME [epoch: 28.1 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5258108195613784		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.5258108195613784 | validation: 0.6298700404300404]
	TIME [epoch: 28 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6015710653985185		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.6015710653985185 | validation: 0.5519217683474223]
	TIME [epoch: 28.1 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5246938179446097		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.5246938179446097 | validation: 0.7654987325858281]
	TIME [epoch: 28.1 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6977870499725229		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.6977870499725229 | validation: 0.7939868042211586]
	TIME [epoch: 28 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6265243068614963		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.6265243068614963 | validation: 0.784341160886205]
	TIME [epoch: 28.1 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6235226068045926		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.6235226068045926 | validation: 0.661534008982666]
	TIME [epoch: 28.1 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.727870402690712		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.727870402690712 | validation: 0.71372558816002]
	TIME [epoch: 28.1 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.593666681147569		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.593666681147569 | validation: 0.5139701062687589]
	TIME [epoch: 28.1 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5874224999762708		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.5874224999762708 | validation: 0.509105923601206]
	TIME [epoch: 28.1 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6444555832853825		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.6444555832853825 | validation: 0.9121179827935535]
	TIME [epoch: 28.1 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.553375553763398		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.553375553763398 | validation: 0.5918640709499472]
	TIME [epoch: 28.1 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4999161285255417		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.4999161285255417 | validation: 0.8966525017025947]
	TIME [epoch: 28.1 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7407650634852263		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.7407650634852263 | validation: 0.4686261642666137]
	TIME [epoch: 28.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_640.pth
	Model improved!!!
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5660336844284575		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.5660336844284575 | validation: 0.7437868422518664]
	TIME [epoch: 28 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5938848212793482		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.5938848212793482 | validation: 0.8365194208329823]
	TIME [epoch: 28.1 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6374052689591355		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.6374052689591355 | validation: 1.1398880693905393]
	TIME [epoch: 28 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8867677625588614		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.8867677625588614 | validation: 1.7003578344646435]
	TIME [epoch: 28 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1632135305205527		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 1.1632135305205527 | validation: 0.5732476062054127]
	TIME [epoch: 28 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4583017926207614		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.4583017926207614 | validation: 0.6204614053291851]
	TIME [epoch: 28 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6714682359394487		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.6714682359394487 | validation: 0.7767135634943374]
	TIME [epoch: 28.1 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6207189371199024		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.6207189371199024 | validation: 0.60919948535096]
	TIME [epoch: 28.1 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.555713080877371		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.555713080877371 | validation: 0.48247594350637796]
	TIME [epoch: 28 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44300851669863633		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.44300851669863633 | validation: 0.8115684643320284]
	TIME [epoch: 28.1 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.565432640295507		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.565432640295507 | validation: 0.5761476552143705]
	TIME [epoch: 28.1 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5981501192140499		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.5981501192140499 | validation: 0.5032305011197912]
	TIME [epoch: 28.1 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4446518064504721		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.4446518064504721 | validation: 0.6077393030070536]
	TIME [epoch: 28.1 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5647901759016233		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.5647901759016233 | validation: 0.6977871593074698]
	TIME [epoch: 28 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5171729899522988		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.5171729899522988 | validation: 0.6100596020289268]
	TIME [epoch: 28.1 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5405684279224393		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.5405684279224393 | validation: 0.5125043267895513]
	TIME [epoch: 28 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5096822464318421		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.5096822464318421 | validation: 0.5441004169484022]
	TIME [epoch: 28.1 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5201537362178117		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.5201537362178117 | validation: 0.5813929661714257]
	TIME [epoch: 28.1 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45919863473860456		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.45919863473860456 | validation: 0.6269340525942427]
	TIME [epoch: 28 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5028783674759411		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.5028783674759411 | validation: 0.7753258566765945]
	TIME [epoch: 28.1 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5973262286339701		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.5973262286339701 | validation: 0.7588823468180464]
	TIME [epoch: 28.1 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5822395831880729		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.5822395831880729 | validation: 0.5045826685521008]
	TIME [epoch: 28 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5143950519872023		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.5143950519872023 | validation: 0.7564805574238819]
	TIME [epoch: 28.1 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8319092739028945		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.8319092739028945 | validation: 0.668578496360305]
	TIME [epoch: 28 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5590030722774398		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.5590030722774398 | validation: 0.6645187671586338]
	TIME [epoch: 28.1 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6671937967960229		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.6671937967960229 | validation: 0.6153618183472185]
	TIME [epoch: 28 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4827682981219601		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.4827682981219601 | validation: 0.5695662487760634]
	TIME [epoch: 28 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46944234082073505		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.46944234082073505 | validation: 0.6149943691611374]
	TIME [epoch: 28 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41370212807360635		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.41370212807360635 | validation: 0.5440791793538721]
	TIME [epoch: 28 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44898291510692256		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.44898291510692256 | validation: 0.6572350555929041]
	TIME [epoch: 28 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5962280074795031		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.5962280074795031 | validation: 0.9289833172018558]
	TIME [epoch: 28.1 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.625096159671633		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.625096159671633 | validation: 0.635968004459885]
	TIME [epoch: 28 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.515733162783218		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.515733162783218 | validation: 0.5749037481281535]
	TIME [epoch: 28.1 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6258031126504493		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.6258031126504493 | validation: 0.6311076509700174]
	TIME [epoch: 28 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5027445769431822		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.5027445769431822 | validation: 0.6041786630558502]
	TIME [epoch: 28.1 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6280330377263554		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.6280330377263554 | validation: 0.6523619720087561]
	TIME [epoch: 28 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49103800253433416		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.49103800253433416 | validation: 0.5231666454258614]
	TIME [epoch: 28 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5459333812078587		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.5459333812078587 | validation: 0.5398108708238955]
	TIME [epoch: 28 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48696645661025384		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.48696645661025384 | validation: 0.5960698416220229]
	TIME [epoch: 28 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4888187800345394		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.4888187800345394 | validation: 0.4634980184579635]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_680.pth
	Model improved!!!
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4246463786917849		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.4246463786917849 | validation: 0.9736348471433819]
	TIME [epoch: 28 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6813059233898014		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.6813059233898014 | validation: 0.5415255626635456]
	TIME [epoch: 28 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4645555845983846		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.4645555845983846 | validation: 0.4899857000207572]
	TIME [epoch: 28 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48052336230494064		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.48052336230494064 | validation: 0.5379501102944572]
	TIME [epoch: 28 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40409803681095324		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.40409803681095324 | validation: 0.5938943126819242]
	TIME [epoch: 28 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49236988309340884		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.49236988309340884 | validation: 0.4516679360372183]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_686.pth
	Model improved!!!
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45025243577535795		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.45025243577535795 | validation: 1.11291499259018]
	TIME [epoch: 28 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6370433837817052		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.6370433837817052 | validation: 0.47051165734977946]
	TIME [epoch: 28 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5500448435968698		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.5500448435968698 | validation: 0.7719248357451098]
	TIME [epoch: 28 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5077888750022268		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.5077888750022268 | validation: 0.47539878677794745]
	TIME [epoch: 28 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3920480032243948		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.3920480032243948 | validation: 0.5672866867069886]
	TIME [epoch: 28 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5505672634355779		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.5505672634355779 | validation: 0.5086620749474076]
	TIME [epoch: 28 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5288589328214681		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.5288589328214681 | validation: 0.5160954113531673]
	TIME [epoch: 28 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6299296375438155		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.6299296375438155 | validation: 0.535308771403863]
	TIME [epoch: 28 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6069496456084934		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.6069496456084934 | validation: 0.47460136111310613]
	TIME [epoch: 28 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5132676586406966		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.5132676586406966 | validation: 0.8670963811713434]
	TIME [epoch: 28 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4969841666638459		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.4969841666638459 | validation: 0.4188534767987341]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_697.pth
	Model improved!!!
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5113840329317767		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.5113840329317767 | validation: 0.6550549261380593]
	TIME [epoch: 27.9 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48779793168335095		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.48779793168335095 | validation: 0.5520412500810286]
	TIME [epoch: 27.9 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.453324758101171		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.453324758101171 | validation: 0.5000364326507364]
	TIME [epoch: 27.9 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4430083886068369		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.4430083886068369 | validation: 0.7987844305181835]
	TIME [epoch: 28 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5995157639068945		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.5995157639068945 | validation: 0.6029730550225244]
	TIME [epoch: 28 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46161209345815823		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.46161209345815823 | validation: 0.5367456927878069]
	TIME [epoch: 28 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47092950341191253		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.47092950341191253 | validation: 0.8052251823347167]
	TIME [epoch: 28 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6156611146244948		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.6156611146244948 | validation: 0.7861930999790332]
	TIME [epoch: 28 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4837206215009487		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.4837206215009487 | validation: 0.4888202164774094]
	TIME [epoch: 28.1 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37746978939567616		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.37746978939567616 | validation: 0.5902082060108281]
	TIME [epoch: 28.1 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4367292348054396		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.4367292348054396 | validation: 0.48123018265419815]
	TIME [epoch: 28.1 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40540541269846125		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.40540541269846125 | validation: 0.5462105256047023]
	TIME [epoch: 28 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5484934826188527		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.5484934826188527 | validation: 0.7415561668394074]
	TIME [epoch: 28 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6878064356496717		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.6878064356496717 | validation: 0.5448132824688273]
	TIME [epoch: 28 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4596599665207346		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.4596599665207346 | validation: 0.4262439447506347]
	TIME [epoch: 28 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3728619989918899		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.3728619989918899 | validation: 0.4406778639171791]
	TIME [epoch: 28 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47407824151646494		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.47407824151646494 | validation: 0.6203962784426118]
	TIME [epoch: 28 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3830564879393647		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.3830564879393647 | validation: 0.5481007350731419]
	TIME [epoch: 28 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5094116278970019		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.5094116278970019 | validation: 0.8767993434188353]
	TIME [epoch: 28.1 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.553005943253764		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.553005943253764 | validation: 0.4843284725722802]
	TIME [epoch: 28 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4041343251871228		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.4041343251871228 | validation: 0.43580302353997996]
	TIME [epoch: 28 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4005567599759866		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.4005567599759866 | validation: 0.5516697143706298]
	TIME [epoch: 28.1 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5374703879287875		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.5374703879287875 | validation: 0.5633083150429284]
	TIME [epoch: 28 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5301795585356079		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.5301795585356079 | validation: 0.587063158578952]
	TIME [epoch: 28.1 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7591107520987989		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.7591107520987989 | validation: 0.7169627642793629]
	TIME [epoch: 28.1 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7504120919777495		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.7504120919777495 | validation: 0.6263473124259344]
	TIME [epoch: 28.1 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5249276268428141		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.5249276268428141 | validation: 0.5743484516820366]
	TIME [epoch: 28.1 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49112796145834403		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.49112796145834403 | validation: 0.592778695102484]
	TIME [epoch: 28 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4483006037094959		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.4483006037094959 | validation: 0.5237636927004014]
	TIME [epoch: 28.1 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4621465302412857		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.4621465302412857 | validation: 0.6330134646917028]
	TIME [epoch: 28.1 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5665520099157143		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.5665520099157143 | validation: 0.581521936760436]
	TIME [epoch: 28.1 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6218674682556884		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.6218674682556884 | validation: 1.208590182243299]
	TIME [epoch: 28.1 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.901691214167269		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.901691214167269 | validation: 0.6713215234238626]
	TIME [epoch: 28.1 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6894826596420147		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.6894826596420147 | validation: 0.9432361700437131]
	TIME [epoch: 28 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8455133235711546		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.8455133235711546 | validation: 0.8476799704951781]
	TIME [epoch: 28.1 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7361598977002151		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.7361598977002151 | validation: 0.5682760189688554]
	TIME [epoch: 28 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5416892426696719		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.5416892426696719 | validation: 0.4571573074716902]
	TIME [epoch: 28 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43560480924144906		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.43560480924144906 | validation: 0.7231757007867355]
	TIME [epoch: 28 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5311491571376962		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.5311491571376962 | validation: 0.539489854284466]
	TIME [epoch: 28 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4760997645185096		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.4760997645185096 | validation: 0.5990138630814237]
	TIME [epoch: 28 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4817738023088015		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.4817738023088015 | validation: 0.5709313164635935]
	TIME [epoch: 28 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4947685583279627		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.4947685583279627 | validation: 0.529958086031259]
	TIME [epoch: 28 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5211330519957685		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.5211330519957685 | validation: 0.6969921897310064]
	TIME [epoch: 28 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5039074670892036		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.5039074670892036 | validation: 0.5621093893700969]
	TIME [epoch: 28 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4419748703336851		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.4419748703336851 | validation: 0.5099807916958501]
	TIME [epoch: 28.1 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4899451002455055		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.4899451002455055 | validation: 0.5883132393726015]
	TIME [epoch: 28.1 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43475565028553165		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.43475565028553165 | validation: 0.4359786083210877]
	TIME [epoch: 28 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3766833957631316		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.3766833957631316 | validation: 0.4361472482724181]
	TIME [epoch: 28.1 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4274575271606643		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.4274575271606643 | validation: 0.5472649442407935]
	TIME [epoch: 28 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48979306455021976		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.48979306455021976 | validation: 0.6288051188487677]
	TIME [epoch: 28 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5100805777621363		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.5100805777621363 | validation: 0.7261564307407314]
	TIME [epoch: 28 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4343970407589046		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.4343970407589046 | validation: 0.5688395938683186]
	TIME [epoch: 28.1 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5168815575371376		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.5168815575371376 | validation: 0.6419109404591936]
	TIME [epoch: 28 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48497302360598915		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.48497302360598915 | validation: 0.4502424563720153]
	TIME [epoch: 28 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3842895046345864		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.3842895046345864 | validation: 0.615278516401521]
	TIME [epoch: 28 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41425715876441793		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.41425715876441793 | validation: 0.5158754244554491]
	TIME [epoch: 28 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6179158788765444		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.6179158788765444 | validation: 0.6513039682622105]
	TIME [epoch: 27.9 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.95528295561157		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.95528295561157 | validation: 1.1157936580483911]
	TIME [epoch: 28 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7147833944731117		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.7147833944731117 | validation: 0.5943654410438006]
	TIME [epoch: 28 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.64519931491913		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.64519931491913 | validation: 0.7200560330104034]
	TIME [epoch: 28 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5790986330343066		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.5790986330343066 | validation: 0.6012154170839166]
	TIME [epoch: 28 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.478197173938261		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.478197173938261 | validation: 0.48018903933026175]
	TIME [epoch: 28 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.485070651525001		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.485070651525001 | validation: 0.6709930018054082]
	TIME [epoch: 28 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5051596151939944		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.5051596151939944 | validation: 0.4216953990872242]
	TIME [epoch: 28 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40626393427984664		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.40626393427984664 | validation: 0.4757243382472305]
	TIME [epoch: 28.1 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4777538407339012		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.4777538407339012 | validation: 0.5381607244368126]
	TIME [epoch: 28.1 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4389233735100362		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.4389233735100362 | validation: 0.4422243626133296]
	TIME [epoch: 28 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41448552352483586		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.41448552352483586 | validation: 0.4039564222010589]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_765.pth
	Model improved!!!
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4049537120703032		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.4049537120703032 | validation: 0.5625125000586187]
	TIME [epoch: 28.1 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43820917035684515		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.43820917035684515 | validation: 0.4153099029895646]
	TIME [epoch: 28.1 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3948837422503117		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.3948837422503117 | validation: 0.558387025392839]
	TIME [epoch: 28.1 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44162156405433833		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.44162156405433833 | validation: 0.7225538860386784]
	TIME [epoch: 28.1 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5816731377971688		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.5816731377971688 | validation: 0.40326530332983124]
	TIME [epoch: 28.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_770.pth
	Model improved!!!
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3891702623426736		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.3891702623426736 | validation: 0.5731471397956119]
	TIME [epoch: 28.1 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45566364258363784		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.45566364258363784 | validation: 0.5005976242898991]
	TIME [epoch: 28.1 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5195983240936011		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.5195983240936011 | validation: 0.5637143078588435]
	TIME [epoch: 28.1 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6139456997455114		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.6139456997455114 | validation: 0.49667675791801963]
	TIME [epoch: 28 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5085051327538823		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.5085051327538823 | validation: 0.6173974221660666]
	TIME [epoch: 28.1 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48465839718153064		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.48465839718153064 | validation: 0.4600955077819813]
	TIME [epoch: 28.1 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4210191563404566		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.4210191563404566 | validation: 0.4905681182596682]
	TIME [epoch: 28.1 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5024772201965501		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.5024772201965501 | validation: 0.5357018840362259]
	TIME [epoch: 28.1 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48826087120641004		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.48826087120641004 | validation: 0.4606753160794399]
	TIME [epoch: 28.1 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.413127450085567		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.413127450085567 | validation: 0.40945912520320404]
	TIME [epoch: 28.1 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36733460847903676		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.36733460847903676 | validation: 0.44582166824554437]
	TIME [epoch: 28.1 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36986087944756296		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.36986087944756296 | validation: 0.421579452420183]
	TIME [epoch: 28.1 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4134907370085323		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.4134907370085323 | validation: 0.36502360707649606]
	TIME [epoch: 28.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_783.pth
	Model improved!!!
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41697080633584643		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.41697080633584643 | validation: 0.5885846221240606]
	TIME [epoch: 28.1 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3987641978863065		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.3987641978863065 | validation: 0.41251265914755353]
	TIME [epoch: 28.1 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36720278239032894		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.36720278239032894 | validation: 0.3680468770477585]
	TIME [epoch: 28 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3835391293015445		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.3835391293015445 | validation: 0.3606375334134046]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_787.pth
	Model improved!!!
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3414459269692852		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.3414459269692852 | validation: 0.8764338844565484]
	TIME [epoch: 28 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.777481580368464		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.777481580368464 | validation: 1.0353463064896997]
	TIME [epoch: 28 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6085242652972478		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.6085242652972478 | validation: 0.4346018923699527]
	TIME [epoch: 28 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.379860574921417		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.379860574921417 | validation: 0.4980876947854304]
	TIME [epoch: 28 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4298127401008536		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.4298127401008536 | validation: 0.47227898892141995]
	TIME [epoch: 28 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36571108411855424		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.36571108411855424 | validation: 0.4353856203014358]
	TIME [epoch: 28 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35799313407234234		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.35799313407234234 | validation: 0.3848477899958398]
	TIME [epoch: 28 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3489008913500815		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.3489008913500815 | validation: 0.4084493110976658]
	TIME [epoch: 28 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3885897750634798		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.3885897750634798 | validation: 0.6023691077448493]
	TIME [epoch: 28 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8442676709541223		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.8442676709541223 | validation: 0.8690751513380667]
	TIME [epoch: 28 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6791031118329628		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.6791031118329628 | validation: 0.5388588669595766]
	TIME [epoch: 28 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.469638170502904		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.469638170502904 | validation: 0.5656015178789235]
	TIME [epoch: 28 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4333487883315398		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.4333487883315398 | validation: 0.5151171375285108]
	TIME [epoch: 28 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38009652700324986		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.38009652700324986 | validation: 0.4582778161131279]
	TIME [epoch: 28 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40156728707048966		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.40156728707048966 | validation: 0.5083855178285129]
	TIME [epoch: 28 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5373778638497679		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.5373778638497679 | validation: 0.3755874128646741]
	TIME [epoch: 28 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4020060755531355		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.4020060755531355 | validation: 0.3550707474417397]
	TIME [epoch: 28.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_804.pth
	Model improved!!!
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3411514762291063		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.3411514762291063 | validation: 0.6360918607651481]
	TIME [epoch: 27.9 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4813124789433889		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.4813124789433889 | validation: 0.5834364300459829]
	TIME [epoch: 28 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5242780683646322		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.5242780683646322 | validation: 0.743181973957804]
	TIME [epoch: 28 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5423990058588553		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.5423990058588553 | validation: 0.4191927374629978]
	TIME [epoch: 27.9 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33891546845757453		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.33891546845757453 | validation: 0.4693882704066607]
	TIME [epoch: 28 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36689343914233874		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.36689343914233874 | validation: 0.41412554892468534]
	TIME [epoch: 27.9 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5151360760733603		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.5151360760733603 | validation: 0.568246634281826]
	TIME [epoch: 28 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5131620019822981		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.5131620019822981 | validation: 0.9909997952895533]
	TIME [epoch: 27.9 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8401184686120909		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.8401184686120909 | validation: 0.5697961650500348]
	TIME [epoch: 27.9 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4375350855149017		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.4375350855149017 | validation: 0.3708061704454028]
	TIME [epoch: 28 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38855696441367127		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.38855696441367127 | validation: 0.4069848251215363]
	TIME [epoch: 27.9 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.402041222824901		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.402041222824901 | validation: 0.44749774866455455]
	TIME [epoch: 28 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44928760542920043		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.44928760542920043 | validation: 0.5536433697153613]
	TIME [epoch: 28 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4480880869859237		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.4480880869859237 | validation: 0.508482157051114]
	TIME [epoch: 27.9 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43040766818983167		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.43040766818983167 | validation: 0.6071695087533163]
	TIME [epoch: 28 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4726715338827774		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.4726715338827774 | validation: 0.5987201335796359]
	TIME [epoch: 27.9 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5418571145692712		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.5418571145692712 | validation: 0.6417725651505936]
	TIME [epoch: 28 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41623431479325956		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.41623431479325956 | validation: 0.3936531704421461]
	TIME [epoch: 28 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3193353867213963		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.3193353867213963 | validation: 0.3691530172002666]
	TIME [epoch: 28 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44393710967214717		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.44393710967214717 | validation: 0.5447415875103667]
	TIME [epoch: 28 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5579184138092674		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.5579184138092674 | validation: 0.43781929121776186]
	TIME [epoch: 28 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38817543729518905		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.38817543729518905 | validation: 0.38536140771246435]
	TIME [epoch: 28 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35734762209159326		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.35734762209159326 | validation: 0.39853603775945823]
	TIME [epoch: 28 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4275517904035978		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.4275517904035978 | validation: 0.47955643286057653]
	TIME [epoch: 28 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39620244106279867		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.39620244106279867 | validation: 0.37195359286776836]
	TIME [epoch: 28 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3546240098282999		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.3546240098282999 | validation: 0.9045105263622827]
	TIME [epoch: 28 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5794873797004404		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.5794873797004404 | validation: 0.43690233216071067]
	TIME [epoch: 28 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39431643519934406		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.39431643519934406 | validation: 0.37041078509634817]
	TIME [epoch: 28 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35697531262351845		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.35697531262351845 | validation: 0.3730770708977201]
	TIME [epoch: 28 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3506473493638493		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.3506473493638493 | validation: 0.49398721922057937]
	TIME [epoch: 28 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3781681170481226		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.3781681170481226 | validation: 0.388677777605734]
	TIME [epoch: 28 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3420886828875865		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.3420886828875865 | validation: 0.34549974997806426]
	TIME [epoch: 28.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_836.pth
	Model improved!!!
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3555589655567773		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.3555589655567773 | validation: 0.40469955517632455]
	TIME [epoch: 28 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5348263338916269		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.5348263338916269 | validation: 0.5494099242652312]
	TIME [epoch: 28 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5071531802013607		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.5071531802013607 | validation: 0.6206331293954339]
	TIME [epoch: 28 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6154528970197386		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.6154528970197386 | validation: 0.6199153460890603]
	TIME [epoch: 28 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43024461339171133		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.43024461339171133 | validation: 0.3745075485805166]
	TIME [epoch: 28 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36187888965170756		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.36187888965170756 | validation: 0.5463291531282494]
	TIME [epoch: 28 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40786658919688923		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.40786658919688923 | validation: 0.41191629942132985]
	TIME [epoch: 28 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4694859377997397		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.4694859377997397 | validation: 0.6312738085443804]
	TIME [epoch: 28.1 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4410922734676659		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.4410922734676659 | validation: 0.43160083474352645]
	TIME [epoch: 28 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3300633424671624		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.3300633424671624 | validation: 0.38737406869601493]
	TIME [epoch: 28 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40278558885538845		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.40278558885538845 | validation: 0.45931131049298657]
	TIME [epoch: 28 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3308367700906539		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.3308367700906539 | validation: 0.3922331073869831]
	TIME [epoch: 28 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34009593585983683		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.34009593585983683 | validation: 0.485949448130023]
	TIME [epoch: 28 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44276587893748665		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.44276587893748665 | validation: 0.4425301751874763]
	TIME [epoch: 28 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4120051976653589		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.4120051976653589 | validation: 0.48986929278130775]
	TIME [epoch: 28 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47386935765630883		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.47386935765630883 | validation: 0.43780594882950447]
	TIME [epoch: 28.1 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.361920102006676		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.361920102006676 | validation: 0.49910295416572625]
	TIME [epoch: 28 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46376403562874746		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.46376403562874746 | validation: 0.34958775801906344]
	TIME [epoch: 28 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.379751819516		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.379751819516 | validation: 0.5500508214113938]
	TIME [epoch: 28.1 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3972440420487837		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.3972440420487837 | validation: 0.4367943138679024]
	TIME [epoch: 28 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44108422932935865		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.44108422932935865 | validation: 0.7565347009409277]
	TIME [epoch: 28 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6628049427620368		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.6628049427620368 | validation: 0.5482621660119066]
	TIME [epoch: 28 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5559466917591322		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.5559466917591322 | validation: 0.5639050472779347]
	TIME [epoch: 28 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44416439572930955		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.44416439572930955 | validation: 0.38304117298800905]
	TIME [epoch: 28 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3983886260057301		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.3983886260057301 | validation: 0.356760432157319]
	TIME [epoch: 28 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3417054698791651		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.3417054698791651 | validation: 0.34800147007928145]
	TIME [epoch: 28 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3667905406896248		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.3667905406896248 | validation: 0.4780928027431105]
	TIME [epoch: 28 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5075393750710824		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.5075393750710824 | validation: 0.7093743644902034]
	TIME [epoch: 28 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.506608948797197		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.506608948797197 | validation: 0.4181882736442313]
	TIME [epoch: 28 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3684460678795732		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.3684460678795732 | validation: 0.4340409228746659]
	TIME [epoch: 28.1 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3844308317133558		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.3844308317133558 | validation: 0.42614980771295846]
	TIME [epoch: 28 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35342243080749286		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.35342243080749286 | validation: 0.4533996872285843]
	TIME [epoch: 28 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38196293317808017		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.38196293317808017 | validation: 0.3674315207625822]
	TIME [epoch: 28 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3665189282655168		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.3665189282655168 | validation: 0.46996278774199796]
	TIME [epoch: 28 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3973933086077422		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.3973933086077422 | validation: 0.35465500594420507]
	TIME [epoch: 28 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3337054143970373		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.3337054143970373 | validation: 0.3677572497039487]
	TIME [epoch: 28 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33727701781964176		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.33727701781964176 | validation: 0.40596317524025904]
	TIME [epoch: 28 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38115461525499195		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.38115461525499195 | validation: 0.4876852749839226]
	TIME [epoch: 28 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33501121929898625		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.33501121929898625 | validation: 0.342137663008062]
	TIME [epoch: 28.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_875.pth
	Model improved!!!
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37649693006872786		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.37649693006872786 | validation: 0.4239619542122472]
	TIME [epoch: 28 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3433165128607741		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.3433165128607741 | validation: 0.40687828733660303]
	TIME [epoch: 28 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4343735408727406		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.4343735408727406 | validation: 0.47827117405672104]
	TIME [epoch: 28 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4105907808936984		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.4105907808936984 | validation: 0.4418347276770729]
	TIME [epoch: 28 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4048343151572278		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.4048343151572278 | validation: 0.4061431963042703]
	TIME [epoch: 28 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3810112092395169		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.3810112092395169 | validation: 0.3899043836895734]
	TIME [epoch: 28 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39973841492469536		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.39973841492469536 | validation: 0.32815354166057153]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_882.pth
	Model improved!!!
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32385639098288976		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.32385639098288976 | validation: 0.3413968173323996]
	TIME [epoch: 28 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3388349335745894		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.3388349335745894 | validation: 0.4252144401341555]
	TIME [epoch: 28 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3774052583070675		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.3774052583070675 | validation: 0.42548207121410214]
	TIME [epoch: 28 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3445226281310816		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.3445226281310816 | validation: 0.3234576200419717]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_886.pth
	Model improved!!!
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3535414634277866		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.3535414634277866 | validation: 0.38535983505727717]
	TIME [epoch: 28 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36579769304758764		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.36579769304758764 | validation: 0.3773221485758244]
	TIME [epoch: 28 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34775895188118866		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.34775895188118866 | validation: 0.41295062444662817]
	TIME [epoch: 28 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.315897166134081		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.315897166134081 | validation: 0.3403621101365583]
	TIME [epoch: 28 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33078089876729905		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.33078089876729905 | validation: 0.35503142706679824]
	TIME [epoch: 28 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31278819413643266		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.31278819413643266 | validation: 0.3179783613167941]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_892.pth
	Model improved!!!
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3338575128141452		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.3338575128141452 | validation: 0.311202679487897]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_893.pth
	Model improved!!!
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29346640172054267		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.29346640172054267 | validation: 0.3408023509312409]
	TIME [epoch: 28 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4264819041856158		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.4264819041856158 | validation: 0.376891762410474]
	TIME [epoch: 28 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3551833700591221		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.3551833700591221 | validation: 0.4052709388004459]
	TIME [epoch: 28 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37833462037165627		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.37833462037165627 | validation: 0.38973318439610516]
	TIME [epoch: 27.9 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3974568871017143		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.3974568871017143 | validation: 0.5023868093410322]
	TIME [epoch: 27.9 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4346545047321578		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.4346545047321578 | validation: 0.5824850344815506]
	TIME [epoch: 27.9 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4130176698217401		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.4130176698217401 | validation: 0.46577080500142365]
	TIME [epoch: 27.9 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3813104654193557		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.3813104654193557 | validation: 0.42273730501115764]
	TIME [epoch: 28 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3550012771198513		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.3550012771198513 | validation: 0.3834597857527791]
	TIME [epoch: 28 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34111766088909873		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.34111766088909873 | validation: 0.5425587159274344]
	TIME [epoch: 28 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.441904228595772		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.441904228595772 | validation: 0.4607020599582806]
	TIME [epoch: 28 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36104092673623567		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.36104092673623567 | validation: 0.4072936392023283]
	TIME [epoch: 28 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36917765613367837		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.36917765613367837 | validation: 0.3309331637007861]
	TIME [epoch: 28 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35272796612670454		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.35272796612670454 | validation: 0.40992928392965683]
	TIME [epoch: 28 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39715575801745623		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.39715575801745623 | validation: 0.42519766300806394]
	TIME [epoch: 28 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34180491802171553		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.34180491802171553 | validation: 0.34343642678725794]
	TIME [epoch: 28 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36253079639841373		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.36253079639841373 | validation: 0.5782360199603158]
	TIME [epoch: 28 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4336621095552496		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.4336621095552496 | validation: 0.3762542075310917]
	TIME [epoch: 28 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3534678080319257		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.3534678080319257 | validation: 0.34574540531260467]
	TIME [epoch: 28 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3295576108396785		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.3295576108396785 | validation: 0.3671193959907898]
	TIME [epoch: 28 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3764082659564609		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.3764082659564609 | validation: 0.42406750128548837]
	TIME [epoch: 28 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46164313007873176		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.46164313007873176 | validation: 0.4049663609437683]
	TIME [epoch: 28 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3767294630132916		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.3767294630132916 | validation: 0.4054847267390268]
	TIME [epoch: 28 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37303606239113196		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.37303606239113196 | validation: 0.3555114851138253]
	TIME [epoch: 28 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3267432861542334		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.3267432861542334 | validation: 0.35966035064722573]
	TIME [epoch: 28 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41300250282891693		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.41300250282891693 | validation: 0.43260911872964825]
	TIME [epoch: 28 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38110835926203357		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.38110835926203357 | validation: 0.41897547647733546]
	TIME [epoch: 28 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3694545168265358		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.3694545168265358 | validation: 0.4134241764671082]
	TIME [epoch: 28 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32210819524369066		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.32210819524369066 | validation: 0.3359055623310773]
	TIME [epoch: 28 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30724845445275006		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.30724845445275006 | validation: 0.3674834599018428]
	TIME [epoch: 28 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32306445772989834		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.32306445772989834 | validation: 0.4123261391349118]
	TIME [epoch: 28 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33464122361787385		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.33464122361787385 | validation: 0.433573170794613]
	TIME [epoch: 28 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3778153634415846		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.3778153634415846 | validation: 0.44056854307902965]
	TIME [epoch: 28 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4092662329657861		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.4092662329657861 | validation: 0.392195952693488]
	TIME [epoch: 28 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34550512382793797		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.34550512382793797 | validation: 0.3935019285197703]
	TIME [epoch: 28 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30799476828158423		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.30799476828158423 | validation: 0.3372065826136554]
	TIME [epoch: 28 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3410900562301321		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.3410900562301321 | validation: 0.4230813288421703]
	TIME [epoch: 28 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32863076672262115		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.32863076672262115 | validation: 0.3745096845303187]
	TIME [epoch: 28 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3193110478900085		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.3193110478900085 | validation: 0.43029288957175427]
	TIME [epoch: 28 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35315972141307184		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.35315972141307184 | validation: 0.4238121256638391]
	TIME [epoch: 28 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3442974327318632		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.3442974327318632 | validation: 0.4748518239977898]
	TIME [epoch: 28 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42144772067599856		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.42144772067599856 | validation: 0.4318668952672374]
	TIME [epoch: 28 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31271694964973795		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.31271694964973795 | validation: 0.4160833526416324]
	TIME [epoch: 28 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34137985059442716		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.34137985059442716 | validation: 0.42423570558145435]
	TIME [epoch: 28 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5431334712270783		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.5431334712270783 | validation: 0.8128343142905868]
	TIME [epoch: 28 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5705551149376064		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.5705551149376064 | validation: 0.4041655397020035]
	TIME [epoch: 28 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48217908879781357		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.48217908879781357 | validation: 0.4252475824990606]
	TIME [epoch: 28 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3309445700359476		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.3309445700359476 | validation: 0.5359926852738774]
	TIME [epoch: 28 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5948470393731493		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.5948470393731493 | validation: 0.8238382117274294]
	TIME [epoch: 28 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5356114089119932		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.5356114089119932 | validation: 0.5566492482201936]
	TIME [epoch: 28 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37642265691482923		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.37642265691482923 | validation: 0.41481585211947064]
	TIME [epoch: 28 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37594149525641085		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.37594149525641085 | validation: 0.5225903032944748]
	TIME [epoch: 28 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42467171888909405		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.42467171888909405 | validation: 0.6254207569642884]
	TIME [epoch: 28 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4132935583365146		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.4132935583365146 | validation: 0.46305143879382044]
	TIME [epoch: 28 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4013705421582074		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.4013705421582074 | validation: 0.44725448575773413]
	TIME [epoch: 28 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3580332770345196		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.3580332770345196 | validation: 0.4816234266757098]
	TIME [epoch: 28 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3423758469317884		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.3423758469317884 | validation: 0.42739817910019556]
	TIME [epoch: 28 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3984684375788572		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.3984684375788572 | validation: 0.4005455934051124]
	TIME [epoch: 28 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4278703685990429		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.4278703685990429 | validation: 0.5831884200463344]
	TIME [epoch: 28 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4360281441379534		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.4360281441379534 | validation: 0.37059829268542643]
	TIME [epoch: 28 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34882923756912065		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.34882923756912065 | validation: 0.34013275123667797]
	TIME [epoch: 28 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39028180708867494		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.39028180708867494 | validation: 0.39070943524565116]
	TIME [epoch: 28 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32810802595626104		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.32810802595626104 | validation: 0.3361665390253028]
	TIME [epoch: 28 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3041552758752165		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.3041552758752165 | validation: 0.315451848829004]
	TIME [epoch: 28 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2920253901520155		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.2920253901520155 | validation: 0.3224092958879834]
	TIME [epoch: 28 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32102890804730116		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.32102890804730116 | validation: 0.3202695180452544]
	TIME [epoch: 28 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2676428981680923		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.2676428981680923 | validation: 0.32470071201863704]
	TIME [epoch: 28 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2765283617774895		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.2765283617774895 | validation: 0.3842407348195966]
	TIME [epoch: 28 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2953818328737684		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.2953818328737684 | validation: 0.3183709439601755]
	TIME [epoch: 28 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32701058816367684		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.32701058816367684 | validation: 0.4567934807765092]
	TIME [epoch: 28 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3550722921233118		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.3550722921233118 | validation: 0.3493776820537868]
	TIME [epoch: 28 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36355467381724743		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.36355467381724743 | validation: 0.36257634757161866]
	TIME [epoch: 28 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3187375201707368		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.3187375201707368 | validation: 0.32844733455034375]
	TIME [epoch: 27.9 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.282747494313601		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.282747494313601 | validation: 0.39903147639491676]
	TIME [epoch: 28 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39674116414613425		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.39674116414613425 | validation: 0.3894139600650091]
	TIME [epoch: 28 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.300709440559397		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.300709440559397 | validation: 0.3274207830642483]
	TIME [epoch: 28 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32198169602352245		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.32198169602352245 | validation: 0.33864728473910843]
	TIME [epoch: 28 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3118306641589764		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.3118306641589764 | validation: 0.32887694838057563]
	TIME [epoch: 28 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35405650613356077		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.35405650613356077 | validation: 0.438360483362017]
	TIME [epoch: 28 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37503485383980106		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.37503485383980106 | validation: 0.3716027706552382]
	TIME [epoch: 28 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34543200857484835		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.34543200857484835 | validation: 0.3475515574164234]
	TIME [epoch: 28 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3429521509446079		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.3429521509446079 | validation: 0.3276287137774432]
	TIME [epoch: 28 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3205572269086337		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.3205572269086337 | validation: 0.37646162174579995]
	TIME [epoch: 28 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3204013575270876		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.3204013575270876 | validation: 0.334175335543936]
	TIME [epoch: 28 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32386255303845063		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.32386255303845063 | validation: 0.3709565887107192]
	TIME [epoch: 28 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.363174343552998		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.363174343552998 | validation: 0.39282733033523204]
	TIME [epoch: 28 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3276800731377855		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.3276800731377855 | validation: 0.36616653793234266]
	TIME [epoch: 28 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31561738961541774		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.31561738961541774 | validation: 0.3227866065748491]
	TIME [epoch: 28 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3538306611686436		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.3538306611686436 | validation: 0.3993562392530258]
	TIME [epoch: 28 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3650265463008502		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.3650265463008502 | validation: 0.35888736761814016]
	TIME [epoch: 28 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3634035280906918		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.3634035280906918 | validation: 0.42526600133563036]
	TIME [epoch: 28 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48643331582805127		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.48643331582805127 | validation: 0.46162358360406935]
	TIME [epoch: 28 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.379393028214746		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.379393028214746 | validation: 0.33801647787307404]
	TIME [epoch: 28 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3453435202618504		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.3453435202618504 | validation: 0.32485352530317924]
	TIME [epoch: 28 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3318000652282467		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.3318000652282467 | validation: 0.33474827242416616]
	TIME [epoch: 28 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33307097733211305		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.33307097733211305 | validation: 0.3549267816614168]
	TIME [epoch: 28 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35216339956488313		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.35216339956488313 | validation: 0.3448920616914659]
	TIME [epoch: 28 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3296902782113496		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.3296902782113496 | validation: 0.34456026816964463]
	TIME [epoch: 28 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35275021932141315		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.35275021932141315 | validation: 0.4066061956726071]
	TIME [epoch: 28 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32509892888635644		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.32509892888635644 | validation: 0.39523387160560014]
	TIME [epoch: 28 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3414130714612659		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.3414130714612659 | validation: 0.37231634829624055]
	TIME [epoch: 28 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3451504211530108		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.3451504211530108 | validation: 0.35873845286607137]
	TIME [epoch: 28 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30625991940948627		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.30625991940948627 | validation: 0.3263707677665771]
	TIME [epoch: 28 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3396011196651719		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.3396011196651719 | validation: 0.385955342585684]
	TIME [epoch: 28 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3565690987528555		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.3565690987528555 | validation: 0.30288862218172286]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_998.pth
	Model improved!!!
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28091765281867725		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.28091765281867725 | validation: 0.34848954163414936]
	TIME [epoch: 28 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30257361410273115		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.30257361410273115 | validation: 0.3191513197571013]
	TIME [epoch: 28 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30276259396057303		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.30276259396057303 | validation: 0.44396903833195256]
	TIME [epoch: 28.1 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33123660034242075		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.33123660034242075 | validation: 0.40713634682580163]
	TIME [epoch: 28 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3885203975449094		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.3885203975449094 | validation: 0.4961726066177426]
	TIME [epoch: 28 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40959822279374375		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.40959822279374375 | validation: 0.46187162939841797]
	TIME [epoch: 28 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3023160902646698		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.3023160902646698 | validation: 0.32308424567227584]
	TIME [epoch: 28 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2782753188403735		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.2782753188403735 | validation: 0.40290084494951217]
	TIME [epoch: 28 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33276174708889666		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.33276174708889666 | validation: 0.43418134617154075]
	TIME [epoch: 28 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33638668449618214		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.33638668449618214 | validation: 0.433622760002184]
	TIME [epoch: 28 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3081571503555526		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.3081571503555526 | validation: 0.4979299195334658]
	TIME [epoch: 27.9 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34409697201158956		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.34409697201158956 | validation: 0.3570273140850561]
	TIME [epoch: 28 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27128453141091946		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.27128453141091946 | validation: 0.37007189477877417]
	TIME [epoch: 28 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3216980540705384		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.3216980540705384 | validation: 0.32501871496053225]
	TIME [epoch: 28 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29316013077600156		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.29316013077600156 | validation: 0.3324243395495621]
	TIME [epoch: 28 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27746186274285356		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.27746186274285356 | validation: 0.34104412103842535]
	TIME [epoch: 28 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33066843758386993		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.33066843758386993 | validation: 0.35188585077343315]
	TIME [epoch: 28 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29428490763445003		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.29428490763445003 | validation: 0.332937352604358]
	TIME [epoch: 28 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2667576995951065		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.2667576995951065 | validation: 0.38194174112590346]
	TIME [epoch: 28 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28862669148521036		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.28862669148521036 | validation: 0.35211225744101393]
	TIME [epoch: 28.1 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2904030129645394		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.2904030129645394 | validation: 0.49699473705899183]
	TIME [epoch: 28 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4518035793812477		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.4518035793812477 | validation: 0.5442199009370237]
	TIME [epoch: 28.1 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4054575744980011		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.4054575744980011 | validation: 0.4266476258756727]
	TIME [epoch: 28 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29476781203123176		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.29476781203123176 | validation: 0.3784514081728513]
	TIME [epoch: 28 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2802482685830006		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.2802482685830006 | validation: 0.3553336918689354]
	TIME [epoch: 28 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33997241253442034		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.33997241253442034 | validation: 0.3611067434344579]
	TIME [epoch: 28.1 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2935796940667027		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.2935796940667027 | validation: 0.3716402978645867]
	TIME [epoch: 28.1 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27893569763357073		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.27893569763357073 | validation: 0.36321767983652165]
	TIME [epoch: 28 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2888441938313068		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.2888441938313068 | validation: 0.3840475836249009]
	TIME [epoch: 28 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3058579937070751		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.3058579937070751 | validation: 0.4117937249277891]
	TIME [epoch: 28 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29909325912716966		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.29909325912716966 | validation: 0.3677369336638375]
	TIME [epoch: 28.1 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31150239604912594		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.31150239604912594 | validation: 0.4068865350665671]
	TIME [epoch: 28 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3916055662776086		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.3916055662776086 | validation: 0.32344137045375504]
	TIME [epoch: 28.1 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2972494917250205		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.2972494917250205 | validation: 0.37149485035944635]
	TIME [epoch: 28 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29607330895678763		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.29607330895678763 | validation: 0.3327824181007914]
	TIME [epoch: 28.1 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2653391185279742		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.2653391185279742 | validation: 0.30722604294465117]
	TIME [epoch: 28 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2719000656804241		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.2719000656804241 | validation: 0.35863231559812436]
	TIME [epoch: 28 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3550203024216534		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.3550203024216534 | validation: 0.5513486584949275]
	TIME [epoch: 28.1 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3924736955657665		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.3924736955657665 | validation: 0.49709154745538203]
	TIME [epoch: 28.1 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32403392494034233		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.32403392494034233 | validation: 0.34802191080095446]
	TIME [epoch: 28 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2622610608163094		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.2622610608163094 | validation: 0.31548810354046547]
	TIME [epoch: 28.1 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37383123235997795		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.37383123235997795 | validation: 0.4615114703626547]
	TIME [epoch: 28 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37557777658512714		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.37557777658512714 | validation: 0.3276159916517377]
	TIME [epoch: 28.1 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31288404193550895		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.31288404193550895 | validation: 0.34758029455595413]
	TIME [epoch: 28 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29656042337358		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.29656042337358 | validation: 0.32416004501664875]
	TIME [epoch: 28.1 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28898877700052966		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.28898877700052966 | validation: 0.32309267667329994]
	TIME [epoch: 28 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3005566653666014		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.3005566653666014 | validation: 0.38286130937060364]
	TIME [epoch: 28.1 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3848280850115305		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.3848280850115305 | validation: 0.45347280205437723]
	TIME [epoch: 28 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4404798487964583		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.4404798487964583 | validation: 0.4303205463042231]
	TIME [epoch: 28 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37376314707170155		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.37376314707170155 | validation: 0.3362055682295932]
	TIME [epoch: 28 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32718822024461636		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.32718822024461636 | validation: 0.3679855281160411]
	TIME [epoch: 28.1 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42538601226615474		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.42538601226615474 | validation: 0.4583515887092656]
	TIME [epoch: 28 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37844275058558086		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.37844275058558086 | validation: 0.3127937628288802]
	TIME [epoch: 28.1 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.308428608368925		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.308428608368925 | validation: 0.38027449047314166]
	TIME [epoch: 28.1 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35830479923666403		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.35830479923666403 | validation: 0.353356088458506]
	TIME [epoch: 28 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3533381155228057		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.3533381155228057 | validation: 0.40614471109134087]
	TIME [epoch: 28 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37642436221283404		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.37642436221283404 | validation: 0.33185824764311767]
	TIME [epoch: 28 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3470641589702378		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.3470641589702378 | validation: 0.3999439752436559]
	TIME [epoch: 28 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3295941589978926		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.3295941589978926 | validation: 0.344536261278557]
	TIME [epoch: 28.1 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3372496698350251		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.3372496698350251 | validation: 0.3284967188046985]
	TIME [epoch: 28 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3178840240463531		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.3178840240463531 | validation: 0.3356266793557638]
	TIME [epoch: 28.1 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32348009719620247		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.32348009719620247 | validation: 0.3302759578568788]
	TIME [epoch: 28.1 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3435562371153204		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.3435562371153204 | validation: 0.37150552599721504]
	TIME [epoch: 28.1 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3145464007377097		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.3145464007377097 | validation: 0.31345913209435106]
	TIME [epoch: 28.1 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30441976749837873		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.30441976749837873 | validation: 0.3160626788358828]
	TIME [epoch: 28 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3049400493105978		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.3049400493105978 | validation: 0.41376587354818656]
	TIME [epoch: 28.1 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3410537068259888		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.3410537068259888 | validation: 0.30728351556853345]
	TIME [epoch: 28.1 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2753827361083048		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.2753827361083048 | validation: 0.30381496100673283]
	TIME [epoch: 28.1 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29012858077557435		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.29012858077557435 | validation: 0.3000583865517151]
	TIME [epoch: 28.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_1067.pth
	Model improved!!!
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32215524048408795		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.32215524048408795 | validation: 0.45478662156495403]
	TIME [epoch: 28 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30939109286952815		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.30939109286952815 | validation: 0.3172574604722612]
	TIME [epoch: 28 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26243163675875214		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.26243163675875214 | validation: 0.29131250318428875]
	TIME [epoch: 28.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_1070.pth
	Model improved!!!
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2816654214762428		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.2816654214762428 | validation: 0.36267032716282316]
	TIME [epoch: 28 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29277214239056876		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.29277214239056876 | validation: 0.3471307508161726]
	TIME [epoch: 28.1 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27774726702582153		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.27774726702582153 | validation: 0.38786267132962]
	TIME [epoch: 28 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3086266510945922		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.3086266510945922 | validation: 0.426139888406116]
	TIME [epoch: 28.1 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34699954841753655		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.34699954841753655 | validation: 0.38907161431929477]
	TIME [epoch: 28.1 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2966314320754677		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.2966314320754677 | validation: 0.3419562394033988]
	TIME [epoch: 28 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4111367937025796		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.4111367937025796 | validation: 0.652346893960652]
	TIME [epoch: 28.1 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5333736808316261		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.5333736808316261 | validation: 0.387628018369949]
	TIME [epoch: 28 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32251984691352675		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.32251984691352675 | validation: 0.3073909017887999]
	TIME [epoch: 28 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2909975207168801		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.2909975207168801 | validation: 0.30435571362313313]
	TIME [epoch: 28.1 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2820028738541733		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.2820028738541733 | validation: 0.30066438202829654]
	TIME [epoch: 28 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3465015426539053		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.3465015426539053 | validation: 0.447311980570666]
	TIME [epoch: 28.1 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.325503910231746		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.325503910231746 | validation: 0.29519348415142]
	TIME [epoch: 28 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2807025897692677		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.2807025897692677 | validation: 0.3012410186081721]
	TIME [epoch: 28.1 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27905247564696056		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.27905247564696056 | validation: 0.28464845926076854]
	TIME [epoch: 28.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_1085.pth
	Model improved!!!
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29208100986663044		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.29208100986663044 | validation: 0.3248720752373957]
	TIME [epoch: 28.1 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2903356014824596		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.2903356014824596 | validation: 0.34808381886572315]
	TIME [epoch: 28 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3124934974290211		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.3124934974290211 | validation: 0.336668275429802]
	TIME [epoch: 28.1 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2925960919251156		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.2925960919251156 | validation: 0.343563535094678]
	TIME [epoch: 28 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29289481792263655		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.29289481792263655 | validation: 0.28700621544123217]
	TIME [epoch: 28.1 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.293444294680309		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.293444294680309 | validation: 0.2938553392421202]
	TIME [epoch: 28.1 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2976212250441302		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.2976212250441302 | validation: 0.35965548615000553]
	TIME [epoch: 28.1 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4130673685973919		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.4130673685973919 | validation: 0.47985361771655405]
	TIME [epoch: 28.1 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39810557198175445		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.39810557198175445 | validation: 0.36471649138104995]
	TIME [epoch: 28 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33680734421155917		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.33680734421155917 | validation: 0.3648675190141834]
	TIME [epoch: 28.1 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3439457171681042		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.3439457171681042 | validation: 0.3789846650518552]
	TIME [epoch: 28 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34331207726794577		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.34331207726794577 | validation: 0.36635423534449274]
	TIME [epoch: 28.1 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3632230325109336		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.3632230325109336 | validation: 0.3646992933171158]
	TIME [epoch: 28.1 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37275842330595443		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.37275842330595443 | validation: 0.38310150324275316]
	TIME [epoch: 28 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36413549016436475		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.36413549016436475 | validation: 0.379786954925967]
	TIME [epoch: 28.1 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35266651092585455		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.35266651092585455 | validation: 0.38293042529364973]
	TIME [epoch: 28 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34095215030400705		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.34095215030400705 | validation: 0.3027086108907585]
	TIME [epoch: 28.1 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2797731451848092		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.2797731451848092 | validation: 0.3658158262667115]
	TIME [epoch: 28.1 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29221510480087615		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.29221510480087615 | validation: 0.30541567145651416]
	TIME [epoch: 28 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32828388401366615		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.32828388401366615 | validation: 0.30524420661231283]
	TIME [epoch: 28.1 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3172575264256732		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.3172575264256732 | validation: 0.3546845634749491]
	TIME [epoch: 28 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.321956368361865		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.321956368361865 | validation: 0.2798139771577091]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_1107.pth
	Model improved!!!
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29789902754661357		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.29789902754661357 | validation: 0.30327826375434314]
	TIME [epoch: 28.1 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3033895302164253		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.3033895302164253 | validation: 0.32956595579832687]
	TIME [epoch: 28 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29044822390339187		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.29044822390339187 | validation: 0.3046192757036647]
	TIME [epoch: 28 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28535027591017775		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.28535027591017775 | validation: 0.311743886471956]
	TIME [epoch: 28.1 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2960095805748297		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.2960095805748297 | validation: 0.33949541951540424]
	TIME [epoch: 28 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33577244641100673		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.33577244641100673 | validation: 0.41130859998250385]
	TIME [epoch: 28.1 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3276539071899278		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.3276539071899278 | validation: 0.3493494089109374]
	TIME [epoch: 28 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3282410415413748		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.3282410415413748 | validation: 0.3935179334252942]
	TIME [epoch: 28.1 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3036347608875768		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.3036347608875768 | validation: 0.29717325433392483]
	TIME [epoch: 28.1 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2962849827685481		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.2962849827685481 | validation: 0.3384766983215045]
	TIME [epoch: 28.1 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3085419214751225		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.3085419214751225 | validation: 0.34300916150225264]
	TIME [epoch: 28.1 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2854781522714819		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.2854781522714819 | validation: 0.3165639506653246]
	TIME [epoch: 28.1 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2893626628706169		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.2893626628706169 | validation: 0.35231093501116734]
	TIME [epoch: 28.1 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30177264149995076		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.30177264149995076 | validation: 0.3407162836509717]
	TIME [epoch: 28.1 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2948359966245816		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.2948359966245816 | validation: 0.3504229666855362]
	TIME [epoch: 28 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30821599477722267		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.30821599477722267 | validation: 0.4117660246143023]
	TIME [epoch: 28.1 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.287796859485838		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.287796859485838 | validation: 0.30253042697313987]
	TIME [epoch: 28.1 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26809804297246365		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.26809804297246365 | validation: 0.3121987328814271]
	TIME [epoch: 28.1 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.281827561707953		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.281827561707953 | validation: 0.37580842704409306]
	TIME [epoch: 28.1 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.286996150387832		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.286996150387832 | validation: 0.3158091287499615]
	TIME [epoch: 28 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27859873920983247		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.27859873920983247 | validation: 0.29196887143400296]
	TIME [epoch: 28.1 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28289575889944063		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.28289575889944063 | validation: 0.3394318999960754]
	TIME [epoch: 28 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30940030615121805		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.30940030615121805 | validation: 0.32805472342323655]
	TIME [epoch: 28.1 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2898618878718825		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.2898618878718825 | validation: 0.30749357596921023]
	TIME [epoch: 28 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28122549742328184		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.28122549742328184 | validation: 0.3367220225138209]
	TIME [epoch: 28 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33394303626294614		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.33394303626294614 | validation: 0.32653603647288343]
	TIME [epoch: 28.1 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31695644938325496		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.31695644938325496 | validation: 0.34862286932466263]
	TIME [epoch: 28.1 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.349508550702101		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.349508550702101 | validation: 0.3485277617276586]
	TIME [epoch: 28 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3346308961320119		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.3346308961320119 | validation: 0.2970736826179889]
	TIME [epoch: 28.1 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27708356087292396		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.27708356087292396 | validation: 0.2902549686264733]
	TIME [epoch: 28 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28221856733462336		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.28221856733462336 | validation: 0.3282344667566289]
	TIME [epoch: 28.1 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28954743348213774		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.28954743348213774 | validation: 0.2725818847250448]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_1139.pth
	Model improved!!!
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2913270340990877		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.2913270340990877 | validation: 0.31974737051702806]
	TIME [epoch: 28 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30193572389946854		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.30193572389946854 | validation: 0.30564593515250643]
	TIME [epoch: 28.1 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30739883558027603		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.30739883558027603 | validation: 0.3226262604791743]
	TIME [epoch: 28.1 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3060471888721195		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.3060471888721195 | validation: 0.3117846780182943]
	TIME [epoch: 28.1 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31623126849925565		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.31623126849925565 | validation: 0.3882031422402058]
	TIME [epoch: 28.1 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3951057612566522		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.3951057612566522 | validation: 0.3879708099993159]
	TIME [epoch: 28 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3569622369464309		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.3569622369464309 | validation: 0.3832250493017395]
	TIME [epoch: 28.1 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3361752557211153		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.3361752557211153 | validation: 0.3794033004210979]
	TIME [epoch: 28.1 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34545074980317686		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.34545074980317686 | validation: 0.3332814052798364]
	TIME [epoch: 28.1 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.316852198223046		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.316852198223046 | validation: 0.28776631478145254]
	TIME [epoch: 28.1 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2817078711349196		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.2817078711349196 | validation: 0.27149254223540487]
	TIME [epoch: 28.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_1150.pth
	Model improved!!!
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2743766768504185		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.2743766768504185 | validation: 0.29753760656874695]
	TIME [epoch: 28.1 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2863932011649874		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.2863932011649874 | validation: 0.291155216349462]
	TIME [epoch: 28.1 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28030224223361716		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.28030224223361716 | validation: 0.3031516538961189]
	TIME [epoch: 28.1 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2853731105429339		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.2853731105429339 | validation: 0.29512890547665643]
	TIME [epoch: 28.1 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2820249541365285		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.2820249541365285 | validation: 0.3032099883830161]
	TIME [epoch: 28.1 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3207462640416948		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.3207462640416948 | validation: 0.3586952792589831]
	TIME [epoch: 28.1 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30023886686082185		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.30023886686082185 | validation: 0.27544712995990006]
	TIME [epoch: 28.1 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27044060414318705		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.27044060414318705 | validation: 0.3576626338160204]
	TIME [epoch: 28.1 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2966590622170378		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.2966590622170378 | validation: 0.37537226106451804]
	TIME [epoch: 28.1 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2951222549109909		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.2951222549109909 | validation: 0.32235205280755597]
	TIME [epoch: 28.1 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2872580876091195		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.2872580876091195 | validation: 0.3252225220655856]
	TIME [epoch: 28.1 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3312639550921169		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.3312639550921169 | validation: 0.31512757344574394]
	TIME [epoch: 28.1 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30001727700722375		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.30001727700722375 | validation: 0.28238135338587667]
	TIME [epoch: 28.1 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28852259661944724		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.28852259661944724 | validation: 0.29245365620569297]
	TIME [epoch: 28.1 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31658182540075597		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.31658182540075597 | validation: 0.3788856515185532]
	TIME [epoch: 28.1 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37125260923602876		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.37125260923602876 | validation: 0.3409884694332027]
	TIME [epoch: 28.1 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31893915924434824		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.31893915924434824 | validation: 0.2904475474916691]
	TIME [epoch: 28.1 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2845880020850341		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.2845880020850341 | validation: 0.2825300144394139]
	TIME [epoch: 28 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2832896291402196		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.2832896291402196 | validation: 0.29450927426264906]
	TIME [epoch: 28.1 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29076459616150274		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.29076459616150274 | validation: 0.3225586842210851]
	TIME [epoch: 28.1 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2868109046430919		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.2868109046430919 | validation: 0.28129998053549576]
	TIME [epoch: 28.1 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2778615334806462		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.2778615334806462 | validation: 0.29090629705173454]
	TIME [epoch: 28.1 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28953600499536863		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.28953600499536863 | validation: 0.2950007656616221]
	TIME [epoch: 28.1 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31713646465251777		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.31713646465251777 | validation: 0.35749731892955033]
	TIME [epoch: 28.1 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3222762530734335		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.3222762530734335 | validation: 0.27194285519821587]
	TIME [epoch: 28.1 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28527178920334656		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.28527178920334656 | validation: 0.2975604978442805]
	TIME [epoch: 28.1 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3244273882439557		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.3244273882439557 | validation: 0.31559871251040816]
	TIME [epoch: 28.1 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30475304337641196		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.30475304337641196 | validation: 0.324343005970486]
	TIME [epoch: 28 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3011962846939862		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.3011962846939862 | validation: 0.26537819900278514]
	TIME [epoch: 28.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_1179.pth
	Model improved!!!
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2822943419418613		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.2822943419418613 | validation: 0.290800378971162]
	TIME [epoch: 28.1 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27278061074309223		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.27278061074309223 | validation: 0.2899745952900846]
	TIME [epoch: 28 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28532672061800896		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.28532672061800896 | validation: 0.2873729168629118]
	TIME [epoch: 28.1 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28944791080199833		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.28944791080199833 | validation: 0.28605846368964444]
	TIME [epoch: 28.1 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2836600714751925		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.2836600714751925 | validation: 0.29148239863675857]
	TIME [epoch: 28.1 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29395618025299236		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.29395618025299236 | validation: 0.3184019086503786]
	TIME [epoch: 28.1 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31400438478856985		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.31400438478856985 | validation: 0.3104077232015764]
	TIME [epoch: 28 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32820837839747363		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.32820837839747363 | validation: 0.3197379793189341]
	TIME [epoch: 28.1 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3351963209468037		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.3351963209468037 | validation: 0.3269966947919798]
	TIME [epoch: 28 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33020192613969557		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.33020192613969557 | validation: 0.32391901386747085]
	TIME [epoch: 28 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29229189599849564		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.29229189599849564 | validation: 0.28784953174686023]
	TIME [epoch: 28 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2912136633450939		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.2912136633450939 | validation: 0.2803298273111447]
	TIME [epoch: 28 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2619219748803488		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.2619219748803488 | validation: 0.28920204730104376]
	TIME [epoch: 28.1 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2644042748166585		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.2644042748166585 | validation: 0.28010911191282245]
	TIME [epoch: 28.1 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2718532247549148		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.2718532247549148 | validation: 0.2796066329188258]
	TIME [epoch: 28 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.317932985255057		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.317932985255057 | validation: 0.34818476205925825]
	TIME [epoch: 28.1 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3032230487887091		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.3032230487887091 | validation: 0.2766960703587549]
	TIME [epoch: 28 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2710423271151511		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.2710423271151511 | validation: 0.3051115981169908]
	TIME [epoch: 28.1 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2796582685228907		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.2796582685228907 | validation: 0.3318700984925417]
	TIME [epoch: 28.1 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27307106169125334		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.27307106169125334 | validation: 0.289781895966729]
	TIME [epoch: 28.1 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2569616075792034		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.2569616075792034 | validation: 0.26505423672690137]
	TIME [epoch: 28.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_1200.pth
	Model improved!!!
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2861654222924042		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.2861654222924042 | validation: 0.3150865600882644]
	TIME [epoch: 28 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2930345765663317		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.2930345765663317 | validation: 0.30545043198046956]
	TIME [epoch: 28.1 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2880051843408947		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.2880051843408947 | validation: 0.2866714714115574]
	TIME [epoch: 28.1 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2909182325060031		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.2909182325060031 | validation: 0.3059504069752598]
	TIME [epoch: 28 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2960883698232909		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.2960883698232909 | validation: 0.312222971342714]
	TIME [epoch: 28.1 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29359047521204723		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.29359047521204723 | validation: 0.3291213840680898]
	TIME [epoch: 28 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32147129169543376		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.32147129169543376 | validation: 0.3401004893605512]
	TIME [epoch: 28 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35918116600700467		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.35918116600700467 | validation: 0.3593066508247263]
	TIME [epoch: 28.1 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37218523517198865		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.37218523517198865 | validation: 0.3169459562547669]
	TIME [epoch: 28 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3198050860216251		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.3198050860216251 | validation: 0.312019855142855]
	TIME [epoch: 28.1 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2946247185261861		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.2946247185261861 | validation: 0.27721279181551084]
	TIME [epoch: 28.1 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29092185615451077		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.29092185615451077 | validation: 0.31547668022435027]
	TIME [epoch: 28 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30926914779824316		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.30926914779824316 | validation: 0.28456542790295025]
	TIME [epoch: 28.1 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28799289716305126		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.28799289716305126 | validation: 0.31884091755655264]
	TIME [epoch: 28 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3036461666567376		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.3036461666567376 | validation: 0.30491637315068426]
	TIME [epoch: 28.1 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2758282182702591		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.2758282182702591 | validation: 0.2800392636620237]
	TIME [epoch: 28.1 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27185441167016544		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.27185441167016544 | validation: 0.2962935756097852]
	TIME [epoch: 28.1 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2608938352645266		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.2608938352645266 | validation: 0.343808378632295]
	TIME [epoch: 28.1 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31065547896599005		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.31065547896599005 | validation: 0.37942287384158546]
	TIME [epoch: 28 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32271594326489594		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.32271594326489594 | validation: 0.27527198382039086]
	TIME [epoch: 28.1 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26277089461239567		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.26277089461239567 | validation: 0.2718422329541367]
	TIME [epoch: 28.1 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2633899311435719		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.2633899311435719 | validation: 0.2661888956283392]
	TIME [epoch: 28 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26043562705631734		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.26043562705631734 | validation: 0.2730074946345117]
	TIME [epoch: 28.1 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2658512355337829		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.2658512355337829 | validation: 0.2739513245693055]
	TIME [epoch: 28 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2725842423227041		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.2725842423227041 | validation: 0.27868251393348153]
	TIME [epoch: 28.1 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2759777876077453		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.2759777876077453 | validation: 0.3544087926425236]
	TIME [epoch: 28.1 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2806855361803914		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.2806855361803914 | validation: 0.34139722992607596]
	TIME [epoch: 28.1 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30836822559529503		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.30836822559529503 | validation: 0.35843818093844576]
	TIME [epoch: 28.1 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2933618134919649		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.2933618134919649 | validation: 0.3266024893638602]
	TIME [epoch: 28.1 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26456095292747867		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.26456095292747867 | validation: 0.2990524436237995]
	TIME [epoch: 28.1 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27392150926080217		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.27392150926080217 | validation: 0.2741009434926606]
	TIME [epoch: 28 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2569259793045817		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.2569259793045817 | validation: 0.31960068279936726]
	TIME [epoch: 28 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26882861299130145		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.26882861299130145 | validation: 0.3382041885996156]
	TIME [epoch: 28 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25401094861710916		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.25401094861710916 | validation: 0.2874246824673154]
	TIME [epoch: 28 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24790259944850895		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.24790259944850895 | validation: 0.2723885934373484]
	TIME [epoch: 28 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2528267399969656		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.2528267399969656 | validation: 0.28010101893023076]
	TIME [epoch: 28 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25418920126286515		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.25418920126286515 | validation: 0.3336567798486024]
	TIME [epoch: 28 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2742371430288548		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.2742371430288548 | validation: 0.3710678436510358]
	TIME [epoch: 28 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2863467707980457		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.2863467707980457 | validation: 0.3578126085892254]
	TIME [epoch: 28 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29608113279107295		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.29608113279107295 | validation: 0.40795964354602965]
	TIME [epoch: 28 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3048634136555442		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.3048634136555442 | validation: 0.35798970339042996]
	TIME [epoch: 28 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2798019970542816		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.2798019970542816 | validation: 0.36242924637146173]
	TIME [epoch: 28 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.295634700868293		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.295634700868293 | validation: 0.4385837690513834]
	TIME [epoch: 28 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3287866953465765		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.3287866953465765 | validation: 0.37455974696896976]
	TIME [epoch: 28 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.279101643419841		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.279101643419841 | validation: 0.34884376974618764]
	TIME [epoch: 28 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24801913818199361		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.24801913818199361 | validation: 0.29822175409629575]
	TIME [epoch: 28 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2601964190098286		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.2601964190098286 | validation: 0.29654894283439104]
	TIME [epoch: 28.1 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2707265924862725		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.2707265924862725 | validation: 0.2873238938837464]
	TIME [epoch: 28.1 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2664838893408199		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.2664838893408199 | validation: 0.2989963512619478]
	TIME [epoch: 28.1 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2687569067490315		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.2687569067490315 | validation: 0.30859848770892656]
	TIME [epoch: 28 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26085728404412595		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.26085728404412595 | validation: 0.3594005006823977]
	TIME [epoch: 28 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2610461914843275		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.2610461914843275 | validation: 0.3484495468822148]
	TIME [epoch: 28 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27731667014998984		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.27731667014998984 | validation: 0.3559084640119079]
	TIME [epoch: 28 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27426641969294263		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.27426641969294263 | validation: 0.32029721578838394]
	TIME [epoch: 28.1 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24681254384249376		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.24681254384249376 | validation: 0.27973261790714815]
	TIME [epoch: 28 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24866647847243803		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.24866647847243803 | validation: 0.2771718925524604]
	TIME [epoch: 28.1 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24642212326611787		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.24642212326611787 | validation: 0.2929972474801817]
	TIME [epoch: 28 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2810461329759648		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.2810461329759648 | validation: 0.3077059058048655]
	TIME [epoch: 28.1 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2741495040331672		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.2741495040331672 | validation: 0.2951825915054731]
	TIME [epoch: 28.1 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24360704575223885		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.24360704575223885 | validation: 0.3193956027797466]
	TIME [epoch: 28 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2642549639552367		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.2642549639552367 | validation: 0.31191901082345924]
	TIME [epoch: 28 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25124892672390453		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.25124892672390453 | validation: 0.30145790970145236]
	TIME [epoch: 28 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24102929773376208		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.24102929773376208 | validation: 0.2885993332600011]
	TIME [epoch: 28 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23944060560009145		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.23944060560009145 | validation: 0.2966897086906501]
	TIME [epoch: 28.1 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24202340414608794		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.24202340414608794 | validation: 0.3088763659734696]
	TIME [epoch: 28 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25514375638232417		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.25514375638232417 | validation: 0.2965030753786036]
	TIME [epoch: 28 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2669567810292369		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.2669567810292369 | validation: 0.27540532781434496]
	TIME [epoch: 28 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23844331423434134		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.23844331423434134 | validation: 0.28236497043874]
	TIME [epoch: 28 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24848370321676605		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.24848370321676605 | validation: 0.32633859006713534]
	TIME [epoch: 28 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25000240719157585		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.25000240719157585 | validation: 0.34169304527184574]
	TIME [epoch: 28.1 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26352463051284725		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.26352463051284725 | validation: 0.3909912833351763]
	TIME [epoch: 28.1 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26904861026941695		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.26904861026941695 | validation: 0.3315469345507631]
	TIME [epoch: 28.1 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2464703356194462		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.2464703356194462 | validation: 0.29219234177965475]
	TIME [epoch: 28 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25570440668644256		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.25570440668644256 | validation: 0.30715592378269724]
	TIME [epoch: 28.1 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24907769969401922		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.24907769969401922 | validation: 0.287834377477274]
	TIME [epoch: 28 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2699788301894619		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.2699788301894619 | validation: 0.28041710203809295]
	TIME [epoch: 28 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2511864807532649		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.2511864807532649 | validation: 0.2761395654184045]
	TIME [epoch: 28.1 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2469237138745938		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.2469237138745938 | validation: 0.2954163147747781]
	TIME [epoch: 28 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2804285819784629		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.2804285819784629 | validation: 0.3370616407196272]
	TIME [epoch: 28 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3313152474873287		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.3313152474873287 | validation: 0.31776192873470605]
	TIME [epoch: 28.1 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3274957494832912		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.3274957494832912 | validation: 0.37716298538156756]
	TIME [epoch: 28 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33651775856709454		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.33651775856709454 | validation: 0.3000917962234487]
	TIME [epoch: 28.1 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2776440797414371		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.2776440797414371 | validation: 0.2794862798693216]
	TIME [epoch: 28 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2675401669861627		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.2675401669861627 | validation: 0.292714433931846]
	TIME [epoch: 28 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2595575487942082		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.2595575487942082 | validation: 0.27766789178178763]
	TIME [epoch: 28.1 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24745368770384762		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.24745368770384762 | validation: 0.3056635425914352]
	TIME [epoch: 28 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23853416180623602		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.23853416180623602 | validation: 0.28340515246601045]
	TIME [epoch: 28 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23203018851779397		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.23203018851779397 | validation: 0.27867640594394616]
	TIME [epoch: 28 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23844186716730392		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.23844186716730392 | validation: 0.32396760986718165]
	TIME [epoch: 28 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25666311975079475		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.25666311975079475 | validation: 0.3543522513336454]
	TIME [epoch: 28 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2818211531416992		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.2818211531416992 | validation: 0.3570405776310272]
	TIME [epoch: 28 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25731985275730596		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.25731985275730596 | validation: 0.300770217276352]
	TIME [epoch: 28 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24470749851784235		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.24470749851784235 | validation: 0.31613018314866537]
	TIME [epoch: 28 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25034179054939376		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.25034179054939376 | validation: 0.3128342999361897]
	TIME [epoch: 28 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26014669869559026		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.26014669869559026 | validation: 0.3207362779144819]
	TIME [epoch: 28 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2725559755371033		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.2725559755371033 | validation: 0.34103643330584094]
	TIME [epoch: 28 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2747619318596275		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.2747619318596275 | validation: 0.385025035620249]
	TIME [epoch: 28 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2764950221529602		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.2764950221529602 | validation: 0.348096590801717]
	TIME [epoch: 28 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2816251821469255		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.2816251821469255 | validation: 0.37201347966501275]
	TIME [epoch: 28.1 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26846294117903774		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.26846294117903774 | validation: 0.3545806836745154]
	TIME [epoch: 28.1 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26693725578081057		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.26693725578081057 | validation: 0.33103956491361963]
	TIME [epoch: 28 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2706472082498044		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.2706472082498044 | validation: 0.3446466557043422]
	TIME [epoch: 28.1 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2770954619614462		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.2770954619614462 | validation: 0.3739066070995446]
	TIME [epoch: 28 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2843704153574353		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.2843704153574353 | validation: 0.3542618170984024]
	TIME [epoch: 28 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2800601639768922		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.2800601639768922 | validation: 0.3463027623228366]
	TIME [epoch: 28 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26333054450344845		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.26333054450344845 | validation: 0.32586028825364993]
	TIME [epoch: 28.1 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2409968903676399		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.2409968903676399 | validation: 0.29847916751303377]
	TIME [epoch: 28 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24275617704463648		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.24275617704463648 | validation: 0.29867214599037384]
	TIME [epoch: 28.1 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2403676206465054		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.2403676206465054 | validation: 0.2837125092053027]
	TIME [epoch: 28 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2302778556585143		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.2302778556585143 | validation: 0.28886161786544123]
	TIME [epoch: 28 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23969266192206184		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.23969266192206184 | validation: 0.28699295951753095]
	TIME [epoch: 28 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2590984454028167		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.2590984454028167 | validation: 0.29076590326340573]
	TIME [epoch: 28 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2737568558978302		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.2737568558978302 | validation: 0.29715722400969646]
	TIME [epoch: 28 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29297860259292685		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.29297860259292685 | validation: 0.32188152828989675]
	TIME [epoch: 28 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3125715785380828		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.3125715785380828 | validation: 0.30249960647430685]
	TIME [epoch: 28 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2739090032669532		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.2739090032669532 | validation: 0.29900656984917745]
	TIME [epoch: 27.9 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2588861011054655		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.2588861011054655 | validation: 0.30424436984066944]
	TIME [epoch: 28 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3145869351176589		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.3145869351176589 | validation: 0.33011033015158014]
	TIME [epoch: 28 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31957934391639825		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.31957934391639825 | validation: 0.29289656486047594]
	TIME [epoch: 28 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2703908733655228		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.2703908733655228 | validation: 0.2906934877921102]
	TIME [epoch: 28 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2779977946344907		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.2779977946344907 | validation: 0.31322729256818194]
	TIME [epoch: 28 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31136564593199323		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.31136564593199323 | validation: 0.2925823972512945]
	TIME [epoch: 28 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2578437105759224		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.2578437105759224 | validation: 0.2750513286238178]
	TIME [epoch: 28 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24101135633079604		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.24101135633079604 | validation: 0.2843380123858549]
	TIME [epoch: 28 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2558924505056191		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.2558924505056191 | validation: 0.28099164633196316]
	TIME [epoch: 28 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2636335221852348		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.2636335221852348 | validation: 0.2880299927653846]
	TIME [epoch: 28 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2583665380735014		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.2583665380735014 | validation: 0.2845625149693255]
	TIME [epoch: 28 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2527084403859834		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.2527084403859834 | validation: 0.27766375215534667]
	TIME [epoch: 28 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24925554393044955		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.24925554393044955 | validation: 0.2841271937551152]
	TIME [epoch: 28 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2980648319291433		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.2980648319291433 | validation: 0.3136008640950885]
	TIME [epoch: 28 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31883822991802346		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.31883822991802346 | validation: 0.3287840090215532]
	TIME [epoch: 28 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.309718407224095		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.309718407224095 | validation: 0.32309160384233593]
	TIME [epoch: 28 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3159057591352461		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.3159057591352461 | validation: 0.31772444753441736]
	TIME [epoch: 28 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3100272918420651		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.3100272918420651 | validation: 0.31097451971035733]
	TIME [epoch: 28 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2907378377273602		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.2907378377273602 | validation: 0.2959557400580048]
	TIME [epoch: 28 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2780746550925263		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.2780746550925263 | validation: 0.3004139656264917]
	TIME [epoch: 28.1 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30110519668760566		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.30110519668760566 | validation: 0.28050591061622815]
	TIME [epoch: 28 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27390560404483744		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.27390560404483744 | validation: 0.2905561087351073]
	TIME [epoch: 28.1 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29117838413569014		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.29117838413569014 | validation: 0.29634811194621674]
	TIME [epoch: 28 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2839670590793763		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.2839670590793763 | validation: 0.30284458131139397]
	TIME [epoch: 28 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2958642681063496		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.2958642681063496 | validation: 0.3109087124099241]
	TIME [epoch: 28 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26487383275376636		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.26487383275376636 | validation: 0.3075717843837646]
	TIME [epoch: 28 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28960335388216657		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.28960335388216657 | validation: 0.3548745865988859]
	TIME [epoch: 28 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2998287468210775		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.2998287468210775 | validation: 0.3611587232718246]
	TIME [epoch: 28 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29952523478067117		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.29952523478067117 | validation: 0.32631407638144494]
	TIME [epoch: 27.9 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27341322657239536		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.27341322657239536 | validation: 0.31011657215381505]
	TIME [epoch: 27.9 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2906397824952542		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.2906397824952542 | validation: 0.32345474135064967]
	TIME [epoch: 27.9 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2871747091289843		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.2871747091289843 | validation: 0.3094688922485581]
	TIME [epoch: 28 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26498456137809867		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.26498456137809867 | validation: 0.3195700660168131]
	TIME [epoch: 28 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27034946810929616		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.27034946810929616 | validation: 0.29627403355722337]
	TIME [epoch: 28 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26241755558189206		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.26241755558189206 | validation: 0.3122229751974563]
	TIME [epoch: 28 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25697232170245304		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.25697232170245304 | validation: 0.31297604283268693]
	TIME [epoch: 28 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27833921545839135		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.27833921545839135 | validation: 0.30100593455324914]
	TIME [epoch: 28 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25753401298911394		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.25753401298911394 | validation: 0.2972724933429457]
	TIME [epoch: 28.1 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26844838818401684		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.26844838818401684 | validation: 0.29945580409186]
	TIME [epoch: 28 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2549895546012884		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.2549895546012884 | validation: 0.2991389208241803]
	TIME [epoch: 28 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2648177443000686		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.2648177443000686 | validation: 0.2986660292224843]
	TIME [epoch: 28 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26866629365511036		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.26866629365511036 | validation: 0.31631350130541874]
	TIME [epoch: 28 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2653800892305688		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.2653800892305688 | validation: 0.2902773892996007]
	TIME [epoch: 28 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2582851312439449		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.2582851312439449 | validation: 0.2903287931267843]
	TIME [epoch: 28.1 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23418027354922125		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.23418027354922125 | validation: 0.2922207476317689]
	TIME [epoch: 28.1 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23253328114743832		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.23253328114743832 | validation: 0.2823465905808284]
	TIME [epoch: 28.1 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24153734485097084		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.24153734485097084 | validation: 0.2806646300058512]
	TIME [epoch: 28.1 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24539725327156492		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.24539725327156492 | validation: 0.30007680960781835]
	TIME [epoch: 28 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27228926688547567		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.27228926688547567 | validation: 0.3133401331391157]
	TIME [epoch: 28 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2598263464544579		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.2598263464544579 | validation: 0.2943615456080421]
	TIME [epoch: 28.1 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24752033596794898		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.24752033596794898 | validation: 0.28945469267637314]
	TIME [epoch: 28.1 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2529934530246624		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.2529934530246624 | validation: 0.29361752776238903]
	TIME [epoch: 28.1 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24825302494852575		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.24825302494852575 | validation: 0.33345032847355316]
	TIME [epoch: 28 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2625096115799806		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.2625096115799806 | validation: 0.3477866991144522]
	TIME [epoch: 28 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2770223101058245		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.2770223101058245 | validation: 0.32625018489303853]
	TIME [epoch: 28 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2662081051359981		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.2662081051359981 | validation: 0.32588498054851855]
	TIME [epoch: 28 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24772421989464152		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.24772421989464152 | validation: 0.311921000230657]
	TIME [epoch: 28 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24988968038491632		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.24988968038491632 | validation: 0.3290579177661175]
	TIME [epoch: 28 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24400876539575497		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.24400876539575497 | validation: 0.29476777580996816]
	TIME [epoch: 28 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23258626963528584		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.23258626963528584 | validation: 0.2852850602325484]
	TIME [epoch: 28 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2432847476388723		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.2432847476388723 | validation: 0.2881618248841886]
	TIME [epoch: 28 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24762330934855034		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.24762330934855034 | validation: 0.2982617737339406]
	TIME [epoch: 28 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25629158748526315		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.25629158748526315 | validation: 0.2851109982653287]
	TIME [epoch: 28 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26035582616976444		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.26035582616976444 | validation: 0.316316870132639]
	TIME [epoch: 28 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2898950071171919		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.2898950071171919 | validation: 0.3048955039521663]
	TIME [epoch: 28 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.293599052356587		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.293599052356587 | validation: 0.34276305212996383]
	TIME [epoch: 28 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3349172274084269		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.3349172274084269 | validation: 0.37735962039270676]
	TIME [epoch: 28 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3717558097573887		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.3717558097573887 | validation: 0.335560426524404]
	TIME [epoch: 28 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2792385717606457		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.2792385717606457 | validation: 0.29269767729247315]
	TIME [epoch: 28 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26825815157553734		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.26825815157553734 | validation: 0.27377523797151]
	TIME [epoch: 28 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2518148027876731		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.2518148027876731 | validation: 0.2802217402547649]
	TIME [epoch: 28 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2353664068015161		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.2353664068015161 | validation: 0.29975578784014]
	TIME [epoch: 28 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2419734893706137		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.2419734893706137 | validation: 0.3196748503616733]
	TIME [epoch: 28 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2611449231570235		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.2611449231570235 | validation: 0.33325407554632314]
	TIME [epoch: 28 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24498313369295455		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.24498313369295455 | validation: 0.34108805621837995]
	TIME [epoch: 28 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24656323834468113		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.24656323834468113 | validation: 0.30122473955911616]
	TIME [epoch: 28 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22906509615850212		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.22906509615850212 | validation: 0.2778253750344484]
	TIME [epoch: 28 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23809935168568908		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.23809935168568908 | validation: 0.2656028880247547]
	TIME [epoch: 28 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2321765843110253		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.2321765843110253 | validation: 0.27069885340662114]
	TIME [epoch: 28 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23834180302055324		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.23834180302055324 | validation: 0.28377364398669996]
	TIME [epoch: 28 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24710723971364285		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.24710723971364285 | validation: 0.28260858711561554]
	TIME [epoch: 28 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23571278541848792		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.23571278541848792 | validation: 0.2795624612582812]
	TIME [epoch: 28 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23757597146129442		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.23757597146129442 | validation: 0.2796281867948566]
	TIME [epoch: 28.1 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22771226956335075		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.22771226956335075 | validation: 0.2741586758016906]
	TIME [epoch: 28.1 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.239370110985947		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.239370110985947 | validation: 0.26467264182349515]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_1401.pth
	Model improved!!!
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25261047787513324		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.25261047787513324 | validation: 0.2845563285862627]
	TIME [epoch: 28 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26698364525205565		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.26698364525205565 | validation: 0.2905091597817728]
	TIME [epoch: 28 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29110220500700756		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.29110220500700756 | validation: 0.30281874559207234]
	TIME [epoch: 28.1 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2990067145343537		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.2990067145343537 | validation: 0.31674542889267093]
	TIME [epoch: 28.1 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3005955112510035		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.3005955112510035 | validation: 0.3150076237307703]
	TIME [epoch: 28 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.295989855536399		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.295989855536399 | validation: 0.30852305171158656]
	TIME [epoch: 28.1 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27948717651073934		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.27948717651073934 | validation: 0.30405126780073277]
	TIME [epoch: 28 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26313143242645065		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.26313143242645065 | validation: 0.31173095673018425]
	TIME [epoch: 28 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2662964819658875		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.2662964819658875 | validation: 0.30561418890606423]
	TIME [epoch: 28.1 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25427915222316677		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.25427915222316677 | validation: 0.30077526462127013]
	TIME [epoch: 28 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2551127174999983		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.2551127174999983 | validation: 0.3005611475967327]
	TIME [epoch: 28.1 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25243341805303954		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.25243341805303954 | validation: 0.29873849015846077]
	TIME [epoch: 28 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24108955050657796		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.24108955050657796 | validation: 0.3020104309939835]
	TIME [epoch: 28 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24864446144220015		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.24864446144220015 | validation: 0.28580746108606636]
	TIME [epoch: 28 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2537076460155319		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.2537076460155319 | validation: 0.2882746658212214]
	TIME [epoch: 28 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2680012485214375		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.2680012485214375 | validation: 0.2771724777227732]
	TIME [epoch: 28 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2514554890784236		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.2514554890784236 | validation: 0.30071258905151477]
	TIME [epoch: 28.1 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23800821815544512		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.23800821815544512 | validation: 0.29081658435951613]
	TIME [epoch: 28 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23581663147965143		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.23581663147965143 | validation: 0.3068811086760777]
	TIME [epoch: 28.1 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24065956223780732		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.24065956223780732 | validation: 0.30995523078065607]
	TIME [epoch: 28 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23917676528681764		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.23917676528681764 | validation: 0.30071115973392487]
	TIME [epoch: 28 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22569989813846167		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.22569989813846167 | validation: 0.2877190172988474]
	TIME [epoch: 28 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23235979078947994		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.23235979078947994 | validation: 0.30274624562195235]
	TIME [epoch: 28 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24464748722410956		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.24464748722410956 | validation: 0.34866408069127874]
	TIME [epoch: 28 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2686172967789471		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.2686172967789471 | validation: 0.35492106729828954]
	TIME [epoch: 28 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2671092117789437		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.2671092117789437 | validation: 0.3380696937630877]
	TIME [epoch: 28.1 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2517703061267446		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.2517703061267446 | validation: 0.3105204233174772]
	TIME [epoch: 28.1 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2405263591900174		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.2405263591900174 | validation: 0.330596297992427]
	TIME [epoch: 28 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24738242954975392		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.24738242954975392 | validation: 0.32343182997452913]
	TIME [epoch: 28 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23982476322090557		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.23982476322090557 | validation: 0.29205513922795573]
	TIME [epoch: 28 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23221745148819015		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.23221745148819015 | validation: 0.2838199709037299]
	TIME [epoch: 28 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23688989402438987		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.23688989402438987 | validation: 0.2863129960087368]
	TIME [epoch: 28 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24525024762687436		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.24525024762687436 | validation: 0.2968103975249799]
	TIME [epoch: 28 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23274598656872664		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.23274598656872664 | validation: 0.29928803828581424]
	TIME [epoch: 28 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24052584413723965		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.24052584413723965 | validation: 0.28281277992775966]
	TIME [epoch: 28 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23798159917743109		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.23798159917743109 | validation: 0.2874611317518036]
	TIME [epoch: 28.1 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.235831238795487		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.235831238795487 | validation: 0.2808836216804293]
	TIME [epoch: 28 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23602138832123853		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.23602138832123853 | validation: 0.2807166852974914]
	TIME [epoch: 28 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23650691888327174		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.23650691888327174 | validation: 0.2739003303910206]
	TIME [epoch: 28 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23881234391315195		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.23881234391315195 | validation: 0.2794890169038281]
	TIME [epoch: 28.1 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23180778554515663		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.23180778554515663 | validation: 0.2845764018549996]
	TIME [epoch: 28 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2342879151486122		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.2342879151486122 | validation: 0.29682462804517695]
	TIME [epoch: 28.1 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2383784629445878		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.2383784629445878 | validation: 0.28303454798002436]
	TIME [epoch: 28 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22894629930203297		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.22894629930203297 | validation: 0.27624758186095866]
	TIME [epoch: 28 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22725889773697824		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.22725889773697824 | validation: 0.2898086343240046]
	TIME [epoch: 28 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23338414294719537		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.23338414294719537 | validation: 0.30210613131590036]
	TIME [epoch: 28 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23627512300650033		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.23627512300650033 | validation: 0.28677810937583137]
	TIME [epoch: 28 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22405601904522887		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.22405601904522887 | validation: 0.2848132113689601]
	TIME [epoch: 28 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22925513983265441		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.22925513983265441 | validation: 0.2799965326999612]
	TIME [epoch: 28 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23220966109772007		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.23220966109772007 | validation: 0.2782443507987458]
	TIME [epoch: 28 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23022161981919634		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.23022161981919634 | validation: 0.2925375227656655]
	TIME [epoch: 28 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24016528098938184		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.24016528098938184 | validation: 0.3104034474439347]
	TIME [epoch: 28 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24442627281419288		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.24442627281419288 | validation: 0.29429838655643403]
	TIME [epoch: 28 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24239981295006485		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.24239981295006485 | validation: 0.31278746638068855]
	TIME [epoch: 28.1 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24166551196214092		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.24166551196214092 | validation: 0.34456709091726717]
	TIME [epoch: 28.1 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24622939662488563		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.24622939662488563 | validation: 0.3231355446485748]
	TIME [epoch: 28 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2382831278483397		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.2382831278483397 | validation: 0.3165212312632123]
	TIME [epoch: 28 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2379444658195799		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.2379444658195799 | validation: 0.31911099143060867]
	TIME [epoch: 28.1 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24038533364648856		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.24038533364648856 | validation: 0.3281866326298926]
	TIME [epoch: 28 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24284020085587554		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.24284020085587554 | validation: 0.3104233091354113]
	TIME [epoch: 28.1 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23728694580780813		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.23728694580780813 | validation: 0.28879379549026096]
	TIME [epoch: 28 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2360988244578746		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.2360988244578746 | validation: 0.28061318577165417]
	TIME [epoch: 28.1 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23305688956492768		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.23305688956492768 | validation: 0.27101972524722584]
	TIME [epoch: 28 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2408350347398266		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.2408350347398266 | validation: 0.32153226405230084]
	TIME [epoch: 28.1 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.261839939935509		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.261839939935509 | validation: 0.31028319577995883]
	TIME [epoch: 28.1 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2431357742688035		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.2431357742688035 | validation: 0.31046191066582723]
	TIME [epoch: 28 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24714644171835104		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.24714644171835104 | validation: 0.3136377361808579]
	TIME [epoch: 28 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2420976851738571		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.2420976851738571 | validation: 0.32910978197001667]
	TIME [epoch: 28.1 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24620043207525627		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.24620043207525627 | validation: 0.31799631209496765]
	TIME [epoch: 28 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2514099761183673		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.2514099761183673 | validation: 0.31386455210155895]
	TIME [epoch: 28.1 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2461692486715794		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.2461692486715794 | validation: 0.3179133360885867]
	TIME [epoch: 28 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25070968411501043		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.25070968411501043 | validation: 0.30084553778338136]
	TIME [epoch: 28 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24409258420584573		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.24409258420584573 | validation: 0.28973280929653894]
	TIME [epoch: 28 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2478359857869315		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.2478359857869315 | validation: 0.2931084418363535]
	TIME [epoch: 28 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2568163228967899		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.2568163228967899 | validation: 0.2788221117608684]
	TIME [epoch: 28.1 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2589549547109526		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.2589549547109526 | validation: 0.28991868481512617]
	TIME [epoch: 28 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25382668971715866		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.25382668971715866 | validation: 0.27447995605127723]
	TIME [epoch: 28 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25088178033390096		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.25088178033390096 | validation: 0.2887038014682848]
	TIME [epoch: 28 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2457189123555151		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.2457189123555151 | validation: 0.2714441801039801]
	TIME [epoch: 28 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2415421620080671		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.2415421620080671 | validation: 0.2936630030590087]
	TIME [epoch: 28.1 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24410594697485333		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.24410594697485333 | validation: 0.275471481052379]
	TIME [epoch: 28.1 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2325960567031572		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.2325960567031572 | validation: 0.2841036329091418]
	TIME [epoch: 28.1 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2343604587934057		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.2343604587934057 | validation: 0.28615453713208155]
	TIME [epoch: 28.1 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23733138078467647		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.23733138078467647 | validation: 0.28049433781953]
	TIME [epoch: 28 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22930471289593335		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.22930471289593335 | validation: 0.29463183560215733]
	TIME [epoch: 28 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2324597719857654		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.2324597719857654 | validation: 0.29860179382387647]
	TIME [epoch: 28 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23557212746559392		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.23557212746559392 | validation: 0.3004757158305387]
	TIME [epoch: 28 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2283339713480612		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.2283339713480612 | validation: 0.2852129670307336]
	TIME [epoch: 28.1 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23375311136267515		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.23375311136267515 | validation: 0.2679720541209541]
	TIME [epoch: 28 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24527316049530773		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.24527316049530773 | validation: 0.2811535201206188]
	TIME [epoch: 28 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2465549479340635		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.2465549479340635 | validation: 0.2853915010780343]
	TIME [epoch: 28 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24523442371659177		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.24523442371659177 | validation: 0.27822493144860067]
	TIME [epoch: 28 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.253610763174824		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.253610763174824 | validation: 0.2729906384072555]
	TIME [epoch: 28.1 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23686841583732196		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.23686841583732196 | validation: 0.27658131907117894]
	TIME [epoch: 28 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23166328407303566		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.23166328407303566 | validation: 0.2910585203455605]
	TIME [epoch: 28 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24535834009435498		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.24535834009435498 | validation: 0.2827894475785994]
	TIME [epoch: 28.1 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2388613332832656		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.2388613332832656 | validation: 0.2935403788723468]
	TIME [epoch: 28 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23432531740381085		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.23432531740381085 | validation: 0.30149982996496205]
	TIME [epoch: 28.1 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24381706281436138		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.24381706281436138 | validation: 0.3029066442235836]
	TIME [epoch: 28 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23994957714278128		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.23994957714278128 | validation: 0.31529989045334283]
	TIME [epoch: 28.1 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2405932447651827		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.2405932447651827 | validation: 0.29300709514467516]
	TIME [epoch: 28.1 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2423227638824716		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.2423227638824716 | validation: 0.29201688861284797]
	TIME [epoch: 28 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23619715165015975		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.23619715165015975 | validation: 0.2978873665355711]
	TIME [epoch: 28.1 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23391869123875372		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.23391869123875372 | validation: 0.2783149222163977]
	TIME [epoch: 28 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23805546129523023		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.23805546129523023 | validation: 0.27364253647190134]
	TIME [epoch: 28 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23220833514735387		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.23220833514735387 | validation: 0.2958607130425838]
	TIME [epoch: 28 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2290685437301243		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.2290685437301243 | validation: 0.2967376521363575]
	TIME [epoch: 28 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.224740534432443		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.224740534432443 | validation: 0.2896982599843496]
	TIME [epoch: 28.1 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22581053427597936		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.22581053427597936 | validation: 0.29818387987251443]
	TIME [epoch: 28 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22392697591134614		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.22392697591134614 | validation: 0.27866395657815546]
	TIME [epoch: 28 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23833350500793635		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.23833350500793635 | validation: 0.27843423787577803]
	TIME [epoch: 28 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2428986946750794		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.2428986946750794 | validation: 0.28168274170396296]
	TIME [epoch: 28 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26039705844110694		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.26039705844110694 | validation: 0.28646781614820976]
	TIME [epoch: 28.1 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25182398531216504		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.25182398531216504 | validation: 0.292825381433097]
	TIME [epoch: 28 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27037294831305286		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.27037294831305286 | validation: 0.2950344801271671]
	TIME [epoch: 28 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2687151506176988		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.2687151506176988 | validation: 0.28097019357241365]
	TIME [epoch: 28.1 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26330282669391725		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.26330282669391725 | validation: 0.2818568755917715]
	TIME [epoch: 28 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2420944554179012		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.2420944554179012 | validation: 0.2974021755347447]
	TIME [epoch: 28 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24616409399995764		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.24616409399995764 | validation: 0.2915616595774186]
	TIME [epoch: 28 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2407657568728187		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.2407657568728187 | validation: 0.2996467438816883]
	TIME [epoch: 28 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23760340696769716		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.23760340696769716 | validation: 0.2908492774170668]
	TIME [epoch: 28 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25129975039078983		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.25129975039078983 | validation: 0.2841033827630296]
	TIME [epoch: 28 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24792808030045205		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.24792808030045205 | validation: 0.28883893142384837]
	TIME [epoch: 28.1 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24020343802070276		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.24020343802070276 | validation: 0.2951660220923877]
	TIME [epoch: 28.1 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23610802908181835		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.23610802908181835 | validation: 0.2946550920986068]
	TIME [epoch: 28 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23678922884236547		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.23678922884236547 | validation: 0.28909559705807414]
	TIME [epoch: 28.1 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24722494877349804		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.24722494877349804 | validation: 0.2960010383245777]
	TIME [epoch: 28 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23536955663514753		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.23536955663514753 | validation: 0.27787974846517594]
	TIME [epoch: 28 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2298768470277668		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.2298768470277668 | validation: 0.2700183759837457]
	TIME [epoch: 28 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2458199218409424		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.2458199218409424 | validation: 0.2758976596227652]
	TIME [epoch: 28.1 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24460780336622248		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.24460780336622248 | validation: 0.2811370245981672]
	TIME [epoch: 28 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24276129732292961		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.24276129732292961 | validation: 0.29272503438499425]
	TIME [epoch: 28 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24761051148191454		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.24761051148191454 | validation: 0.2908581075481939]
	TIME [epoch: 28 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2538550190089613		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.2538550190089613 | validation: 0.27763126156167944]
	TIME [epoch: 28 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2461500479286846		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.2461500479286846 | validation: 0.2884105386867345]
	TIME [epoch: 28 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24471690902492502		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.24471690902492502 | validation: 0.29181751931720046]
	TIME [epoch: 28 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2496258077980839		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.2496258077980839 | validation: 0.28508270172208255]
	TIME [epoch: 28 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2570481304339467		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.2570481304339467 | validation: 0.3039095554644966]
	TIME [epoch: 28 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2441310344476015		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.2441310344476015 | validation: 0.2963294572882387]
	TIME [epoch: 28 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24920851202466832		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.24920851202466832 | validation: 0.3148527869516295]
	TIME [epoch: 28 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.252981716845578		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.252981716845578 | validation: 0.32177529918022457]
	TIME [epoch: 28 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2511341236346887		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.2511341236346887 | validation: 0.3231385929859671]
	TIME [epoch: 28 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2552868020825107		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.2552868020825107 | validation: 0.3355548624570653]
	TIME [epoch: 28 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24697271390340336		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.24697271390340336 | validation: 0.31611326053746475]
	TIME [epoch: 28 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24622186879128238		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.24622186879128238 | validation: 0.32186021212474236]
	TIME [epoch: 28 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24105051265893696		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.24105051265893696 | validation: 0.312072609068612]
	TIME [epoch: 28.1 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.242623826091033		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.242623826091033 | validation: 0.3172449930084865]
	TIME [epoch: 28.1 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23915467364819754		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.23915467364819754 | validation: 0.2939001286730014]
	TIME [epoch: 28 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22767651876579353		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.22767651876579353 | validation: 0.2873865816594543]
	TIME [epoch: 28.1 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23027396889370905		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.23027396889370905 | validation: 0.3120042220639994]
	TIME [epoch: 28 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2330667640782163		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.2330667640782163 | validation: 0.31574526372765993]
	TIME [epoch: 28 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24333167021741897		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.24333167021741897 | validation: 0.34052672754479313]
	TIME [epoch: 28 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23960163650320887		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.23960163650320887 | validation: 0.32557492984204944]
	TIME [epoch: 28 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23847133571349777		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.23847133571349777 | validation: 0.3120325033842725]
	TIME [epoch: 28 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24037218031108654		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.24037218031108654 | validation: 0.3017693586626816]
	TIME [epoch: 28 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23257046754826588		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.23257046754826588 | validation: 0.289625536974972]
	TIME [epoch: 28 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22672131138086135		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.22672131138086135 | validation: 0.3042754607719719]
	TIME [epoch: 28.1 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24189784377334267		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.24189784377334267 | validation: 0.29668260833455984]
	TIME [epoch: 28 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23379896179403506		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.23379896179403506 | validation: 0.32186182916469547]
	TIME [epoch: 28 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24194791880753072		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.24194791880753072 | validation: 0.3294688705115238]
	TIME [epoch: 28 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24143969392382283		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.24143969392382283 | validation: 0.3041815982617989]
	TIME [epoch: 28 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23713260011090573		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.23713260011090573 | validation: 0.3189939074676713]
	TIME [epoch: 28 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24522716923815785		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.24522716923815785 | validation: 0.333444427911871]
	TIME [epoch: 28 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2409967475434267		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.2409967475434267 | validation: 0.33676807440812684]
	TIME [epoch: 28 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2505398605667125		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.2505398605667125 | validation: 0.33700870327551513]
	TIME [epoch: 28 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25737210893096263		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.25737210893096263 | validation: 0.34815133012997834]
	TIME [epoch: 28 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2689920188233167		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.2689920188233167 | validation: 0.3626328262806851]
	TIME [epoch: 28 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27135227538247286		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.27135227538247286 | validation: 0.3764687772979552]
	TIME [epoch: 28 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2686208855938667		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.2686208855938667 | validation: 0.3577091120623898]
	TIME [epoch: 28.1 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25821934217978904		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.25821934217978904 | validation: 0.3446199896301846]
	TIME [epoch: 28 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2524280712007613		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.2524280712007613 | validation: 0.3369590256977735]
	TIME [epoch: 28 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23815118967723192		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.23815118967723192 | validation: 0.30386332700386476]
	TIME [epoch: 28 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2396619342516677		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.2396619342516677 | validation: 0.33949667440100784]
	TIME [epoch: 28 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.251613184594782		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.251613184594782 | validation: 0.3446488482762828]
	TIME [epoch: 28 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24728015615619597		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.24728015615619597 | validation: 0.329389141186457]
	TIME [epoch: 28 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2404484282945758		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.2404484282945758 | validation: 0.30505633035348234]
	TIME [epoch: 28 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2366519787356186		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.2366519787356186 | validation: 0.3191288963390499]
	TIME [epoch: 28 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24090003713392621		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.24090003713392621 | validation: 0.2966094516872703]
	TIME [epoch: 28 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23516697376892903		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.23516697376892903 | validation: 0.3048862467875312]
	TIME [epoch: 28 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23708531389470525		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.23708531389470525 | validation: 0.288653105080504]
	TIME [epoch: 28 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23618549989035387		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.23618549989035387 | validation: 0.29777269541374746]
	TIME [epoch: 28 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24167816775490406		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.24167816775490406 | validation: 0.30624923805136595]
	TIME [epoch: 28 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25047794656066696		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.25047794656066696 | validation: 0.3116503757846774]
	TIME [epoch: 28 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25992862061212785		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.25992862061212785 | validation: 0.30302534092663247]
	TIME [epoch: 28 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2696072120123724		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.2696072120123724 | validation: 0.29513048149577076]
	TIME [epoch: 28 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26395471555544797		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.26395471555544797 | validation: 0.2798521703360634]
	TIME [epoch: 28 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24540427209878998		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.24540427209878998 | validation: 0.28640066443146917]
	TIME [epoch: 28 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2497935932766357		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.2497935932766357 | validation: 0.28620776264731274]
	TIME [epoch: 28 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24862506687804042		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.24862506687804042 | validation: 0.2881480292406798]
	TIME [epoch: 28 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24749438133432028		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.24749438133432028 | validation: 0.2810651541695035]
	TIME [epoch: 28 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2511416251835344		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.2511416251835344 | validation: 0.2857018750974396]
	TIME [epoch: 28 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25321670496386856		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.25321670496386856 | validation: 0.29484182106253287]
	TIME [epoch: 28 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24592929196763796		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.24592929196763796 | validation: 0.29519857610961814]
	TIME [epoch: 28 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24793975482709657		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.24793975482709657 | validation: 0.29364936123710494]
	TIME [epoch: 28 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25473846002558787		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.25473846002558787 | validation: 0.30197215418781537]
	TIME [epoch: 28 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2487823035982173		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.2487823035982173 | validation: 0.30656119101868007]
	TIME [epoch: 28 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24315596961209263		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.24315596961209263 | validation: 0.2949659907486457]
	TIME [epoch: 28 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24460569091186907		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.24460569091186907 | validation: 0.29176604055548716]
	TIME [epoch: 28 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23850245877160176		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.23850245877160176 | validation: 0.29189230097841046]
	TIME [epoch: 28 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24416518957346497		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.24416518957346497 | validation: 0.3011720150549054]
	TIME [epoch: 28 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2520546613687677		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.2520546613687677 | validation: 0.2883833835258976]
	TIME [epoch: 28 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2461864532947251		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.2461864532947251 | validation: 0.283823294792807]
	TIME [epoch: 28 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25588232110059517		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.25588232110059517 | validation: 0.2876366191051999]
	TIME [epoch: 28 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25459989849992964		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.25459989849992964 | validation: 0.28682105836445354]
	TIME [epoch: 28 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24970094585043628		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.24970094585043628 | validation: 0.29447035330163085]
	TIME [epoch: 28 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24889860415616868		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.24889860415616868 | validation: 0.27988699633003084]
	TIME [epoch: 28 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24791329308426677		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.24791329308426677 | validation: 0.3026261914498826]
	TIME [epoch: 28.1 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25460400793929283		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.25460400793929283 | validation: 0.30455928987112957]
	TIME [epoch: 28 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24982065231525338		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.24982065231525338 | validation: 0.2962623838960718]
	TIME [epoch: 28 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2402551209633697		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.2402551209633697 | validation: 0.2953900986676627]
	TIME [epoch: 28 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24478024948670943		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.24478024948670943 | validation: 0.28668856385460384]
	TIME [epoch: 28 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23306720408503873		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.23306720408503873 | validation: 0.287493222436402]
	TIME [epoch: 28 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24700000384815718		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.24700000384815718 | validation: 0.28728679060696033]
	TIME [epoch: 28 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24113520761296947		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.24113520761296947 | validation: 0.2748401184837822]
	TIME [epoch: 28 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25509582085657		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.25509582085657 | validation: 0.2860945564041637]
	TIME [epoch: 28 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2616176175884982		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.2616176175884982 | validation: 0.288603151292526]
	TIME [epoch: 28 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2560165896551852		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.2560165896551852 | validation: 0.2908785871430197]
	TIME [epoch: 28 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25043194980676		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.25043194980676 | validation: 0.2989146285225484]
	TIME [epoch: 28 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2540053820022223		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.2540053820022223 | validation: 0.3133970272692255]
	TIME [epoch: 28 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2493098814461054		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.2493098814461054 | validation: 0.29386215919255027]
	TIME [epoch: 28 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24098178542749657		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.24098178542749657 | validation: 0.29121552623677494]
	TIME [epoch: 28 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23638256374801445		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.23638256374801445 | validation: 0.2919824090091045]
	TIME [epoch: 28 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23710357671699447		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.23710357671699447 | validation: 0.29948193575714405]
	TIME [epoch: 28 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2487262314811846		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.2487262314811846 | validation: 0.2850930351906154]
	TIME [epoch: 28 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2469771302881738		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.2469771302881738 | validation: 0.2954183900445184]
	TIME [epoch: 28 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23553229663513586		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.23553229663513586 | validation: 0.30147011352910197]
	TIME [epoch: 28 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24511271618737684		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.24511271618737684 | validation: 0.2966173395181253]
	TIME [epoch: 28 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23952737223636406		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.23952737223636406 | validation: 0.292524562990384]
	TIME [epoch: 28 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23441011256766786		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.23441011256766786 | validation: 0.29542371045493526]
	TIME [epoch: 28 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23478013803482797		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.23478013803482797 | validation: 0.28956429572788045]
	TIME [epoch: 28 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24809767088192303		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.24809767088192303 | validation: 0.284459235672694]
	TIME [epoch: 28 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2393184779246669		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.2393184779246669 | validation: 0.29188302472002603]
	TIME [epoch: 28 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24235105734571594		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.24235105734571594 | validation: 0.3036689129423497]
	TIME [epoch: 28.1 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25831394071988517		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.25831394071988517 | validation: 0.2956061400289371]
	TIME [epoch: 28 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25792876343978355		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.25792876343978355 | validation: 0.2909632154097287]
	TIME [epoch: 28 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2582725139285633		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.2582725139285633 | validation: 0.3024957084924942]
	TIME [epoch: 28 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24723040039923583		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.24723040039923583 | validation: 0.28847267518837555]
	TIME [epoch: 28 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2586730025909388		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.2586730025909388 | validation: 0.2911149808592003]
	TIME [epoch: 28 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26901605726482625		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.26901605726482625 | validation: 0.28977837112330657]
	TIME [epoch: 28 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2785048327037323		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.2785048327037323 | validation: 0.3009774844561529]
	TIME [epoch: 28 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2617080858146375		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.2617080858146375 | validation: 0.2946578115257362]
	TIME [epoch: 28 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2643294981642823		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.2643294981642823 | validation: 0.2868088669826059]
	TIME [epoch: 28 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2651172035925669		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.2651172035925669 | validation: 0.29776361821034913]
	TIME [epoch: 28 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26333442008336283		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.26333442008336283 | validation: 0.30958358032461314]
	TIME [epoch: 28 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2578695182254669		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.2578695182254669 | validation: 0.3043099177443573]
	TIME [epoch: 28 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25208582840167765		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.25208582840167765 | validation: 0.28870186684730365]
	TIME [epoch: 28.1 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25350768943085655		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.25350768943085655 | validation: 0.29263061324273454]
	TIME [epoch: 28 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2490856487598298		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.2490856487598298 | validation: 0.2771637742232355]
	TIME [epoch: 28.1 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24347433774974814		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.24347433774974814 | validation: 0.293066129706052]
	TIME [epoch: 28.1 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24556396772311825		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.24556396772311825 | validation: 0.295228263327817]
	TIME [epoch: 28 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24145321830363203		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.24145321830363203 | validation: 0.2818587806126336]
	TIME [epoch: 28.1 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24805354438152805		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.24805354438152805 | validation: 0.29402721199637655]
	TIME [epoch: 28.1 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2475635553158183		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.2475635553158183 | validation: 0.30487315619842986]
	TIME [epoch: 28.1 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2576411587471793		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.2576411587471793 | validation: 0.3071302351750723]
	TIME [epoch: 28.1 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2553494488106921		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.2553494488106921 | validation: 0.28637223699364966]
	TIME [epoch: 28 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25027723754223974		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.25027723754223974 | validation: 0.2943411614529299]
	TIME [epoch: 28 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25182574681669956		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.25182574681669956 | validation: 0.29255142264424977]
	TIME [epoch: 28 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2505167812067811		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.2505167812067811 | validation: 0.29530251909338523]
	TIME [epoch: 28 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2554493038511654		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.2554493038511654 | validation: 0.28966231544461446]
	TIME [epoch: 28 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24995667168197483		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.24995667168197483 | validation: 0.2935710655315353]
	TIME [epoch: 28 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25054456104522516		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.25054456104522516 | validation: 0.30476788652784464]
	TIME [epoch: 28 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24811165883909037		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.24811165883909037 | validation: 0.29550130979367695]
	TIME [epoch: 28.1 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23976564317650223		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.23976564317650223 | validation: 0.2840708705421609]
	TIME [epoch: 28 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2410507844811138		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.2410507844811138 | validation: 0.28425977592071827]
	TIME [epoch: 28.1 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2355773794579952		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.2355773794579952 | validation: 0.275214017653789]
	TIME [epoch: 28 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24165311966530967		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.24165311966530967 | validation: 0.2944591562872532]
	TIME [epoch: 28.1 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24331781205469472		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.24331781205469472 | validation: 0.3046723482337621]
	TIME [epoch: 28.1 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2362972748243889		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.2362972748243889 | validation: 0.2925741608879672]
	TIME [epoch: 28 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2368657234814588		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.2368657234814588 | validation: 0.2979084790711012]
	TIME [epoch: 28.1 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24524733549862654		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.24524733549862654 | validation: 0.2862566156878512]
	TIME [epoch: 28 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24315154603206987		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.24315154603206987 | validation: 0.2870290569366101]
	TIME [epoch: 28 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2560854954018567		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.2560854954018567 | validation: 0.287958834291679]
	TIME [epoch: 28 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25490364613897004		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.25490364613897004 | validation: 0.2939706172057293]
	TIME [epoch: 28 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2560406354628817		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.2560406354628817 | validation: 0.2972126716635592]
	TIME [epoch: 28.1 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2673249630592589		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.2673249630592589 | validation: 0.30133964499812005]
	TIME [epoch: 28 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2624122992019536		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.2624122992019536 | validation: 0.2939342092358242]
	TIME [epoch: 28 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25090058506451074		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.25090058506451074 | validation: 0.29586068255502956]
	TIME [epoch: 28 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2565565620242492		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.2565565620242492 | validation: 0.28168270644777116]
	TIME [epoch: 28 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2544332430052352		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.2544332430052352 | validation: 0.28842689696892915]
	TIME [epoch: 28 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2653970693999428		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.2653970693999428 | validation: 0.2922001363681791]
	TIME [epoch: 28 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2744110274786691		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.2744110274786691 | validation: 0.27918021624430284]
	TIME [epoch: 27.9 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2627534293104383		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.2627534293104383 | validation: 0.29081330369189656]
	TIME [epoch: 28 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24533346384767835		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.24533346384767835 | validation: 0.268017494034731]
	TIME [epoch: 27.9 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2512433113466816		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.2512433113466816 | validation: 0.28546903080763747]
	TIME [epoch: 28 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24808689515333637		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.24808689515333637 | validation: 0.2871464170431149]
	TIME [epoch: 28 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2643447959842118		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.2643447959842118 | validation: 0.2808143138687688]
	TIME [epoch: 28 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2519076553466835		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.2519076553466835 | validation: 0.2728456930874971]
	TIME [epoch: 28.1 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25040157540068475		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.25040157540068475 | validation: 0.2702386763167597]
	TIME [epoch: 28 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25844257763615686		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.25844257763615686 | validation: 0.2788500510577423]
	TIME [epoch: 28 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25413294849609114		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.25413294849609114 | validation: 0.2752247831126319]
	TIME [epoch: 28 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24057100493028324		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.24057100493028324 | validation: 0.28084822562100725]
	TIME [epoch: 28 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24395022675879913		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.24395022675879913 | validation: 0.2853841907458212]
	TIME [epoch: 28 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23519011657269057		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.23519011657269057 | validation: 0.28547062811653356]
	TIME [epoch: 28 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23220876893539732		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.23220876893539732 | validation: 0.27956860080633655]
	TIME [epoch: 28 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23379570929042737		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.23379570929042737 | validation: 0.28088927463618346]
	TIME [epoch: 28 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22980485657203298		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.22980485657203298 | validation: 0.280844519024078]
	TIME [epoch: 28 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23427285994613797		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.23427285994613797 | validation: 0.2795309365406131]
	TIME [epoch: 28.1 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23620118034647652		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.23620118034647652 | validation: 0.27327401093391984]
	TIME [epoch: 28 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23216927542194754		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.23216927542194754 | validation: 0.2824902530168658]
	TIME [epoch: 28 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23501806608254047		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.23501806608254047 | validation: 0.27223964360525027]
	TIME [epoch: 28 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2395229819543072		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.2395229819543072 | validation: 0.2782810701983278]
	TIME [epoch: 28 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24153222357243437		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.24153222357243437 | validation: 0.2832255569496396]
	TIME [epoch: 28.1 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23154585182528875		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.23154585182528875 | validation: 0.2898691404084749]
	TIME [epoch: 28 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.237499291600761		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.237499291600761 | validation: 0.2775857966214236]
	TIME [epoch: 28 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23483926451356513		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.23483926451356513 | validation: 0.27303159774745067]
	TIME [epoch: 28.1 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23364348262847162		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.23364348262847162 | validation: 0.28794868294475945]
	TIME [epoch: 28 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22913998295943544		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.22913998295943544 | validation: 0.27526981806735706]
	TIME [epoch: 28 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23387822035728967		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.23387822035728967 | validation: 0.27036818071575663]
	TIME [epoch: 28 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23763028831233038		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.23763028831233038 | validation: 0.28927225649861926]
	TIME [epoch: 28 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23314698923973667		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.23314698923973667 | validation: 0.28118444774659584]
	TIME [epoch: 28 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23848920018344866		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.23848920018344866 | validation: 0.2798859208442531]
	TIME [epoch: 28 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23471521783999572		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.23471521783999572 | validation: 0.2834989190386173]
	TIME [epoch: 28 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23489965276314093		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.23489965276314093 | validation: 0.27094308190522987]
	TIME [epoch: 28 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24103144672578147		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.24103144672578147 | validation: 0.28522496743878384]
	TIME [epoch: 28 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24564236410188137		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.24564236410188137 | validation: 0.2768513298229121]
	TIME [epoch: 28 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23475653772458302		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.23475653772458302 | validation: 0.2824764092485766]
	TIME [epoch: 28 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24005534628165526		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.24005534628165526 | validation: 0.28206907528841707]
	TIME [epoch: 28.1 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23402847814681196		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.23402847814681196 | validation: 0.289283509827261]
	TIME [epoch: 28.1 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23486419816013285		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.23486419816013285 | validation: 0.2788237615599782]
	TIME [epoch: 28 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2450352444602005		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.2450352444602005 | validation: 0.27952098675228676]
	TIME [epoch: 28 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22735160864468143		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.22735160864468143 | validation: 0.284520052634666]
	TIME [epoch: 28 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23385332648420898		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.23385332648420898 | validation: 0.28718582205013243]
	TIME [epoch: 28 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2357782817111389		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.2357782817111389 | validation: 0.27767293007597904]
	TIME [epoch: 28 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2300862864338879		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.2300862864338879 | validation: 0.27661452476792614]
	TIME [epoch: 28 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23210502304059005		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.23210502304059005 | validation: 0.27940124056996335]
	TIME [epoch: 28 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.235741638182478		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.235741638182478 | validation: 0.27892277959476025]
	TIME [epoch: 28 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22868529471611057		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.22868529471611057 | validation: 0.28966815731122514]
	TIME [epoch: 28 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22798647394759314		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.22798647394759314 | validation: 0.2894915411817218]
	TIME [epoch: 28 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2287632910862109		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.2287632910862109 | validation: 0.2817428520432584]
	TIME [epoch: 28 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22850280694724512		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.22850280694724512 | validation: 0.28801975482679254]
	TIME [epoch: 28.1 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24186349104923627		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.24186349104923627 | validation: 0.27755218509103396]
	TIME [epoch: 28.1 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2360979804274836		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.2360979804274836 | validation: 0.2822371322050529]
	TIME [epoch: 28 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24611556286121958		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.24611556286121958 | validation: 0.2946121403659013]
	TIME [epoch: 28 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2459387589597049		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.2459387589597049 | validation: 0.28312917535404525]
	TIME [epoch: 28 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25130880277388784		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.25130880277388784 | validation: 0.2797522291316129]
	TIME [epoch: 28 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2558466733295629		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.2558466733295629 | validation: 0.29579508552545036]
	TIME [epoch: 28 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2586911495695027		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.2586911495695027 | validation: 0.2862497645028105]
	TIME [epoch: 28 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24442005590804827		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.24442005590804827 | validation: 0.28435290356731363]
	TIME [epoch: 28 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2521933525319819		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.2521933525319819 | validation: 0.27897320298907646]
	TIME [epoch: 28 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25128694160913706		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.25128694160913706 | validation: 0.2824674395107369]
	TIME [epoch: 28.1 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25826616790437484		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.25826616790437484 | validation: 0.2800932179276802]
	TIME [epoch: 28 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.251599446200247		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.251599446200247 | validation: 0.27488914801784425]
	TIME [epoch: 28 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2650376091758142		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.2650376091758142 | validation: 0.28778525899696245]
	TIME [epoch: 28 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24471210685229652		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.24471210685229652 | validation: 0.28086300940568926]
	TIME [epoch: 28.1 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2615853244217098		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.2615853244217098 | validation: 0.28300681095753294]
	TIME [epoch: 28 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25265878444820855		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.25265878444820855 | validation: 0.2765749627430118]
	TIME [epoch: 28 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24639833649403525		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.24639833649403525 | validation: 0.2857498513489777]
	TIME [epoch: 28 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2582562855300821		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.2582562855300821 | validation: 0.28282562613214834]
	TIME [epoch: 28 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2590234408847352		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.2590234408847352 | validation: 0.27817002528620804]
	TIME [epoch: 28 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2576909193943852		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.2576909193943852 | validation: 0.2810811895020545]
	TIME [epoch: 28 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24722478459690247		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.24722478459690247 | validation: 0.28560731303054177]
	TIME [epoch: 28.2 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25301794443782866		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.25301794443782866 | validation: 0.28230922579545026]
	TIME [epoch: 28.1 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26347836837301647		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.26347836837301647 | validation: 0.28486434370353736]
	TIME [epoch: 28.1 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2659116925108256		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.2659116925108256 | validation: 0.2894612128124461]
	TIME [epoch: 28.1 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25732460855596795		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.25732460855596795 | validation: 0.28303834642110337]
	TIME [epoch: 28 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2584963194447303		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.2584963194447303 | validation: 0.2802414235936798]
	TIME [epoch: 28.1 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25440647060275856		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.25440647060275856 | validation: 0.27838392192492906]
	TIME [epoch: 28 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26024292740556554		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.26024292740556554 | validation: 0.29636681606418047]
	TIME [epoch: 28.1 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2680150630140899		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.2680150630140899 | validation: 0.2755721806691716]
	TIME [epoch: 28 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2534772323912763		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.2534772323912763 | validation: 0.29218385301216865]
	TIME [epoch: 28 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25284348630579523		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.25284348630579523 | validation: 0.28230096178496766]
	TIME [epoch: 28 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24935420288348634		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.24935420288348634 | validation: 0.27208091924255506]
	TIME [epoch: 28.1 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25368515633223676		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.25368515633223676 | validation: 0.2716513573712518]
	TIME [epoch: 28 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25361261298753823		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.25361261298753823 | validation: 0.2794105605710774]
	TIME [epoch: 28 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24182347988756364		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.24182347988756364 | validation: 0.2785609187705177]
	TIME [epoch: 28 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23962720750381233		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.23962720750381233 | validation: 0.28210906534575997]
	TIME [epoch: 28 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2403489940156302		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.2403489940156302 | validation: 0.2828944141835987]
	TIME [epoch: 28 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23036164649733856		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.23036164649733856 | validation: 0.2871079287971145]
	TIME [epoch: 28.1 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2336383537525364		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.2336383537525364 | validation: 0.27683408464043324]
	TIME [epoch: 28.1 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24557560182048166		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.24557560182048166 | validation: 0.28737290917684877]
	TIME [epoch: 28 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23574380557593574		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.23574380557593574 | validation: 0.28401172692216636]
	TIME [epoch: 28.1 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23662956409355362		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.23662956409355362 | validation: 0.282703908922663]
	TIME [epoch: 28.1 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23910693314894382		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.23910693314894382 | validation: 0.28708546935893814]
	TIME [epoch: 28 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24037376638019253		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.24037376638019253 | validation: 0.28680015177984736]
	TIME [epoch: 28.1 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2401121437214379		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.2401121437214379 | validation: 0.2941201072552479]
	TIME [epoch: 28 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24041668969631258		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.24041668969631258 | validation: 0.2898735240157188]
	TIME [epoch: 28.1 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24207426673295745		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.24207426673295745 | validation: 0.2804541457954446]
	TIME [epoch: 28 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2432861643736013		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.2432861643736013 | validation: 0.2832319197535734]
	TIME [epoch: 28 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2364389977724864		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.2364389977724864 | validation: 0.27645638517282534]
	TIME [epoch: 28 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2329319040460241		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.2329319040460241 | validation: 0.28281069196716324]
	TIME [epoch: 28 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23653903594636577		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.23653903594636577 | validation: 0.2769326381158546]
	TIME [epoch: 28 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23567891451486503		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.23567891451486503 | validation: 0.27113002032484157]
	TIME [epoch: 28 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2332147870042328		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.2332147870042328 | validation: 0.2735219751348737]
	TIME [epoch: 28 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23381810164298622		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.23381810164298622 | validation: 0.2781150127868883]
	TIME [epoch: 28 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2349445664204254		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.2349445664204254 | validation: 0.2748955431748598]
	TIME [epoch: 28 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24244214303697845		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.24244214303697845 | validation: 0.278964232053242]
	TIME [epoch: 28 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24491709829162417		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.24491709829162417 | validation: 0.29243466452811184]
	TIME [epoch: 28.1 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2440638300546678		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.2440638300546678 | validation: 0.26934044101823457]
	TIME [epoch: 28 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24061628300863958		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.24061628300863958 | validation: 0.2807025607101929]
	TIME [epoch: 28 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23585781916410362		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.23585781916410362 | validation: 0.2800215060699896]
	TIME [epoch: 28 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23721046830585196		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.23721046830585196 | validation: 0.27500624476040597]
	TIME [epoch: 28 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24573775450321078		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.24573775450321078 | validation: 0.2804585033916404]
	TIME [epoch: 28 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24270695093476696		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.24270695093476696 | validation: 0.28058321468091124]
	TIME [epoch: 27.9 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2332756770525225		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.2332756770525225 | validation: 0.27357117078390003]
	TIME [epoch: 28.1 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23356014723812737		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.23356014723812737 | validation: 0.2826152157563307]
	TIME [epoch: 28 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22695375480091146		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.22695375480091146 | validation: 0.2786004573110833]
	TIME [epoch: 28 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23558776567740553		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.23558776567740553 | validation: 0.2863634520132375]
	TIME [epoch: 28.1 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23011488579599923		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.23011488579599923 | validation: 0.2833118790414212]
	TIME [epoch: 28 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22921962196118412		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.22921962196118412 | validation: 0.26938584283365685]
	TIME [epoch: 28.1 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.228112296315676		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.228112296315676 | validation: 0.2891256886492411]
	TIME [epoch: 28.1 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22745449630382242		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.22745449630382242 | validation: 0.28211704636833357]
	TIME [epoch: 28 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2322444941506833		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.2322444941506833 | validation: 0.27644466457267874]
	TIME [epoch: 28.1 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23193042307895304		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.23193042307895304 | validation: 0.2851056211926781]
	TIME [epoch: 28.1 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22650792487533838		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.22650792487533838 | validation: 0.28005592943023017]
	TIME [epoch: 28.1 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22967707649489355		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.22967707649489355 | validation: 0.2885435943668555]
	TIME [epoch: 28.1 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22882099886949814		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.22882099886949814 | validation: 0.2887197156449174]
	TIME [epoch: 28 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22420206906859272		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.22420206906859272 | validation: 0.2844270633439959]
	TIME [epoch: 28.1 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.233010155833892		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.233010155833892 | validation: 0.2850099026134063]
	TIME [epoch: 28.1 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23799513883394213		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.23799513883394213 | validation: 0.27778720571147897]
	TIME [epoch: 28.1 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2290258338194559		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.2290258338194559 | validation: 0.2858202459234004]
	TIME [epoch: 28.1 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22785103770212384		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.22785103770212384 | validation: 0.29090496492296125]
	TIME [epoch: 28 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2297414341022062		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.2297414341022062 | validation: 0.2907757406630533]
	TIME [epoch: 28.1 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2292830236639513		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.2292830236639513 | validation: 0.28130687951405436]
	TIME [epoch: 28.1 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2272237701631793		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.2272237701631793 | validation: 0.28569593760151313]
	TIME [epoch: 28 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22508739574704661		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.22508739574704661 | validation: 0.26677036882655936]
	TIME [epoch: 28.1 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22798066764920258		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.22798066764920258 | validation: 0.2703539183467207]
	TIME [epoch: 28 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2284867893919591		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.2284867893919591 | validation: 0.27666782578291055]
	TIME [epoch: 28.1 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22940915583718446		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.22940915583718446 | validation: 0.27388588517050044]
	TIME [epoch: 28.1 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23362761725214423		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.23362761725214423 | validation: 0.27504533568446193]
	TIME [epoch: 28 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23331848534437993		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.23331848534437993 | validation: 0.270761762081962]
	TIME [epoch: 28.1 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23185321154231042		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.23185321154231042 | validation: 0.27588532020876133]
	TIME [epoch: 28 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23208583006283687		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.23208583006283687 | validation: 0.2773846360267874]
	TIME [epoch: 28 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23409253858500445		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.23409253858500445 | validation: 0.2739086486933941]
	TIME [epoch: 28.1 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23029481127876297		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.23029481127876297 | validation: 0.2741040109797397]
	TIME [epoch: 28.1 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23310738364723435		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.23310738364723435 | validation: 0.272079783663617]
	TIME [epoch: 28.1 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22778202249323223		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.22778202249323223 | validation: 0.273711019872248]
	TIME [epoch: 28.1 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23450905948639988		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.23450905948639988 | validation: 0.26604817186652874]
	TIME [epoch: 28.1 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.234775195024621		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.234775195024621 | validation: 0.2731937039745038]
	TIME [epoch: 28.1 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23286603265788103		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.23286603265788103 | validation: 0.2687506024243859]
	TIME [epoch: 28.1 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23135637783886137		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.23135637783886137 | validation: 0.27494315301456335]
	TIME [epoch: 28.1 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23785240444547442		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.23785240444547442 | validation: 0.26850599528127705]
	TIME [epoch: 28.1 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24661147147077572		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.24661147147077572 | validation: 0.27855810155722166]
	TIME [epoch: 28.1 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24234464918413298		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.24234464918413298 | validation: 0.262121803207582]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_1834.pth
	Model improved!!!
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24163767594154767		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.24163767594154767 | validation: 0.2666407404616773]
	TIME [epoch: 28 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2440683601380552		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.2440683601380552 | validation: 0.2721887358048964]
	TIME [epoch: 28.1 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2399241753884867		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.2399241753884867 | validation: 0.26672956044802903]
	TIME [epoch: 28.1 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23605215419664116		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.23605215419664116 | validation: 0.2680196329161639]
	TIME [epoch: 28.1 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24449499709426145		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.24449499709426145 | validation: 0.27100238524886844]
	TIME [epoch: 28.1 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23715732499144618		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.23715732499144618 | validation: 0.26687843701299474]
	TIME [epoch: 28 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.236359822532899		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.236359822532899 | validation: 0.28036267303715934]
	TIME [epoch: 28.1 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23845882936251409		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.23845882936251409 | validation: 0.2861692373742279]
	TIME [epoch: 28.1 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23965855070126554		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.23965855070126554 | validation: 0.2752530148695997]
	TIME [epoch: 28 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24735967540540205		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.24735967540540205 | validation: 0.2610656454938466]
	TIME [epoch: 28.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_1844.pth
	Model improved!!!
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24667418243131078		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.24667418243131078 | validation: 0.269031502595284]
	TIME [epoch: 28 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24078194562678407		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.24078194562678407 | validation: 0.2727925959448709]
	TIME [epoch: 28 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23435927311814134		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.23435927311814134 | validation: 0.27371830006948566]
	TIME [epoch: 28.1 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2325849660381795		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.2325849660381795 | validation: 0.2695804630581404]
	TIME [epoch: 28 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2458431541252517		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.2458431541252517 | validation: 0.27591591249837255]
	TIME [epoch: 28.1 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24901630528849322		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.24901630528849322 | validation: 0.27544417116654424]
	TIME [epoch: 28 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.244348041535353		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.244348041535353 | validation: 0.2761367669863253]
	TIME [epoch: 28 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2504898820017952		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.2504898820017952 | validation: 0.2669729090502992]
	TIME [epoch: 28 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24846932367982538		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.24846932367982538 | validation: 0.27002997996111494]
	TIME [epoch: 28 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24420716625366212		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.24420716625366212 | validation: 0.268456468857696]
	TIME [epoch: 28 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2443428392840258		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.2443428392840258 | validation: 0.26795128175400323]
	TIME [epoch: 28 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24627566026501027		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.24627566026501027 | validation: 0.2699025774287881]
	TIME [epoch: 28 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24065249455797894		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.24065249455797894 | validation: 0.27248229786835565]
	TIME [epoch: 28 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2466844664630672		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.2466844664630672 | validation: 0.2732658707577373]
	TIME [epoch: 28 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2467176969745405		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.2467176969745405 | validation: 0.2673020557137479]
	TIME [epoch: 28 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24774836038465076		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.24774836038465076 | validation: 0.2667075313461336]
	TIME [epoch: 28 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24632541803892538		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.24632541803892538 | validation: 0.2764981498205545]
	TIME [epoch: 28 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2544251370991237		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.2544251370991237 | validation: 0.2738684309615389]
	TIME [epoch: 28 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25250610962994857		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.25250610962994857 | validation: 0.27098990546566676]
	TIME [epoch: 28 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25565795775357025		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.25565795775357025 | validation: 0.2731072710842982]
	TIME [epoch: 28 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24501004108162625		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.24501004108162625 | validation: 0.27055477871633116]
	TIME [epoch: 28.1 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23769849680746535		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.23769849680746535 | validation: 0.28010960340099306]
	TIME [epoch: 28 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2612503039405748		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.2612503039405748 | validation: 0.27589792849484324]
	TIME [epoch: 28 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25995283609036535		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.25995283609036535 | validation: 0.2821057773778383]
	TIME [epoch: 28 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2634443170515123		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.2634443170515123 | validation: 0.27787087057309584]
	TIME [epoch: 28 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25567960513593346		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.25567960513593346 | validation: 0.28115639388439334]
	TIME [epoch: 28 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25910343098653926		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.25910343098653926 | validation: 0.26791062296554435]
	TIME [epoch: 28 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26122034401208805		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.26122034401208805 | validation: 0.27274416785462274]
	TIME [epoch: 28 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26095552713594977		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.26095552713594977 | validation: 0.27815936755611265]
	TIME [epoch: 28 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26472360093594416		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.26472360093594416 | validation: 0.2636057364903128]
	TIME [epoch: 28 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2605105721129766		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.2605105721129766 | validation: 0.25996619285595357]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_1875.pth
	Model improved!!!
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2624040634870407		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.2624040634870407 | validation: 0.27323191644437606]
	TIME [epoch: 28 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2521657221623062		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.2521657221623062 | validation: 0.2816681128452638]
	TIME [epoch: 28 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2690081669344076		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.2690081669344076 | validation: 0.2749538680954467]
	TIME [epoch: 28 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2568156826795037		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.2568156826795037 | validation: 0.2701351407276842]
	TIME [epoch: 28 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2535755609752446		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.2535755609752446 | validation: 0.26594141253656906]
	TIME [epoch: 28 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25057156710783024		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.25057156710783024 | validation: 0.2727657586754452]
	TIME [epoch: 28 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2545429546195247		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.2545429546195247 | validation: 0.27807058404989377]
	TIME [epoch: 28 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25657893896292255		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.25657893896292255 | validation: 0.2758564058048317]
	TIME [epoch: 28 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2487700951792776		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.2487700951792776 | validation: 0.2739295190453511]
	TIME [epoch: 28.1 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24865861677681012		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.24865861677681012 | validation: 0.27079169222263555]
	TIME [epoch: 28 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24996791538136848		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.24996791538136848 | validation: 0.2727552809071678]
	TIME [epoch: 28 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.250183284442592		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.250183284442592 | validation: 0.2713765373698739]
	TIME [epoch: 28.1 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2532595068664716		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.2532595068664716 | validation: 0.27444736924054436]
	TIME [epoch: 28.1 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26204836606981535		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.26204836606981535 | validation: 0.28223880490098424]
	TIME [epoch: 28 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2651545568811732		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.2651545568811732 | validation: 0.27447484673794914]
	TIME [epoch: 28.1 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2579924157234048		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.2579924157234048 | validation: 0.2734158646829728]
	TIME [epoch: 28.1 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2522701286730011		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.2522701286730011 | validation: 0.267427123366252]
	TIME [epoch: 28 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24421848181045602		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.24421848181045602 | validation: 0.2730081713486356]
	TIME [epoch: 28.1 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24551768359436332		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.24551768359436332 | validation: 0.27794882546670624]
	TIME [epoch: 28 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2432813487911926		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.2432813487911926 | validation: 0.2678793759957732]
	TIME [epoch: 28.1 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24704681252028632		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.24704681252028632 | validation: 0.2747303290416217]
	TIME [epoch: 28.1 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24406694195507692		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.24406694195507692 | validation: 0.2735271737111369]
	TIME [epoch: 28 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25001494151998754		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.25001494151998754 | validation: 0.27065704178943567]
	TIME [epoch: 28.1 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24638754955044156		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.24638754955044156 | validation: 0.2761020804372651]
	TIME [epoch: 28 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24687672290335907		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.24687672290335907 | validation: 0.2709522537672992]
	TIME [epoch: 28.1 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24783487369933271		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.24783487369933271 | validation: 0.2753038199712313]
	TIME [epoch: 28.1 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25490848005502126		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.25490848005502126 | validation: 0.2765305281787586]
	TIME [epoch: 28 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24260649505493492		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.24260649505493492 | validation: 0.2710902462171122]
	TIME [epoch: 28.1 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24226532761977101		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.24226532761977101 | validation: 0.26612360866605383]
	TIME [epoch: 28 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24657966642375073		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.24657966642375073 | validation: 0.2634343494527808]
	TIME [epoch: 28.1 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24185251869209695		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.24185251869209695 | validation: 0.27744850984103486]
	TIME [epoch: 28.1 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24089881789918016		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.24089881789918016 | validation: 0.27299022755563074]
	TIME [epoch: 28.1 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2338749584548569		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.2338749584548569 | validation: 0.2783946921209261]
	TIME [epoch: 28.1 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24239978963494277		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.24239978963494277 | validation: 0.27125594491948307]
	TIME [epoch: 28 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24844447914753673		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.24844447914753673 | validation: 0.27909425273425925]
	TIME [epoch: 28.1 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24269512588358652		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.24269512588358652 | validation: 0.2730332364000115]
	TIME [epoch: 28 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2448661964959985		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.2448661964959985 | validation: 0.27200649212010974]
	TIME [epoch: 28 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24090227136582462		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.24090227136582462 | validation: 0.2691686862843918]
	TIME [epoch: 28.1 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24366965645133354		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.24366965645133354 | validation: 0.2765457452982026]
	TIME [epoch: 28.1 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25246761898866193		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.25246761898866193 | validation: 0.26996848330418854]
	TIME [epoch: 28 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24265079541463974		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.24265079541463974 | validation: 0.2736932884819595]
	TIME [epoch: 28.1 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24922885653437038		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.24922885653437038 | validation: 0.2715690989289001]
	TIME [epoch: 28 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24991688026043407		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.24991688026043407 | validation: 0.2664522087003218]
	TIME [epoch: 28.1 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23837693479346544		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.23837693479346544 | validation: 0.28150283847206276]
	TIME [epoch: 28.1 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2433184425337625		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.2433184425337625 | validation: 0.273380732817169]
	TIME [epoch: 28 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2529873056708455		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.2529873056708455 | validation: 0.26567797834745555]
	TIME [epoch: 28.1 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25583346620969594		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.25583346620969594 | validation: 0.2689214516322015]
	TIME [epoch: 28 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2471271056292077		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.2471271056292077 | validation: 0.27750803690676706]
	TIME [epoch: 28.1 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26153894386638393		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.26153894386638393 | validation: 0.28320887782199267]
	TIME [epoch: 28 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2400853745633934		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.2400853745633934 | validation: 0.2812811902945975]
	TIME [epoch: 28 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24244288129576075		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.24244288129576075 | validation: 0.27041048289709696]
	TIME [epoch: 28 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2452847597116357		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.2452847597116357 | validation: 0.2657781959777099]
	TIME [epoch: 28 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24587542300395487		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.24587542300395487 | validation: 0.2712381544539918]
	TIME [epoch: 28 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24947418422207895		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.24947418422207895 | validation: 0.25647839884857454]
	TIME [epoch: 28.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240424_132548/states/model_tr_study5_1929.pth
	Model improved!!!
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2482757663294652		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.2482757663294652 | validation: 0.267720738227593]
	TIME [epoch: 28.1 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2466976947340565		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.2466976947340565 | validation: 0.277111791560796]
	TIME [epoch: 28.1 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24439500289932709		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.24439500289932709 | validation: 0.27460589053261963]
	TIME [epoch: 28 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24990115120248596		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.24990115120248596 | validation: 0.2724123382763775]
	TIME [epoch: 28 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24331257744291063		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.24331257744291063 | validation: 0.28179414496039756]
	TIME [epoch: 28 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2406832780314618		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.2406832780314618 | validation: 0.2790572535116817]
	TIME [epoch: 28 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2555006509116715		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.2555006509116715 | validation: 0.281260193436189]
	TIME [epoch: 28 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25032720683268783		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.25032720683268783 | validation: 0.28071100130193477]
	TIME [epoch: 28 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25223410884035086		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.25223410884035086 | validation: 0.2723666397129445]
	TIME [epoch: 28 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25172316115216914		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.25172316115216914 | validation: 0.270602201198006]
	TIME [epoch: 28 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24165964801423281		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.24165964801423281 | validation: 0.2740102904284133]
	TIME [epoch: 28 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2457021652569438		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.2457021652569438 | validation: 0.2602285181918097]
	TIME [epoch: 28.1 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2441599318721983		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.2441599318721983 | validation: 0.27697236248765883]
	TIME [epoch: 28 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23546459212839677		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.23546459212839677 | validation: 0.26364915035008324]
	TIME [epoch: 27.9 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2428396635282723		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.2428396635282723 | validation: 0.27384854514646967]
	TIME [epoch: 28 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23954316673438972		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.23954316673438972 | validation: 0.2710648216440808]
	TIME [epoch: 28 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22921745344223846		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.22921745344223846 | validation: 0.2656195634214686]
	TIME [epoch: 28 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23528210210740677		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.23528210210740677 | validation: 0.26134332462152826]
	TIME [epoch: 28.1 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23987211423725746		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.23987211423725746 | validation: 0.2788894248973298]
	TIME [epoch: 28 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23397802858453504		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.23397802858453504 | validation: 0.28097969927380595]
	TIME [epoch: 28 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23476516095658995		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.23476516095658995 | validation: 0.2749147953892316]
	TIME [epoch: 28 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24744312957992012		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.24744312957992012 | validation: 0.2609460170812068]
	TIME [epoch: 28 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23674066327952414		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.23674066327952414 | validation: 0.27667848463155337]
	TIME [epoch: 28 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24537298701063917		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.24537298701063917 | validation: 0.28176929923931787]
	TIME [epoch: 28 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24372511508181177		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.24372511508181177 | validation: 0.2759917522006446]
	TIME [epoch: 28 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24588676549866828		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.24588676549866828 | validation: 0.2860651391476833]
	TIME [epoch: 28 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24021619908040032		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.24021619908040032 | validation: 0.2747718531874317]
	TIME [epoch: 28 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23662497297928708		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.23662497297928708 | validation: 0.26693288418280486]
	TIME [epoch: 28.1 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2366152731926125		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.2366152731926125 | validation: 0.273567617202168]
	TIME [epoch: 28 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2495153443209953		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.2495153443209953 | validation: 0.273416894025106]
	TIME [epoch: 28.1 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24545316690307467		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.24545316690307467 | validation: 0.2697786951868943]
	TIME [epoch: 28.1 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2394994462476673		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.2394994462476673 | validation: 0.27312945338652234]
	TIME [epoch: 28.1 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24508133825865824		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.24508133825865824 | validation: 0.2688701523668199]
	TIME [epoch: 28 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2532902609622474		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.2532902609622474 | validation: 0.2637675803629208]
	TIME [epoch: 28 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25135696173050354		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.25135696173050354 | validation: 0.2691845633529746]
	TIME [epoch: 28 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25630401608660036		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.25630401608660036 | validation: 0.2715447702912966]
	TIME [epoch: 28.1 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2519476979600651		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.2519476979600651 | validation: 0.2823360638085542]
	TIME [epoch: 28 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25066128125094844		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.25066128125094844 | validation: 0.2668089408752404]
	TIME [epoch: 28.1 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23194416794372263		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.23194416794372263 | validation: 0.2760771091704713]
	TIME [epoch: 28 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23463313999766067		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.23463313999766067 | validation: 0.27123442225014094]
	TIME [epoch: 28.1 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23293098650471894		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.23293098650471894 | validation: 0.2675285033318441]
	TIME [epoch: 28 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24419471897261624		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.24419471897261624 | validation: 0.27841705847228404]
	TIME [epoch: 28 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2398641405825226		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.2398641405825226 | validation: 0.26661604495115354]
	TIME [epoch: 28 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2532019856858762		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.2532019856858762 | validation: 0.2615107380819112]
	TIME [epoch: 28 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2487178517557746		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.2487178517557746 | validation: 0.2589637050900886]
	TIME [epoch: 28 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23864528169815274		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.23864528169815274 | validation: 0.2761888303102918]
	TIME [epoch: 28.1 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25315299511876427		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.25315299511876427 | validation: 0.2682112495293983]
	TIME [epoch: 28 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24470823151298476		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.24470823151298476 | validation: 0.280765451101104]
	TIME [epoch: 28.1 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24980159868314342		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.24980159868314342 | validation: 0.27471093740723557]
	TIME [epoch: 28.1 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2586369917464823		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.2586369917464823 | validation: 0.2826465751800122]
	TIME [epoch: 28 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24512352132865775		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.24512352132865775 | validation: 0.26973720617623204]
	TIME [epoch: 28 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25687538619436057		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.25687538619436057 | validation: 0.26891188970002927]
	TIME [epoch: 28 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24535076046687787		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.24535076046687787 | validation: 0.27604076968864527]
	TIME [epoch: 28.1 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24181035242307514		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.24181035242307514 | validation: 0.26629904113590436]
	TIME [epoch: 28 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2441048312212935		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.2441048312212935 | validation: 0.2690344811455367]
	TIME [epoch: 28 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2428352229400625		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.2428352229400625 | validation: 0.26538954824295014]
	TIME [epoch: 28.1 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2498253477066042		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.2498253477066042 | validation: 0.2648763574213579]
	TIME [epoch: 28 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24723884751680628		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.24723884751680628 | validation: 0.27107432713881857]
	TIME [epoch: 28.1 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24201839013736165		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.24201839013736165 | validation: 0.26885650359134317]
	TIME [epoch: 28 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23578883324555525		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.23578883324555525 | validation: 0.2725648556550733]
	TIME [epoch: 28.1 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24083023467042042		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.24083023467042042 | validation: 0.2787762049450065]
	TIME [epoch: 28 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24766821422690283		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.24766821422690283 | validation: 0.2820634807480814]
	TIME [epoch: 28.1 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25496474027365235		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.25496474027365235 | validation: 0.27478422096026467]
	TIME [epoch: 28 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25575090069352613		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.25575090069352613 | validation: 0.26232887109028985]
	TIME [epoch: 28.1 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25616677212608363		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.25616677212608363 | validation: 0.26544384930121956]
	TIME [epoch: 28 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2408785840382885		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.2408785840382885 | validation: 0.27059982569686286]
	TIME [epoch: 28 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2548458377730181		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.2548458377730181 | validation: 0.2729481131803629]
	TIME [epoch: 28 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2449655636388055		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.2449655636388055 | validation: 0.2705797337252541]
	TIME [epoch: 28.1 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24670460366238847		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.24670460366238847 | validation: 0.27157800491670275]
	TIME [epoch: 28 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2506131248324169		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.2506131248324169 | validation: 0.26706886489624687]
	TIME [epoch: 28 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23872461804881978		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.23872461804881978 | validation: 0.27290971516838414]
	TIME [epoch: 28 sec]
Finished training in 56295.981 seconds.
