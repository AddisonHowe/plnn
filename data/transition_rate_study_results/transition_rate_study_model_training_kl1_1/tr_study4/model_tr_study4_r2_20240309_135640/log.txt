Args:
Namespace(name='model_tr_study4', outdir='out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2', training_data='data/transition_rate_studies/tr_study4/tr_study4_training/r2', validation_data='data/transition_rate_studies/tr_study4/tr_study4_validation/r2', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 385478345

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.288738972665714		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.288738972665714 | validation: 6.99356241639915]
	TIME [epoch: 91.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.688092652212563		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.688092652212563 | validation: 6.188406038381227]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.983023972465787		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.983023972465787 | validation: 5.577071896046841]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.530139755343755		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.530139755343755 | validation: 5.080582827421422]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.902706247145385		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.902706247145385 | validation: 4.581496204191033]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.449900233246242		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.449900233246242 | validation: 4.159767517024115]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9354048590493487		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9354048590493487 | validation: 4.087188635923955]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8269008105562228		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8269008105562228 | validation: 3.6530489609522374]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.579115889390504		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.579115889390504 | validation: 3.6485155601689394]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5655242740689292		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5655242740689292 | validation: 4.319854297058083]
	TIME [epoch: 13 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.664079333295822		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.664079333295822 | validation: 3.519405013056034]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3985953566181957		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3985953566181957 | validation: 3.3935182642989297]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4240258824202603		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4240258824202603 | validation: 3.448215727629586]
	TIME [epoch: 13 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.310487842871407		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.310487842871407 | validation: 3.5437403089357447]
	TIME [epoch: 13 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.339416725150919		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.339416725150919 | validation: 3.3533735956529553]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3296417324800145		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3296417324800145 | validation: 3.454005576317884]
	TIME [epoch: 13 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2977531539782667		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2977531539782667 | validation: 3.4342787675291016]
	TIME [epoch: 13 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.35729548428439		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.35729548428439 | validation: 3.289993993171247]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1479371319178404		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1479371319178404 | validation: 6.206084413164607]
	TIME [epoch: 13 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.177257067299888		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.177257067299888 | validation: 3.2006690796681743]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.093602912159421		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.093602912159421 | validation: 3.051122209944168]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1002344020331587		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1002344020331587 | validation: 3.0171727872540415]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.114377557289812		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.114377557289812 | validation: 3.105982942421083]
	TIME [epoch: 13 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.856770287444755		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.856770287444755 | validation: 2.8567399116937553]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7897719923292454		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7897719923292454 | validation: 2.7273740251461254]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8175908783157846		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8175908783157846 | validation: 2.7745164001567186]
	TIME [epoch: 13 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7851398708692856		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7851398708692856 | validation: 2.8025226563231724]
	TIME [epoch: 13 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.491858160508324		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.491858160508324 | validation: 2.384835783116039]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1213704340829387		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1213704340829387 | validation: 2.3925298568583266]
	TIME [epoch: 13 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2679451834094246		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2679451834094246 | validation: 1.799924893044307]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9567230250435927		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9567230250435927 | validation: 2.2962368924850574]
	TIME [epoch: 13 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.747926299774006		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.747926299774006 | validation: 1.7877558209145659]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7226779082683472		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7226779082683472 | validation: 1.463830240835337]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.496492842574848		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.496492842574848 | validation: 1.819518137712541]
	TIME [epoch: 13 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6734901093338643		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6734901093338643 | validation: 3.769302387576106]
	TIME [epoch: 13 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2911423368440134		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2911423368440134 | validation: 3.0631334804555923]
	TIME [epoch: 13 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.236001018306723		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.236001018306723 | validation: 1.5857251473935299]
	TIME [epoch: 13 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4341101743673954		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4341101743673954 | validation: 1.437518969854789]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5505289574806955		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5505289574806955 | validation: 1.4388970601177955]
	TIME [epoch: 13 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4442168669889766		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4442168669889766 | validation: 1.436630393567666]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3395454026163391		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3395454026163391 | validation: 1.2334608459960286]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2375837659124453		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2375837659124453 | validation: 3.909775885424366]
	TIME [epoch: 13 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.217783845966321		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.217783845966321 | validation: 6.2303437479117365]
	TIME [epoch: 13 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.280819737958583		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.280819737958583 | validation: 6.720535304162463]
	TIME [epoch: 13 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.432870548344915		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.432870548344915 | validation: 4.7752474265480105]
	TIME [epoch: 13 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4709100564248185		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.4709100564248185 | validation: 3.8807690047125143]
	TIME [epoch: 13 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8618073763084926		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8618073763084926 | validation: 3.4464711081361576]
	TIME [epoch: 13 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3514079630433344		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3514079630433344 | validation: 3.0849420410095796]
	TIME [epoch: 13 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.914572227920334		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.914572227920334 | validation: 3.2776349019094373]
	TIME [epoch: 13 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.80276395562475		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.80276395562475 | validation: 2.7244024804751]
	TIME [epoch: 13 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.807682826713804		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 2.807682826713804 | validation: 2.669546023330241]
	TIME [epoch: 13 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.786433254163695		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 2.786433254163695 | validation: 2.6448081919757622]
	TIME [epoch: 13 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7767350444037255		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 2.7767350444037255 | validation: 2.9140806659779366]
	TIME [epoch: 13 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.654953961520859		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 2.654953961520859 | validation: 2.3296905811570183]
	TIME [epoch: 13 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.768516049339341		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 2.768516049339341 | validation: 2.576251616361604]
	TIME [epoch: 13 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4242716519487337		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 2.4242716519487337 | validation: 2.137539628823065]
	TIME [epoch: 13 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.45250838878973		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 2.45250838878973 | validation: 5.167169528522589]
	TIME [epoch: 13 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.710233467825258		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 4.710233467825258 | validation: 5.407797859478108]
	TIME [epoch: 13 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.508000377354788		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 4.508000377354788 | validation: 4.1109313784532056]
	TIME [epoch: 13 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3703421616395706		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 3.3703421616395706 | validation: 3.0619148771738702]
	TIME [epoch: 13 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2898830719446144		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 3.2898830719446144 | validation: 2.8381997193167128]
	TIME [epoch: 13 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.497757938641782		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 2.497757938641782 | validation: 2.2552059579736516]
	TIME [epoch: 13 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.282186943435299		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 2.282186943435299 | validation: 2.1150670619879746]
	TIME [epoch: 13 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8398968848924304		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 2.8398968848924304 | validation: 1.8957092420686519]
	TIME [epoch: 13 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.940071048889754		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 1.940071048889754 | validation: 2.180335712883408]
	TIME [epoch: 13 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9457836714750798		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 1.9457836714750798 | validation: 1.6771494558741658]
	TIME [epoch: 13 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1288235617685416		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 2.1288235617685416 | validation: 1.7376413015841814]
	TIME [epoch: 13 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5875508662198006		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 1.5875508662198006 | validation: 1.8473892414566357]
	TIME [epoch: 13 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3610537023134084		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 2.3610537023134084 | validation: 1.5587475027019662]
	TIME [epoch: 13 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0038041562747293		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 2.0038041562747293 | validation: 1.6660460492099716]
	TIME [epoch: 13 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.498350206330317		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 2.498350206330317 | validation: 4.18524600676659]
	TIME [epoch: 13 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.78196143128376		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 2.78196143128376 | validation: 1.6474324903132567]
	TIME [epoch: 13 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6628134035471622		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 1.6628134035471622 | validation: 1.4591995398512034]
	TIME [epoch: 13 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.290820853077182		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 2.290820853077182 | validation: 3.074933835487333]
	TIME [epoch: 13 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1509192378659487		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 2.1509192378659487 | validation: 1.4407768425463332]
	TIME [epoch: 13 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3742635839314368		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 1.3742635839314368 | validation: 1.6000227611575042]
	TIME [epoch: 13 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4527353957946028		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 1.4527353957946028 | validation: 1.288086892001374]
	TIME [epoch: 13 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4105527109975833		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 1.4105527109975833 | validation: 1.565011423381796]
	TIME [epoch: 13 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3876161151939868		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 1.3876161151939868 | validation: 1.3451606634037492]
	TIME [epoch: 13 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5441947264542055		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 1.5441947264542055 | validation: 2.037981225479886]
	TIME [epoch: 13 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0483939756823184		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 2.0483939756823184 | validation: 1.4098600853054213]
	TIME [epoch: 13 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2650099139124222		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 1.2650099139124222 | validation: 1.1687225629975035]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_82.pth
	Model improved!!!
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2520228806638838		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 1.2520228806638838 | validation: 0.9621740802284259]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_83.pth
	Model improved!!!
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0835623736278222		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 1.0835623736278222 | validation: 1.1430139091830336]
	TIME [epoch: 13 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3393164746382813		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 1.3393164746382813 | validation: 2.8701787794047173]
	TIME [epoch: 13 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8553148353757731		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 1.8553148353757731 | validation: 1.0798744037339885]
	TIME [epoch: 13 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0716031105785562		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 1.0716031105785562 | validation: 0.9142910818278707]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_87.pth
	Model improved!!!
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1572825502560957		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 1.1572825502560957 | validation: 1.2551489402948013]
	TIME [epoch: 13 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9595221103807066		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.9595221103807066 | validation: 1.2525393946988939]
	TIME [epoch: 13 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.469405022916963		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 1.469405022916963 | validation: 3.0409764594884408]
	TIME [epoch: 13 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7464967469748602		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 2.7464967469748602 | validation: 1.207179614092426]
	TIME [epoch: 13 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0559801827693172		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 1.0559801827693172 | validation: 2.461051906785544]
	TIME [epoch: 13 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4235608564747266		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 1.4235608564747266 | validation: 0.8852405598999971]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_93.pth
	Model improved!!!
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8064239993791261		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 0.8064239993791261 | validation: 0.9282558145015901]
	TIME [epoch: 13 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4621350704575609		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 1.4621350704575609 | validation: 2.6834307703868094]
	TIME [epoch: 13 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.796952456636284		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 1.796952456636284 | validation: 1.3145165490146127]
	TIME [epoch: 13 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4039792519726124		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 1.4039792519726124 | validation: 0.7567291084576181]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.072621172289767		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 1.072621172289767 | validation: 1.6412993504360116]
	TIME [epoch: 13 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1549201982699833		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 1.1549201982699833 | validation: 1.1326437264775204]
	TIME [epoch: 13 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8374629125052869		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.8374629125052869 | validation: 2.417229870271525]
	TIME [epoch: 13 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5159105366240007		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 1.5159105366240007 | validation: 0.6803654394463735]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_101.pth
	Model improved!!!
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9416486650798002		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 0.9416486650798002 | validation: 0.8693892612054]
	TIME [epoch: 13 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7404782518586928		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 0.7404782518586928 | validation: 0.6045524940463061]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_103.pth
	Model improved!!!
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7260754030208129		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 0.7260754030208129 | validation: 0.7498353814883661]
	TIME [epoch: 13 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.292582120904504		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 1.292582120904504 | validation: 0.7238689517711021]
	TIME [epoch: 13 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7097912046880086		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 0.7097912046880086 | validation: 0.7946720252676639]
	TIME [epoch: 13 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.688401578689565		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.688401578689565 | validation: 0.45112549866952223]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_107.pth
	Model improved!!!
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5843898590630683		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 0.5843898590630683 | validation: 0.4974742589933291]
	TIME [epoch: 13 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6267297994142557		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 0.6267297994142557 | validation: 0.6799111967491587]
	TIME [epoch: 13 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7509890381461872		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.7509890381461872 | validation: 0.6243649323471947]
	TIME [epoch: 13 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5316780506825408		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 0.5316780506825408 | validation: 0.45599163705456314]
	TIME [epoch: 13 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7510651424983996		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 0.7510651424983996 | validation: 0.5872625836430876]
	TIME [epoch: 13 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6901846099007634		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 0.6901846099007634 | validation: 0.7212149414768573]
	TIME [epoch: 13 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2494064425880982		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 1.2494064425880982 | validation: 2.3865350163256513]
	TIME [epoch: 13 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8718565861009777		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 3.8718565861009777 | validation: 3.491357404976363]
	TIME [epoch: 13 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.037310783105835		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 4.037310783105835 | validation: 3.50719955878367]
	TIME [epoch: 13 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.004916364776221		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 4.004916364776221 | validation: 3.2698008397102756]
	TIME [epoch: 13 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.79245805196625		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 3.79245805196625 | validation: 3.287785689973065]
	TIME [epoch: 13 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7561627608531998		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 3.7561627608531998 | validation: 3.239300807925884]
	TIME [epoch: 13 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7902990784344306		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 3.7902990784344306 | validation: 3.163936140031757]
	TIME [epoch: 13 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7091213846984585		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 3.7091213846984585 | validation: 3.318809148305421]
	TIME [epoch: 13 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6911930281008445		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 3.6911930281008445 | validation: 3.1499533474902406]
	TIME [epoch: 13 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.434913753329137		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 3.434913753329137 | validation: 2.536465407350681]
	TIME [epoch: 13 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8964813663825517		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 1.8964813663825517 | validation: 0.8700453540215596]
	TIME [epoch: 13 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7845149907130157		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.7845149907130157 | validation: 0.6800643701151147]
	TIME [epoch: 13 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9857601446540205		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 0.9857601446540205 | validation: 0.900552502745575]
	TIME [epoch: 13 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4985469397278717		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 1.4985469397278717 | validation: 1.1684321678083416]
	TIME [epoch: 13 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8478405566547139		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 0.8478405566547139 | validation: 0.5649175992829127]
	TIME [epoch: 13 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6742321103277673		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 0.6742321103277673 | validation: 0.9512964030679112]
	TIME [epoch: 13 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7826194188609885		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.7826194188609885 | validation: 0.7462646946391662]
	TIME [epoch: 13 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6397160500721357		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 0.6397160500721357 | validation: 0.6441251143317913]
	TIME [epoch: 13 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6834408450157805		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 0.6834408450157805 | validation: 0.6363930939764594]
	TIME [epoch: 13 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5223169833077184		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 0.5223169833077184 | validation: 0.9406419203259148]
	TIME [epoch: 13 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8880896924804313		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.8880896924804313 | validation: 0.6806562700915707]
	TIME [epoch: 13 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.057261063444267		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 1.057261063444267 | validation: 0.7831097595735454]
	TIME [epoch: 13 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6424702511437163		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.6424702511437163 | validation: 0.47244777157749507]
	TIME [epoch: 13 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4642433758063745		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 0.4642433758063745 | validation: 0.3870143984203686]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_137.pth
	Model improved!!!
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4618760329696884		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 0.4618760329696884 | validation: 0.3711314406701953]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_138.pth
	Model improved!!!
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5239149160153463		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 0.5239149160153463 | validation: 0.47792535325359503]
	TIME [epoch: 13 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45191528467763276		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.45191528467763276 | validation: 0.7522505222632725]
	TIME [epoch: 13 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4333332026979		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 1.4333332026979 | validation: 0.8187653316360056]
	TIME [epoch: 13 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.663054515668717		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.663054515668717 | validation: 0.6933063064042999]
	TIME [epoch: 13 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.791957990580844		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 1.791957990580844 | validation: 1.5876520008446244]
	TIME [epoch: 13 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1531730243854599		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 1.1531730243854599 | validation: 0.6850303978625181]
	TIME [epoch: 13 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6571046288700317		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.6571046288700317 | validation: 0.8706366656995865]
	TIME [epoch: 13 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7511622440006852		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.7511622440006852 | validation: 0.7073348172878591]
	TIME [epoch: 13 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.830977482652431		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.830977482652431 | validation: 0.6313090330262378]
	TIME [epoch: 13 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5961826682695787		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 0.5961826682695787 | validation: 0.4564886321436128]
	TIME [epoch: 13 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5299099243227756		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.5299099243227756 | validation: 0.5935093615457966]
	TIME [epoch: 13 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.512345590914522		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.512345590914522 | validation: 1.1839048593414365]
	TIME [epoch: 13 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7615664340249504		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.7615664340249504 | validation: 0.3501842917951426]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_151.pth
	Model improved!!!
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3859574580288987		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.3859574580288987 | validation: 0.4826164034365376]
	TIME [epoch: 13 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48457564523749913		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 0.48457564523749913 | validation: 0.2793716198057031]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_153.pth
	Model improved!!!
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3855670753047431		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.3855670753047431 | validation: 0.3601224275932275]
	TIME [epoch: 13 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5290787919455904		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.5290787919455904 | validation: 1.332880894128472]
	TIME [epoch: 13 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.076429628341187		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 1.076429628341187 | validation: 0.42021077252740496]
	TIME [epoch: 13 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4355809315457061		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 0.4355809315457061 | validation: 0.35451730324574654]
	TIME [epoch: 13 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3475420775444933		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 0.3475420775444933 | validation: 0.34819692650601836]
	TIME [epoch: 13 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7056231498838906		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.7056231498838906 | validation: 0.7367481625774879]
	TIME [epoch: 13 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6673923458640597		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.6673923458640597 | validation: 0.7513961159523679]
	TIME [epoch: 13 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4777398195928758		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.4777398195928758 | validation: 0.43483671588153483]
	TIME [epoch: 13 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1611039749053513		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 1.1611039749053513 | validation: 2.043683588547545]
	TIME [epoch: 13 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2229157768557364		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 1.2229157768557364 | validation: 0.5255755831173227]
	TIME [epoch: 13 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4710580966008784		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.4710580966008784 | validation: 0.3969707676778421]
	TIME [epoch: 13 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4976343663211567		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.4976343663211567 | validation: 0.4282479606405434]
	TIME [epoch: 13 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42389811684402906		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 0.42389811684402906 | validation: 0.2935468921229895]
	TIME [epoch: 13 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34405554185519477		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 0.34405554185519477 | validation: 0.3049541459424849]
	TIME [epoch: 13 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4331174968421037		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.4331174968421037 | validation: 0.6421135482507532]
	TIME [epoch: 13 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7190763546422538		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.7190763546422538 | validation: 0.4241453092750013]
	TIME [epoch: 13 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46904852885923326		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.46904852885923326 | validation: 0.5123154362922346]
	TIME [epoch: 13 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3581925858254488		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.3581925858254488 | validation: 0.3039220561859035]
	TIME [epoch: 13 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4202345227735984		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.4202345227735984 | validation: 0.33997228614829816]
	TIME [epoch: 13 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35648880912315317		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.35648880912315317 | validation: 0.38795375472083693]
	TIME [epoch: 13 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4017156679007172		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.4017156679007172 | validation: 0.32226308698518197]
	TIME [epoch: 13 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35640975467316566		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.35640975467316566 | validation: 0.40229000764855827]
	TIME [epoch: 13 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3901454810019349		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 0.3901454810019349 | validation: 0.2333301724447444]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_176.pth
	Model improved!!!
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2899002077360138		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.2899002077360138 | validation: 0.20385296171471548]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_177.pth
	Model improved!!!
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49903853890605254		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.49903853890605254 | validation: 0.49952461831584194]
	TIME [epoch: 13 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39523845040536465		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.39523845040536465 | validation: 0.47669040908130145]
	TIME [epoch: 13 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47364895053699785		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.47364895053699785 | validation: 0.41098664989475425]
	TIME [epoch: 13 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41302119076835825		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.41302119076835825 | validation: 0.40422007432278945]
	TIME [epoch: 13 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38723054840521276		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.38723054840521276 | validation: 0.26484929554393727]
	TIME [epoch: 13 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3708834854664939		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.3708834854664939 | validation: 0.39273765139972133]
	TIME [epoch: 13 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7929871653904876		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.7929871653904876 | validation: 0.42635356585110984]
	TIME [epoch: 13 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4451585545577835		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.4451585545577835 | validation: 0.2921974161995802]
	TIME [epoch: 13 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36844245408531295		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.36844245408531295 | validation: 0.2889953777347416]
	TIME [epoch: 13 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32696724823752565		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.32696724823752565 | validation: 0.22899169972134928]
	TIME [epoch: 13 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3265494629465728		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.3265494629465728 | validation: 0.49655734159696807]
	TIME [epoch: 13 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41227263910684686		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.41227263910684686 | validation: 0.2518828035985481]
	TIME [epoch: 13 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3708597602764869		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.3708597602764869 | validation: 0.33947494654710964]
	TIME [epoch: 13 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9556584387922182		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.9556584387922182 | validation: 1.378164006500464]
	TIME [epoch: 13 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.623807367985474		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.623807367985474 | validation: 0.31152442380652695]
	TIME [epoch: 13 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.051470498341887		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 1.051470498341887 | validation: 0.3532909262510763]
	TIME [epoch: 13 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5425693915972849		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.5425693915972849 | validation: 0.34011714893280526]
	TIME [epoch: 13 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4773647204399156		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.4773647204399156 | validation: 0.47429546603525324]
	TIME [epoch: 13 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5117215870780119		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.5117215870780119 | validation: 0.3896947592691452]
	TIME [epoch: 13 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49365991203100845		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.49365991203100845 | validation: 0.43098689862417405]
	TIME [epoch: 13 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3831534373949048		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.3831534373949048 | validation: 0.3087344983698771]
	TIME [epoch: 13 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3490648750015362		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.3490648750015362 | validation: 0.33438029744781317]
	TIME [epoch: 13 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36486525519747914		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.36486525519747914 | validation: 0.3442547496946956]
	TIME [epoch: 13 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33442611182876064		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.33442611182876064 | validation: 0.5359674785969434]
	TIME [epoch: 13 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49471440746527506		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.49471440746527506 | validation: 0.31230990517529833]
	TIME [epoch: 13 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33630855702860823		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.33630855702860823 | validation: 0.37982046439050804]
	TIME [epoch: 13 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6941865335436422		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.6941865335436422 | validation: 0.6703266371180979]
	TIME [epoch: 13 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2464067297628088		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 1.2464067297628088 | validation: 0.5556458160820656]
	TIME [epoch: 13 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5378519271915235		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.5378519271915235 | validation: 0.48883497375085155]
	TIME [epoch: 13 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5346433291998767		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.5346433291998767 | validation: 0.4652699790967698]
	TIME [epoch: 13 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5302945370082595		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.5302945370082595 | validation: 0.4664623523849922]
	TIME [epoch: 13 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4319137705565617		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.4319137705565617 | validation: 0.361384408752981]
	TIME [epoch: 13 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3889633925921507		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.3889633925921507 | validation: 0.3488830259704437]
	TIME [epoch: 13 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34961843082646726		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.34961843082646726 | validation: 0.26822874317443796]
	TIME [epoch: 13 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36439738772210617		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.36439738772210617 | validation: 0.36239360645159885]
	TIME [epoch: 13 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39140711652860294		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.39140711652860294 | validation: 0.3036977887299228]
	TIME [epoch: 13 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39557153371042475		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.39557153371042475 | validation: 0.26782640804375335]
	TIME [epoch: 13 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3322025444238402		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.3322025444238402 | validation: 0.30688876474306037]
	TIME [epoch: 13 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36735305409400654		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.36735305409400654 | validation: 0.2541455665909145]
	TIME [epoch: 13 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33680743337174657		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.33680743337174657 | validation: 0.28121886135762886]
	TIME [epoch: 13 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30998712181263205		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.30998712181263205 | validation: 0.30283818011776276]
	TIME [epoch: 13 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32983905917997586		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.32983905917997586 | validation: 0.23361520882183429]
	TIME [epoch: 13 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33713137805062227		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.33713137805062227 | validation: 0.3882701526027056]
	TIME [epoch: 13 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38976748819970913		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.38976748819970913 | validation: 0.19391133190964877]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_221.pth
	Model improved!!!
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29460324961729045		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.29460324961729045 | validation: 0.26546753984950094]
	TIME [epoch: 13 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3791089467062705		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.3791089467062705 | validation: 0.4654165176809573]
	TIME [epoch: 13 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44480909022754705		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.44480909022754705 | validation: 0.48667366163364756]
	TIME [epoch: 13 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4172959213545959		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.4172959213545959 | validation: 0.26506525144132426]
	TIME [epoch: 13 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2747374013066806		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.2747374013066806 | validation: 0.26823530078475744]
	TIME [epoch: 13 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30351853007009577		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.30351853007009577 | validation: 0.3397741997826009]
	TIME [epoch: 13 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2963575103792342		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.2963575103792342 | validation: 0.2375576148462722]
	TIME [epoch: 13 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42020014864541866		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.42020014864541866 | validation: 0.31190097348101903]
	TIME [epoch: 13 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3402771004443273		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.3402771004443273 | validation: 0.4099800328982463]
	TIME [epoch: 13 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36499080907578174		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.36499080907578174 | validation: 0.7607104895335004]
	TIME [epoch: 13 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8333827430088849		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.8333827430088849 | validation: 0.804356021620664]
	TIME [epoch: 13 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5199459650159537		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 1.5199459650159537 | validation: 0.5769076213431256]
	TIME [epoch: 13.1 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5467448991773259		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.5467448991773259 | validation: 0.48910074685981386]
	TIME [epoch: 13 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47048850788613295		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.47048850788613295 | validation: 0.2558989861119041]
	TIME [epoch: 13 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2796062295384837		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.2796062295384837 | validation: 0.2743259934376721]
	TIME [epoch: 13 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31083260738105384		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.31083260738105384 | validation: 0.3869342159564842]
	TIME [epoch: 13 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3942834724765609		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.3942834724765609 | validation: 0.28891552637280427]
	TIME [epoch: 13 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3133344999173675		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.3133344999173675 | validation: 0.4366709115182178]
	TIME [epoch: 13 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3364234302840137		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.3364234302840137 | validation: 0.3016433266423909]
	TIME [epoch: 13 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45716594699541124		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.45716594699541124 | validation: 0.32646389102827833]
	TIME [epoch: 13 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3336217576526083		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.3336217576526083 | validation: 0.22623677455485466]
	TIME [epoch: 13 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24154375733692662		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.24154375733692662 | validation: 0.3421057348125677]
	TIME [epoch: 13 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2820812000338376		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.2820812000338376 | validation: 0.19057239731964992]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_244.pth
	Model improved!!!
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2620972717237292		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.2620972717237292 | validation: 0.17974292284310028]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_245.pth
	Model improved!!!
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23292328807318147		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.23292328807318147 | validation: 0.3982535651372422]
	TIME [epoch: 13 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31070451869308746		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.31070451869308746 | validation: 0.3105465281759366]
	TIME [epoch: 13 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3583219665807551		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.3583219665807551 | validation: 0.3366853261341242]
	TIME [epoch: 13 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2872892128526265		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.2872892128526265 | validation: 0.2636844462800615]
	TIME [epoch: 13 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28065629589281005		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.28065629589281005 | validation: 0.2396378033425259]
	TIME [epoch: 13 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2584325081318036		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.2584325081318036 | validation: 0.31806418772485784]
	TIME [epoch: 13 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2814821140808756		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.2814821140808756 | validation: 0.19460843643617054]
	TIME [epoch: 13 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2407545023320122		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.2407545023320122 | validation: 0.21060966856955873]
	TIME [epoch: 13 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2577718152917155		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.2577718152917155 | validation: 0.2217595523196249]
	TIME [epoch: 13 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31881134016218066		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.31881134016218066 | validation: 0.3009627300067728]
	TIME [epoch: 13 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37381252494383077		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.37381252494383077 | validation: 0.31288802324354487]
	TIME [epoch: 13 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3169949595944256		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.3169949595944256 | validation: 0.2242888723534532]
	TIME [epoch: 13 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3457793975801003		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.3457793975801003 | validation: 0.2631424445632272]
	TIME [epoch: 13 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29187048655004333		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.29187048655004333 | validation: 0.2930158468061381]
	TIME [epoch: 13 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3383117183764962		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.3383117183764962 | validation: 0.26942599943613926]
	TIME [epoch: 13 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3143366940002076		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.3143366940002076 | validation: 0.18776937759717827]
	TIME [epoch: 13 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2940977966386086		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.2940977966386086 | validation: 0.3475440604990125]
	TIME [epoch: 13 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30584097811259536		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.30584097811259536 | validation: 0.3137748799790896]
	TIME [epoch: 13 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3598596915629252		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.3598596915629252 | validation: 0.27167604894778646]
	TIME [epoch: 13 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2531113659189611		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.2531113659189611 | validation: 0.19792057251705333]
	TIME [epoch: 13 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31188911374492845		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.31188911374492845 | validation: 0.23704234845821337]
	TIME [epoch: 13 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9667884563227828		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.9667884563227828 | validation: 1.8474705540513643]
	TIME [epoch: 13 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.211024483458812		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 1.211024483458812 | validation: 0.4139835423921553]
	TIME [epoch: 13 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4076411397467704		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.4076411397467704 | validation: 0.2951849985796108]
	TIME [epoch: 13 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3093136256599943		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.3093136256599943 | validation: 0.2107112552498187]
	TIME [epoch: 13 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7179765575979217		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.7179765575979217 | validation: 3.1265167637786204]
	TIME [epoch: 13 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0424291726782933		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 2.0424291726782933 | validation: 0.4036316779685484]
	TIME [epoch: 13 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3681046707839173		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.3681046707839173 | validation: 0.32066433157214086]
	TIME [epoch: 13.1 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49153430553001903		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.49153430553001903 | validation: 0.3028334657450919]
	TIME [epoch: 13 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29290821603206635		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.29290821603206635 | validation: 0.2717356061230375]
	TIME [epoch: 13 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32798491132378566		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.32798491132378566 | validation: 0.28832841761594213]
	TIME [epoch: 13 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34657802620201716		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.34657802620201716 | validation: 0.34525320591181]
	TIME [epoch: 13 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2912672891975194		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.2912672891975194 | validation: 0.20550678654203552]
	TIME [epoch: 13 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22983170150350196		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.22983170150350196 | validation: 0.20715013065138052]
	TIME [epoch: 13 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24878302236366343		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.24878302236366343 | validation: 0.28122769416502813]
	TIME [epoch: 13 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28716859011451795		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.28716859011451795 | validation: 0.32590235338328094]
	TIME [epoch: 13 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3343846019279127		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.3343846019279127 | validation: 0.21800289182706523]
	TIME [epoch: 13 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26044382381984765		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.26044382381984765 | validation: 0.1982393010574826]
	TIME [epoch: 13 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23934723864266502		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.23934723864266502 | validation: 0.23934650458065043]
	TIME [epoch: 13 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26940198824827954		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.26940198824827954 | validation: 0.25150788058213175]
	TIME [epoch: 13 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2647178045035872		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.2647178045035872 | validation: 0.5546608592769458]
	TIME [epoch: 13 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44918674740591286		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.44918674740591286 | validation: 0.2828668288621414]
	TIME [epoch: 13 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2904818374823914		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.2904818374823914 | validation: 0.21777042351633746]
	TIME [epoch: 13 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29528259725288875		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.29528259725288875 | validation: 0.23059251290790284]
	TIME [epoch: 13 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2570503321267449		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.2570503321267449 | validation: 0.20050271446937262]
	TIME [epoch: 13 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23589665489771416		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.23589665489771416 | validation: 0.20187264783633319]
	TIME [epoch: 13 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2568022268293813		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.2568022268293813 | validation: 0.26303645476876836]
	TIME [epoch: 13 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5718044248004887		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.5718044248004887 | validation: 0.3087220454859281]
	TIME [epoch: 13 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27969796588745355		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.27969796588745355 | validation: 0.15469071055748576]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_294.pth
	Model improved!!!
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2098039820543158		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.2098039820543158 | validation: 0.16279682994184627]
	TIME [epoch: 13 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27704321684786065		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.27704321684786065 | validation: 0.3908808448083947]
	TIME [epoch: 13 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3683492953740506		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.3683492953740506 | validation: 0.4380755582051114]
	TIME [epoch: 13 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6913986711337047		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.6913986711337047 | validation: 0.6262986196215428]
	TIME [epoch: 13 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5943731480113069		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.5943731480113069 | validation: 0.4131545823393602]
	TIME [epoch: 13 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5024295249407098		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.5024295249407098 | validation: 0.3531618318820299]
	TIME [epoch: 13 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2912463058856983		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.2912463058856983 | validation: 0.2150017724349901]
	TIME [epoch: 13 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23532301386271953		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.23532301386271953 | validation: 0.21296893032698797]
	TIME [epoch: 13 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22869917355715455		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.22869917355715455 | validation: 0.2858535490651426]
	TIME [epoch: 13 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.272545930022516		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.272545930022516 | validation: 0.18191004588585993]
	TIME [epoch: 13 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2193557922059604		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.2193557922059604 | validation: 0.2559047466524395]
	TIME [epoch: 13 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29212314932573874		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.29212314932573874 | validation: 0.2026847162511082]
	TIME [epoch: 13 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.355201027762697		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.355201027762697 | validation: 0.2955319608030469]
	TIME [epoch: 13 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2626576840727104		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.2626576840727104 | validation: 0.29522814850361584]
	TIME [epoch: 13 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3136048045057228		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.3136048045057228 | validation: 0.29161515399511007]
	TIME [epoch: 13 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2501259646208456		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.2501259646208456 | validation: 0.17882138969319336]
	TIME [epoch: 13 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21220418259425253		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.21220418259425253 | validation: 0.32142771565976647]
	TIME [epoch: 13 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31367161082804845		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.31367161082804845 | validation: 0.19120837464027318]
	TIME [epoch: 13 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2279137322828885		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.2279137322828885 | validation: 0.1675017880750595]
	TIME [epoch: 13 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2108340486767472		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.2108340486767472 | validation: 0.18211111839316474]
	TIME [epoch: 13 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26946906145750243		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.26946906145750243 | validation: 0.2076360801988539]
	TIME [epoch: 13 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2729824800645176		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.2729824800645176 | validation: 0.2562246266641358]
	TIME [epoch: 13 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2852071028568673		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.2852071028568673 | validation: 0.2727741382660733]
	TIME [epoch: 13 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2374738546981271		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.2374738546981271 | validation: 0.23851419567555618]
	TIME [epoch: 13 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24231514161745532		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.24231514161745532 | validation: 0.14434925554976752]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_319.pth
	Model improved!!!
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23788604560829396		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.23788604560829396 | validation: 0.27344495464428814]
	TIME [epoch: 13 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23050170001355616		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.23050170001355616 | validation: 0.23945402463337295]
	TIME [epoch: 13 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22477855062578073		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.22477855062578073 | validation: 0.3353755743043986]
	TIME [epoch: 13 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3329874415354586		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.3329874415354586 | validation: 0.1851236511090758]
	TIME [epoch: 13 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2434659456872393		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.2434659456872393 | validation: 0.17126289936535968]
	TIME [epoch: 13 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26799225830948276		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.26799225830948276 | validation: 0.21573157042190413]
	TIME [epoch: 13 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23580888896837585		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.23580888896837585 | validation: 0.18609454994116006]
	TIME [epoch: 13 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20873650807317629		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.20873650807317629 | validation: 0.14994908946113847]
	TIME [epoch: 13 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21424832320491288		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.21424832320491288 | validation: 0.22124551097901815]
	TIME [epoch: 13 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2655928753650161		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.2655928753650161 | validation: 0.24232822650675534]
	TIME [epoch: 13 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22218863317448045		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.22218863317448045 | validation: 0.382595646574857]
	TIME [epoch: 13 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34396052179206926		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.34396052179206926 | validation: 0.2153122436854244]
	TIME [epoch: 13 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29472349949141685		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.29472349949141685 | validation: 0.26019870344042306]
	TIME [epoch: 13 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2552063506468719		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.2552063506468719 | validation: 0.2443905309895219]
	TIME [epoch: 13 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2834994721764881		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.2834994721764881 | validation: 0.21907976160617865]
	TIME [epoch: 13 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3159121933024591		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.3159121933024591 | validation: 0.20641124880338527]
	TIME [epoch: 13 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22441266593768222		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.22441266593768222 | validation: 0.1770837601592086]
	TIME [epoch: 13 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26351136563085303		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.26351136563085303 | validation: 0.22933334131378438]
	TIME [epoch: 13 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24400145302773238		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.24400145302773238 | validation: 0.2816937531611156]
	TIME [epoch: 13 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7834854817644787		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.7834854817644787 | validation: 0.7000272198257831]
	TIME [epoch: 13 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48223527014715484		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.48223527014715484 | validation: 0.3372068820851413]
	TIME [epoch: 13 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9026737639979676		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.9026737639979676 | validation: 0.8356979607636756]
	TIME [epoch: 13 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7547891946431198		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.7547891946431198 | validation: 1.5969324158648739]
	TIME [epoch: 13 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.254127204415081		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 1.254127204415081 | validation: 0.6946244751608965]
	TIME [epoch: 13 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5543039393501838		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.5543039393501838 | validation: 0.3203628453942748]
	TIME [epoch: 13 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37560699161840316		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.37560699161840316 | validation: 0.43336115292120897]
	TIME [epoch: 13 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4751236857554205		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.4751236857554205 | validation: 0.35258534708908107]
	TIME [epoch: 13 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.266585577667307		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.266585577667307 | validation: 0.17936047901097588]
	TIME [epoch: 13 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22431629586314003		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.22431629586314003 | validation: 0.18387439827530597]
	TIME [epoch: 13 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25162617156413936		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.25162617156413936 | validation: 0.21060448786876676]
	TIME [epoch: 13 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23818722634889106		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.23818722634889106 | validation: 0.14553682413294253]
	TIME [epoch: 13 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18616807021870427		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.18616807021870427 | validation: 0.19756154729947242]
	TIME [epoch: 13 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2743906721881474		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.2743906721881474 | validation: 0.23997195506640398]
	TIME [epoch: 13 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20226900380590862		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.20226900380590862 | validation: 0.1540374324200151]
	TIME [epoch: 13 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16753307123701155		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.16753307123701155 | validation: 0.15220861443642433]
	TIME [epoch: 13 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1794037602630126		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.1794037602630126 | validation: 0.16030780239104447]
	TIME [epoch: 13 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17706265500704024		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.17706265500704024 | validation: 0.19149783735711648]
	TIME [epoch: 13 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22306067186339407		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.22306067186339407 | validation: 0.13545968197128613]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_357.pth
	Model improved!!!
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16466462944777616		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.16466462944777616 | validation: 0.13898680657168458]
	TIME [epoch: 13 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2203103619346255		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.2203103619346255 | validation: 0.13754960886788006]
	TIME [epoch: 13 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18726716408404565		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.18726716408404565 | validation: 0.18934028771069022]
	TIME [epoch: 13 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23975872825339029		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.23975872825339029 | validation: 0.22130554307162478]
	TIME [epoch: 13 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27283458990508525		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.27283458990508525 | validation: 0.3538461121049589]
	TIME [epoch: 13 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3120800653746534		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.3120800653746534 | validation: 0.17789947698164887]
	TIME [epoch: 13 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2269582261021153		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.2269582261021153 | validation: 0.16443359632853968]
	TIME [epoch: 13 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1743675511977088		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.1743675511977088 | validation: 0.1479022199314761]
	TIME [epoch: 13 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1787710150145242		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.1787710150145242 | validation: 0.11964295658554262]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_366.pth
	Model improved!!!
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24553845632115762		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.24553845632115762 | validation: 0.18342810232303117]
	TIME [epoch: 13 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24409549945295875		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.24409549945295875 | validation: 0.2712546552332813]
	TIME [epoch: 13 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.264116964703239		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.264116964703239 | validation: 0.12480467993887409]
	TIME [epoch: 13 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3525974826395713		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.3525974826395713 | validation: 0.38876199085386065]
	TIME [epoch: 13 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6495038422810772		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.6495038422810772 | validation: 1.025981215086619]
	TIME [epoch: 13 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8276787353099935		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.8276787353099935 | validation: 0.4411545387872129]
	TIME [epoch: 13 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5613802723280377		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.5613802723280377 | validation: 0.39101300954411505]
	TIME [epoch: 13 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5769375747547276		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.5769375747547276 | validation: 0.5204542002594017]
	TIME [epoch: 13 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47666730456669276		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.47666730456669276 | validation: 0.38007954257883797]
	TIME [epoch: 13 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4991551374046175		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.4991551374046175 | validation: 0.4991460383241187]
	TIME [epoch: 13 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8142851269674685		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.8142851269674685 | validation: 0.7369327201181872]
	TIME [epoch: 13 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.924516065154876		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.924516065154876 | validation: 0.9222794940397185]
	TIME [epoch: 13 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8466247898065168		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.8466247898065168 | validation: 0.474625391436466]
	TIME [epoch: 13 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4538817611431569		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.4538817611431569 | validation: 0.29862580346021256]
	TIME [epoch: 13 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37694309050756986		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.37694309050756986 | validation: 0.4430135630492738]
	TIME [epoch: 13 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41617394895605153		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.41617394895605153 | validation: 0.3409995300864732]
	TIME [epoch: 13 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5071545249696671		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.5071545249696671 | validation: 0.6963643302108665]
	TIME [epoch: 13 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5839060300345459		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.5839060300345459 | validation: 0.29327346349543176]
	TIME [epoch: 13 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27104272244226113		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.27104272244226113 | validation: 0.27603183341797555]
	TIME [epoch: 13 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2553621944698389		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.2553621944698389 | validation: 0.18470458593300104]
	TIME [epoch: 13 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18413655898509054		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.18413655898509054 | validation: 0.23492205841846]
	TIME [epoch: 13 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20662606779757983		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.20662606779757983 | validation: 0.15947548978929113]
	TIME [epoch: 13 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17443213414179207		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.17443213414179207 | validation: 0.2019940801134493]
	TIME [epoch: 13 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3006032031717343		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.3006032031717343 | validation: 0.8606758438438559]
	TIME [epoch: 13 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7865313819333999		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.7865313819333999 | validation: 0.8133771446457072]
	TIME [epoch: 13 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6720558605466922		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.6720558605466922 | validation: 0.27317926196679415]
	TIME [epoch: 13 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39624558784032315		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.39624558784032315 | validation: 0.3324334274266029]
	TIME [epoch: 13 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3735551986199804		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.3735551986199804 | validation: 0.17509661928705345]
	TIME [epoch: 13 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20225916621177964		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.20225916621177964 | validation: 0.2049255604657715]
	TIME [epoch: 13 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18891177625540384		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.18891177625540384 | validation: 0.20728143211025224]
	TIME [epoch: 13 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17945481530713253		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.17945481530713253 | validation: 0.1283500195614167]
	TIME [epoch: 13 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14134461386496078		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.14134461386496078 | validation: 0.12107079849436446]
	TIME [epoch: 13 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1263889302661615		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.1263889302661615 | validation: 0.2283047838886452]
	TIME [epoch: 13 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21530381043758726		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.21530381043758726 | validation: 0.10887228543974806]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_400.pth
	Model improved!!!
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16799175590598303		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.16799175590598303 | validation: 0.19727761665469665]
	TIME [epoch: 13 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2102249602609847		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.2102249602609847 | validation: 0.20707553751031577]
	TIME [epoch: 13 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20974672809087808		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.20974672809087808 | validation: 0.14604437778455703]
	TIME [epoch: 13 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18415562629722168		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.18415562629722168 | validation: 0.14547987684993235]
	TIME [epoch: 13 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18207985038166202		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.18207985038166202 | validation: 0.18176815313857783]
	TIME [epoch: 13 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1874228519293961		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.1874228519293961 | validation: 0.2424922599546248]
	TIME [epoch: 13 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22397602368016595		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.22397602368016595 | validation: 0.1690923386536392]
	TIME [epoch: 13 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24454306010795088		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.24454306010795088 | validation: 0.36891653111446926]
	TIME [epoch: 13 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29989136064755406		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.29989136064755406 | validation: 0.14934157126745404]
	TIME [epoch: 13 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3297195365230525		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.3297195365230525 | validation: 0.7408704337696241]
	TIME [epoch: 13 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5284314385394038		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.5284314385394038 | validation: 0.20422369479792607]
	TIME [epoch: 13 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22159303057005422		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.22159303057005422 | validation: 0.21336144152471057]
	TIME [epoch: 13 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4870051816102786		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.4870051816102786 | validation: 0.4783101277634589]
	TIME [epoch: 13 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34614015962619016		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.34614015962619016 | validation: 0.21333682755321157]
	TIME [epoch: 13 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2305301942405456		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.2305301942405456 | validation: 0.17336698477914644]
	TIME [epoch: 13 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21129213906123115		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.21129213906123115 | validation: 0.2217843499653908]
	TIME [epoch: 13 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31513566147908273		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.31513566147908273 | validation: 0.3042718160818095]
	TIME [epoch: 13 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4086334832042697		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.4086334832042697 | validation: 0.3587277057343111]
	TIME [epoch: 13 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34228074114021484		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.34228074114021484 | validation: 0.22602855358367724]
	TIME [epoch: 13 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19277737401836845		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.19277737401836845 | validation: 0.1690056023905814]
	TIME [epoch: 13 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2282610629557228		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.2282610629557228 | validation: 0.1547551336355209]
	TIME [epoch: 13 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11812798162042362		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.11812798162042362 | validation: 0.16030248183024173]
	TIME [epoch: 13 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16222809459935428		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.16222809459935428 | validation: 0.06700869694288829]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_423.pth
	Model improved!!!
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12383655815594179		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.12383655815594179 | validation: 0.04782361303845589]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_424.pth
	Model improved!!!
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13933736165619887		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.13933736165619887 | validation: 0.12043298930471995]
	TIME [epoch: 13 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12089520139752014		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.12089520139752014 | validation: 0.15099835901408748]
	TIME [epoch: 13 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13457907636199962		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.13457907636199962 | validation: 0.12153473636780819]
	TIME [epoch: 13 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10289794875069534		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.10289794875069534 | validation: 0.10351198518284552]
	TIME [epoch: 13 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14361195813663244		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.14361195813663244 | validation: 0.5004047030650468]
	TIME [epoch: 13 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6177636835572182		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.6177636835572182 | validation: 0.2346000679595608]
	TIME [epoch: 13 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21586417760101084		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.21586417760101084 | validation: 0.20270507925339906]
	TIME [epoch: 13 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2913855225856718		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.2913855225856718 | validation: 0.2967347411293112]
	TIME [epoch: 13 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23321967829157442		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.23321967829157442 | validation: 0.10653014592661864]
	TIME [epoch: 13 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11412617199337899		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.11412617199337899 | validation: 0.10699446115917843]
	TIME [epoch: 13 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12395256411265956		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.12395256411265956 | validation: 0.11564110011581777]
	TIME [epoch: 13 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1879527740565473		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.1879527740565473 | validation: 0.21622416039604136]
	TIME [epoch: 13 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26024951335115437		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.26024951335115437 | validation: 0.2289334657586916]
	TIME [epoch: 13 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2103162164276478		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.2103162164276478 | validation: 0.18636183398050613]
	TIME [epoch: 13 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16050169613585966		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.16050169613585966 | validation: 0.09844958375424125]
	TIME [epoch: 13 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14952393948397785		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.14952393948397785 | validation: 0.08802023276630301]
	TIME [epoch: 13 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14610545169313613		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.14610545169313613 | validation: 0.08845819848243537]
	TIME [epoch: 13 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12957011611611052		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.12957011611611052 | validation: 0.07935996543884814]
	TIME [epoch: 13 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09622603676172942		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.09622603676172942 | validation: 0.07975505531492176]
	TIME [epoch: 13 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1816250262019422		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.1816250262019422 | validation: 0.2503941679940218]
	TIME [epoch: 13 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.194352673991656		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.194352673991656 | validation: 0.25708531106224014]
	TIME [epoch: 13 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2481727582455383		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.2481727582455383 | validation: 0.2241523946600914]
	TIME [epoch: 13 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21735536060786753		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.21735536060786753 | validation: 0.1479462043341234]
	TIME [epoch: 13 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16225698918752937		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.16225698918752937 | validation: 0.11922111212036082]
	TIME [epoch: 13 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13591251809379237		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.13591251809379237 | validation: 0.10051786454650817]
	TIME [epoch: 13 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16012971585179103		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.16012971585179103 | validation: 0.2265005145751169]
	TIME [epoch: 13 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2147016421367784		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.2147016421367784 | validation: 0.10929757774674713]
	TIME [epoch: 13 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1975717834770564		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.1975717834770564 | validation: 0.17839635506244172]
	TIME [epoch: 13 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1571665000312728		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.1571665000312728 | validation: 0.14362793039847085]
	TIME [epoch: 13 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14939502994098464		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.14939502994098464 | validation: 0.13319835841483718]
	TIME [epoch: 13 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14485887912242532		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.14485887912242532 | validation: 0.14176816817902463]
	TIME [epoch: 13 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1669614677155837		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.1669614677155837 | validation: 0.1602650471808935]
	TIME [epoch: 13 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15315886464857142		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.15315886464857142 | validation: 0.14667846180745073]
	TIME [epoch: 13 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15914424656229792		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.15914424656229792 | validation: 0.09441415419032863]
	TIME [epoch: 13 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16374175716480177		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.16374175716480177 | validation: 0.20156228417125868]
	TIME [epoch: 13 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.262237315241876		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.262237315241876 | validation: 0.1898795762933071]
	TIME [epoch: 13 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21393126241961005		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.21393126241961005 | validation: 0.16170013129179425]
	TIME [epoch: 13 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20424341526928078		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.20424341526928078 | validation: 0.18215721776323968]
	TIME [epoch: 13 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20703603593286374		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.20703603593286374 | validation: 0.1345241295008125]
	TIME [epoch: 13 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14289507769102802		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.14289507769102802 | validation: 0.11357384134094116]
	TIME [epoch: 13 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16159481849997526		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.16159481849997526 | validation: 0.1889815254641467]
	TIME [epoch: 13.1 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1699027484003291		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.1699027484003291 | validation: 0.16221448927363802]
	TIME [epoch: 13 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17027128845682293		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.17027128845682293 | validation: 0.11001318400316673]
	TIME [epoch: 13 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13447674464467013		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.13447674464467013 | validation: 0.10743973905033301]
	TIME [epoch: 13.1 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14337451317204955		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.14337451317204955 | validation: 0.09568063195780269]
	TIME [epoch: 13 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11232977984470086		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.11232977984470086 | validation: 0.09921126971626994]
	TIME [epoch: 13 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1510822458357227		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.1510822458357227 | validation: 0.11870141811769984]
	TIME [epoch: 13 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1273226195535471		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.1273226195535471 | validation: 0.08785049214958779]
	TIME [epoch: 13 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14605856993890443		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.14605856993890443 | validation: 0.10027607250099951]
	TIME [epoch: 13 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12069772685335642		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.12069772685335642 | validation: 0.10046905322055469]
	TIME [epoch: 13 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15852666916191255		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.15852666916191255 | validation: 0.19041552394465527]
	TIME [epoch: 13 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20149295877320822		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.20149295877320822 | validation: 0.13466173030633397]
	TIME [epoch: 13 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16962511171456282		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.16962511171456282 | validation: 0.14914839194939392]
	TIME [epoch: 13 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1702521497674619		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.1702521497674619 | validation: 0.14300579645224637]
	TIME [epoch: 13 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14649419815332634		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.14649419815332634 | validation: 0.14955198815708592]
	TIME [epoch: 13 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17819921691087978		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.17819921691087978 | validation: 0.16235326931303373]
	TIME [epoch: 13 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22848582397423514		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.22848582397423514 | validation: 0.17151415974764891]
	TIME [epoch: 13 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21269721328455193		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.21269721328455193 | validation: 0.18891330861961508]
	TIME [epoch: 13 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24700950185028356		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.24700950185028356 | validation: 0.17301432718757498]
	TIME [epoch: 13 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21607985168215585		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.21607985168215585 | validation: 0.17177066118663448]
	TIME [epoch: 13 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18389534308744		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.18389534308744 | validation: 0.14539283850564919]
	TIME [epoch: 13 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17340458828783134		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.17340458828783134 | validation: 0.13728404620709087]
	TIME [epoch: 13 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17090043686304968		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.17090043686304968 | validation: 0.20298111745488612]
	TIME [epoch: 13 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19129709246312862		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.19129709246312862 | validation: 0.1189166980811244]
	TIME [epoch: 13 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15630948574065334		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.15630948574065334 | validation: 0.24500979555753183]
	TIME [epoch: 13 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.201158245783861		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.201158245783861 | validation: 0.12392979038101863]
	TIME [epoch: 13 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1809496983112158		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.1809496983112158 | validation: 0.16787752376072443]
	TIME [epoch: 13 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17023806949238024		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.17023806949238024 | validation: 0.16139405622279449]
	TIME [epoch: 13 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24833226284699975		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.24833226284699975 | validation: 0.1276699149884077]
	TIME [epoch: 13 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16356833838149848		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.16356833838149848 | validation: 0.16728335625801533]
	TIME [epoch: 13 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15079825764579524		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.15079825764579524 | validation: 0.10929538397175098]
	TIME [epoch: 13 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14046994753898617		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.14046994753898617 | validation: 0.11439287992369965]
	TIME [epoch: 13 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15101362168386429		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.15101362168386429 | validation: 0.19187281625665178]
	TIME [epoch: 13.1 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14807581024432814		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.14807581024432814 | validation: 0.08798729387270136]
	TIME [epoch: 13 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1226270062409234		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.1226270062409234 | validation: 0.11040577909607546]
	TIME [epoch: 13 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12629291274239318		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.12629291274239318 | validation: 0.11882599898583954]
	TIME [epoch: 13 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1403866296836113		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.1403866296836113 | validation: 0.10794459929010822]
	TIME [epoch: 13 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1316355417811875		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.1316355417811875 | validation: 0.07976070783914134]
	TIME [epoch: 13 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1101903182397724		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.1101903182397724 | validation: 0.10086916832221335]
	TIME [epoch: 13 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.122302068627577		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.122302068627577 | validation: 0.11783630719065782]
	TIME [epoch: 13 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14879775944581178		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.14879775944581178 | validation: 0.18952548498778415]
	TIME [epoch: 13 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16520232047577194		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.16520232047577194 | validation: 0.12637009206526056]
	TIME [epoch: 13 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.141507034815661		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.141507034815661 | validation: 0.09336990928916315]
	TIME [epoch: 13.1 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14823491852404164		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.14823491852404164 | validation: 0.22542970973446594]
	TIME [epoch: 13 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19946166951261088		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.19946166951261088 | validation: 0.11709646469970526]
	TIME [epoch: 13 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15895640523447807		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.15895640523447807 | validation: 0.12184805250613517]
	TIME [epoch: 13 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1670925647054371		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.1670925647054371 | validation: 0.11242261441795842]
	TIME [epoch: 13.1 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10662130074762283		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.10662130074762283 | validation: 0.10503163551613119]
	TIME [epoch: 13 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12456397002446135		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.12456397002446135 | validation: 0.2679417286741865]
	TIME [epoch: 13 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4071721441378088		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.4071721441378088 | validation: 0.24046611359281728]
	TIME [epoch: 13.1 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18187047816149532		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.18187047816149532 | validation: 0.11076602010050839]
	TIME [epoch: 13 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10098598986124613		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.10098598986124613 | validation: 0.10685886448060997]
	TIME [epoch: 13 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14893976021520472		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.14893976021520472 | validation: 0.13064433615851764]
	TIME [epoch: 13 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11123462700336649		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.11123462700336649 | validation: 0.1094811559683366]
	TIME [epoch: 13 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11386730745576149		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.11386730745576149 | validation: 0.11406573398470689]
	TIME [epoch: 13 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11643964157884622		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.11643964157884622 | validation: 0.17242584800065186]
	TIME [epoch: 13 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16609798999434372		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.16609798999434372 | validation: 0.13260852117496902]
	TIME [epoch: 13 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18756876310757037		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.18756876310757037 | validation: 0.11219575334775087]
	TIME [epoch: 13 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13660022908640712		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.13660022908640712 | validation: 0.10429208946168]
	TIME [epoch: 13 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11023994425786973		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.11023994425786973 | validation: 0.08316698792852055]
	TIME [epoch: 13 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10181117488954873		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.10181117488954873 | validation: 0.11156800046241863]
	TIME [epoch: 13 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10568059543346935		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.10568059543346935 | validation: 0.06233694837055699]
	TIME [epoch: 13 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1082185613787132		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.1082185613787132 | validation: 0.14300849813854058]
	TIME [epoch: 13 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11611596310145109		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.11611596310145109 | validation: 0.10091043627737735]
	TIME [epoch: 13 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13824913139684342		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.13824913139684342 | validation: 0.16199020427754096]
	TIME [epoch: 13 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20047038257787522		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.20047038257787522 | validation: 0.17320160109475674]
	TIME [epoch: 13 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1422523687846984		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.1422523687846984 | validation: 0.1098538035798288]
	TIME [epoch: 13 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11636422465730956		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.11636422465730956 | validation: 0.10182862778353506]
	TIME [epoch: 13 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11428426498233821		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.11428426498233821 | validation: 0.12551137128654363]
	TIME [epoch: 13 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15501162957931408		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.15501162957931408 | validation: 0.14593509921689443]
	TIME [epoch: 13 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13928934585548053		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.13928934585548053 | validation: 0.12207345469006882]
	TIME [epoch: 13 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1393546628251684		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.1393546628251684 | validation: 0.13447674347408772]
	TIME [epoch: 13 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15731562381689923		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.15731562381689923 | validation: 0.17077110938532214]
	TIME [epoch: 13 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19534043420345137		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.19534043420345137 | validation: 0.16900131055451503]
	TIME [epoch: 13 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31997102398776084		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.31997102398776084 | validation: 0.20594388620958376]
	TIME [epoch: 13 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2080016554157231		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.2080016554157231 | validation: 0.16692565274247856]
	TIME [epoch: 13 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18247452331464323		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.18247452331464323 | validation: 0.15755088803008313]
	TIME [epoch: 13 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20191596942065365		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.20191596942065365 | validation: 0.25099100757663195]
	TIME [epoch: 13 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22901525821006163		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.22901525821006163 | validation: 0.1673974363099484]
	TIME [epoch: 13 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1790818362695134		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.1790818362695134 | validation: 0.16043206044728273]
	TIME [epoch: 13 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16330940965185772		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.16330940965185772 | validation: 0.11975274280142337]
	TIME [epoch: 13 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17432173304458376		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.17432173304458376 | validation: 0.16632143934191143]
	TIME [epoch: 13 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19039293241353472		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.19039293241353472 | validation: 0.13855121067052067]
	TIME [epoch: 13 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15643758825149917		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.15643758825149917 | validation: 0.1355947208779733]
	TIME [epoch: 13 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16797069412213778		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.16797069412213778 | validation: 0.14083888567519595]
	TIME [epoch: 13 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17383026103962942		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.17383026103962942 | validation: 0.15176712799531877]
	TIME [epoch: 13 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.176328356027519		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.176328356027519 | validation: 0.1422734557450609]
	TIME [epoch: 13 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17444200106151114		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.17444200106151114 | validation: 0.13491033158130925]
	TIME [epoch: 13 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1667433585945459		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.1667433585945459 | validation: 0.12154421896445135]
	TIME [epoch: 13 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1486074755749957		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.1486074755749957 | validation: 0.14639745585043254]
	TIME [epoch: 13 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1659297918278777		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.1659297918278777 | validation: 0.1200993129105349]
	TIME [epoch: 13 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14193166517294148		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.14193166517294148 | validation: 0.12329626909937957]
	TIME [epoch: 13 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1527278365138368		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.1527278365138368 | validation: 0.1760483026859648]
	TIME [epoch: 13 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15732030679582365		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.15732030679582365 | validation: 0.10740498756879]
	TIME [epoch: 13 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1352236105442386		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.1352236105442386 | validation: 0.14717976546541292]
	TIME [epoch: 13 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1499273478195222		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.1499273478195222 | validation: 0.10309495671382117]
	TIME [epoch: 13 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1292730516307437		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.1292730516307437 | validation: 0.1409827518441724]
	TIME [epoch: 13 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1774283153857555		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.1774283153857555 | validation: 0.17087899604253193]
	TIME [epoch: 13 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21619152808498332		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.21619152808498332 | validation: 0.17565849826697721]
	TIME [epoch: 13 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21611284976946743		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.21611284976946743 | validation: 0.1761525912887482]
	TIME [epoch: 13 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17776257634467432		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.17776257634467432 | validation: 0.1466468567717087]
	TIME [epoch: 13 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14635165073637946		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.14635165073637946 | validation: 0.13328127929092035]
	TIME [epoch: 13 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14050243362862133		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.14050243362862133 | validation: 0.12155227590571258]
	TIME [epoch: 13 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12498547339050857		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.12498547339050857 | validation: 0.11405388684679753]
	TIME [epoch: 13 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13433037766174133		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.13433037766174133 | validation: 0.11591508834253399]
	TIME [epoch: 13 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1381225615106517		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.1381225615106517 | validation: 0.11749585511295575]
	TIME [epoch: 13 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14258726746780065		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.14258726746780065 | validation: 0.13878680718454928]
	TIME [epoch: 13 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16573953874383285		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.16573953874383285 | validation: 0.12357968284939291]
	TIME [epoch: 13 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1821127263870527		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.1821127263870527 | validation: 0.20225374517460942]
	TIME [epoch: 13 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20045032928354567		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.20045032928354567 | validation: 0.18578520818089325]
	TIME [epoch: 13 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18271548380527236		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.18271548380527236 | validation: 0.1293512568585202]
	TIME [epoch: 13 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1613451054965212		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.1613451054965212 | validation: 0.13836093167800254]
	TIME [epoch: 13 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1658508654235398		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.1658508654235398 | validation: 0.15523212122975674]
	TIME [epoch: 13 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18189324657139716		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.18189324657139716 | validation: 0.13174332572489297]
	TIME [epoch: 13 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15197169024246743		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.15197169024246743 | validation: 0.14031222467668492]
	TIME [epoch: 13 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15866832345435458		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.15866832345435458 | validation: 0.17921224321564125]
	TIME [epoch: 13 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18700916099154669		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.18700916099154669 | validation: 0.1582461937109315]
	TIME [epoch: 13 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20109896383534442		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.20109896383534442 | validation: 0.17405058123247913]
	TIME [epoch: 13 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15819192365750404		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.15819192365750404 | validation: 0.14209429713818078]
	TIME [epoch: 13 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16575452497868165		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.16575452497868165 | validation: 0.10817341680305226]
	TIME [epoch: 13 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13269324381952033		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.13269324381952033 | validation: 0.12675126471965267]
	TIME [epoch: 13 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1264165326257749		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.1264165326257749 | validation: 0.08776601382817177]
	TIME [epoch: 13 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10180512807726692		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.10180512807726692 | validation: 0.07337614456953573]
	TIME [epoch: 13 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09926287650957621		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.09926287650957621 | validation: 0.09346113097686437]
	TIME [epoch: 13 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10502387502885999		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.10502387502885999 | validation: 0.06546079337620193]
	TIME [epoch: 13 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09299606367945686		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.09299606367945686 | validation: 0.07905347180551182]
	TIME [epoch: 13 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10178632149989492		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.10178632149989492 | validation: 0.0933260968869859]
	TIME [epoch: 13 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10688630557951317		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.10688630557951317 | validation: 0.09303478436478013]
	TIME [epoch: 13 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11933134873132473		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.11933134873132473 | validation: 0.12627539779967728]
	TIME [epoch: 13 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.153361685836895		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.153361685836895 | validation: 0.15864088802356222]
	TIME [epoch: 13 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1421616283017649		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.1421616283017649 | validation: 0.09822930842603281]
	TIME [epoch: 13 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09789639680167198		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.09789639680167198 | validation: 0.08688017420399655]
	TIME [epoch: 13 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11645095957224653		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.11645095957224653 | validation: 0.14809132837202074]
	TIME [epoch: 13 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17482504356911574		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.17482504356911574 | validation: 0.1458552332496277]
	TIME [epoch: 13 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13133048797422078		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.13133048797422078 | validation: 0.09823416973738087]
	TIME [epoch: 13 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11095295178109786		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.11095295178109786 | validation: 0.09818863705675705]
	TIME [epoch: 13 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10861714938491898		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.10861714938491898 | validation: 0.09685362621388613]
	TIME [epoch: 13 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11236169465236863		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.11236169465236863 | validation: 0.11427248089460022]
	TIME [epoch: 13 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12183386007134972		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.12183386007134972 | validation: 0.10256408344253615]
	TIME [epoch: 13 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1265339043896252		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.1265339043896252 | validation: 0.10294432837193512]
	TIME [epoch: 13 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14205748662659462		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.14205748662659462 | validation: 0.117635560281897]
	TIME [epoch: 13 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1354192783567855		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.1354192783567855 | validation: 0.12006266290695905]
	TIME [epoch: 13 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14003522839267424		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.14003522839267424 | validation: 0.14436582818570137]
	TIME [epoch: 13 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13326664590873402		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.13326664590873402 | validation: 0.1084927956286564]
	TIME [epoch: 13 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13204164539068114		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.13204164539068114 | validation: 0.12954815635403708]
	TIME [epoch: 13 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13322437509008284		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.13322437509008284 | validation: 0.1069072890441235]
	TIME [epoch: 13 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13563467407824492		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.13563467407824492 | validation: 0.09606470494073813]
	TIME [epoch: 13 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1415281116322557		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.1415281116322557 | validation: 0.20921846229212523]
	TIME [epoch: 13.1 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2059795797611923		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.2059795797611923 | validation: 0.12628946202571634]
	TIME [epoch: 13 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13562974210328657		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.13562974210328657 | validation: 0.1340219256476091]
	TIME [epoch: 13 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1379749340396016		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.1379749340396016 | validation: 0.09067463109331435]
	TIME [epoch: 13 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10809819104397532		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.10809819104397532 | validation: 0.09269703326139034]
	TIME [epoch: 13 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12061709243551486		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.12061709243551486 | validation: 0.11404173657822536]
	TIME [epoch: 13 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12239412164306301		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.12239412164306301 | validation: 0.1259931728975621]
	TIME [epoch: 13 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13553099112627282		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.13553099112627282 | validation: 0.1001748817566023]
	TIME [epoch: 13 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12386747606577811		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.12386747606577811 | validation: 0.11094954450877116]
	TIME [epoch: 13 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14847596194381954		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.14847596194381954 | validation: 0.11872109008209485]
	TIME [epoch: 13 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1158276347712885		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.1158276347712885 | validation: 0.09688134875223371]
	TIME [epoch: 13 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1134306860518237		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.1134306860518237 | validation: 0.08068470132724738]
	TIME [epoch: 13 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08202649120559476		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.08202649120559476 | validation: 0.06436928645859159]
	TIME [epoch: 13 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08994151880177248		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.08994151880177248 | validation: 0.07087387454657913]
	TIME [epoch: 13.1 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09164780218280563		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.09164780218280563 | validation: 0.08710542231424048]
	TIME [epoch: 13 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10409021545090792		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.10409021545090792 | validation: 0.08973607942295204]
	TIME [epoch: 13 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09007864780515061		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.09007864780515061 | validation: 0.07631559105395239]
	TIME [epoch: 13 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0821944892717624		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.0821944892717624 | validation: 0.07066217578575082]
	TIME [epoch: 13 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08786952737825868		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.08786952737825868 | validation: 0.11501601227876913]
	TIME [epoch: 13 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12552558196868524		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.12552558196868524 | validation: 0.11196077412966368]
	TIME [epoch: 13 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1256866093300351		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.1256866093300351 | validation: 0.11793227905253768]
	TIME [epoch: 13 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16638514288298767		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.16638514288298767 | validation: 0.10344752314375891]
	TIME [epoch: 13 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12846492954249863		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.12846492954249863 | validation: 0.08542404872453382]
	TIME [epoch: 13 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1065816882494583		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.1065816882494583 | validation: 0.08434789731499541]
	TIME [epoch: 13 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11315368372460516		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.11315368372460516 | validation: 0.08455791212712008]
	TIME [epoch: 13 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11631366034760647		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.11631366034760647 | validation: 0.13687944653359252]
	TIME [epoch: 13 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1396193369112628		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.1396193369112628 | validation: 0.11094610123406826]
	TIME [epoch: 13 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11739404511741625		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.11739404511741625 | validation: 0.11127168072644551]
	TIME [epoch: 13 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12513508477318447		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.12513508477318447 | validation: 0.10683628839313912]
	TIME [epoch: 13 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15589792628837223		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.15589792628837223 | validation: 0.17800414132543607]
	TIME [epoch: 13 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19067554201374415		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.19067554201374415 | validation: 0.13307865649694361]
	TIME [epoch: 13 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16251164637464324		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.16251164637464324 | validation: 0.1494974779888265]
	TIME [epoch: 13 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15231493750964722		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.15231493750964722 | validation: 0.12822648710177253]
	TIME [epoch: 13 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13881208031292774		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.13881208031292774 | validation: 0.114510672941898]
	TIME [epoch: 13 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12558566463081458		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.12558566463081458 | validation: 0.10824426706836647]
	TIME [epoch: 13 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10488838927557957		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.10488838927557957 | validation: 0.10341233276994222]
	TIME [epoch: 13 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10200593763088656		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.10200593763088656 | validation: 0.08389678351939676]
	TIME [epoch: 13 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09628187399355247		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.09628187399355247 | validation: 0.07935570729938023]
	TIME [epoch: 13 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08831058705169743		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.08831058705169743 | validation: 0.10377395263786919]
	TIME [epoch: 13 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20140109501472148		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.20140109501472148 | validation: 0.19776310435359398]
	TIME [epoch: 13 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15333488125848013		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.15333488125848013 | validation: 0.08711647815937361]
	TIME [epoch: 13 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12037928238388981		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.12037928238388981 | validation: 0.09103078278122065]
	TIME [epoch: 13 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10980802787695276		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.10980802787695276 | validation: 0.08227324761734693]
	TIME [epoch: 13 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09938310578080284		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.09938310578080284 | validation: 0.09393797113586437]
	TIME [epoch: 13 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11785437481414737		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.11785437481414737 | validation: 0.1314941029620116]
	TIME [epoch: 13 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14116680917789073		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.14116680917789073 | validation: 0.11040346636184661]
	TIME [epoch: 13 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12246713761080466		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.12246713761080466 | validation: 0.09845446322624732]
	TIME [epoch: 13 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11365044493007798		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.11365044493007798 | validation: 0.08814331306770389]
	TIME [epoch: 13 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1083155317759183		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.1083155317759183 | validation: 0.1020653676908971]
	TIME [epoch: 13 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1376355355493026		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.1376355355493026 | validation: 0.1084377864023904]
	TIME [epoch: 13 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12860622119014364		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.12860622119014364 | validation: 0.10526035793972517]
	TIME [epoch: 13 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12741951216614078		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.12741951216614078 | validation: 0.08755760651179362]
	TIME [epoch: 13 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.128153398262503		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.128153398262503 | validation: 0.08179871052452171]
	TIME [epoch: 13 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10588327145944998		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.10588327145944998 | validation: 0.09964072969383093]
	TIME [epoch: 13.1 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11933580341896577		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.11933580341896577 | validation: 0.12063107316102926]
	TIME [epoch: 13 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13853839568970897		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.13853839568970897 | validation: 0.07384512377829039]
	TIME [epoch: 13 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1052588206335051		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.1052588206335051 | validation: 0.08763072158853229]
	TIME [epoch: 13 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12608043898546703		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.12608043898546703 | validation: 0.09665088632966752]
	TIME [epoch: 13 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10760589538344187		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.10760589538344187 | validation: 0.08144224269919123]
	TIME [epoch: 13 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12374662025379604		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.12374662025379604 | validation: 0.0962423107367988]
	TIME [epoch: 13.1 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10865832943745403		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.10865832943745403 | validation: 0.08257390742795022]
	TIME [epoch: 13 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10622973985489173		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.10622973985489173 | validation: 0.10034255582218304]
	TIME [epoch: 13 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09360578532403643		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.09360578532403643 | validation: 0.07093986431374819]
	TIME [epoch: 13 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07779780994537369		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.07779780994537369 | validation: 0.0570725076636791]
	TIME [epoch: 13 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07957145312676583		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.07957145312676583 | validation: 0.08291369348840764]
	TIME [epoch: 13 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0726304110751955		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.0726304110751955 | validation: 0.06447324381845879]
	TIME [epoch: 13 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09370540161139777		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.09370540161139777 | validation: 0.09096576593072514]
	TIME [epoch: 13 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08691316195198717		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.08691316195198717 | validation: 0.061556929537837216]
	TIME [epoch: 13 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06387400921654014		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.06387400921654014 | validation: 0.06307966802341924]
	TIME [epoch: 13 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0963455269571962		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.0963455269571962 | validation: 0.1100314678834315]
	TIME [epoch: 13 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11049317134473331		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.11049317134473331 | validation: 0.06935231311402398]
	TIME [epoch: 13 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09017674673330127		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.09017674673330127 | validation: 0.0663741357128007]
	TIME [epoch: 13 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09906387466326856		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.09906387466326856 | validation: 0.09633692067215303]
	TIME [epoch: 13 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12458727406635293		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.12458727406635293 | validation: 0.09853100646149532]
	TIME [epoch: 13 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12921225219436505		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.12921225219436505 | validation: 0.08575218164219639]
	TIME [epoch: 13 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11089359939325119		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.11089359939325119 | validation: 0.09213932110366059]
	TIME [epoch: 13 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11468631088782946		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.11468631088782946 | validation: 0.07165584733757374]
	TIME [epoch: 13 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09473960034961809		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.09473960034961809 | validation: 0.05816877167233624]
	TIME [epoch: 13 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0908002774435983		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.0908002774435983 | validation: 0.1216811726012727]
	TIME [epoch: 13 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14995421962729838		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.14995421962729838 | validation: 0.09004225808087764]
	TIME [epoch: 13 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09578983702969818		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.09578983702969818 | validation: 0.07315907719409413]
	TIME [epoch: 13 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0842915560634237		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.0842915560634237 | validation: 0.05794780709820092]
	TIME [epoch: 13 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0814508836473849		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.0814508836473849 | validation: 0.06129197610421117]
	TIME [epoch: 13 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08840511316823912		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.08840511316823912 | validation: 0.07868196427686107]
	TIME [epoch: 13 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1119054243666922		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.1119054243666922 | validation: 0.10163501261043986]
	TIME [epoch: 13 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15383108844214044		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.15383108844214044 | validation: 0.14859746315646363]
	TIME [epoch: 13 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15986165531952676		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.15986165531952676 | validation: 0.1315968108889111]
	TIME [epoch: 13 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22110740609377855		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.22110740609377855 | validation: 0.2928082889607928]
	TIME [epoch: 13 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28268835031512535		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.28268835031512535 | validation: 0.15155823967215204]
	TIME [epoch: 13 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13633143385631463		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.13633143385631463 | validation: 0.10450627984866863]
	TIME [epoch: 13 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1564535731816666		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.1564535731816666 | validation: 0.19401897630514925]
	TIME [epoch: 13 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24179967801039562		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.24179967801039562 | validation: 0.15304579493469583]
	TIME [epoch: 13 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15201189203183776		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.15201189203183776 | validation: 0.08121928364673588]
	TIME [epoch: 13 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09765267038491321		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.09765267038491321 | validation: 0.07335971075296839]
	TIME [epoch: 13 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10376537865960907		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.10376537865960907 | validation: 0.06579980828331153]
	TIME [epoch: 13 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08748381377477443		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.08748381377477443 | validation: 0.06163810909930451]
	TIME [epoch: 13 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07486405030748906		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.07486405030748906 | validation: 0.06222675258684945]
	TIME [epoch: 13 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06925435233145552		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.06925435233145552 | validation: 0.06909348349265547]
	TIME [epoch: 13 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08296264719730555		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.08296264719730555 | validation: 0.046455515197334984]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_710.pth
	Model improved!!!
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059066410299494915		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.059066410299494915 | validation: 0.07431571070773915]
	TIME [epoch: 13 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0967383805414493		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.0967383805414493 | validation: 0.07077992744342552]
	TIME [epoch: 13 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09070023386863542		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.09070023386863542 | validation: 0.10582663865491693]
	TIME [epoch: 13 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10321730191714026		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.10321730191714026 | validation: 0.06001709231125684]
	TIME [epoch: 13 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06398968148762275		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.06398968148762275 | validation: 0.057718000483162106]
	TIME [epoch: 13 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06411201654767137		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.06411201654767137 | validation: 0.07643882895738145]
	TIME [epoch: 13 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09536537292459629		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.09536537292459629 | validation: 0.09340215353620615]
	TIME [epoch: 13 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07922764613507635		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.07922764613507635 | validation: 0.04930946891726544]
	TIME [epoch: 13.1 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0812033897339895		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.0812033897339895 | validation: 0.07629659524800754]
	TIME [epoch: 13 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09328047853315583		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.09328047853315583 | validation: 0.07341406536917289]
	TIME [epoch: 13 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07130893273386715		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.07130893273386715 | validation: 0.042379664827332186]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_721.pth
	Model improved!!!
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06393285837607314		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.06393285837607314 | validation: 0.05284367418810364]
	TIME [epoch: 13 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10386087233792762		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.10386087233792762 | validation: 0.18936242089221544]
	TIME [epoch: 13 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18652906490440807		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.18652906490440807 | validation: 0.08584022150197367]
	TIME [epoch: 13 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08853928108682417		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.08853928108682417 | validation: 0.09521307416088122]
	TIME [epoch: 13 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10938146613975758		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.10938146613975758 | validation: 0.07430116510271885]
	TIME [epoch: 13 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08381692119286893		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.08381692119286893 | validation: 0.07125389174012751]
	TIME [epoch: 13 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07945271442157453		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.07945271442157453 | validation: 0.08237983052282323]
	TIME [epoch: 13 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11121231858670821		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.11121231858670821 | validation: 0.13190875158873575]
	TIME [epoch: 13 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14037060997868364		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.14037060997868364 | validation: 0.095646814562078]
	TIME [epoch: 13 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10236044591496403		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.10236044591496403 | validation: 0.04415927076344089]
	TIME [epoch: 13 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07005366896466234		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.07005366896466234 | validation: 0.0618185905073318]
	TIME [epoch: 13 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06494757188548342		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.06494757188548342 | validation: 0.05155492017642014]
	TIME [epoch: 13 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05784692669945921		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.05784692669945921 | validation: 0.05291249822568081]
	TIME [epoch: 13 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06563004603825144		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.06563004603825144 | validation: 0.05530565542622446]
	TIME [epoch: 13 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07269702604070952		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.07269702604070952 | validation: 0.04696323656719064]
	TIME [epoch: 13 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06924739791849266		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.06924739791849266 | validation: 0.09571347855179956]
	TIME [epoch: 13.1 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11257780003550617		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.11257780003550617 | validation: 0.07843942197172159]
	TIME [epoch: 13 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07128760386481299		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.07128760386481299 | validation: 0.043019195720162794]
	TIME [epoch: 13 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054241274495458076		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.054241274495458076 | validation: 0.0428878494902542]
	TIME [epoch: 13 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05059423888415222		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.05059423888415222 | validation: 0.04722718407855684]
	TIME [epoch: 13.1 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061839453643067664		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.061839453643067664 | validation: 0.0440077988308062]
	TIME [epoch: 13 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060085457546722176		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.060085457546722176 | validation: 0.05866471413289706]
	TIME [epoch: 13 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06354101009759217		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.06354101009759217 | validation: 0.05456550487173461]
	TIME [epoch: 13.1 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08406856540175281		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.08406856540175281 | validation: 0.06888459081322655]
	TIME [epoch: 13 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07501121986065931		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.07501121986065931 | validation: 0.06317412457608158]
	TIME [epoch: 13 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06706174303231813		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.06706174303231813 | validation: 0.03555289258924506]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_747.pth
	Model improved!!!
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06371218194508912		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.06371218194508912 | validation: 0.06437600762012055]
	TIME [epoch: 13 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07954572255097436		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.07954572255097436 | validation: 0.05744466203859072]
	TIME [epoch: 13 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07431946513140437		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.07431946513140437 | validation: 0.0692481790437063]
	TIME [epoch: 13 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07509910271566445		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.07509910271566445 | validation: 0.07372339967866488]
	TIME [epoch: 13.1 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08469619496788165		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.08469619496788165 | validation: 0.05701045641762381]
	TIME [epoch: 13 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08097678603851446		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.08097678603851446 | validation: 0.06424426536219746]
	TIME [epoch: 13 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08204959481109136		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.08204959481109136 | validation: 0.07246010273781792]
	TIME [epoch: 13.1 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07877864458216133		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.07877864458216133 | validation: 0.0534817347282212]
	TIME [epoch: 13 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06976442924952916		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.06976442924952916 | validation: 0.056990223129519714]
	TIME [epoch: 13 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06633818323465704		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.06633818323465704 | validation: 0.06685866253853265]
	TIME [epoch: 13.1 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0759302001949809		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.0759302001949809 | validation: 0.03390770463251185]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_758.pth
	Model improved!!!
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05739031423548885		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.05739031423548885 | validation: 0.04983820590729995]
	TIME [epoch: 13 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06278184949760651		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.06278184949760651 | validation: 0.04156695964322047]
	TIME [epoch: 13 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059550164788689214		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.059550164788689214 | validation: 0.038820270307716134]
	TIME [epoch: 13.1 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08294350966256138		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.08294350966256138 | validation: 0.0691205342799445]
	TIME [epoch: 13 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07934818141494308		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.07934818141494308 | validation: 0.05569078089572039]
	TIME [epoch: 13 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0857865108741212		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.0857865108741212 | validation: 0.06845339791689402]
	TIME [epoch: 13.1 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06890764112712444		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.06890764112712444 | validation: 0.0628056559597192]
	TIME [epoch: 13 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06466998164699275		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.06466998164699275 | validation: 0.04913218331775596]
	TIME [epoch: 13 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07159936297000458		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.07159936297000458 | validation: 0.05617825806911995]
	TIME [epoch: 13 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08448347401388732		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.08448347401388732 | validation: 0.0629006811519066]
	TIME [epoch: 13 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07965150019883216		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.07965150019883216 | validation: 0.06398524587335372]
	TIME [epoch: 13 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07762935887478967		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.07762935887478967 | validation: 0.06409416209050205]
	TIME [epoch: 13 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06350226270920103		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.06350226270920103 | validation: 0.04593565651816082]
	TIME [epoch: 13 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06654828558877207		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.06654828558877207 | validation: 0.052868787825937756]
	TIME [epoch: 13 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0768958131566272		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.0768958131566272 | validation: 0.04147749563333214]
	TIME [epoch: 13 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051863757788571524		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.051863757788571524 | validation: 0.048977569589683106]
	TIME [epoch: 13 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08872013661215133		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.08872013661215133 | validation: 0.11549539391827857]
	TIME [epoch: 13 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10853024251449347		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.10853024251449347 | validation: 0.048712573294594]
	TIME [epoch: 13 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06922194041050381		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.06922194041050381 | validation: 0.042325512564168284]
	TIME [epoch: 13 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06220129310271855		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.06220129310271855 | validation: 0.05203277846349874]
	TIME [epoch: 13 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06753900343024555		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.06753900343024555 | validation: 0.054003784054271316]
	TIME [epoch: 13 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07034566782731311		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.07034566782731311 | validation: 0.04903723722098779]
	TIME [epoch: 13 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07347802772785858		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.07347802772785858 | validation: 0.04810168945396933]
	TIME [epoch: 13 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05978771717115082		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.05978771717115082 | validation: 0.062393412423594925]
	TIME [epoch: 13 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07230004382610052		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.07230004382610052 | validation: 0.055731372251103466]
	TIME [epoch: 13 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062486045346839714		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.062486045346839714 | validation: 0.04843766153091826]
	TIME [epoch: 13.1 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05892386417781584		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.05892386417781584 | validation: 0.06618644672118724]
	TIME [epoch: 13 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07005264951792925		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.07005264951792925 | validation: 0.06390874073284937]
	TIME [epoch: 13 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07081187492967757		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.07081187492967757 | validation: 0.04694413909456876]
	TIME [epoch: 13.1 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05979408610258957		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.05979408610258957 | validation: 0.05288957172320721]
	TIME [epoch: 13 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06268262947109844		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.06268262947109844 | validation: 0.047566308290706474]
	TIME [epoch: 13 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06102400392600926		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.06102400392600926 | validation: 0.038488313937138544]
	TIME [epoch: 13.1 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0683557597081933		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.0683557597081933 | validation: 0.04981061834339565]
	TIME [epoch: 13 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08105517898948515		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.08105517898948515 | validation: 0.06702308975725209]
	TIME [epoch: 13 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0739574044944406		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.0739574044944406 | validation: 0.042312090322041744]
	TIME [epoch: 13 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04273358932261945		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.04273358932261945 | validation: 0.029288877832137218]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_794.pth
	Model improved!!!
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047183908371592344		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.047183908371592344 | validation: 0.043395545280266956]
	TIME [epoch: 13 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055206574954531115		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.055206574954531115 | validation: 0.04812527216341704]
	TIME [epoch: 13 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05476449711940223		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.05476449711940223 | validation: 0.03561691744118736]
	TIME [epoch: 13.1 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055484706414440116		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.055484706414440116 | validation: 0.061775259265313444]
	TIME [epoch: 13 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07965495963217807		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.07965495963217807 | validation: 0.07294292858966801]
	TIME [epoch: 13 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10228164387526781		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.10228164387526781 | validation: 0.08055588374010263]
	TIME [epoch: 13 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08023057906041384		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.08023057906041384 | validation: 0.05299901092230664]
	TIME [epoch: 13 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04950844532258762		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.04950844532258762 | validation: 0.04152996912414864]
	TIME [epoch: 13 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055400332576965736		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.055400332576965736 | validation: 0.06176950458015187]
	TIME [epoch: 13 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07450891844762662		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.07450891844762662 | validation: 0.06634378424339105]
	TIME [epoch: 13 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07379431396546293		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.07379431396546293 | validation: 0.04156663862058311]
	TIME [epoch: 13 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05431315944889689		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.05431315944889689 | validation: 0.04220113290112766]
	TIME [epoch: 13 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05631369950783269		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.05631369950783269 | validation: 0.04449407802025946]
	TIME [epoch: 13 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046911205045434654		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.046911205045434654 | validation: 0.03958193745327555]
	TIME [epoch: 13 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04976300348094186		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.04976300348094186 | validation: 0.03356166188317182]
	TIME [epoch: 13 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05855102309798926		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.05855102309798926 | validation: 0.037927690387825376]
	TIME [epoch: 13.1 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05019720685499762		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.05019720685499762 | validation: 0.04222713793649884]
	TIME [epoch: 13 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045690355800238905		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.045690355800238905 | validation: 0.03463066369297862]
	TIME [epoch: 13 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04731582548827321		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.04731582548827321 | validation: 0.05417417327527055]
	TIME [epoch: 13.1 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0977090179224215		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.0977090179224215 | validation: 0.07500612111999139]
	TIME [epoch: 13 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07802584931001598		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.07802584931001598 | validation: 0.042870891543391125]
	TIME [epoch: 13 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05394390677359645		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.05394390677359645 | validation: 0.03587512709296399]
	TIME [epoch: 13 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062319445692264		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.062319445692264 | validation: 0.06205466910757057]
	TIME [epoch: 13.1 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10622604713371972		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.10622604713371972 | validation: 0.09214558261132527]
	TIME [epoch: 13 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09711231733874853		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.09711231733874853 | validation: 0.056377960988484146]
	TIME [epoch: 13 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07349321571300785		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.07349321571300785 | validation: 0.046804818695738624]
	TIME [epoch: 13.1 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06640539364612497		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.06640539364612497 | validation: 0.07133425085997235]
	TIME [epoch: 13 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.084816528257503		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.084816528257503 | validation: 0.047875723660277265]
	TIME [epoch: 13 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06015193249152873		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.06015193249152873 | validation: 0.05592302845614905]
	TIME [epoch: 13.1 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05923435176212946		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.05923435176212946 | validation: 0.04843218028595027]
	TIME [epoch: 13 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06591061691011338		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.06591061691011338 | validation: 0.05876661717772872]
	TIME [epoch: 13 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07194251403006233		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.07194251403006233 | validation: 0.05026428433746171]
	TIME [epoch: 13 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06530806987820076		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.06530806987820076 | validation: 0.10198383223808284]
	TIME [epoch: 13.1 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11027169256688758		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.11027169256688758 | validation: 0.12191834983044494]
	TIME [epoch: 13 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08590545156009965		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.08590545156009965 | validation: 0.05519238578699675]
	TIME [epoch: 13 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0806318145751822		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.0806318145751822 | validation: 0.060454781135666366]
	TIME [epoch: 13.1 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0703414199375255		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.0703414199375255 | validation: 0.051091298662427474]
	TIME [epoch: 13 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06805188164431364		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.06805188164431364 | validation: 0.04821600118395287]
	TIME [epoch: 13 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06813376544387148		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.06813376544387148 | validation: 0.052696898651695766]
	TIME [epoch: 13 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09112226822094258		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.09112226822094258 | validation: 0.11058069111019035]
	TIME [epoch: 13 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1379458978429078		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.1379458978429078 | validation: 0.12366909157233537]
	TIME [epoch: 13 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1091200333094843		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.1091200333094843 | validation: 0.06785762992077836]
	TIME [epoch: 13 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06848404644989901		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.06848404644989901 | validation: 0.06519920690357059]
	TIME [epoch: 13 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08511728066526597		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.08511728066526597 | validation: 0.09108884244584367]
	TIME [epoch: 13 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09584394377958023		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.09584394377958023 | validation: 0.0652527293357971]
	TIME [epoch: 13 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08054249609524117		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.08054249609524117 | validation: 0.053543673550781996]
	TIME [epoch: 13 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06278930306606505		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.06278930306606505 | validation: 0.04896949876191819]
	TIME [epoch: 13 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06807667570787818		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.06807667570787818 | validation: 0.05915887075456012]
	TIME [epoch: 13 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06470543806361029		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.06470543806361029 | validation: 0.0569465083651135]
	TIME [epoch: 13 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06708285597104187		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.06708285597104187 | validation: 0.06127338556823701]
	TIME [epoch: 13 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06784709273071682		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.06784709273071682 | validation: 0.059538623036132964]
	TIME [epoch: 13 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05924945475394178		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.05924945475394178 | validation: 0.03914821520352756]
	TIME [epoch: 13.1 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04760094511998148		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.04760094511998148 | validation: 0.03362259663368228]
	TIME [epoch: 13 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053894379475049416		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.053894379475049416 | validation: 0.03160980123851343]
	TIME [epoch: 13 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05404244824136234		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.05404244824136234 | validation: 0.0682224992298287]
	TIME [epoch: 13.1 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09448672267700088		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.09448672267700088 | validation: 0.10187990547805628]
	TIME [epoch: 13 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09458154289526882		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.09458154289526882 | validation: 0.05511945137158294]
	TIME [epoch: 13 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0625983471098016		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.0625983471098016 | validation: 0.06435119468964816]
	TIME [epoch: 13 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07320688234474704		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.07320688234474704 | validation: 0.056865265921190476]
	TIME [epoch: 13.1 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06658257089940081		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.06658257089940081 | validation: 0.07712790174137225]
	TIME [epoch: 13 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08043269909738303		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.08043269909738303 | validation: 0.059914810926965066]
	TIME [epoch: 13 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07310595012191456		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.07310595012191456 | validation: 0.0471636763732438]
	TIME [epoch: 13.1 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06897803109822602		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.06897803109822602 | validation: 0.07035305824306244]
	TIME [epoch: 13 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07175900148862341		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.07175900148862341 | validation: 0.04985078410209584]
	TIME [epoch: 13 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059585362047803014		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.059585362047803014 | validation: 0.05313891793297424]
	TIME [epoch: 13 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06234504927650876		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.06234504927650876 | validation: 0.05670257139772595]
	TIME [epoch: 13 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06913225486373184		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.06913225486373184 | validation: 0.05530492236151486]
	TIME [epoch: 13 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05486169252086862		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.05486169252086862 | validation: 0.035847908152408424]
	TIME [epoch: 13 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0461112390733705		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.0461112390733705 | validation: 0.04660210870034984]
	TIME [epoch: 13 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05165489167911798		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.05165489167911798 | validation: 0.03631095632847061]
	TIME [epoch: 13 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04190143291369438		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.04190143291369438 | validation: 0.023533013787337784]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_865.pth
	Model improved!!!
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03834022635085606		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.03834022635085606 | validation: 0.025381740766210276]
	TIME [epoch: 13 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04023836782268886		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.04023836782268886 | validation: 0.03127437243320989]
	TIME [epoch: 13 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04293450479137301		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.04293450479137301 | validation: 0.031660886122108545]
	TIME [epoch: 13 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048988585023432125		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.048988585023432125 | validation: 0.043671491246047245]
	TIME [epoch: 13 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05206032894154178		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.05206032894154178 | validation: 0.03191218823297162]
	TIME [epoch: 13 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037139156311349696		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.037139156311349696 | validation: 0.02155921668110436]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_871.pth
	Model improved!!!
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03310810466625505		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.03310810466625505 | validation: 0.04317289341493346]
	TIME [epoch: 13 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03870199025405128		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.03870199025405128 | validation: 0.033010274922183405]
	TIME [epoch: 13 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032381852096375466		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.032381852096375466 | validation: 0.032579471851214174]
	TIME [epoch: 13 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040695223328710284		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.040695223328710284 | validation: 0.04061773133118222]
	TIME [epoch: 13 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04325519013462768		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.04325519013462768 | validation: 0.025476253548676175]
	TIME [epoch: 13.1 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03913656932961403		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.03913656932961403 | validation: 0.028968722863065226]
	TIME [epoch: 13 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04680147600442979		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.04680147600442979 | validation: 0.039417988757195266]
	TIME [epoch: 13 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05900464572206515		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.05900464572206515 | validation: 0.04117368819906607]
	TIME [epoch: 13 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04788150038551418		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.04788150038551418 | validation: 0.059779904944761916]
	TIME [epoch: 13 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06797041742908966		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.06797041742908966 | validation: 0.05437138067292766]
	TIME [epoch: 13 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054187546173575483		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.054187546173575483 | validation: 0.050516412938404774]
	TIME [epoch: 13 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049746178216978534		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.049746178216978534 | validation: 0.04392706110992631]
	TIME [epoch: 13 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0498089105646989		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.0498089105646989 | validation: 0.03771990683301068]
	TIME [epoch: 13 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05673974989903616		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.05673974989903616 | validation: 0.05643892107235862]
	TIME [epoch: 13 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0829424125407797		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.0829424125407797 | validation: 0.06128341229152214]
	TIME [epoch: 13 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05045956834515947		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.05045956834515947 | validation: 0.03228373606477659]
	TIME [epoch: 13 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05627700383422124		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.05627700383422124 | validation: 0.06788873320494415]
	TIME [epoch: 13 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0880163029473186		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.0880163029473186 | validation: 0.11913322313149097]
	TIME [epoch: 13 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17619233059551112		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.17619233059551112 | validation: 0.10431330109685086]
	TIME [epoch: 13 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0854952352521768		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.0854952352521768 | validation: 0.05177530408454205]
	TIME [epoch: 13 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0741742372252931		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.0741742372252931 | validation: 0.09259877123294061]
	TIME [epoch: 13 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11982312395145878		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.11982312395145878 | validation: 0.13907032005507666]
	TIME [epoch: 13 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15578070152691212		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.15578070152691212 | validation: 0.1199232127344256]
	TIME [epoch: 13 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11522292710914392		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.11522292710914392 | validation: 0.0602243876790617]
	TIME [epoch: 13 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06852755546723462		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.06852755546723462 | validation: 0.06808682953166181]
	TIME [epoch: 13 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06524790006137972		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.06524790006137972 | validation: 0.03541193621064575]
	TIME [epoch: 13 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042444975005491645		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.042444975005491645 | validation: 0.031547911942835766]
	TIME [epoch: 13 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03909702126067208		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.03909702126067208 | validation: 0.029112495945948155]
	TIME [epoch: 13 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04541954442414375		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.04541954442414375 | validation: 0.04353950008038414]
	TIME [epoch: 13 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05082648064847077		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.05082648064847077 | validation: 0.049436898482925644]
	TIME [epoch: 13 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06125000151699485		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.06125000151699485 | validation: 0.06927096050595082]
	TIME [epoch: 13 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07375120155140619		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.07375120155140619 | validation: 0.04591910276715033]
	TIME [epoch: 13 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053634552846865496		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.053634552846865496 | validation: 0.04321533358025276]
	TIME [epoch: 13 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050853271891625626		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.050853271891625626 | validation: 0.026294202891179827]
	TIME [epoch: 13 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04894514432386986		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.04894514432386986 | validation: 0.03284119530460812]
	TIME [epoch: 13 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04533046137674359		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.04533046137674359 | validation: 0.039911168430498495]
	TIME [epoch: 13 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04516871756421661		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.04516871756421661 | validation: 0.03173820566013299]
	TIME [epoch: 13 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04417735240804491		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.04417735240804491 | validation: 0.04953616789095985]
	TIME [epoch: 13 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07879117618897		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.07879117618897 | validation: 0.0755153919894687]
	TIME [epoch: 13 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09007296182761299		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.09007296182761299 | validation: 0.08069199271629855]
	TIME [epoch: 13 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0822196723722034		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.0822196723722034 | validation: 0.06616600475744885]
	TIME [epoch: 13 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07160301036636088		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.07160301036636088 | validation: 0.08148277978968048]
	TIME [epoch: 13 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10989839943756288		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.10989839943756288 | validation: 0.11176640114698971]
	TIME [epoch: 13 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13060507467892432		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.13060507467892432 | validation: 0.08222400583070993]
	TIME [epoch: 13 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08828101824607493		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.08828101824607493 | validation: 0.053927613173093365]
	TIME [epoch: 13 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06865198769422845		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.06865198769422845 | validation: 0.04204975958459123]
	TIME [epoch: 13 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055731527927700183		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.055731527927700183 | validation: 0.05039025151798853]
	TIME [epoch: 13 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060642419292889535		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.060642419292889535 | validation: 0.04067447923309743]
	TIME [epoch: 13.1 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04756859427798883		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.04756859427798883 | validation: 0.037344568487426066]
	TIME [epoch: 13 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043216077181857895		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.043216077181857895 | validation: 0.030440829981226828]
	TIME [epoch: 13 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037448711173906676		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.037448711173906676 | validation: 0.03258646995674569]
	TIME [epoch: 13 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039621352494215036		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.039621352494215036 | validation: 0.04369184819479537]
	TIME [epoch: 13 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04733851423841107		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.04733851423841107 | validation: 0.03077986264708919]
	TIME [epoch: 13 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04314469353007289		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.04314469353007289 | validation: 0.03860202648596443]
	TIME [epoch: 13 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042116884627236874		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.042116884627236874 | validation: 0.027964037351287305]
	TIME [epoch: 13 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0452402534826585		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.0452402534826585 | validation: 0.027419141601622482]
	TIME [epoch: 13 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042494702418188916		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.042494702418188916 | validation: 0.03417196507099086]
	TIME [epoch: 13 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049175253119746035		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.049175253119746035 | validation: 0.027807912169469567]
	TIME [epoch: 13.1 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037072618177306005		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.037072618177306005 | validation: 0.03132067365642164]
	TIME [epoch: 13 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035497703407820255		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.035497703407820255 | validation: 0.028725530903631134]
	TIME [epoch: 13 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03597741763852393		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.03597741763852393 | validation: 0.02223368566116154]
	TIME [epoch: 13.1 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04031372558369477		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.04031372558369477 | validation: 0.04005431791652358]
	TIME [epoch: 13 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04199891204244091		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.04199891204244091 | validation: 0.043143244574559494]
	TIME [epoch: 13 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06612398811359604		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.06612398811359604 | validation: 0.06302927525309818]
	TIME [epoch: 13.1 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06468210395092511		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.06468210395092511 | validation: 0.05914431398180959]
	TIME [epoch: 13 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06890846836401054		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.06890846836401054 | validation: 0.056865179171746334]
	TIME [epoch: 13 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0643537282781378		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.0643537282781378 | validation: 0.06165519138384421]
	TIME [epoch: 13 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0637747254470362		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.0637747254470362 | validation: 0.0642909472481897]
	TIME [epoch: 13 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08589920417906388		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.08589920417906388 | validation: 0.07422400036317672]
	TIME [epoch: 13 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07864742144838656		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.07864742144838656 | validation: 0.06425642486457615]
	TIME [epoch: 13 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07018774990008513		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.07018774990008513 | validation: 0.06198503253425742]
	TIME [epoch: 13 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05571538552399896		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.05571538552399896 | validation: 0.056161000349755005]
	TIME [epoch: 13 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0617186380663331		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.0617186380663331 | validation: 0.04217817085305474]
	TIME [epoch: 13 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04768334379542872		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.04768334379542872 | validation: 0.038882468906749325]
	TIME [epoch: 13 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0501669262490746		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.0501669262490746 | validation: 0.04266358520824671]
	TIME [epoch: 13 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05314691305403869		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.05314691305403869 | validation: 0.05566262841370776]
	TIME [epoch: 13 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060743155829587815		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.060743155829587815 | validation: 0.05536105606580955]
	TIME [epoch: 13 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060523914019982646		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.060523914019982646 | validation: 0.04369136287904762]
	TIME [epoch: 13 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05785643154669059		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.05785643154669059 | validation: 0.04933573920306156]
	TIME [epoch: 13 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06334040133412244		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.06334040133412244 | validation: 0.05294896381215926]
	TIME [epoch: 13 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04713807733085247		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.04713807733085247 | validation: 0.03898099706197299]
	TIME [epoch: 13 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04789525271300628		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.04789525271300628 | validation: 0.035722192147526546]
	TIME [epoch: 13 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04385436233543308		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.04385436233543308 | validation: 0.03418063111823032]
	TIME [epoch: 13 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051104097645349046		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.051104097645349046 | validation: 0.046864013284580695]
	TIME [epoch: 13 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05632811977005877		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.05632811977005877 | validation: 0.04644915180369852]
	TIME [epoch: 13 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05699272148996381		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.05699272148996381 | validation: 0.04286884999266883]
	TIME [epoch: 13 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06211259734810295		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.06211259734810295 | validation: 0.05123852720417957]
	TIME [epoch: 13 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05739504388185049		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.05739504388185049 | validation: 0.0519945994078045]
	TIME [epoch: 13 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051499042641654356		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.051499042641654356 | validation: 0.049022894422435286]
	TIME [epoch: 13 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061900196910260746		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.061900196910260746 | validation: 0.053927460235572565]
	TIME [epoch: 13 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06494323080435907		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.06494323080435907 | validation: 0.04225674081757017]
	TIME [epoch: 13 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05497298634749806		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.05497298634749806 | validation: 0.03437368069206317]
	TIME [epoch: 13 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04743539111403856		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.04743539111403856 | validation: 0.032115809081091067]
	TIME [epoch: 13 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04578163295918889		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.04578163295918889 | validation: 0.03647312764622065]
	TIME [epoch: 13 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0438151803964879		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.0438151803964879 | validation: 0.03461141952762678]
	TIME [epoch: 13 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05604741159556413		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.05604741159556413 | validation: 0.04052700961381147]
	TIME [epoch: 13 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050980214906725586		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.050980214906725586 | validation: 0.029335782195446667]
	TIME [epoch: 13 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0454863867227516		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.0454863867227516 | validation: 0.025437107909637158]
	TIME [epoch: 13 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04531789883825975		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.04531789883825975 | validation: 0.03806150417102844]
	TIME [epoch: 13 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04741580411346791		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.04741580411346791 | validation: 0.04322374683063499]
	TIME [epoch: 13 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0464071043893233		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.0464071043893233 | validation: 0.029994741694305712]
	TIME [epoch: 13 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04508142612280401		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.04508142612280401 | validation: 0.037097703949895026]
	TIME [epoch: 13 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03819275060890253		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.03819275060890253 | validation: 0.03758903563210437]
	TIME [epoch: 13 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0444355817799565		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.0444355817799565 | validation: 0.03607311835154375]
	TIME [epoch: 13 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041265204288793406		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.041265204288793406 | validation: 0.03190982386936207]
	TIME [epoch: 13 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038277361710833735		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.038277361710833735 | validation: 0.03356641931901446]
	TIME [epoch: 13 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048697021838952734		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.048697021838952734 | validation: 0.03358048675619273]
	TIME [epoch: 13 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04150193254075169		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.04150193254075169 | validation: 0.03123254993309477]
	TIME [epoch: 13 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044799014224084416		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.044799014224084416 | validation: 0.03772773894664704]
	TIME [epoch: 13 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049480875913484705		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.049480875913484705 | validation: 0.04457082996308819]
	TIME [epoch: 13 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06736143842719382		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.06736143842719382 | validation: 0.048432096368391304]
	TIME [epoch: 13 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0708526974656365		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.0708526974656365 | validation: 0.07253608273071992]
	TIME [epoch: 13 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07110743838493724		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.07110743838493724 | validation: 0.035816568342308945]
	TIME [epoch: 13 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04715495093196576		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.04715495093196576 | validation: 0.031798373473985876]
	TIME [epoch: 13 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04483039273794427		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.04483039273794427 | validation: 0.023313727970208795]
	TIME [epoch: 13 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04755694953888551		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.04755694953888551 | validation: 0.04275184788674977]
	TIME [epoch: 13 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055836150684281605		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.055836150684281605 | validation: 0.04919245431175857]
	TIME [epoch: 13 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06508104593206329		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.06508104593206329 | validation: 0.06534139711673147]
	TIME [epoch: 13 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06140584483477837		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.06140584483477837 | validation: 0.05601033715919462]
	TIME [epoch: 13 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053830787006024845		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.053830787006024845 | validation: 0.04800416591128868]
	TIME [epoch: 13.1 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045497787718757315		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.045497787718757315 | validation: 0.023783587137833698]
	TIME [epoch: 13 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033669689791238515		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.033669689791238515 | validation: 0.028110739427383062]
	TIME [epoch: 13 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04201454562735501		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.04201454562735501 | validation: 0.041728104713494245]
	TIME [epoch: 13.1 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043898732392579326		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.043898732392579326 | validation: 0.026520847613416318]
	TIME [epoch: 13 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03552430308761567		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.03552430308761567 | validation: 0.028272926792152098]
	TIME [epoch: 13 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03681469749172147		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.03681469749172147 | validation: 0.02384066874500971]
	TIME [epoch: 13 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036618432463758205		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.036618432463758205 | validation: 0.04545302234140158]
	TIME [epoch: 13 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0463768423189793		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.0463768423189793 | validation: 0.0325483476899517]
	TIME [epoch: 13 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03494572420667945		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.03494572420667945 | validation: 0.026980724678838934]
	TIME [epoch: 13 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0393808184058112		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.0393808184058112 | validation: 0.04124369436082379]
	TIME [epoch: 13 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04520087737218355		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.04520087737218355 | validation: 0.0374571803630861]
	TIME [epoch: 13 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03987435114383954		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.03987435114383954 | validation: 0.0279220290060518]
	TIME [epoch: 13 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037581119741404406		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.037581119741404406 | validation: 0.03335398516593778]
	TIME [epoch: 13 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039101712212129984		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.039101712212129984 | validation: 0.018777780126848994]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_1005.pth
	Model improved!!!
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036587906634470244		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.036587906634470244 | validation: 0.03247811047749999]
	TIME [epoch: 13 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03310636771668808		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.03310636771668808 | validation: 0.01527956697241756]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_1007.pth
	Model improved!!!
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03295045756154982		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.03295045756154982 | validation: 0.025759236802602965]
	TIME [epoch: 13 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040219410519172355		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.040219410519172355 | validation: 0.028402361169330134]
	TIME [epoch: 13 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0388203162182269		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.0388203162182269 | validation: 0.03219838022260638]
	TIME [epoch: 13 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0381162962120105		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.0381162962120105 | validation: 0.02377394991680838]
	TIME [epoch: 13 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03726990482474221		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.03726990482474221 | validation: 0.025338240658023176]
	TIME [epoch: 13 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038853247460270496		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.038853247460270496 | validation: 0.03185647063692954]
	TIME [epoch: 13 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04020563106990145		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.04020563106990145 | validation: 0.02414745976704345]
	TIME [epoch: 13 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0389249158217628		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.0389249158217628 | validation: 0.04215207939746438]
	TIME [epoch: 13 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04649696733714331		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.04649696733714331 | validation: 0.031105386516924845]
	TIME [epoch: 13 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041126475605721996		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.041126475605721996 | validation: 0.03309686993502879]
	TIME [epoch: 13 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04983443752202892		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.04983443752202892 | validation: 0.05031437519828757]
	TIME [epoch: 13 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07114284343156116		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.07114284343156116 | validation: 0.06429368872822604]
	TIME [epoch: 13 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07123247521029165		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.07123247521029165 | validation: 0.05317274224544012]
	TIME [epoch: 13 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04811698126429445		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.04811698126429445 | validation: 0.03203109148467944]
	TIME [epoch: 13 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038162150921101264		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.038162150921101264 | validation: 0.0232103385976711]
	TIME [epoch: 13 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03941598085117297		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.03941598085117297 | validation: 0.024754389149571097]
	TIME [epoch: 13 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04237372392220541		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.04237372392220541 | validation: 0.03013827941715057]
	TIME [epoch: 13 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044052654879920376		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.044052654879920376 | validation: 0.0360035809690658]
	TIME [epoch: 13 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04979450472738721		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.04979450472738721 | validation: 0.038716824488644275]
	TIME [epoch: 13 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046982596816165935		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.046982596816165935 | validation: 0.030723457511684905]
	TIME [epoch: 13 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0382900747108863		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.0382900747108863 | validation: 0.030522519358113023]
	TIME [epoch: 13 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036444536430355765		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.036444536430355765 | validation: 0.026698732510138462]
	TIME [epoch: 13 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04246228627507373		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.04246228627507373 | validation: 0.03588077561173277]
	TIME [epoch: 13 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046541597510702956		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.046541597510702956 | validation: 0.031852081726683606]
	TIME [epoch: 13 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040761904325595816		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.040761904325595816 | validation: 0.03790883986170565]
	TIME [epoch: 13 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033548765458228116		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.033548765458228116 | validation: 0.023096361592327412]
	TIME [epoch: 13 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03929206385566136		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.03929206385566136 | validation: 0.025039160592845465]
	TIME [epoch: 13 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03189648626847402		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.03189648626847402 | validation: 0.028203282865684836]
	TIME [epoch: 13 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032974767792538814		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.032974767792538814 | validation: 0.025571058634094347]
	TIME [epoch: 13 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036141079211575264		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.036141079211575264 | validation: 0.03462651052028279]
	TIME [epoch: 13 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04190795867661286		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.04190795867661286 | validation: 0.03064920212839667]
	TIME [epoch: 13 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04224022902203959		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.04224022902203959 | validation: 0.030984489194597984]
	TIME [epoch: 13 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039814706122177045		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.039814706122177045 | validation: 0.029368403058907908]
	TIME [epoch: 13 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04406845902168532		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.04406845902168532 | validation: 0.03979232365689765]
	TIME [epoch: 13 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043633624626835274		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.043633624626835274 | validation: 0.03757732715188358]
	TIME [epoch: 13 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0377764162205287		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.0377764162205287 | validation: 0.022602556589596316]
	TIME [epoch: 13 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03277469858132385		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.03277469858132385 | validation: 0.02151079434611799]
	TIME [epoch: 13.1 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027879825752543747		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.027879825752543747 | validation: 0.03153947641520738]
	TIME [epoch: 13 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037544252253033754		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.037544252253033754 | validation: 0.030417112832543742]
	TIME [epoch: 13 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03590515435562831		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.03590515435562831 | validation: 0.02808105748155834]
	TIME [epoch: 13 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04110773863732211		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.04110773863732211 | validation: 0.029088522427898056]
	TIME [epoch: 13 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04761117281220364		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.04761117281220364 | validation: 0.03249329455909836]
	TIME [epoch: 13 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03350108235173685		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.03350108235173685 | validation: 0.01893471920277249]
	TIME [epoch: 13 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031261181351658625		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.031261181351658625 | validation: 0.015443255200421318]
	TIME [epoch: 13 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03374671390077851		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.03374671390077851 | validation: 0.02736424629805451]
	TIME [epoch: 13 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04231779372302206		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.04231779372302206 | validation: 0.0291162867888404]
	TIME [epoch: 13 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039851456302607356		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.039851456302607356 | validation: 0.02698987973826658]
	TIME [epoch: 13 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040543037391782236		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.040543037391782236 | validation: 0.03741470092996799]
	TIME [epoch: 13 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04229651479261523		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.04229651479261523 | validation: 0.02423570598345002]
	TIME [epoch: 13 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036741336316855396		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.036741336316855396 | validation: 0.03399316060147538]
	TIME [epoch: 13 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04215096497669349		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.04215096497669349 | validation: 0.030297097715042902]
	TIME [epoch: 13 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042181954756971514		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.042181954756971514 | validation: 0.024982979094283944]
	TIME [epoch: 13 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037463685643414485		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.037463685643414485 | validation: 0.03703690574698432]
	TIME [epoch: 13.1 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04566555177683549		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.04566555177683549 | validation: 0.043869704387239424]
	TIME [epoch: 13 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050776487926890074		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.050776487926890074 | validation: 0.04044224579074784]
	TIME [epoch: 13 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05377865135646495		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.05377865135646495 | validation: 0.03677436229419791]
	TIME [epoch: 13 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04286104609863816		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.04286104609863816 | validation: 0.03030717781998244]
	TIME [epoch: 13 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03632272887207037		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.03632272887207037 | validation: 0.03350178124031041]
	TIME [epoch: 13 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036024982007911585		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.036024982007911585 | validation: 0.033037731759523487]
	TIME [epoch: 13 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04015137782329895		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.04015137782329895 | validation: 0.03850336247967488]
	TIME [epoch: 13 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03922769254256057		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.03922769254256057 | validation: 0.04042278094219192]
	TIME [epoch: 13 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04711545069222284		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.04711545069222284 | validation: 0.035818796524263875]
	TIME [epoch: 13 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03838036611446665		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.03838036611446665 | validation: 0.021037050341289366]
	TIME [epoch: 13 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03865648526424124		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.03865648526424124 | validation: 0.03236449233651935]
	TIME [epoch: 13 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03329036622148495		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.03329036622148495 | validation: 0.03057624844808694]
	TIME [epoch: 13 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044143919288039735		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.044143919288039735 | validation: 0.03003361352169808]
	TIME [epoch: 13 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040106458026808914		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.040106458026808914 | validation: 0.0251291514543608]
	TIME [epoch: 13 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03688618543662576		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.03688618543662576 | validation: 0.030755934900684123]
	TIME [epoch: 13 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04881714520649067		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.04881714520649067 | validation: 0.03923466889403157]
	TIME [epoch: 13 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04006660350668065		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.04006660350668065 | validation: 0.02744603733260017]
	TIME [epoch: 13 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03669220520919694		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.03669220520919694 | validation: 0.026405987809410694]
	TIME [epoch: 13 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03903378608429196		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.03903378608429196 | validation: 0.022160302830718095]
	TIME [epoch: 13 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037546426995607785		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.037546426995607785 | validation: 0.018139941685567807]
	TIME [epoch: 13 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033141619411315555		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.033141619411315555 | validation: 0.014203042539450214]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_1081.pth
	Model improved!!!
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028813622299429346		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.028813622299429346 | validation: 0.029803042387322818]
	TIME [epoch: 13 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032034034575911106		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.032034034575911106 | validation: 0.02814601122547566]
	TIME [epoch: 13 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036344368359379445		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.036344368359379445 | validation: 0.0228220696892564]
	TIME [epoch: 13 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030414252023960905		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.030414252023960905 | validation: 0.026782727978082562]
	TIME [epoch: 13 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030243196446708115		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.030243196446708115 | validation: 0.019564366124498318]
	TIME [epoch: 13 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031600430079015834		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.031600430079015834 | validation: 0.024998420980839056]
	TIME [epoch: 13 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03447080194684442		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.03447080194684442 | validation: 0.024741601183437715]
	TIME [epoch: 13 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03427770463706624		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.03427770463706624 | validation: 0.013149112473504997]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_1089.pth
	Model improved!!!
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029766856840191428		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.029766856840191428 | validation: 0.02076065970057469]
	TIME [epoch: 13 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03636039289869536		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.03636039289869536 | validation: 0.03278346616752106]
	TIME [epoch: 13 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050478373700044155		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.050478373700044155 | validation: 0.03196277104961501]
	TIME [epoch: 13 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04509211087382163		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.04509211087382163 | validation: 0.040061611147697955]
	TIME [epoch: 13 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042396959970970975		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.042396959970970975 | validation: 0.04097846870163423]
	TIME [epoch: 13 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03607631092416473		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.03607631092416473 | validation: 0.042483293858572184]
	TIME [epoch: 13 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04737093546927944		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.04737093546927944 | validation: 0.03766305227913375]
	TIME [epoch: 13 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04310395955500218		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.04310395955500218 | validation: 0.03625506049905957]
	TIME [epoch: 13 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03746272692102873		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.03746272692102873 | validation: 0.030962339767492252]
	TIME [epoch: 13 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038025233566258684		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.038025233566258684 | validation: 0.028813044794054346]
	TIME [epoch: 13 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038984248519190905		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.038984248519190905 | validation: 0.03379926894527067]
	TIME [epoch: 13 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03612939814951441		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.03612939814951441 | validation: 0.0358469974089952]
	TIME [epoch: 13 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03762253641981269		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.03762253641981269 | validation: 0.022411683857413017]
	TIME [epoch: 13 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034038170305661475		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.034038170305661475 | validation: 0.02648967657821184]
	TIME [epoch: 13 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03440527616331807		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.03440527616331807 | validation: 0.02850323229658372]
	TIME [epoch: 13 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029603764592065998		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.029603764592065998 | validation: 0.023145249438684307]
	TIME [epoch: 13 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03529754636659392		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.03529754636659392 | validation: 0.033178703054714855]
	TIME [epoch: 13 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03321722675078115		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.03321722675078115 | validation: 0.02791093467119026]
	TIME [epoch: 13 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039675525628054015		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.039675525628054015 | validation: 0.0297208301065203]
	TIME [epoch: 13 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04073324279200986		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.04073324279200986 | validation: 0.03221478347991952]
	TIME [epoch: 13 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03946400427734163		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.03946400427734163 | validation: 0.01933237504940755]
	TIME [epoch: 13 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03983712492567472		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.03983712492567472 | validation: 0.03150336967566835]
	TIME [epoch: 13 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03515836651788358		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.03515836651788358 | validation: 0.029507149466304013]
	TIME [epoch: 13 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03596371883257688		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.03596371883257688 | validation: 0.03556278366290076]
	TIME [epoch: 13.1 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03937757253866397		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.03937757253866397 | validation: 0.030040823282405836]
	TIME [epoch: 13 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03662070567852688		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.03662070567852688 | validation: 0.023113235181027068]
	TIME [epoch: 13 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037757631463482585		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.037757631463482585 | validation: 0.02866115823531474]
	TIME [epoch: 13 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03928173498382519		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.03928173498382519 | validation: 0.026334211765343535]
	TIME [epoch: 13 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034455681973915936		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.034455681973915936 | validation: 0.02401363354834091]
	TIME [epoch: 13 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03672079471554651		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.03672079471554651 | validation: 0.027143557958678798]
	TIME [epoch: 13.1 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03890764158647943		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.03890764158647943 | validation: 0.035885230685594065]
	TIME [epoch: 13 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0494169651014583		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.0494169651014583 | validation: 0.037046587506681584]
	TIME [epoch: 13 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046155276736829474		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.046155276736829474 | validation: 0.028896409194668387]
	TIME [epoch: 13 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04142421329539589		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.04142421329539589 | validation: 0.022409467935719418]
	TIME [epoch: 13 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037020105632594474		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.037020105632594474 | validation: 0.023134594617994515]
	TIME [epoch: 13 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0327233214877556		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.0327233214877556 | validation: 0.026398385378374148]
	TIME [epoch: 13 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030521571185580226		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.030521571185580226 | validation: 0.027114123525525925]
	TIME [epoch: 13 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03488865864600748		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.03488865864600748 | validation: 0.02750346776625643]
	TIME [epoch: 13 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03486645142857615		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.03486645142857615 | validation: 0.035346430289571254]
	TIME [epoch: 13 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03547912054452478		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.03547912054452478 | validation: 0.024488999197930225]
	TIME [epoch: 13 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032456500299314205		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.032456500299314205 | validation: 0.02351188895017973]
	TIME [epoch: 13 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030779159180523156		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.030779159180523156 | validation: 0.011393098963349427]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_1131.pth
	Model improved!!!
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02884812400422779		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.02884812400422779 | validation: 0.015585310151668388]
	TIME [epoch: 13 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034311890382778605		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.034311890382778605 | validation: 0.022049959058811956]
	TIME [epoch: 13 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031146032236141534		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.031146032236141534 | validation: 0.013838820876548598]
	TIME [epoch: 13 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027971315516068504		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.027971315516068504 | validation: 0.020250850828950586]
	TIME [epoch: 13 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03218058425786895		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.03218058425786895 | validation: 0.013545133047028446]
	TIME [epoch: 13 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03511243285540502		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.03511243285540502 | validation: 0.028430131390414976]
	TIME [epoch: 13 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0335078177112243		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.0335078177112243 | validation: 0.016076892813282444]
	TIME [epoch: 13 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03453104979763757		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.03453104979763757 | validation: 0.02776126483551017]
	TIME [epoch: 13 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03469283945144824		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.03469283945144824 | validation: 0.033475728935020946]
	TIME [epoch: 13 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039542698993181524		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.039542698993181524 | validation: 0.027793318999461546]
	TIME [epoch: 13 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03888494698982596		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.03888494698982596 | validation: 0.03852372719781719]
	TIME [epoch: 13 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048324835148840464		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.048324835148840464 | validation: 0.035484453289834454]
	TIME [epoch: 13 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039806645678273175		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.039806645678273175 | validation: 0.03833662854706845]
	TIME [epoch: 13 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039965738172083536		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.039965738172083536 | validation: 0.03165925012342272]
	TIME [epoch: 13 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043962644906402726		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.043962644906402726 | validation: 0.042340265602892266]
	TIME [epoch: 13 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043983715828526004		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.043983715828526004 | validation: 0.03959030329450008]
	TIME [epoch: 13 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0497889653944386		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.0497889653944386 | validation: 0.03292646780331571]
	TIME [epoch: 13 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047127089741398606		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.047127089741398606 | validation: 0.03556288363161785]
	TIME [epoch: 13 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03921250461993969		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.03921250461993969 | validation: 0.03326198349626663]
	TIME [epoch: 13 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04426952154732409		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.04426952154732409 | validation: 0.03592608234691685]
	TIME [epoch: 13 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055308341308477366		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.055308341308477366 | validation: 0.038600082185746815]
	TIME [epoch: 13 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05235053333209853		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.05235053333209853 | validation: 0.04406091418083101]
	TIME [epoch: 13 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04931538225222158		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.04931538225222158 | validation: 0.031424936201409695]
	TIME [epoch: 13 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040249274891813576		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.040249274891813576 | validation: 0.021555767783299092]
	TIME [epoch: 13 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03667752380640227		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.03667752380640227 | validation: 0.03291059124419624]
	TIME [epoch: 13 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03813683217461222		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.03813683217461222 | validation: 0.029844308071660705]
	TIME [epoch: 13 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03929796996726616		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.03929796996726616 | validation: 0.03175048336181865]
	TIME [epoch: 13 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046176611271747145		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.046176611271747145 | validation: 0.024748868993694467]
	TIME [epoch: 13 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042578633280286465		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.042578633280286465 | validation: 0.03582718377720001]
	TIME [epoch: 13 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05135249392811314		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.05135249392811314 | validation: 0.03352444777096657]
	TIME [epoch: 13 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047988774934499184		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.047988774934499184 | validation: 0.029160865801692536]
	TIME [epoch: 13 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04311421643651781		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.04311421643651781 | validation: 0.04053236008836647]
	TIME [epoch: 13 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05139984465524607		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.05139984465524607 | validation: 0.034871334241669015]
	TIME [epoch: 13 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04945667777611327		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.04945667777611327 | validation: 0.04658886133539456]
	TIME [epoch: 13 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059087567556187603		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.059087567556187603 | validation: 0.05503958552954068]
	TIME [epoch: 13 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05489217041309714		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.05489217041309714 | validation: 0.034059882013390975]
	TIME [epoch: 13 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05124033988807246		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.05124033988807246 | validation: 0.03338973575068598]
	TIME [epoch: 13 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050191179705533114		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.050191179705533114 | validation: 0.03707630341449937]
	TIME [epoch: 13 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0508746493140472		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.0508746493140472 | validation: 0.03602255361957506]
	TIME [epoch: 13 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040942421300634003		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.040942421300634003 | validation: 0.030788225395482507]
	TIME [epoch: 13 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04490912483028961		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.04490912483028961 | validation: 0.02374345057602714]
	TIME [epoch: 13 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03819564976488975		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.03819564976488975 | validation: 0.03843201359555812]
	TIME [epoch: 13 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04166086479579433		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.04166086479579433 | validation: 0.027978728758898442]
	TIME [epoch: 13 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04494173096477465		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.04494173096477465 | validation: 0.03147255048421548]
	TIME [epoch: 13 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043866983410237106		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.043866983410237106 | validation: 0.0292166819888094]
	TIME [epoch: 13 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043862829642592416		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.043862829642592416 | validation: 0.030908438780853035]
	TIME [epoch: 13 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041435865023010915		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.041435865023010915 | validation: 0.028513606311820615]
	TIME [epoch: 13 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043565640663037086		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.043565640663037086 | validation: 0.03599517300947991]
	TIME [epoch: 13 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048622391026533554		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.048622391026533554 | validation: 0.03741139624906797]
	TIME [epoch: 13 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04339955167782479		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.04339955167782479 | validation: 0.039711966297103204]
	TIME [epoch: 13 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04644675131515482		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.04644675131515482 | validation: 0.03728119593173755]
	TIME [epoch: 13 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046252967930121264		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.046252967930121264 | validation: 0.03747719866756781]
	TIME [epoch: 13 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04647805118535392		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.04647805118535392 | validation: 0.02653703020057338]
	TIME [epoch: 13 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03999870596088391		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.03999870596088391 | validation: 0.03071960663354532]
	TIME [epoch: 13 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043428141192285996		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.043428141192285996 | validation: 0.03706604897280883]
	TIME [epoch: 13 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041794395088246866		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.041794395088246866 | validation: 0.03284358622103878]
	TIME [epoch: 13 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044548452136927964		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.044548452136927964 | validation: 0.02797132789996291]
	TIME [epoch: 13 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038508777666220725		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.038508777666220725 | validation: 0.03301397186912197]
	TIME [epoch: 13 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035491553729682816		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.035491553729682816 | validation: 0.0242391269502903]
	TIME [epoch: 13 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03766998897716721		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.03766998897716721 | validation: 0.029601159439808324]
	TIME [epoch: 13 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03815725149976565		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.03815725149976565 | validation: 0.02382051278157657]
	TIME [epoch: 13 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04102344489780215		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.04102344489780215 | validation: 0.022065169572027747]
	TIME [epoch: 13 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03742266059367019		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.03742266059367019 | validation: 0.027673420952092753]
	TIME [epoch: 13 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036549749242613595		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.036549749242613595 | validation: 0.030061399144894505]
	TIME [epoch: 13 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0398303073952585		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.0398303073952585 | validation: 0.021057013831780002]
	TIME [epoch: 13 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033390097533631244		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.033390097533631244 | validation: 0.03055597388399594]
	TIME [epoch: 13 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03684815260702897		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.03684815260702897 | validation: 0.025058344230004935]
	TIME [epoch: 13 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043974423915792954		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.043974423915792954 | validation: 0.030986184222312366]
	TIME [epoch: 13 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03654933830242756		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.03654933830242756 | validation: 0.017503775323734573]
	TIME [epoch: 13 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04027147537484812		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.04027147537484812 | validation: 0.03817316106714499]
	TIME [epoch: 13 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04168854679351383		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.04168854679351383 | validation: 0.03552705420661032]
	TIME [epoch: 13 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04323285919217209		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.04323285919217209 | validation: 0.03525953436426063]
	TIME [epoch: 13 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04347627191386294		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.04347627191386294 | validation: 0.03285867483212394]
	TIME [epoch: 13 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036532013322344015		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.036532013322344015 | validation: 0.025979957612275006]
	TIME [epoch: 13 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03333329392004317		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.03333329392004317 | validation: 0.02214057186683825]
	TIME [epoch: 13 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03552545857971114		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.03552545857971114 | validation: 0.0255829132208651]
	TIME [epoch: 13 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0335893112550583		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.0335893112550583 | validation: 0.015325591104648413]
	TIME [epoch: 13 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031024844611140093		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.031024844611140093 | validation: 0.030530173659078674]
	TIME [epoch: 13 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03286590403438424		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.03286590403438424 | validation: 0.01697238043988552]
	TIME [epoch: 13 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034343729529397515		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.034343729529397515 | validation: 0.03110703702067051]
	TIME [epoch: 13 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03486375212874097		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.03486375212874097 | validation: 0.03076055342118273]
	TIME [epoch: 13 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03239201500285406		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.03239201500285406 | validation: 0.018641895535962343]
	TIME [epoch: 13 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03152773021678086		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.03152773021678086 | validation: 0.025247345566562277]
	TIME [epoch: 13 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032505131555814866		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.032505131555814866 | validation: 0.020189980573203935]
	TIME [epoch: 13 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033472971327026806		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.033472971327026806 | validation: 0.014732872014861838]
	TIME [epoch: 13 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031096898160595788		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.031096898160595788 | validation: 0.019546488193834304]
	TIME [epoch: 13 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037422288261930226		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.037422288261930226 | validation: 0.019660602696592224]
	TIME [epoch: 13 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033252974739018865		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.033252974739018865 | validation: 0.021707550517669247]
	TIME [epoch: 13 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03421308879621971		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.03421308879621971 | validation: 0.02242312262602656]
	TIME [epoch: 13 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032090827005301935		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.032090827005301935 | validation: 0.01525111287133201]
	TIME [epoch: 13 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03703802201546112		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.03703802201546112 | validation: 0.02485726540242106]
	TIME [epoch: 13 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03490277245951044		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.03490277245951044 | validation: 0.019638774016220457]
	TIME [epoch: 13 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03414220643695455		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.03414220643695455 | validation: 0.027724427788963783]
	TIME [epoch: 13 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036429395122922176		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.036429395122922176 | validation: 0.023331258857292578]
	TIME [epoch: 13 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04128554525476151		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.04128554525476151 | validation: 0.0342881354010618]
	TIME [epoch: 13 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03892739412364219		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.03892739412364219 | validation: 0.024204486342597756]
	TIME [epoch: 13 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04345895452654511		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.04345895452654511 | validation: 0.027513127621110817]
	TIME [epoch: 13 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04477087945023155		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.04477087945023155 | validation: 0.027603157190614437]
	TIME [epoch: 13 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03943715620516208		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.03943715620516208 | validation: 0.020983102843880126]
	TIME [epoch: 13 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03650473718217912		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.03650473718217912 | validation: 0.029327646533454654]
	TIME [epoch: 13 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034550757144050495		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.034550757144050495 | validation: 0.012947604575184105]
	TIME [epoch: 13 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03511607511816692		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.03511607511816692 | validation: 0.02189458795687853]
	TIME [epoch: 13 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03523316167087437		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.03523316167087437 | validation: 0.020817020960209005]
	TIME [epoch: 13 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04091115775350873		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.04091115775350873 | validation: 0.031324110503754346]
	TIME [epoch: 13 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039685613538256094		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.039685613538256094 | validation: 0.026812976793929848]
	TIME [epoch: 13 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040684337459375844		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.040684337459375844 | validation: 0.026900218073780586]
	TIME [epoch: 13 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036554118618226245		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.036554118618226245 | validation: 0.027498315561875427]
	TIME [epoch: 13 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03859021660669683		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.03859021660669683 | validation: 0.027336165660150295]
	TIME [epoch: 13 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0338350741715646		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.0338350741715646 | validation: 0.02768799633990618]
	TIME [epoch: 13 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03514074228423598		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.03514074228423598 | validation: 0.015872856060966535]
	TIME [epoch: 13 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03481670822044992		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.03481670822044992 | validation: 0.027213342855449085]
	TIME [epoch: 13 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03510879521274478		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.03510879521274478 | validation: 0.025579829915902776]
	TIME [epoch: 13 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04099274426989562		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.04099274426989562 | validation: 0.033677822583305456]
	TIME [epoch: 13 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040472421065899586		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.040472421065899586 | validation: 0.02630241815919214]
	TIME [epoch: 13 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04086846739215756		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.04086846739215756 | validation: 0.02691346229272502]
	TIME [epoch: 13 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033186377971611426		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.033186377971611426 | validation: 0.032592739455590915]
	TIME [epoch: 13 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03414356595675867		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.03414356595675867 | validation: 0.02404714888085059]
	TIME [epoch: 13 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036759099543593715		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.036759099543593715 | validation: 0.029419802944605156]
	TIME [epoch: 13 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030810448693232323		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.030810448693232323 | validation: 0.01929064471654542]
	TIME [epoch: 13 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030124893116145593		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.030124893116145593 | validation: 0.023885289697337955]
	TIME [epoch: 13 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031043974866308482		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.031043974866308482 | validation: 0.02153037510600683]
	TIME [epoch: 13 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024084856331507143		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.024084856331507143 | validation: 0.016335584931776816]
	TIME [epoch: 13 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03157130409094415		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.03157130409094415 | validation: 0.01470656011708145]
	TIME [epoch: 13 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030475616902514824		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.030475616902514824 | validation: 0.02245602959645627]
	TIME [epoch: 13 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02932217041914202		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.02932217041914202 | validation: 0.021254216778268917]
	TIME [epoch: 13 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029674732277108828		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.029674732277108828 | validation: 0.020404381155676204]
	TIME [epoch: 13 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03109938961719172		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.03109938961719172 | validation: 0.02290803058604469]
	TIME [epoch: 13 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032554978641510406		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.032554978641510406 | validation: 0.01862649264920195]
	TIME [epoch: 13 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03434000163055755		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.03434000163055755 | validation: 0.023102866904187867]
	TIME [epoch: 13 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0314405090033612		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.0314405090033612 | validation: 0.024040927987054685]
	TIME [epoch: 13 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026342065561643764		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.026342065561643764 | validation: 0.02580031092969928]
	TIME [epoch: 13 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026627496242477344		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.026627496242477344 | validation: 0.014482397913431493]
	TIME [epoch: 13 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02765082130721808		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.02765082130721808 | validation: 0.022208715032661197]
	TIME [epoch: 13 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027935731221797697		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.027935731221797697 | validation: 0.019695610586498095]
	TIME [epoch: 13 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02749114534389101		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.02749114534389101 | validation: 0.02109178137061421]
	TIME [epoch: 13 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026851037138025738		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.026851037138025738 | validation: 0.02432393591244137]
	TIME [epoch: 13 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030561339641170377		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.030561339641170377 | validation: 0.008371523715285047]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240309_135640/states/model_tr_study4_1268.pth
	Model improved!!!
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027111448321539392		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.027111448321539392 | validation: 0.014407768721271133]
	TIME [epoch: 13 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025098470248453075		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.025098470248453075 | validation: 0.013597813633909191]
	TIME [epoch: 13 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02691164415576916		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.02691164415576916 | validation: 0.02380832709329191]
	TIME [epoch: 13 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030083249173127224		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.030083249173127224 | validation: 0.023905001739952362]
	TIME [epoch: 13 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03645587112528934		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.03645587112528934 | validation: 0.02590163110344572]
	TIME [epoch: 13 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03678052474606773		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.03678052474606773 | validation: 0.019555393735284216]
	TIME [epoch: 13 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030473503908743062		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.030473503908743062 | validation: 0.01599796705836961]
	TIME [epoch: 13 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02837119438334528		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.02837119438334528 | validation: 0.028251711379295812]
	TIME [epoch: 13 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03251883031311129		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.03251883031311129 | validation: 0.02304623386007444]
	TIME [epoch: 13 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034678780489406015		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.034678780489406015 | validation: 0.0338830491902464]
	TIME [epoch: 13 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041576781704992676		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.041576781704992676 | validation: 0.03321418213302561]
	TIME [epoch: 13 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04594000283313296		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.04594000283313296 | validation: 0.03585906436532394]
	TIME [epoch: 13 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04422158458322746		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.04422158458322746 | validation: 0.02885167358325429]
	TIME [epoch: 13 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03924574972333082		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.03924574972333082 | validation: 0.03342026124634818]
	TIME [epoch: 13 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037324059998941714		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.037324059998941714 | validation: 0.026451650334586806]
	TIME [epoch: 13 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030837815907905262		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.030837815907905262 | validation: 0.020161661111549007]
	TIME [epoch: 13 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028759378371811528		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.028759378371811528 | validation: 0.024029870698412205]
	TIME [epoch: 13 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030270729084001507		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.030270729084001507 | validation: 0.022680324636235736]
	TIME [epoch: 13 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029908048709546216		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.029908048709546216 | validation: 0.0202243565484684]
	TIME [epoch: 13 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03183221415093851		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.03183221415093851 | validation: 0.02089442266165933]
	TIME [epoch: 13 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03145853289078998		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.03145853289078998 | validation: 0.025270634052817514]
	TIME [epoch: 13 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03392431501278005		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.03392431501278005 | validation: 0.026828138106189586]
	TIME [epoch: 13 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03494603748192318		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.03494603748192318 | validation: 0.02483990127982594]
	TIME [epoch: 13 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032909062609430634		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.032909062609430634 | validation: 0.014761518352236519]
	TIME [epoch: 13 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03215385450031947		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.03215385450031947 | validation: 0.029909550857373634]
	TIME [epoch: 13 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03133476681735881		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.03133476681735881 | validation: 0.022402081569668955]
	TIME [epoch: 13 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031615570193607764		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.031615570193607764 | validation: 0.019127169230053327]
	TIME [epoch: 13 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03509018583286164		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.03509018583286164 | validation: 0.022844086452512947]
	TIME [epoch: 13 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029189245457583175		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.029189245457583175 | validation: 0.02552032178908476]
	TIME [epoch: 13 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03411760897308883		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.03411760897308883 | validation: 0.020387040428978556]
	TIME [epoch: 13 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030280753135593023		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.030280753135593023 | validation: 0.02961676307694001]
	TIME [epoch: 13 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03364526004414565		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.03364526004414565 | validation: 0.030806053398458124]
	TIME [epoch: 13 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04051193074262801		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.04051193074262801 | validation: 0.030913459240411837]
	TIME [epoch: 13 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03802550724907284		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.03802550724907284 | validation: 0.02657569494420913]
	TIME [epoch: 13 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0316366884012504		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.0316366884012504 | validation: 0.03349292811740993]
	TIME [epoch: 13 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03989685068382249		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.03989685068382249 | validation: 0.02868471357529903]
	TIME [epoch: 13 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03926835368746386		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.03926835368746386 | validation: 0.031193226641940363]
	TIME [epoch: 13 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03700719319255206		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.03700719319255206 | validation: 0.030431313363653567]
	TIME [epoch: 13 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03989578546602114		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.03989578546602114 | validation: 0.04151039739723249]
	TIME [epoch: 13 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04233083362256586		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.04233083362256586 | validation: 0.034804320574877694]
	TIME [epoch: 13 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04417227869223902		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.04417227869223902 | validation: 0.038979248841895686]
	TIME [epoch: 13 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0499480454164747		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.0499480454164747 | validation: 0.04966123688347466]
	TIME [epoch: 13 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05342044661189011		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.05342044661189011 | validation: 0.048784481311308844]
	TIME [epoch: 13 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054335999609460915		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.054335999609460915 | validation: 0.03829633243343699]
	TIME [epoch: 13 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04469827773336486		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.04469827773336486 | validation: 0.024898737699961777]
	TIME [epoch: 13 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03697166874162355		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.03697166874162355 | validation: 0.03358749532096228]
	TIME [epoch: 13 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03740903496132899		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.03740903496132899 | validation: 0.03201243355667219]
	TIME [epoch: 13 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038086878297214855		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.038086878297214855 | validation: 0.037456036075846126]
	TIME [epoch: 13 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03415757610708927		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.03415757610708927 | validation: 0.0348240033507461]
	TIME [epoch: 13 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03150155860753882		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.03150155860753882 | validation: 0.027500675740582913]
	TIME [epoch: 13 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03520846943725253		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.03520846943725253 | validation: 0.026775598772817925]
	TIME [epoch: 13 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028262521267024256		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.028262521267024256 | validation: 0.026080571817860925]
	TIME [epoch: 13 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035403042324890346		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.035403042324890346 | validation: 0.02107182298812615]
	TIME [epoch: 13 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03387300974036391		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.03387300974036391 | validation: 0.027549552548113802]
	TIME [epoch: 13 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029481150020936653		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.029481150020936653 | validation: 0.019490936070042084]
	TIME [epoch: 13 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03187724044078512		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.03187724044078512 | validation: 0.02055068509959446]
	TIME [epoch: 13 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031657900087876986		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.031657900087876986 | validation: 0.025755578615663324]
	TIME [epoch: 13 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029380542390392853		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.029380542390392853 | validation: 0.025905620838326003]
	TIME [epoch: 13 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032925278480056816		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.032925278480056816 | validation: 0.024217741099437366]
	TIME [epoch: 13 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03158040968072698		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.03158040968072698 | validation: 0.025102546890165]
	TIME [epoch: 13 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03406487108757629		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.03406487108757629 | validation: 0.026225200714640868]
	TIME [epoch: 13 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03472029941084665		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.03472029941084665 | validation: 0.02237225924894483]
	TIME [epoch: 13 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03162748904604335		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.03162748904604335 | validation: 0.024197189813369647]
	TIME [epoch: 13 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034553810936340176		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.034553810936340176 | validation: 0.023110255404410984]
	TIME [epoch: 13 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029753094475560373		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.029753094475560373 | validation: 0.016589704684141653]
	TIME [epoch: 13 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028949047288146727		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.028949047288146727 | validation: 0.01766542088732383]
	TIME [epoch: 13 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02456161836360223		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.02456161836360223 | validation: 0.02123298824684427]
	TIME [epoch: 13 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03008785449886832		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.03008785449886832 | validation: 0.020314290531190445]
	TIME [epoch: 13 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026844891921023413		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.026844891921023413 | validation: 0.018706391680860177]
	TIME [epoch: 13 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028421076968561033		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.028421076968561033 | validation: 0.02758622037298446]
	TIME [epoch: 13 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031086519774539884		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.031086519774539884 | validation: 0.024554000344898994]
	TIME [epoch: 13 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031188713288026183		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.031188713288026183 | validation: 0.023362152596249377]
	TIME [epoch: 13 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03012361122847843		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.03012361122847843 | validation: 0.02356385150033328]
	TIME [epoch: 13 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03278288778312796		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.03278288778312796 | validation: 0.019235450138291515]
	TIME [epoch: 13 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031242218558260617		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.031242218558260617 | validation: 0.029928812638507506]
	TIME [epoch: 13 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03320177636700457		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.03320177636700457 | validation: 0.01767339037519886]
	TIME [epoch: 13 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028953181532974864		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.028953181532974864 | validation: 0.024339114767470693]
	TIME [epoch: 13 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029666268402548435		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.029666268402548435 | validation: 0.022796955100626858]
	TIME [epoch: 13 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0298704775626152		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.0298704775626152 | validation: 0.019375194360296825]
	TIME [epoch: 13 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03425833387829109		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.03425833387829109 | validation: 0.033637214807438295]
	TIME [epoch: 13 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03563198372589012		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.03563198372589012 | validation: 0.022055880448000442]
	TIME [epoch: 13 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031660247904019556		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.031660247904019556 | validation: 0.03346293561586091]
	TIME [epoch: 13 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034898329928538696		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.034898329928538696 | validation: 0.021566270971163697]
	TIME [epoch: 13 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03266375994536455		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.03266375994536455 | validation: 0.02892775170559668]
	TIME [epoch: 13 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03179030969727055		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.03179030969727055 | validation: 0.025726343511039168]
	TIME [epoch: 13 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030484578619695644		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.030484578619695644 | validation: 0.02228863948088821]
	TIME [epoch: 13 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032002785178922764		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.032002785178922764 | validation: 0.025328229690248713]
	TIME [epoch: 13 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03254222735933319		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.03254222735933319 | validation: 0.023948556086568533]
	TIME [epoch: 13 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031043977085432498		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.031043977085432498 | validation: 0.02263259420361848]
	TIME [epoch: 13 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03344189106720047		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.03344189106720047 | validation: 0.02622239694555428]
	TIME [epoch: 13 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03472511248820408		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.03472511248820408 | validation: 0.02752494939272647]
	TIME [epoch: 13 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028180957034579082		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.028180957034579082 | validation: 0.025999362317227995]
	TIME [epoch: 13 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02639646639012687		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.02639646639012687 | validation: 0.02183586863071609]
	TIME [epoch: 13 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02814969917372643		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.02814969917372643 | validation: 0.02449666004955553]
	TIME [epoch: 13 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02905509552730938		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.02905509552730938 | validation: 0.014707054113616575]
	TIME [epoch: 13 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0329449005659387		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.0329449005659387 | validation: 0.020007904979030103]
	TIME [epoch: 13 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02879485279448942		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.02879485279448942 | validation: 0.01808670686814983]
	TIME [epoch: 13 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03196880539697036		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.03196880539697036 | validation: 0.01445018282706394]
	TIME [epoch: 13 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028519309747595145		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.028519309747595145 | validation: 0.022012595991429018]
	TIME [epoch: 13 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028661709041338742		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.028661709041338742 | validation: 0.021848885150357485]
	TIME [epoch: 13 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030926605321783762		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.030926605321783762 | validation: 0.018991881141307107]
	TIME [epoch: 13 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03038233296421354		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.03038233296421354 | validation: 0.018043082288440475]
	TIME [epoch: 13 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02795673064386621		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.02795673064386621 | validation: 0.018751296462368595]
	TIME [epoch: 13 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028514370346632897		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.028514370346632897 | validation: 0.026342526796226232]
	TIME [epoch: 13 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0284037821893279		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.0284037821893279 | validation: 0.0176912557588399]
	TIME [epoch: 13 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02933110233762238		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.02933110233762238 | validation: 0.02146970197794388]
	TIME [epoch: 13 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029497747107815907		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.029497747107815907 | validation: 0.028926953639639305]
	TIME [epoch: 13 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02905145142199773		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.02905145142199773 | validation: 0.02626444626794497]
	TIME [epoch: 13 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031697869606614734		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.031697869606614734 | validation: 0.021262275592992777]
	TIME [epoch: 13 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032493700263099376		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.032493700263099376 | validation: 0.022268224563734645]
	TIME [epoch: 13 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031354347113082985		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.031354347113082985 | validation: 0.02029723627284957]
	TIME [epoch: 13 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02899441199586977		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.02899441199586977 | validation: 0.029009629521143658]
	TIME [epoch: 13 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033072190205621306		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.033072190205621306 | validation: 0.014169846415507465]
	TIME [epoch: 13 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027925334536957794		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.027925334536957794 | validation: 0.024117017600525252]
	TIME [epoch: 13 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02670153139565328		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.02670153139565328 | validation: 0.01986274795030843]
	TIME [epoch: 13 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03137139883481427		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.03137139883481427 | validation: 0.018360840186152947]
	TIME [epoch: 13 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025885741226439957		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.025885741226439957 | validation: 0.024778214574000628]
	TIME [epoch: 13 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02942826373408888		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.02942826373408888 | validation: 0.014113161404405168]
	TIME [epoch: 13 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030279109415118757		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.030279109415118757 | validation: 0.02163260584407675]
	TIME [epoch: 13 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027107594191345587		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.027107594191345587 | validation: 0.025388982281389864]
	TIME [epoch: 13 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03226401633716938		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.03226401633716938 | validation: 0.020834902756489356]
	TIME [epoch: 13 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03191257329485565		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.03191257329485565 | validation: 0.02782336255006212]
	TIME [epoch: 13 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03102043390601282		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.03102043390601282 | validation: 0.030913658452464077]
	TIME [epoch: 13 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03026842942196263		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.03026842942196263 | validation: 0.02050424844663188]
	TIME [epoch: 13 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03103526277440449		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.03103526277440449 | validation: 0.02260815538820813]
	TIME [epoch: 13 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030896248988476687		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.030896248988476687 | validation: 0.02054748467444985]
	TIME [epoch: 13 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032012921699896765		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.032012921699896765 | validation: 0.022817285181605102]
	TIME [epoch: 13 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030778997899486432		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.030778997899486432 | validation: 0.029359302442416132]
	TIME [epoch: 13 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02961349708447624		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.02961349708447624 | validation: 0.024250136538257507]
	TIME [epoch: 13 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028141636511770568		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.028141636511770568 | validation: 0.009088295871857237]
	TIME [epoch: 13 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032829929339081146		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.032829929339081146 | validation: 0.017914894871757715]
	TIME [epoch: 13 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02904178409628394		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.02904178409628394 | validation: 0.00999450721421608]
	TIME [epoch: 13 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02850851327631993		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.02850851327631993 | validation: 0.015182013237368635]
	TIME [epoch: 13 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029397690051938954		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.029397690051938954 | validation: 0.026119198033019337]
	TIME [epoch: 13 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030159027513450003		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.030159027513450003 | validation: 0.02354672347875813]
	TIME [epoch: 13 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028016348377758127		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.028016348377758127 | validation: 0.021790168365053812]
	TIME [epoch: 13 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029241288916594554		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.029241288916594554 | validation: 0.015639284859185903]
	TIME [epoch: 13 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029431834886293032		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.029431834886293032 | validation: 0.014724708752228208]
	TIME [epoch: 13 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026274191027508886		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.026274191027508886 | validation: 0.015750080000434426]
	TIME [epoch: 13 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02772928972857924		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.02772928972857924 | validation: 0.023933708808942168]
	TIME [epoch: 13 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02890629189607399		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.02890629189607399 | validation: 0.0204618767675572]
	TIME [epoch: 13 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026484988899215044		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.026484988899215044 | validation: 0.014617990425773617]
	TIME [epoch: 13 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027497590010073944		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.027497590010073944 | validation: 0.018565090722730552]
	TIME [epoch: 13 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027759358124946173		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.027759358124946173 | validation: 0.01856446866807576]
	TIME [epoch: 13 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02733305094756313		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.02733305094756313 | validation: 0.018217334399199765]
	TIME [epoch: 13 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028524512017653898		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.028524512017653898 | validation: 0.013940486443361938]
	TIME [epoch: 13 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02914259970348458		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.02914259970348458 | validation: 0.02077934847475852]
	TIME [epoch: 13 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03150228705371892		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.03150228705371892 | validation: 0.022079581173381217]
	TIME [epoch: 13 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02921149902597391		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.02921149902597391 | validation: 0.01857684213963355]
	TIME [epoch: 13 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027877261084446603		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.027877261084446603 | validation: 0.02323505872427126]
	TIME [epoch: 13 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02480370988874774		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.02480370988874774 | validation: 0.021768085239233643]
	TIME [epoch: 13 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027776761921199267		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.027776761921199267 | validation: 0.017911940260079976]
	TIME [epoch: 13 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030105550346026612		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.030105550346026612 | validation: 0.019996115769877653]
	TIME [epoch: 13 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02734247082780213		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.02734247082780213 | validation: 0.015606427527589782]
	TIME [epoch: 13 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026860025878928277		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.026860025878928277 | validation: 0.02270152351318144]
	TIME [epoch: 13 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02714349856990555		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.02714349856990555 | validation: 0.027086108887352953]
	TIME [epoch: 13 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03130649015905784		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.03130649015905784 | validation: 0.013063674396635217]
	TIME [epoch: 13 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027616344171727425		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.027616344171727425 | validation: 0.017911095967418123]
	TIME [epoch: 13 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029379067600494493		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.029379067600494493 | validation: 0.0174343574873878]
	TIME [epoch: 13 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028353716405604315		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.028353716405604315 | validation: 0.02151197572747245]
	TIME [epoch: 13 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029395984258704634		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.029395984258704634 | validation: 0.01461385521158319]
	TIME [epoch: 13 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02682663428779868		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.02682663428779868 | validation: 0.01786960045623615]
	TIME [epoch: 13 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02674252517785928		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.02674252517785928 | validation: 0.011996938753660787]
	TIME [epoch: 13 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026249275496041998		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.026249275496041998 | validation: 0.02719720865142716]
	TIME [epoch: 13 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026741736557895093		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.026741736557895093 | validation: 0.010887277251950173]
	TIME [epoch: 13 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03003624554867081		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.03003624554867081 | validation: 0.03232178492734847]
	TIME [epoch: 13 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02829449630544063		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.02829449630544063 | validation: 0.023125431757675636]
	TIME [epoch: 13 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026896966202882906		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.026896966202882906 | validation: 0.016930833162050726]
	TIME [epoch: 13 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027522723630279432		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.027522723630279432 | validation: 0.01743095816490401]
	TIME [epoch: 13 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02743014186446737		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.02743014186446737 | validation: 0.017843381359574962]
	TIME [epoch: 13 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027377581898566167		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.027377581898566167 | validation: 0.011286876546773069]
	TIME [epoch: 13 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02462870735880645		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.02462870735880645 | validation: 0.012302376101112544]
	TIME [epoch: 13 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031401216605256216		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.031401216605256216 | validation: 0.017959164987051992]
	TIME [epoch: 13 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026529851376889152		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.026529851376889152 | validation: 0.010108230398176772]
	TIME [epoch: 13 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028116585024861727		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.028116585024861727 | validation: 0.015437323209247227]
	TIME [epoch: 13 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027915367619931165		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.027915367619931165 | validation: 0.014688510870560363]
	TIME [epoch: 13 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030634404902009377		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.030634404902009377 | validation: 0.015844190285081914]
	TIME [epoch: 13 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02542902141379938		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.02542902141379938 | validation: 0.021304438472553987]
	TIME [epoch: 13 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02498035711474883		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.02498035711474883 | validation: 0.010851716712157136]
	TIME [epoch: 13 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027169387894962836		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.027169387894962836 | validation: 0.02302033418774248]
	TIME [epoch: 13 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028006708471881022		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.028006708471881022 | validation: 0.016698328966365243]
	TIME [epoch: 13 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026055463715465296		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.026055463715465296 | validation: 0.017699746196783817]
	TIME [epoch: 13 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028654813395301106		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.028654813395301106 | validation: 0.027984039176393236]
	TIME [epoch: 13 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028033033697382657		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.028033033697382657 | validation: 0.019789692201510833]
	TIME [epoch: 13 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03002168587216178		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.03002168587216178 | validation: 0.021088480285600394]
	TIME [epoch: 13 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03119340454121839		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.03119340454121839 | validation: 0.026605996294070806]
	TIME [epoch: 13 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03102146926474106		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.03102146926474106 | validation: 0.027664831126443197]
	TIME [epoch: 13 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02882611429205229		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.02882611429205229 | validation: 0.015821323707863377]
	TIME [epoch: 13 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028063867103435697		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.028063867103435697 | validation: 0.019850119085315233]
	TIME [epoch: 13 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032229368344851114		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.032229368344851114 | validation: 0.021289007131197073]
	TIME [epoch: 13 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030082527990830152		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.030082527990830152 | validation: 0.022891634779530684]
	TIME [epoch: 13 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03422597067231665		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.03422597067231665 | validation: 0.023820224954388573]
	TIME [epoch: 13 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032527184364883485		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.032527184364883485 | validation: 0.018676720980461314]
	TIME [epoch: 13 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03451794127676573		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.03451794127676573 | validation: 0.02584432379660558]
	TIME [epoch: 13 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034237553637326244		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.034237553637326244 | validation: 0.03081270371653194]
	TIME [epoch: 13 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028790953837106566		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.028790953837106566 | validation: 0.02033387736374817]
	TIME [epoch: 13 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03210880390144044		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.03210880390144044 | validation: 0.020998115140149456]
	TIME [epoch: 13 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030140379387070284		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.030140379387070284 | validation: 0.01745805132121388]
	TIME [epoch: 13 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030372933446100495		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.030372933446100495 | validation: 0.023718448074846944]
	TIME [epoch: 13 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02924583682151402		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.02924583682151402 | validation: 0.013733166938848096]
	TIME [epoch: 13 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029331926363545854		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.029331926363545854 | validation: 0.02036371919587508]
	TIME [epoch: 13 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028857528972654423		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.028857528972654423 | validation: 0.014201731922591266]
	TIME [epoch: 13 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029644637890023105		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.029644637890023105 | validation: 0.021765082311924658]
	TIME [epoch: 13 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02896415224320159		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.02896415224320159 | validation: 0.030841619267846662]
	TIME [epoch: 13 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033051858599358226		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.033051858599358226 | validation: 0.025319320760773218]
	TIME [epoch: 13 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032931316093354666		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.032931316093354666 | validation: 0.027040862357760976]
	TIME [epoch: 13 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035295279891591494		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.035295279891591494 | validation: 0.02025004271915528]
	TIME [epoch: 13 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029048348835513715		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.029048348835513715 | validation: 0.029811621502607064]
	TIME [epoch: 13 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035406466512016614		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.035406466512016614 | validation: 0.024344270769385085]
	TIME [epoch: 13 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033585983233831856		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.033585983233831856 | validation: 0.03125136499878973]
	TIME [epoch: 13 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03471472339824321		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.03471472339824321 | validation: 0.02854560763944844]
	TIME [epoch: 13 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03856328632313937		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.03856328632313937 | validation: 0.031273791720587946]
	TIME [epoch: 13 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04115851393922909		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.04115851393922909 | validation: 0.030654898340440818]
	TIME [epoch: 13 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038732111888607736		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.038732111888607736 | validation: 0.025408645541362115]
	TIME [epoch: 13 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0390594018293559		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.0390594018293559 | validation: 0.024862678541035278]
	TIME [epoch: 13 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035711999235797987		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.035711999235797987 | validation: 0.032346240259187885]
	TIME [epoch: 13 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036135009434672426		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.036135009434672426 | validation: 0.02987234360460708]
	TIME [epoch: 13 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03577235572526062		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.03577235572526062 | validation: 0.030347612142014757]
	TIME [epoch: 13 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03792400795793854		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.03792400795793854 | validation: 0.033772754747199756]
	TIME [epoch: 13 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037434671968729766		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.037434671968729766 | validation: 0.026946546419720586]
	TIME [epoch: 13 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03428475223903036		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.03428475223903036 | validation: 0.026453227810772587]
	TIME [epoch: 13 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03370066206635019		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.03370066206635019 | validation: 0.02186696585994896]
	TIME [epoch: 13 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03583615612051925		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.03583615612051925 | validation: 0.024501894974184982]
	TIME [epoch: 13 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03530934929983217		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.03530934929983217 | validation: 0.028920241972038283]
	TIME [epoch: 13 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03245702944593379		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.03245702944593379 | validation: 0.02723451579799088]
	TIME [epoch: 13 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033635666065704034		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.033635666065704034 | validation: 0.025112424371992265]
	TIME [epoch: 13 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03334840649634716		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.03334840649634716 | validation: 0.015594958371511064]
	TIME [epoch: 13 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03073864598329689		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.03073864598329689 | validation: 0.024578643844968308]
	TIME [epoch: 13 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034488261368003675		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.034488261368003675 | validation: 0.02297200600123072]
	TIME [epoch: 13 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0357741484318367		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.0357741484318367 | validation: 0.02480631117459729]
	TIME [epoch: 13.1 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030940604488436947		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.030940604488436947 | validation: 0.030290639080615786]
	TIME [epoch: 13 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03159558437420963		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.03159558437420963 | validation: 0.018051250749392695]
	TIME [epoch: 13 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029295764678446676		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.029295764678446676 | validation: 0.021570201226031257]
	TIME [epoch: 13 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03304876484011128		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.03304876484011128 | validation: 0.02579488010779125]
	TIME [epoch: 13 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03215735548221691		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.03215735548221691 | validation: 0.023240762695047826]
	TIME [epoch: 13 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032590949194844954		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.032590949194844954 | validation: 0.018043660112883476]
	TIME [epoch: 13 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028258968573524085		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.028258968573524085 | validation: 0.023504006962404303]
	TIME [epoch: 13 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036121454934336446		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.036121454934336446 | validation: 0.021217799485830007]
	TIME [epoch: 13 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03313133257828023		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.03313133257828023 | validation: 0.025158511779839077]
	TIME [epoch: 13 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032361360974286935		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.032361360974286935 | validation: 0.025075080804392018]
	TIME [epoch: 13 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03704147610778197		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.03704147610778197 | validation: 0.02828256191395062]
	TIME [epoch: 13 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0350431180223768		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.0350431180223768 | validation: 0.032118608184213075]
	TIME [epoch: 13 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03508295013174474		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.03508295013174474 | validation: 0.034101651047738865]
	TIME [epoch: 13.1 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03368457440592152		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.03368457440592152 | validation: 0.030919982011708046]
	TIME [epoch: 13 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03549330664200143		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.03549330664200143 | validation: 0.020898230552920866]
	TIME [epoch: 13 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032183557762427095		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.032183557762427095 | validation: 0.030925917276638463]
	TIME [epoch: 13 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037974371060390914		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.037974371060390914 | validation: 0.026153481941874706]
	TIME [epoch: 13 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03180206176821403		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.03180206176821403 | validation: 0.021274036158089454]
	TIME [epoch: 13 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03435780992643418		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.03435780992643418 | validation: 0.0267176342423761]
	TIME [epoch: 13 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03671194390264647		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.03671194390264647 | validation: 0.03563109945833546]
	TIME [epoch: 13 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03329908174430292		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.03329908174430292 | validation: 0.022799489219216755]
	TIME [epoch: 13 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033957592907455356		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.033957592907455356 | validation: 0.021906012420986193]
	TIME [epoch: 13 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03529478759573407		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.03529478759573407 | validation: 0.02688116653824852]
	TIME [epoch: 13 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03769280237840581		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.03769280237840581 | validation: 0.023830552414897337]
	TIME [epoch: 13 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037289004631216316		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.037289004631216316 | validation: 0.02263876769519289]
	TIME [epoch: 13 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03757678927269824		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.03757678927269824 | validation: 0.036900559636818445]
	TIME [epoch: 13.1 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03377823839412421		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.03377823839412421 | validation: 0.034733935693670705]
	TIME [epoch: 13 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02948720164405316		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.02948720164405316 | validation: 0.022956595878631608]
	TIME [epoch: 13 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03058002981367839		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.03058002981367839 | validation: 0.030122314889533795]
	TIME [epoch: 13 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03656768273686084		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.03656768273686084 | validation: 0.025679477201694497]
	TIME [epoch: 13 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03153640451849317		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.03153640451849317 | validation: 0.02395689597258304]
	TIME [epoch: 13 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03177847454552654		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.03177847454552654 | validation: 0.022627086051119415]
	TIME [epoch: 13 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032936055815567834		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.032936055815567834 | validation: 0.015329934705645617]
	TIME [epoch: 13 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03358750798240805		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.03358750798240805 | validation: 0.017711457798937135]
	TIME [epoch: 13 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028315723321293104		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.028315723321293104 | validation: 0.024907516493620482]
	TIME [epoch: 13 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029792905934950178		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.029792905934950178 | validation: 0.02107342597031977]
	TIME [epoch: 13 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02809672309790375		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.02809672309790375 | validation: 0.020563985238220322]
	TIME [epoch: 13 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029612537519136516		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.029612537519136516 | validation: 0.01905718566425958]
	TIME [epoch: 13 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026517203077299444		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.026517203077299444 | validation: 0.018723355377580908]
	TIME [epoch: 13 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029329834814311482		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.029329834814311482 | validation: 0.018807080848066704]
	TIME [epoch: 13 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03043902161511121		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.03043902161511121 | validation: 0.019578819538930363]
	TIME [epoch: 13 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029917324671665087		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.029917324671665087 | validation: 0.013091105960236799]
	TIME [epoch: 13 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028360155656955294		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.028360155656955294 | validation: 0.018292428362285604]
	TIME [epoch: 13 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030995108005166354		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.030995108005166354 | validation: 0.027154631746284404]
	TIME [epoch: 13 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027376019212415396		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.027376019212415396 | validation: 0.02001685088923851]
	TIME [epoch: 13 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03028509886426177		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.03028509886426177 | validation: 0.015707575903570286]
	TIME [epoch: 13 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02917138498901156		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.02917138498901156 | validation: 0.01599139739916891]
	TIME [epoch: 13 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02655585988919451		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.02655585988919451 | validation: 0.02054336031524497]
	TIME [epoch: 13 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02748844431363423		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.02748844431363423 | validation: 0.013661273787474934]
	TIME [epoch: 13 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025604898273229888		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.025604898273229888 | validation: 0.021934326723892613]
	TIME [epoch: 13 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030875247752545597		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.030875247752545597 | validation: 0.018522566173863213]
	TIME [epoch: 13 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026729151260450452		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.026729151260450452 | validation: 0.01123770325018598]
	TIME [epoch: 13 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03261603072206824		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.03261603072206824 | validation: 0.02053236575656303]
	TIME [epoch: 13 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02590173653363754		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.02590173653363754 | validation: 0.01988417595529196]
	TIME [epoch: 13 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030943464568005806		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.030943464568005806 | validation: 0.021948591864688033]
	TIME [epoch: 13 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03017904201813245		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.03017904201813245 | validation: 0.016019188729084963]
	TIME [epoch: 13 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02806380434015268		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.02806380434015268 | validation: 0.01835089963540811]
	TIME [epoch: 13 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027797649086858722		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.027797649086858722 | validation: 0.023238491694067866]
	TIME [epoch: 13 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02940602346685872		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.02940602346685872 | validation: 0.026911295133937207]
	TIME [epoch: 13 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026454977131829212		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.026454977131829212 | validation: 0.02131933461902642]
	TIME [epoch: 13 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025736990561018885		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.025736990561018885 | validation: 0.01886388040772471]
	TIME [epoch: 13 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027299779922457558		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.027299779922457558 | validation: 0.01871340996096976]
	TIME [epoch: 13 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029781360535237725		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.029781360535237725 | validation: 0.020896994956961585]
	TIME [epoch: 13 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02873732583645586		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.02873732583645586 | validation: 0.018688658604392557]
	TIME [epoch: 13 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028974819102815255		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.028974819102815255 | validation: 0.020047965003986236]
	TIME [epoch: 13 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02590599182147607		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.02590599182147607 | validation: 0.024053776158396142]
	TIME [epoch: 13 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028864559829316634		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.028864559829316634 | validation: 0.015368913209449447]
	TIME [epoch: 13 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029582703168302034		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.029582703168302034 | validation: 0.021196326677605154]
	TIME [epoch: 13 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0273919092513354		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.0273919092513354 | validation: 0.024326502138107983]
	TIME [epoch: 13 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029600712352846947		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.029600712352846947 | validation: 0.01734980241611455]
	TIME [epoch: 13 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026775041736661485		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.026775041736661485 | validation: 0.022782263849326297]
	TIME [epoch: 13 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02740901327331228		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.02740901327331228 | validation: 0.023239841059045183]
	TIME [epoch: 13 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02661080259516388		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.02661080259516388 | validation: 0.021542369407828978]
	TIME [epoch: 13 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03042769548834197		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.03042769548834197 | validation: 0.023458023878967227]
	TIME [epoch: 13 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02679891790694541		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.02679891790694541 | validation: 0.024627489330761424]
	TIME [epoch: 13 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03047283337354455		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.03047283337354455 | validation: 0.02584146533381378]
	TIME [epoch: 13 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024772609178409927		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.024772609178409927 | validation: 0.022688415739019804]
	TIME [epoch: 13 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02922392539737906		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.02922392539737906 | validation: 0.011826252569956232]
	TIME [epoch: 13 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0269584467945211		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.0269584467945211 | validation: 0.020805538743868385]
	TIME [epoch: 13 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02650981785279346		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.02650981785279346 | validation: 0.02206774753287063]
	TIME [epoch: 13 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028148317209341273		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.028148317209341273 | validation: 0.016298393553963973]
	TIME [epoch: 13 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026732079104197035		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.026732079104197035 | validation: 0.014807413192155727]
	TIME [epoch: 13 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02966764351220901		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.02966764351220901 | validation: 0.020513197174247832]
	TIME [epoch: 13 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027163289083810147		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.027163289083810147 | validation: 0.02674087858489611]
	TIME [epoch: 13 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024746509283713795		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.024746509283713795 | validation: 0.0186917931841651]
	TIME [epoch: 13 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02529678472051068		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.02529678472051068 | validation: 0.015517617086706821]
	TIME [epoch: 13 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02811477528728483		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.02811477528728483 | validation: 0.023094618444212532]
	TIME [epoch: 13 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029583570874928397		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.029583570874928397 | validation: 0.02716370575693372]
	TIME [epoch: 13 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028226148976003538		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.028226148976003538 | validation: 0.018608432982493105]
	TIME [epoch: 13 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026129665458792053		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.026129665458792053 | validation: 0.026421828346589595]
	TIME [epoch: 13 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026404436606127308		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.026404436606127308 | validation: 0.02101122493678667]
	TIME [epoch: 13 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02876987835643438		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.02876987835643438 | validation: 0.020192835224857576]
	TIME [epoch: 13 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024764181267857975		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.024764181267857975 | validation: 0.03101846434210258]
	TIME [epoch: 13 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03319534511496171		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.03319534511496171 | validation: 0.027528071329420867]
	TIME [epoch: 13 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032236657267391035		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.032236657267391035 | validation: 0.022941998759088852]
	TIME [epoch: 13 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028102659085491526		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.028102659085491526 | validation: 0.020374002143189737]
	TIME [epoch: 13 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026972396521078437		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.026972396521078437 | validation: 0.02417806996629544]
	TIME [epoch: 13 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027534590022227204		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.027534590022227204 | validation: 0.021934424152268487]
	TIME [epoch: 13 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02723912594182526		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.02723912594182526 | validation: 0.01975276312553625]
	TIME [epoch: 13 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032671503433174175		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.032671503433174175 | validation: 0.021045923340813618]
	TIME [epoch: 13 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028895148716441707		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.028895148716441707 | validation: 0.018945829047795924]
	TIME [epoch: 13 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030472326749955987		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.030472326749955987 | validation: 0.020535487378604177]
	TIME [epoch: 13 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029124831013253086		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.029124831013253086 | validation: 0.024427531148672823]
	TIME [epoch: 13 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02803116465396581		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.02803116465396581 | validation: 0.023559712780338]
	TIME [epoch: 13 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0245760265600082		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.0245760265600082 | validation: 0.024760507065445664]
	TIME [epoch: 13 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023880388790672016		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.023880388790672016 | validation: 0.016129667034479482]
	TIME [epoch: 13 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030353034712566885		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.030353034712566885 | validation: 0.013007265588388382]
	TIME [epoch: 13 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02839104654554478		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.02839104654554478 | validation: 0.01650313353355343]
	TIME [epoch: 13 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03196370881395433		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.03196370881395433 | validation: 0.01504083909249812]
	TIME [epoch: 13 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030363450652929877		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.030363450652929877 | validation: 0.019513305612348195]
	TIME [epoch: 13 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02956513472364957		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.02956513472364957 | validation: 0.02460853527695922]
	TIME [epoch: 13 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029907210814694232		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.029907210814694232 | validation: 0.024685908024415757]
	TIME [epoch: 13 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025277325618222653		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.025277325618222653 | validation: 0.014863379807337608]
	TIME [epoch: 13 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023621194529167444		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.023621194529167444 | validation: 0.02053289125471375]
	TIME [epoch: 13 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027189115618016124		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.027189115618016124 | validation: 0.025828577299458925]
	TIME [epoch: 13 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0300765306257135		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.0300765306257135 | validation: 0.02116015021783024]
	TIME [epoch: 13 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02943586253371904		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.02943586253371904 | validation: 0.018789696000228062]
	TIME [epoch: 13 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023683935996300427		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.023683935996300427 | validation: 0.022668752292968934]
	TIME [epoch: 13 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027275504653049967		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.027275504653049967 | validation: 0.013361808654167282]
	TIME [epoch: 13 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027805094269455828		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.027805094269455828 | validation: 0.02202106099484196]
	TIME [epoch: 13 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028101930019750893		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.028101930019750893 | validation: 0.015806491004090303]
	TIME [epoch: 13 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029303026516282915		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.029303026516282915 | validation: 0.01579666444821227]
	TIME [epoch: 13 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029253546676814374		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.029253546676814374 | validation: 0.01997865759122538]
	TIME [epoch: 13 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02763523574810043		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.02763523574810043 | validation: 0.027160643897216598]
	TIME [epoch: 13 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026989925235140926		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.026989925235140926 | validation: 0.022554390291880423]
	TIME [epoch: 13 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03177227131614312		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.03177227131614312 | validation: 0.022133830440234505]
	TIME [epoch: 13 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03315019766817301		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.03315019766817301 | validation: 0.024797456537450895]
	TIME [epoch: 13 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03145403346062441		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.03145403346062441 | validation: 0.01725719638953909]
	TIME [epoch: 13 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029802415692039626		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.029802415692039626 | validation: 0.022230992664486263]
	TIME [epoch: 13 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029247994177316133		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.029247994177316133 | validation: 0.018390445278630846]
	TIME [epoch: 13 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02783732250482136		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.02783732250482136 | validation: 0.021872319027370652]
	TIME [epoch: 13.1 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027490139589003842		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.027490139589003842 | validation: 0.02057048957271315]
	TIME [epoch: 13 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026866049828452733		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.026866049828452733 | validation: 0.009871760539649114]
	TIME [epoch: 13 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025164965074428846		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.025164965074428846 | validation: 0.017219889690767844]
	TIME [epoch: 13 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031465839014124544		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.031465839014124544 | validation: 0.02395897577859987]
	TIME [epoch: 13 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027715272655082394		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.027715272655082394 | validation: 0.022507742309106838]
	TIME [epoch: 13 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02584087984245635		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.02584087984245635 | validation: 0.019051435987744406]
	TIME [epoch: 13 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025548076646272545		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.025548076646272545 | validation: 0.0257235631709998]
	TIME [epoch: 13 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029385451921274338		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.029385451921274338 | validation: 0.02062974411599775]
	TIME [epoch: 13 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02796757031078606		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.02796757031078606 | validation: 0.01724878610309085]
	TIME [epoch: 13 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028022538332931078		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.028022538332931078 | validation: 0.022178730273027386]
	TIME [epoch: 13 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029844674668501433		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.029844674668501433 | validation: 0.0150378153948191]
	TIME [epoch: 13 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027547125724454582		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.027547125724454582 | validation: 0.01877515813164146]
	TIME [epoch: 13 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02486506292990879		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.02486506292990879 | validation: 0.0211666594285704]
	TIME [epoch: 13 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030430568545361546		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.030430568545361546 | validation: 0.021447945891822997]
	TIME [epoch: 13 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02911900526004641		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.02911900526004641 | validation: 0.01935418231761638]
	TIME [epoch: 13 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030207592338651293		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.030207592338651293 | validation: 0.015289810870396745]
	TIME [epoch: 13 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027484521680340074		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.027484521680340074 | validation: 0.011886289313348999]
	TIME [epoch: 13 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029859056049640988		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.029859056049640988 | validation: 0.018068067312294087]
	TIME [epoch: 13 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0275710490526047		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.0275710490526047 | validation: 0.020860732210276667]
	TIME [epoch: 13 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02809722146494839		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.02809722146494839 | validation: 0.011395413359668247]
	TIME [epoch: 13 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02993818501295612		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.02993818501295612 | validation: 0.018416137642325955]
	TIME [epoch: 13 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02920280355061129		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.02920280355061129 | validation: 0.01679485979875486]
	TIME [epoch: 13 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028203252000609642		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.028203252000609642 | validation: 0.026999924045254725]
	TIME [epoch: 13 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03361477951565672		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.03361477951565672 | validation: 0.026668591700656528]
	TIME [epoch: 13 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031471930528866605		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.031471930528866605 | validation: 0.02799095953272428]
	TIME [epoch: 13 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031557044545715		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.031557044545715 | validation: 0.030100202754603504]
	TIME [epoch: 13 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03566953306723039		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.03566953306723039 | validation: 0.02575824123562683]
	TIME [epoch: 13 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03211665168405379		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.03211665168405379 | validation: 0.039339913629164745]
	TIME [epoch: 13 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032388684840298235		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.032388684840298235 | validation: 0.01834130960319131]
	TIME [epoch: 13 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028380202164463963		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.028380202164463963 | validation: 0.0204991928968277]
	TIME [epoch: 13 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02966437642615791		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.02966437642615791 | validation: 0.02177508661001152]
	TIME [epoch: 13 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03014635425350146		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.03014635425350146 | validation: 0.025135297216627443]
	TIME [epoch: 13 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0301363960976374		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.0301363960976374 | validation: 0.021994592484797303]
	TIME [epoch: 13 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028402886973619732		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.028402886973619732 | validation: 0.02313791528529326]
	TIME [epoch: 13 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031238935915704813		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.031238935915704813 | validation: 0.024211564349441588]
	TIME [epoch: 13 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032258538732343064		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.032258538732343064 | validation: 0.027823906815144288]
	TIME [epoch: 13 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03304060919467629		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.03304060919467629 | validation: 0.02089265548929965]
	TIME [epoch: 13 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028118444148628657		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.028118444148628657 | validation: 0.020407273838521225]
	TIME [epoch: 13 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03171554078494382		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.03171554078494382 | validation: 0.018610756704025646]
	TIME [epoch: 13 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027651612990098877		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.027651612990098877 | validation: 0.024138372343667083]
	TIME [epoch: 13 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03241912806486858		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.03241912806486858 | validation: 0.024404920047739153]
	TIME [epoch: 13 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030818741871760577		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.030818741871760577 | validation: 0.02432673235893245]
	TIME [epoch: 13 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03206600841674949		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.03206600841674949 | validation: 0.025347030058269774]
	TIME [epoch: 13 sec]
EPOCH 1673/2000:
	Training over batches...
