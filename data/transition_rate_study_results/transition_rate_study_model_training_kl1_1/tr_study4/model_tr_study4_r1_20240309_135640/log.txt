Args:
Namespace(name='model_tr_study4', outdir='out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1', training_data='data/transition_rate_studies/tr_study4/tr_study4_training/r1', validation_data='data/transition_rate_studies/tr_study4/tr_study4_validation/r1', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 914251625

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.89425556305823		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.89425556305823 | validation: 7.4897583469762665]
	TIME [epoch: 91.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.681739096801392		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.681739096801392 | validation: 5.680167523993123]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.775311984827177		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.775311984827177 | validation: 5.398385200067678]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.20091170653608		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.20091170653608 | validation: 4.7539543561549475]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.768849351799246		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.768849351799246 | validation: 4.311102060162942]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.301758710403075		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.301758710403075 | validation: 4.81515257094438]
	TIME [epoch: 13 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.2997098814903385		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.2997098814903385 | validation: 3.4571765576081406]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.080235516271835		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.080235516271835 | validation: 3.93621893662347]
	TIME [epoch: 12.9 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8019667189153648		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8019667189153648 | validation: 3.444061823730721]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.516364124335474		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.516364124335474 | validation: 3.5091720842810923]
	TIME [epoch: 13.1 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5741950744255955		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5741950744255955 | validation: 3.8592500476828504]
	TIME [epoch: 13 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.71682634138693		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.71682634138693 | validation: 3.290971828128337]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.503356819471536		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.503356819471536 | validation: 3.4010871892897807]
	TIME [epoch: 13 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.370402748862416		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.370402748862416 | validation: 3.3762213306060413]
	TIME [epoch: 13 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.364599062757162		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.364599062757162 | validation: 3.673255924793847]
	TIME [epoch: 13 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.384095459472266		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.384095459472266 | validation: 3.150774777204108]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.296088512440893		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.296088512440893 | validation: 3.043992340359981]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.107268858483924		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.107268858483924 | validation: 5.441311788087673]
	TIME [epoch: 13 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.225066206594138		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.225066206594138 | validation: 3.0729881456940293]
	TIME [epoch: 13 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2183544190858613		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2183544190858613 | validation: 3.1731962220986754]
	TIME [epoch: 13.1 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.137221440130238		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.137221440130238 | validation: 3.850153875688993]
	TIME [epoch: 13 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2104721438033357		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2104721438033357 | validation: 2.8687935806575386]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9478648035001576		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9478648035001576 | validation: 3.272179101188365]
	TIME [epoch: 13 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0580338980043478		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0580338980043478 | validation: 2.8752255001952194]
	TIME [epoch: 13 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0635231107139065		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0635231107139065 | validation: 2.8600535904870377]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.953706053160634		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.953706053160634 | validation: 2.6748769406752273]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.687245051740354		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.687245051740354 | validation: 2.679035458445552]
	TIME [epoch: 13 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4338107798388657		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4338107798388657 | validation: 4.292283369661354]
	TIME [epoch: 13 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8798114031155424		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8798114031155424 | validation: 2.933460525108223]
	TIME [epoch: 12.9 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6526392255150157		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6526392255150157 | validation: 2.565659754634506]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.491224632004166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.491224632004166 | validation: 2.5480325646847466]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.478575982923161		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.478575982923161 | validation: 2.7071325547245513]
	TIME [epoch: 13 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5992388984963335		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5992388984963335 | validation: 2.177159763655043]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3124193904316654		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3124193904316654 | validation: 2.3186373750633957]
	TIME [epoch: 13 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.238819145773224		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.238819145773224 | validation: 2.0811400395762574]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4922100074605096		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4922100074605096 | validation: 2.1446737002353458]
	TIME [epoch: 13 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1394123022000726		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1394123022000726 | validation: 2.0645938659111263]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9854387623834124		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9854387623834124 | validation: 1.7807837645023352]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7931305495407768		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7931305495407768 | validation: 1.6717428637677905]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.613620588298378		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.613620588298378 | validation: 2.086324189496295]
	TIME [epoch: 13 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.754091564505283		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.754091564505283 | validation: 1.4542185751724475]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4712316611850362		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4712316611850362 | validation: 1.3346385785671464]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7535964956876384		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7535964956876384 | validation: 2.322870824110941]
	TIME [epoch: 13 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9143232622458977		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9143232622458977 | validation: 1.4947677554443441]
	TIME [epoch: 13 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5098259327767738		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5098259327767738 | validation: 1.2549309117165224]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4085505634114348		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4085505634114348 | validation: 1.2060067363847524]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1842317596458123		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1842317596458123 | validation: 1.492085436396011]
	TIME [epoch: 13 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.523149951994328		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.523149951994328 | validation: 1.445953069082105]
	TIME [epoch: 13 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2546334453162487		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2546334453162487 | validation: 1.561828530124512]
	TIME [epoch: 13 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2965045439300398		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2965045439300398 | validation: 1.019547989387612]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2204159867925444		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 1.2204159867925444 | validation: 1.1579449961264123]
	TIME [epoch: 13 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2935828702296521		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 1.2935828702296521 | validation: 0.9529719394407045]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.044683064718026		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 1.044683064718026 | validation: 1.0260726182135325]
	TIME [epoch: 13 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9564455727414354		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 0.9564455727414354 | validation: 1.8472898756073353]
	TIME [epoch: 13 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.16894171261549		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 1.16894171261549 | validation: 1.6343423548438254]
	TIME [epoch: 13 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1263906892765305		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 1.1263906892765305 | validation: 1.3126040623639228]
	TIME [epoch: 13 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0154299447616202		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 1.0154299447616202 | validation: 1.4960201026110764]
	TIME [epoch: 13 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.12058953459905		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 1.12058953459905 | validation: 1.065457755154898]
	TIME [epoch: 13.1 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9910074368625981		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 0.9910074368625981 | validation: 0.8792031152309047]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.916552215162088		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 0.916552215162088 | validation: 0.7703636230155091]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2119370290788514		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 1.2119370290788514 | validation: 0.8150145592229241]
	TIME [epoch: 13 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0352679244384506		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 1.0352679244384506 | validation: 0.9422605489527954]
	TIME [epoch: 13.1 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.176334959031886		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 1.176334959031886 | validation: 0.8811679149624813]
	TIME [epoch: 13 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1294300022750936		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 1.1294300022750936 | validation: 0.8890011252253188]
	TIME [epoch: 13 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9905525388777124		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 0.9905525388777124 | validation: 0.7270207004452971]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8728404553480004		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 0.8728404553480004 | validation: 0.687494889589894]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9313364401170119		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 0.9313364401170119 | validation: 1.0837270362073204]
	TIME [epoch: 13 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9282851096594114		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 0.9282851096594114 | validation: 1.0182328723743257]
	TIME [epoch: 13 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.886185338772923		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 0.886185338772923 | validation: 0.713406493336618]
	TIME [epoch: 13.1 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7218627645481503		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.7218627645481503 | validation: 0.6570376811813189]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_70.pth
	Model improved!!!
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7874300643849338		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.7874300643849338 | validation: 0.9506414906244478]
	TIME [epoch: 13 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6859757223417365		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 0.6859757223417365 | validation: 0.6925322908368647]
	TIME [epoch: 13 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.787212557031205		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 0.787212557031205 | validation: 0.8637750584702201]
	TIME [epoch: 13 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8377635315165654		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 0.8377635315165654 | validation: 0.5972875787587465]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_74.pth
	Model improved!!!
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8160287831963509		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.8160287831963509 | validation: 1.270700510257709]
	TIME [epoch: 13 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.839702601249616		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 0.839702601249616 | validation: 0.5606304964374624]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6026976829173043		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 0.6026976829173043 | validation: 0.8137182447061733]
	TIME [epoch: 13 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7093934771402658		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 0.7093934771402658 | validation: 0.47964994561168467]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7042711359475509		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 0.7042711359475509 | validation: 0.46000585782512204]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49116161640415035		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.49116161640415035 | validation: 1.6631956575088334]
	TIME [epoch: 13 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8812051401148313		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 0.8812051401148313 | validation: 0.4440298845115178]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_81.pth
	Model improved!!!
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6005490782622143		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 0.6005490782622143 | validation: 0.44825978732377025]
	TIME [epoch: 13 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7933406949657988		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 0.7933406949657988 | validation: 0.4835974520254493]
	TIME [epoch: 13.1 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48571083696299805		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 0.48571083696299805 | validation: 1.1554572502310174]
	TIME [epoch: 13.1 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0515204329129304		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 1.0515204329129304 | validation: 0.5183611714824214]
	TIME [epoch: 13 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5936286404191975		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 0.5936286404191975 | validation: 0.9411857839805536]
	TIME [epoch: 13.1 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7038490529752044		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 0.7038490529752044 | validation: 1.2669349621016917]
	TIME [epoch: 13.1 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7688817889073735		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 0.7688817889073735 | validation: 0.4487346323938835]
	TIME [epoch: 13 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6445888739540409		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.6445888739540409 | validation: 0.5925050634619716]
	TIME [epoch: 13 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5285646055486084		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.5285646055486084 | validation: 0.5618882904213489]
	TIME [epoch: 13.1 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8378560418940137		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 0.8378560418940137 | validation: 1.1526686823143821]
	TIME [epoch: 13 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8086157514256609		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 0.8086157514256609 | validation: 0.3673756725353467]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_92.pth
	Model improved!!!
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4626527844218111		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 0.4626527844218111 | validation: 0.7460257430109818]
	TIME [epoch: 13.1 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.553569965605252		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 0.553569965605252 | validation: 0.40364629578791766]
	TIME [epoch: 13 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7374500617555712		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.7374500617555712 | validation: 0.3860244765892077]
	TIME [epoch: 13 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4310587182010977		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 0.4310587182010977 | validation: 0.5043635834781314]
	TIME [epoch: 13.1 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6118369129679859		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 0.6118369129679859 | validation: 0.4307084276464714]
	TIME [epoch: 13.1 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5244352358712601		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.5244352358712601 | validation: 0.5570279910242794]
	TIME [epoch: 13 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.781340809461327		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 0.781340809461327 | validation: 0.5749780401163233]
	TIME [epoch: 13 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4781890763762524		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.4781890763762524 | validation: 0.710215549532818]
	TIME [epoch: 13.1 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.631020462866826		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 0.631020462866826 | validation: 0.4736670486657788]
	TIME [epoch: 13.1 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4519969424787142		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 0.4519969424787142 | validation: 0.5895204902201029]
	TIME [epoch: 13.1 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5720631585246029		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 0.5720631585246029 | validation: 1.3577066469444072]
	TIME [epoch: 13.1 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7488427898139283		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 0.7488427898139283 | validation: 0.3785061903948054]
	TIME [epoch: 13.1 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5075031090955469		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.5075031090955469 | validation: 0.6079891997061736]
	TIME [epoch: 13 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7332530937959578		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 0.7332530937959578 | validation: 0.3075720955599577]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_106.pth
	Model improved!!!
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5255389682167416		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.5255389682167416 | validation: 0.3841042822062709]
	TIME [epoch: 13 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49929366098605044		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 0.49929366098605044 | validation: 0.6598448327853303]
	TIME [epoch: 13.1 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5228933553317536		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 0.5228933553317536 | validation: 0.34242620857762923]
	TIME [epoch: 13 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5157010209628377		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.5157010209628377 | validation: 0.46822086794433615]
	TIME [epoch: 13 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4635638697523513		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 0.4635638697523513 | validation: 0.8406371309387017]
	TIME [epoch: 13.1 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4750615668896386		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 0.4750615668896386 | validation: 0.4095443908977617]
	TIME [epoch: 13 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42742550616616953		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 0.42742550616616953 | validation: 0.29818750005982314]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_113.pth
	Model improved!!!
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33348694286061487		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 0.33348694286061487 | validation: 0.548948810730697]
	TIME [epoch: 13 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49248246844317906		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.49248246844317906 | validation: 0.4320369653695439]
	TIME [epoch: 13.1 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47756198866187805		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.47756198866187805 | validation: 0.34799387535276366]
	TIME [epoch: 13 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5744569751287236		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 0.5744569751287236 | validation: 0.7232987531556465]
	TIME [epoch: 13 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6063649354464958		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 0.6063649354464958 | validation: 0.41156590731030634]
	TIME [epoch: 13.1 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4244522622737689		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 0.4244522622737689 | validation: 0.34364492679447106]
	TIME [epoch: 13 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7149174224424052		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.7149174224424052 | validation: 0.5343721882176129]
	TIME [epoch: 13 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6735685673144538		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 0.6735685673144538 | validation: 0.36111823031398926]
	TIME [epoch: 13 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3862611769334708		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 0.3862611769334708 | validation: 0.6864483812888404]
	TIME [epoch: 13.1 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5524474832715864		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 0.5524474832715864 | validation: 0.6284196973904582]
	TIME [epoch: 13.1 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7637497171725054		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 0.7637497171725054 | validation: 0.9342302644934666]
	TIME [epoch: 13 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5373595322401103		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.5373595322401103 | validation: 0.5152120920803711]
	TIME [epoch: 13.1 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4503429215480595		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 0.4503429215480595 | validation: 0.36722131668457375]
	TIME [epoch: 13 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3731762930658046		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 0.3731762930658046 | validation: 0.2853719501311861]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_127.pth
	Model improved!!!
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36742120169145354		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 0.36742120169145354 | validation: 0.3146549092572713]
	TIME [epoch: 13.1 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6364703919455201		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 0.6364703919455201 | validation: 0.5636903622338598]
	TIME [epoch: 13.1 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43242753608938006		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.43242753608938006 | validation: 0.41632781276728187]
	TIME [epoch: 13 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42317849799175977		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 0.42317849799175977 | validation: 0.31619663886675226]
	TIME [epoch: 13.1 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37003500743986434		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 0.37003500743986434 | validation: 0.4105859597614506]
	TIME [epoch: 13.1 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3570366576738681		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 0.3570366576738681 | validation: 0.3527874708310661]
	TIME [epoch: 13 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3893141203048384		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.3893141203048384 | validation: 0.30649532743225877]
	TIME [epoch: 13 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5128296748561153		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.5128296748561153 | validation: 0.6287927254495455]
	TIME [epoch: 13 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45507048317528315		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.45507048317528315 | validation: 0.6884598309861576]
	TIME [epoch: 13 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5131799861422754		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 0.5131799861422754 | validation: 0.3084105652374563]
	TIME [epoch: 13 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3950552075555547		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 0.3950552075555547 | validation: 0.4079200438693076]
	TIME [epoch: 13 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6235465574495387		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 0.6235465574495387 | validation: 0.608383315316949]
	TIME [epoch: 13 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45368844641336414		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.45368844641336414 | validation: 0.28182638073900196]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_140.pth
	Model improved!!!
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38055586681127884		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 0.38055586681127884 | validation: 0.42028717123625764]
	TIME [epoch: 13 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5105959232019088		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.5105959232019088 | validation: 0.49332114559085993]
	TIME [epoch: 13 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4574640374912964		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.4574640374912964 | validation: 0.3271983505764986]
	TIME [epoch: 13.1 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.629377716145228		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 0.629377716145228 | validation: 0.3808914253458462]
	TIME [epoch: 13 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39120694464876615		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.39120694464876615 | validation: 0.37913205959045615]
	TIME [epoch: 13 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4345615878332833		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.4345615878332833 | validation: 0.5665229523331147]
	TIME [epoch: 13.1 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5328292517890894		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.5328292517890894 | validation: 0.39959315092025693]
	TIME [epoch: 13.1 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4465806262826373		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 0.4465806262826373 | validation: 0.36757409778202305]
	TIME [epoch: 13 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36136092017091515		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.36136092017091515 | validation: 0.3770917022436553]
	TIME [epoch: 13.1 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45393194531336195		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.45393194531336195 | validation: 0.8554844788051236]
	TIME [epoch: 13.1 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5273908453498815		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.5273908453498815 | validation: 0.30928200336404404]
	TIME [epoch: 13 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3889243674887618		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.3889243674887618 | validation: 0.3705143542443568]
	TIME [epoch: 13 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4267839635304793		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 0.4267839635304793 | validation: 0.35115994369648207]
	TIME [epoch: 13.1 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49995633068443535		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.49995633068443535 | validation: 0.40638718512149047]
	TIME [epoch: 13.1 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44878379393691403		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.44878379393691403 | validation: 0.33389918223814036]
	TIME [epoch: 13 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42424013477206934		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 0.42424013477206934 | validation: 0.5406037307271039]
	TIME [epoch: 13 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7583507786439498		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 0.7583507786439498 | validation: 0.6609226711532321]
	TIME [epoch: 13.1 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.541025386087572		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 0.541025386087572 | validation: 0.3468938183552083]
	TIME [epoch: 13 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41075397858708096		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.41075397858708096 | validation: 0.38142246870227736]
	TIME [epoch: 13.1 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39670697455946063		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.39670697455946063 | validation: 0.44091614543513274]
	TIME [epoch: 13 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46757205657734524		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.46757205657734524 | validation: 0.40478674885669125]
	TIME [epoch: 13.1 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5399236487755952		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.5399236487755952 | validation: 0.46081668658555247]
	TIME [epoch: 13 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40745280458289307		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.40745280458289307 | validation: 0.3189158835899845]
	TIME [epoch: 13 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36706132728687785		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.36706132728687785 | validation: 0.3346492174940162]
	TIME [epoch: 13.1 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3913948675912835		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.3913948675912835 | validation: 0.33717499302226017]
	TIME [epoch: 13 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3532490494045999		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 0.3532490494045999 | validation: 0.4054403934327456]
	TIME [epoch: 13 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47788160835000953		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 0.47788160835000953 | validation: 0.4254236797365512]
	TIME [epoch: 13 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4467704846501821		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.4467704846501821 | validation: 0.44204027671940294]
	TIME [epoch: 13.1 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4224669619783433		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.4224669619783433 | validation: 0.33008772428603494]
	TIME [epoch: 13 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3577596773021224		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.3577596773021224 | validation: 0.35066328727134244]
	TIME [epoch: 13 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5111467285226763		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.5111467285226763 | validation: 0.6546966295180436]
	TIME [epoch: 13.1 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5991395810654458		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.5991395810654458 | validation: 0.36943246798673557]
	TIME [epoch: 13 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37855262307577214		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.37855262307577214 | validation: 0.4852106361055652]
	TIME [epoch: 13 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40027822126445994		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.40027822126445994 | validation: 0.304418938506762]
	TIME [epoch: 13 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36503651888369015		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.36503651888369015 | validation: 0.3387080582855259]
	TIME [epoch: 13.1 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3101599107264823		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 0.3101599107264823 | validation: 0.29735360064413213]
	TIME [epoch: 13 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4362813489540436		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.4362813489540436 | validation: 0.528822261268349]
	TIME [epoch: 13 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4446264531639469		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.4446264531639469 | validation: 0.376302549141477]
	TIME [epoch: 13.1 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40086733232041394		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.40086733232041394 | validation: 0.24791955402434618]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_179.pth
	Model improved!!!
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2951772525166929		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.2951772525166929 | validation: 0.3837800929342067]
	TIME [epoch: 13 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36571343839646303		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.36571343839646303 | validation: 0.37883161598018894]
	TIME [epoch: 13 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31974631098281736		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.31974631098281736 | validation: 0.27839087739937585]
	TIME [epoch: 13 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29935940039073694		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.29935940039073694 | validation: 0.2568816501391368]
	TIME [epoch: 13 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4905768799926397		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.4905768799926397 | validation: 0.6220304465201916]
	TIME [epoch: 13 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3934327449625132		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.3934327449625132 | validation: 0.8873698608133048]
	TIME [epoch: 13 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5394380436537504		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.5394380436537504 | validation: 0.325988534578824]
	TIME [epoch: 13 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.376884211831243		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.376884211831243 | validation: 0.29738703065568745]
	TIME [epoch: 13 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30901145461159985		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.30901145461159985 | validation: 1.100901809462613]
	TIME [epoch: 13 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.579139507409363		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.579139507409363 | validation: 0.467393088765224]
	TIME [epoch: 13.1 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4043343455350978		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.4043343455350978 | validation: 0.3325497170078988]
	TIME [epoch: 13 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31723396006479787		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.31723396006479787 | validation: 0.23661837693934773]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_191.pth
	Model improved!!!
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3436437017463574		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.3436437017463574 | validation: 0.36071737861778647]
	TIME [epoch: 13.1 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3031651185444768		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.3031651185444768 | validation: 0.26602358056141123]
	TIME [epoch: 13 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26760518683118817		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.26760518683118817 | validation: 0.29633712849653476]
	TIME [epoch: 13 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4006439813002552		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.4006439813002552 | validation: 0.3198688184383802]
	TIME [epoch: 13 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34696118015003186		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.34696118015003186 | validation: 0.2705031325414971]
	TIME [epoch: 13.1 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3702784472251718		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.3702784472251718 | validation: 0.30223619431319454]
	TIME [epoch: 13 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29876253428525396		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.29876253428525396 | validation: 0.2578591709008382]
	TIME [epoch: 13 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30429084694736		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.30429084694736 | validation: 0.24815241981485395]
	TIME [epoch: 13.1 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3521197660118294		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.3521197660118294 | validation: 0.4131571267764318]
	TIME [epoch: 13 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2904059530541137		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.2904059530541137 | validation: 0.3113463222598286]
	TIME [epoch: 13 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3848562789292036		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.3848562789292036 | validation: 0.4481585471563738]
	TIME [epoch: 13 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4486383026863279		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.4486383026863279 | validation: 0.283621203612846]
	TIME [epoch: 13 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31070143938578904		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.31070143938578904 | validation: 0.4424484241701252]
	TIME [epoch: 13 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3462273479468421		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.3462273479468421 | validation: 0.2945092455426239]
	TIME [epoch: 13 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34621303927252955		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.34621303927252955 | validation: 0.26860875760992925]
	TIME [epoch: 13 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28384643699856776		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.28384643699856776 | validation: 0.4223239121897693]
	TIME [epoch: 13.1 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47213628921113215		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.47213628921113215 | validation: 0.6628434925326278]
	TIME [epoch: 13 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41096264375233904		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.41096264375233904 | validation: 0.43525829829341617]
	TIME [epoch: 13 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38190886064930474		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.38190886064930474 | validation: 0.26720569492202734]
	TIME [epoch: 13.1 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4153392937826109		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.4153392937826109 | validation: 0.3652927678649043]
	TIME [epoch: 13 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3692603014796428		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.3692603014796428 | validation: 0.292698624861175]
	TIME [epoch: 13 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3161020741643664		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.3161020741643664 | validation: 0.3242437822254124]
	TIME [epoch: 13 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.348527284582244		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.348527284582244 | validation: 0.37378625817405353]
	TIME [epoch: 13.1 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3100205755916882		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.3100205755916882 | validation: 0.26756780929811724]
	TIME [epoch: 13 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32134202657180755		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.32134202657180755 | validation: 0.27419085617420574]
	TIME [epoch: 13 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3482236591073514		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.3482236591073514 | validation: 0.5033741265070008]
	TIME [epoch: 13.1 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39858461489916286		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.39858461489916286 | validation: 0.3333920933244487]
	TIME [epoch: 13 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3696542808384601		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.3696542808384601 | validation: 0.3162923804658791]
	TIME [epoch: 13 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29675087662300154		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.29675087662300154 | validation: 0.365136996118933]
	TIME [epoch: 13 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3210030847833827		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.3210030847833827 | validation: 0.42907893604660163]
	TIME [epoch: 13.1 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3958978533270131		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.3958978533270131 | validation: 0.33128568518270085]
	TIME [epoch: 13 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35166471386416		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.35166471386416 | validation: 0.45451386509182734]
	TIME [epoch: 13 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.462060277456708		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.462060277456708 | validation: 0.4058304523047758]
	TIME [epoch: 13.1 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46371043977960263		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.46371043977960263 | validation: 0.3101783941639934]
	TIME [epoch: 13 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3927729675136196		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.3927729675136196 | validation: 0.4206299468994055]
	TIME [epoch: 13 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4122302947389287		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.4122302947389287 | validation: 0.6037999152095195]
	TIME [epoch: 13 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46682110912924285		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.46682110912924285 | validation: 0.30492301865598587]
	TIME [epoch: 13.1 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3401559672382945		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.3401559672382945 | validation: 0.2714055188733179]
	TIME [epoch: 13 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2853384482157857		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.2853384482157857 | validation: 0.46382792054946004]
	TIME [epoch: 13 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3206161936074497		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.3206161936074497 | validation: 0.4026170830221773]
	TIME [epoch: 13.1 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34355149221251		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.34355149221251 | validation: 0.41103603065033223]
	TIME [epoch: 13 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32242772421644594		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.32242772421644594 | validation: 0.3299771881280838]
	TIME [epoch: 13 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3642687691568713		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.3642687691568713 | validation: 0.37153049360052065]
	TIME [epoch: 13 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3056008625921934		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.3056008625921934 | validation: 0.4110480300029438]
	TIME [epoch: 13.1 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36227470990647		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.36227470990647 | validation: 0.2847813202814977]
	TIME [epoch: 13 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2779064065215176		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.2779064065215176 | validation: 0.2689457800774326]
	TIME [epoch: 13 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3123415663857969		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.3123415663857969 | validation: 0.4764790675012678]
	TIME [epoch: 13.1 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3687832640805263		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.3687832640805263 | validation: 0.3496839849305459]
	TIME [epoch: 13 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3224588686937293		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.3224588686937293 | validation: 0.243178262995257]
	TIME [epoch: 13 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32504268158760347		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.32504268158760347 | validation: 0.45577643557997627]
	TIME [epoch: 13 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36748727982143276		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.36748727982143276 | validation: 0.22442953131994514]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_242.pth
	Model improved!!!
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25705857558653117		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.25705857558653117 | validation: 0.2771540300795611]
	TIME [epoch: 13 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32143984602513404		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.32143984602513404 | validation: 0.3602263588115534]
	TIME [epoch: 13 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3185834195563184		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.3185834195563184 | validation: 0.20413024657723874]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_245.pth
	Model improved!!!
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2767482200243519		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.2767482200243519 | validation: 0.38118245691433317]
	TIME [epoch: 13 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2657651292338417		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.2657651292338417 | validation: 0.39610210622268754]
	TIME [epoch: 13 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.273013162332705		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.273013162332705 | validation: 0.2958422155817952]
	TIME [epoch: 13 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30988845403271437		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.30988845403271437 | validation: 0.26411434583782833]
	TIME [epoch: 13.1 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37600840571328714		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.37600840571328714 | validation: 0.20053153027871126]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_250.pth
	Model improved!!!
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2392197123134556		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.2392197123134556 | validation: 0.32705340197499594]
	TIME [epoch: 13 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45305586755634		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.45305586755634 | validation: 0.2455831619045756]
	TIME [epoch: 13.1 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2575893103011472		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.2575893103011472 | validation: 0.24683277456573657]
	TIME [epoch: 13.1 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2650425875894543		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.2650425875894543 | validation: 0.3845907135734805]
	TIME [epoch: 13 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3099718411059025		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.3099718411059025 | validation: 0.24316923037363372]
	TIME [epoch: 13 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27076597420393655		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.27076597420393655 | validation: 0.36336279046259834]
	TIME [epoch: 13.1 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29591538638486753		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.29591538638486753 | validation: 0.2945645992894329]
	TIME [epoch: 13.1 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.293510868464804		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.293510868464804 | validation: 0.2338472169618165]
	TIME [epoch: 13.1 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27933037289750384		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.27933037289750384 | validation: 0.27824179680659167]
	TIME [epoch: 13 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27009481834258325		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.27009481834258325 | validation: 0.41262181325365915]
	TIME [epoch: 13.1 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.343097138121074		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.343097138121074 | validation: 0.3699804445534917]
	TIME [epoch: 13.1 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32353972822708527		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.32353972822708527 | validation: 0.21439018590006206]
	TIME [epoch: 13 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.358647422827848		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.358647422827848 | validation: 0.3292867206045318]
	TIME [epoch: 13.1 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30906962556701206		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.30906962556701206 | validation: 0.2525469313889986]
	TIME [epoch: 13 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28990572384639773		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.28990572384639773 | validation: 0.4184657300850789]
	TIME [epoch: 13 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35274678508049795		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.35274678508049795 | validation: 1.1466320067633153]
	TIME [epoch: 13 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6135312758850058		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.6135312758850058 | validation: 0.4512867667438911]
	TIME [epoch: 13.1 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36713821756466114		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.36713821756466114 | validation: 0.3865972185739895]
	TIME [epoch: 13.1 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3460724414848633		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.3460724414848633 | validation: 0.31545549952352764]
	TIME [epoch: 13 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4467967790912343		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.4467967790912343 | validation: 0.4030470993717451]
	TIME [epoch: 13.1 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3687956643151815		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.3687956643151815 | validation: 0.43102913436724316]
	TIME [epoch: 13 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4094342738315471		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.4094342738315471 | validation: 0.5682277087812598]
	TIME [epoch: 13 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4356186403284721		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.4356186403284721 | validation: 0.429329635511717]
	TIME [epoch: 13 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3468834362813884		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.3468834362813884 | validation: 0.290354564362185]
	TIME [epoch: 13.1 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28179274523400105		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.28179274523400105 | validation: 0.28919409188004336]
	TIME [epoch: 13 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26850877123149014		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.26850877123149014 | validation: 0.3421929628947055]
	TIME [epoch: 13 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31365729927154		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.31365729927154 | validation: 0.3115747522647863]
	TIME [epoch: 13.1 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32212385038818775		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.32212385038818775 | validation: 0.6420045694731847]
	TIME [epoch: 13.1 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3514789924270345		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.3514789924270345 | validation: 0.29530360724667803]
	TIME [epoch: 13 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2533340200450051		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.2533340200450051 | validation: 0.24154082316752937]
	TIME [epoch: 13 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24865334008209133		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.24865334008209133 | validation: 0.2694165809928565]
	TIME [epoch: 13.1 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24696951110720644		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.24696951110720644 | validation: 0.23177117720830404]
	TIME [epoch: 13.1 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31358462961224165		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.31358462961224165 | validation: 0.40663676751926303]
	TIME [epoch: 13 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33389801103129657		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.33389801103129657 | validation: 0.26120740211901694]
	TIME [epoch: 13.1 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2522624540602103		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.2522624540602103 | validation: 0.2516675393903921]
	TIME [epoch: 13.1 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31353492325337307		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.31353492325337307 | validation: 0.2134584744641878]
	TIME [epoch: 13 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28270837803988547		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.28270837803988547 | validation: 0.22227364767393568]
	TIME [epoch: 13 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2750688098776568		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.2750688098776568 | validation: 0.2805387199556135]
	TIME [epoch: 13.1 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24899138798201406		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.24899138798201406 | validation: 0.2570337089924556]
	TIME [epoch: 13 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23688101404859452		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.23688101404859452 | validation: 0.2331738681191028]
	TIME [epoch: 13.1 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2993228898753618		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.2993228898753618 | validation: 0.251152171946367]
	TIME [epoch: 13.1 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.271373842218286		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.271373842218286 | validation: 0.3039424924828112]
	TIME [epoch: 13.1 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28612524117499044		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.28612524117499044 | validation: 0.29140822765029945]
	TIME [epoch: 13.1 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26665755473531483		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.26665755473531483 | validation: 0.3169028037493428]
	TIME [epoch: 13.1 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25253379952993327		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.25253379952993327 | validation: 0.24196079638663812]
	TIME [epoch: 13.1 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5124224142060287		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.5124224142060287 | validation: 0.33898568498983755]
	TIME [epoch: 13.1 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2839184864504102		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.2839184864504102 | validation: 0.2877838744863744]
	TIME [epoch: 13 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2720563339911927		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.2720563339911927 | validation: 0.24507395493243775]
	TIME [epoch: 13.1 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24025570449517972		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.24025570449517972 | validation: 0.276411658322297]
	TIME [epoch: 13.1 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34068034899654465		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.34068034899654465 | validation: 0.25795541006174494]
	TIME [epoch: 13 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2909295668834768		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.2909295668834768 | validation: 0.2328637091445861]
	TIME [epoch: 13 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27757358769562646		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.27757358769562646 | validation: 0.40787342801204884]
	TIME [epoch: 13.1 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.285317766934422		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.285317766934422 | validation: 0.2875746866518187]
	TIME [epoch: 13 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3666478141279514		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.3666478141279514 | validation: 0.3298961764254119]
	TIME [epoch: 13 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26801892345468536		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.26801892345468536 | validation: 0.29145356850237447]
	TIME [epoch: 13 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28149915608841036		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.28149915608841036 | validation: 0.25952520287645514]
	TIME [epoch: 13.1 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24492413043393751		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.24492413043393751 | validation: 0.31888731432532375]
	TIME [epoch: 13.1 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3733061522190152		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.3733061522190152 | validation: 0.24920333714163803]
	TIME [epoch: 13 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33237245923158143		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.33237245923158143 | validation: 0.28638464662469004]
	TIME [epoch: 13.1 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2468329625839775		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.2468329625839775 | validation: 0.2714018196593028]
	TIME [epoch: 13 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22971491675739064		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.22971491675739064 | validation: 0.2505163877514932]
	TIME [epoch: 13 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2661466949776724		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.2661466949776724 | validation: 0.20420858357443727]
	TIME [epoch: 13 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22633185931009506		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.22633185931009506 | validation: 0.225091170326425]
	TIME [epoch: 13.1 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3083693776531359		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.3083693776531359 | validation: 0.20459111960178078]
	TIME [epoch: 13 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24378345800823908		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.24378345800823908 | validation: 0.24052579055409273]
	TIME [epoch: 13 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25709816840462874		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.25709816840462874 | validation: 0.21174330371678346]
	TIME [epoch: 13.1 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21843565865562245		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.21843565865562245 | validation: 0.2737485611903594]
	TIME [epoch: 13 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3224919868956483		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.3224919868956483 | validation: 0.25098574584925226]
	TIME [epoch: 13.1 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23931069940323924		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.23931069940323924 | validation: 0.1985238730357812]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_319.pth
	Model improved!!!
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2739707515992966		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.2739707515992966 | validation: 0.23027087961438308]
	TIME [epoch: 13.1 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22261173187967184		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.22261173187967184 | validation: 0.21064441723856675]
	TIME [epoch: 13 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2167464541942283		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.2167464541942283 | validation: 0.2788104661518584]
	TIME [epoch: 13.1 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26031672841172837		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.26031672841172837 | validation: 0.2926448126900996]
	TIME [epoch: 13.1 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27249700577167957		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.27249700577167957 | validation: 0.2546281764032563]
	TIME [epoch: 13.1 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47426157318439977		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.47426157318439977 | validation: 0.9011629122545578]
	TIME [epoch: 13.1 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5561705228915874		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.5561705228915874 | validation: 0.34107620627205676]
	TIME [epoch: 13.1 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43632011210168387		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.43632011210168387 | validation: 0.3108691277488569]
	TIME [epoch: 13.1 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24196794827515816		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.24196794827515816 | validation: 0.2315895079641631]
	TIME [epoch: 13.1 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.256793409724555		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.256793409724555 | validation: 0.22633291966062213]
	TIME [epoch: 13 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2398274241593491		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.2398274241593491 | validation: 0.274547218685814]
	TIME [epoch: 13.1 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24514889402847292		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.24514889402847292 | validation: 0.2095569856098824]
	TIME [epoch: 13.1 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24206557763521888		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.24206557763521888 | validation: 0.2808464356819599]
	TIME [epoch: 13.1 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.297241068573871		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.297241068573871 | validation: 0.3303656081304752]
	TIME [epoch: 13 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26094395782652924		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.26094395782652924 | validation: 0.3028810593283638]
	TIME [epoch: 13.1 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4752107473057659		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.4752107473057659 | validation: 0.4691221107737064]
	TIME [epoch: 13 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34386758086975183		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.34386758086975183 | validation: 0.31349548898314683]
	TIME [epoch: 13 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29715594723744215		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.29715594723744215 | validation: 0.22095811628041456]
	TIME [epoch: 13.1 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24026387364985294		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.24026387364985294 | validation: 0.27722030318693897]
	TIME [epoch: 13.1 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23229879150711816		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.23229879150711816 | validation: 0.27812489765685894]
	TIME [epoch: 13 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2471681524709039		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.2471681524709039 | validation: 0.24786908649093428]
	TIME [epoch: 13 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22202957571455398		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.22202957571455398 | validation: 0.21852297407316643]
	TIME [epoch: 13.1 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22779887984980898		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.22779887984980898 | validation: 0.16681565345494967]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_342.pth
	Model improved!!!
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21092230693918973		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.21092230693918973 | validation: 0.26224250685567735]
	TIME [epoch: 13 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24180866587688615		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.24180866587688615 | validation: 0.24597697488945938]
	TIME [epoch: 13.1 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3206522585747983		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.3206522585747983 | validation: 0.30665922162615816]
	TIME [epoch: 13 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24404923328304318		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.24404923328304318 | validation: 0.24673737379029717]
	TIME [epoch: 13 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2426437951429659		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.2426437951429659 | validation: 0.20427974888143424]
	TIME [epoch: 13 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23586057663164645		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.23586057663164645 | validation: 0.23532571338126587]
	TIME [epoch: 13.1 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3307479588406271		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.3307479588406271 | validation: 0.19275293703407903]
	TIME [epoch: 13.1 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21393580909869264		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.21393580909869264 | validation: 0.21729902629000453]
	TIME [epoch: 13 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2377191270765025		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.2377191270765025 | validation: 0.2966383870269649]
	TIME [epoch: 13.1 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2936560139651553		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.2936560139651553 | validation: 0.24963124429098393]
	TIME [epoch: 13.1 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25404250614010526		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.25404250614010526 | validation: 0.1940126970846527]
	TIME [epoch: 13 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2704537282893848		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.2704537282893848 | validation: 0.18274517777347973]
	TIME [epoch: 13 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2024669608428645		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.2024669608428645 | validation: 0.24144375687049938]
	TIME [epoch: 13.1 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20767130959197858		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.20767130959197858 | validation: 0.22602865824227597]
	TIME [epoch: 13 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2192161971916909		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.2192161971916909 | validation: 0.22496894080575713]
	TIME [epoch: 13 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20793462374709537		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.20793462374709537 | validation: 0.306819642742622]
	TIME [epoch: 13 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.259186599238634		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.259186599238634 | validation: 0.26419337428211953]
	TIME [epoch: 13.1 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20398513948295996		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.20398513948295996 | validation: 0.3722446716077179]
	TIME [epoch: 13 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2337854795558117		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.2337854795558117 | validation: 0.24442033076401268]
	TIME [epoch: 13 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22362549430710474		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.22362549430710474 | validation: 0.22644738575669224]
	TIME [epoch: 13.1 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2164352555032093		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.2164352555032093 | validation: 0.22610836327484343]
	TIME [epoch: 13 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20189249028691633		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.20189249028691633 | validation: 0.19231361317037277]
	TIME [epoch: 13 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2373335079702552		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.2373335079702552 | validation: 0.3243236881493261]
	TIME [epoch: 13 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2596478429223963		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.2596478429223963 | validation: 0.43382068976842547]
	TIME [epoch: 13.1 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3173166133349458		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.3173166133349458 | validation: 0.37398372509748457]
	TIME [epoch: 13 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3296457545194319		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.3296457545194319 | validation: 0.33704264998528344]
	TIME [epoch: 13.1 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3633288744126065		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.3633288744126065 | validation: 0.2886035725649571]
	TIME [epoch: 13.1 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3498131825489689		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.3498131825489689 | validation: 0.6261607187586564]
	TIME [epoch: 13 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4078534189345543		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.4078534189345543 | validation: 0.33021204660791753]
	TIME [epoch: 13 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2709939216674405		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.2709939216674405 | validation: 0.27553715902775616]
	TIME [epoch: 13 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25414801614281046		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.25414801614281046 | validation: 0.23974870976178367]
	TIME [epoch: 13.1 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2364830756559831		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.2364830756559831 | validation: 0.8711544059862192]
	TIME [epoch: 13.1 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6184717048241528		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.6184717048241528 | validation: 0.3044555018864289]
	TIME [epoch: 13 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3160513638795612		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.3160513638795612 | validation: 0.3536521928137477]
	TIME [epoch: 13.1 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.283173232584461		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.283173232584461 | validation: 0.29224378407277607]
	TIME [epoch: 13 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27395160065859653		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.27395160065859653 | validation: 0.23931444875511332]
	TIME [epoch: 13 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24632492467722908		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.24632492467722908 | validation: 0.35242818154048766]
	TIME [epoch: 13 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2766889109622559		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.2766889109622559 | validation: 0.2802283769523063]
	TIME [epoch: 13.1 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36646422612113283		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.36646422612113283 | validation: 0.2581334011468772]
	TIME [epoch: 13.1 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29447456696177365		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.29447456696177365 | validation: 0.3810551252659971]
	TIME [epoch: 13 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28198325265852847		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.28198325265852847 | validation: 0.5374000811880518]
	TIME [epoch: 13.1 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4581358696780876		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.4581358696780876 | validation: 0.2724457484491952]
	TIME [epoch: 13 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2747485766516456		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.2747485766516456 | validation: 0.31789319824162177]
	TIME [epoch: 13.1 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2876538530222925		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.2876538530222925 | validation: 0.23737829673071822]
	TIME [epoch: 13.1 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2549621465628189		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.2549621465628189 | validation: 0.2763327873844401]
	TIME [epoch: 13.1 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23094455663937305		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.23094455663937305 | validation: 0.20322373598970214]
	TIME [epoch: 13.1 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22835754971061484		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.22835754971061484 | validation: 0.3004679740252263]
	TIME [epoch: 13.1 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2764857160869446		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.2764857160869446 | validation: 0.2968640484305939]
	TIME [epoch: 13.1 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23451440274013033		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.23451440274013033 | validation: 0.25386533126634836]
	TIME [epoch: 13.1 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3416950601050891		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.3416950601050891 | validation: 0.35462956089555275]
	TIME [epoch: 13 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26333605094999635		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.26333605094999635 | validation: 0.2592320224506575]
	TIME [epoch: 13 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2536419113801435		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.2536419113801435 | validation: 0.22938274260105154]
	TIME [epoch: 13.1 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25294968631885645		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.25294968631885645 | validation: 0.2881756503365654]
	TIME [epoch: 13 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4500564073529618		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.4500564073529618 | validation: 0.27440047656266264]
	TIME [epoch: 13 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24636424693177567		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.24636424693177567 | validation: 0.17238085659414984]
	TIME [epoch: 13.1 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2036300698257732		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.2036300698257732 | validation: 0.18913904880116633]
	TIME [epoch: 13.1 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22402145521802075		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.22402145521802075 | validation: 0.2323540603528508]
	TIME [epoch: 13 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20923578401866738		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.20923578401866738 | validation: 0.22676415180235546]
	TIME [epoch: 13 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19072260299948057		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.19072260299948057 | validation: 0.26657551588179795]
	TIME [epoch: 13.1 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2059039423572455		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.2059039423572455 | validation: 0.18679650816582224]
	TIME [epoch: 13 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2013410063714655		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.2013410063714655 | validation: 0.20038174963617203]
	TIME [epoch: 13 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24010559159429698		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.24010559159429698 | validation: 0.196067873219097]
	TIME [epoch: 13 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22851964320681228		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.22851964320681228 | validation: 0.48316943047922745]
	TIME [epoch: 13.1 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2939051551933867		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.2939051551933867 | validation: 0.22174235537654008]
	TIME [epoch: 13 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17695206308680755		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.17695206308680755 | validation: 0.22842819090473807]
	TIME [epoch: 13 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24507920492195123		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.24507920492195123 | validation: 0.18548220534801943]
	TIME [epoch: 13.1 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20630303466473793		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.20630303466473793 | validation: 0.20498614424901582]
	TIME [epoch: 13 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2048911989267467		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.2048911989267467 | validation: 0.18244836930301364]
	TIME [epoch: 13 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19901707197163468		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.19901707197163468 | validation: 0.19266469215362636]
	TIME [epoch: 13 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1790755577423801		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.1790755577423801 | validation: 0.20320004533699343]
	TIME [epoch: 13.1 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20465228973980257		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.20465228973980257 | validation: 0.25141592820660713]
	TIME [epoch: 13 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21719931361164874		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.21719931361164874 | validation: 0.2231911563295288]
	TIME [epoch: 13 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22669461183783557		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.22669461183783557 | validation: 0.277991823732825]
	TIME [epoch: 13.1 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2313759213195005		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.2313759213195005 | validation: 0.29026843137707425]
	TIME [epoch: 13 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24021598783162695		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.24021598783162695 | validation: 0.18227019418127022]
	TIME [epoch: 13 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1857574795922292		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.1857574795922292 | validation: 0.22324331185930235]
	TIME [epoch: 13 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2626584504570069		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.2626584504570069 | validation: 0.23864016503537286]
	TIME [epoch: 13.1 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21515324653951928		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.21515324653951928 | validation: 0.2159243049080006]
	TIME [epoch: 13 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2313418300260754		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.2313418300260754 | validation: 0.19909940948872654]
	TIME [epoch: 13 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22908030875727114		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.22908030875727114 | validation: 0.19361452295414297]
	TIME [epoch: 13.1 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19029348317444567		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.19029348317444567 | validation: 0.26810524102339334]
	TIME [epoch: 13 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21843124274401113		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.21843124274401113 | validation: 0.19699530573010066]
	TIME [epoch: 13 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33405940690949715		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.33405940690949715 | validation: 0.2595632623889295]
	TIME [epoch: 13 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24739391782194683		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.24739391782194683 | validation: 0.304281428758678]
	TIME [epoch: 13.1 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2946770790401022		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.2946770790401022 | validation: 0.16723601031731897]
	TIME [epoch: 13 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17545120731030608		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.17545120731030608 | validation: 0.177099406818362]
	TIME [epoch: 13 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18111978813332183		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.18111978813332183 | validation: 0.16700504944618033]
	TIME [epoch: 13.1 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1752813431612132		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.1752813431612132 | validation: 0.23635452677375873]
	TIME [epoch: 13 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23271628699050462		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.23271628699050462 | validation: 0.3569704322270954]
	TIME [epoch: 13.1 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26208449071251855		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.26208449071251855 | validation: 0.21192695279516172]
	TIME [epoch: 13 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20121728363192692		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.20121728363192692 | validation: 0.15088961469191786]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_433.pth
	Model improved!!!
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20546292105552155		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.20546292105552155 | validation: 0.21046602090096733]
	TIME [epoch: 13.1 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1985036687349524		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.1985036687349524 | validation: 0.19407829795401493]
	TIME [epoch: 13 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20027191037501946		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.20027191037501946 | validation: 0.15009584565379083]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_436.pth
	Model improved!!!
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18102586191851		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.18102586191851 | validation: 0.17938580817332545]
	TIME [epoch: 13 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1729375223290836		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.1729375223290836 | validation: 0.15881442929125175]
	TIME [epoch: 13 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17191098844485553		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.17191098844485553 | validation: 0.1618941965278605]
	TIME [epoch: 13 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20189455381651877		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.20189455381651877 | validation: 0.17957091631316976]
	TIME [epoch: 13.1 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18868568451219753		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.18868568451219753 | validation: 0.15579963198977909]
	TIME [epoch: 13 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17532425046530103		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.17532425046530103 | validation: 0.18444193872570996]
	TIME [epoch: 13 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21488782141659252		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.21488782141659252 | validation: 0.18598042540448462]
	TIME [epoch: 13 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2236022561502653		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.2236022561502653 | validation: 0.3466623753753851]
	TIME [epoch: 13 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28940342142193026		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.28940342142193026 | validation: 0.21035989895989413]
	TIME [epoch: 13 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19368645416484026		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.19368645416484026 | validation: 0.16373841951688456]
	TIME [epoch: 13 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17383186429615477		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.17383186429615477 | validation: 0.17163437226948966]
	TIME [epoch: 13.1 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16518134211778612		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.16518134211778612 | validation: 0.18322254127044604]
	TIME [epoch: 13 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1878012482069062		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.1878012482069062 | validation: 0.265645509159596]
	TIME [epoch: 13 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31591370530596685		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.31591370530596685 | validation: 0.17614035732308836]
	TIME [epoch: 13 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19576816734643562		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.19576816734643562 | validation: 0.1520732769134185]
	TIME [epoch: 13.1 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16798066362621417		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.16798066362621417 | validation: 0.18352314262398658]
	TIME [epoch: 13 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21447940193286907		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.21447940193286907 | validation: 0.259194876754809]
	TIME [epoch: 13 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.231494190025235		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.231494190025235 | validation: 0.30616286877059296]
	TIME [epoch: 13.1 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2728390889906264		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.2728390889906264 | validation: 0.48932692476118234]
	TIME [epoch: 13 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37201063551850083		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.37201063551850083 | validation: 0.18369047848737075]
	TIME [epoch: 13 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17536381810826165		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.17536381810826165 | validation: 0.2997007134772124]
	TIME [epoch: 13 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.247090800966899		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.247090800966899 | validation: 0.269661198437372]
	TIME [epoch: 13.1 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25446880745233136		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.25446880745233136 | validation: 0.2498484115502935]
	TIME [epoch: 13 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20336781308844448		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.20336781308844448 | validation: 0.2120652390539833]
	TIME [epoch: 13 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2273503138110763		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.2273503138110763 | validation: 0.195803180926546]
	TIME [epoch: 13.1 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20519619889473947		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.20519619889473947 | validation: 0.23996391468484443]
	TIME [epoch: 13 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21739425309604604		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.21739425309604604 | validation: 0.24642911661404898]
	TIME [epoch: 13 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.288790813215393		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.288790813215393 | validation: 0.30685772113737847]
	TIME [epoch: 13 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2854861591580755		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.2854861591580755 | validation: 0.24115224486934841]
	TIME [epoch: 13.1 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2384857148185608		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.2384857148185608 | validation: 0.7709995819657002]
	TIME [epoch: 13 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5731053359580915		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.5731053359580915 | validation: 0.25075140273599245]
	TIME [epoch: 13 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23727444566968134		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.23727444566968134 | validation: 0.2410194303493137]
	TIME [epoch: 13.1 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2613272348667858		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.2613272348667858 | validation: 0.2504167532321652]
	TIME [epoch: 13 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2121219230271772		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.2121219230271772 | validation: 0.33745430236730284]
	TIME [epoch: 13 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27987781211234497		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.27987781211234497 | validation: 0.30035565784743207]
	TIME [epoch: 13 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24932269772910165		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.24932269772910165 | validation: 0.1700464893337353]
	TIME [epoch: 13.1 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1774677558002116		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.1774677558002116 | validation: 0.17468739450760631]
	TIME [epoch: 13 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21139092581243507		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.21139092581243507 | validation: 0.22858857720987114]
	TIME [epoch: 13 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32504805115622915		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.32504805115622915 | validation: 0.3335840271775188]
	TIME [epoch: 13.1 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25080962831978126		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.25080962831978126 | validation: 0.25259861710313347]
	TIME [epoch: 13 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2305910306290579		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.2305910306290579 | validation: 0.19955739395633182]
	TIME [epoch: 13 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2474501189397078		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.2474501189397078 | validation: 0.23385032144201334]
	TIME [epoch: 13 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19269506767650796		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.19269506767650796 | validation: 0.15661279467802866]
	TIME [epoch: 13.1 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16371553515592074		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.16371553515592074 | validation: 0.14280419829339713]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_480.pth
	Model improved!!!
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15513984162962233		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.15513984162962233 | validation: 0.2187408804847441]
	TIME [epoch: 13 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15740089430642307		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.15740089430642307 | validation: 0.16537064531955153]
	TIME [epoch: 13.1 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1828464915773076		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.1828464915773076 | validation: 0.12922017810975833]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_483.pth
	Model improved!!!
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2471458716081443		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.2471458716081443 | validation: 0.45895820492308476]
	TIME [epoch: 13 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29837723389895365		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.29837723389895365 | validation: 0.3217120849495415]
	TIME [epoch: 13 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2192986969492038		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.2192986969492038 | validation: 0.20138894804158028]
	TIME [epoch: 13.1 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23800924138341514		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.23800924138341514 | validation: 0.19585659419342885]
	TIME [epoch: 13.1 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1776178846080898		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.1776178846080898 | validation: 0.16378198677290903]
	TIME [epoch: 13.1 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15979326620559314		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.15979326620559314 | validation: 0.23361142802057824]
	TIME [epoch: 13.1 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23183330327254442		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.23183330327254442 | validation: 0.18541750923570027]
	TIME [epoch: 13.1 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16783419807148706		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.16783419807148706 | validation: 0.13108743989473515]
	TIME [epoch: 13.1 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1597246038918038		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.1597246038918038 | validation: 0.1634213683726221]
	TIME [epoch: 13.1 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19441339529264984		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.19441339529264984 | validation: 0.1608777598564462]
	TIME [epoch: 13.1 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16299955275863007		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.16299955275863007 | validation: 0.1346578815201795]
	TIME [epoch: 13.1 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14587985874700182		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.14587985874700182 | validation: 0.2287889452895983]
	TIME [epoch: 13.1 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1853279343809931		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.1853279343809931 | validation: 0.1645484285407983]
	TIME [epoch: 13.1 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1964668559308078		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.1964668559308078 | validation: 0.2528108048881925]
	TIME [epoch: 13.1 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23302269490060828		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.23302269490060828 | validation: 0.18263453895401455]
	TIME [epoch: 13.1 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1483555547271254		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.1483555547271254 | validation: 0.13347826145103764]
	TIME [epoch: 13.1 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1559473787718374		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.1559473787718374 | validation: 0.1376214276815719]
	TIME [epoch: 13.1 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15419388078899748		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.15419388078899748 | validation: 0.20240534439466146]
	TIME [epoch: 13.1 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18775066462869502		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.18775066462869502 | validation: 0.13997254182648602]
	TIME [epoch: 13.1 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14235036206182466		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.14235036206182466 | validation: 0.1558309046426854]
	TIME [epoch: 13.1 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18492747250375652		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.18492747250375652 | validation: 0.41990975568847794]
	TIME [epoch: 13.1 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23525484586039563		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.23525484586039563 | validation: 0.16406638204848506]
	TIME [epoch: 13 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18443544252297223		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.18443544252297223 | validation: 0.1509808553718791]
	TIME [epoch: 13.1 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14477873617611364		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.14477873617611364 | validation: 0.13707631176783763]
	TIME [epoch: 13.1 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17413316567968296		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.17413316567968296 | validation: 0.31259612500189277]
	TIME [epoch: 13.1 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26712032519909973		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.26712032519909973 | validation: 0.18838365423858988]
	TIME [epoch: 13 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18490926341161182		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.18490926341161182 | validation: 0.1890392080136293]
	TIME [epoch: 13 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1722908743156006		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.1722908743156006 | validation: 0.13992269455270942]
	TIME [epoch: 13.1 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17243632900389363		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.17243632900389363 | validation: 0.1991289095605243]
	TIME [epoch: 13.1 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20137926625021751		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.20137926625021751 | validation: 0.22666615689571998]
	TIME [epoch: 13 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16857556143314684		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.16857556143314684 | validation: 0.151850880791336]
	TIME [epoch: 13.1 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13827299827946624		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.13827299827946624 | validation: 0.15993570064930107]
	TIME [epoch: 13 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15495002903195612		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.15495002903195612 | validation: 0.16703971401188458]
	TIME [epoch: 13 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17404774220991837		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.17404774220991837 | validation: 0.18905518864792065]
	TIME [epoch: 13 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14238713512775308		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.14238713512775308 | validation: 0.18561002820795075]
	TIME [epoch: 13.1 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18772312558708754		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.18772312558708754 | validation: 0.3154652337507723]
	TIME [epoch: 13 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21875236205419551		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.21875236205419551 | validation: 0.1381048600098398]
	TIME [epoch: 13 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.165913567522055		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.165913567522055 | validation: 0.13105856253484213]
	TIME [epoch: 13.1 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1603062168316342		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.1603062168316342 | validation: 0.22749272409021992]
	TIME [epoch: 13 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24801777163651773		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.24801777163651773 | validation: 0.18036503801432294]
	TIME [epoch: 13 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16054585054906717		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.16054585054906717 | validation: 0.1660866514668743]
	TIME [epoch: 13 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18052592979748527		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.18052592979748527 | validation: 0.16553075961152908]
	TIME [epoch: 13.1 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1590290443349513		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.1590290443349513 | validation: 0.1909166039844744]
	TIME [epoch: 13 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16989660620388794		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.16989660620388794 | validation: 0.1333417517302348]
	TIME [epoch: 13 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15659515423922588		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.15659515423922588 | validation: 0.12894551823177228]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_528.pth
	Model improved!!!
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13270851860257218		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.13270851860257218 | validation: 0.14220736208210275]
	TIME [epoch: 13 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30892509932686996		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.30892509932686996 | validation: 0.3590560933791892]
	TIME [epoch: 13 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25864769294166023		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.25864769294166023 | validation: 0.19746246262103412]
	TIME [epoch: 13 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23864975205114794		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.23864975205114794 | validation: 0.21102915277631773]
	TIME [epoch: 13.1 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18034435334210144		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.18034435334210144 | validation: 0.16269308078310538]
	TIME [epoch: 13 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18833172294297373		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.18833172294297373 | validation: 0.23816582854107238]
	TIME [epoch: 13 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23322620731534194		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.23322620731534194 | validation: 0.17961286671614232]
	TIME [epoch: 13.1 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1855084670410045		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.1855084670410045 | validation: 0.15176464820985142]
	TIME [epoch: 13 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16741608433626445		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.16741608433626445 | validation: 0.16686704306964273]
	TIME [epoch: 13 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1617034066849734		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.1617034066849734 | validation: 0.18531520796239828]
	TIME [epoch: 13 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2733938823593146		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.2733938823593146 | validation: 0.2425381379034213]
	TIME [epoch: 13.1 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17884043420425644		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.17884043420425644 | validation: 0.17104938877707235]
	TIME [epoch: 13 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1581419695986427		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.1581419695986427 | validation: 0.17795282571405005]
	TIME [epoch: 13 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16615363751928613		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.16615363751928613 | validation: 0.16657623878882066]
	TIME [epoch: 13.1 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17175880654160547		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.17175880654160547 | validation: 0.12525367314912378]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_543.pth
	Model improved!!!
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1294586961669689		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.1294586961669689 | validation: 0.1369080017816999]
	TIME [epoch: 13 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15999329344097546		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.15999329344097546 | validation: 0.1505120850512262]
	TIME [epoch: 13 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18862934626837827		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.18862934626837827 | validation: 0.23645155278663338]
	TIME [epoch: 13.1 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19428555651105484		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.19428555651105484 | validation: 0.1298881860884818]
	TIME [epoch: 13 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15857982698763498		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.15857982698763498 | validation: 0.241500188369044]
	TIME [epoch: 13 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25221709764365774		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.25221709764365774 | validation: 0.2403914474883919]
	TIME [epoch: 13.1 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2148179083469888		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.2148179083469888 | validation: 0.20214171684015475]
	TIME [epoch: 13 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18932719013541605		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.18932719013541605 | validation: 0.2037063835003498]
	TIME [epoch: 13 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20395650090206266		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.20395650090206266 | validation: 0.22823466701088074]
	TIME [epoch: 13 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20945818642668465		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.20945818642668465 | validation: 0.17230358797203696]
	TIME [epoch: 13.1 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17020972810109727		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.17020972810109727 | validation: 0.12450894943775791]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_554.pth
	Model improved!!!
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12326971387474875		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.12326971387474875 | validation: 0.12134747040669837]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_555.pth
	Model improved!!!
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13527228995181478		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.13527228995181478 | validation: 0.1714040472224361]
	TIME [epoch: 13.1 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16519255129015392		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.16519255129015392 | validation: 0.19206717014909416]
	TIME [epoch: 13.1 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16919076195936422		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.16919076195936422 | validation: 0.1364798064328523]
	TIME [epoch: 13 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1567598274166248		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.1567598274166248 | validation: 0.2161153204243419]
	TIME [epoch: 13 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22594696207609666		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.22594696207609666 | validation: 0.1956871139042936]
	TIME [epoch: 13.1 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1834422064357773		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.1834422064357773 | validation: 0.16928551484474547]
	TIME [epoch: 13 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1816519561684587		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.1816519561684587 | validation: 0.12571852055860455]
	TIME [epoch: 13 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15321341815640163		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.15321341815640163 | validation: 0.15771602518692462]
	TIME [epoch: 13.1 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14827726865324628		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.14827726865324628 | validation: 0.14546633489746286]
	TIME [epoch: 13.1 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18388502115902905		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.18388502115902905 | validation: 0.2500585491019092]
	TIME [epoch: 13 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17180748025643486		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.17180748025643486 | validation: 0.1294264151181514]
	TIME [epoch: 13 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14089688585739957		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.14089688585739957 | validation: 0.16821746425616246]
	TIME [epoch: 13.1 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15312667840178462		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.15312667840178462 | validation: 0.13186126336906268]
	TIME [epoch: 13 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13479420014056592		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.13479420014056592 | validation: 0.1544242182735935]
	TIME [epoch: 13 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12777255190170017		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.12777255190170017 | validation: 0.1340056340822524]
	TIME [epoch: 13.1 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.151461772868404		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.151461772868404 | validation: 0.12540815608129388]
	TIME [epoch: 13.1 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.192201201064684		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.192201201064684 | validation: 0.17595223547907515]
	TIME [epoch: 13 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1531747849039385		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.1531747849039385 | validation: 0.1287543245096613]
	TIME [epoch: 13 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15539115043500032		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.15539115043500032 | validation: 0.15783178412082316]
	TIME [epoch: 13.1 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1522248745272229		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.1522248745272229 | validation: 0.1937059047960549]
	TIME [epoch: 13 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15073196051144644		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.15073196051144644 | validation: 0.14795135092964617]
	TIME [epoch: 13 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1350547851670389		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.1350547851670389 | validation: 0.11506163290896211]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_577.pth
	Model improved!!!
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14188557846233713		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.14188557846233713 | validation: 0.18381827863977535]
	TIME [epoch: 13.1 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14064789880140244		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.14064789880140244 | validation: 0.11769378968758618]
	TIME [epoch: 13 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11793955287711524		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.11793955287711524 | validation: 0.1670247407148085]
	TIME [epoch: 13 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19292232642298274		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.19292232642298274 | validation: 0.14444118979950957]
	TIME [epoch: 13.1 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19969780496576006		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.19969780496576006 | validation: 0.27795308049394335]
	TIME [epoch: 13 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19092549994659913		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.19092549994659913 | validation: 0.1504536662920518]
	TIME [epoch: 13 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19152207591684584		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.19152207591684584 | validation: 0.1965419104261634]
	TIME [epoch: 13 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1493742262175929		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.1493742262175929 | validation: 0.11866169424218422]
	TIME [epoch: 13.1 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.156187480045591		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.156187480045591 | validation: 0.17438106481497306]
	TIME [epoch: 13 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2295546196558132		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.2295546196558132 | validation: 0.2249739639571365]
	TIME [epoch: 13 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24092633157269364		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.24092633157269364 | validation: 0.15554271769955194]
	TIME [epoch: 13 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1416694521742464		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.1416694521742464 | validation: 0.11865842993213464]
	TIME [epoch: 13 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10768941370598978		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.10768941370598978 | validation: 0.20015256060567385]
	TIME [epoch: 13 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15470018628675278		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.15470018628675278 | validation: 0.1537184198829245]
	TIME [epoch: 13 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11228236722203008		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.11228236722203008 | validation: 0.12873804201476538]
	TIME [epoch: 13 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16727417334020026		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.16727417334020026 | validation: 0.11836763939005669]
	TIME [epoch: 13 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11691971339576193		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.11691971339576193 | validation: 0.16187093938582828]
	TIME [epoch: 13 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14449416385104744		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.14449416385104744 | validation: 0.14326681668759558]
	TIME [epoch: 13 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1285647694189343		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.1285647694189343 | validation: 0.09147670422529525]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_596.pth
	Model improved!!!
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10709639246124222		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.10709639246124222 | validation: 0.11242662932920965]
	TIME [epoch: 13 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12034434413858536		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.12034434413858536 | validation: 0.13435520107431181]
	TIME [epoch: 13 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1390870473583854		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.1390870473583854 | validation: 0.1397673128577932]
	TIME [epoch: 13.1 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14900831721741375		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.14900831721741375 | validation: 0.15367810000688287]
	TIME [epoch: 13 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18890178140116984		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.18890178140116984 | validation: 0.2967532540490613]
	TIME [epoch: 13 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23399156793262504		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.23399156793262504 | validation: 0.1530326730888064]
	TIME [epoch: 13.1 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13195759802769536		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.13195759802769536 | validation: 0.11939718351322905]
	TIME [epoch: 13.1 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12619816794754898		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.12619816794754898 | validation: 0.10000893698064914]
	TIME [epoch: 13 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11213649291695536		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.11213649291695536 | validation: 0.2003696042234205]
	TIME [epoch: 13 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1743578232422302		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.1743578232422302 | validation: 0.11323228094557625]
	TIME [epoch: 13.1 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2580167219640767		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.2580167219640767 | validation: 0.35478723759149433]
	TIME [epoch: 13 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24226282308469138		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.24226282308469138 | validation: 0.16409511120636702]
	TIME [epoch: 13 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13965080989694978		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.13965080989694978 | validation: 0.13450722306673776]
	TIME [epoch: 13.1 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14598344615183206		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.14598344615183206 | validation: 0.14037658485506646]
	TIME [epoch: 13.1 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17519180545606516		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.17519180545606516 | validation: 0.12607461803420414]
	TIME [epoch: 13 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12740539776470766		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.12740539776470766 | validation: 0.14758177289891125]
	TIME [epoch: 13 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1303305588699139		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.1303305588699139 | validation: 0.16790226285674195]
	TIME [epoch: 13.1 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2133096523507368		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.2133096523507368 | validation: 0.19436369662147335]
	TIME [epoch: 13 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1626018622648125		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.1626018622648125 | validation: 0.14878229242022775]
	TIME [epoch: 13 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1399692316725747		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.1399692316725747 | validation: 0.10376519035253608]
	TIME [epoch: 13.1 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10338470129979752		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.10338470129979752 | validation: 0.12696388572855719]
	TIME [epoch: 13 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14909140089102557		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.14909140089102557 | validation: 0.12099846263825882]
	TIME [epoch: 13 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12177350499798315		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.12177350499798315 | validation: 0.12935036348014792]
	TIME [epoch: 13 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11669803765842547		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.11669803765842547 | validation: 0.11082173777428433]
	TIME [epoch: 13.1 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16748219856052712		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.16748219856052712 | validation: 0.14112260794030365]
	TIME [epoch: 13 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12306352140507731		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.12306352140507731 | validation: 0.11399743947651969]
	TIME [epoch: 13 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1068780417657671		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.1068780417657671 | validation: 0.11568753796912747]
	TIME [epoch: 13.1 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10718736199268321		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.10718736199268321 | validation: 0.1294436849248017]
	TIME [epoch: 13 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13788533337784725		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.13788533337784725 | validation: 0.17298225054823685]
	TIME [epoch: 13 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1406927011175301		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.1406927011175301 | validation: 0.11552760719004612]
	TIME [epoch: 13 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11660216041164738		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.11660216041164738 | validation: 0.12427748623729108]
	TIME [epoch: 13.1 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11329428602626616		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.11329428602626616 | validation: 0.19263612039052103]
	TIME [epoch: 13 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2827293753817435		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.2827293753817435 | validation: 0.20346229247643352]
	TIME [epoch: 13 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16458483795775702		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.16458483795775702 | validation: 0.1560399477954687]
	TIME [epoch: 13 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1664120883818101		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.1664120883818101 | validation: 0.1943187327569699]
	TIME [epoch: 13.1 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16468394060366687		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.16468394060366687 | validation: 0.31600065006369116]
	TIME [epoch: 13 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2810192604681853		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.2810192604681853 | validation: 0.16672856254187773]
	TIME [epoch: 13 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15654575264180395		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.15654575264180395 | validation: 0.18038423301108925]
	TIME [epoch: 13.1 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13443060249337052		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.13443060249337052 | validation: 0.10934534761286072]
	TIME [epoch: 13 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11336874428422362		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.11336874428422362 | validation: 0.11535885738623967]
	TIME [epoch: 13 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.105041435006006		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.105041435006006 | validation: 0.11845780756517585]
	TIME [epoch: 13 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1360755796802519		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.1360755796802519 | validation: 0.19003209470302082]
	TIME [epoch: 13 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1841164874714633		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.1841164874714633 | validation: 0.13967872691824235]
	TIME [epoch: 13 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1516913084149466		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.1516913084149466 | validation: 0.16763679803636602]
	TIME [epoch: 13 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12452913184145795		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.12452913184145795 | validation: 0.1263537016481915]
	TIME [epoch: 13.1 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1253913871980876		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.1253913871980876 | validation: 0.1214814621137057]
	TIME [epoch: 13 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10995810084431214		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.10995810084431214 | validation: 0.12132855412197813]
	TIME [epoch: 13 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21753660708951655		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.21753660708951655 | validation: 0.272816929388542]
	TIME [epoch: 13 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20466965403906354		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.20466965403906354 | validation: 0.15278965566986633]
	TIME [epoch: 13 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13091966270238237		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.13091966270238237 | validation: 0.16032478184709664]
	TIME [epoch: 13 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11859040003527224		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.11859040003527224 | validation: 0.1005974800962959]
	TIME [epoch: 13 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13474424316876832		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.13474424316876832 | validation: 0.1510044081754657]
	TIME [epoch: 13 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11785651024613263		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.11785651024613263 | validation: 0.10986352697588]
	TIME [epoch: 13 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11164675339073513		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.11164675339073513 | validation: 0.1278155340501748]
	TIME [epoch: 13 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11909835741226996		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.11909835741226996 | validation: 0.1373142658575545]
	TIME [epoch: 13 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16653126636364785		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.16653126636364785 | validation: 0.18107334761231939]
	TIME [epoch: 13 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15278001675262787		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.15278001675262787 | validation: 0.1433470954772835]
	TIME [epoch: 13 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15810664193972912		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.15810664193972912 | validation: 0.1958453673174406]
	TIME [epoch: 13 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16118583025281638		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.16118583025281638 | validation: 0.14616993268853637]
	TIME [epoch: 13 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.132867515846279		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.132867515846279 | validation: 0.11616455253367124]
	TIME [epoch: 13 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10095753742107337		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.10095753742107337 | validation: 0.11819951843357561]
	TIME [epoch: 13 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11066506458778833		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.11066506458778833 | validation: 0.11684989390294766]
	TIME [epoch: 13 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12474629537773227		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.12474629537773227 | validation: 0.13358404114825614]
	TIME [epoch: 13.1 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1507633668098628		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.1507633668098628 | validation: 0.13232387201412657]
	TIME [epoch: 13 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13539077332310837		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.13539077332310837 | validation: 0.13613019069628976]
	TIME [epoch: 13 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14878071661055808		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.14878071661055808 | validation: 0.1231116299792079]
	TIME [epoch: 13.1 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13144206078443416		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.13144206078443416 | validation: 0.18372263249174497]
	TIME [epoch: 13.1 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15630642989500854		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.15630642989500854 | validation: 0.12674110530240174]
	TIME [epoch: 13 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11774723581520188		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.11774723581520188 | validation: 0.1176706684992066]
	TIME [epoch: 13 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13012086169111248		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.13012086169111248 | validation: 0.13320485653248232]
	TIME [epoch: 13.1 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14112942965081043		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.14112942965081043 | validation: 0.15948147095313084]
	TIME [epoch: 13.1 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17229413551678968		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.17229413551678968 | validation: 0.2022581764957891]
	TIME [epoch: 13 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16436958788853623		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.16436958788853623 | validation: 0.16198084904505788]
	TIME [epoch: 13.1 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14621029066645452		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.14621029066645452 | validation: 0.10912182135972052]
	TIME [epoch: 13.1 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12556405777691992		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.12556405777691992 | validation: 0.1782458264791072]
	TIME [epoch: 13 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1806313985115346		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.1806313985115346 | validation: 0.239460446808906]
	TIME [epoch: 13 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1738020817726732		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.1738020817726732 | validation: 0.1257436006981628]
	TIME [epoch: 13.1 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10787976493666232		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.10787976493666232 | validation: 0.1327405691724041]
	TIME [epoch: 13 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10300709114571327		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.10300709114571327 | validation: 0.09862426155141232]
	TIME [epoch: 13 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10410225081899244		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.10410225081899244 | validation: 0.11594832004133789]
	TIME [epoch: 13 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14839453277234874		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.14839453277234874 | validation: 0.12297489044359662]
	TIME [epoch: 13.1 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11355138806033113		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.11355138806033113 | validation: 0.118385927409627]
	TIME [epoch: 13 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13147969179696106		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.13147969179696106 | validation: 0.15241665668005225]
	TIME [epoch: 13 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.172197913657697		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.172197913657697 | validation: 0.1925471239659146]
	TIME [epoch: 13.1 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20168760147642822		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.20168760147642822 | validation: 0.1905421598293812]
	TIME [epoch: 13 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18468657466314098		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.18468657466314098 | validation: 0.18028735618656058]
	TIME [epoch: 13 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16048208172315098		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.16048208172315098 | validation: 0.14531911209007256]
	TIME [epoch: 13 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1205964875878531		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.1205964875878531 | validation: 0.1203619835080442]
	TIME [epoch: 13.1 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1245996387337674		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.1245996387337674 | validation: 0.10417668733494338]
	TIME [epoch: 13 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1000632548608986		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.1000632548608986 | validation: 0.09741849069789467]
	TIME [epoch: 13 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12119888443817516		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.12119888443817516 | validation: 0.11409388812736772]
	TIME [epoch: 13.1 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10792213946377997		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.10792213946377997 | validation: 0.09782100395360945]
	TIME [epoch: 13 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11353179683334698		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.11353179683334698 | validation: 0.11142773631476677]
	TIME [epoch: 13 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10700426458776222		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.10700426458776222 | validation: 0.13617315928114695]
	TIME [epoch: 13 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1155442916918382		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.1155442916918382 | validation: 0.13077764231513272]
	TIME [epoch: 13.1 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11129845349823754		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.11129845349823754 | validation: 0.14098550186354117]
	TIME [epoch: 13 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13266583055795889		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.13266583055795889 | validation: 0.10339543031841925]
	TIME [epoch: 13 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10109420517699043		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.10109420517699043 | validation: 0.12645701506885543]
	TIME [epoch: 13.1 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09724078164679997		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.09724078164679997 | validation: 0.11047632281524707]
	TIME [epoch: 13 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11212878883166211		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.11212878883166211 | validation: 0.17858624223390757]
	TIME [epoch: 13 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18189412667140029		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.18189412667140029 | validation: 0.19329725290592464]
	TIME [epoch: 13 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14536471599060152		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.14536471599060152 | validation: 0.10348424186542937]
	TIME [epoch: 13.1 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12030081405452012		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.12030081405452012 | validation: 0.13676562439510154]
	TIME [epoch: 13 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12843492347726088		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.12843492347726088 | validation: 0.13881265502241458]
	TIME [epoch: 13 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12644670051149723		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.12644670051149723 | validation: 0.12294109775535658]
	TIME [epoch: 13.1 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10124613542176845		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.10124613542176845 | validation: 0.09752632861423935]
	TIME [epoch: 13 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10021484623576542		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.10021484623576542 | validation: 0.09901397413307268]
	TIME [epoch: 13 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10447329274954514		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.10447329274954514 | validation: 0.0921423562195633]
	TIME [epoch: 13 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1606378733497355		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.1606378733497355 | validation: 0.24113845922901989]
	TIME [epoch: 13.1 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1574931416471465		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.1574931416471465 | validation: 0.10957954347863222]
	TIME [epoch: 13 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09974230054661179		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.09974230054661179 | validation: 0.11108940188046543]
	TIME [epoch: 13 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10542948812773797		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.10542948812773797 | validation: 0.12302657566298629]
	TIME [epoch: 13.1 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14708651735775277		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.14708651735775277 | validation: 0.1599670630481524]
	TIME [epoch: 13 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13136960089866082		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.13136960089866082 | validation: 0.11364536139099383]
	TIME [epoch: 13 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11078233802553257		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.11078233802553257 | validation: 0.11187346210366102]
	TIME [epoch: 13 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10236115752912579		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.10236115752912579 | validation: 0.11568858451083766]
	TIME [epoch: 13.1 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.102438800393257		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.102438800393257 | validation: 0.16797389100505147]
	TIME [epoch: 13 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11660710544962728		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.11660710544962728 | validation: 0.10312101547964915]
	TIME [epoch: 13 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1047499832814632		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.1047499832814632 | validation: 0.08729716020100474]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_715.pth
	Model improved!!!
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09335766317386729		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.09335766317386729 | validation: 0.11257156980552208]
	TIME [epoch: 13 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09740640105303444		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.09740640105303444 | validation: 0.11896492880812375]
	TIME [epoch: 13 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11171301802302552		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.11171301802302552 | validation: 0.14190284430500236]
	TIME [epoch: 13 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14296814682112352		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.14296814682112352 | validation: 0.17418117646335937]
	TIME [epoch: 13 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14830263254856085		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.14830263254856085 | validation: 0.2017721853976139]
	TIME [epoch: 13 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24326473086936257		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.24326473086936257 | validation: 0.2370046475873179]
	TIME [epoch: 13 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1740410525382507		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.1740410525382507 | validation: 0.18890239985180488]
	TIME [epoch: 13 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17942005152708537		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.17942005152708537 | validation: 0.18013212553180225]
	TIME [epoch: 13 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1556555170468233		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.1556555170468233 | validation: 0.13172860662533248]
	TIME [epoch: 13 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11458900248740214		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.11458900248740214 | validation: 0.13319695171964396]
	TIME [epoch: 13 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11805102629922676		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.11805102629922676 | validation: 0.12365858981160997]
	TIME [epoch: 13 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11643225350544753		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.11643225350544753 | validation: 0.13367407093821515]
	TIME [epoch: 13 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11436162264226166		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.11436162264226166 | validation: 0.11194168301016051]
	TIME [epoch: 13 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09944021582068094		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.09944021582068094 | validation: 0.1079263498591861]
	TIME [epoch: 13 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10145146346139844		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.10145146346139844 | validation: 0.14293850742745062]
	TIME [epoch: 13.1 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1110614321548948		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.1110614321548948 | validation: 0.10108022138556219]
	TIME [epoch: 13 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1140384867691509		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.1140384867691509 | validation: 0.1256019632247272]
	TIME [epoch: 13 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10644028893449646		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.10644028893449646 | validation: 0.10678700352819835]
	TIME [epoch: 13.1 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08627875654105165		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.08627875654105165 | validation: 0.10705350320017264]
	TIME [epoch: 13 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14386284167069396		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.14386284167069396 | validation: 0.2762027867528952]
	TIME [epoch: 13 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19395868559753227		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.19395868559753227 | validation: 0.1363272054043295]
	TIME [epoch: 13 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1201642051993312		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.1201642051993312 | validation: 0.17779595899370917]
	TIME [epoch: 13.1 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16151477801834582		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.16151477801834582 | validation: 0.18425974037430018]
	TIME [epoch: 13 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14101731748969812		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.14101731748969812 | validation: 0.1137358969069285]
	TIME [epoch: 13 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11161863841484775		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.11161863841484775 | validation: 0.10161713041951273]
	TIME [epoch: 13.1 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1046583452141418		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.1046583452141418 | validation: 0.11177298101811257]
	TIME [epoch: 13.1 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08948031600721543		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.08948031600721543 | validation: 0.09492321500758025]
	TIME [epoch: 13.1 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10151150022115057		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.10151150022115057 | validation: 0.11617882003844365]
	TIME [epoch: 13 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1111912862272718		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.1111912862272718 | validation: 0.17912920861683218]
	TIME [epoch: 13.1 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15775300795880456		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.15775300795880456 | validation: 0.13715554983440748]
	TIME [epoch: 13 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18118153605701495		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.18118153605701495 | validation: 0.2123926321891032]
	TIME [epoch: 13 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13411735454694956		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.13411735454694956 | validation: 0.11362982009634061]
	TIME [epoch: 13.1 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12051908704340611		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.12051908704340611 | validation: 0.1388043565089019]
	TIME [epoch: 13 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12153223213062944		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.12153223213062944 | validation: 0.10284993045752176]
	TIME [epoch: 13 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09192268061035525		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.09192268061035525 | validation: 0.09444370894203757]
	TIME [epoch: 13 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09385010997255759		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.09385010997255759 | validation: 0.1066582820937972]
	TIME [epoch: 13.1 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10207570111759566		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.10207570111759566 | validation: 0.12357557706573513]
	TIME [epoch: 13 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11247148815499262		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.11247148815499262 | validation: 0.10401918842613884]
	TIME [epoch: 13 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10736353694226135		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.10736353694226135 | validation: 0.13627912737450149]
	TIME [epoch: 13.1 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12193255033810757		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.12193255033810757 | validation: 0.1203884844058162]
	TIME [epoch: 13 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10375423294196749		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.10375423294196749 | validation: 0.09225034591458157]
	TIME [epoch: 13 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0900513169065405		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.0900513169065405 | validation: 0.11171547087372434]
	TIME [epoch: 13 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11119104393380276		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.11119104393380276 | validation: 0.14246762116374537]
	TIME [epoch: 13.1 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14132806685397087		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.14132806685397087 | validation: 0.14054510522514502]
	TIME [epoch: 13 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1189081510102652		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.1189081510102652 | validation: 0.10089594230716248]
	TIME [epoch: 13 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09898668511611608		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.09898668511611608 | validation: 0.10073128001221082]
	TIME [epoch: 13.1 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09613850080654454		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.09613850080654454 | validation: 0.13775138659083813]
	TIME [epoch: 13 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12163614479817		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.12163614479817 | validation: 0.09957730491207631]
	TIME [epoch: 13 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0969185240436429		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.0969185240436429 | validation: 0.15783442968250513]
	TIME [epoch: 13 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14028352491014032		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.14028352491014032 | validation: 0.11507785911105091]
	TIME [epoch: 13.1 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09466489616905363		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.09466489616905363 | validation: 0.08877155973539065]
	TIME [epoch: 13 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08327499348494073		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.08327499348494073 | validation: 0.09717924661311032]
	TIME [epoch: 13 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10970096636391075		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.10970096636391075 | validation: 0.1537837468533858]
	TIME [epoch: 13 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11286701812086129		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.11286701812086129 | validation: 0.08394143166042291]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_769.pth
	Model improved!!!
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08863205863878232		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.08863205863878232 | validation: 0.08925605930651795]
	TIME [epoch: 13 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09603623626834187		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.09603623626834187 | validation: 0.10870351744573256]
	TIME [epoch: 13 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10290834201946941		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.10290834201946941 | validation: 0.10756566365508423]
	TIME [epoch: 13 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11274306373416801		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.11274306373416801 | validation: 0.11280807427594304]
	TIME [epoch: 13 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10310225759489226		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.10310225759489226 | validation: 0.09930769001261189]
	TIME [epoch: 13 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09945889348889132		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.09945889348889132 | validation: 0.12027058760779631]
	TIME [epoch: 13 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10578387308538015		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.10578387308538015 | validation: 0.10052857325275259]
	TIME [epoch: 13.1 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09185746653233821		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.09185746653233821 | validation: 0.10231578654704766]
	TIME [epoch: 13 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09313344221201922		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.09313344221201922 | validation: 0.14224665470894804]
	TIME [epoch: 13 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1408751240163196		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.1408751240163196 | validation: 0.10553395644907951]
	TIME [epoch: 13.1 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13371157692087185		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.13371157692087185 | validation: 0.22454762199275746]
	TIME [epoch: 13 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20191742374155044		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.20191742374155044 | validation: 0.22150872570888097]
	TIME [epoch: 13 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20146825190754658		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.20146825190754658 | validation: 0.13645235777315629]
	TIME [epoch: 13 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10792925611816695		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.10792925611816695 | validation: 0.10221635729053481]
	TIME [epoch: 13.1 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09504032452938439		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.09504032452938439 | validation: 0.09231324036174275]
	TIME [epoch: 13 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09783400607212193		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.09783400607212193 | validation: 0.13106937399968951]
	TIME [epoch: 13 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09844979895288022		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.09844979895288022 | validation: 0.10032350580627673]
	TIME [epoch: 13.1 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10212677128209105		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.10212677128209105 | validation: 0.1107760418806077]
	TIME [epoch: 13 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13875617834407145		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.13875617834407145 | validation: 0.14340331281445484]
	TIME [epoch: 13 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09422573337793998		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.09422573337793998 | validation: 0.08677083273134382]
	TIME [epoch: 13 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09229669713702625		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.09229669713702625 | validation: 0.08812703470635239]
	TIME [epoch: 13.1 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11435934661712358		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.11435934661712358 | validation: 0.1217852841575829]
	TIME [epoch: 13 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11961800035665482		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.11961800035665482 | validation: 0.129373416083643]
	TIME [epoch: 13 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11118229100615297		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.11118229100615297 | validation: 0.13194815446009253]
	TIME [epoch: 13.1 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11933099186043963		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.11933099186043963 | validation: 0.10161506041931055]
	TIME [epoch: 13 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09312713011169808		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.09312713011169808 | validation: 0.10277733707555832]
	TIME [epoch: 13 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1050815834963105		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.1050815834963105 | validation: 0.167817101418419]
	TIME [epoch: 13 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1590561283693528		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.1590561283693528 | validation: 0.16360985819984958]
	TIME [epoch: 13.1 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13291437227458955		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.13291437227458955 | validation: 0.11670710341891564]
	TIME [epoch: 13 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1319120661007689		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.1319120661007689 | validation: 0.1480981023341443]
	TIME [epoch: 13 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10959253815185434		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.10959253815185434 | validation: 0.09281210192995122]
	TIME [epoch: 13.1 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09924508935394141		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.09924508935394141 | validation: 0.12013955300361788]
	TIME [epoch: 13 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10117252265876027		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.10117252265876027 | validation: 0.11611850262438257]
	TIME [epoch: 13 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10632067765007466		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.10632067765007466 | validation: 0.1113695241950602]
	TIME [epoch: 13 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08799748992685871		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.08799748992685871 | validation: 0.08878003947931142]
	TIME [epoch: 13.1 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09753407170179773		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.09753407170179773 | validation: 0.08117307353785126]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_805.pth
	Model improved!!!
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07951292047416156		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.07951292047416156 | validation: 0.08248688904173858]
	TIME [epoch: 13 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0772803349933684		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.0772803349933684 | validation: 0.10755864680901235]
	TIME [epoch: 13.1 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10282978236192354		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.10282978236192354 | validation: 0.08762631420446029]
	TIME [epoch: 13 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08987558981021315		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.08987558981021315 | validation: 0.10799233493728233]
	TIME [epoch: 13 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09985574960813938		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.09985574960813938 | validation: 0.11535630544277904]
	TIME [epoch: 13 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08884182039669734		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.08884182039669734 | validation: 0.09918757402697434]
	TIME [epoch: 13.1 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08636454753573373		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.08636454753573373 | validation: 0.07972725252502633]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_812.pth
	Model improved!!!
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07340694858300416		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.07340694858300416 | validation: 0.08947419424921221]
	TIME [epoch: 13 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08319805244632525		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.08319805244632525 | validation: 0.11585288087212792]
	TIME [epoch: 13.1 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10907790495848213		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.10907790495848213 | validation: 0.0862054585316817]
	TIME [epoch: 13.1 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12090582072434333		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.12090582072434333 | validation: 0.16185061952422672]
	TIME [epoch: 13 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1307679725129413		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.1307679725129413 | validation: 0.1258103554834864]
	TIME [epoch: 13.1 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12481686142053051		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.12481686142053051 | validation: 0.16286963381153594]
	TIME [epoch: 13.1 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1466163301781507		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.1466163301781507 | validation: 0.12760404867547828]
	TIME [epoch: 13 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11860610614378471		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.11860610614378471 | validation: 0.13830933893174788]
	TIME [epoch: 13.1 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11424461005970306		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.11424461005970306 | validation: 0.14292699870200776]
	TIME [epoch: 13.1 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10862691153443184		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.10862691153443184 | validation: 0.1004360868202856]
	TIME [epoch: 13.1 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10075841194652839		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.10075841194652839 | validation: 0.12309406796851359]
	TIME [epoch: 13.1 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15675034716200525		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.15675034716200525 | validation: 0.16589119094439098]
	TIME [epoch: 13 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1161113172470463		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.1161113172470463 | validation: 0.09202094224503408]
	TIME [epoch: 13.1 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.112936399039018		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.112936399039018 | validation: 0.13194472785175043]
	TIME [epoch: 13 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12089408833619274		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.12089408833619274 | validation: 0.09089878518675759]
	TIME [epoch: 13 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08218069196240659		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.08218069196240659 | validation: 0.09784797884200337]
	TIME [epoch: 13.1 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09309951957135346		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.09309951957135346 | validation: 0.11383409187882414]
	TIME [epoch: 13.1 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09678506549323163		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.09678506549323163 | validation: 0.10052237446742329]
	TIME [epoch: 13 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11075303481277105		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.11075303481277105 | validation: 0.12772223481876924]
	TIME [epoch: 13 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12226067731095132		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.12226067731095132 | validation: 0.11692371188482785]
	TIME [epoch: 13.1 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09244925663443453		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.09244925663443453 | validation: 0.10291843863214496]
	TIME [epoch: 13 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12095116904561207		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.12095116904561207 | validation: 0.1619129199727237]
	TIME [epoch: 13 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16591708312614475		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.16591708312614475 | validation: 0.1458890231213188]
	TIME [epoch: 13 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18096568027769366		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.18096568027769366 | validation: 0.1841845387526228]
	TIME [epoch: 13.1 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17722817091272186		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.17722817091272186 | validation: 0.12678741116575545]
	TIME [epoch: 13 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10846663213291917		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.10846663213291917 | validation: 0.07769221768848196]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_838.pth
	Model improved!!!
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07337853561115877		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.07337853561115877 | validation: 0.09251476945032995]
	TIME [epoch: 13.1 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08296052274163257		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.08296052274163257 | validation: 0.12241260020573975]
	TIME [epoch: 13 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10833093157473957		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.10833093157473957 | validation: 0.1112785060461935]
	TIME [epoch: 13 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09890773731725688		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.09890773731725688 | validation: 0.10197474158111733]
	TIME [epoch: 13 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09900668764371044		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.09900668764371044 | validation: 0.1013142248920082]
	TIME [epoch: 13.1 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08514500148712235		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.08514500148712235 | validation: 0.09064045920469706]
	TIME [epoch: 13 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09062166758508045		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.09062166758508045 | validation: 0.12701815227063068]
	TIME [epoch: 13.1 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12407849821895323		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.12407849821895323 | validation: 0.11416350708939846]
	TIME [epoch: 13.1 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11025098464200031		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.11025098464200031 | validation: 0.12152948828013564]
	TIME [epoch: 13.1 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08902104812379422		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.08902104812379422 | validation: 0.09373465528674522]
	TIME [epoch: 13 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0813406058199605		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.0813406058199605 | validation: 0.09616844406933923]
	TIME [epoch: 13.1 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07280901778263286		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.07280901778263286 | validation: 0.07980734893089597]
	TIME [epoch: 13.1 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07738138348036581		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.07738138348036581 | validation: 0.07891165493218848]
	TIME [epoch: 13.1 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07697699114174676		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.07697699114174676 | validation: 0.07410907849649112]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_852.pth
	Model improved!!!
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07572757050337639		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.07572757050337639 | validation: 0.0772525955924497]
	TIME [epoch: 13.1 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06892093828289994		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.06892093828289994 | validation: 0.0762403303420294]
	TIME [epoch: 13 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0675381594028126		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.0675381594028126 | validation: 0.07720964744096982]
	TIME [epoch: 13 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0659582023848822		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.0659582023848822 | validation: 0.08862881942441822]
	TIME [epoch: 13 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0815045464145148		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.0815045464145148 | validation: 0.08324553328886003]
	TIME [epoch: 13.1 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0733064355973047		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.0733064355973047 | validation: 0.0741058917245156]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_858.pth
	Model improved!!!
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07840634743027639		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.07840634743027639 | validation: 0.08584196777027449]
	TIME [epoch: 13 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07426354214220005		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.07426354214220005 | validation: 0.08160259911020976]
	TIME [epoch: 13.1 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08855251348088014		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.08855251348088014 | validation: 0.09133133513711993]
	TIME [epoch: 13 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08118894838537037		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.08118894838537037 | validation: 0.07597112153749316]
	TIME [epoch: 13 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07532856814804248		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.07532856814804248 | validation: 0.07602500551985031]
	TIME [epoch: 13 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08349136012950688		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.08349136012950688 | validation: 0.08778921899892439]
	TIME [epoch: 13.1 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08318221325308933		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.08318221325308933 | validation: 0.07998361990899353]
	TIME [epoch: 13 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07915003583372923		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.07915003583372923 | validation: 0.09171219744529693]
	TIME [epoch: 13 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08808575781452299		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.08808575781452299 | validation: 0.09941016637880828]
	TIME [epoch: 13.1 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09904115754354924		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.09904115754354924 | validation: 0.1061536058983943]
	TIME [epoch: 13 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07945313254393224		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.07945313254393224 | validation: 0.078423297548123]
	TIME [epoch: 13 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07936453964333258		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.07936453964333258 | validation: 0.0853948608754176]
	TIME [epoch: 13 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07480396965340008		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.07480396965340008 | validation: 0.08354860728147509]
	TIME [epoch: 13.1 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08374919100620282		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.08374919100620282 | validation: 0.0932358711255123]
	TIME [epoch: 13 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07593377903275238		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.07593377903275238 | validation: 0.0872009765604852]
	TIME [epoch: 13 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07504031250304033		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.07504031250304033 | validation: 0.08343300018405128]
	TIME [epoch: 13.1 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08399707080013277		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.08399707080013277 | validation: 0.09675802466031741]
	TIME [epoch: 13 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11790061784956436		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.11790061784956436 | validation: 0.14733390587429798]
	TIME [epoch: 13 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11028334084341514		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.11028334084341514 | validation: 0.09503025980974003]
	TIME [epoch: 13 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08898312713152484		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.08898312713152484 | validation: 0.09769108503856005]
	TIME [epoch: 13 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0847888611853168		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.0847888611853168 | validation: 0.07144716706111885]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_879.pth
	Model improved!!!
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06912385717182923		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.06912385717182923 | validation: 0.07775201284707152]
	TIME [epoch: 13 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0736047034530241		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.0736047034530241 | validation: 0.08013509098537913]
	TIME [epoch: 13 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07132035575835052		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.07132035575835052 | validation: 0.07426135004097194]
	TIME [epoch: 13 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0741942622489379		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.0741942622489379 | validation: 0.08959632514382282]
	TIME [epoch: 13 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08925662580843967		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.08925662580843967 | validation: 0.08020278467314633]
	TIME [epoch: 13 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07809432049750199		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.07809432049750199 | validation: 0.08665661593623888]
	TIME [epoch: 13 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09010486317773403		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.09010486317773403 | validation: 0.08297916642539904]
	TIME [epoch: 13 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08327195478073074		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.08327195478073074 | validation: 0.11880271071624958]
	TIME [epoch: 13 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10069184306227799		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.10069184306227799 | validation: 0.07972029034401698]
	TIME [epoch: 13 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07443699925042419		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.07443699925042419 | validation: 0.07331253826998795]
	TIME [epoch: 13 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07637154378094262		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.07637154378094262 | validation: 0.10065357874395037]
	TIME [epoch: 13 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11778620058619708		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.11778620058619708 | validation: 0.12111602212121743]
	TIME [epoch: 13 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13350923420490587		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.13350923420490587 | validation: 0.13437901575675837]
	TIME [epoch: 13 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12016845375407456		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.12016845375407456 | validation: 0.10852346164871399]
	TIME [epoch: 13 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10198668302458147		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.10198668302458147 | validation: 0.11624681989062358]
	TIME [epoch: 13 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11849800490269866		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.11849800490269866 | validation: 0.1225734747173926]
	TIME [epoch: 13 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10680523645970277		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.10680523645970277 | validation: 0.08131966014041588]
	TIME [epoch: 13.1 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09040878408199111		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.09040878408199111 | validation: 0.11379929475224788]
	TIME [epoch: 13 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11831259482969014		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.11831259482969014 | validation: 0.11402909399348676]
	TIME [epoch: 13 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.110512924210936		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.110512924210936 | validation: 0.11908737822621225]
	TIME [epoch: 13.1 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12654305768809895		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.12654305768809895 | validation: 0.1288722616692629]
	TIME [epoch: 13.1 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11633412358805681		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.11633412358805681 | validation: 0.088173541297433]
	TIME [epoch: 13.1 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08792816822898757		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.08792816822898757 | validation: 0.08839462837953199]
	TIME [epoch: 13.1 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08056420007933149		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.08056420007933149 | validation: 0.09430910045428631]
	TIME [epoch: 13.1 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0788018348724435		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.0788018348724435 | validation: 0.07954173578299618]
	TIME [epoch: 13.1 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08222095004862798		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.08222095004862798 | validation: 0.08888567325864545]
	TIME [epoch: 13.1 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08002324578145395		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.08002324578145395 | validation: 0.07672076558962763]
	TIME [epoch: 13.1 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07643518333622472		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.07643518333622472 | validation: 0.09233902245686398]
	TIME [epoch: 13.1 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09681586422005539		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.09681586422005539 | validation: 0.10257104251410276]
	TIME [epoch: 13.1 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09611834719466297		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.09611834719466297 | validation: 0.09336899433847629]
	TIME [epoch: 13.1 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08175661570398533		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.08175661570398533 | validation: 0.0924597387105223]
	TIME [epoch: 13.1 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07877984687603966		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.07877984687603966 | validation: 0.07978085677924812]
	TIME [epoch: 13.1 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07786412712017553		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.07786412712017553 | validation: 0.08971852631020219]
	TIME [epoch: 13.1 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08047720606354798		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.08047720606354798 | validation: 0.10137916790131754]
	TIME [epoch: 13.1 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0813921382922364		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.0813921382922364 | validation: 0.08479637703989398]
	TIME [epoch: 13 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08712164564194408		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.08712164564194408 | validation: 0.08066132543536385]
	TIME [epoch: 13.1 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08770782605400225		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.08770782605400225 | validation: 0.0974856619915166]
	TIME [epoch: 13.1 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09191388333991937		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.09191388333991937 | validation: 0.08259623417398192]
	TIME [epoch: 13.1 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07428371056660525		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.07428371056660525 | validation: 0.0900527860682353]
	TIME [epoch: 13 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07014901397421855		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.07014901397421855 | validation: 0.0795519049050744]
	TIME [epoch: 13 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07525986973021168		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.07525986973021168 | validation: 0.10152459498825277]
	TIME [epoch: 13.1 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07593569784228053		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.07593569784228053 | validation: 0.09024252669533851]
	TIME [epoch: 13 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0755954447508959		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.0755954447508959 | validation: 0.09608628689673598]
	TIME [epoch: 13 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08507928918555704		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.08507928918555704 | validation: 0.0872910990461785]
	TIME [epoch: 13 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08042546802515897		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.08042546802515897 | validation: 0.0728555960389651]
	TIME [epoch: 13.1 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07418020247926399		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.07418020247926399 | validation: 0.07432816995714751]
	TIME [epoch: 13 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06959353683313944		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.06959353683313944 | validation: 0.07827152086498897]
	TIME [epoch: 13 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07892939470931462		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.07892939470931462 | validation: 0.11487144103155013]
	TIME [epoch: 13.1 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08719188161684495		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.08719188161684495 | validation: 0.09596622006177569]
	TIME [epoch: 13 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09022633526944952		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.09022633526944952 | validation: 0.1133235075889772]
	TIME [epoch: 13 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10142743647499194		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.10142743647499194 | validation: 0.09308157147931574]
	TIME [epoch: 13 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07773461828168235		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.07773461828168235 | validation: 0.07664201115716215]
	TIME [epoch: 13.1 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0749904162530962		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.0749904162530962 | validation: 0.07448839451519551]
	TIME [epoch: 13 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07118181965881573		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.07118181965881573 | validation: 0.10749523255856859]
	TIME [epoch: 13 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10193074369415023		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.10193074369415023 | validation: 0.08361687822647096]
	TIME [epoch: 13.1 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07838636802495144		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.07838636802495144 | validation: 0.09144715389332567]
	TIME [epoch: 13.1 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08326406891717068		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.08326406891717068 | validation: 0.10304604984958171]
	TIME [epoch: 13 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0919752898334734		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.0919752898334734 | validation: 0.08551546464794971]
	TIME [epoch: 13 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07115321414312951		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.07115321414312951 | validation: 0.09631580522942422]
	TIME [epoch: 13.1 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08784739170972064		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.08784739170972064 | validation: 0.11339667669680094]
	TIME [epoch: 13 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09637797763599201		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.09637797763599201 | validation: 0.08983038724857266]
	TIME [epoch: 13 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08119173000614831		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.08119173000614831 | validation: 0.10101803454300388]
	TIME [epoch: 13.1 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07520623839268582		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.07520623839268582 | validation: 0.09185726354876785]
	TIME [epoch: 13 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08633715305855608		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.08633715305855608 | validation: 0.07936355713488152]
	TIME [epoch: 13 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07379310630815399		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.07379310630815399 | validation: 0.08341310479107318]
	TIME [epoch: 13 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07520637920700503		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.07520637920700503 | validation: 0.09541420023180514]
	TIME [epoch: 13.1 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1103168577413077		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.1103168577413077 | validation: 0.09503553990145619]
	TIME [epoch: 13 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08317519904166926		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.08317519904166926 | validation: 0.09290920510026539]
	TIME [epoch: 13 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08621171710304415		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.08621171710304415 | validation: 0.07054907787191711]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_948.pth
	Model improved!!!
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07377001030359744		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.07377001030359744 | validation: 0.09024122782565534]
	TIME [epoch: 13.1 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09159086764833957		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.09159086764833957 | validation: 0.08922353829916847]
	TIME [epoch: 13 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07915531082384947		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.07915531082384947 | validation: 0.09075951912008921]
	TIME [epoch: 13 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08320704599959619		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.08320704599959619 | validation: 0.10015889722071307]
	TIME [epoch: 13.1 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11389360704599054		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.11389360704599054 | validation: 0.1629783061347999]
	TIME [epoch: 13 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12082872803715945		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.12082872803715945 | validation: 0.09894136986503767]
	TIME [epoch: 13 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08076600173249382		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.08076600173249382 | validation: 0.07975271868005374]
	TIME [epoch: 13 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07436932357811404		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.07436932357811404 | validation: 0.07464298622025055]
	TIME [epoch: 13.1 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07330826457705908		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.07330826457705908 | validation: 0.0777341930812026]
	TIME [epoch: 13 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07471714862983321		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.07471714862983321 | validation: 0.08358939027235873]
	TIME [epoch: 13 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07598330854372551		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.07598330854372551 | validation: 0.09545646940651482]
	TIME [epoch: 13.1 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09284946472958379		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.09284946472958379 | validation: 0.09301669994285777]
	TIME [epoch: 13 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07286300200103107		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.07286300200103107 | validation: 0.07457474241525155]
	TIME [epoch: 13 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0757589656875822		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.0757589656875822 | validation: 0.07988004052170647]
	TIME [epoch: 13 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0682023871280154		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.0682023871280154 | validation: 0.07785292486340609]
	TIME [epoch: 13.1 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06953947743007172		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.06953947743007172 | validation: 0.07469471842480421]
	TIME [epoch: 13 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07337705143612439		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.07337705143612439 | validation: 0.0725771818095981]
	TIME [epoch: 13 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06612302793361854		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.06612302793361854 | validation: 0.07493552159373712]
	TIME [epoch: 13.1 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07574154399078142		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.07574154399078142 | validation: 0.0872085359763486]
	TIME [epoch: 13 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0776202017506575		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.0776202017506575 | validation: 0.09027037463697742]
	TIME [epoch: 13 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10118127016142706		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.10118127016142706 | validation: 0.12577800736368872]
	TIME [epoch: 13 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11252116988549621		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.11252116988549621 | validation: 0.11841067676480803]
	TIME [epoch: 13.1 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09643157346489659		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.09643157346489659 | validation: 0.09368991309418861]
	TIME [epoch: 13 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08059387035729261		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.08059387035729261 | validation: 0.08893653495682195]
	TIME [epoch: 13 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07282543645476074		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.07282543645476074 | validation: 0.07577588594727422]
	TIME [epoch: 13.1 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0703008165250316		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.0703008165250316 | validation: 0.07594833375181652]
	TIME [epoch: 13 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07105271874388257		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.07105271874388257 | validation: 0.07493353268014537]
	TIME [epoch: 13 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07095237419287637		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.07095237419287637 | validation: 0.07931885976658035]
	TIME [epoch: 13 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0746096390011566		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.0746096390011566 | validation: 0.0970508213015918]
	TIME [epoch: 13.1 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07762675246446635		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.07762675246446635 | validation: 0.07720114519222246]
	TIME [epoch: 13 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07093534971362951		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.07093534971362951 | validation: 0.0778059559681805]
	TIME [epoch: 13 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08032148957788476		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.08032148957788476 | validation: 0.12181029313104481]
	TIME [epoch: 13.1 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1481957135326038		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.1481957135326038 | validation: 0.1398062855987131]
	TIME [epoch: 13 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10810959835230285		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.10810959835230285 | validation: 0.08398840624956531]
	TIME [epoch: 13 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08010294378927386		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.08010294378927386 | validation: 0.08813914094737356]
	TIME [epoch: 13 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08549042983045077		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.08549042983045077 | validation: 0.0888860450691541]
	TIME [epoch: 13.1 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0829809320146456		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.0829809320146456 | validation: 0.08175799399653504]
	TIME [epoch: 13 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07435360319455116		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.07435360319455116 | validation: 0.07910280571800025]
	TIME [epoch: 13 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07629190989446107		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.07629190989446107 | validation: 0.08071700781744444]
	TIME [epoch: 13.1 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07596671001811414		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.07596671001811414 | validation: 0.09735503827425497]
	TIME [epoch: 13 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0796429299834095		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.0796429299834095 | validation: 0.09043009075702503]
	TIME [epoch: 13 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08187449733014712		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.08187449733014712 | validation: 0.09308011116724756]
	TIME [epoch: 13 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08653399749637936		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.08653399749637936 | validation: 0.14208958642185124]
	TIME [epoch: 13.1 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1348664600841794		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.1348664600841794 | validation: 0.11057959626086188]
	TIME [epoch: 13 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08807944947224268		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.08807944947224268 | validation: 0.09547099573112311]
	TIME [epoch: 13 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08849243376710858		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.08849243376710858 | validation: 0.10961051711305732]
	TIME [epoch: 13.1 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09689943444939736		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.09689943444939736 | validation: 0.08619417225962994]
	TIME [epoch: 13 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07275461976822253		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.07275461976822253 | validation: 0.07814875632147476]
	TIME [epoch: 13 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0637258032527679		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.0637258032527679 | validation: 0.07446536696392766]
	TIME [epoch: 13 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06422427002149529		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.06422427002149529 | validation: 0.06708884167740685]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_998.pth
	Model improved!!!
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06975818593830427		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.06975818593830427 | validation: 0.07513713876581359]
	TIME [epoch: 13 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06702874011217777		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.06702874011217777 | validation: 0.08811789909149509]
	TIME [epoch: 13 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06918021234442126		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.06918021234442126 | validation: 0.07016008664478497]
	TIME [epoch: 13.1 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06858274725927006		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.06858274725927006 | validation: 0.08710925331381365]
	TIME [epoch: 13 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0835271735389212		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.0835271735389212 | validation: 0.10788722829549517]
	TIME [epoch: 13 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11082816079692356		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.11082816079692356 | validation: 0.1054697662880129]
	TIME [epoch: 13 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08785274543041005		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.08785274543041005 | validation: 0.10127221144791863]
	TIME [epoch: 13.1 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08539254370439135		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.08539254370439135 | validation: 0.08501631900032837]
	TIME [epoch: 13 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06819256466291192		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.06819256466291192 | validation: 0.08279452738477773]
	TIME [epoch: 13 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07371375095765727		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.07371375095765727 | validation: 0.0949204985820069]
	TIME [epoch: 13 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07555131893556541		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.07555131893556541 | validation: 0.08380397540861977]
	TIME [epoch: 13.1 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07740121889358094		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.07740121889358094 | validation: 0.07726389190140123]
	TIME [epoch: 13 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0681928604674009		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.0681928604674009 | validation: 0.0737548539684834]
	TIME [epoch: 13 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06692282784714415		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.06692282784714415 | validation: 0.07828063159370513]
	TIME [epoch: 13.1 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07783442464805973		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.07783442464805973 | validation: 0.08791315160415032]
	TIME [epoch: 13 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08672917032537523		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.08672917032537523 | validation: 0.1116389717725077]
	TIME [epoch: 13 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0958246572870609		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.0958246572870609 | validation: 0.11119038844270168]
	TIME [epoch: 13 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09201330116642456		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.09201330116642456 | validation: 0.09067572691326287]
	TIME [epoch: 13.1 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07318157409068593		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.07318157409068593 | validation: 0.08248945756803507]
	TIME [epoch: 13 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08196630890736702		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.08196630890736702 | validation: 0.112336214178621]
	TIME [epoch: 13 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0898223752490134		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.0898223752490134 | validation: 0.08522898546392574]
	TIME [epoch: 13.1 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0713164199001387		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.0713164199001387 | validation: 0.07945043026271584]
	TIME [epoch: 13 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07121032078807757		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.07121032078807757 | validation: 0.08715307361984281]
	TIME [epoch: 13 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08448683056144315		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.08448683056144315 | validation: 0.0825192198698757]
	TIME [epoch: 13 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07669448879685833		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.07669448879685833 | validation: 0.08657790310679438]
	TIME [epoch: 13.1 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08569503616863469		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.08569503616863469 | validation: 0.09416981485031116]
	TIME [epoch: 13 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08717986902730732		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.08717986902730732 | validation: 0.09122087169790728]
	TIME [epoch: 13 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10133510149904267		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.10133510149904267 | validation: 0.10338737004790094]
	TIME [epoch: 13.1 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09929304120587007		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.09929304120587007 | validation: 0.10515621020367494]
	TIME [epoch: 13 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11656718625274455		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.11656718625274455 | validation: 0.12081329605257579]
	TIME [epoch: 13 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10146811672366794		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.10146811672366794 | validation: 0.09781884878709862]
	TIME [epoch: 13 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08778489405291004		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.08778489405291004 | validation: 0.08648643203095922]
	TIME [epoch: 13.1 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07548436230485336		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.07548436230485336 | validation: 0.08146500203298077]
	TIME [epoch: 13 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06798711409170388		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.06798711409170388 | validation: 0.07697634341659076]
	TIME [epoch: 13 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07159033472517069		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.07159033472517069 | validation: 0.07010326735864998]
	TIME [epoch: 13.1 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0718903226123831		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.0718903226123831 | validation: 0.0836547989619757]
	TIME [epoch: 13 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07064058931770888		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.07064058931770888 | validation: 0.07943277093579158]
	TIME [epoch: 13 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06725501209183454		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.06725501209183454 | validation: 0.06881915858014058]
	TIME [epoch: 13 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06716197950282331		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.06716197950282331 | validation: 0.07693451470164658]
	TIME [epoch: 13.1 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07042693486275209		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.07042693486275209 | validation: 0.07329510709061111]
	TIME [epoch: 13 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07015466084882763		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.07015466084882763 | validation: 0.0864009087422303]
	TIME [epoch: 13 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07403150596300676		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.07403150596300676 | validation: 0.08563795672622856]
	TIME [epoch: 13.1 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07067696585836594		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.07067696585836594 | validation: 0.08251377027414115]
	TIME [epoch: 13 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08131764216272491		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.08131764216272491 | validation: 0.08691024149471353]
	TIME [epoch: 13 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07714740941556954		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.07714740941556954 | validation: 0.08789801376257855]
	TIME [epoch: 13 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06993175267608612		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.06993175267608612 | validation: 0.06394669944613322]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_1044.pth
	Model improved!!!
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06790270192288919		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.06790270192288919 | validation: 0.07895055118068249]
	TIME [epoch: 13 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0697444934644848		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.0697444934644848 | validation: 0.07662713921858155]
	TIME [epoch: 13 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06905872692735164		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.06905872692735164 | validation: 0.0747837119315421]
	TIME [epoch: 13.1 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07357588617326154		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.07357588617326154 | validation: 0.09681164798353806]
	TIME [epoch: 13 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11274938234795626		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.11274938234795626 | validation: 0.10382418023787349]
	TIME [epoch: 13 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10936107477802964		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.10936107477802964 | validation: 0.09530130513738785]
	TIME [epoch: 13 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08962153795647987		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.08962153795647987 | validation: 0.07834113431543561]
	TIME [epoch: 13.1 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07303073674341419		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.07303073674341419 | validation: 0.08759150674669645]
	TIME [epoch: 13 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09255264452443551		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.09255264452443551 | validation: 0.08667877386633153]
	TIME [epoch: 13 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08384766059715743		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.08384766059715743 | validation: 0.10160790259087463]
	TIME [epoch: 13.1 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09139216285091532		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.09139216285091532 | validation: 0.10675139084431105]
	TIME [epoch: 13.1 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10353094800375573		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.10353094800375573 | validation: 0.1041630003553309]
	TIME [epoch: 13 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10017202282077484		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.10017202282077484 | validation: 0.0896936119215122]
	TIME [epoch: 13.1 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08466104340798754		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.08466104340798754 | validation: 0.09594808726601275]
	TIME [epoch: 13.1 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08947506365458853		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.08947506365458853 | validation: 0.09008127362715423]
	TIME [epoch: 13 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08667121890964363		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.08667121890964363 | validation: 0.09080281847216311]
	TIME [epoch: 13 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08344821065440461		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.08344821065440461 | validation: 0.09093754212876679]
	TIME [epoch: 13 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08983822536019599		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.08983822536019599 | validation: 0.0927914780676237]
	TIME [epoch: 13.1 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07890823109093399		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.07890823109093399 | validation: 0.07780912982075662]
	TIME [epoch: 13 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07445313800647856		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.07445313800647856 | validation: 0.08125513748964085]
	TIME [epoch: 13 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06619488190245927		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.06619488190245927 | validation: 0.07582054073041415]
	TIME [epoch: 13.1 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0669200174693333		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.0669200174693333 | validation: 0.09008240747747528]
	TIME [epoch: 13 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08498455927162703		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.08498455927162703 | validation: 0.10519129182625253]
	TIME [epoch: 13 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1024943804578545		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.1024943804578545 | validation: 0.08755479064596633]
	TIME [epoch: 13 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08085972636908653		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.08085972636908653 | validation: 0.08376030238726345]
	TIME [epoch: 13.1 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07755664600268225		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.07755664600268225 | validation: 0.07913188148845415]
	TIME [epoch: 13 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07197227424340225		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.07197227424340225 | validation: 0.07442274485612377]
	TIME [epoch: 13 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07211365000961577		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.07211365000961577 | validation: 0.07059476294967826]
	TIME [epoch: 13.1 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07152560205132144		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.07152560205132144 | validation: 0.07187145491692393]
	TIME [epoch: 13.1 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07904675852132373		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.07904675852132373 | validation: 0.08948141734125095]
	TIME [epoch: 13 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08936478114642461		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.08936478114642461 | validation: 0.09972157989786354]
	TIME [epoch: 13 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08614900202063695		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.08614900202063695 | validation: 0.08482834690040436]
	TIME [epoch: 13.1 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08211875327198281		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.08211875327198281 | validation: 0.09358583726786904]
	TIME [epoch: 13 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08463577412455674		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.08463577412455674 | validation: 0.10363137260613994]
	TIME [epoch: 13 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08516984790500104		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.08516984790500104 | validation: 0.10134363275926951]
	TIME [epoch: 13.1 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08205457111645359		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.08205457111645359 | validation: 0.08039830143936176]
	TIME [epoch: 13 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08019793015320323		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.08019793015320323 | validation: 0.08194675309732961]
	TIME [epoch: 13 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07409051407440506		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.07409051407440506 | validation: 0.08702870644406606]
	TIME [epoch: 13 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.067238005792398		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.067238005792398 | validation: 0.06708684067116638]
	TIME [epoch: 13.1 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07052354137874048		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.07052354137874048 | validation: 0.07521683027156945]
	TIME [epoch: 13 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07103498685718809		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.07103498685718809 | validation: 0.08450545418991157]
	TIME [epoch: 13 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07702771632789451		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.07702771632789451 | validation: 0.11298562284745771]
	TIME [epoch: 13.1 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09021406211573242		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.09021406211573242 | validation: 0.09837464577386511]
	TIME [epoch: 13 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08040826462960157		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.08040826462960157 | validation: 0.0784964470829965]
	TIME [epoch: 13 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0774639979107745		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.0774639979107745 | validation: 0.08577401294823817]
	TIME [epoch: 13 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07803516141029528		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.07803516141029528 | validation: 0.07471800223808397]
	TIME [epoch: 13.1 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0758292635556238		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.0758292635556238 | validation: 0.0743245718041613]
	TIME [epoch: 13 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07922206363980722		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.07922206363980722 | validation: 0.0873335823862209]
	TIME [epoch: 13 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0760771298327827		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.0760771298327827 | validation: 0.08451131368160138]
	TIME [epoch: 13 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07270571294567375		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.07270571294567375 | validation: 0.07718310017415016]
	TIME [epoch: 13 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06976857466203501		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.06976857466203501 | validation: 0.08311689731530753]
	TIME [epoch: 13 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07460261495220105		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.07460261495220105 | validation: 0.07654941118007388]
	TIME [epoch: 13 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07195328658064257		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.07195328658064257 | validation: 0.08266874488454824]
	TIME [epoch: 13.1 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07466959168124655		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.07466959168124655 | validation: 0.07889635412133476]
	TIME [epoch: 13 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0666950702359745		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.0666950702359745 | validation: 0.0726760673358453]
	TIME [epoch: 13 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06648785853912208		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.06648785853912208 | validation: 0.07045876583036555]
	TIME [epoch: 13.1 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07085278671908675		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.07085278671908675 | validation: 0.07317164707147507]
	TIME [epoch: 13.1 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06977868571471985		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.06977868571471985 | validation: 0.07705707681820316]
	TIME [epoch: 13.1 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0797887987707412		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.0797887987707412 | validation: 0.09291933272866387]
	TIME [epoch: 13.1 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07823154088849384		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.07823154088849384 | validation: 0.06832234763127329]
	TIME [epoch: 13.1 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06933802157892104		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.06933802157892104 | validation: 0.08656137664271503]
	TIME [epoch: 13.1 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07265326161684268		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.07265326161684268 | validation: 0.07534025071964712]
	TIME [epoch: 13 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06352424637732909		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.06352424637732909 | validation: 0.08295986733825551]
	TIME [epoch: 13.1 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07210122230472045		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.07210122230472045 | validation: 0.08005022324277587]
	TIME [epoch: 13.1 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06855257946881706		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.06855257946881706 | validation: 0.10247451883336307]
	TIME [epoch: 13.1 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09092711140742969		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.09092711140742969 | validation: 0.1081316573503872]
	TIME [epoch: 13 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08034856381647638		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.08034856381647638 | validation: 0.09351158178160829]
	TIME [epoch: 13.1 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08267326675548006		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.08267326675548006 | validation: 0.10008735844595835]
	TIME [epoch: 13.1 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09333949537851001		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.09333949537851001 | validation: 0.10194471876889122]
	TIME [epoch: 13 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08396081244896855		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.08396081244896855 | validation: 0.07699824551624329]
	TIME [epoch: 13 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07246019253242389		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.07246019253242389 | validation: 0.07427268275653963]
	TIME [epoch: 13.1 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06975809143698578		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.06975809143698578 | validation: 0.07061906489882183]
	TIME [epoch: 13 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06272117733069253		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.06272117733069253 | validation: 0.05899324133999897]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_1117.pth
	Model improved!!!
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0630976790609228		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.0630976790609228 | validation: 0.06501178719494748]
	TIME [epoch: 13.1 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06291385093787077		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.06291385093787077 | validation: 0.0707869998040295]
	TIME [epoch: 13 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06443054281936313		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.06443054281936313 | validation: 0.07961445440675301]
	TIME [epoch: 13 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06869973211541187		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.06869973211541187 | validation: 0.08561066396316695]
	TIME [epoch: 13 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07066194728216366		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.07066194728216366 | validation: 0.07373027048570939]
	TIME [epoch: 13.1 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06949530673181001		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.06949530673181001 | validation: 0.09801626129090459]
	TIME [epoch: 13 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07776090283064839		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.07776090283064839 | validation: 0.08268294816141455]
	TIME [epoch: 13 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06856407631316978		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.06856407631316978 | validation: 0.07970008749555184]
	TIME [epoch: 13.1 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0657796039273775		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.0657796039273775 | validation: 0.07461225767487556]
	TIME [epoch: 13 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06343728747909043		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.06343728747909043 | validation: 0.07065665532551998]
	TIME [epoch: 13 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06263328208868299		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.06263328208868299 | validation: 0.0736545136436207]
	TIME [epoch: 13 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07067141966915069		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.07067141966915069 | validation: 0.0716821899067555]
	TIME [epoch: 13 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06207206334554147		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.06207206334554147 | validation: 0.073936591557361]
	TIME [epoch: 13 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06743672535190667		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.06743672535190667 | validation: 0.07862759578219504]
	TIME [epoch: 13 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07653291904258816		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.07653291904258816 | validation: 0.0824515730825778]
	TIME [epoch: 13 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08279078876777006		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.08279078876777006 | validation: 0.0950893421454968]
	TIME [epoch: 13 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07566887914120346		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.07566887914120346 | validation: 0.07416341496633215]
	TIME [epoch: 13 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062477401129478714		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.062477401129478714 | validation: 0.06757332030533642]
	TIME [epoch: 13 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06407956358784714		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.06407956358784714 | validation: 0.06773381974974842]
	TIME [epoch: 13.1 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06768715890467705		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.06768715890467705 | validation: 0.06953358872451747]
	TIME [epoch: 13.1 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06918599630975333		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.06918599630975333 | validation: 0.07912095221393897]
	TIME [epoch: 13 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07029930598797623		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.07029930598797623 | validation: 0.07427333378271367]
	TIME [epoch: 13.1 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07268101354808498		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.07268101354808498 | validation: 0.07657859818714771]
	TIME [epoch: 13.1 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07458425097426895		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.07458425097426895 | validation: 0.07634402732677817]
	TIME [epoch: 13 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07111810347601082		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.07111810347601082 | validation: 0.07818585096088185]
	TIME [epoch: 13 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06975198356910363		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.06975198356910363 | validation: 0.07351090196124627]
	TIME [epoch: 13.1 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06061703614776581		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.06061703614776581 | validation: 0.0750263527696877]
	TIME [epoch: 13 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06305946216907767		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.06305946216907767 | validation: 0.07567544883636307]
	TIME [epoch: 13 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07091103484111654		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.07091103484111654 | validation: 0.0734399215500736]
	TIME [epoch: 13.1 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07354654960756027		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.07354654960756027 | validation: 0.08708451546503146]
	TIME [epoch: 13.1 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07214599026967766		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.07214599026967766 | validation: 0.08065648512281723]
	TIME [epoch: 13 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07480650385356301		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.07480650385356301 | validation: 0.08680594927875172]
	TIME [epoch: 13 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07420064565826073		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.07420064565826073 | validation: 0.07891055319379478]
	TIME [epoch: 13.1 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06975605722452985		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.06975605722452985 | validation: 0.08261245387431838]
	TIME [epoch: 13 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06753448954785256		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.06753448954785256 | validation: 0.07277845007831854]
	TIME [epoch: 13.1 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06768602984699068		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.06768602984699068 | validation: 0.07118740778255102]
	TIME [epoch: 13.1 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07025655184490119		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.07025655184490119 | validation: 0.07447826351870802]
	TIME [epoch: 13.1 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06943246733827246		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.06943246733827246 | validation: 0.07213141744649763]
	TIME [epoch: 13 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06843038198167652		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.06843038198167652 | validation: 0.08414007462974787]
	TIME [epoch: 13 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0740656967622289		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.0740656967622289 | validation: 0.07500800230354787]
	TIME [epoch: 13.1 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0757676127622581		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.0757676127622581 | validation: 0.0774626489918066]
	TIME [epoch: 13 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06910087275133937		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.06910087275133937 | validation: 0.067170145928549]
	TIME [epoch: 13 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06687181336694273		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.06687181336694273 | validation: 0.07927234307859993]
	TIME [epoch: 13.1 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0698337434202063		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.0698337434202063 | validation: 0.07116251050466499]
	TIME [epoch: 13 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0667529462662575		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.0667529462662575 | validation: 0.06882509943769685]
	TIME [epoch: 13 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08081625166409846		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.08081625166409846 | validation: 0.0721821250708203]
	TIME [epoch: 13 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07242489123779308		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.07242489123779308 | validation: 0.08056284212913525]
	TIME [epoch: 13.1 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07630492686611286		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.07630492686611286 | validation: 0.08117765910649384]
	TIME [epoch: 13 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07498660757681558		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.07498660757681558 | validation: 0.08175954007374518]
	TIME [epoch: 13 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07150884693051228		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.07150884693051228 | validation: 0.07085388022370742]
	TIME [epoch: 13.1 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06286674779034582		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.06286674779034582 | validation: 0.0711914065551204]
	TIME [epoch: 13.1 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06649378610916891		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.06649378610916891 | validation: 0.06456032039635533]
	TIME [epoch: 13 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06380274598373384		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.06380274598373384 | validation: 0.07365705554909809]
	TIME [epoch: 13 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062215137762400056		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.062215137762400056 | validation: 0.07424835083656019]
	TIME [epoch: 13.1 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06052019830371963		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.06052019830371963 | validation: 0.06468926546224849]
	TIME [epoch: 13 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06247825855046706		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.06247825855046706 | validation: 0.06382288861932421]
	TIME [epoch: 13 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061573726701189546		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.061573726701189546 | validation: 0.07347912276166471]
	TIME [epoch: 13 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06599100026583771		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.06599100026583771 | validation: 0.07401215813212111]
	TIME [epoch: 13.1 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06378654341101898		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.06378654341101898 | validation: 0.07756418438836372]
	TIME [epoch: 13 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06611618116383633		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.06611618116383633 | validation: 0.07811054574051467]
	TIME [epoch: 13 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07254530045837773		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.07254530045837773 | validation: 0.07075910230100925]
	TIME [epoch: 13.1 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07084793699476821		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.07084793699476821 | validation: 0.0740901933413324]
	TIME [epoch: 13 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07230657971352383		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.07230657971352383 | validation: 0.07851888797466507]
	TIME [epoch: 13 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08066146832604132		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.08066146832604132 | validation: 0.10297671859237927]
	TIME [epoch: 13 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08222705637668709		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.08222705637668709 | validation: 0.08503126600858947]
	TIME [epoch: 13.1 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07734229402810089		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.07734229402810089 | validation: 0.0877823761930944]
	TIME [epoch: 13 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07481395174225902		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.07481395174225902 | validation: 0.07607238565395198]
	TIME [epoch: 13 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0793356057686683		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.0793356057686683 | validation: 0.08327505874693003]
	TIME [epoch: 13.1 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07345471153890856		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.07345471153890856 | validation: 0.07844831412862054]
	TIME [epoch: 13 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07331174154709036		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.07331174154709036 | validation: 0.07604424431574425]
	TIME [epoch: 13 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07084605692740215		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.07084605692740215 | validation: 0.07910898966847808]
	TIME [epoch: 13 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06740630230110708		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.06740630230110708 | validation: 0.0719367418076003]
	TIME [epoch: 13.1 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07169044110600752		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.07169044110600752 | validation: 0.07502163852127659]
	TIME [epoch: 13 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06605594147437008		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.06605594147437008 | validation: 0.06631211783423963]
	TIME [epoch: 13 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06990138932775654		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.06990138932775654 | validation: 0.0735112614894155]
	TIME [epoch: 13.1 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06940483545085942		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.06940483545085942 | validation: 0.0747910859926579]
	TIME [epoch: 13 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06716283868189363		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.06716283868189363 | validation: 0.06977015805198619]
	TIME [epoch: 13 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07050246232559534		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.07050246232559534 | validation: 0.07181294400029863]
	TIME [epoch: 13 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06996691773209451		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.06996691773209451 | validation: 0.06992909892560517]
	TIME [epoch: 13.1 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06607096188140302		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.06607096188140302 | validation: 0.06575604381030932]
	TIME [epoch: 13 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06828764280351897		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.06828764280351897 | validation: 0.07434129587029353]
	TIME [epoch: 13 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.069993795480711		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.069993795480711 | validation: 0.07433669727406157]
	TIME [epoch: 13.1 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06332320509268786		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.06332320509268786 | validation: 0.0725789014396807]
	TIME [epoch: 13 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0631094417849703		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.0631094417849703 | validation: 0.07369801555285502]
	TIME [epoch: 13 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06877456523280605		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.06877456523280605 | validation: 0.07498701647401056]
	TIME [epoch: 13 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07277555166424113		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.07277555166424113 | validation: 0.08504878801876915]
	TIME [epoch: 13.1 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07143407535964238		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.07143407535964238 | validation: 0.06969604174538781]
	TIME [epoch: 13 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06853764352965377		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.06853764352965377 | validation: 0.07118611697355587]
	TIME [epoch: 13 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06582802923431197		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.06582802923431197 | validation: 0.08273719291987737]
	TIME [epoch: 13.1 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07152232222910078		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.07152232222910078 | validation: 0.07593507664632794]
	TIME [epoch: 13.1 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06261797417232354		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.06261797417232354 | validation: 0.06899160752992105]
	TIME [epoch: 13.1 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06103559746650305		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.06103559746650305 | validation: 0.07595896798291843]
	TIME [epoch: 13.1 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06164595677680086		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.06164595677680086 | validation: 0.06752646443405157]
	TIME [epoch: 13.1 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06501872342330814		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.06501872342330814 | validation: 0.07096701085116705]
	TIME [epoch: 13.1 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06551457704654104		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.06551457704654104 | validation: 0.06432126445414901]
	TIME [epoch: 13.1 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07077548690721064		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.07077548690721064 | validation: 0.06982437568657908]
	TIME [epoch: 13.1 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06568008227661579		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.06568008227661579 | validation: 0.07236597508171035]
	TIME [epoch: 13.1 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07609147119959286		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.07609147119959286 | validation: 0.08711155668526989]
	TIME [epoch: 13.1 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07445936838048159		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.07445936838048159 | validation: 0.06462006497985144]
	TIME [epoch: 13.1 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06436863940504245		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.06436863940504245 | validation: 0.06657932720279722]
	TIME [epoch: 13.1 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05907453270972534		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.05907453270972534 | validation: 0.06956305859905769]
	TIME [epoch: 13 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06123791464183553		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.06123791464183553 | validation: 0.07188561777559191]
	TIME [epoch: 13 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06521326654357541		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.06521326654357541 | validation: 0.06713214437300814]
	TIME [epoch: 13.1 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0587255972044246		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.0587255972044246 | validation: 0.066018287920178]
	TIME [epoch: 13.1 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057170992146442376		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.057170992146442376 | validation: 0.061923517771316786]
	TIME [epoch: 13.1 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05661337706815617		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.05661337706815617 | validation: 0.06556904318973296]
	TIME [epoch: 13 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06187937966117135		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.06187937966117135 | validation: 0.07260780588548263]
	TIME [epoch: 13.1 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05903293758141134		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.05903293758141134 | validation: 0.0652956427456245]
	TIME [epoch: 13 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05889045549958078		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.05889045549958078 | validation: 0.06652502625718179]
	TIME [epoch: 13 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06511409118990139		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.06511409118990139 | validation: 0.06744860668210657]
	TIME [epoch: 13 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06812131214842229		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.06812131214842229 | validation: 0.07621192210753777]
	TIME [epoch: 13.1 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06131658534763793		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.06131658534763793 | validation: 0.06863779753834086]
	TIME [epoch: 13 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058761553786523		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.058761553786523 | validation: 0.06304901310812325]
	TIME [epoch: 13 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06084450734313778		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.06084450734313778 | validation: 0.06806943516879406]
	TIME [epoch: 13.1 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060208371034130875		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.060208371034130875 | validation: 0.06332848346162075]
	TIME [epoch: 13 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05796862886396344		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.05796862886396344 | validation: 0.0627125787817994]
	TIME [epoch: 13 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06159175233678615		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.06159175233678615 | validation: 0.07117262146212064]
	TIME [epoch: 13 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06859727107111196		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.06859727107111196 | validation: 0.07617649006731163]
	TIME [epoch: 13.1 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0624584570951049		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.0624584570951049 | validation: 0.06282487398954871]
	TIME [epoch: 13 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05564085732514884		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.05564085732514884 | validation: 0.05823081828929137]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_1237.pth
	Model improved!!!
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058781567771216715		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.058781567771216715 | validation: 0.06424758643976185]
	TIME [epoch: 13.1 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05957375529724363		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.05957375529724363 | validation: 0.05971214435696537]
	TIME [epoch: 13 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06108987208088208		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.06108987208088208 | validation: 0.06441221466364062]
	TIME [epoch: 13 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06170018798284477		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.06170018798284477 | validation: 0.07977159228352786]
	TIME [epoch: 13 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06374574522726839		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.06374574522726839 | validation: 0.07246365366886937]
	TIME [epoch: 13.1 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06054911215822813		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.06054911215822813 | validation: 0.06738304857611115]
	TIME [epoch: 13 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0617722146378195		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.0617722146378195 | validation: 0.07190584097712337]
	TIME [epoch: 13 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06189540813147809		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.06189540813147809 | validation: 0.07270388543534373]
	TIME [epoch: 13.1 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06177897869785978		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.06177897869785978 | validation: 0.0699400799505149]
	TIME [epoch: 13 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06879900348876221		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.06879900348876221 | validation: 0.08499075256777744]
	TIME [epoch: 13 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07008363468805609		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.07008363468805609 | validation: 0.06913727929180498]
	TIME [epoch: 13 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06637607263746265		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.06637607263746265 | validation: 0.07313967004187205]
	TIME [epoch: 13.1 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05994667529537111		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.05994667529537111 | validation: 0.06278418217874646]
	TIME [epoch: 13 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05848135529659549		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.05848135529659549 | validation: 0.06417517191797341]
	TIME [epoch: 13 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057577200155849585		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.057577200155849585 | validation: 0.07010888970083594]
	TIME [epoch: 13.1 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05787698659536547		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.05787698659536547 | validation: 0.07551480281241277]
	TIME [epoch: 13 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.064357040555814		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.064357040555814 | validation: 0.07384094131387563]
	TIME [epoch: 13 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06478768841453483		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.06478768841453483 | validation: 0.07202485724450236]
	TIME [epoch: 13 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05991107241670995		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.05991107241670995 | validation: 0.07329790417729339]
	TIME [epoch: 13.1 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059934451642578684		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.059934451642578684 | validation: 0.07462615682210384]
	TIME [epoch: 13 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06182677355654827		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.06182677355654827 | validation: 0.06466089714695156]
	TIME [epoch: 13 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05621324861986162		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.05621324861986162 | validation: 0.05976968121063779]
	TIME [epoch: 13 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054851081461936915		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.054851081461936915 | validation: 0.06532141450433035]
	TIME [epoch: 13 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059086474353696974		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.059086474353696974 | validation: 0.0617105042665972]
	TIME [epoch: 13 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06094660375803185		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.06094660375803185 | validation: 0.059681439287880174]
	TIME [epoch: 13 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06118701062275073		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.06118701062275073 | validation: 0.06322441408400312]
	TIME [epoch: 13 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06788121301194418		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.06788121301194418 | validation: 0.0676622572943011]
	TIME [epoch: 13 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06392305080668262		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.06392305080668262 | validation: 0.06533245328566227]
	TIME [epoch: 13 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0626678557331581		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.0626678557331581 | validation: 0.06513159847391496]
	TIME [epoch: 13 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06188727989115487		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.06188727989115487 | validation: 0.06289165940648869]
	TIME [epoch: 13 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05951740229844019		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.05951740229844019 | validation: 0.059540019998361816]
	TIME [epoch: 13 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06181116092021566		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.06181116092021566 | validation: 0.07024020192098748]
	TIME [epoch: 13 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05872558561226275		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.05872558561226275 | validation: 0.06595926322367149]
	TIME [epoch: 13.1 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06283070101220234		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.06283070101220234 | validation: 0.06139690430119057]
	TIME [epoch: 13 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059334960978847016		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.059334960978847016 | validation: 0.07168207652413544]
	TIME [epoch: 13 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06684841677167679		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.06684841677167679 | validation: 0.08328282293672809]
	TIME [epoch: 13.1 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06945647912267236		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.06945647912267236 | validation: 0.08165627827786075]
	TIME [epoch: 13.1 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07288896682559282		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.07288896682559282 | validation: 0.07231936335280995]
	TIME [epoch: 13.1 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06580690245809148		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.06580690245809148 | validation: 0.07522991314299671]
	TIME [epoch: 13.1 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06438398929609676		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.06438398929609676 | validation: 0.06633592500110366]
	TIME [epoch: 13.1 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05864754472025148		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.05864754472025148 | validation: 0.06452878818169153]
	TIME [epoch: 13 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05680922613634188		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.05680922613634188 | validation: 0.061745303031283894]
	TIME [epoch: 13 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05603542461493192		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.05603542461493192 | validation: 0.06264815395266482]
	TIME [epoch: 13.1 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056920121747549665		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.056920121747549665 | validation: 0.0556726847715962]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_1281.pth
	Model improved!!!
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06340600733388166		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.06340600733388166 | validation: 0.0767412723416293]
	TIME [epoch: 13 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06255691855938675		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.06255691855938675 | validation: 0.07253545014509297]
	TIME [epoch: 13.1 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062386906152381405		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.062386906152381405 | validation: 0.06455337235246915]
	TIME [epoch: 13.1 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05960102010152191		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.05960102010152191 | validation: 0.06348222082928212]
	TIME [epoch: 13 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06057029275384877		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.06057029275384877 | validation: 0.06128339417850546]
	TIME [epoch: 13.1 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05383377024210589		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.05383377024210589 | validation: 0.0660120945566278]
	TIME [epoch: 13.1 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05764057913968896		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.05764057913968896 | validation: 0.0644955603370044]
	TIME [epoch: 13.1 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060277154267510666		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.060277154267510666 | validation: 0.06212637487692778]
	TIME [epoch: 13 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060890549229608466		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.060890549229608466 | validation: 0.06536664848478442]
	TIME [epoch: 13.1 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05966212567482097		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.05966212567482097 | validation: 0.06306206968056043]
	TIME [epoch: 13.1 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05596881335788164		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.05596881335788164 | validation: 0.06352119894882112]
	TIME [epoch: 13.1 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05724550346345281		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.05724550346345281 | validation: 0.0615728599443238]
	TIME [epoch: 13.1 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05299895678616469		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.05299895678616469 | validation: 0.06101519944459652]
	TIME [epoch: 13.1 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058426974328563766		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.058426974328563766 | validation: 0.07281279187587943]
	TIME [epoch: 13.1 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052875256340475754		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.052875256340475754 | validation: 0.0628101883130281]
	TIME [epoch: 13 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05653424900958482		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.05653424900958482 | validation: 0.06365234642897641]
	TIME [epoch: 13 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05916193441141364		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.05916193441141364 | validation: 0.06494635978673055]
	TIME [epoch: 13.1 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05689434445919338		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.05689434445919338 | validation: 0.06451374008148394]
	TIME [epoch: 13 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06132361486043374		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.06132361486043374 | validation: 0.0680948949851376]
	TIME [epoch: 13.1 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060430155967753606		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.060430155967753606 | validation: 0.06314919642353083]
	TIME [epoch: 13 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05775906336950318		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.05775906336950318 | validation: 0.06787035588401608]
	TIME [epoch: 13.1 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05348041828276344		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.05348041828276344 | validation: 0.06910114048139565]
	TIME [epoch: 13 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05537331856753727		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.05537331856753727 | validation: 0.052834872576239145]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_1304.pth
	Model improved!!!
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052870976426346805		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.052870976426346805 | validation: 0.06229166857220321]
	TIME [epoch: 13.1 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05373069815797256		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.05373069815797256 | validation: 0.066328324689298]
	TIME [epoch: 13 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0575233224322638		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.0575233224322638 | validation: 0.06120349059100423]
	TIME [epoch: 13 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05732611224627007		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.05732611224627007 | validation: 0.06465418484825879]
	TIME [epoch: 13 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056647155914425006		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.056647155914425006 | validation: 0.06479641546502363]
	TIME [epoch: 13.1 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05744781762760018		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.05744781762760018 | validation: 0.05838809588590464]
	TIME [epoch: 13 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05898499845291276		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.05898499845291276 | validation: 0.06354993551313017]
	TIME [epoch: 13 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05812627331451724		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.05812627331451724 | validation: 0.06818671239753611]
	TIME [epoch: 13.1 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05654669626026145		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.05654669626026145 | validation: 0.0630533063920882]
	TIME [epoch: 13 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06004441331545802		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.06004441331545802 | validation: 0.06663799713364982]
	TIME [epoch: 13 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057030560014316695		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.057030560014316695 | validation: 0.06688315285098966]
	TIME [epoch: 13 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05729299021115447		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.05729299021115447 | validation: 0.06253596999660266]
	TIME [epoch: 13.1 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05549565522959707		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.05549565522959707 | validation: 0.06319323077443433]
	TIME [epoch: 13 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05897636808085964		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.05897636808085964 | validation: 0.05578701967088954]
	TIME [epoch: 13 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057447485748503294		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.057447485748503294 | validation: 0.05897234049345551]
	TIME [epoch: 13.1 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05723572744140687		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.05723572744140687 | validation: 0.06545267352758072]
	TIME [epoch: 13.1 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05908797886017153		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.05908797886017153 | validation: 0.06444867131851517]
	TIME [epoch: 13 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05588977557509845		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.05588977557509845 | validation: 0.05603003223737091]
	TIME [epoch: 13 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0563687583093809		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.0563687583093809 | validation: 0.06134767492122798]
	TIME [epoch: 13.1 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05408758487136466		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.05408758487136466 | validation: 0.06454435836202467]
	TIME [epoch: 13 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05782681510929242		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.05782681510929242 | validation: 0.06521456560678016]
	TIME [epoch: 13 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061923444825123845		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.061923444825123845 | validation: 0.06821775674583078]
	TIME [epoch: 13.1 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06399210858243495		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.06399210858243495 | validation: 0.06808474048129258]
	TIME [epoch: 13.1 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06321116460905885		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.06321116460905885 | validation: 0.06620065101957921]
	TIME [epoch: 13 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06582489496814851		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.06582489496814851 | validation: 0.07048773953930161]
	TIME [epoch: 13 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06056198618635781		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.06056198618635781 | validation: 0.06694645244490785]
	TIME [epoch: 13.1 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0593197223874319		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.0593197223874319 | validation: 0.07054145031999826]
	TIME [epoch: 13 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05948630410697525		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.05948630410697525 | validation: 0.07309776793781919]
	TIME [epoch: 13 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05983418209294975		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.05983418209294975 | validation: 0.07234874161314975]
	TIME [epoch: 13.1 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055659640333108454		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.055659640333108454 | validation: 0.06301947737928387]
	TIME [epoch: 13.1 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06302934995523962		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.06302934995523962 | validation: 0.0655137116989291]
	TIME [epoch: 13 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0638458866465081		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.0638458866465081 | validation: 0.057895867549957285]
	TIME [epoch: 13 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06263028413190212		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.06263028413190212 | validation: 0.0716109595372783]
	TIME [epoch: 13.1 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06051615503367365		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.06051615503367365 | validation: 0.06614861405035612]
	TIME [epoch: 13 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0582731907181252		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.0582731907181252 | validation: 0.06059474050075478]
	TIME [epoch: 13 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0653530915325785		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.0653530915325785 | validation: 0.072372007122575]
	TIME [epoch: 13.1 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06788867357964978		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.06788867357964978 | validation: 0.07288868888607461]
	TIME [epoch: 13 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.074179602998242		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.074179602998242 | validation: 0.06963088357922549]
	TIME [epoch: 13 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07523010011631565		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.07523010011631565 | validation: 0.07312403128885173]
	TIME [epoch: 13 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07603523647064056		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.07603523647064056 | validation: 0.0701126320245964]
	TIME [epoch: 13.1 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06579790197274377		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.06579790197274377 | validation: 0.07371426342149083]
	TIME [epoch: 13 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07468286356667944		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.07468286356667944 | validation: 0.07258386284553027]
	TIME [epoch: 13 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07321756115356454		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.07321756115356454 | validation: 0.067034192532936]
	TIME [epoch: 13.1 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06868449750773642		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.06868449750773642 | validation: 0.07880383603852847]
	TIME [epoch: 13 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07439463380569307		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.07439463380569307 | validation: 0.06590302830752046]
	TIME [epoch: 13 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06714480969052501		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.06714480969052501 | validation: 0.064701642348217]
	TIME [epoch: 13 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06118088522312878		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.06118088522312878 | validation: 0.0750225559643825]
	TIME [epoch: 13.1 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0637016773024672		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.0637016773024672 | validation: 0.06493036312196407]
	TIME [epoch: 13 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06117666614451628		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.06117666614451628 | validation: 0.06751384196736802]
	TIME [epoch: 13 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06401968614324804		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.06401968614324804 | validation: 0.07513485116135728]
	TIME [epoch: 13 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05733636938683976		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.05733636938683976 | validation: 0.06264551240012722]
	TIME [epoch: 13.1 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06482647379611087		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.06482647379611087 | validation: 0.07271797689530832]
	TIME [epoch: 13 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05836817355026647		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.05836817355026647 | validation: 0.06440718387922106]
	TIME [epoch: 13 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06139947186138145		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.06139947186138145 | validation: 0.06616647710856614]
	TIME [epoch: 13.1 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05972439776602985		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.05972439776602985 | validation: 0.06277535229255486]
	TIME [epoch: 13.1 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05707688221567246		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.05707688221567246 | validation: 0.06741315038521466]
	TIME [epoch: 13 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05760772154628876		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.05760772154628876 | validation: 0.06636277629294972]
	TIME [epoch: 13 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05790090717834038		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.05790090717834038 | validation: 0.06763859830512342]
	TIME [epoch: 13.1 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05903378450473026		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.05903378450473026 | validation: 0.07185039509826466]
	TIME [epoch: 13 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06704232989956704		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.06704232989956704 | validation: 0.06618918569083877]
	TIME [epoch: 13 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059556896206895665		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.059556896206895665 | validation: 0.06643209800284636]
	TIME [epoch: 13.1 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06063028081895002		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.06063028081895002 | validation: 0.06553122810806483]
	TIME [epoch: 13 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05523490760630078		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.05523490760630078 | validation: 0.06828998849233031]
	TIME [epoch: 13 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058952413548805205		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.058952413548805205 | validation: 0.06413690727678231]
	TIME [epoch: 13.1 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06166024331975255		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.06166024331975255 | validation: 0.06189501942711168]
	TIME [epoch: 13.1 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056225188318314495		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.056225188318314495 | validation: 0.06095619974958166]
	TIME [epoch: 13.1 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0553663369013803		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.0553663369013803 | validation: 0.0648379053455096]
	TIME [epoch: 13.1 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05993240692271641		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.05993240692271641 | validation: 0.06394528198187095]
	TIME [epoch: 13.1 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05815837166287787		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.05815837166287787 | validation: 0.061077516975085795]
	TIME [epoch: 13.1 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058734387537309335		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.058734387537309335 | validation: 0.06626467859185996]
	TIME [epoch: 13.1 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054654451916189256		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.054654451916189256 | validation: 0.06573643159311733]
	TIME [epoch: 13.1 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05537690731179901		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.05537690731179901 | validation: 0.06819333990359992]
	TIME [epoch: 13.1 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05448293931979811		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.05448293931979811 | validation: 0.06728049933210238]
	TIME [epoch: 13 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05775553987875319		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.05775553987875319 | validation: 0.060527522572217225]
	TIME [epoch: 13 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05501742069637647		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.05501742069637647 | validation: 0.06189601113198033]
	TIME [epoch: 13.1 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05754933893475563		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.05754933893475563 | validation: 0.0572707200894537]
	TIME [epoch: 13 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057937906173371925		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.057937906173371925 | validation: 0.06451950997768113]
	TIME [epoch: 13 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05605772040199291		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.05605772040199291 | validation: 0.05982504266638505]
	TIME [epoch: 13 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05085368138649435		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.05085368138649435 | validation: 0.06045794131986902]
	TIME [epoch: 13.1 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05647997954966914		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.05647997954966914 | validation: 0.058875813216388115]
	TIME [epoch: 13 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055267424962806316		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.055267424962806316 | validation: 0.06692743434712317]
	TIME [epoch: 13 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06270048684177411		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.06270048684177411 | validation: 0.07049937442613902]
	TIME [epoch: 13.1 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057969026371087765		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.057969026371087765 | validation: 0.0609987478320196]
	TIME [epoch: 13 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056850124242023424		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.056850124242023424 | validation: 0.06579656199552752]
	TIME [epoch: 13 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05927007624745838		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.05927007624745838 | validation: 0.06649532386488602]
	TIME [epoch: 13 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05594073401738572		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.05594073401738572 | validation: 0.06968329330703782]
	TIME [epoch: 13.1 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05924005114490084		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.05924005114490084 | validation: 0.06960968425951614]
	TIME [epoch: 13 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06023182956265845		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.06023182956265845 | validation: 0.06748958600423548]
	TIME [epoch: 13 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06416551356748981		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.06416551356748981 | validation: 0.07297577781552735]
	TIME [epoch: 13.1 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05927004348964349		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.05927004348964349 | validation: 0.07126095509745138]
	TIME [epoch: 13 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06162555032977003		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.06162555032977003 | validation: 0.062234675096602084]
	TIME [epoch: 13 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061895103111195914		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.061895103111195914 | validation: 0.0736253368753326]
	TIME [epoch: 13 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06316219785329508		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.06316219785329508 | validation: 0.07693456322853674]
	TIME [epoch: 13.1 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06375425542264151		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.06375425542264151 | validation: 0.06436982902945207]
	TIME [epoch: 13 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06324416510033082		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.06324416510033082 | validation: 0.07654874560454843]
	TIME [epoch: 13 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06867381870222444		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.06867381870222444 | validation: 0.06892849134017508]
	TIME [epoch: 13.1 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06490792306965001		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.06490792306965001 | validation: 0.06978031470185919]
	TIME [epoch: 13 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060315887769975915		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.060315887769975915 | validation: 0.06428919545830995]
	TIME [epoch: 13 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059371403281967015		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.059371403281967015 | validation: 0.07030899409918512]
	TIME [epoch: 13 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06259222104624786		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.06259222104624786 | validation: 0.06471116308621967]
	TIME [epoch: 13.1 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0609536454463272		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.0609536454463272 | validation: 0.07410810311943905]
	TIME [epoch: 13 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06288066487210889		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.06288066487210889 | validation: 0.07118193449168606]
	TIME [epoch: 13 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06010388198120782		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.06010388198120782 | validation: 0.06257375998850154]
	TIME [epoch: 13.1 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.066001897228424		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.066001897228424 | validation: 0.06624935426000195]
	TIME [epoch: 13.1 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05626549065893975		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.05626549065893975 | validation: 0.07329758421859942]
	TIME [epoch: 13 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061173666849338726		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.061173666849338726 | validation: 0.07769931114774395]
	TIME [epoch: 13 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0662422593754356		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.0662422593754356 | validation: 0.07695616967525352]
	TIME [epoch: 13.1 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06720061728348498		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.06720061728348498 | validation: 0.06895543378519962]
	TIME [epoch: 13 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06636601578987343		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.06636601578987343 | validation: 0.07391019669333738]
	TIME [epoch: 13 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06825891096126463		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.06825891096126463 | validation: 0.06864110198508983]
	TIME [epoch: 13 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.063166983318386		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.063166983318386 | validation: 0.06536883096816881]
	TIME [epoch: 13.1 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05556287345286504		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.05556287345286504 | validation: 0.0688965548264219]
	TIME [epoch: 13 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0620735003832588		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.0620735003832588 | validation: 0.058101133766668304]
	TIME [epoch: 13 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059069605964651654		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.059069605964651654 | validation: 0.05701754256145239]
	TIME [epoch: 13.1 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057641781737007444		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.057641781737007444 | validation: 0.06542877569081261]
	TIME [epoch: 13 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05747813597829032		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.05747813597829032 | validation: 0.07227259140745396]
	TIME [epoch: 13 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05578872215452611		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.05578872215452611 | validation: 0.06606897697767607]
	TIME [epoch: 13 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055650696732879666		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.055650696732879666 | validation: 0.06141117080132528]
	TIME [epoch: 13.1 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05892794459111418		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.05892794459111418 | validation: 0.061454666875600895]
	TIME [epoch: 13 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05750181688652468		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.05750181688652468 | validation: 0.06775058282984829]
	TIME [epoch: 13 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060769021953885574		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.060769021953885574 | validation: 0.060999855488908745]
	TIME [epoch: 13.1 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06164533697321048		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.06164533697321048 | validation: 0.06267513232684706]
	TIME [epoch: 13 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060123814130455415		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.060123814130455415 | validation: 0.0639089991376599]
	TIME [epoch: 13 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062315511016849		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.062315511016849 | validation: 0.06858659100044362]
	TIME [epoch: 13 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060316851729902185		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.060316851729902185 | validation: 0.06996153051889271]
	TIME [epoch: 13.1 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057575703655896274		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.057575703655896274 | validation: 0.0602561031746562]
	TIME [epoch: 13 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059174823702959164		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.059174823702959164 | validation: 0.061897220944217006]
	TIME [epoch: 13 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05723328372660453		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.05723328372660453 | validation: 0.06722580252445569]
	TIME [epoch: 13.1 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05874094515356127		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.05874094515356127 | validation: 0.07103108597899886]
	TIME [epoch: 13 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0569908848945366		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.0569908848945366 | validation: 0.05876792357399655]
	TIME [epoch: 13 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05135477309214348		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.05135477309214348 | validation: 0.06512548798214342]
	TIME [epoch: 13 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05416952013579508		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.05416952013579508 | validation: 0.06476957888500687]
	TIME [epoch: 13.1 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056365837899012436		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.056365837899012436 | validation: 0.0608910898414871]
	TIME [epoch: 13 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05856817739933765		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.05856817739933765 | validation: 0.062069755087229485]
	TIME [epoch: 13 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053978573864662795		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.053978573864662795 | validation: 0.059617340983526994]
	TIME [epoch: 13.1 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0555310454465367		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.0555310454465367 | validation: 0.07284036734228559]
	TIME [epoch: 13 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05506105321142438		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.05506105321142438 | validation: 0.06351063983005811]
	TIME [epoch: 13 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05952654212841907		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.05952654212841907 | validation: 0.07087485722377843]
	TIME [epoch: 13 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05528217627703103		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.05528217627703103 | validation: 0.059010944506950484]
	TIME [epoch: 13.1 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05984676328806434		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.05984676328806434 | validation: 0.06037315578131619]
	TIME [epoch: 13 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057371436933137135		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.057371436933137135 | validation: 0.06323858741989394]
	TIME [epoch: 13 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05617070199378484		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.05617070199378484 | validation: 0.06664163279101909]
	TIME [epoch: 13.1 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05649080975034408		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.05649080975034408 | validation: 0.0588693149903928]
	TIME [epoch: 13.1 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060811400808315166		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.060811400808315166 | validation: 0.06155018049305804]
	TIME [epoch: 13 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05986658185452097		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.05986658185452097 | validation: 0.06899380685395552]
	TIME [epoch: 13 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057557341405299584		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.057557341405299584 | validation: 0.061285632716662736]
	TIME [epoch: 13.1 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06044039830904682		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.06044039830904682 | validation: 0.0617275130067585]
	TIME [epoch: 13 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06062498285012888		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.06062498285012888 | validation: 0.07707178655941264]
	TIME [epoch: 13 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05944350343061616		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.05944350343061616 | validation: 0.07289372820311549]
	TIME [epoch: 13.1 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0642945152517526		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.0642945152517526 | validation: 0.06670692208670896]
	TIME [epoch: 13.1 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06043591700199666		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.06043591700199666 | validation: 0.0695960830831592]
	TIME [epoch: 13 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06307548539879475		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.06307548539879475 | validation: 0.06574682294069342]
	TIME [epoch: 13 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06109985696677307		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.06109985696677307 | validation: 0.0629762560419473]
	TIME [epoch: 13.1 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05318537448607273		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.05318537448607273 | validation: 0.06659461861794647]
	TIME [epoch: 13 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05816815861822727		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.05816815861822727 | validation: 0.06660729821186355]
	TIME [epoch: 13 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058540724014117196		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.058540724014117196 | validation: 0.06444512951439771]
	TIME [epoch: 13.1 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05595553672675589		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.05595553672675589 | validation: 0.06056416736819743]
	TIME [epoch: 13 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05419235485931185		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.05419235485931185 | validation: 0.0629898188088047]
	TIME [epoch: 13 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05843711188921649		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.05843711188921649 | validation: 0.06398707670974425]
	TIME [epoch: 13 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05915605805843657		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.05915605805843657 | validation: 0.06230107413779593]
	TIME [epoch: 13.1 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05804862463493746		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.05804862463493746 | validation: 0.06752975170626473]
	TIME [epoch: 13 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059418984764159466		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.059418984764159466 | validation: 0.06932184888015376]
	TIME [epoch: 13 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06321399347224287		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.06321399347224287 | validation: 0.07549593045184592]
	TIME [epoch: 13 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06840534487781433		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.06840534487781433 | validation: 0.06951393538360906]
	TIME [epoch: 13.1 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.068541907787091		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.068541907787091 | validation: 0.0890762582357241]
	TIME [epoch: 13 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06937977171856954		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.06937977171856954 | validation: 0.08454609314609761]
	TIME [epoch: 13 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06889611214211956		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.06889611214211956 | validation: 0.08769223576206607]
	TIME [epoch: 13.1 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07355117940512204		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.07355117940512204 | validation: 0.08677641675103832]
	TIME [epoch: 13 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06706901830854888		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.06706901830854888 | validation: 0.08295555469658629]
	TIME [epoch: 13 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06737575398127742		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.06737575398127742 | validation: 0.07832215667580815]
	TIME [epoch: 13 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06161317611184616		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.06161317611184616 | validation: 0.07851218494380133]
	TIME [epoch: 13.1 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06116790743781425		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.06116790743781425 | validation: 0.06881456861391297]
	TIME [epoch: 13 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05967708464647914		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.05967708464647914 | validation: 0.07132442167713761]
	TIME [epoch: 13 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06204103062238706		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.06204103062238706 | validation: 0.06657017686992578]
	TIME [epoch: 13.1 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06005671242100406		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.06005671242100406 | validation: 0.07027795541521091]
	TIME [epoch: 13 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0636696293192342		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.0636696293192342 | validation: 0.06442757877313966]
	TIME [epoch: 13 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0669881579953029		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.0669881579953029 | validation: 0.07641078712186568]
	TIME [epoch: 13 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06490078334386176		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.06490078334386176 | validation: 0.07007159497775457]
	TIME [epoch: 13.1 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06142907066060338		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.06142907066060338 | validation: 0.07398025713765569]
	TIME [epoch: 13 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059927221291968626		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.059927221291968626 | validation: 0.07215193384922501]
	TIME [epoch: 13 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05854683816824994		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.05854683816824994 | validation: 0.07195828651769719]
	TIME [epoch: 13.1 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058094288854692006		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.058094288854692006 | validation: 0.06198808783933947]
	TIME [epoch: 13 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05169078309614393		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.05169078309614393 | validation: 0.06239681346154475]
	TIME [epoch: 13 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052862236055511186		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.052862236055511186 | validation: 0.05964152068444907]
	TIME [epoch: 13 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05307070218961141		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.05307070218961141 | validation: 0.058835084939259846]
	TIME [epoch: 13.1 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053281980649206584		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.053281980649206584 | validation: 0.06496193002995547]
	TIME [epoch: 13 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05405021658443056		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.05405021658443056 | validation: 0.05542180808640116]
	TIME [epoch: 13 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05481279371235525		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.05481279371235525 | validation: 0.056333077523426256]
	TIME [epoch: 13.1 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05345298733594278		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.05345298733594278 | validation: 0.0568109675687837]
	TIME [epoch: 13.1 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050050437652482495		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.050050437652482495 | validation: 0.06303166181627982]
	TIME [epoch: 13.1 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05556985372390927		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.05556985372390927 | validation: 0.051836484231015265]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_1495.pth
	Model improved!!!
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05497792360271993		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.05497792360271993 | validation: 0.06807346025685208]
	TIME [epoch: 13.1 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05421600149776872		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.05421600149776872 | validation: 0.05305953930205329]
	TIME [epoch: 13 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04924387551187702		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.04924387551187702 | validation: 0.06321870952283329]
	TIME [epoch: 13 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054491540910010725		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.054491540910010725 | validation: 0.06396468402815833]
	TIME [epoch: 13.1 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055825119367338055		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.055825119367338055 | validation: 0.05212845338064704]
	TIME [epoch: 13.1 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05377875019365124		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.05377875019365124 | validation: 0.06194521964885162]
	TIME [epoch: 13 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05464488615357736		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.05464488615357736 | validation: 0.0686535226851006]
	TIME [epoch: 13 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05062151728825201		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.05062151728825201 | validation: 0.055399158324726416]
	TIME [epoch: 13.1 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05231026419362217		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.05231026419362217 | validation: 0.06693136014619727]
	TIME [epoch: 13 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05264800080027241		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.05264800080027241 | validation: 0.06153912767290152]
	TIME [epoch: 13 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058935950894942926		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.058935950894942926 | validation: 0.06116068969121741]
	TIME [epoch: 13.1 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05711134113995145		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.05711134113995145 | validation: 0.058616435160614544]
	TIME [epoch: 13.1 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056222009531109327		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.056222009531109327 | validation: 0.06810307870290407]
	TIME [epoch: 13 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0493203013269017		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.0493203013269017 | validation: 0.05406881983903508]
	TIME [epoch: 13 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05136604543042379		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.05136604543042379 | validation: 0.056180985257203546]
	TIME [epoch: 13.1 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05065176765756503		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.05065176765756503 | validation: 0.061696539372793034]
	TIME [epoch: 13 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055775555780924926		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.055775555780924926 | validation: 0.0627628398894363]
	TIME [epoch: 13 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05546409745941743		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.05546409745941743 | validation: 0.06718944354262565]
	TIME [epoch: 13.1 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053018002205422625		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.053018002205422625 | validation: 0.06098682027713447]
	TIME [epoch: 13.1 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049773777354631815		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.049773777354631815 | validation: 0.06156863529771316]
	TIME [epoch: 13 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04999975958070646		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.04999975958070646 | validation: 0.06068109875123581]
	TIME [epoch: 13 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05422148944337968		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.05422148944337968 | validation: 0.0633412969123738]
	TIME [epoch: 13.1 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055902057066373495		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.055902057066373495 | validation: 0.055298099934733023]
	TIME [epoch: 13 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05116183188766425		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.05116183188766425 | validation: 0.06414749709184851]
	TIME [epoch: 13 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05340575664266928		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.05340575664266928 | validation: 0.05859253728624405]
	TIME [epoch: 13.1 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05467699267164905		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.05467699267164905 | validation: 0.06022563341803849]
	TIME [epoch: 13.1 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057686878021561055		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.057686878021561055 | validation: 0.06387532330456866]
	TIME [epoch: 13 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056063230236295905		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.056063230236295905 | validation: 0.06865978548206507]
	TIME [epoch: 13 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05481554979465344		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.05481554979465344 | validation: 0.0603399482171136]
	TIME [epoch: 13.1 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0550292131153265		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.0550292131153265 | validation: 0.06130740493836912]
	TIME [epoch: 13 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055086188019673694		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.055086188019673694 | validation: 0.062080465392855125]
	TIME [epoch: 13 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05518512061466724		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.05518512061466724 | validation: 0.06606521420527607]
	TIME [epoch: 13 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054885017227093325		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.054885017227093325 | validation: 0.05445254245848224]
	TIME [epoch: 13.1 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05411867375494742		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.05411867375494742 | validation: 0.05683232628672373]
	TIME [epoch: 13 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052826485461302836		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.052826485461302836 | validation: 0.06860456254560456]
	TIME [epoch: 13 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05258825193905153		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.05258825193905153 | validation: 0.067070729054445]
	TIME [epoch: 13.1 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053226325560783855		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.053226325560783855 | validation: 0.06099600836127024]
	TIME [epoch: 13 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054887913890952586		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.054887913890952586 | validation: 0.06844001813211259]
	TIME [epoch: 13 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055663558707864276		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.055663558707864276 | validation: 0.06932100849763373]
	TIME [epoch: 13 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05271061572437533		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.05271061572437533 | validation: 0.05815400695040813]
	TIME [epoch: 13.1 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05431645328711627		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.05431645328711627 | validation: 0.06456338879145317]
	TIME [epoch: 13 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050462312509915855		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.050462312509915855 | validation: 0.06070961576893745]
	TIME [epoch: 13 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053828284422872096		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.053828284422872096 | validation: 0.06608035736552056]
	TIME [epoch: 13.1 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05270697442131328		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.05270697442131328 | validation: 0.05940307111204716]
	TIME [epoch: 13 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053801360328353344		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.053801360328353344 | validation: 0.05425413251272618]
	TIME [epoch: 13 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05283508804762171		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.05283508804762171 | validation: 0.06488503606816225]
	TIME [epoch: 13.1 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052824295997825337		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.052824295997825337 | validation: 0.06212671152083186]
	TIME [epoch: 13.1 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055549882307768264		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.055549882307768264 | validation: 0.06835667752595379]
	TIME [epoch: 13 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05528026845324895		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.05528026845324895 | validation: 0.05824975989116718]
	TIME [epoch: 13 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056579488484921545		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.056579488484921545 | validation: 0.06545677481163581]
	TIME [epoch: 13.1 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06260109896812188		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.06260109896812188 | validation: 0.05520271296511366]
	TIME [epoch: 13 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05649574307356304		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.05649574307356304 | validation: 0.06730095697098984]
	TIME [epoch: 13 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05530044376639799		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.05530044376639799 | validation: 0.06468626702247911]
	TIME [epoch: 13 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055090946449392456		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.055090946449392456 | validation: 0.06065227651038887]
	TIME [epoch: 13.1 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05399812432790241		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.05399812432790241 | validation: 0.06556941947424604]
	TIME [epoch: 13 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052665957927967945		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.052665957927967945 | validation: 0.05805718954284366]
	TIME [epoch: 13 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05308109626687748		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.05308109626687748 | validation: 0.05523689587003449]
	TIME [epoch: 13.1 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04998079857533544		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.04998079857533544 | validation: 0.07037006740514352]
	TIME [epoch: 13 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051903488149269206		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.051903488149269206 | validation: 0.05261978065295299]
	TIME [epoch: 13 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0520169811684351		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.0520169811684351 | validation: 0.06156252619998874]
	TIME [epoch: 13 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049643313497443296		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.049643313497443296 | validation: 0.06318416812712467]
	TIME [epoch: 13.1 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052939998385050674		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.052939998385050674 | validation: 0.0643408900680261]
	TIME [epoch: 13 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05247955609456613		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.05247955609456613 | validation: 0.057777156453989814]
	TIME [epoch: 13 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053573529218752844		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.053573529218752844 | validation: 0.06335793045305135]
	TIME [epoch: 13.1 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04884955251712249		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.04884955251712249 | validation: 0.06246114145281317]
	TIME [epoch: 13 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05302727293023209		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.05302727293023209 | validation: 0.06562961059056167]
	TIME [epoch: 13 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053592442906453056		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.053592442906453056 | validation: 0.06351138673131815]
	TIME [epoch: 13 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053882405334580344		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.053882405334580344 | validation: 0.06058813564712965]
	TIME [epoch: 13.1 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05160629061972434		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.05160629061972434 | validation: 0.051513447527400606]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_1564.pth
	Model improved!!!
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05371507490558601		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.05371507490558601 | validation: 0.06285599216280566]
	TIME [epoch: 13 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05484526544111293		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.05484526544111293 | validation: 0.05626363660557802]
	TIME [epoch: 13.1 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05521168125983965		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.05521168125983965 | validation: 0.05640452782232459]
	TIME [epoch: 13 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0530632429599653		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.0530632429599653 | validation: 0.05615278033971295]
	TIME [epoch: 13 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0546284622903958		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.0546284622903958 | validation: 0.05370926298678787]
	TIME [epoch: 13 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053115875344532534		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.053115875344532534 | validation: 0.05897433323860979]
	TIME [epoch: 13.1 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05589727417484109		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.05589727417484109 | validation: 0.0656458432442736]
	TIME [epoch: 13 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056030037855681405		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.056030037855681405 | validation: 0.06631324675547794]
	TIME [epoch: 13 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058176965940093237		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.058176965940093237 | validation: 0.06586610340617385]
	TIME [epoch: 13.1 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0604022254937346		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.0604022254937346 | validation: 0.06055899605359034]
	TIME [epoch: 13 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053597162694335176		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.053597162694335176 | validation: 0.055767543702336705]
	TIME [epoch: 13 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05650257595823695		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.05650257595823695 | validation: 0.06721304117262694]
	TIME [epoch: 13 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05831089083656092		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.05831089083656092 | validation: 0.06891720444616656]
	TIME [epoch: 13.1 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05818757093786525		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.05818757093786525 | validation: 0.057839523890641564]
	TIME [epoch: 13 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060332414938199914		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.060332414938199914 | validation: 0.05941651078228343]
	TIME [epoch: 13 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060672572533394295		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.060672572533394295 | validation: 0.07175734906416172]
	TIME [epoch: 13.1 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05984546427746318		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.05984546427746318 | validation: 0.06791477745006565]
	TIME [epoch: 13 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06030149156219261		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.06030149156219261 | validation: 0.06904949447877538]
	TIME [epoch: 13 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05830353835880234		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.05830353835880234 | validation: 0.061298370242446096]
	TIME [epoch: 13 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05939461682039815		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.05939461682039815 | validation: 0.07788113648822119]
	TIME [epoch: 13.1 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06052653116353804		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.06052653116353804 | validation: 0.06568489646321067]
	TIME [epoch: 13 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05927113461072883		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.05927113461072883 | validation: 0.06240434823585557]
	TIME [epoch: 13 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05893028751410143		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.05893028751410143 | validation: 0.062210667145789315]
	TIME [epoch: 13 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05446687973225773		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.05446687973225773 | validation: 0.06186324795390803]
	TIME [epoch: 13.1 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05685427408559506		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.05685427408559506 | validation: 0.06910517697923033]
	TIME [epoch: 13 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05416258910536991		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.05416258910536991 | validation: 0.06517702101253804]
	TIME [epoch: 13 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05760363590718281		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.05760363590718281 | validation: 0.06301068426758995]
	TIME [epoch: 13.1 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05492550998109207		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.05492550998109207 | validation: 0.0716404967648809]
	TIME [epoch: 13 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058632134152194496		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.058632134152194496 | validation: 0.05630295889103637]
	TIME [epoch: 13 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05763006148247904		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.05763006148247904 | validation: 0.06151501515883043]
	TIME [epoch: 13 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05949641803123921		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.05949641803123921 | validation: 0.05969158506381751]
	TIME [epoch: 13.1 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05831780518704728		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.05831780518704728 | validation: 0.0708247268413125]
	TIME [epoch: 13 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060665200557431936		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.060665200557431936 | validation: 0.06137212575464126]
	TIME [epoch: 13 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05939431799410243		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.05939431799410243 | validation: 0.06111619796683375]
	TIME [epoch: 13.1 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05680210724030385		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.05680210724030385 | validation: 0.06642322911825219]
	TIME [epoch: 13 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05626938591631042		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.05626938591631042 | validation: 0.06856372048370236]
	TIME [epoch: 13 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058940723957276966		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.058940723957276966 | validation: 0.07207871934727923]
	TIME [epoch: 13 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052401008985922384		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.052401008985922384 | validation: 0.054955273786833826]
	TIME [epoch: 13.1 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05650411865222811		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.05650411865222811 | validation: 0.0581106574574436]
	TIME [epoch: 13 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05479615863361714		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.05479615863361714 | validation: 0.06253699716707364]
	TIME [epoch: 13 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0569672565400174		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.0569672565400174 | validation: 0.06691503703584399]
	TIME [epoch: 13.1 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05582979927998271		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.05582979927998271 | validation: 0.06097985743101493]
	TIME [epoch: 13 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05815209568926498		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.05815209568926498 | validation: 0.06518071478373048]
	TIME [epoch: 13 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05171494287998671		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.05171494287998671 | validation: 0.06646366449170861]
	TIME [epoch: 13 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050965537215674		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.050965537215674 | validation: 0.05129121684932597]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240309_135640/states/model_tr_study4_1609.pth
	Model improved!!!
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048660073620988606		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.048660073620988606 | validation: 0.06073795732258374]
	TIME [epoch: 13 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054361547523085696		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.054361547523085696 | validation: 0.061036415708204256]
	TIME [epoch: 13 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05083641444064106		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.05083641444064106 | validation: 0.05297953589015725]
	TIME [epoch: 13.1 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05512370862418518		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.05512370862418518 | validation: 0.06128098361474912]
	TIME [epoch: 13 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05295742746718073		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.05295742746718073 | validation: 0.05358289471633287]
	TIME [epoch: 13 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05287334373107865		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.05287334373107865 | validation: 0.05807543942273023]
	TIME [epoch: 13 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05569397890147554		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.05569397890147554 | validation: 0.056934913638616955]
	TIME [epoch: 13.1 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05222445476258165		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.05222445476258165 | validation: 0.056182678300203445]
	TIME [epoch: 13 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050139314983280614		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.050139314983280614 | validation: 0.06482365034280817]
	TIME [epoch: 13 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05151480939736089		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.05151480939736089 | validation: 0.059115517056420055]
	TIME [epoch: 13.1 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05379867528380781		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.05379867528380781 | validation: 0.06679928554400828]
	TIME [epoch: 13 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051645090574027316		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.051645090574027316 | validation: 0.062129414433308626]
	TIME [epoch: 13 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05416981116856015		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.05416981116856015 | validation: 0.057416361276776885]
	TIME [epoch: 13 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056268957931518135		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.056268957931518135 | validation: 0.05789323678179409]
	TIME [epoch: 13.1 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05381919211861428		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.05381919211861428 | validation: 0.06464560949549078]
	TIME [epoch: 13 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052610495969258604		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.052610495969258604 | validation: 0.0627928710755341]
	TIME [epoch: 13 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055213200475654		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.055213200475654 | validation: 0.056265332441955876]
	TIME [epoch: 13.1 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053948526723661544		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.053948526723661544 | validation: 0.06396045007925746]
	TIME [epoch: 13 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052659036805981496		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.052659036805981496 | validation: 0.05384522670684788]
	TIME [epoch: 13 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0496552088019079		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.0496552088019079 | validation: 0.05799414504789667]
	TIME [epoch: 13 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051573342790513343		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.051573342790513343 | validation: 0.05720875261359975]
	TIME [epoch: 13.1 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059439750259856684		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.059439750259856684 | validation: 0.06214787373553292]
	TIME [epoch: 13.1 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053137581729936115		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.053137581729936115 | validation: 0.05688366459017569]
	TIME [epoch: 13 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053815413676304456		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.053815413676304456 | validation: 0.05829678410743533]
	TIME [epoch: 13.1 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05558466048211018		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.05558466048211018 | validation: 0.06115920821126352]
	TIME [epoch: 13.1 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05237096019757183		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.05237096019757183 | validation: 0.06142002843579374]
	TIME [epoch: 13 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051948930038917554		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.051948930038917554 | validation: 0.06453941560241443]
	TIME [epoch: 13 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05241583204664163		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.05241583204664163 | validation: 0.058318873020402784]
	TIME [epoch: 13.1 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05206917372051629		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.05206917372051629 | validation: 0.056533635895052385]
	TIME [epoch: 13 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055743049867050046		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.055743049867050046 | validation: 0.06324441249034661]
	TIME [epoch: 13 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05358914699360465		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.05358914699360465 | validation: 0.06184348891089335]
	TIME [epoch: 13.1 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05675134789576113		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.05675134789576113 | validation: 0.06034426068480946]
	TIME [epoch: 13.1 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056940147619182674		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.056940147619182674 | validation: 0.05774924537644343]
	TIME [epoch: 13 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05776898990315091		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.05776898990315091 | validation: 0.058188970589969025]
	TIME [epoch: 13 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054665589884782775		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.054665589884782775 | validation: 0.06118056298586077]
	TIME [epoch: 13.1 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05592013726512519		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.05592013726512519 | validation: 0.06423946501677198]
	TIME [epoch: 13 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05659016329023774		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.05659016329023774 | validation: 0.05363704994611161]
	TIME [epoch: 13 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050968328002194155		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.050968328002194155 | validation: 0.0646849180582682]
	TIME [epoch: 13.1 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0548317895960077		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.0548317895960077 | validation: 0.058952028386700016]
	TIME [epoch: 13.1 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05520552605466483		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.05520552605466483 | validation: 0.06698925228898844]
	TIME [epoch: 13 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05468690364159462		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.05468690364159462 | validation: 0.06432667444229447]
	TIME [epoch: 13 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05537221480502537		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.05537221480502537 | validation: 0.06080603427103217]
	TIME [epoch: 13.1 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05732020423019553		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.05732020423019553 | validation: 0.05672203037933867]
	TIME [epoch: 13 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05339907478073172		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.05339907478073172 | validation: 0.05892295747967666]
	TIME [epoch: 13 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05411221416526871		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.05411221416526871 | validation: 0.05926607587690136]
	TIME [epoch: 13 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056486998994920073		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.056486998994920073 | validation: 0.0593025516399239]
	TIME [epoch: 13.1 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05609446284044636		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.05609446284044636 | validation: 0.07066792547046392]
	TIME [epoch: 13 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054261038559241574		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.054261038559241574 | validation: 0.061735333006520565]
	TIME [epoch: 13 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05501535540795263		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.05501535540795263 | validation: 0.05815818949453009]
	TIME [epoch: 13.1 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05950693745176732		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.05950693745176732 | validation: 0.06578217928425673]
	TIME [epoch: 13 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05638051226165332		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.05638051226165332 | validation: 0.06511463621954293]
	TIME [epoch: 13 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05660734665728418		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.05660734665728418 | validation: 0.06119597764981844]
	TIME [epoch: 13 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05608170381432517		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.05608170381432517 | validation: 0.06010626785275098]
	TIME [epoch: 13.1 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05434491833891934		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.05434491833891934 | validation: 0.06214264513899991]
	TIME [epoch: 13 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05517085679709176		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.05517085679709176 | validation: 0.058463001372342005]
	TIME [epoch: 13 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05432082175383972		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.05432082175383972 | validation: 0.05609624686258701]
	TIME [epoch: 13.1 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05484760254156829		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.05484760254156829 | validation: 0.06135552535973439]
	TIME [epoch: 13 sec]
EPOCH 1667/2000:
	Training over batches...
