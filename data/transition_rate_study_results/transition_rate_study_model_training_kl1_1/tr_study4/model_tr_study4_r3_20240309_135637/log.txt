Args:
Namespace(name='model_tr_study4', outdir='out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3', training_data='data/transition_rate_studies/tr_study4/tr_study4_training/r3', validation_data='data/transition_rate_studies/tr_study4/tr_study4_validation/r3', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1364222980

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.280871379612023		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.280871379612023 | validation: 7.297605921418477]
	TIME [epoch: 99.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.511337528385088		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.511337528385088 | validation: 7.14230942228125]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.99580403478203		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.99580403478203 | validation: 6.503078143656607]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.029189180948142		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.029189180948142 | validation: 5.821293506166617]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.275148568606424		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.275148568606424 | validation: 5.374453603102482]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.913449219507441		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.913449219507441 | validation: 5.085158168282159]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.517385758825936		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.517385758825936 | validation: 4.779330519757422]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.131205204394033		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.131205204394033 | validation: 4.491761945615639]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.691755678935599		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.691755678935599 | validation: 4.152478587494957]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.2129865215684665		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.2129865215684665 | validation: 3.8479121397979545]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.77855148816648		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.77855148816648 | validation: 4.966435045194524]
	TIME [epoch: 11.5 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.094174332065677		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.094174332065677 | validation: 3.5970453729344354]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.552948074503771		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.552948074503771 | validation: 3.4730339087422113]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5335016676985553		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5335016676985553 | validation: 3.389267899007814]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.313835883644602		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.313835883644602 | validation: 3.259264443098646]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.398535568837092		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.398535568837092 | validation: 3.285114995195844]
	TIME [epoch: 11.5 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1851647688534115		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1851647688534115 | validation: 3.182575600233751]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1603322655635835		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1603322655635835 | validation: 3.36686184286691]
	TIME [epoch: 11.5 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0420628902268962		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0420628902268962 | validation: 3.1939056661880993]
	TIME [epoch: 11.5 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.094154295725914		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.094154295725914 | validation: 3.207207950904518]
	TIME [epoch: 11.6 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.079160239854818		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.079160239854818 | validation: 2.914207298411042]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9289486898336405		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9289486898336405 | validation: 3.2636131107664768]
	TIME [epoch: 11.5 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.957739725652193		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.957739725652193 | validation: 2.852953127412267]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.759303517047822		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.759303517047822 | validation: 2.842661021270923]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7791033579069495		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7791033579069495 | validation: 2.7054875147755006]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.569121838383836		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.569121838383836 | validation: 2.600241535780413]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.484961339668924		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.484961339668924 | validation: 2.399781509382077]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6797857527472484		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6797857527472484 | validation: 3.3899807996912363]
	TIME [epoch: 11.5 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.831366989270653		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.831366989270653 | validation: 2.2570457296808146]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.317003195223653		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.317003195223653 | validation: 2.4820230535828136]
	TIME [epoch: 11.6 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4309859254213295		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4309859254213295 | validation: 2.131208377772036]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.181551726283029		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.181551726283029 | validation: 2.151172036022925]
	TIME [epoch: 11.5 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2676649120288594		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2676649120288594 | validation: 1.9116063320556627]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4058262854075467		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4058262854075467 | validation: 2.1781396625705067]
	TIME [epoch: 11.5 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.107899092156968		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.107899092156968 | validation: 1.8768670732608614]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1313032257001034		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1313032257001034 | validation: 2.025234937086821]
	TIME [epoch: 11.6 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3484090171869783		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3484090171869783 | validation: 2.1781055697959117]
	TIME [epoch: 11.5 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2534778341833595		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2534778341833595 | validation: 1.9833169801415453]
	TIME [epoch: 11.5 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8924718774870493		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8924718774870493 | validation: 1.6432855837513263]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.630828309867328		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.630828309867328 | validation: 1.4693051647776851]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.575516780523171		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.575516780523171 | validation: 1.70268460689738]
	TIME [epoch: 11.5 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6026636982969389		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6026636982969389 | validation: 1.6007211752813613]
	TIME [epoch: 11.5 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3475867864315108		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3475867864315108 | validation: 3.151968719159713]
	TIME [epoch: 11.6 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2077232253683		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2077232253683 | validation: 1.4704374693027216]
	TIME [epoch: 11.5 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.562710114676711		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.562710114676711 | validation: 1.8810354846714774]
	TIME [epoch: 11.5 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5018879551494373		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5018879551494373 | validation: 1.6597703873667466]
	TIME [epoch: 11.6 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3871695806778224		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3871695806778224 | validation: 1.8319378370350796]
	TIME [epoch: 11.5 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3493103709948624		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3493103709948624 | validation: 1.0145231882025414]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.327493734666134		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.327493734666134 | validation: 1.1370552359493955]
	TIME [epoch: 11.6 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4769752578860178		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4769752578860178 | validation: 1.3576368613794723]
	TIME [epoch: 11.5 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1489057017992526		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 1.1489057017992526 | validation: 1.0945381727503187]
	TIME [epoch: 11.5 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1041043321137127		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 1.1041043321137127 | validation: 1.0209743102536848]
	TIME [epoch: 11.5 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1757623882801422		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 1.1757623882801422 | validation: 1.0332356230829054]
	TIME [epoch: 11.5 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1180169401309936		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 1.1180169401309936 | validation: 4.335182300322391]
	TIME [epoch: 11.5 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4855928890717056		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 2.4855928890717056 | validation: 1.949446777174481]
	TIME [epoch: 11.5 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4709225959055414		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 1.4709225959055414 | validation: 1.031702174159786]
	TIME [epoch: 11.5 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.046691261964924		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 1.046691261964924 | validation: 1.4781219913113943]
	TIME [epoch: 11.5 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0557145059940254		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 1.0557145059940254 | validation: 0.8249882680467223]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.05334340269213		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 1.05334340269213 | validation: 0.9797852454565481]
	TIME [epoch: 11.6 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0084406583652197		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 1.0084406583652197 | validation: 1.641766912774541]
	TIME [epoch: 11.5 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2571228534130086		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 1.2571228534130086 | validation: 0.9352822856001906]
	TIME [epoch: 11.5 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9741046509434055		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.9741046509434055 | validation: 1.2700060226823828]
	TIME [epoch: 11.5 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9336594312881126		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 0.9336594312881126 | validation: 1.1798181188161119]
	TIME [epoch: 11.5 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9939811134746008		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 0.9939811134746008 | validation: 1.0935912110374804]
	TIME [epoch: 11.5 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0362944630919244		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 1.0362944630919244 | validation: 1.0187545000794647]
	TIME [epoch: 11.6 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8185937455374801		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 0.8185937455374801 | validation: 1.0774297772825907]
	TIME [epoch: 11.5 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9613662835348612		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 0.9613662835348612 | validation: 0.8125633218054668]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7839996139854334		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 0.7839996139854334 | validation: 1.3205354497192598]
	TIME [epoch: 11.5 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8675722133728777		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 0.8675722133728777 | validation: 0.5856323678796341]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9209919429193608		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.9209919429193608 | validation: 1.2835269930915498]
	TIME [epoch: 11.5 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0303779600457694		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 1.0303779600457694 | validation: 0.9974022012141824]
	TIME [epoch: 11.5 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9103499388414138		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 0.9103499388414138 | validation: 0.9426234687614382]
	TIME [epoch: 11.6 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9177420954204636		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 0.9177420954204636 | validation: 0.716231994088289]
	TIME [epoch: 11.5 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7582650317647329		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 0.7582650317647329 | validation: 0.8394689178537837]
	TIME [epoch: 11.5 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7917298648790807		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.7917298648790807 | validation: 2.502485861416149]
	TIME [epoch: 11.6 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.327281729196618		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 1.327281729196618 | validation: 0.9146963426646068]
	TIME [epoch: 11.5 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8182371443475042		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 0.8182371443475042 | validation: 0.9795169636624965]
	TIME [epoch: 11.5 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.775711831992077		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 0.775711831992077 | validation: 0.6495618265238613]
	TIME [epoch: 11.5 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7283354238676152		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 0.7283354238676152 | validation: 0.7889967210820388]
	TIME [epoch: 11.5 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0579985084724597		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 1.0579985084724597 | validation: 0.8271007063597032]
	TIME [epoch: 11.5 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7657951384840622		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 0.7657951384840622 | validation: 0.8051042783945627]
	TIME [epoch: 11.5 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7023295440885058		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 0.7023295440885058 | validation: 0.9126321809678254]
	TIME [epoch: 11.5 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8023140030155463		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 0.8023140030155463 | validation: 0.6642319978731027]
	TIME [epoch: 11.5 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9684239985957797		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 0.9684239985957797 | validation: 1.4534885896555385]
	TIME [epoch: 11.5 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9400293290442204		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.9400293290442204 | validation: 0.5638946342504845]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_85.pth
	Model improved!!!
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8896510697198391		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 0.8896510697198391 | validation: 0.7908711766420461]
	TIME [epoch: 11.5 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7653317080487663		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 0.7653317080487663 | validation: 1.0715159508259902]
	TIME [epoch: 11.5 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8673825516658309		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 0.8673825516658309 | validation: 0.643749042183208]
	TIME [epoch: 11.5 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8417476095323909		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.8417476095323909 | validation: 1.349199718647522]
	TIME [epoch: 11.5 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5000245886349994		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 1.5000245886349994 | validation: 1.0449792003814151]
	TIME [epoch: 11.5 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.018947051471091		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 1.018947051471091 | validation: 1.6503740263415574]
	TIME [epoch: 11.5 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.07796492487903		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 1.07796492487903 | validation: 1.0631125467233415]
	TIME [epoch: 11.5 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8763250213886643		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 0.8763250213886643 | validation: 0.8228602187948547]
	TIME [epoch: 11.5 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7842629688558914		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 0.7842629688558914 | validation: 0.8650032864499784]
	TIME [epoch: 11.5 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.884026908854674		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.884026908854674 | validation: 0.7153728949241338]
	TIME [epoch: 11.5 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2064370878008281		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 1.2064370878008281 | validation: 0.9572390220977025]
	TIME [epoch: 11.5 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.820872760368462		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 0.820872760368462 | validation: 0.7071275726869527]
	TIME [epoch: 11.5 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7037755933475008		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.7037755933475008 | validation: 0.8084764825746618]
	TIME [epoch: 11.5 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7895507724002655		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 0.7895507724002655 | validation: 0.8251584785445621]
	TIME [epoch: 11.5 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.873738737723032		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.873738737723032 | validation: 0.716118625348431]
	TIME [epoch: 11.5 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.764322904226712		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 0.764322904226712 | validation: 0.8873413964160295]
	TIME [epoch: 11.6 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0706293860996872		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 1.0706293860996872 | validation: 0.9346324471789342]
	TIME [epoch: 11.5 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7220754164187838		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 0.7220754164187838 | validation: 0.749681289883906]
	TIME [epoch: 11.5 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6532041615541725		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 0.6532041615541725 | validation: 0.9290264915410326]
	TIME [epoch: 11.5 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7735770584870131		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.7735770584870131 | validation: 1.3604252137161266]
	TIME [epoch: 11.5 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0964406962533984		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 1.0964406962533984 | validation: 0.6328768632505337]
	TIME [epoch: 11.8 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6393854778987154		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.6393854778987154 | validation: 0.8125618583370506]
	TIME [epoch: 11.6 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6574553135790975		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 0.6574553135790975 | validation: 0.624054582036446]
	TIME [epoch: 11.5 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5886749917154531		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 0.5886749917154531 | validation: 0.6536576081557304]
	TIME [epoch: 11.5 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5480135609977015		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.5480135609977015 | validation: 0.6998510468026544]
	TIME [epoch: 11.5 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6007996380976608		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 0.6007996380976608 | validation: 0.8662908525176082]
	TIME [epoch: 11.6 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.698959416984553		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 0.698959416984553 | validation: 0.901881834500195]
	TIME [epoch: 11.5 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8127390868781447		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 0.8127390868781447 | validation: 0.8423069735374]
	TIME [epoch: 11.5 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8829481317773513		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 0.8829481317773513 | validation: 1.0692125336692935]
	TIME [epoch: 11.6 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.731055851211271		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.731055851211271 | validation: 0.655936644631836]
	TIME [epoch: 11.5 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5534823544979618		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.5534823544979618 | validation: 0.651363061556348]
	TIME [epoch: 11.5 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6753459357440316		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 0.6753459357440316 | validation: 0.5398236249609568]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_117.pth
	Model improved!!!
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5829601855418749		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 0.5829601855418749 | validation: 0.6247990705546654]
	TIME [epoch: 11.5 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5370758231948023		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 0.5370758231948023 | validation: 0.5510174540597645]
	TIME [epoch: 11.5 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5167697861142202		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.5167697861142202 | validation: 1.044140627759298]
	TIME [epoch: 11.6 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7595300337930836		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 0.7595300337930836 | validation: 0.7775119495412611]
	TIME [epoch: 11.5 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9211940905103765		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 0.9211940905103765 | validation: 0.6384844609779073]
	TIME [epoch: 11.5 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5447374650000837		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 0.5447374650000837 | validation: 0.49398149495739563]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_123.pth
	Model improved!!!
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6772959736569055		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 0.6772959736569055 | validation: 0.5643667836639396]
	TIME [epoch: 11.6 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5954140161114877		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.5954140161114877 | validation: 0.6496968064962795]
	TIME [epoch: 11.5 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5477586325703251		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 0.5477586325703251 | validation: 0.48892919915187727]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_126.pth
	Model improved!!!
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7257224790152885		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 0.7257224790152885 | validation: 0.8233517236573771]
	TIME [epoch: 11.6 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.687344861654016		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 1.687344861654016 | validation: 1.4937794305585295]
	TIME [epoch: 11.5 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2635681204003628		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 1.2635681204003628 | validation: 1.0841845439499698]
	TIME [epoch: 11.5 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.403489784084944		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 1.403489784084944 | validation: 1.2860096024332621]
	TIME [epoch: 11.6 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0350298534711615		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 1.0350298534711615 | validation: 0.6433743065514542]
	TIME [epoch: 11.5 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7423510732904203		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 0.7423510732904203 | validation: 0.5872238139208762]
	TIME [epoch: 11.5 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5513552893433906		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 0.5513552893433906 | validation: 0.5098563762037523]
	TIME [epoch: 11.6 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5577621509192124		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.5577621509192124 | validation: 0.5366839693141178]
	TIME [epoch: 11.5 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46673213339493613		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.46673213339493613 | validation: 0.4964616654642752]
	TIME [epoch: 11.5 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5192480833383065		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.5192480833383065 | validation: 0.5644905531012055]
	TIME [epoch: 11.6 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5335707480025851		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 0.5335707480025851 | validation: 0.6184820212679923]
	TIME [epoch: 11.5 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5199401106390635		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 0.5199401106390635 | validation: 0.6103671661023264]
	TIME [epoch: 11.5 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5917098484053458		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 0.5917098484053458 | validation: 0.6196582586575228]
	TIME [epoch: 11.5 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4664603365198755		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.4664603365198755 | validation: 0.6524394840321865]
	TIME [epoch: 11.6 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.606332390976853		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 0.606332390976853 | validation: 0.39287265185242176]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_141.pth
	Model improved!!!
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46886382637010077		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.46886382637010077 | validation: 0.430999957410382]
	TIME [epoch: 11.5 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47025338046744336		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.47025338046744336 | validation: 0.43398637623016273]
	TIME [epoch: 11.6 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4805152484983248		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 0.4805152484983248 | validation: 0.47165106479085855]
	TIME [epoch: 11.5 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7224534156924535		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.7224534156924535 | validation: 0.4489706532076406]
	TIME [epoch: 11.5 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4442053526853915		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.4442053526853915 | validation: 0.4296496579081086]
	TIME [epoch: 11.6 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44841256499099813		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.44841256499099813 | validation: 0.7533590768222892]
	TIME [epoch: 11.5 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.85763021921676		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 0.85763021921676 | validation: 0.6228503014774787]
	TIME [epoch: 11.5 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6496915806169367		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.6496915806169367 | validation: 0.47609272910256606]
	TIME [epoch: 11.6 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6154192604080637		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.6154192604080637 | validation: 0.5573525010169441]
	TIME [epoch: 11.5 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5046057654433509		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.5046057654433509 | validation: 0.4561661061811891]
	TIME [epoch: 11.5 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5435387412656867		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.5435387412656867 | validation: 0.41514347950329267]
	TIME [epoch: 11.5 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47814169205053		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 0.47814169205053 | validation: 0.48751375643944883]
	TIME [epoch: 11.5 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46439713608195454		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.46439713608195454 | validation: 0.5526926812703]
	TIME [epoch: 11.5 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6097776102675672		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.6097776102675672 | validation: 1.0310221309693686]
	TIME [epoch: 11.5 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7671225164079791		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 0.7671225164079791 | validation: 0.5623141762257537]
	TIME [epoch: 11.6 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6875947495209278		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 0.6875947495209278 | validation: 1.05185599422618]
	TIME [epoch: 11.5 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8128812035394486		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 0.8128812035394486 | validation: 0.655250573263463]
	TIME [epoch: 11.5 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47937410110652645		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.47937410110652645 | validation: 0.8957601460704901]
	TIME [epoch: 11.5 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0798269365486342		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 1.0798269365486342 | validation: 0.7879090209484209]
	TIME [epoch: 11.5 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6144534549724496		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.6144534549724496 | validation: 0.6373628879595482]
	TIME [epoch: 11.5 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46896115581714615		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.46896115581714615 | validation: 0.9854587247256597]
	TIME [epoch: 11.5 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7626290869280803		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.7626290869280803 | validation: 0.541383376865065]
	TIME [epoch: 11.5 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4728954207854634		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.4728954207854634 | validation: 0.40980215561901573]
	TIME [epoch: 11.5 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4336557805796698		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.4336557805796698 | validation: 0.3587028491242532]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_165.pth
	Model improved!!!
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4261094115985744		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 0.4261094115985744 | validation: 0.5320770815440719]
	TIME [epoch: 11.5 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4550986863495392		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 0.4550986863495392 | validation: 0.5052385969355562]
	TIME [epoch: 11.5 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5350143750690324		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.5350143750690324 | validation: 0.3955413928548099]
	TIME [epoch: 11.5 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3895022853283352		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.3895022853283352 | validation: 0.37368917580923616]
	TIME [epoch: 11.5 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41375402221931623		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.41375402221931623 | validation: 0.4164953734484437]
	TIME [epoch: 11.5 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44648930049757346		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.44648930049757346 | validation: 0.438822848270558]
	TIME [epoch: 11.5 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4065296822854708		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.4065296822854708 | validation: 0.3930014868380338]
	TIME [epoch: 11.5 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39480549571369017		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.39480549571369017 | validation: 0.601373334674158]
	TIME [epoch: 11.5 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4326047458255655		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.4326047458255655 | validation: 0.33027581598446054]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_174.pth
	Model improved!!!
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5598558793422262		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.5598558793422262 | validation: 0.390978476423127]
	TIME [epoch: 11.5 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4326785929661943		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 0.4326785929661943 | validation: 0.4834296896424516]
	TIME [epoch: 11.5 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40067256578281407		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.40067256578281407 | validation: 0.4319580019796325]
	TIME [epoch: 11.5 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35197531455050163		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.35197531455050163 | validation: 0.5054068496045993]
	TIME [epoch: 11.5 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45407903123781923		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.45407903123781923 | validation: 0.4694717112783111]
	TIME [epoch: 11.5 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40302843778064856		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.40302843778064856 | validation: 0.3359214442968487]
	TIME [epoch: 11.5 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40347942203767073		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.40347942203767073 | validation: 0.4832955484196006]
	TIME [epoch: 11.5 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4433929591620013		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.4433929591620013 | validation: 0.6075119026420073]
	TIME [epoch: 11.5 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40376772401531136		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.40376772401531136 | validation: 0.28292800355083264]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_183.pth
	Model improved!!!
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6238823695513083		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.6238823695513083 | validation: 1.0542227795851502]
	TIME [epoch: 11.5 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6514564860778511		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.6514564860778511 | validation: 0.5335466146319384]
	TIME [epoch: 11.5 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3922716015084945		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.3922716015084945 | validation: 0.42218795164314366]
	TIME [epoch: 11.5 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36384428423064846		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.36384428423064846 | validation: 0.7310658864765252]
	TIME [epoch: 11.5 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5593946853231995		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.5593946853231995 | validation: 0.5805103308978903]
	TIME [epoch: 11.5 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4555077764042542		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.4555077764042542 | validation: 0.4052658497319911]
	TIME [epoch: 11.5 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32012731831642		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.32012731831642 | validation: 0.42132651233702256]
	TIME [epoch: 11.5 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45023246246940096		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.45023246246940096 | validation: 0.47803194583248065]
	TIME [epoch: 11.5 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3375653945524344		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.3375653945524344 | validation: 0.3214503431258987]
	TIME [epoch: 11.5 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42894543756585995		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.42894543756585995 | validation: 0.39762847690257247]
	TIME [epoch: 11.5 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4448153192040894		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.4448153192040894 | validation: 0.3846025626095495]
	TIME [epoch: 11.5 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36254127949843573		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.36254127949843573 | validation: 0.7404482661540407]
	TIME [epoch: 11.5 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5416822601789426		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.5416822601789426 | validation: 0.4142463231891723]
	TIME [epoch: 11.5 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33732894519910783		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.33732894519910783 | validation: 0.39386209830550784]
	TIME [epoch: 11.5 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.483891732095136		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 1.483891732095136 | validation: 0.7737223031670846]
	TIME [epoch: 11.5 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7940437181967288		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.7940437181967288 | validation: 0.6911093310451688]
	TIME [epoch: 11.5 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6792894919122041		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.6792894919122041 | validation: 0.7800470140410518]
	TIME [epoch: 11.5 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6913819007744483		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.6913819007744483 | validation: 0.54220287519856]
	TIME [epoch: 11.5 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6287813909357415		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.6287813909357415 | validation: 0.5824191153196769]
	TIME [epoch: 11.5 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47807830245509214		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.47807830245509214 | validation: 0.4042615418166785]
	TIME [epoch: 11.5 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3694235627769101		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.3694235627769101 | validation: 0.21345194293085964]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_204.pth
	Model improved!!!
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41785987462541285		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.41785987462541285 | validation: 0.2971406065691237]
	TIME [epoch: 11.5 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2943942893127298		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.2943942893127298 | validation: 0.2808292349193304]
	TIME [epoch: 11.5 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2657989642867315		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.2657989642867315 | validation: 0.49008640103781714]
	TIME [epoch: 11.5 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5791475287218032		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.5791475287218032 | validation: 0.7208442929030128]
	TIME [epoch: 11.5 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6146666877685976		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.6146666877685976 | validation: 0.7177781465252906]
	TIME [epoch: 11.5 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6807884632264959		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.6807884632264959 | validation: 0.5095560154255511]
	TIME [epoch: 11.5 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.313385081249728		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.313385081249728 | validation: 0.22030990386978558]
	TIME [epoch: 11.5 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2041330913338275		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.2041330913338275 | validation: 0.19875829625501176]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_212.pth
	Model improved!!!
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21414329563345819		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.21414329563345819 | validation: 0.20603776830699472]
	TIME [epoch: 11.5 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2367017547377752		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.2367017547377752 | validation: 0.21585942271341232]
	TIME [epoch: 11.5 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2276304288996963		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.2276304288996963 | validation: 0.3296189857626143]
	TIME [epoch: 11.5 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2710993177963755		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.2710993177963755 | validation: 0.20431315172369643]
	TIME [epoch: 11.5 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22232910183147153		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.22232910183147153 | validation: 0.3043288791994553]
	TIME [epoch: 11.5 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3225040353690419		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.3225040353690419 | validation: 1.0312587183214268]
	TIME [epoch: 11.5 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5322587731486844		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.5322587731486844 | validation: 0.3645344014218134]
	TIME [epoch: 11.5 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2873648321796862		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.2873648321796862 | validation: 0.361970675020716]
	TIME [epoch: 11.5 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37202864707504724		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.37202864707504724 | validation: 0.45319154519171123]
	TIME [epoch: 11.6 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31006702203233377		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.31006702203233377 | validation: 0.2598879156454977]
	TIME [epoch: 11.5 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7766400186913474		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.7766400186913474 | validation: 0.6969555338498479]
	TIME [epoch: 11.5 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43061307315533187		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.43061307315533187 | validation: 0.2916723827475606]
	TIME [epoch: 11.5 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24443944970513767		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.24443944970513767 | validation: 0.30868230721392353]
	TIME [epoch: 11.5 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23010063221808524		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.23010063221808524 | validation: 0.1629015223943959]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_226.pth
	Model improved!!!
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20836164529796278		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.20836164529796278 | validation: 0.15111105766716704]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_227.pth
	Model improved!!!
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17316186578752968		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.17316186578752968 | validation: 0.2198076221401517]
	TIME [epoch: 11.5 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29335522237437756		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.29335522237437756 | validation: 0.181206564781399]
	TIME [epoch: 11.5 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2150902325572474		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.2150902325572474 | validation: 0.21061188553092927]
	TIME [epoch: 11.6 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21578626464307993		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.21578626464307993 | validation: 0.387231692323909]
	TIME [epoch: 11.5 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27145396955871093		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.27145396955871093 | validation: 0.22388298932959813]
	TIME [epoch: 11.5 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2012958770486275		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.2012958770486275 | validation: 0.17096321711696696]
	TIME [epoch: 11.6 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.190990688260638		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.190990688260638 | validation: 0.24663341790526505]
	TIME [epoch: 11.5 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16167018143695244		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.16167018143695244 | validation: 0.11917777249358683]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_235.pth
	Model improved!!!
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18559382427678678		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.18559382427678678 | validation: 0.4064018529203656]
	TIME [epoch: 11.5 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3170784831257726		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.3170784831257726 | validation: 0.2442518087454472]
	TIME [epoch: 11.6 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25641449719757836		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.25641449719757836 | validation: 0.26365390369350894]
	TIME [epoch: 11.5 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31110285926652537		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.31110285926652537 | validation: 0.3799728763228542]
	TIME [epoch: 11.5 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4477801097277715		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.4477801097277715 | validation: 0.22743887925099746]
	TIME [epoch: 11.6 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21190381756895224		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.21190381756895224 | validation: 0.19386620503138957]
	TIME [epoch: 11.5 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18901129429205465		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.18901129429205465 | validation: 0.18402319342286874]
	TIME [epoch: 11.5 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19817589263572521		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.19817589263572521 | validation: 0.2208662838052109]
	TIME [epoch: 11.6 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21276998586935247		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.21276998586935247 | validation: 0.20043109238544168]
	TIME [epoch: 11.5 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18140832164921478		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.18140832164921478 | validation: 0.14678747891936614]
	TIME [epoch: 11.5 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26627488761209983		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.26627488761209983 | validation: 0.2329901017617505]
	TIME [epoch: 11.6 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3596128942931452		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.3596128942931452 | validation: 0.25196972539581425]
	TIME [epoch: 11.5 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2001848631516646		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.2001848631516646 | validation: 0.2593780448210362]
	TIME [epoch: 11.5 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30488939029464235		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.30488939029464235 | validation: 0.22314857730362395]
	TIME [epoch: 11.5 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2783302289196905		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.2783302289196905 | validation: 0.29120305907247795]
	TIME [epoch: 11.6 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2576946129330668		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.2576946129330668 | validation: 0.26556752431471364]
	TIME [epoch: 11.5 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2466828182275162		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.2466828182275162 | validation: 0.2599697602152897]
	TIME [epoch: 11.5 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44004854158108153		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.44004854158108153 | validation: 1.0511710848179647]
	TIME [epoch: 11.6 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45764905065092787		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.45764905065092787 | validation: 0.2233515562001714]
	TIME [epoch: 11.5 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21573151859259398		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.21573151859259398 | validation: 0.191956877938079]
	TIME [epoch: 11.5 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2033020889638187		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.2033020889638187 | validation: 0.191227248982394]
	TIME [epoch: 11.6 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1825484054026584		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.1825484054026584 | validation: 0.17210991368590098]
	TIME [epoch: 11.5 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18247095258940488		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.18247095258940488 | validation: 0.20105513252484272]
	TIME [epoch: 11.5 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3033651865022621		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.3033651865022621 | validation: 0.28716505568919437]
	TIME [epoch: 11.6 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2599539341030516		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.2599539341030516 | validation: 0.20903275031622623]
	TIME [epoch: 11.5 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27075324928442884		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.27075324928442884 | validation: 0.2596314052101683]
	TIME [epoch: 11.5 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2247569260359552		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.2247569260359552 | validation: 0.2566700179292463]
	TIME [epoch: 11.5 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.602305320232756		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 1.602305320232756 | validation: 3.2833049050651004]
	TIME [epoch: 11.6 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.366051418704883		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 3.366051418704883 | validation: 3.4075846148841005]
	TIME [epoch: 11.5 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2598857859830592		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 3.2598857859830592 | validation: 3.5363149320105602]
	TIME [epoch: 11.5 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.323088349942845		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 3.323088349942845 | validation: 3.421716322861881]
	TIME [epoch: 11.6 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.28504569328282		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 3.28504569328282 | validation: 3.4787492622514358]
	TIME [epoch: 11.5 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.318387249223184		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 3.318387249223184 | validation: 3.5546216050756376]
	TIME [epoch: 11.5 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.381149015340209		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 3.381149015340209 | validation: 3.407258575527966]
	TIME [epoch: 11.6 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2592221567233954		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 3.2592221567233954 | validation: 3.405286433736874]
	TIME [epoch: 11.5 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.277530193517345		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 3.277530193517345 | validation: 3.38998801857204]
	TIME [epoch: 11.5 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2811002212522973		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 3.2811002212522973 | validation: 3.524697355079211]
	TIME [epoch: 11.6 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.335000454881507		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 3.335000454881507 | validation: 3.335622945477768]
	TIME [epoch: 11.5 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.28431588128128		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 3.28431588128128 | validation: 3.315613404818645]
	TIME [epoch: 11.5 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2094026604404418		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 3.2094026604404418 | validation: 3.4507364120869126]
	TIME [epoch: 11.5 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.28946584388634		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 3.28946584388634 | validation: 3.4060122908873867]
	TIME [epoch: 11.6 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.283970181682928		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 3.283970181682928 | validation: 3.4538403094560097]
	TIME [epoch: 11.5 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.282954137044875		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 3.282954137044875 | validation: 3.3864030866426207]
	TIME [epoch: 11.5 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.273769516713206		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 3.273769516713206 | validation: 3.4619670769162862]
	TIME [epoch: 11.6 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2523276711106206		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 3.2523276711106206 | validation: 3.398095955247147]
	TIME [epoch: 11.5 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2366929985912787		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 3.2366929985912787 | validation: 3.3759771414985473]
	TIME [epoch: 11.5 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2322042483120472		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 3.2322042483120472 | validation: 3.429994106134286]
	TIME [epoch: 11.6 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2976209973780217		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 3.2976209973780217 | validation: 3.3857014124410387]
	TIME [epoch: 11.5 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.207959161935132		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 3.207959161935132 | validation: 3.391090914465304]
	TIME [epoch: 11.5 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2408140862456727		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 3.2408140862456727 | validation: 3.343977742474167]
	TIME [epoch: 11.6 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.20773429318274		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 3.20773429318274 | validation: 3.3290161556842373]
	TIME [epoch: 11.5 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2888362359316368		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 3.2888362359316368 | validation: 3.5255058486218864]
	TIME [epoch: 11.5 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2786233217908043		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 3.2786233217908043 | validation: 3.466019046082157]
	TIME [epoch: 11.6 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2421747398323477		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 3.2421747398323477 | validation: 3.341585556390214]
	TIME [epoch: 11.5 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.261115501387794		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 3.261115501387794 | validation: 3.4406885854551037]
	TIME [epoch: 11.5 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3026870695555948		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 3.3026870695555948 | validation: 3.3075154689370514]
	TIME [epoch: 11.5 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6975154259250385		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 3.6975154259250385 | validation: 3.876767720385019]
	TIME [epoch: 11.6 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.26184557328381		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 3.26184557328381 | validation: 3.438729192865511]
	TIME [epoch: 11.5 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.223903291197156		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 3.223903291197156 | validation: 3.2978751785107687]
	TIME [epoch: 11.5 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.212237738236092		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 3.212237738236092 | validation: 3.6761221550609755]
	TIME [epoch: 11.6 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4371923442078787		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 3.4371923442078787 | validation: 3.3702803129651278]
	TIME [epoch: 11.5 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1713418269560254		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 3.1713418269560254 | validation: 3.300209886540572]
	TIME [epoch: 11.5 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.226496412588499		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 3.226496412588499 | validation: 3.4511006349034825]
	TIME [epoch: 11.6 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2766317407797665		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 3.2766317407797665 | validation: 3.3414295014702713]
	TIME [epoch: 11.5 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.190860246577401		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 3.190860246577401 | validation: 3.272496058562359]
	TIME [epoch: 11.5 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1790802275073666		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 3.1790802275073666 | validation: 3.305446598016096]
	TIME [epoch: 11.6 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.190694336988355		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 3.190694336988355 | validation: 3.3303956548682367]
	TIME [epoch: 11.5 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.220723501160111		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 3.220723501160111 | validation: 3.4250743630173783]
	TIME [epoch: 11.5 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3380915336375407		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 3.3380915336375407 | validation: 3.277182596351651]
	TIME [epoch: 11.5 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.119015930850818		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 3.119015930850818 | validation: 3.5668022732455062]
	TIME [epoch: 11.6 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3653876403256		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 3.3653876403256 | validation: 3.276503305627814]
	TIME [epoch: 11.5 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3407663573621647		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 3.3407663573621647 | validation: 3.9596873449998053]
	TIME [epoch: 11.5 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2691021042372594		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 3.2691021042372594 | validation: 2.9914631656410804]
	TIME [epoch: 11.6 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0019137165050664		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 3.0019137165050664 | validation: 2.739332618113094]
	TIME [epoch: 11.5 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1742741603669624		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 2.1742741603669624 | validation: 1.1514312119775827]
	TIME [epoch: 11.5 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0010571089652782		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 1.0010571089652782 | validation: 0.5154875056249264]
	TIME [epoch: 11.6 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5390314183958721		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.5390314183958721 | validation: 0.7057237746610524]
	TIME [epoch: 11.5 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5534585804646374		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.5534585804646374 | validation: 0.45622456416419904]
	TIME [epoch: 11.5 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5069030522064308		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.5069030522064308 | validation: 0.3982731857548357]
	TIME [epoch: 11.6 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37313783793861244		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.37313783793861244 | validation: 0.352123780512794]
	TIME [epoch: 11.5 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39123717394284996		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.39123717394284996 | validation: 0.7804188892306648]
	TIME [epoch: 11.5 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.57883735047777		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.57883735047777 | validation: 0.7948609731263989]
	TIME [epoch: 11.5 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7158415221165524		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.7158415221165524 | validation: 0.3976925150682873]
	TIME [epoch: 11.6 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36488533657771793		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.36488533657771793 | validation: 0.4895614242229817]
	TIME [epoch: 11.5 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.423823296583299		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.423823296583299 | validation: 0.33995376228408036]
	TIME [epoch: 11.5 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3065511386780798		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.3065511386780798 | validation: 0.2420710443742355]
	TIME [epoch: 11.6 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23826402825559573		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.23826402825559573 | validation: 0.33479745660505855]
	TIME [epoch: 11.5 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7049207247304947		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.7049207247304947 | validation: 0.5968520743823202]
	TIME [epoch: 11.5 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.364106906613397		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.364106906613397 | validation: 0.31118852386441326]
	TIME [epoch: 11.6 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30210020412439537		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.30210020412439537 | validation: 0.5404733567822779]
	TIME [epoch: 11.5 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5260750363463738		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.5260750363463738 | validation: 0.3371716617943927]
	TIME [epoch: 11.5 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.342441067078906		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.342441067078906 | validation: 0.2874103688751746]
	TIME [epoch: 11.6 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2976295613902161		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.2976295613902161 | validation: 0.2495266165934631]
	TIME [epoch: 11.5 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2394259306140486		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.2394259306140486 | validation: 0.24621704929696656]
	TIME [epoch: 11.5 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2379706702138382		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.2379706702138382 | validation: 0.22616010333298334]
	TIME [epoch: 11.5 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21928242257231922		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.21928242257231922 | validation: 0.2377010373615701]
	TIME [epoch: 11.6 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20942405870025385		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.20942405870025385 | validation: 0.26285068662600325]
	TIME [epoch: 11.5 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2228597426729071		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.2228597426729071 | validation: 0.1501328753435002]
	TIME [epoch: 11.5 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13959361486205213		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.13959361486205213 | validation: 0.12216254523318004]
	TIME [epoch: 11.6 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21604183711569697		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.21604183711569697 | validation: 0.23858237749103953]
	TIME [epoch: 11.5 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4650861080064487		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.4650861080064487 | validation: 0.8042687144756109]
	TIME [epoch: 11.5 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40964331218103417		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.40964331218103417 | validation: 0.21353630128340556]
	TIME [epoch: 11.6 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23189629716375953		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.23189629716375953 | validation: 0.3169098456688654]
	TIME [epoch: 11.5 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21884421336979154		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.21884421336979154 | validation: 0.15547366731555667]
	TIME [epoch: 11.5 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1153155900010844		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.1153155900010844 | validation: 0.17649658043770394]
	TIME [epoch: 11.6 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18666707453273038		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.18666707453273038 | validation: 0.12114544117357151]
	TIME [epoch: 11.5 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11199167544301235		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.11199167544301235 | validation: 0.137227345977994]
	TIME [epoch: 11.5 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18683908028760748		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.18683908028760748 | validation: 0.20200788600262398]
	TIME [epoch: 11.5 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2064805071764238		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.2064805071764238 | validation: 0.2788154900654757]
	TIME [epoch: 11.6 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3073725422653814		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.3073725422653814 | validation: 0.30212305721673055]
	TIME [epoch: 11.5 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2039669049748553		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.2039669049748553 | validation: 0.13763584341465848]
	TIME [epoch: 11.5 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20191508411294418		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.20191508411294418 | validation: 0.23375125585606596]
	TIME [epoch: 11.6 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27521499550073925		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.27521499550073925 | validation: 0.21845230256290712]
	TIME [epoch: 11.5 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15219958485929108		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.15219958485929108 | validation: 0.18630389477523251]
	TIME [epoch: 11.5 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24991581166178162		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.24991581166178162 | validation: 0.3395593925792503]
	TIME [epoch: 11.6 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2855536677866195		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.2855536677866195 | validation: 0.22700329229530997]
	TIME [epoch: 11.5 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1994024047337894		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.1994024047337894 | validation: 0.2156627956605052]
	TIME [epoch: 11.5 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1968990313366704		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.1968990313366704 | validation: 0.1534682830541632]
	TIME [epoch: 11.6 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18117361861498646		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.18117361861498646 | validation: 0.14557249795094188]
	TIME [epoch: 11.5 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15405844060343138		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.15405844060343138 | validation: 0.12252393865814375]
	TIME [epoch: 11.5 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12384959406218185		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.12384959406218185 | validation: 0.13997428107173376]
	TIME [epoch: 11.5 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1603810819223554		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.1603810819223554 | validation: 0.16387006936333967]
	TIME [epoch: 11.6 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1558051564803289		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.1558051564803289 | validation: 0.1442384790387308]
	TIME [epoch: 11.5 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12299619210215873		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.12299619210215873 | validation: 0.11815690280322443]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_359.pth
	Model improved!!!
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6943853402352171		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.6943853402352171 | validation: 1.9556078911745525]
	TIME [epoch: 11.6 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2459135780912785		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 1.2459135780912785 | validation: 0.22045109626557177]
	TIME [epoch: 11.5 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20900661303526735		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.20900661303526735 | validation: 0.3510012126263689]
	TIME [epoch: 11.5 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6866920207115927		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.6866920207115927 | validation: 1.496968208768901]
	TIME [epoch: 11.5 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0977268074480124		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 1.0977268074480124 | validation: 0.473735459210359]
	TIME [epoch: 11.5 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2622381037586669		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.2622381037586669 | validation: 0.12309745767087833]
	TIME [epoch: 11.5 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15114375213537867		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.15114375213537867 | validation: 0.2450497452067587]
	TIME [epoch: 11.6 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4963381216847406		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.4963381216847406 | validation: 0.260257043801648]
	TIME [epoch: 11.5 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2739238237709787		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.2739238237709787 | validation: 0.3556872461479181]
	TIME [epoch: 11.5 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2846207996278119		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.2846207996278119 | validation: 0.20054626722898802]
	TIME [epoch: 11.5 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6420960978797299		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.6420960978797299 | validation: 1.1884303714749291]
	TIME [epoch: 11.5 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6457439504552778		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.6457439504552778 | validation: 0.28934886307077384]
	TIME [epoch: 11.5 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24946336689625914		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.24946336689625914 | validation: 0.2512799332294187]
	TIME [epoch: 11.5 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1814269270633345		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.1814269270633345 | validation: 0.15140847893748238]
	TIME [epoch: 11.5 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12706742845436358		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.12706742845436358 | validation: 0.15060270225330932]
	TIME [epoch: 11.5 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23627429698923402		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.23627429698923402 | validation: 0.5174389719208153]
	TIME [epoch: 11.5 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5088356121119761		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.5088356121119761 | validation: 0.3294996853307996]
	TIME [epoch: 11.5 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24530591708041066		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.24530591708041066 | validation: 0.3014032693069579]
	TIME [epoch: 11.5 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24623265386833462		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.24623265386833462 | validation: 0.14492184801113037]
	TIME [epoch: 11.5 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12591567138900644		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.12591567138900644 | validation: 0.11215579946453472]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_379.pth
	Model improved!!!
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13634994454030086		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.13634994454030086 | validation: 0.1741966065277514]
	TIME [epoch: 11.5 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13953191815277116		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.13953191815277116 | validation: 0.1421870922930172]
	TIME [epoch: 11.5 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13583657102070915		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.13583657102070915 | validation: 0.1310368656372081]
	TIME [epoch: 11.5 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14871013190518786		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.14871013190518786 | validation: 0.20263938608013513]
	TIME [epoch: 11.5 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20441113788453227		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.20441113788453227 | validation: 0.23286175126593775]
	TIME [epoch: 11.5 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24666026411681805		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.24666026411681805 | validation: 0.1648507968830892]
	TIME [epoch: 11.5 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23165473852917912		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.23165473852917912 | validation: 0.212900300623821]
	TIME [epoch: 11.5 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24065940900034422		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.24065940900034422 | validation: 0.14676812484300986]
	TIME [epoch: 11.5 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1490460141244117		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.1490460141244117 | validation: 0.1743391345363576]
	TIME [epoch: 11.5 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1477399170827337		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.1477399170827337 | validation: 0.1639866050894814]
	TIME [epoch: 11.5 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1452584145005667		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.1452584145005667 | validation: 0.12927608242610011]
	TIME [epoch: 11.5 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19392927449403213		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.19392927449403213 | validation: 0.20416511635522377]
	TIME [epoch: 11.5 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17314136420476242		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.17314136420476242 | validation: 0.13564010560923317]
	TIME [epoch: 11.5 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14525163141663056		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.14525163141663056 | validation: 0.21125986746819997]
	TIME [epoch: 11.5 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4077306607385216		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.4077306607385216 | validation: 0.6232193816755183]
	TIME [epoch: 11.5 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6695260732130303		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.6695260732130303 | validation: 0.4028636968446224]
	TIME [epoch: 11.5 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4460951667263141		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.4460951667263141 | validation: 0.5599700974832881]
	TIME [epoch: 11.5 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5768919072031653		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.5768919072031653 | validation: 0.23469467792456405]
	TIME [epoch: 11.5 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6739248546676204		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.6739248546676204 | validation: 0.6585160313969389]
	TIME [epoch: 11.5 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44509948570873836		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.44509948570873836 | validation: 0.2856520754549733]
	TIME [epoch: 11.6 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31460848701457844		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.31460848701457844 | validation: 0.3495281122937341]
	TIME [epoch: 11.5 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23940212646424897		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.23940212646424897 | validation: 0.18180074361973073]
	TIME [epoch: 11.5 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13835341176940505		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.13835341176940505 | validation: 0.2014352621002017]
	TIME [epoch: 11.5 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1754169936420826		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.1754169936420826 | validation: 0.1515321758919692]
	TIME [epoch: 11.5 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11815035173360587		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.11815035173360587 | validation: 0.10700762781220263]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_404.pth
	Model improved!!!
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07735883085222203		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.07735883085222203 | validation: 0.09353929461349626]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_405.pth
	Model improved!!!
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0846414876776873		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.0846414876776873 | validation: 0.12156509094756074]
	TIME [epoch: 11.5 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13770461909484974		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.13770461909484974 | validation: 0.07982597988844012]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_407.pth
	Model improved!!!
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08004013956976924		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.08004013956976924 | validation: 0.15506405849546787]
	TIME [epoch: 11.5 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20593480297296823		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.20593480297296823 | validation: 0.19734337041288338]
	TIME [epoch: 11.5 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26483826030395374		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.26483826030395374 | validation: 0.6969759315694346]
	TIME [epoch: 11.5 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5965308808751785		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.5965308808751785 | validation: 0.2524342067203563]
	TIME [epoch: 11.6 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27749938073209257		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.27749938073209257 | validation: 0.23461087149927978]
	TIME [epoch: 11.5 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20654941055438586		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.20654941055438586 | validation: 0.24339516918253054]
	TIME [epoch: 11.5 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22576711847948705		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.22576711847948705 | validation: 0.16581379315834105]
	TIME [epoch: 11.5 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15307656047087428		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.15307656047087428 | validation: 0.12681386493233818]
	TIME [epoch: 11.5 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2925020625771618		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.2925020625771618 | validation: 1.0181363178768572]
	TIME [epoch: 11.5 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9346706743038138		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.9346706743038138 | validation: 0.6508369336440498]
	TIME [epoch: 11.5 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.548558306391977		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.548558306391977 | validation: 0.31811511794804737]
	TIME [epoch: 11.5 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2963870777538458		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.2963870777538458 | validation: 0.3084800381288723]
	TIME [epoch: 11.5 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26761465813620144		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.26761465813620144 | validation: 0.20389540056136504]
	TIME [epoch: 11.5 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25499044077510835		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.25499044077510835 | validation: 0.16789514244894413]
	TIME [epoch: 11.6 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17469830434947142		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.17469830434947142 | validation: 0.1635604322094882]
	TIME [epoch: 11.5 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22551690447427764		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.22551690447427764 | validation: 0.39366269409172033]
	TIME [epoch: 11.5 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.817962146303064		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.817962146303064 | validation: 1.0804981708317245]
	TIME [epoch: 11.5 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8568657384668171		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.8568657384668171 | validation: 0.3653426654039177]
	TIME [epoch: 11.5 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38543232575967334		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.38543232575967334 | validation: 0.3134981066340374]
	TIME [epoch: 11.5 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26509581219843265		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.26509581219843265 | validation: 0.21727183487261534]
	TIME [epoch: 11.5 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17064550358497202		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.17064550358497202 | validation: 0.2466343090148854]
	TIME [epoch: 11.5 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25938876394242893		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.25938876394242893 | validation: 0.11529969029789269]
	TIME [epoch: 11.5 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15130620372169112		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.15130620372169112 | validation: 0.21712672962196033]
	TIME [epoch: 11.5 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15746479966702007		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.15746479966702007 | validation: 0.1354325900387019]
	TIME [epoch: 11.6 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2150148377131424		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.2150148377131424 | validation: 0.20332623871014044]
	TIME [epoch: 11.5 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19532096037244787		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.19532096037244787 | validation: 0.10476218292547547]
	TIME [epoch: 11.5 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11289357320397234		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.11289357320397234 | validation: 0.09023854956906094]
	TIME [epoch: 11.5 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1257859139490971		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.1257859139490971 | validation: 0.10922127005795845]
	TIME [epoch: 11.5 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11418121056378554		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.11418121056378554 | validation: 0.09002840378680556]
	TIME [epoch: 11.5 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11269373722289044		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.11269373722289044 | validation: 0.12106057487504501]
	TIME [epoch: 11.5 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1139766469659527		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.1139766469659527 | validation: 0.20998056360707368]
	TIME [epoch: 11.5 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7217566708287729		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.7217566708287729 | validation: 1.5005999213586971]
	TIME [epoch: 11.5 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0676951960403307		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 1.0676951960403307 | validation: 0.4851034265287061]
	TIME [epoch: 11.5 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3012462140196379		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.3012462140196379 | validation: 0.1835507279181057]
	TIME [epoch: 11.5 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16304604319629926		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.16304604319629926 | validation: 0.15672524445135516]
	TIME [epoch: 11.5 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1377006956600734		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.1377006956600734 | validation: 0.13334018300477102]
	TIME [epoch: 11.5 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13928038974430274		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.13928038974430274 | validation: 0.22228181796740193]
	TIME [epoch: 11.5 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19647386733248257		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.19647386733248257 | validation: 0.13442807144602945]
	TIME [epoch: 11.5 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15009914013305808		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.15009914013305808 | validation: 0.24723606250068514]
	TIME [epoch: 11.5 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19379420474896258		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.19379420474896258 | validation: 0.14037677283056219]
	TIME [epoch: 11.5 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12655055747218205		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.12655055747218205 | validation: 0.15155933217469592]
	TIME [epoch: 11.5 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15181028935567886		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.15181028935567886 | validation: 0.1777398593529492]
	TIME [epoch: 11.5 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1379082463918562		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.1379082463918562 | validation: 0.09783942124250952]
	TIME [epoch: 11.6 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13793436830975014		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.13793436830975014 | validation: 0.21382784640149508]
	TIME [epoch: 11.5 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3293293108111339		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.3293293108111339 | validation: 0.17821422591821418]
	TIME [epoch: 11.5 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18979398407477022		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.18979398407477022 | validation: 0.24152114789252702]
	TIME [epoch: 11.5 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31943446890686455		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.31943446890686455 | validation: 0.4554714799579258]
	TIME [epoch: 11.5 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3405154727020768		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.3405154727020768 | validation: 0.263779615504785]
	TIME [epoch: 11.5 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31283643608233175		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.31283643608233175 | validation: 0.40086055326515846]
	TIME [epoch: 11.5 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30413472099057565		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.30413472099057565 | validation: 0.20630410358145448]
	TIME [epoch: 11.5 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19944996093385717		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.19944996093385717 | validation: 0.23240374174236597]
	TIME [epoch: 11.5 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18348384912800897		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.18348384912800897 | validation: 0.20880279190741136]
	TIME [epoch: 11.5 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21037795882233606		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.21037795882233606 | validation: 0.17812614017220132]
	TIME [epoch: 11.5 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1290366426637995		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.1290366426637995 | validation: 0.11508466602584339]
	TIME [epoch: 11.5 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15321036682663403		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.15321036682663403 | validation: 0.2859358819626763]
	TIME [epoch: 11.5 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31062323665076375		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.31062323665076375 | validation: 0.20857972149394102]
	TIME [epoch: 11.5 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22047291089648724		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.22047291089648724 | validation: 0.323589171161214]
	TIME [epoch: 11.5 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2298968236241022		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.2298968236241022 | validation: 0.17517991314745124]
	TIME [epoch: 11.5 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1939585112382064		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.1939585112382064 | validation: 0.15324303740212608]
	TIME [epoch: 11.5 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15467469296397401		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.15467469296397401 | validation: 0.13776046180302673]
	TIME [epoch: 11.5 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1267580179001372		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.1267580179001372 | validation: 0.10179654521046091]
	TIME [epoch: 11.5 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12455347782698455		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.12455347782698455 | validation: 0.17872980072788366]
	TIME [epoch: 11.5 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18630198540092469		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.18630198540092469 | validation: 0.19842604151977278]
	TIME [epoch: 11.5 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21186705021998536		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.21186705021998536 | validation: 0.18409049311775472]
	TIME [epoch: 11.5 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1670668873400209		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.1670668873400209 | validation: 0.19238592745710165]
	TIME [epoch: 11.5 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23144609916769857		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.23144609916769857 | validation: 0.17165579814806217]
	TIME [epoch: 11.5 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16983191255344987		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.16983191255344987 | validation: 0.2872366318115994]
	TIME [epoch: 11.5 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3309286506481681		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.3309286506481681 | validation: 0.4349282321747988]
	TIME [epoch: 11.5 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4228802692689		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.4228802692689 | validation: 0.2365073952101292]
	TIME [epoch: 11.5 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1793416433278966		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.1793416433278966 | validation: 0.1462155086454759]
	TIME [epoch: 11.5 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16215672558456376		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.16215672558456376 | validation: 0.23974061471921382]
	TIME [epoch: 11.5 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2999504828244106		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.2999504828244106 | validation: 0.231826135780442]
	TIME [epoch: 11.5 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2055383262915582		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.2055383262915582 | validation: 0.20737635940270202]
	TIME [epoch: 11.6 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15749624188115016		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.15749624188115016 | validation: 0.1974472861809028]
	TIME [epoch: 11.5 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20171335377243246		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.20171335377243246 | validation: 0.1807022194855473]
	TIME [epoch: 11.5 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17006476998722103		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.17006476998722103 | validation: 0.18216367439996853]
	TIME [epoch: 11.6 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17649976385584543		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.17649976385584543 | validation: 0.14640372439264773]
	TIME [epoch: 11.5 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17243411645484866		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.17243411645484866 | validation: 0.20359158574892322]
	TIME [epoch: 11.5 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16836843110219435		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.16836843110219435 | validation: 0.12383733776838916]
	TIME [epoch: 11.5 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09818696521056122		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.09818696521056122 | validation: 0.10272614497056959]
	TIME [epoch: 11.5 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13524471197814814		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.13524471197814814 | validation: 0.11565382023713379]
	TIME [epoch: 11.5 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13961745609159132		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.13961745609159132 | validation: 0.39514823509200325]
	TIME [epoch: 11.5 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31134013533770477		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.31134013533770477 | validation: 0.23529782293144835]
	TIME [epoch: 11.5 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1597209356492196		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.1597209356492196 | validation: 0.18797962883012667]
	TIME [epoch: 11.5 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1807134405151375		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.1807134405151375 | validation: 0.1536672175776511]
	TIME [epoch: 11.5 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1384688674649716		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.1384688674649716 | validation: 0.20792513754486933]
	TIME [epoch: 11.5 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2020160367820641		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.2020160367820641 | validation: 0.20912091294945215]
	TIME [epoch: 11.5 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18035881148935695		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.18035881148935695 | validation: 0.17131996460002868]
	TIME [epoch: 11.5 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1541086004029461		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.1541086004029461 | validation: 0.1571400274347388]
	TIME [epoch: 11.5 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16196778007271148		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.16196778007271148 | validation: 0.17815268639160706]
	TIME [epoch: 11.5 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14500743312165354		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.14500743312165354 | validation: 0.14287971214441494]
	TIME [epoch: 11.5 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1239713789381772		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.1239713789381772 | validation: 0.14861187307085]
	TIME [epoch: 11.5 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12043702729719577		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.12043702729719577 | validation: 0.13108133021144883]
	TIME [epoch: 11.5 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1266827857143975		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.1266827857143975 | validation: 0.1274903557909993]
	TIME [epoch: 11.5 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11791043899331324		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.11791043899331324 | validation: 0.1301913844286825]
	TIME [epoch: 11.5 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11999732758345116		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.11999732758345116 | validation: 0.09501437885810568]
	TIME [epoch: 11.5 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10482952467452072		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.10482952467452072 | validation: 0.1131932619483158]
	TIME [epoch: 11.5 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10930921694667159		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.10930921694667159 | validation: 0.1458703348004878]
	TIME [epoch: 11.5 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1524195755977802		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.1524195755977802 | validation: 0.11762393269828783]
	TIME [epoch: 11.5 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11069408521699771		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.11069408521699771 | validation: 0.0993965843196418]
	TIME [epoch: 11.5 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10162896718291585		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.10162896718291585 | validation: 0.09623061976685307]
	TIME [epoch: 11.5 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08760469604261589		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.08760469604261589 | validation: 0.10260402120294027]
	TIME [epoch: 11.6 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13107602202994742		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.13107602202994742 | validation: 0.16039978125499174]
	TIME [epoch: 11.5 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14678234898427495		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.14678234898427495 | validation: 0.22233461404464291]
	TIME [epoch: 11.5 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16996666997888218		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.16996666997888218 | validation: 0.13584749912394642]
	TIME [epoch: 11.5 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17448620610533438		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.17448620610533438 | validation: 0.31634204486241724]
	TIME [epoch: 11.5 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29886125114630313		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.29886125114630313 | validation: 0.29074341577095275]
	TIME [epoch: 11.5 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4146024149778358		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.4146024149778358 | validation: 0.5582122355983332]
	TIME [epoch: 11.5 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5744622124729748		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.5744622124729748 | validation: 0.26965659507390854]
	TIME [epoch: 11.5 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23452957628628637		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.23452957628628637 | validation: 0.17971708523963603]
	TIME [epoch: 11.5 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.153392545716808		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.153392545716808 | validation: 0.1501475873112318]
	TIME [epoch: 11.5 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14487323848038913		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.14487323848038913 | validation: 0.1385709183525356]
	TIME [epoch: 11.5 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12189075270193049		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.12189075270193049 | validation: 0.13346227191977394]
	TIME [epoch: 11.5 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14842668173696671		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.14842668173696671 | validation: 0.1983430429205962]
	TIME [epoch: 11.5 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17548471423593767		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.17548471423593767 | validation: 0.1887121147848444]
	TIME [epoch: 11.5 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15981758580693917		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.15981758580693917 | validation: 0.19574163794013777]
	TIME [epoch: 11.5 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1790078571296869		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.1790078571296869 | validation: 0.20039533867987025]
	TIME [epoch: 11.5 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1733374480004823		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.1733374480004823 | validation: 0.12270143675690816]
	TIME [epoch: 11.5 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11096805124483752		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.11096805124483752 | validation: 0.11806420654219289]
	TIME [epoch: 11.5 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12805877977012364		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.12805877977012364 | validation: 0.1888366668405117]
	TIME [epoch: 11.5 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1768146392351646		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.1768146392351646 | validation: 0.1708526050856331]
	TIME [epoch: 11.5 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12193405465598461		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.12193405465598461 | validation: 0.13950597899038217]
	TIME [epoch: 11.5 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15343155472291914		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.15343155472291914 | validation: 0.14906079582570983]
	TIME [epoch: 11.5 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11530682073463659		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.11530682073463659 | validation: 0.11485844504268018]
	TIME [epoch: 11.5 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1827437530855874		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.1827437530855874 | validation: 0.36393074461221214]
	TIME [epoch: 11.5 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6004053727530636		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.6004053727530636 | validation: 0.3868044078329608]
	TIME [epoch: 11.5 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25821546036159543		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.25821546036159543 | validation: 0.1468444031945921]
	TIME [epoch: 11.5 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13745840523745118		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.13745840523745118 | validation: 0.10065647212476969]
	TIME [epoch: 11.5 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10078447651239142		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.10078447651239142 | validation: 0.07184174861101643]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_536.pth
	Model improved!!!
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09188904912575292		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.09188904912575292 | validation: 0.12349441789552312]
	TIME [epoch: 11.5 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0898234679806316		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.0898234679806316 | validation: 0.07809370488715967]
	TIME [epoch: 11.5 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07689448559757575		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.07689448559757575 | validation: 0.08007768282037268]
	TIME [epoch: 11.5 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06896321161505098		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.06896321161505098 | validation: 0.07264817016577062]
	TIME [epoch: 11.5 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08559867559385179		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.08559867559385179 | validation: 0.07147789658778637]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_541.pth
	Model improved!!!
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08054457815269576		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.08054457815269576 | validation: 0.09144517888713949]
	TIME [epoch: 11.5 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0988489554211628		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.0988489554211628 | validation: 0.10041820123862417]
	TIME [epoch: 11.5 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10706498573260151		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.10706498573260151 | validation: 0.08272674180883036]
	TIME [epoch: 11.5 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09254490854136678		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.09254490854136678 | validation: 0.09304825978630273]
	TIME [epoch: 11.5 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08807414211706907		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.08807414211706907 | validation: 0.08757461403917428]
	TIME [epoch: 11.5 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09679301935266535		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.09679301935266535 | validation: 0.10255919205421114]
	TIME [epoch: 11.5 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09520014052029427		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.09520014052029427 | validation: 0.10699312861398856]
	TIME [epoch: 11.5 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11014892370555751		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.11014892370555751 | validation: 0.15156680645009799]
	TIME [epoch: 11.5 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23575320288161553		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.23575320288161553 | validation: 0.2759687192546979]
	TIME [epoch: 11.5 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21203992298670704		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.21203992298670704 | validation: 0.1689898952976185]
	TIME [epoch: 11.5 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1256906223898942		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.1256906223898942 | validation: 0.10357172734718711]
	TIME [epoch: 11.5 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08692995089414504		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.08692995089414504 | validation: 0.08860196679920225]
	TIME [epoch: 11.5 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0891171230218672		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.0891171230218672 | validation: 0.09227811597621251]
	TIME [epoch: 11.5 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13155883441773705		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.13155883441773705 | validation: 0.33835818417605773]
	TIME [epoch: 11.5 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2107909800402485		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.2107909800402485 | validation: 0.10106418851145745]
	TIME [epoch: 11.5 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09882567227012308		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.09882567227012308 | validation: 0.1813895881665693]
	TIME [epoch: 11.5 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15965212581452265		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.15965212581452265 | validation: 0.12421006948404116]
	TIME [epoch: 11.5 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11285432690732754		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.11285432690732754 | validation: 0.07137213712551832]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_559.pth
	Model improved!!!
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10238915560931		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.10238915560931 | validation: 0.10989342633300078]
	TIME [epoch: 11.5 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08998270273782588		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.08998270273782588 | validation: 0.10004254478326628]
	TIME [epoch: 11.5 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08066552098943121		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.08066552098943121 | validation: 0.0644244122052913]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_562.pth
	Model improved!!!
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07500358085438663		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.07500358085438663 | validation: 0.07072778497892372]
	TIME [epoch: 11.5 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07303567338766015		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.07303567338766015 | validation: 0.06289505141216606]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_564.pth
	Model improved!!!
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07017066793824614		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.07017066793824614 | validation: 0.05755433212907992]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_565.pth
	Model improved!!!
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06487029303696269		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.06487029303696269 | validation: 0.07258209363707888]
	TIME [epoch: 11.5 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08645455580528308		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.08645455580528308 | validation: 0.10077735092185254]
	TIME [epoch: 11.5 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08251917540665556		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.08251917540665556 | validation: 0.07357139384671971]
	TIME [epoch: 11.5 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07199354456542713		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.07199354456542713 | validation: 0.07835935089821951]
	TIME [epoch: 11.5 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09750483603855065		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.09750483603855065 | validation: 0.10757714427342645]
	TIME [epoch: 11.5 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10194531351826208		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.10194531351826208 | validation: 0.11212399663032986]
	TIME [epoch: 11.5 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0864099660225757		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.0864099660225757 | validation: 0.07024156297473158]
	TIME [epoch: 11.5 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07773201199947757		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.07773201199947757 | validation: 0.09056593552918622]
	TIME [epoch: 11.5 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13686425716090114		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.13686425716090114 | validation: 0.09851773938663247]
	TIME [epoch: 11.5 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08993109968852309		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.08993109968852309 | validation: 0.10215588868250308]
	TIME [epoch: 11.5 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.103084273786294		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.103084273786294 | validation: 0.08056598996705094]
	TIME [epoch: 11.5 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07859889524685068		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.07859889524685068 | validation: 0.08726668478718157]
	TIME [epoch: 11.5 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09481024336133094		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.09481024336133094 | validation: 0.08201362710075706]
	TIME [epoch: 11.5 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08061231393684838		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.08061231393684838 | validation: 0.05337300610582107]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_579.pth
	Model improved!!!
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06561930449539767		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.06561930449539767 | validation: 0.08585089271610429]
	TIME [epoch: 11.5 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07187722057322937		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.07187722057322937 | validation: 0.07204493323180639]
	TIME [epoch: 11.5 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09028276872627583		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.09028276872627583 | validation: 0.09126804320342492]
	TIME [epoch: 11.5 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11474272392954538		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.11474272392954538 | validation: 0.11300863800350662]
	TIME [epoch: 11.5 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10365117950836253		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.10365117950836253 | validation: 0.07269099343735076]
	TIME [epoch: 11.5 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06454953023738713		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.06454953023738713 | validation: 0.07905483750036917]
	TIME [epoch: 11.5 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06802108839417964		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.06802108839417964 | validation: 0.08010164255961588]
	TIME [epoch: 11.5 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06204448004450071		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.06204448004450071 | validation: 0.0671201066642414]
	TIME [epoch: 11.5 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06184259537434907		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.06184259537434907 | validation: 0.07715081764069238]
	TIME [epoch: 11.5 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07850235799585585		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.07850235799585585 | validation: 0.08789008286047566]
	TIME [epoch: 11.5 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09743619839722123		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.09743619839722123 | validation: 0.10618008796990333]
	TIME [epoch: 11.5 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11094066466299661		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.11094066466299661 | validation: 0.12758859372345197]
	TIME [epoch: 11.5 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1113189914630992		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.1113189914630992 | validation: 0.10046520895936584]
	TIME [epoch: 11.5 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0990028933788751		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.0990028933788751 | validation: 0.11405622204258795]
	TIME [epoch: 11.5 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10230214778152907		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.10230214778152907 | validation: 0.09214728614747428]
	TIME [epoch: 11.5 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08336054968925179		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.08336054968925179 | validation: 0.07002684054144631]
	TIME [epoch: 11.5 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06835482886991807		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.06835482886991807 | validation: 0.13005885608903373]
	TIME [epoch: 11.5 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.203210542872689		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.203210542872689 | validation: 0.1843566737584812]
	TIME [epoch: 11.5 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12297247277725058		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.12297247277725058 | validation: 0.08154444060011112]
	TIME [epoch: 11.5 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07397909835509558		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.07397909835509558 | validation: 0.06750864582706369]
	TIME [epoch: 11.5 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0686777938839693		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.0686777938839693 | validation: 0.06548173995539805]
	TIME [epoch: 11.5 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08800373299224784		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.08800373299224784 | validation: 0.16437803304182416]
	TIME [epoch: 11.5 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1718452986963295		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.1718452986963295 | validation: 0.22480716198450224]
	TIME [epoch: 11.5 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13241383564584605		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.13241383564584605 | validation: 0.06075205437200557]
	TIME [epoch: 11.5 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07127551625399527		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.07127551625399527 | validation: 0.07410961085514883]
	TIME [epoch: 11.5 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06975636658354978		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.06975636658354978 | validation: 0.06695742626886712]
	TIME [epoch: 11.5 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06951880423993265		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.06951880423993265 | validation: 0.07574223817027502]
	TIME [epoch: 11.5 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0780981670070918		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.0780981670070918 | validation: 0.11099652229845505]
	TIME [epoch: 11.5 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08455323439074411		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.08455323439074411 | validation: 0.07756603142509694]
	TIME [epoch: 11.5 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09435169638404851		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.09435169638404851 | validation: 0.17812088907503157]
	TIME [epoch: 11.5 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27030978927711913		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.27030978927711913 | validation: 0.33271350741342703]
	TIME [epoch: 11.5 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20409385872579483		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.20409385872579483 | validation: 0.20356299896349042]
	TIME [epoch: 11.5 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20260348171017134		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.20260348171017134 | validation: 0.16261121271487677]
	TIME [epoch: 11.5 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11426478044549854		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.11426478044549854 | validation: 0.1379598709811144]
	TIME [epoch: 11.5 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19050872045307626		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.19050872045307626 | validation: 0.34072794623583236]
	TIME [epoch: 11.5 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2806274482558304		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.2806274482558304 | validation: 0.23044690696477996]
	TIME [epoch: 11.5 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19962799286212302		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.19962799286212302 | validation: 0.18379819391173094]
	TIME [epoch: 11.5 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13997039835945468		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.13997039835945468 | validation: 0.13993846297566914]
	TIME [epoch: 11.5 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15474166316502241		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.15474166316502241 | validation: 0.1705571225125474]
	TIME [epoch: 11.5 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19774517581596684		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.19774517581596684 | validation: 0.3959708002809292]
	TIME [epoch: 11.5 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5213268449982161		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.5213268449982161 | validation: 0.6269655513760891]
	TIME [epoch: 11.5 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5740949880771006		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.5740949880771006 | validation: 0.49065703365490143]
	TIME [epoch: 11.5 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3621443391002503		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.3621443391002503 | validation: 0.21773330962398163]
	TIME [epoch: 11.5 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2093108029367216		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.2093108029367216 | validation: 0.1294032402573055]
	TIME [epoch: 11.5 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14036961409276993		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.14036961409276993 | validation: 0.10564493724346079]
	TIME [epoch: 11.5 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10238191151071926		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.10238191151071926 | validation: 0.07614310638591003]
	TIME [epoch: 11.5 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08255419125859362		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.08255419125859362 | validation: 0.08716675665862841]
	TIME [epoch: 11.5 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09204742656552428		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.09204742656552428 | validation: 0.08783972360354919]
	TIME [epoch: 11.5 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10274105053074739		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.10274105053074739 | validation: 0.12714112019885615]
	TIME [epoch: 11.5 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09927772343663815		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.09927772343663815 | validation: 0.07662922014083601]
	TIME [epoch: 11.5 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08287146475490423		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.08287146475490423 | validation: 0.07049469660655792]
	TIME [epoch: 11.5 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07140139455569844		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.07140139455569844 | validation: 0.1003501294659187]
	TIME [epoch: 11.5 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10214964258071617		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.10214964258071617 | validation: 0.08985620782117444]
	TIME [epoch: 11.6 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08420659868676264		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.08420659868676264 | validation: 0.07484474149804836]
	TIME [epoch: 11.5 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07788756385499683		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.07788756385499683 | validation: 0.07990339524153728]
	TIME [epoch: 11.5 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09395746538949984		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.09395746538949984 | validation: 0.10100509851635009]
	TIME [epoch: 11.5 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11143569450876664		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.11143569450876664 | validation: 0.08499629303975954]
	TIME [epoch: 11.5 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08336225667187395		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.08336225667187395 | validation: 0.06610908679898347]
	TIME [epoch: 11.5 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06460738238299077		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.06460738238299077 | validation: 0.06954312947303477]
	TIME [epoch: 11.5 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054179729235696354		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.054179729235696354 | validation: 0.05620462367644045]
	TIME [epoch: 11.5 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054754870366443914		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.054754870366443914 | validation: 0.06480084474163403]
	TIME [epoch: 11.5 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0671122315031418		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.0671122315031418 | validation: 0.07571516905720295]
	TIME [epoch: 11.5 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06888621863893249		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.06888621863893249 | validation: 0.074931422534991]
	TIME [epoch: 11.5 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09119280159883411		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.09119280159883411 | validation: 0.08052755450000308]
	TIME [epoch: 11.5 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06266262736064737		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.06266262736064737 | validation: 0.05270061415906623]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_644.pth
	Model improved!!!
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05849034568430809		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.05849034568430809 | validation: 0.061245861232136746]
	TIME [epoch: 11.5 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06433232664228442		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.06433232664228442 | validation: 0.09623042081282833]
	TIME [epoch: 11.5 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0907034705962452		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.0907034705962452 | validation: 0.06495464815445469]
	TIME [epoch: 11.5 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0687151171861953		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.0687151171861953 | validation: 0.07610792687409443]
	TIME [epoch: 11.5 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09531065962879143		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.09531065962879143 | validation: 0.09369123397292482]
	TIME [epoch: 11.5 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12890675151515718		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.12890675151515718 | validation: 0.15300089467788391]
	TIME [epoch: 11.5 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18080793670028433		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.18080793670028433 | validation: 0.2345882672635188]
	TIME [epoch: 11.5 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1670765435934048		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.1670765435934048 | validation: 0.08858212607625704]
	TIME [epoch: 11.5 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.094206785089763		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.094206785089763 | validation: 0.1446615580313042]
	TIME [epoch: 11.5 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13527568871774318		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.13527568871774318 | validation: 0.2337831485955797]
	TIME [epoch: 11.5 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19901161326855152		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.19901161326855152 | validation: 0.21519143412945746]
	TIME [epoch: 11.5 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17548034487164063		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.17548034487164063 | validation: 0.17896923927175276]
	TIME [epoch: 11.5 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1327721061316512		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.1327721061316512 | validation: 0.06966015245943184]
	TIME [epoch: 11.5 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06274092387563318		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.06274092387563318 | validation: 0.08416167214072864]
	TIME [epoch: 11.5 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08289960625250173		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.08289960625250173 | validation: 0.06781308117234973]
	TIME [epoch: 11.5 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08784569389725479		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.08784569389725479 | validation: 0.1105969591379058]
	TIME [epoch: 11.5 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08185686352210074		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.08185686352210074 | validation: 0.046275174288031844]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_661.pth
	Model improved!!!
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046020679429737074		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.046020679429737074 | validation: 0.045292910617112686]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_662.pth
	Model improved!!!
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03470741121420745		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.03470741121420745 | validation: 0.05274058984118248]
	TIME [epoch: 11.5 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04177787023786245		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.04177787023786245 | validation: 0.04480069903440548]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_664.pth
	Model improved!!!
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038853920818981785		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.038853920818981785 | validation: 0.055460996412809424]
	TIME [epoch: 11.5 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055098259763531665		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.055098259763531665 | validation: 0.07985656090083267]
	TIME [epoch: 11.5 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07747896235634921		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.07747896235634921 | validation: 0.0674322448265163]
	TIME [epoch: 11.6 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05643424537389993		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.05643424537389993 | validation: 0.048620444312218736]
	TIME [epoch: 11.5 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04901162802230995		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.04901162802230995 | validation: 0.061427853752977414]
	TIME [epoch: 11.5 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055727146954839615		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.055727146954839615 | validation: 0.0603814390290523]
	TIME [epoch: 11.5 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06350243467326587		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.06350243467326587 | validation: 0.05679735081269923]
	TIME [epoch: 11.6 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06847300405885456		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.06847300405885456 | validation: 0.08002219174810972]
	TIME [epoch: 11.5 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07164681656878362		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.07164681656878362 | validation: 0.09224577133226028]
	TIME [epoch: 11.5 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07561724453305427		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.07561724453305427 | validation: 0.059987950367620134]
	TIME [epoch: 11.5 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05778204698199536		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.05778204698199536 | validation: 0.055925284821686294]
	TIME [epoch: 11.5 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05305994373593456		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.05305994373593456 | validation: 0.08768882463342227]
	TIME [epoch: 11.5 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06886355767039598		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.06886355767039598 | validation: 0.05095365083504039]
	TIME [epoch: 11.5 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04653693359310504		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.04653693359310504 | validation: 0.05892833560845482]
	TIME [epoch: 11.5 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05004384787982906		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.05004384787982906 | validation: 0.07041831545101346]
	TIME [epoch: 11.5 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05886336939944925		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.05886336939944925 | validation: 0.060880925752291655]
	TIME [epoch: 11.5 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05618021437863498		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.05618021437863498 | validation: 0.06552439184590485]
	TIME [epoch: 11.5 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07690741905962276		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.07690741905962276 | validation: 0.0868981027476223]
	TIME [epoch: 11.5 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08632080931148368		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.08632080931148368 | validation: 0.08688333418516533]
	TIME [epoch: 11.5 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10255590301020287		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.10255590301020287 | validation: 0.10979175159736825]
	TIME [epoch: 11.5 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13286830245518594		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.13286830245518594 | validation: 0.12834705764769347]
	TIME [epoch: 11.5 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12593428282521754		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.12593428282521754 | validation: 0.10979826809935446]
	TIME [epoch: 11.5 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1278519378688039		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.1278519378688039 | validation: 0.1217678055239469]
	TIME [epoch: 11.6 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10909860499587012		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.10909860499587012 | validation: 0.10356622866799749]
	TIME [epoch: 11.5 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09322038373329111		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.09322038373329111 | validation: 0.11135798861393278]
	TIME [epoch: 11.5 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.094854866026564		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.094854866026564 | validation: 0.09454548487655881]
	TIME [epoch: 11.5 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07674966133102942		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.07674966133102942 | validation: 0.06902098188489919]
	TIME [epoch: 11.5 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06207965335244179		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.06207965335244179 | validation: 0.06589964689336637]
	TIME [epoch: 11.5 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05869260655360614		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.05869260655360614 | validation: 0.08695283188973532]
	TIME [epoch: 11.5 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0686722771782154		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.0686722771782154 | validation: 0.06125959820311]
	TIME [epoch: 11.5 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0687156307769898		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.0687156307769898 | validation: 0.0526276480843228]
	TIME [epoch: 11.5 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05255028199786381		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.05255028199786381 | validation: 0.06272619730532394]
	TIME [epoch: 11.5 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07144857687697301		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.07144857687697301 | validation: 0.073760627913509]
	TIME [epoch: 11.5 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0582745320079931		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.0582745320079931 | validation: 0.0568975830353968]
	TIME [epoch: 11.5 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07468049536283769		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.07468049536283769 | validation: 0.1424196560907149]
	TIME [epoch: 11.5 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13161965666146902		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.13161965666146902 | validation: 0.1286450109266514]
	TIME [epoch: 11.5 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10357358505972059		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.10357358505972059 | validation: 0.10162187562222201]
	TIME [epoch: 11.5 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08982043646512178		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.08982043646512178 | validation: 0.06295776671289206]
	TIME [epoch: 11.5 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06820441130707267		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.06820441130707267 | validation: 0.08309161898941576]
	TIME [epoch: 11.5 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06487970369020449		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.06487970369020449 | validation: 0.06966849152019462]
	TIME [epoch: 11.5 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05869758628935974		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.05869758628935974 | validation: 0.06942505167038947]
	TIME [epoch: 11.5 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06874061872820789		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.06874061872820789 | validation: 0.06552283508400654]
	TIME [epoch: 11.6 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06647932555667221		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.06647932555667221 | validation: 0.07277815120125587]
	TIME [epoch: 11.5 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08821838698241256		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.08821838698241256 | validation: 0.11289146970215003]
	TIME [epoch: 11.5 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12101996832441406		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.12101996832441406 | validation: 0.12522903103855193]
	TIME [epoch: 11.5 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10485071408607344		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.10485071408607344 | validation: 0.11094068619777099]
	TIME [epoch: 11.5 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1205348460155745		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.1205348460155745 | validation: 0.12440149243480772]
	TIME [epoch: 11.5 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10849568174603981		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.10849568174603981 | validation: 0.09832738369407604]
	TIME [epoch: 11.5 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09439795275332741		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.09439795275332741 | validation: 0.08845855644050182]
	TIME [epoch: 11.5 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08663437531813872		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.08663437531813872 | validation: 0.09432766719740177]
	TIME [epoch: 11.5 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09356810601465221		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.09356810601465221 | validation: 0.09555698809371733]
	TIME [epoch: 11.5 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08782544880871958		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.08782544880871958 | validation: 0.09199389399064307]
	TIME [epoch: 11.5 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08245104703305044		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.08245104703305044 | validation: 0.08175387297743508]
	TIME [epoch: 11.5 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0753010129006869		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.0753010129006869 | validation: 0.07311169139581195]
	TIME [epoch: 11.5 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08027333437146529		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.08027333437146529 | validation: 0.10401884917884126]
	TIME [epoch: 11.5 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08785949693576163		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.08785949693576163 | validation: 0.07794171126508856]
	TIME [epoch: 11.5 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07171659100067172		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.07171659100067172 | validation: 0.07262777187067053]
	TIME [epoch: 11.5 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06615815567412035		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.06615815567412035 | validation: 0.06995132011664294]
	TIME [epoch: 11.5 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06672011591737874		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.06672011591737874 | validation: 0.08711818340763702]
	TIME [epoch: 11.5 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07941760456738044		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.07941760456738044 | validation: 0.08902279546025779]
	TIME [epoch: 11.5 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07561744984194527		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.07561744984194527 | validation: 0.07986727335986847]
	TIME [epoch: 11.5 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09036176090078427		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.09036176090078427 | validation: 0.11692926556762398]
	TIME [epoch: 11.5 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11676534614274149		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.11676534614274149 | validation: 0.10934510334510117]
	TIME [epoch: 11.5 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11802045900784627		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.11802045900784627 | validation: 0.11703849090874638]
	TIME [epoch: 11.5 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1273729131857529		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.1273729131857529 | validation: 0.1617167881464873]
	TIME [epoch: 11.5 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16238601815907291		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.16238601815907291 | validation: 0.13120835858182933]
	TIME [epoch: 11.5 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11056749163964914		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.11056749163964914 | validation: 0.11296483451824578]
	TIME [epoch: 11.5 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1066502172911443		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.1066502172911443 | validation: 0.10178187651424424]
	TIME [epoch: 11.5 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10079885014038192		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.10079885014038192 | validation: 0.10073117707094933]
	TIME [epoch: 11.5 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10337609631117935		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.10337609631117935 | validation: 0.10188106758796392]
	TIME [epoch: 11.5 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1001207644239098		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.1001207644239098 | validation: 0.10758665057652415]
	TIME [epoch: 11.5 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10573713335742393		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.10573713335742393 | validation: 0.10920194753370861]
	TIME [epoch: 11.5 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10037233561715618		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.10037233561715618 | validation: 0.12503689666972598]
	TIME [epoch: 11.5 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11107782803778563		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.11107782803778563 | validation: 0.10245697125164979]
	TIME [epoch: 11.5 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08517238047556042		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.08517238047556042 | validation: 0.08012964491828424]
	TIME [epoch: 11.5 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07398540200996329		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.07398540200996329 | validation: 0.0776245725451891]
	TIME [epoch: 11.5 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07425779026151275		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.07425779026151275 | validation: 0.07121548558885743]
	TIME [epoch: 11.5 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0746526420433866		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.0746526420433866 | validation: 0.08695552825596257]
	TIME [epoch: 11.5 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09293354336487317		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.09293354336487317 | validation: 0.10120051861982454]
	TIME [epoch: 11.5 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09027894719458866		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.09027894719458866 | validation: 0.08306054848376318]
	TIME [epoch: 11.5 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09754103418729163		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.09754103418729163 | validation: 0.10842538096868232]
	TIME [epoch: 11.5 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1000633354717333		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.1000633354717333 | validation: 0.12022592253419663]
	TIME [epoch: 11.5 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1204511935492181		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.1204511935492181 | validation: 0.12127167369943327]
	TIME [epoch: 11.5 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11761723526539546		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.11761723526539546 | validation: 0.12171932564423546]
	TIME [epoch: 11.6 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10601324106395488		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.10601324106395488 | validation: 0.10775123289630535]
	TIME [epoch: 11.5 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10737045776473635		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.10737045776473635 | validation: 0.09574653704572775]
	TIME [epoch: 11.5 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09601080636289305		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.09601080636289305 | validation: 0.10475462154863383]
	TIME [epoch: 11.5 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.089340759750137		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.089340759750137 | validation: 0.0879738654438638]
	TIME [epoch: 11.5 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07747287424705665		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.07747287424705665 | validation: 0.06421753158016485]
	TIME [epoch: 11.5 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07425104808470237		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.07425104808470237 | validation: 0.08697067284548393]
	TIME [epoch: 11.5 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08620490015663893		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.08620490015663893 | validation: 0.07701003432466112]
	TIME [epoch: 11.5 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07459481097824061		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.07459481097824061 | validation: 0.08840782566497758]
	TIME [epoch: 11.5 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0819633915536966		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.0819633915536966 | validation: 0.0714550657112474]
	TIME [epoch: 11.5 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07874843465023777		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.07874843465023777 | validation: 0.09742342904099424]
	TIME [epoch: 11.5 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08210260561836655		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.08210260561836655 | validation: 0.08200499605284156]
	TIME [epoch: 11.5 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0805602969189118		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.0805602969189118 | validation: 0.08328345772328084]
	TIME [epoch: 11.5 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07293245904821181		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.07293245904821181 | validation: 0.09699027094204665]
	TIME [epoch: 11.6 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09576590796756938		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.09576590796756938 | validation: 0.10425623188346224]
	TIME [epoch: 11.5 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10269608917782974		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.10269608917782974 | validation: 0.09436625156264508]
	TIME [epoch: 11.5 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07772053561926232		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.07772053561926232 | validation: 0.0745065454943361]
	TIME [epoch: 11.5 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08505938695641471		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.08505938695641471 | validation: 0.09495706854703852]
	TIME [epoch: 11.5 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08050066712963064		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.08050066712963064 | validation: 0.06713920773562979]
	TIME [epoch: 11.5 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0653409870325782		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.0653409870325782 | validation: 0.06787296637357466]
	TIME [epoch: 11.5 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06923917132942628		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.06923917132942628 | validation: 0.06263352785797699]
	TIME [epoch: 11.5 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0812205356313187		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.0812205356313187 | validation: 0.10795902218804805]
	TIME [epoch: 11.5 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1053759283411919		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.1053759283411919 | validation: 0.1183289458079251]
	TIME [epoch: 11.5 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10049476496966658		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.10049476496966658 | validation: 0.09329189849595101]
	TIME [epoch: 11.5 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08338909115314729		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.08338909115314729 | validation: 0.07805604223329154]
	TIME [epoch: 11.5 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08822892564040705		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.08822892564040705 | validation: 0.10878368589839063]
	TIME [epoch: 11.5 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1024083513793876		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.1024083513793876 | validation: 0.08321410026467584]
	TIME [epoch: 11.5 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0839162118964899		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.0839162118964899 | validation: 0.09281435690869635]
	TIME [epoch: 11.5 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08971410299358687		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.08971410299358687 | validation: 0.09255654902719837]
	TIME [epoch: 11.5 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08703831135492056		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.08703831135492056 | validation: 0.07994177320087265]
	TIME [epoch: 11.5 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07563164750971861		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.07563164750971861 | validation: 0.07374738690751068]
	TIME [epoch: 11.6 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06334342907349085		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.06334342907349085 | validation: 0.06271378555339055]
	TIME [epoch: 11.5 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05991088291070764		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.05991088291070764 | validation: 0.04923925159903853]
	TIME [epoch: 11.5 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046794947532953664		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.046794947532953664 | validation: 0.058890864905304596]
	TIME [epoch: 11.5 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04921490122688841		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.04921490122688841 | validation: 0.04995792939483749]
	TIME [epoch: 11.5 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05439189884339764		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.05439189884339764 | validation: 0.05790013176429474]
	TIME [epoch: 11.5 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04753538558606158		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.04753538558606158 | validation: 0.05228428871789562]
	TIME [epoch: 11.6 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05852025198528406		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.05852025198528406 | validation: 0.06052189064120817]
	TIME [epoch: 11.5 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0654773669620278		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.0654773669620278 | validation: 0.06972684554154544]
	TIME [epoch: 11.5 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0605313337458391		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.0605313337458391 | validation: 0.06315094070927187]
	TIME [epoch: 11.6 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05425556677742547		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.05425556677742547 | validation: 0.062299779681072524]
	TIME [epoch: 11.5 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052915395866393836		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.052915395866393836 | validation: 0.05773105110508315]
	TIME [epoch: 11.5 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049044562450609674		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.049044562450609674 | validation: 0.049880525737792586]
	TIME [epoch: 11.5 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04749952692262287		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.04749952692262287 | validation: 0.06026630828086363]
	TIME [epoch: 11.6 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04754507835055603		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.04754507835055603 | validation: 0.06202065278468084]
	TIME [epoch: 11.5 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06024981428671557		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.06024981428671557 | validation: 0.06829860119491249]
	TIME [epoch: 11.5 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06323501567609738		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.06323501567609738 | validation: 0.05445898629834898]
	TIME [epoch: 11.5 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05797965019101029		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.05797965019101029 | validation: 0.06731949716436114]
	TIME [epoch: 11.5 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06573689021372602		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.06573689021372602 | validation: 0.066077331850239]
	TIME [epoch: 11.5 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06191544217706457		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.06191544217706457 | validation: 0.0506419123027758]
	TIME [epoch: 11.5 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053935477823461156		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.053935477823461156 | validation: 0.07266118440912563]
	TIME [epoch: 11.5 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08470219881377362		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.08470219881377362 | validation: 0.061852776806435764]
	TIME [epoch: 11.5 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05725272454187162		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.05725272454187162 | validation: 0.0634399569206194]
	TIME [epoch: 11.5 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05864392300369715		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.05864392300369715 | validation: 0.05362807717460423]
	TIME [epoch: 11.5 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06217801150456623		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.06217801150456623 | validation: 0.08326685643464479]
	TIME [epoch: 11.5 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06520326483486463		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.06520326483486463 | validation: 0.054603094718309805]
	TIME [epoch: 11.5 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04858510103859995		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.04858510103859995 | validation: 0.05220143794386149]
	TIME [epoch: 11.5 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056319610361091704		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.056319610361091704 | validation: 0.0624385479807906]
	TIME [epoch: 11.5 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05860725150529575		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.05860725150529575 | validation: 0.057693208731677985]
	TIME [epoch: 11.5 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047213823948436866		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.047213823948436866 | validation: 0.05083908426811706]
	TIME [epoch: 11.5 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04696485824877655		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.04696485824877655 | validation: 0.05039733053390612]
	TIME [epoch: 11.5 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04842518214470362		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.04842518214470362 | validation: 0.051762701084238485]
	TIME [epoch: 11.5 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047167922263017435		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.047167922263017435 | validation: 0.04927111560422894]
	TIME [epoch: 11.5 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0452671129574556		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.0452671129574556 | validation: 0.05894218298454817]
	TIME [epoch: 11.5 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05221722326607464		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.05221722326607464 | validation: 0.046599173738212346]
	TIME [epoch: 11.5 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04688964676006702		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.04688964676006702 | validation: 0.07418002343812628]
	TIME [epoch: 11.5 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07653745930413855		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.07653745930413855 | validation: 0.08811797579317172]
	TIME [epoch: 11.5 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08222455748543596		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.08222455748543596 | validation: 0.08325054056241499]
	TIME [epoch: 11.5 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06061136078788742		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.06061136078788742 | validation: 0.056096298778362]
	TIME [epoch: 11.5 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05170400948432666		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.05170400948432666 | validation: 0.05862082258199339]
	TIME [epoch: 11.5 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04488755722182411		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.04488755722182411 | validation: 0.043914396224548395]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_818.pth
	Model improved!!!
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050615514681828996		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.050615514681828996 | validation: 0.050664477007586604]
	TIME [epoch: 11.5 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046080667611608866		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.046080667611608866 | validation: 0.04465419187594509]
	TIME [epoch: 11.5 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043701840857413334		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.043701840857413334 | validation: 0.032013623928358416]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_821.pth
	Model improved!!!
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03651529018322096		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.03651529018322096 | validation: 0.0421656590594899]
	TIME [epoch: 11.5 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03764170050823319		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.03764170050823319 | validation: 0.050982256251841225]
	TIME [epoch: 11.6 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043648525275122134		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.043648525275122134 | validation: 0.03810572392902287]
	TIME [epoch: 11.5 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04130839392789072		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.04130839392789072 | validation: 0.04073410525635413]
	TIME [epoch: 11.5 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0517766139512885		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.0517766139512885 | validation: 0.041844065944255916]
	TIME [epoch: 11.6 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048404025936859586		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.048404025936859586 | validation: 0.060519200204700016]
	TIME [epoch: 11.5 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04959930781496402		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.04959930781496402 | validation: 0.057998529042841945]
	TIME [epoch: 11.5 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04606202727233863		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.04606202727233863 | validation: 0.04322102313458907]
	TIME [epoch: 11.6 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04465003707665155		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.04465003707665155 | validation: 0.04977301719938766]
	TIME [epoch: 11.5 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055013542396397094		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.055013542396397094 | validation: 0.07086719587891556]
	TIME [epoch: 11.5 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05144659735067554		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.05144659735067554 | validation: 0.04120423245501681]
	TIME [epoch: 11.5 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04871721712318511		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.04871721712318511 | validation: 0.04793584821063023]
	TIME [epoch: 11.5 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049609006280661935		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.049609006280661935 | validation: 0.04970154654214049]
	TIME [epoch: 11.5 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04414994101508634		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.04414994101508634 | validation: 0.040430531406094906]
	TIME [epoch: 11.5 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04563488076112542		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.04563488076112542 | validation: 0.056383525763781604]
	TIME [epoch: 11.6 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059339898283997224		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.059339898283997224 | validation: 0.0527234525227691]
	TIME [epoch: 11.5 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04718375000843317		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.04718375000843317 | validation: 0.0540881118569918]
	TIME [epoch: 11.5 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05108247828726892		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.05108247828726892 | validation: 0.051001393860486924]
	TIME [epoch: 11.6 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0471734169295248		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.0471734169295248 | validation: 0.0570518732879817]
	TIME [epoch: 11.5 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059774268280923866		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.059774268280923866 | validation: 0.05154445195875498]
	TIME [epoch: 11.5 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05011874120150522		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.05011874120150522 | validation: 0.05674646279697777]
	TIME [epoch: 11.6 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054025045816702165		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.054025045816702165 | validation: 0.05180013104195101]
	TIME [epoch: 11.5 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05261900877630407		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.05261900877630407 | validation: 0.07601825070408029]
	TIME [epoch: 11.5 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07874166143345573		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.07874166143345573 | validation: 0.10219135684676783]
	TIME [epoch: 11.5 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08098760040010496		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.08098760040010496 | validation: 0.056284687651451615]
	TIME [epoch: 11.5 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04520768301029327		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.04520768301029327 | validation: 0.05243649790554754]
	TIME [epoch: 11.5 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04587045929582453		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.04587045929582453 | validation: 0.05681318007249473]
	TIME [epoch: 11.5 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05097033911627168		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.05097033911627168 | validation: 0.03914459303065911]
	TIME [epoch: 11.6 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04325749916758838		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.04325749916758838 | validation: 0.04840271511416429]
	TIME [epoch: 11.5 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04282704067045003		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.04282704067045003 | validation: 0.044088670305831565]
	TIME [epoch: 11.5 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04566270799079798		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.04566270799079798 | validation: 0.048222693845652954]
	TIME [epoch: 11.6 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04078070817008525		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.04078070817008525 | validation: 0.04910488491626065]
	TIME [epoch: 11.5 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04780842952977499		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.04780842952977499 | validation: 0.055828207261517944]
	TIME [epoch: 11.5 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05494489782575445		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.05494489782575445 | validation: 0.048751641686320665]
	TIME [epoch: 11.6 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05297829265292506		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.05297829265292506 | validation: 0.053863428370736134]
	TIME [epoch: 11.5 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04847719817526922		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.04847719817526922 | validation: 0.0513232078463442]
	TIME [epoch: 11.5 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04836613775583701		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.04836613775583701 | validation: 0.06294134163184259]
	TIME [epoch: 11.5 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05846239452774392		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.05846239452774392 | validation: 0.0672256015164208]
	TIME [epoch: 11.6 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058687545594905896		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.058687545594905896 | validation: 0.06260360387733468]
	TIME [epoch: 11.5 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07398445865708017		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.07398445865708017 | validation: 0.08388116060704735]
	TIME [epoch: 11.5 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06476785593901671		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.06476785593901671 | validation: 0.07224833582552581]
	TIME [epoch: 11.6 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06128859275363682		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.06128859275363682 | validation: 0.08165269389509035]
	TIME [epoch: 11.5 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06248217246522947		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.06248217246522947 | validation: 0.06861959551573932]
	TIME [epoch: 11.5 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06390560784561251		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.06390560784561251 | validation: 0.05821261112936514]
	TIME [epoch: 11.6 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05374631498547128		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.05374631498547128 | validation: 0.05885828130279389]
	TIME [epoch: 11.5 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05201443125343541		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.05201443125343541 | validation: 0.04622383062009611]
	TIME [epoch: 11.5 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058072065530339216		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.058072065530339216 | validation: 0.0607447743564313]
	TIME [epoch: 11.6 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052424496399222906		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.052424496399222906 | validation: 0.06469353062844828]
	TIME [epoch: 11.5 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05009714792200375		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.05009714792200375 | validation: 0.04570794822614829]
	TIME [epoch: 11.5 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044295406800047045		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.044295406800047045 | validation: 0.059567504069116595]
	TIME [epoch: 11.5 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06826848644649411		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.06826848644649411 | validation: 0.08377584675309187]
	TIME [epoch: 11.6 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08035208193884082		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.08035208193884082 | validation: 0.06995800127890962]
	TIME [epoch: 11.5 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054043096800459864		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.054043096800459864 | validation: 0.0632053515624624]
	TIME [epoch: 11.5 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058903845786814256		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.058903845786814256 | validation: 0.061053320663524]
	TIME [epoch: 11.6 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04949058861595009		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.04949058861595009 | validation: 0.05466200079365369]
	TIME [epoch: 11.5 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05086650547965112		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.05086650547965112 | validation: 0.06102517961256871]
	TIME [epoch: 11.5 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050617297383361765		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.050617297383361765 | validation: 0.05388988809047676]
	TIME [epoch: 11.6 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04944941488333673		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.04944941488333673 | validation: 0.04945336621973494]
	TIME [epoch: 11.5 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0455921362110138		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.0455921362110138 | validation: 0.0532405578415777]
	TIME [epoch: 11.5 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04184904045345224		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.04184904045345224 | validation: 0.054491826053419165]
	TIME [epoch: 11.6 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039918528348253775		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.039918528348253775 | validation: 0.042089518252855306]
	TIME [epoch: 11.5 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03695822947239574		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.03695822947239574 | validation: 0.04563254119210258]
	TIME [epoch: 11.5 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03398669398647937		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.03398669398647937 | validation: 0.04194075175611821]
	TIME [epoch: 11.5 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03568738597944739		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.03568738597944739 | validation: 0.03400575215582202]
	TIME [epoch: 11.5 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033794298097693756		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.033794298097693756 | validation: 0.04154930693485031]
	TIME [epoch: 11.5 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037396977045456026		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.037396977045456026 | validation: 0.03896072945271258]
	TIME [epoch: 11.5 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03221675983124627		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.03221675983124627 | validation: 0.04053016374844272]
	TIME [epoch: 11.6 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0332851182184994		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.0332851182184994 | validation: 0.04836895427895476]
	TIME [epoch: 11.5 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04634985323381677		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.04634985323381677 | validation: 0.05674611514384548]
	TIME [epoch: 11.5 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04653619961023117		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.04653619961023117 | validation: 0.04628924561423081]
	TIME [epoch: 11.6 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0411553927994627		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.0411553927994627 | validation: 0.04346235716033771]
	TIME [epoch: 11.5 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044720275692473284		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.044720275692473284 | validation: 0.047757089243693304]
	TIME [epoch: 11.5 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04168503185857428		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.04168503185857428 | validation: 0.0372532225925242]
	TIME [epoch: 11.6 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037303609873293654		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.037303609873293654 | validation: 0.041588978497826994]
	TIME [epoch: 11.5 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03572913562973286		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.03572913562973286 | validation: 0.036322462661342016]
	TIME [epoch: 11.5 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039287320610197816		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.039287320610197816 | validation: 0.031754675799042814]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_897.pth
	Model improved!!!
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03721114328595729		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.03721114328595729 | validation: 0.04049155973134662]
	TIME [epoch: 11.5 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035723963466324726		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.035723963466324726 | validation: 0.037048806137554575]
	TIME [epoch: 11.5 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031513161229977577		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.031513161229977577 | validation: 0.03618389329737991]
	TIME [epoch: 11.5 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04333801850438329		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.04333801850438329 | validation: 0.05041905881118648]
	TIME [epoch: 11.5 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05504694538707959		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.05504694538707959 | validation: 0.04677989805545129]
	TIME [epoch: 11.5 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04562485526576742		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.04562485526576742 | validation: 0.059003501205116785]
	TIME [epoch: 11.5 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0573941495478984		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.0573941495478984 | validation: 0.0633579259809468]
	TIME [epoch: 11.6 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06655604176693151		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.06655604176693151 | validation: 0.06227083336189065]
	TIME [epoch: 11.5 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05651598742182003		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.05651598742182003 | validation: 0.042061752999693884]
	TIME [epoch: 11.5 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044234973272450656		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.044234973272450656 | validation: 0.04960280100594213]
	TIME [epoch: 11.6 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0403689292080022		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.0403689292080022 | validation: 0.05496954084276917]
	TIME [epoch: 11.5 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05148374094182005		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.05148374094182005 | validation: 0.055226769574593854]
	TIME [epoch: 11.5 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0501222454485119		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.0501222454485119 | validation: 0.056201453004377115]
	TIME [epoch: 11.5 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05349280716575762		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.05349280716575762 | validation: 0.05131486946436805]
	TIME [epoch: 11.5 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056823510225735833		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.056823510225735833 | validation: 0.052246349246701594]
	TIME [epoch: 11.5 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04865536722144144		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.04865536722144144 | validation: 0.05817260228944898]
	TIME [epoch: 11.5 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05607445484816639		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.05607445484816639 | validation: 0.060661000446130944]
	TIME [epoch: 11.5 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05286179915511709		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.05286179915511709 | validation: 0.05945964158095162]
	TIME [epoch: 11.5 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05195886701930086		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.05195886701930086 | validation: 0.04170031898286269]
	TIME [epoch: 11.5 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048653359640785286		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.048653359640785286 | validation: 0.05422488135927818]
	TIME [epoch: 11.6 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04482223721687559		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.04482223721687559 | validation: 0.04577218266237698]
	TIME [epoch: 11.5 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04976252841820736		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.04976252841820736 | validation: 0.0454876768571003]
	TIME [epoch: 11.5 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040519364138707076		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.040519364138707076 | validation: 0.048499436259451245]
	TIME [epoch: 11.6 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037244835450923		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.037244835450923 | validation: 0.03650798983781333]
	TIME [epoch: 11.5 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03779077995481943		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.03779077995481943 | validation: 0.051320640516378344]
	TIME [epoch: 11.5 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043834682857084396		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.043834682857084396 | validation: 0.0482175754960382]
	TIME [epoch: 11.5 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04260203785136853		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.04260203785136853 | validation: 0.04182998268763046]
	TIME [epoch: 11.5 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048425301065015906		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.048425301065015906 | validation: 0.06085491452642319]
	TIME [epoch: 11.5 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053409044732030994		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.053409044732030994 | validation: 0.052478550172983154]
	TIME [epoch: 11.5 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042978090216398666		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.042978090216398666 | validation: 0.055024263661002916]
	TIME [epoch: 11.5 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05379784992488347		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.05379784992488347 | validation: 0.0620115604116873]
	TIME [epoch: 11.6 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05606914300639568		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.05606914300639568 | validation: 0.04795037077682899]
	TIME [epoch: 11.5 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039351637743544464		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.039351637743544464 | validation: 0.03939051332905551]
	TIME [epoch: 11.6 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03147344362035611		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.03147344362035611 | validation: 0.039965644830291955]
	TIME [epoch: 11.5 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039945190825600496		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.039945190825600496 | validation: 0.03521896453585908]
	TIME [epoch: 11.5 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032158871016569605		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.032158871016569605 | validation: 0.032223822863077525]
	TIME [epoch: 11.6 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03198550824556484		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.03198550824556484 | validation: 0.03791118790810795]
	TIME [epoch: 11.5 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03675616324655757		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.03675616324655757 | validation: 0.04825473949812739]
	TIME [epoch: 11.5 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034964791837773054		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.034964791837773054 | validation: 0.04340845643060124]
	TIME [epoch: 11.6 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031543033776366025		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.031543033776366025 | validation: 0.047313736404289694]
	TIME [epoch: 11.5 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03566609193473556		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.03566609193473556 | validation: 0.04690590642194564]
	TIME [epoch: 11.5 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034535502266867926		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.034535502266867926 | validation: 0.044576503253440335]
	TIME [epoch: 11.5 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03593854505625116		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.03593854505625116 | validation: 0.05408670178331878]
	TIME [epoch: 11.5 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039772575636736765		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.039772575636736765 | validation: 0.05285503491128862]
	TIME [epoch: 11.5 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052546442007413166		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.052546442007413166 | validation: 0.0597920016499424]
	TIME [epoch: 11.5 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049243472956371756		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.049243472956371756 | validation: 0.05163334334419183]
	TIME [epoch: 11.5 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050173927080380765		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.050173927080380765 | validation: 0.06285589564058335]
	TIME [epoch: 11.5 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06335024032887945		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.06335024032887945 | validation: 0.05419879621363515]
	TIME [epoch: 11.5 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055835676267004475		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.055835676267004475 | validation: 0.06625000281506653]
	TIME [epoch: 11.6 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06457255497938649		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.06457255497938649 | validation: 0.060974072853347175]
	TIME [epoch: 11.5 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05445095360955577		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.05445095360955577 | validation: 0.06180529496754031]
	TIME [epoch: 11.5 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05771451640655754		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.05771451640655754 | validation: 0.05846334918180122]
	TIME [epoch: 11.6 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05159903351310541		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.05159903351310541 | validation: 0.06251037662105365]
	TIME [epoch: 11.5 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053397532271665785		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.053397532271665785 | validation: 0.04823212946249231]
	TIME [epoch: 11.5 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047646438315892804		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.047646438315892804 | validation: 0.03429523021128761]
	TIME [epoch: 11.5 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03738451561409846		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.03738451561409846 | validation: 0.044595369466238516]
	TIME [epoch: 11.5 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0345121935647544		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.0345121935647544 | validation: 0.04813050601037755]
	TIME [epoch: 11.5 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03645055834006384		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.03645055834006384 | validation: 0.04710213461268853]
	TIME [epoch: 11.5 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03687820380920356		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.03687820380920356 | validation: 0.03869152123937432]
	TIME [epoch: 11.5 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0288128463818305		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.0288128463818305 | validation: 0.03393357572259429]
	TIME [epoch: 11.5 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03306480401836043		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.03306480401836043 | validation: 0.03811002344016114]
	TIME [epoch: 11.5 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032916219898531704		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.032916219898531704 | validation: 0.04122822629600933]
	TIME [epoch: 11.6 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0377860029261067		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.0377860029261067 | validation: 0.04050639381280982]
	TIME [epoch: 11.5 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040367897779753976		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.040367897779753976 | validation: 0.047915433811764975]
	TIME [epoch: 11.5 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03999343287763227		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.03999343287763227 | validation: 0.04171100435304284]
	TIME [epoch: 11.6 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03044706801616147		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.03044706801616147 | validation: 0.03982894294223034]
	TIME [epoch: 11.5 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03036280288548448		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.03036280288548448 | validation: 0.039024754998666915]
	TIME [epoch: 11.5 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03451176086032212		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.03451176086032212 | validation: 0.04869472068316878]
	TIME [epoch: 11.5 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05169692053183382		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.05169692053183382 | validation: 0.0579891578751905]
	TIME [epoch: 11.5 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04603830218630972		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.04603830218630972 | validation: 0.040089298234730515]
	TIME [epoch: 11.5 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044710521011342416		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.044710521011342416 | validation: 0.06296346852591754]
	TIME [epoch: 11.5 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054911168519937874		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.054911168519937874 | validation: 0.04133514122741145]
	TIME [epoch: 11.5 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045412905583681204		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.045412905583681204 | validation: 0.04283213655399301]
	TIME [epoch: 11.5 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03434949713692469		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.03434949713692469 | validation: 0.03158469721692302]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_971.pth
	Model improved!!!
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03288751622400725		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.03288751622400725 | validation: 0.03952679487578567]
	TIME [epoch: 11.6 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031264238426173374		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.031264238426173374 | validation: 0.02598460008916793]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_973.pth
	Model improved!!!
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03414789887007869		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.03414789887007869 | validation: 0.03924738991263609]
	TIME [epoch: 11.5 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035386762714955375		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.035386762714955375 | validation: 0.042196313865092566]
	TIME [epoch: 11.6 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035487715952791966		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.035487715952791966 | validation: 0.03843701107194092]
	TIME [epoch: 11.5 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029347372328943043		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.029347372328943043 | validation: 0.04118407411395432]
	TIME [epoch: 11.5 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030903192457977027		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.030903192457977027 | validation: 0.029693372333546443]
	TIME [epoch: 11.6 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03569745283867106		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.03569745283867106 | validation: 0.04098449829599172]
	TIME [epoch: 11.5 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03318164672292566		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.03318164672292566 | validation: 0.04264920097734038]
	TIME [epoch: 11.5 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031318277402850744		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.031318277402850744 | validation: 0.03845158834840255]
	TIME [epoch: 11.5 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032708064436554767		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.032708064436554767 | validation: 0.037897902121035165]
	TIME [epoch: 11.5 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041288112154289056		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.041288112154289056 | validation: 0.04585404266699869]
	TIME [epoch: 11.5 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03379027220180208		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.03379027220180208 | validation: 0.04243295238298224]
	TIME [epoch: 11.5 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03896119525148124		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.03896119525148124 | validation: 0.04158963373566667]
	TIME [epoch: 11.5 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040279858762075973		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.040279858762075973 | validation: 0.04852384475120102]
	TIME [epoch: 11.5 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0371637554461649		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.0371637554461649 | validation: 0.04566614431619874]
	TIME [epoch: 11.5 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04657697267169511		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.04657697267169511 | validation: 0.05942236170866211]
	TIME [epoch: 11.6 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047056165336023685		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.047056165336023685 | validation: 0.04225591958419082]
	TIME [epoch: 11.5 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03583437069364998		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.03583437069364998 | validation: 0.03455857579669971]
	TIME [epoch: 11.5 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04263926091512381		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.04263926091512381 | validation: 0.04256266094158012]
	TIME [epoch: 11.6 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043135730473061906		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.043135730473061906 | validation: 0.04135331486034405]
	TIME [epoch: 11.5 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03980207281718216		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.03980207281718216 | validation: 0.047260931801929904]
	TIME [epoch: 11.5 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041431752303005935		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.041431752303005935 | validation: 0.046195459562126055]
	TIME [epoch: 11.5 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05262679011017328		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.05262679011017328 | validation: 0.04923686936457404]
	TIME [epoch: 11.5 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041767073782702904		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.041767073782702904 | validation: 0.037038704854540146]
	TIME [epoch: 11.5 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033753910711639336		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.033753910711639336 | validation: 0.04753268121801673]
	TIME [epoch: 11.5 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0423580143164246		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.0423580143164246 | validation: 0.04683309343035777]
	TIME [epoch: 11.5 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03827289237173036		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.03827289237173036 | validation: 0.04408888598401855]
	TIME [epoch: 11.5 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03777260278569442		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.03777260278569442 | validation: 0.06293290824648862]
	TIME [epoch: 11.5 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057814657334095715		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.057814657334095715 | validation: 0.0663414800314614]
	TIME [epoch: 11.6 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05429325538751253		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.05429325538751253 | validation: 0.038115849077549384]
	TIME [epoch: 11.5 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041176858774597674		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.041176858774597674 | validation: 0.03837268299268464]
	TIME [epoch: 11.5 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03527591112101941		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.03527591112101941 | validation: 0.03692108593071952]
	TIME [epoch: 11.5 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037574816807210996		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.037574816807210996 | validation: 0.04020091132503478]
	TIME [epoch: 11.5 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04183731515677921		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.04183731515677921 | validation: 0.0449829345053256]
	TIME [epoch: 11.5 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03805081171030668		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.03805081171030668 | validation: 0.038824795990144365]
	TIME [epoch: 11.5 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03919208609991952		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.03919208609991952 | validation: 0.02981177441635902]
	TIME [epoch: 11.5 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0311682731298479		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.0311682731298479 | validation: 0.03841211698172565]
	TIME [epoch: 11.5 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03167651005200756		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.03167651005200756 | validation: 0.04100348499718928]
	TIME [epoch: 11.5 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03376409196100517		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.03376409196100517 | validation: 0.03650427172640079]
	TIME [epoch: 11.5 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03841057130916975		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.03841057130916975 | validation: 0.04586954025620025]
	TIME [epoch: 11.5 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037864982822111135		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.037864982822111135 | validation: 0.04031631136294255]
	TIME [epoch: 11.5 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0347455999492013		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.0347455999492013 | validation: 0.03597301526111824]
	TIME [epoch: 11.6 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0324620298420917		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.0324620298420917 | validation: 0.03820965036422971]
	TIME [epoch: 11.5 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035999182974053814		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.035999182974053814 | validation: 0.04003447175871111]
	TIME [epoch: 11.5 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04133661668879184		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.04133661668879184 | validation: 0.033883322135164734]
	TIME [epoch: 11.6 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037535469435456416		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.037535469435456416 | validation: 0.0350818393791157]
	TIME [epoch: 11.5 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043152722629369464		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.043152722629369464 | validation: 0.04024606792143794]
	TIME [epoch: 11.5 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03446792950492533		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.03446792950492533 | validation: 0.03368672127242886]
	TIME [epoch: 11.5 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03464137615134101		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.03464137615134101 | validation: 0.03566116106400215]
	TIME [epoch: 11.5 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033464333683730654		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.033464333683730654 | validation: 0.03780482747359192]
	TIME [epoch: 11.5 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03759614424624104		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.03759614424624104 | validation: 0.04065646419933147]
	TIME [epoch: 11.5 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0356218536269664		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.0356218536269664 | validation: 0.04376135362625199]
	TIME [epoch: 11.5 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036494851429926214		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.036494851429926214 | validation: 0.039255045720344155]
	TIME [epoch: 11.5 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03591842950964065		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.03591842950964065 | validation: 0.032017636222561575]
	TIME [epoch: 11.5 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03409684167373892		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.03409684167373892 | validation: 0.036876695449387535]
	TIME [epoch: 11.6 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03755192396579803		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.03755192396579803 | validation: 0.04970239660285891]
	TIME [epoch: 11.5 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033054643205299994		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.033054643205299994 | validation: 0.03735711513711469]
	TIME [epoch: 11.5 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030248195702521092		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.030248195702521092 | validation: 0.031653731171864166]
	TIME [epoch: 11.5 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03264259898538775		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.03264259898538775 | validation: 0.029401129106152845]
	TIME [epoch: 11.5 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034951518354730156		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.034951518354730156 | validation: 0.039070477186962826]
	TIME [epoch: 11.5 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036780739515653006		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.036780739515653006 | validation: 0.032621167586909784]
	TIME [epoch: 11.5 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03893981703671756		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.03893981703671756 | validation: 0.031340409169346745]
	TIME [epoch: 11.5 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032379270509045356		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.032379270509045356 | validation: 0.04266932301027996]
	TIME [epoch: 11.5 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035711391068696675		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.035711391068696675 | validation: 0.03781097455659405]
	TIME [epoch: 11.5 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05124195354452328		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.05124195354452328 | validation: 0.06045713919402363]
	TIME [epoch: 11.5 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06084502969235222		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.06084502969235222 | validation: 0.051096618830863715]
	TIME [epoch: 11.5 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05237505240416345		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.05237505240416345 | validation: 0.0493663085043817]
	TIME [epoch: 11.5 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044075378503905194		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.044075378503905194 | validation: 0.03754350616202025]
	TIME [epoch: 11.5 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0330217573024028		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.0330217573024028 | validation: 0.03182787501805469]
	TIME [epoch: 11.5 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03366210250726891		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.03366210250726891 | validation: 0.030503446538011333]
	TIME [epoch: 11.5 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030390013252326063		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.030390013252326063 | validation: 0.037012452933874534]
	TIME [epoch: 11.5 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03115453994815267		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.03115453994815267 | validation: 0.029024960268821207]
	TIME [epoch: 11.5 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030323085225248448		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.030323085225248448 | validation: 0.03309077406266589]
	TIME [epoch: 11.5 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027679550861950005		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.027679550861950005 | validation: 0.031879722855407897]
	TIME [epoch: 11.5 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029223170312375996		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.029223170312375996 | validation: 0.030137374388194384]
	TIME [epoch: 11.5 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032598790898396145		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.032598790898396145 | validation: 0.034402663718975705]
	TIME [epoch: 11.5 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028608422391736124		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.028608422391736124 | validation: 0.032431836658682225]
	TIME [epoch: 11.5 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031074620655306258		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.031074620655306258 | validation: 0.039696821819981444]
	TIME [epoch: 11.5 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03849695564020235		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.03849695564020235 | validation: 0.03037528857747483]
	TIME [epoch: 11.5 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03504798934832663		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.03504798934832663 | validation: 0.03528296668250152]
	TIME [epoch: 11.5 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03349818133456771		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.03349818133456771 | validation: 0.04793778228163017]
	TIME [epoch: 11.5 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03727834019191685		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.03727834019191685 | validation: 0.04268251573945836]
	TIME [epoch: 11.5 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03570820098307699		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.03570820098307699 | validation: 0.03940471963334038]
	TIME [epoch: 11.5 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034072627930043245		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.034072627930043245 | validation: 0.03934904557341072]
	TIME [epoch: 11.5 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03743242675465933		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.03743242675465933 | validation: 0.03641465667754213]
	TIME [epoch: 11.5 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033805120039425485		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.033805120039425485 | validation: 0.03488082850234797]
	TIME [epoch: 11.5 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038355624946374		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.038355624946374 | validation: 0.04391750987335118]
	TIME [epoch: 11.5 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03417548600083089		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.03417548600083089 | validation: 0.044229612472428854]
	TIME [epoch: 11.5 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03858971898039762		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.03858971898039762 | validation: 0.04131605831026564]
	TIME [epoch: 11.5 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03404469605251341		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.03404469605251341 | validation: 0.036882172370866106]
	TIME [epoch: 11.5 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03795161667555626		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.03795161667555626 | validation: 0.03744701269502022]
	TIME [epoch: 11.5 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034274291520524414		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.034274291520524414 | validation: 0.037812738841561194]
	TIME [epoch: 11.5 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03175235309000131		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.03175235309000131 | validation: 0.0399897621476404]
	TIME [epoch: 11.5 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031209846499060626		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.031209846499060626 | validation: 0.04392877688858888]
	TIME [epoch: 11.5 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031092357439756517		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.031092357439756517 | validation: 0.03796088424714654]
	TIME [epoch: 11.5 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039188858478862235		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.039188858478862235 | validation: 0.04442578677627438]
	TIME [epoch: 11.5 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04038335696315404		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.04038335696315404 | validation: 0.042927231925911594]
	TIME [epoch: 11.5 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03687110327208712		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.03687110327208712 | validation: 0.035485974521208705]
	TIME [epoch: 11.5 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03252364219416695		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.03252364219416695 | validation: 0.03415012361506504]
	TIME [epoch: 11.5 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03687881438149593		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.03687881438149593 | validation: 0.04100800028956144]
	TIME [epoch: 11.5 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035044262878834546		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.035044262878834546 | validation: 0.03157121074480609]
	TIME [epoch: 11.5 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027889643780724078		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.027889643780724078 | validation: 0.0390683082180573]
	TIME [epoch: 11.5 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03432664248074887		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.03432664248074887 | validation: 0.040930653797141406]
	TIME [epoch: 11.5 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035088378825906055		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.035088378825906055 | validation: 0.04049524748755358]
	TIME [epoch: 11.5 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03393715615864398		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.03393715615864398 | validation: 0.03352043373563205]
	TIME [epoch: 11.5 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032220358973495344		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.032220358973495344 | validation: 0.03145246125487329]
	TIME [epoch: 11.5 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031089155388570454		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.031089155388570454 | validation: 0.029485278881806493]
	TIME [epoch: 11.5 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030527190672850535		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.030527190672850535 | validation: 0.03332058869091657]
	TIME [epoch: 11.5 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03382949901363844		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.03382949901363844 | validation: 0.04317042740138895]
	TIME [epoch: 11.5 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03620326871094399		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.03620326871094399 | validation: 0.04136124336522082]
	TIME [epoch: 11.5 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041728419835779906		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.041728419835779906 | validation: 0.040008049893651004]
	TIME [epoch: 11.5 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03869375484007227		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.03869375484007227 | validation: 0.02874988374564902]
	TIME [epoch: 11.5 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0353658191305697		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.0353658191305697 | validation: 0.0379757464749505]
	TIME [epoch: 11.5 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028233505945905166		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.028233505945905166 | validation: 0.03815117616468012]
	TIME [epoch: 11.5 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026389235946450734		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.026389235946450734 | validation: 0.032733721454150676]
	TIME [epoch: 11.5 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024943950872656138		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.024943950872656138 | validation: 0.03674702586099654]
	TIME [epoch: 11.5 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03147105805501892		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.03147105805501892 | validation: 0.0366677391966142]
	TIME [epoch: 11.5 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030561739609353517		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.030561739609353517 | validation: 0.04868139184135181]
	TIME [epoch: 11.5 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03782640875115841		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.03782640875115841 | validation: 0.04628646845663373]
	TIME [epoch: 11.5 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041461710214088995		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.041461710214088995 | validation: 0.04940553623498804]
	TIME [epoch: 11.5 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0468787285098124		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.0468787285098124 | validation: 0.04326957094534073]
	TIME [epoch: 11.5 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035947492346433046		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.035947492346433046 | validation: 0.047164977160902295]
	TIME [epoch: 11.5 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04244236851694351		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.04244236851694351 | validation: 0.05222450726741101]
	TIME [epoch: 11.5 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03989616856564063		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.03989616856564063 | validation: 0.035277591639505855]
	TIME [epoch: 11.5 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032447022544311546		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.032447022544311546 | validation: 0.03845681774893742]
	TIME [epoch: 11.5 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033752540050751734		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.033752540050751734 | validation: 0.037227492503519144]
	TIME [epoch: 11.5 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03360409437387592		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.03360409437387592 | validation: 0.03253257841710832]
	TIME [epoch: 11.5 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029622338457043845		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.029622338457043845 | validation: 0.03954622853212433]
	TIME [epoch: 11.5 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03221825572623495		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.03221825572623495 | validation: 0.044709564135600614]
	TIME [epoch: 11.5 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030677566583264457		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.030677566583264457 | validation: 0.032316152722661376]
	TIME [epoch: 11.5 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031482585901645085		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.031482585901645085 | validation: 0.0360899839933002]
	TIME [epoch: 11.5 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03228171824083857		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.03228171824083857 | validation: 0.04120294906343407]
	TIME [epoch: 11.5 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02810340428405903		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.02810340428405903 | validation: 0.030716983693409253]
	TIME [epoch: 11.5 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0356798070528129		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.0356798070528129 | validation: 0.03232429003666351]
	TIME [epoch: 11.5 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030078279542134195		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.030078279542134195 | validation: 0.035522153623519424]
	TIME [epoch: 11.5 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02862302155833935		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.02862302155833935 | validation: 0.03435313382381593]
	TIME [epoch: 11.5 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030076322450409185		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.030076322450409185 | validation: 0.03423328780545429]
	TIME [epoch: 11.5 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032381768625484156		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.032381768625484156 | validation: 0.040978144947702654]
	TIME [epoch: 11.5 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03715294893033548		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.03715294893033548 | validation: 0.04482024346133974]
	TIME [epoch: 11.5 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028958449715288853		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.028958449715288853 | validation: 0.035692609386927525]
	TIME [epoch: 11.5 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027939734466179623		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.027939734466179623 | validation: 0.029723919750505014]
	TIME [epoch: 11.5 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02925041353482464		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.02925041353482464 | validation: 0.03933034529513114]
	TIME [epoch: 11.5 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02815588644766894		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.02815588644766894 | validation: 0.03526845666884054]
	TIME [epoch: 11.5 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02944968570732333		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.02944968570732333 | validation: 0.03998935568174113]
	TIME [epoch: 11.5 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031203721519908634		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.031203721519908634 | validation: 0.03770868194136249]
	TIME [epoch: 11.5 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027569054261521106		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.027569054261521106 | validation: 0.03963463418287854]
	TIME [epoch: 11.5 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034710012293705926		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.034710012293705926 | validation: 0.04356123269812881]
	TIME [epoch: 11.5 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03216197574807762		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.03216197574807762 | validation: 0.02574651913618115]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_1120.pth
	Model improved!!!
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03457695763451796		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.03457695763451796 | validation: 0.03363163169702477]
	TIME [epoch: 11.5 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035016722112034646		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.035016722112034646 | validation: 0.039518527964102816]
	TIME [epoch: 11.5 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030839294498274168		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.030839294498274168 | validation: 0.035319138604657206]
	TIME [epoch: 11.5 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03009516611722679		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.03009516611722679 | validation: 0.03935422493938229]
	TIME [epoch: 11.5 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040975835207964814		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.040975835207964814 | validation: 0.052275045386741506]
	TIME [epoch: 11.5 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050823913441626234		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.050823913441626234 | validation: 0.05085914235432405]
	TIME [epoch: 11.5 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04467373565731668		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.04467373565731668 | validation: 0.03900064153458799]
	TIME [epoch: 11.6 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0489591400735818		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.0489591400735818 | validation: 0.04257739343053179]
	TIME [epoch: 11.5 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04672947313846176		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.04672947313846176 | validation: 0.04341622109592899]
	TIME [epoch: 11.5 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04697474457760186		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.04697474457760186 | validation: 0.06894148855340623]
	TIME [epoch: 11.5 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0627026160704402		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.0627026160704402 | validation: 0.05451748237778295]
	TIME [epoch: 11.5 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052976541564654825		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.052976541564654825 | validation: 0.046966582351379974]
	TIME [epoch: 11.5 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045266400889014104		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.045266400889014104 | validation: 0.044967069675787716]
	TIME [epoch: 11.5 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036701980454682835		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.036701980454682835 | validation: 0.03966501555530944]
	TIME [epoch: 11.6 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03728534351475634		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.03728534351475634 | validation: 0.033895778145155084]
	TIME [epoch: 11.5 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03672362378128148		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.03672362378128148 | validation: 0.04391993906668471]
	TIME [epoch: 11.5 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03333962455938271		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.03333962455938271 | validation: 0.035293348044458835]
	TIME [epoch: 11.5 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034949637659222314		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.034949637659222314 | validation: 0.041013304194143604]
	TIME [epoch: 11.5 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03488654028964701		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.03488654028964701 | validation: 0.04486401465044175]
	TIME [epoch: 11.5 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03430005217280036		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.03430005217280036 | validation: 0.03472594998740099]
	TIME [epoch: 11.5 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0385803163084559		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.0385803163084559 | validation: 0.033079914829035086]
	TIME [epoch: 11.5 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031352628343822186		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.031352628343822186 | validation: 0.03608385045961447]
	TIME [epoch: 11.5 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03323944183078158		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.03323944183078158 | validation: 0.02626582726178174]
	TIME [epoch: 11.5 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029216774898330057		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.029216774898330057 | validation: 0.03003248308393057]
	TIME [epoch: 11.5 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031595202900468376		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.031595202900468376 | validation: 0.03055103614012995]
	TIME [epoch: 11.5 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033387203346017816		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.033387203346017816 | validation: 0.028681275013888334]
	TIME [epoch: 11.5 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03155067879192511		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.03155067879192511 | validation: 0.0329240829232514]
	TIME [epoch: 11.5 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0333999053645022		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.0333999053645022 | validation: 0.03185462774985767]
	TIME [epoch: 11.5 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02939447155392181		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.02939447155392181 | validation: 0.019985457691516308]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_1149.pth
	Model improved!!!
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033563533876778226		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.033563533876778226 | validation: 0.03477889719181447]
	TIME [epoch: 11.5 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03203121950480161		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.03203121950480161 | validation: 0.03234210185028852]
	TIME [epoch: 11.5 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028268215992854676		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.028268215992854676 | validation: 0.033209682203497515]
	TIME [epoch: 11.5 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02795945534985833		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.02795945534985833 | validation: 0.03301975694117783]
	TIME [epoch: 11.6 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029370067975936276		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.029370067975936276 | validation: 0.04003272308429996]
	TIME [epoch: 11.5 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026129064326729373		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.026129064326729373 | validation: 0.03277543057069316]
	TIME [epoch: 11.5 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033843147218047584		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.033843147218047584 | validation: 0.03935451489637628]
	TIME [epoch: 11.5 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031467384742712906		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.031467384742712906 | validation: 0.03649488244065466]
	TIME [epoch: 11.5 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03177986493491308		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.03177986493491308 | validation: 0.035206863780259]
	TIME [epoch: 11.5 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028742170855075338		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.028742170855075338 | validation: 0.03562994108593793]
	TIME [epoch: 11.5 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03126203834710579		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.03126203834710579 | validation: 0.03466254828548857]
	TIME [epoch: 11.5 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032735213511497746		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.032735213511497746 | validation: 0.03792041373487289]
	TIME [epoch: 11.5 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03309531324998794		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.03309531324998794 | validation: 0.037767268303975754]
	TIME [epoch: 11.5 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03309590893135468		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.03309590893135468 | validation: 0.03602283545731316]
	TIME [epoch: 11.5 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026853069095029557		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.026853069095029557 | validation: 0.024904051834109344]
	TIME [epoch: 11.5 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03236291787697899		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.03236291787697899 | validation: 0.03217801671599955]
	TIME [epoch: 11.5 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03467034043837668		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.03467034043837668 | validation: 0.04288575947280004]
	TIME [epoch: 11.5 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03945737988667269		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.03945737988667269 | validation: 0.029887896009353633]
	TIME [epoch: 11.5 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03226387603692342		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.03226387603692342 | validation: 0.02669343719477774]
	TIME [epoch: 11.5 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02769229298972934		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.02769229298972934 | validation: 0.03819703958861622]
	TIME [epoch: 11.5 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032867926840711006		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.032867926840711006 | validation: 0.03415385365532963]
	TIME [epoch: 11.5 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02703470157967682		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.02703470157967682 | validation: 0.028667319192855027]
	TIME [epoch: 11.5 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031379085692469263		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.031379085692469263 | validation: 0.030909133114368426]
	TIME [epoch: 11.5 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02926505065061595		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.02926505065061595 | validation: 0.03600315167407321]
	TIME [epoch: 11.5 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03188030873166069		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.03188030873166069 | validation: 0.0318868610693605]
	TIME [epoch: 11.5 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03464746905165951		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.03464746905165951 | validation: 0.03641440123859991]
	TIME [epoch: 11.5 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027729802047399683		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.027729802047399683 | validation: 0.03548518781683664]
	TIME [epoch: 11.5 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032678709228325366		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.032678709228325366 | validation: 0.033179326745247345]
	TIME [epoch: 11.5 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032111153763648495		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.032111153763648495 | validation: 0.03156693699626594]
	TIME [epoch: 11.5 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03600656250933959		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.03600656250933959 | validation: 0.03994866261030622]
	TIME [epoch: 11.5 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03698810716214362		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.03698810716214362 | validation: 0.04162057255480754]
	TIME [epoch: 11.5 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04005039593439704		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.04005039593439704 | validation: 0.03652329221468533]
	TIME [epoch: 11.5 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03942718178085723		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.03942718178085723 | validation: 0.037353274475543874]
	TIME [epoch: 11.5 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03935585991185953		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.03935585991185953 | validation: 0.03668701319836084]
	TIME [epoch: 11.5 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03584104902103722		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.03584104902103722 | validation: 0.03710379969730932]
	TIME [epoch: 11.5 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03893711965463009		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.03893711965463009 | validation: 0.03846286355360903]
	TIME [epoch: 11.5 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035112853316986686		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.035112853316986686 | validation: 0.04259901654939295]
	TIME [epoch: 11.5 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03978103149455389		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.03978103149455389 | validation: 0.04226453611712854]
	TIME [epoch: 11.5 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045521274293449675		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.045521274293449675 | validation: 0.05867819900885893]
	TIME [epoch: 11.5 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05710413202155022		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.05710413202155022 | validation: 0.060747396933550836]
	TIME [epoch: 11.5 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06683764153705289		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.06683764153705289 | validation: 0.07955094163158931]
	TIME [epoch: 11.5 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08193503096807		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.08193503096807 | validation: 0.07629559131476815]
	TIME [epoch: 11.5 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06667735198646066		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.06667735198646066 | validation: 0.05135873654047897]
	TIME [epoch: 11.5 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04178422594206109		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.04178422594206109 | validation: 0.041720541067876676]
	TIME [epoch: 11.5 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03360367227386073		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.03360367227386073 | validation: 0.03886261693614213]
	TIME [epoch: 11.5 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03544472860627932		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.03544472860627932 | validation: 0.0331818340216294]
	TIME [epoch: 11.5 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028763549673795134		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.028763549673795134 | validation: 0.034516528702576335]
	TIME [epoch: 11.5 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029695141402121615		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.029695141402121615 | validation: 0.04138164784321896]
	TIME [epoch: 11.5 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037691365546735696		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.037691365546735696 | validation: 0.04560690754190366]
	TIME [epoch: 11.5 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039603771092935704		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.039603771092935704 | validation: 0.04841437253091537]
	TIME [epoch: 11.5 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04245731662247		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.04245731662247 | validation: 0.039190776922435694]
	TIME [epoch: 11.5 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03745666579272017		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.03745666579272017 | validation: 0.045337427290920565]
	TIME [epoch: 11.5 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028688852633606605		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.028688852633606605 | validation: 0.03684873194542483]
	TIME [epoch: 11.5 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027178153437612776		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.027178153437612776 | validation: 0.03907316262668301]
	TIME [epoch: 11.5 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02909404070995988		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.02909404070995988 | validation: 0.03820652260965185]
	TIME [epoch: 11.5 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025885505306272184		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.025885505306272184 | validation: 0.02896718731247776]
	TIME [epoch: 11.5 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023711404966413666		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.023711404966413666 | validation: 0.024788799913693087]
	TIME [epoch: 11.5 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025281356991315347		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.025281356991315347 | validation: 0.036187772060853246]
	TIME [epoch: 11.5 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024441636596126363		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.024441636596126363 | validation: 0.03498950451922442]
	TIME [epoch: 11.5 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031012615480549947		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.031012615480549947 | validation: 0.03368120358842405]
	TIME [epoch: 11.5 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03066673253485295		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.03066673253485295 | validation: 0.037077225331581476]
	TIME [epoch: 11.5 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03369438305253704		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.03369438305253704 | validation: 0.03943605973747528]
	TIME [epoch: 11.5 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04237359174860013		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.04237359174860013 | validation: 0.03947832601027111]
	TIME [epoch: 11.5 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038946662438194626		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.038946662438194626 | validation: 0.043014758443089995]
	TIME [epoch: 11.5 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04440896638136617		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.04440896638136617 | validation: 0.056164545153109965]
	TIME [epoch: 11.5 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05559908439881791		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.05559908439881791 | validation: 0.06607693267011822]
	TIME [epoch: 11.5 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06469098185034207		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.06469098185034207 | validation: 0.06908641951044316]
	TIME [epoch: 11.5 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06678827707685005		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.06678827707685005 | validation: 0.0628534698866215]
	TIME [epoch: 11.5 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062575733746563		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.062575733746563 | validation: 0.06055977863569548]
	TIME [epoch: 11.5 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0583875650216036		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.0583875650216036 | validation: 0.05599959248181776]
	TIME [epoch: 11.5 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05334095286271822		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.05334095286271822 | validation: 0.05030143940766593]
	TIME [epoch: 11.5 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053927960148287074		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.053927960148287074 | validation: 0.06289312141776833]
	TIME [epoch: 11.5 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05347464221548599		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.05347464221548599 | validation: 0.05515328036290882]
	TIME [epoch: 11.5 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05023819241101345		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.05023819241101345 | validation: 0.04646544306433034]
	TIME [epoch: 11.5 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04403369884880848		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.04403369884880848 | validation: 0.048638755079947894]
	TIME [epoch: 11.5 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03772112446488546		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.03772112446488546 | validation: 0.03682659807050293]
	TIME [epoch: 11.5 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03053421423695286		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.03053421423695286 | validation: 0.03965109822374299]
	TIME [epoch: 11.5 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03658615030498322		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.03658615030498322 | validation: 0.03470577821741506]
	TIME [epoch: 11.5 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033217425226935084		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.033217425226935084 | validation: 0.021807073357506403]
	TIME [epoch: 11.5 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027237123732403973		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.027237123732403973 | validation: 0.032042474359467145]
	TIME [epoch: 11.5 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0290505416886197		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.0290505416886197 | validation: 0.03584560025109911]
	TIME [epoch: 11.5 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029494638094233073		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.029494638094233073 | validation: 0.027679644764675167]
	TIME [epoch: 11.5 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0297336769810852		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.0297336769810852 | validation: 0.033311221589239236]
	TIME [epoch: 11.5 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028644369248535684		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.028644369248535684 | validation: 0.023391617418252963]
	TIME [epoch: 11.5 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030500042719667848		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.030500042719667848 | validation: 0.029824313676222895]
	TIME [epoch: 11.5 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026808193515812356		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.026808193515812356 | validation: 0.03346710039421992]
	TIME [epoch: 11.5 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037901021745416076		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.037901021745416076 | validation: 0.044261462381778464]
	TIME [epoch: 11.5 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04688036083717225		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.04688036083717225 | validation: 0.05001103595296273]
	TIME [epoch: 11.5 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04509519629501825		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.04509519629501825 | validation: 0.03952264117927132]
	TIME [epoch: 11.5 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03505643205086098		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.03505643205086098 | validation: 0.04699323589791135]
	TIME [epoch: 11.5 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03570085718942175		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.03570085718942175 | validation: 0.03262428040327218]
	TIME [epoch: 11.5 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02889761987743402		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.02889761987743402 | validation: 0.03489713236292107]
	TIME [epoch: 11.5 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028746043138677117		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.028746043138677117 | validation: 0.04713111053399487]
	TIME [epoch: 11.5 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02598835346548386		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.02598835346548386 | validation: 0.03868204879377734]
	TIME [epoch: 11.5 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029995014321131618		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.029995014321131618 | validation: 0.03811360903719826]
	TIME [epoch: 11.5 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025893556616680607		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.025893556616680607 | validation: 0.0316232514274185]
	TIME [epoch: 11.5 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029656979912413842		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.029656979912413842 | validation: 0.02814682408995916]
	TIME [epoch: 11.5 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028095655373255275		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.028095655373255275 | validation: 0.0419425273176536]
	TIME [epoch: 11.5 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03277548794324951		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.03277548794324951 | validation: 0.031734410473640756]
	TIME [epoch: 11.5 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026528382527628916		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.026528382527628916 | validation: 0.032047973174567944]
	TIME [epoch: 11.5 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023922536726770853		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.023922536726770853 | validation: 0.03732641826726524]
	TIME [epoch: 11.5 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028285732473987628		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.028285732473987628 | validation: 0.035486785475304275]
	TIME [epoch: 11.5 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0275773824168126		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.0275773824168126 | validation: 0.03554269901114552]
	TIME [epoch: 11.5 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030799293677751086		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.030799293677751086 | validation: 0.02937633108788341]
	TIME [epoch: 11.5 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026826323827197553		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.026826323827197553 | validation: 0.030418233327653147]
	TIME [epoch: 11.5 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027638349447633513		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.027638349447633513 | validation: 0.03264219395343922]
	TIME [epoch: 11.5 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02945379769482656		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.02945379769482656 | validation: 0.03407254224984477]
	TIME [epoch: 11.5 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02969867267553792		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.02969867267553792 | validation: 0.029176988871297903]
	TIME [epoch: 11.5 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027882857911489756		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.027882857911489756 | validation: 0.02429571001171936]
	TIME [epoch: 11.5 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027696421421445648		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.027696421421445648 | validation: 0.027068498256407815]
	TIME [epoch: 11.5 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029523133758063036		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.029523133758063036 | validation: 0.029481392456073553]
	TIME [epoch: 11.5 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0293301095865662		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.0293301095865662 | validation: 0.026992570597033395]
	TIME [epoch: 11.5 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03316299040949804		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.03316299040949804 | validation: 0.03906116523804653]
	TIME [epoch: 11.5 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03597998582608475		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.03597998582608475 | validation: 0.037732064805543766]
	TIME [epoch: 11.5 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03730462443672715		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.03730462443672715 | validation: 0.04048098445425962]
	TIME [epoch: 11.5 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0393529148027541		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.0393529148027541 | validation: 0.04246971715627014]
	TIME [epoch: 11.5 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03694302032218652		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.03694302032218652 | validation: 0.03829447149702934]
	TIME [epoch: 11.5 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028711864020975586		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.028711864020975586 | validation: 0.03475995708122629]
	TIME [epoch: 11.5 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02732771101069221		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.02732771101069221 | validation: 0.03770571014900936]
	TIME [epoch: 11.5 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03240300082057316		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.03240300082057316 | validation: 0.028688733103522077]
	TIME [epoch: 11.5 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032927289385991		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.032927289385991 | validation: 0.030968399214708075]
	TIME [epoch: 11.5 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026992515465222095		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.026992515465222095 | validation: 0.03912102873774086]
	TIME [epoch: 11.5 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028258523722190107		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.028258523722190107 | validation: 0.03902978341042752]
	TIME [epoch: 11.5 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02921497811321052		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.02921497811321052 | validation: 0.040705777145628876]
	TIME [epoch: 11.5 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03355011673299717		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.03355011673299717 | validation: 0.03582632974517972]
	TIME [epoch: 11.5 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029125323033220678		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.029125323033220678 | validation: 0.03195234292931834]
	TIME [epoch: 11.5 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03441025456704577		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.03441025456704577 | validation: 0.03952594994717247]
	TIME [epoch: 11.5 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028065353864218993		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.028065353864218993 | validation: 0.03323904918803001]
	TIME [epoch: 11.5 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02733515567736789		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.02733515567736789 | validation: 0.04046714057008079]
	TIME [epoch: 11.5 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027463532581724206		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.027463532581724206 | validation: 0.0320360442771925]
	TIME [epoch: 11.5 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029696599249045566		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.029696599249045566 | validation: 0.03845281883734152]
	TIME [epoch: 11.5 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030289417169934392		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.030289417169934392 | validation: 0.03342520142406994]
	TIME [epoch: 11.5 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027355337241245274		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.027355337241245274 | validation: 0.03560557461504338]
	TIME [epoch: 11.5 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03658130031641468		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.03658130031641468 | validation: 0.0572596108621262]
	TIME [epoch: 11.5 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03984576093680956		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.03984576093680956 | validation: 0.04576101263367264]
	TIME [epoch: 11.5 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038786475155367886		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.038786475155367886 | validation: 0.03657787602714478]
	TIME [epoch: 11.5 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031416898682825406		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.031416898682825406 | validation: 0.036058786064080806]
	TIME [epoch: 11.5 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02735346854564442		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.02735346854564442 | validation: 0.039991300710753]
	TIME [epoch: 11.5 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02673050019677923		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.02673050019677923 | validation: 0.028296867806249654]
	TIME [epoch: 11.5 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025784506588885224		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.025784506588885224 | validation: 0.03457407386868514]
	TIME [epoch: 11.5 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029465785575168428		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.029465785575168428 | validation: 0.03872764897360185]
	TIME [epoch: 11.5 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0300452002593486		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.0300452002593486 | validation: 0.031456054715113056]
	TIME [epoch: 11.5 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030217763908113815		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.030217763908113815 | validation: 0.0196996701902299]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_1292.pth
	Model improved!!!
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02897095541965021		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.02897095541965021 | validation: 0.030126457583566517]
	TIME [epoch: 11.5 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03051174618930652		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.03051174618930652 | validation: 0.038227501157841834]
	TIME [epoch: 11.5 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03137346831735813		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.03137346831735813 | validation: 0.041318958927904256]
	TIME [epoch: 11.5 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033354908085210834		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.033354908085210834 | validation: 0.03598829001980551]
	TIME [epoch: 11.5 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03520319444110694		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.03520319444110694 | validation: 0.033180773600902956]
	TIME [epoch: 11.5 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0344578905704034		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.0344578905704034 | validation: 0.03333843820241029]
	TIME [epoch: 11.5 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024348782102870753		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.024348782102870753 | validation: 0.036305042439203954]
	TIME [epoch: 11.5 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027799524836468602		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.027799524836468602 | validation: 0.027572089176355747]
	TIME [epoch: 11.5 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03001357673732455		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.03001357673732455 | validation: 0.03715802382600431]
	TIME [epoch: 11.5 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027240030338281367		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.027240030338281367 | validation: 0.03506735877312876]
	TIME [epoch: 11.5 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02654375541695678		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.02654375541695678 | validation: 0.05003127168132152]
	TIME [epoch: 11.5 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040216959061788835		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.040216959061788835 | validation: 0.04675711108324532]
	TIME [epoch: 11.5 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03479076109833858		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.03479076109833858 | validation: 0.04878559459116454]
	TIME [epoch: 11.5 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03964304630593769		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.03964304630593769 | validation: 0.04943788059717469]
	TIME [epoch: 11.5 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035351877092340514		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.035351877092340514 | validation: 0.041388750518872204]
	TIME [epoch: 11.5 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03558959424823025		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.03558959424823025 | validation: 0.04029680311090848]
	TIME [epoch: 11.5 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03408190774866093		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.03408190774866093 | validation: 0.03864472764461701]
	TIME [epoch: 11.5 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03947045950520491		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.03947045950520491 | validation: 0.03947678190163607]
	TIME [epoch: 11.5 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03554445097898073		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.03554445097898073 | validation: 0.04185069223356459]
	TIME [epoch: 11.5 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0356242778741177		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.0356242778741177 | validation: 0.02929968264050923]
	TIME [epoch: 11.5 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036449222357531154		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.036449222357531154 | validation: 0.031066540187815992]
	TIME [epoch: 11.5 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030493549250269727		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.030493549250269727 | validation: 0.029237621574137968]
	TIME [epoch: 11.5 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029685380837034085		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.029685380837034085 | validation: 0.03260682085998409]
	TIME [epoch: 11.5 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03377014793619087		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.03377014793619087 | validation: 0.04052389125018438]
	TIME [epoch: 11.5 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03132402466105557		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.03132402466105557 | validation: 0.03274005375887713]
	TIME [epoch: 11.5 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029731545674441903		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.029731545674441903 | validation: 0.032080642222327226]
	TIME [epoch: 11.5 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030484160116336045		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.030484160116336045 | validation: 0.033625999572271914]
	TIME [epoch: 11.5 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03151676015875207		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.03151676015875207 | validation: 0.03333651473400611]
	TIME [epoch: 11.5 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034687686904191856		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.034687686904191856 | validation: 0.035889623320852986]
	TIME [epoch: 11.5 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03373581879160476		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.03373581879160476 | validation: 0.04027118932384464]
	TIME [epoch: 11.5 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031014957055413572		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.031014957055413572 | validation: 0.03857613430064188]
	TIME [epoch: 11.5 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031430809249612675		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.031430809249612675 | validation: 0.03518134982072035]
	TIME [epoch: 11.5 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03005564414067638		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.03005564414067638 | validation: 0.0353083613098345]
	TIME [epoch: 11.5 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03254869489426852		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.03254869489426852 | validation: 0.03779417142176467]
	TIME [epoch: 11.5 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03642145554074998		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.03642145554074998 | validation: 0.03937159814927857]
	TIME [epoch: 11.5 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03740919814956545		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.03740919814956545 | validation: 0.03653568619544742]
	TIME [epoch: 11.5 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03470330461267514		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.03470330461267514 | validation: 0.03784837481936488]
	TIME [epoch: 11.5 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02872843953313515		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.02872843953313515 | validation: 0.037206056975468825]
	TIME [epoch: 11.5 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03358436918812974		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.03358436918812974 | validation: 0.03225762529894836]
	TIME [epoch: 11.5 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03176773998409767		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.03176773998409767 | validation: 0.030861104114522454]
	TIME [epoch: 11.5 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021912198289681717		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.021912198289681717 | validation: 0.028957548670637573]
	TIME [epoch: 11.5 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02910250887923843		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.02910250887923843 | validation: 0.01372078768014658]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_1334.pth
	Model improved!!!
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029365865074821952		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.029365865074821952 | validation: 0.03163357638067675]
	TIME [epoch: 11.5 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023807589730979718		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.023807589730979718 | validation: 0.020192743055825437]
	TIME [epoch: 11.5 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02861394103041936		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.02861394103041936 | validation: 0.025321389314486457]
	TIME [epoch: 11.5 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02417031118019823		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.02417031118019823 | validation: 0.029527220885552465]
	TIME [epoch: 11.5 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028700953829955703		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.028700953829955703 | validation: 0.02780445713920643]
	TIME [epoch: 11.5 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024148893000191754		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.024148893000191754 | validation: 0.03075762088222053]
	TIME [epoch: 11.5 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027595875843294246		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.027595875843294246 | validation: 0.03592288160849325]
	TIME [epoch: 11.5 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024974605115873696		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.024974605115873696 | validation: 0.02876150255361118]
	TIME [epoch: 11.5 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02549608893163474		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.02549608893163474 | validation: 0.022524406491060845]
	TIME [epoch: 11.5 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024220788617594417		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.024220788617594417 | validation: 0.024323858801892213]
	TIME [epoch: 11.5 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024542074174728683		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.024542074174728683 | validation: 0.032018314797090136]
	TIME [epoch: 11.5 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02641323134682273		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.02641323134682273 | validation: 0.031764910484526315]
	TIME [epoch: 11.5 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023707488625302232		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.023707488625302232 | validation: 0.02283696624120562]
	TIME [epoch: 11.5 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02075632406808712		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.02075632406808712 | validation: 0.036330074574373164]
	TIME [epoch: 11.5 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023749613679097073		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.023749613679097073 | validation: 0.02273558411106163]
	TIME [epoch: 11.5 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023297528463941588		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.023297528463941588 | validation: 0.02290132523465305]
	TIME [epoch: 11.5 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02499384954149084		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.02499384954149084 | validation: 0.03152988117192604]
	TIME [epoch: 11.5 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023456028074862984		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.023456028074862984 | validation: 0.028755939653773276]
	TIME [epoch: 11.5 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023573603154261363		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.023573603154261363 | validation: 0.02629535501307326]
	TIME [epoch: 11.5 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029121356803190335		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.029121356803190335 | validation: 0.030692824347048175]
	TIME [epoch: 11.5 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02576163838100154		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.02576163838100154 | validation: 0.02225975312155072]
	TIME [epoch: 11.5 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027037786598887385		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.027037786598887385 | validation: 0.023781864299649142]
	TIME [epoch: 11.5 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025829418672920185		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.025829418672920185 | validation: 0.030043532034491047]
	TIME [epoch: 11.5 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022470286002661793		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.022470286002661793 | validation: 0.027405382996832674]
	TIME [epoch: 11.5 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024774177727856412		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.024774177727856412 | validation: 0.024986584775051314]
	TIME [epoch: 11.5 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02554025012362497		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.02554025012362497 | validation: 0.04076004842058655]
	TIME [epoch: 11.5 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02989303532593511		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.02989303532593511 | validation: 0.02973133908903674]
	TIME [epoch: 11.5 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028797541575535192		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.028797541575535192 | validation: 0.025151899179469847]
	TIME [epoch: 11.5 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024458324234982377		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.024458324234982377 | validation: 0.023393074843573693]
	TIME [epoch: 11.5 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02677061412452016		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.02677061412452016 | validation: 0.029215347693494688]
	TIME [epoch: 11.5 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02705348480284274		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.02705348480284274 | validation: 0.03698749749788081]
	TIME [epoch: 11.5 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022999981303292113		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.022999981303292113 | validation: 0.0328054929491344]
	TIME [epoch: 11.5 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028301412470817335		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.028301412470817335 | validation: 0.032452312420984106]
	TIME [epoch: 11.5 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02719980976399291		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.02719980976399291 | validation: 0.03249197353408019]
	TIME [epoch: 11.5 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027869158746092096		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.027869158746092096 | validation: 0.02995985638280117]
	TIME [epoch: 11.5 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026367143958563495		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.026367143958563495 | validation: 0.03824409152686298]
	TIME [epoch: 11.5 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02532469035058013		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.02532469035058013 | validation: 0.033029997056893454]
	TIME [epoch: 11.5 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02549957083735194		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.02549957083735194 | validation: 0.026766964496512717]
	TIME [epoch: 11.5 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030316550152554057		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.030316550152554057 | validation: 0.03314173368119249]
	TIME [epoch: 11.5 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0269037804354937		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.0269037804354937 | validation: 0.03423909450876784]
	TIME [epoch: 11.5 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02877212618598432		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.02877212618598432 | validation: 0.0330239385199424]
	TIME [epoch: 11.5 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027961455481445952		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.027961455481445952 | validation: 0.03236120129653729]
	TIME [epoch: 11.5 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02681045923996954		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.02681045923996954 | validation: 0.028713004457985348]
	TIME [epoch: 11.5 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022106751789879735		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.022106751789879735 | validation: 0.025053114549970865]
	TIME [epoch: 11.5 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022741308749747204		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.022741308749747204 | validation: 0.03902632108184003]
	TIME [epoch: 11.5 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02217610078208556		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.02217610078208556 | validation: 0.03158247224360748]
	TIME [epoch: 11.5 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024468438411369482		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.024468438411369482 | validation: 0.03170576339606849]
	TIME [epoch: 11.5 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024259433035547853		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.024259433035547853 | validation: 0.03131063715859066]
	TIME [epoch: 11.5 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024714755342370387		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.024714755342370387 | validation: 0.03163552211883414]
	TIME [epoch: 11.5 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02576539842179407		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.02576539842179407 | validation: 0.03331994752030004]
	TIME [epoch: 11.5 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0254294934208346		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.0254294934208346 | validation: 0.029746014117579014]
	TIME [epoch: 11.5 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02534249311911716		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.02534249311911716 | validation: 0.02494484268210285]
	TIME [epoch: 11.5 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02580480255413183		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.02580480255413183 | validation: 0.025834040277394738]
	TIME [epoch: 11.5 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020253837565660973		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.020253837565660973 | validation: 0.03411634364495386]
	TIME [epoch: 11.5 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02193970254994557		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.02193970254994557 | validation: 0.022794707844120285]
	TIME [epoch: 11.5 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023458018566109864		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.023458018566109864 | validation: 0.023013522198665513]
	TIME [epoch: 11.5 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025281827438111353		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.025281827438111353 | validation: 0.02546717668429621]
	TIME [epoch: 11.5 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022443818620895072		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.022443818620895072 | validation: 0.03209339640823427]
	TIME [epoch: 11.5 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025200108551363502		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.025200108551363502 | validation: 0.026485415012494577]
	TIME [epoch: 11.5 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022093039848461705		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.022093039848461705 | validation: 0.0300942987177446]
	TIME [epoch: 11.5 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02345870605971364		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.02345870605971364 | validation: 0.03499466046321266]
	TIME [epoch: 11.5 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02358923888198518		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.02358923888198518 | validation: 0.03745920282385262]
	TIME [epoch: 11.5 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024092969052690164		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.024092969052690164 | validation: 0.031470181924354634]
	TIME [epoch: 11.5 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025551803654740354		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.025551803654740354 | validation: 0.027915553960064426]
	TIME [epoch: 11.5 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024928824815038567		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.024928824815038567 | validation: 0.030965701575212615]
	TIME [epoch: 11.5 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02238029512722475		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.02238029512722475 | validation: 0.03518160017066598]
	TIME [epoch: 11.5 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024365601338047993		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.024365601338047993 | validation: 0.027085144486932337]
	TIME [epoch: 11.5 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02670415283007757		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.02670415283007757 | validation: 0.03381276102552889]
	TIME [epoch: 11.5 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02250795244419601		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.02250795244419601 | validation: 0.029789909693491545]
	TIME [epoch: 11.5 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018671761027047422		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.018671761027047422 | validation: 0.02626406481259158]
	TIME [epoch: 11.5 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026028406822068653		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.026028406822068653 | validation: 0.03441719396206811]
	TIME [epoch: 11.5 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021742837363450566		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.021742837363450566 | validation: 0.024283039218646923]
	TIME [epoch: 11.5 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02424208062678454		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.02424208062678454 | validation: 0.02297163821645159]
	TIME [epoch: 11.5 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02353483933972223		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.02353483933972223 | validation: 0.022179808883282963]
	TIME [epoch: 11.5 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023207465261129972		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.023207465261129972 | validation: 0.02527846298407658]
	TIME [epoch: 11.5 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024578307287162232		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.024578307287162232 | validation: 0.03555735923159713]
	TIME [epoch: 11.5 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019003270936567947		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.019003270936567947 | validation: 0.02544897045300825]
	TIME [epoch: 11.5 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018383571091170385		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.018383571091170385 | validation: 0.027477202081396705]
	TIME [epoch: 11.5 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021459696417145502		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.021459696417145502 | validation: 0.023851797049843616]
	TIME [epoch: 11.5 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024764982535355855		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.024764982535355855 | validation: 0.02743133948294937]
	TIME [epoch: 11.5 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021173971760140457		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.021173971760140457 | validation: 0.026895092355244073]
	TIME [epoch: 11.5 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0230078480563474		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.0230078480563474 | validation: 0.03182041908620237]
	TIME [epoch: 11.5 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024464222490663094		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.024464222490663094 | validation: 0.023790855974493326]
	TIME [epoch: 11.5 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022742390116126575		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.022742390116126575 | validation: 0.03402030565733585]
	TIME [epoch: 11.5 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024719649475140323		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.024719649475140323 | validation: 0.03150735617994068]
	TIME [epoch: 11.5 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021709325740043757		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.021709325740043757 | validation: 0.02963413242613513]
	TIME [epoch: 11.5 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025463047671786046		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.025463047671786046 | validation: 0.03171404162937029]
	TIME [epoch: 11.5 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026771022541773645		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.026771022541773645 | validation: 0.02930923346777699]
	TIME [epoch: 11.5 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022390715805390676		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.022390715805390676 | validation: 0.024332436573536058]
	TIME [epoch: 11.5 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024641575099497024		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.024641575099497024 | validation: 0.030178570928082262]
	TIME [epoch: 11.5 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023733177120545335		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.023733177120545335 | validation: 0.02205540962972795]
	TIME [epoch: 11.5 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022050648651493455		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.022050648651493455 | validation: 0.021155807182117067]
	TIME [epoch: 11.5 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02171115161486178		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.02171115161486178 | validation: 0.026417477781536417]
	TIME [epoch: 11.5 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023974523408229094		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.023974523408229094 | validation: 0.01695861906990863]
	TIME [epoch: 11.5 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021315496690656632		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.021315496690656632 | validation: 0.022523318039754516]
	TIME [epoch: 11.5 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0218846641153152		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.0218846641153152 | validation: 0.02314226047866929]
	TIME [epoch: 11.5 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022883668236739447		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.022883668236739447 | validation: 0.03202543579095924]
	TIME [epoch: 11.5 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026459389466779063		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.026459389466779063 | validation: 0.027943028231501525]
	TIME [epoch: 11.5 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023671533341985983		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.023671533341985983 | validation: 0.031725330598893826]
	TIME [epoch: 11.5 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02455837143447633		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.02455837143447633 | validation: 0.02715702459485546]
	TIME [epoch: 11.5 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025090964549498187		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.025090964549498187 | validation: 0.031862871549006994]
	TIME [epoch: 11.5 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022146256165305203		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.022146256165305203 | validation: 0.02190916032978485]
	TIME [epoch: 11.5 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02354935191055018		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.02354935191055018 | validation: 0.025741947306140222]
	TIME [epoch: 11.5 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020241061310350958		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.020241061310350958 | validation: 0.01664805410392718]
	TIME [epoch: 11.5 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019586665823266673		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.019586665823266673 | validation: 0.019633513301686847]
	TIME [epoch: 11.5 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023201888507391907		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.023201888507391907 | validation: 0.01992405425795607]
	TIME [epoch: 11.5 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02173242678026089		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.02173242678026089 | validation: 0.02046863684681542]
	TIME [epoch: 11.5 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022118094054071044		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.022118094054071044 | validation: 0.02673486925740633]
	TIME [epoch: 11.5 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02076205152426991		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.02076205152426991 | validation: 0.026177581722220365]
	TIME [epoch: 11.5 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022485588888998497		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.022485588888998497 | validation: 0.026006548396988693]
	TIME [epoch: 11.5 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02320782615991152		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.02320782615991152 | validation: 0.0320503963096303]
	TIME [epoch: 11.5 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023985805285280888		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.023985805285280888 | validation: 0.03153129910660334]
	TIME [epoch: 11.5 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023444828531162844		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.023444828531162844 | validation: 0.02458706862495338]
	TIME [epoch: 11.5 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024707628788629036		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.024707628788629036 | validation: 0.02882961299532931]
	TIME [epoch: 11.5 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023355991369012997		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.023355991369012997 | validation: 0.024020915328430287]
	TIME [epoch: 11.5 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02140412827602297		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.02140412827602297 | validation: 0.02884377795130342]
	TIME [epoch: 11.5 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020446893645233468		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.020446893645233468 | validation: 0.02866186284979717]
	TIME [epoch: 11.5 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021091799788495177		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.021091799788495177 | validation: 0.025962702327679166]
	TIME [epoch: 11.5 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024049222689555953		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.024049222689555953 | validation: 0.0203587263086229]
	TIME [epoch: 11.5 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020663305020606322		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.020663305020606322 | validation: 0.027000861863388775]
	TIME [epoch: 11.5 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021817845314169002		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.021817845314169002 | validation: 0.021252508500050817]
	TIME [epoch: 11.5 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019862527432893205		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.019862527432893205 | validation: 0.021928899809001985]
	TIME [epoch: 11.5 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01905212250784322		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.01905212250784322 | validation: 0.028659571881350515]
	TIME [epoch: 11.5 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02212527739841061		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.02212527739841061 | validation: 0.02728374622121364]
	TIME [epoch: 11.5 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021479077880340175		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.021479077880340175 | validation: 0.026989487500623178]
	TIME [epoch: 11.5 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024799552967344672		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.024799552967344672 | validation: 0.02307248725748813]
	TIME [epoch: 11.5 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021001117462834416		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.021001117462834416 | validation: 0.025161173318583755]
	TIME [epoch: 11.5 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019553129301031397		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.019553129301031397 | validation: 0.024649665040291285]
	TIME [epoch: 11.5 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02178900285038516		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.02178900285038516 | validation: 0.027786276151823483]
	TIME [epoch: 11.5 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019138632914901293		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.019138632914901293 | validation: 0.026467079903861466]
	TIME [epoch: 11.5 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0226135919804556		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.0226135919804556 | validation: 0.020777776110222593]
	TIME [epoch: 11.5 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02286204805287926		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.02286204805287926 | validation: 0.025637860174792207]
	TIME [epoch: 11.5 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02224902109267559		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.02224902109267559 | validation: 0.029155596042484723]
	TIME [epoch: 11.5 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022295268354705827		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.022295268354705827 | validation: 0.02672345751112515]
	TIME [epoch: 11.5 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019182472128368912		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.019182472128368912 | validation: 0.030176840993143328]
	TIME [epoch: 11.5 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023025293610139868		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.023025293610139868 | validation: 0.022598856443276496]
	TIME [epoch: 11.5 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024942139475836973		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.024942139475836973 | validation: 0.02858606365211174]
	TIME [epoch: 11.5 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022897223641124436		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.022897223641124436 | validation: 0.03456856683299126]
	TIME [epoch: 11.5 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021296466104138153		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.021296466104138153 | validation: 0.02619910185218754]
	TIME [epoch: 11.5 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020529689326255204		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.020529689326255204 | validation: 0.029287335182096537]
	TIME [epoch: 11.5 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020657635070608707		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.020657635070608707 | validation: 0.028876246569308872]
	TIME [epoch: 11.5 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022130227927399906		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.022130227927399906 | validation: 0.021945682565486055]
	TIME [epoch: 11.5 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024194457278184367		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.024194457278184367 | validation: 0.020969718926885508]
	TIME [epoch: 11.5 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024441392342860566		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.024441392342860566 | validation: 0.028610541993750682]
	TIME [epoch: 11.5 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023038552015792267		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.023038552015792267 | validation: 0.017894400960766218]
	TIME [epoch: 11.5 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020681365897010053		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.020681365897010053 | validation: 0.025816988970334086]
	TIME [epoch: 11.5 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02291941758307129		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.02291941758307129 | validation: 0.02578657965365097]
	TIME [epoch: 11.5 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021642768065487875		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.021642768065487875 | validation: 0.018369278337559664]
	TIME [epoch: 11.5 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02000774625334633		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.02000774625334633 | validation: 0.024611091787016807]
	TIME [epoch: 11.5 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02216585462712232		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.02216585462712232 | validation: 0.02612244947240886]
	TIME [epoch: 11.5 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02135716097947927		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.02135716097947927 | validation: 0.02777091221662272]
	TIME [epoch: 11.5 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022980807686365016		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.022980807686365016 | validation: 0.020784775740747104]
	TIME [epoch: 11.5 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02465686377613354		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.02465686377613354 | validation: 0.028864133547518895]
	TIME [epoch: 11.5 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02126205620112945		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.02126205620112945 | validation: 0.021257406964133172]
	TIME [epoch: 11.5 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024534445181579788		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.024534445181579788 | validation: 0.022892717301163334]
	TIME [epoch: 11.5 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02080918161519964		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.02080918161519964 | validation: 0.024095615768920834]
	TIME [epoch: 11.5 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02321737065102731		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.02321737065102731 | validation: 0.02748566932652935]
	TIME [epoch: 11.5 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019669963515059383		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.019669963515059383 | validation: 0.026534920306794246]
	TIME [epoch: 11.5 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022662602073106684		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.022662602073106684 | validation: 0.02439182611735557]
	TIME [epoch: 11.5 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024727828622006114		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.024727828622006114 | validation: 0.029564191585069795]
	TIME [epoch: 11.6 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024312914042241122		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.024312914042241122 | validation: 0.030109327177763545]
	TIME [epoch: 11.5 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026111632791139594		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.026111632791139594 | validation: 0.02838261024520361]
	TIME [epoch: 11.5 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022137063256447573		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.022137063256447573 | validation: 0.03179472647860649]
	TIME [epoch: 11.5 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024391459104487433		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.024391459104487433 | validation: 0.027804225100532973]
	TIME [epoch: 11.5 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022371542464313336		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.022371542464313336 | validation: 0.025097005168826007]
	TIME [epoch: 11.5 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02572160255128866		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.02572160255128866 | validation: 0.03101069910906113]
	TIME [epoch: 11.5 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023305244883202125		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.023305244883202125 | validation: 0.023581270568100363]
	TIME [epoch: 11.5 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02020034404864805		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.02020034404864805 | validation: 0.02009657594789708]
	TIME [epoch: 11.5 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01990779517184654		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.01990779517184654 | validation: 0.02521696255248269]
	TIME [epoch: 11.5 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023911524986768372		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.023911524986768372 | validation: 0.028201830126530707]
	TIME [epoch: 11.5 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024519491743670786		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.024519491743670786 | validation: 0.02063361060369381]
	TIME [epoch: 11.5 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022475590270205355		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.022475590270205355 | validation: 0.03617099142042273]
	TIME [epoch: 11.5 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022524354022731206		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.022524354022731206 | validation: 0.02882405937907109]
	TIME [epoch: 11.5 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02444998119830294		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.02444998119830294 | validation: 0.02859682822507257]
	TIME [epoch: 11.5 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019829611698323667		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.019829611698323667 | validation: 0.03525539468616581]
	TIME [epoch: 11.5 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02320261001329914		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.02320261001329914 | validation: 0.027250493837869358]
	TIME [epoch: 11.6 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02309107918686602		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.02309107918686602 | validation: 0.030877114157695545]
	TIME [epoch: 11.5 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019626237878619956		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.019626237878619956 | validation: 0.029351187811991676]
	TIME [epoch: 11.5 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02212137311471647		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.02212137311471647 | validation: 0.023646963494085856]
	TIME [epoch: 11.5 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022444258522092503		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.022444258522092503 | validation: 0.02461027177289731]
	TIME [epoch: 11.5 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021651751992972094		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.021651751992972094 | validation: 0.026977564454941812]
	TIME [epoch: 11.5 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02335935397402748		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.02335935397402748 | validation: 0.03226083306045665]
	TIME [epoch: 11.5 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025851384925339744		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.025851384925339744 | validation: 0.025021722553621038]
	TIME [epoch: 11.5 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022568623965968808		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.022568623965968808 | validation: 0.02606871365873154]
	TIME [epoch: 11.5 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02473861203128383		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.02473861203128383 | validation: 0.02282353795952534]
	TIME [epoch: 11.5 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0299463761710954		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.0299463761710954 | validation: 0.03192094100667218]
	TIME [epoch: 11.5 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02365562546460901		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.02365562546460901 | validation: 0.03162514429389715]
	TIME [epoch: 11.5 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02700393490200156		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.02700393490200156 | validation: 0.022305261690111593]
	TIME [epoch: 11.5 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025794959343386117		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.025794959343386117 | validation: 0.02930594115603523]
	TIME [epoch: 11.5 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025409941048200463		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.025409941048200463 | validation: 0.028655144528361702]
	TIME [epoch: 11.5 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029078836936359435		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.029078836936359435 | validation: 0.034470867512549984]
	TIME [epoch: 11.5 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02865844411183318		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.02865844411183318 | validation: 0.03482617006080938]
	TIME [epoch: 11.5 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031887541841583524		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.031887541841583524 | validation: 0.03452894554958908]
	TIME [epoch: 11.5 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02149145338289197		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.02149145338289197 | validation: 0.03892338998038267]
	TIME [epoch: 11.5 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026393554407706195		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.026393554407706195 | validation: 0.0331728353298715]
	TIME [epoch: 11.5 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030077363956015606		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.030077363956015606 | validation: 0.035705507938002236]
	TIME [epoch: 11.5 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030311098415480527		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.030311098415480527 | validation: 0.033587187826979746]
	TIME [epoch: 11.5 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02816816844715096		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.02816816844715096 | validation: 0.0321792985744755]
	TIME [epoch: 11.5 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025901373723550593		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.025901373723550593 | validation: 0.026719722946898034]
	TIME [epoch: 11.5 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02370880225103357		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.02370880225103357 | validation: 0.018315784553188642]
	TIME [epoch: 11.5 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024113369717569517		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.024113369717569517 | validation: 0.03035254174669877]
	TIME [epoch: 11.5 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02110990307490795		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.02110990307490795 | validation: 0.030039567320015392]
	TIME [epoch: 11.5 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021270046051465933		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.021270046051465933 | validation: 0.035081095836718354]
	TIME [epoch: 11.5 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02275767529910868		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.02275767529910868 | validation: 0.03389008789144843]
	TIME [epoch: 11.5 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02576565154468145		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.02576565154468145 | validation: 0.039510159058492186]
	TIME [epoch: 11.5 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026174253382754295		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.026174253382754295 | validation: 0.03755986910077271]
	TIME [epoch: 11.5 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029176060618987733		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.029176060618987733 | validation: 0.039294296523924105]
	TIME [epoch: 11.5 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0348456308795791		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.0348456308795791 | validation: 0.0410119698739096]
	TIME [epoch: 11.5 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027967688747530795		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.027967688747530795 | validation: 0.02744695618570124]
	TIME [epoch: 11.5 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030863164127342205		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.030863164127342205 | validation: 0.026996360094897368]
	TIME [epoch: 11.5 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030669385367861193		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.030669385367861193 | validation: 0.033558333523835346]
	TIME [epoch: 11.5 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026558548207851106		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.026558548207851106 | validation: 0.02979470921381087]
	TIME [epoch: 11.5 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028197463316596144		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.028197463316596144 | validation: 0.029633757549763003]
	TIME [epoch: 11.5 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028119618022482168		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.028119618022482168 | validation: 0.025851882408643095]
	TIME [epoch: 11.5 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02559240311384101		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.02559240311384101 | validation: 0.025259886348751863]
	TIME [epoch: 11.5 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026228123835383678		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.026228123835383678 | validation: 0.024406559672806992]
	TIME [epoch: 11.5 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02459370713667274		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.02459370713667274 | validation: 0.03438292170404243]
	TIME [epoch: 11.5 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0284542641674298		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.0284542641674298 | validation: 0.03555222299547533]
	TIME [epoch: 11.5 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029027264764791748		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.029027264764791748 | validation: 0.03795865865308595]
	TIME [epoch: 11.5 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02794065690214722		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.02794065690214722 | validation: 0.03438150317949307]
	TIME [epoch: 11.5 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031576695753311505		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.031576695753311505 | validation: 0.03718628243176648]
	TIME [epoch: 11.5 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03562419144738397		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.03562419144738397 | validation: 0.03930506473988848]
	TIME [epoch: 11.5 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03377184347885746		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.03377184347885746 | validation: 0.03367631100555802]
	TIME [epoch: 11.5 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03474185951304428		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.03474185951304428 | validation: 0.03932842477157446]
	TIME [epoch: 11.5 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03023924201776062		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.03023924201776062 | validation: 0.02905734970437976]
	TIME [epoch: 11.5 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03167491749415922		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.03167491749415922 | validation: 0.031901006038130335]
	TIME [epoch: 11.5 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03042320607771907		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.03042320607771907 | validation: 0.03659703976573277]
	TIME [epoch: 11.5 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023948116985594153		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.023948116985594153 | validation: 0.028022400663925074]
	TIME [epoch: 11.5 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033197155145505974		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.033197155145505974 | validation: 0.028969619116786926]
	TIME [epoch: 11.5 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025822923458658702		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.025822923458658702 | validation: 0.030177123667770544]
	TIME [epoch: 11.5 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022293998015109926		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.022293998015109926 | validation: 0.0245858246503787]
	TIME [epoch: 11.5 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02584023580548994		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.02584023580548994 | validation: 0.02511836072534871]
	TIME [epoch: 11.5 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021750157323160813		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.021750157323160813 | validation: 0.034505210121759326]
	TIME [epoch: 11.5 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021865376865596663		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.021865376865596663 | validation: 0.024464607712150827]
	TIME [epoch: 11.5 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020046250987675134		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.020046250987675134 | validation: 0.02487412664692686]
	TIME [epoch: 11.5 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025680273212849096		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.025680273212849096 | validation: 0.031291695189537214]
	TIME [epoch: 11.5 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02447142042232903		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.02447142042232903 | validation: 0.02113773784910118]
	TIME [epoch: 11.5 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027646822814631048		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.027646822814631048 | validation: 0.03321526847044277]
	TIME [epoch: 11.5 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025960056468419604		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.025960056468419604 | validation: 0.03327578505408615]
	TIME [epoch: 11.5 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026844287224742545		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.026844287224742545 | validation: 0.024932566608142474]
	TIME [epoch: 11.5 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022926348725852082		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.022926348725852082 | validation: 0.031648787558816754]
	TIME [epoch: 11.5 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02331549191520433		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.02331549191520433 | validation: 0.03027872693595888]
	TIME [epoch: 11.5 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025497174135755335		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.025497174135755335 | validation: 0.03365760246503768]
	TIME [epoch: 11.5 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023602155594899456		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.023602155594899456 | validation: 0.031115455087309105]
	TIME [epoch: 11.5 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022383130617131125		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.022383130617131125 | validation: 0.02774178023707295]
	TIME [epoch: 11.5 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02250819505992771		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.02250819505992771 | validation: 0.028705696382459893]
	TIME [epoch: 11.5 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024691277773764928		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.024691277773764928 | validation: 0.0250942163195954]
	TIME [epoch: 11.5 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022991430587329935		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.022991430587329935 | validation: 0.03463893394408932]
	TIME [epoch: 11.5 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02161341768874888		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.02161341768874888 | validation: 0.030552750752962713]
	TIME [epoch: 11.5 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024642563253247575		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.024642563253247575 | validation: 0.02636184874713954]
	TIME [epoch: 11.5 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023800012016387727		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.023800012016387727 | validation: 0.02988525835852235]
	TIME [epoch: 11.5 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02165294573201317		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.02165294573201317 | validation: 0.030788205341449878]
	TIME [epoch: 11.5 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022597296226483606		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.022597296226483606 | validation: 0.025052087811335912]
	TIME [epoch: 11.5 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024781550379020426		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.024781550379020426 | validation: 0.037498628688795325]
	TIME [epoch: 11.5 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022107272748719826		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.022107272748719826 | validation: 0.021534195218589965]
	TIME [epoch: 11.5 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023203958750939398		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.023203958750939398 | validation: 0.025319605872924783]
	TIME [epoch: 11.5 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029259810744529317		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.029259810744529317 | validation: 0.03843298126032006]
	TIME [epoch: 11.5 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02558407369291651		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.02558407369291651 | validation: 0.026999242302136094]
	TIME [epoch: 11.5 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02782458578764647		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.02782458578764647 | validation: 0.03024271895648188]
	TIME [epoch: 11.5 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02781443479319954		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.02781443479319954 | validation: 0.028667630905319604]
	TIME [epoch: 11.5 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02534383177803922		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.02534383177803922 | validation: 0.03174553900743551]
	TIME [epoch: 11.5 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026925715401392863		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.026925715401392863 | validation: 0.028055680347328894]
	TIME [epoch: 11.5 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024340634500160743		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.024340634500160743 | validation: 0.03580314283310746]
	TIME [epoch: 11.5 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024979906364408833		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.024979906364408833 | validation: 0.027444591573842103]
	TIME [epoch: 11.5 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026417698368312596		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.026417698368312596 | validation: 0.027301108526994335]
	TIME [epoch: 11.5 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025304651329146857		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.025304651329146857 | validation: 0.02613143798595453]
	TIME [epoch: 11.5 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02223677520095913		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.02223677520095913 | validation: 0.02873839954084775]
	TIME [epoch: 11.5 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024509138077971303		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.024509138077971303 | validation: 0.02218189894182551]
	TIME [epoch: 11.5 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02139956321743831		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.02139956321743831 | validation: 0.02899766174714098]
	TIME [epoch: 11.5 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021234784605310725		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.021234784605310725 | validation: 0.021238306767196208]
	TIME [epoch: 11.5 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02333487033212272		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.02333487033212272 | validation: 0.030365928393258114]
	TIME [epoch: 11.5 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020180760016374685		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.020180760016374685 | validation: 0.031445812332396406]
	TIME [epoch: 11.5 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024733133627562028		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.024733133627562028 | validation: 0.02612629748813951]
	TIME [epoch: 11.5 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022090514941345823		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.022090514941345823 | validation: 0.030684536250957253]
	TIME [epoch: 11.5 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02448016835087722		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.02448016835087722 | validation: 0.02763622777340551]
	TIME [epoch: 11.5 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022988101088585365		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.022988101088585365 | validation: 0.03174289334077777]
	TIME [epoch: 11.5 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01939529518270744		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.01939529518270744 | validation: 0.02474773175056936]
	TIME [epoch: 11.5 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02221378454896651		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.02221378454896651 | validation: 0.023290330343881848]
	TIME [epoch: 11.5 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024042427505856494		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.024042427505856494 | validation: 0.024300969749767934]
	TIME [epoch: 11.5 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019361510174942528		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.019361510174942528 | validation: 0.027164913335839397]
	TIME [epoch: 11.5 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020764150358622953		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.020764150358622953 | validation: 0.034404270449535194]
	TIME [epoch: 11.5 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023104339062334944		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.023104339062334944 | validation: 0.018868336972030594]
	TIME [epoch: 11.5 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024745884094820036		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.024745884094820036 | validation: 0.03050097878022566]
	TIME [epoch: 11.5 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02040583012005566		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.02040583012005566 | validation: 0.02531281723902686]
	TIME [epoch: 11.5 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01844573913842964		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.01844573913842964 | validation: 0.02472605983618987]
	TIME [epoch: 11.5 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019919036639571865		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.019919036639571865 | validation: 0.019407094856282985]
	TIME [epoch: 11.5 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022301480672905525		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.022301480672905525 | validation: 0.02504280861423454]
	TIME [epoch: 11.5 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021937485846883945		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.021937485846883945 | validation: 0.028170992958494116]
	TIME [epoch: 11.5 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02199080921578891		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.02199080921578891 | validation: 0.03013233781527846]
	TIME [epoch: 11.5 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024213676021122864		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.024213676021122864 | validation: 0.030055657337655486]
	TIME [epoch: 11.5 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021907870612755773		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.021907870612755773 | validation: 0.032073644652998716]
	TIME [epoch: 11.5 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023892653750507593		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.023892653750507593 | validation: 0.02938783731370978]
	TIME [epoch: 11.5 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02256002140110186		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.02256002140110186 | validation: 0.02640467778607391]
	TIME [epoch: 11.5 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019082892885372658		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.019082892885372658 | validation: 0.03423980395992007]
	TIME [epoch: 11.5 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022762866232085285		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.022762866232085285 | validation: 0.026681206486843176]
	TIME [epoch: 11.5 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018387451930150466		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.018387451930150466 | validation: 0.026198293918263615]
	TIME [epoch: 11.5 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02070100753993066		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.02070100753993066 | validation: 0.02317252087526648]
	TIME [epoch: 11.5 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025077546693311713		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.025077546693311713 | validation: 0.03003011213415239]
	TIME [epoch: 11.5 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023360208543857272		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.023360208543857272 | validation: 0.03019715735301458]
	TIME [epoch: 11.5 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020922375473687346		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.020922375473687346 | validation: 0.02711307172857549]
	TIME [epoch: 11.5 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021029004572539495		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.021029004572539495 | validation: 0.02263488332005914]
	TIME [epoch: 11.5 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022493994302346523		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.022493994302346523 | validation: 0.0221136093736379]
	TIME [epoch: 11.5 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025521244774832762		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.025521244774832762 | validation: 0.02573439243153416]
	TIME [epoch: 11.5 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021897841735678367		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.021897841735678367 | validation: 0.024968676345994912]
	TIME [epoch: 11.5 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022091062641651282		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.022091062641651282 | validation: 0.03345239890054241]
	TIME [epoch: 11.5 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020088857951130856		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.020088857951130856 | validation: 0.02692916870840516]
	TIME [epoch: 11.5 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0235998663777516		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.0235998663777516 | validation: 0.01953819481888631]
	TIME [epoch: 11.5 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020326292112753736		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.020326292112753736 | validation: 0.02289354021475316]
	TIME [epoch: 11.5 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02070830724082131		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.02070830724082131 | validation: 0.0328427456332307]
	TIME [epoch: 11.5 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022668659135233072		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.022668659135233072 | validation: 0.025226363200859307]
	TIME [epoch: 11.5 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025197911158966774		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.025197911158966774 | validation: 0.029645333051350874]
	TIME [epoch: 11.5 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02122046561667639		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.02122046561667639 | validation: 0.02432286891005958]
	TIME [epoch: 11.5 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02223408217394184		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.02223408217394184 | validation: 0.030262855603686453]
	TIME [epoch: 11.5 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02026711238226516		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.02026711238226516 | validation: 0.028307389929650012]
	TIME [epoch: 11.5 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021124026489395875		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.021124026489395875 | validation: 0.027175328186246423]
	TIME [epoch: 11.5 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020037382329395684		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.020037382329395684 | validation: 0.02635012735513642]
	TIME [epoch: 11.5 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018759339572319407		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.018759339572319407 | validation: 0.03415548995705143]
	TIME [epoch: 11.5 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019780641062750466		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.019780641062750466 | validation: 0.029087563427517997]
	TIME [epoch: 11.5 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02352615430673869		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.02352615430673869 | validation: 0.032140207297298766]
	TIME [epoch: 11.5 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020207455477545485		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.020207455477545485 | validation: 0.029616864328079952]
	TIME [epoch: 11.5 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020221754362490088		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.020221754362490088 | validation: 0.0314617640829094]
	TIME [epoch: 11.5 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021396302766559107		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.021396302766559107 | validation: 0.03145259994825269]
	TIME [epoch: 11.5 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02157573286882921		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.02157573286882921 | validation: 0.020364144138836814]
	TIME [epoch: 11.5 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019921405359581368		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.019921405359581368 | validation: 0.026808496194157247]
	TIME [epoch: 11.5 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021212365395737398		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.021212365395737398 | validation: 0.0216700651397316]
	TIME [epoch: 11.5 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02264666929142325		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.02264666929142325 | validation: 0.030591014696274677]
	TIME [epoch: 11.5 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022782572547357757		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.022782572547357757 | validation: 0.026626348409677463]
	TIME [epoch: 11.5 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022833654081070555		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.022833654081070555 | validation: 0.03659202878275608]
	TIME [epoch: 11.5 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020452128604026776		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.020452128604026776 | validation: 0.02782111398394938]
	TIME [epoch: 11.5 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023676659574394937		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.023676659574394937 | validation: 0.030793270909569088]
	TIME [epoch: 11.5 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023114125806135977		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.023114125806135977 | validation: 0.030744251792381716]
	TIME [epoch: 11.5 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025684174255907778		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.025684174255907778 | validation: 0.03249786829367146]
	TIME [epoch: 11.5 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02266514172861312		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.02266514172861312 | validation: 0.02964427617372496]
	TIME [epoch: 11.5 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026542672641176525		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.026542672641176525 | validation: 0.024018842953803857]
	TIME [epoch: 11.5 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026443722119271124		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.026443722119271124 | validation: 0.03280532578256708]
	TIME [epoch: 11.5 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027462514589092806		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.027462514589092806 | validation: 0.03177825435845818]
	TIME [epoch: 11.5 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02482927786544377		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.02482927786544377 | validation: 0.028780706045800578]
	TIME [epoch: 11.5 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024757921831510012		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.024757921831510012 | validation: 0.03376262207350919]
	TIME [epoch: 11.5 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025389500646130745		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.025389500646130745 | validation: 0.03298175025608633]
	TIME [epoch: 11.5 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02435469258250271		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.02435469258250271 | validation: 0.031012132061354586]
	TIME [epoch: 11.5 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02162031970064254		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.02162031970064254 | validation: 0.025569259381104624]
	TIME [epoch: 11.5 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022111179481948632		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.022111179481948632 | validation: 0.028272826002409206]
	TIME [epoch: 11.5 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024048741275478368		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.024048741275478368 | validation: 0.032193501290299825]
	TIME [epoch: 11.5 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025641125076243214		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.025641125076243214 | validation: 0.02243422237227133]
	TIME [epoch: 11.5 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02156993654015757		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.02156993654015757 | validation: 0.03407734357233693]
	TIME [epoch: 11.5 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02659347633917315		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.02659347633917315 | validation: 0.03010908905714114]
	TIME [epoch: 11.5 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02331513232429396		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.02331513232429396 | validation: 0.02723947446843473]
	TIME [epoch: 11.5 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020244239116583636		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.020244239116583636 | validation: 0.030113415203890413]
	TIME [epoch: 11.5 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02202570033132559		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.02202570033132559 | validation: 0.03169957255305377]
	TIME [epoch: 11.5 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02424185520514546		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.02424185520514546 | validation: 0.02526733247422707]
	TIME [epoch: 11.5 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023211453360330755		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.023211453360330755 | validation: 0.029735963803898743]
	TIME [epoch: 11.5 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023149579832526718		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.023149579832526718 | validation: 0.024115774395902012]
	TIME [epoch: 11.5 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02371098679311994		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.02371098679311994 | validation: 0.03185221272379929]
	TIME [epoch: 11.5 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022377553127433454		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.022377553127433454 | validation: 0.03335370235428852]
	TIME [epoch: 11.5 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019631415463097913		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.019631415463097913 | validation: 0.03194017093502514]
	TIME [epoch: 11.5 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02334262660890552		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.02334262660890552 | validation: 0.03328923255635928]
	TIME [epoch: 11.5 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021064737249150103		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.021064737249150103 | validation: 0.02844682483784189]
	TIME [epoch: 11.5 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022695902042744673		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.022695902042744673 | validation: 0.020481456250898863]
	TIME [epoch: 11.5 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024406917910295426		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.024406917910295426 | validation: 0.02052248284803301]
	TIME [epoch: 11.5 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021103075938883567		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.021103075938883567 | validation: 0.02613832597981493]
	TIME [epoch: 11.5 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02289780042175503		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.02289780042175503 | validation: 0.03315447210537377]
	TIME [epoch: 11.5 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023179179118550282		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.023179179118550282 | validation: 0.029061032144648363]
	TIME [epoch: 11.5 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02054305147602543		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.02054305147602543 | validation: 0.017352107830503144]
	TIME [epoch: 11.5 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023204391610903395		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.023204391610903395 | validation: 0.023597844543068628]
	TIME [epoch: 11.5 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02097406446040077		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.02097406446040077 | validation: 0.025306890679410072]
	TIME [epoch: 11.5 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016437541583769043		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.016437541583769043 | validation: 0.028608451977700504]
	TIME [epoch: 11.5 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018170245527531204		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.018170245527531204 | validation: 0.02824130206205656]
	TIME [epoch: 11.5 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020616612346570806		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.020616612346570806 | validation: 0.03296820140259644]
	TIME [epoch: 11.5 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02325882838708261		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.02325882838708261 | validation: 0.022938182716670398]
	TIME [epoch: 11.5 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01936772656686139		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.01936772656686139 | validation: 0.025247670420205034]
	TIME [epoch: 11.5 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020407027795283025		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.020407027795283025 | validation: 0.026049103680349038]
	TIME [epoch: 11.5 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022759445093855475		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.022759445093855475 | validation: 0.027105690317917475]
	TIME [epoch: 11.5 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023260124951189023		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.023260124951189023 | validation: 0.023525370621036316]
	TIME [epoch: 11.5 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021866659698465803		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.021866659698465803 | validation: 0.034109930236460216]
	TIME [epoch: 11.5 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0219697549525919		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.0219697549525919 | validation: 0.02751112933227798]
	TIME [epoch: 11.5 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02386409296180062		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.02386409296180062 | validation: 0.03254177649118134]
	TIME [epoch: 11.5 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021491906490616653		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.021491906490616653 | validation: 0.023672115296880673]
	TIME [epoch: 11.5 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02379938826810052		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.02379938826810052 | validation: 0.0288472076776701]
	TIME [epoch: 11.5 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021526381133519013		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.021526381133519013 | validation: 0.028274678004340154]
	TIME [epoch: 11.5 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023801863275512265		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.023801863275512265 | validation: 0.026606794125708957]
	TIME [epoch: 11.5 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024968118359881098		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.024968118359881098 | validation: 0.021946521153892447]
	TIME [epoch: 11.5 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018000152401885253		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.018000152401885253 | validation: 0.031852233650758316]
	TIME [epoch: 11.5 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020249053978838638		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.020249053978838638 | validation: 0.023183833258985844]
	TIME [epoch: 11.5 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017907845181095193		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.017907845181095193 | validation: 0.024645836338839055]
	TIME [epoch: 11.5 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02122402436137986		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.02122402436137986 | validation: 0.01732672161189474]
	TIME [epoch: 11.5 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024844406393863965		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.024844406393863965 | validation: 0.027537902403076492]
	TIME [epoch: 11.5 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024523114195245305		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.024523114195245305 | validation: 0.03459218363631255]
	TIME [epoch: 11.5 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025960944999905134		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.025960944999905134 | validation: 0.029807591333164987]
	TIME [epoch: 11.5 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022252683903748852		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.022252683903748852 | validation: 0.0249626910554515]
	TIME [epoch: 11.5 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019893880449992997		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.019893880449992997 | validation: 0.025702036699171576]
	TIME [epoch: 11.6 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022150339138491175		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.022150339138491175 | validation: 0.02839813949980504]
	TIME [epoch: 11.5 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023944333515749684		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.023944333515749684 | validation: 0.0269556773672711]
	TIME [epoch: 11.5 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022937085624932445		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.022937085624932445 | validation: 0.018503797715537455]
	TIME [epoch: 11.5 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020159180858974095		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.020159180858974095 | validation: 0.024504550582842316]
	TIME [epoch: 11.5 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020635549636823465		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.020635549636823465 | validation: 0.030497398420108086]
	TIME [epoch: 11.5 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019477691393277027		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.019477691393277027 | validation: 0.032957289365554636]
	TIME [epoch: 11.5 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022001061349793155		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.022001061349793155 | validation: 0.01801735127339976]
	TIME [epoch: 11.5 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02218151700643988		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.02218151700643988 | validation: 0.0181436520055379]
	TIME [epoch: 11.5 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02213975238776272		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.02213975238776272 | validation: 0.02920806635732225]
	TIME [epoch: 11.5 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021876418860023034		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.021876418860023034 | validation: 0.019247543916656222]
	TIME [epoch: 11.5 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022076805036019036		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.022076805036019036 | validation: 0.026533442831706288]
	TIME [epoch: 11.5 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0211301102424011		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.0211301102424011 | validation: 0.02402450384397436]
	TIME [epoch: 11.5 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023866291128472182		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.023866291128472182 | validation: 0.026935028335200797]
	TIME [epoch: 11.5 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02067322483010057		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.02067322483010057 | validation: 0.025318266380177472]
	TIME [epoch: 11.5 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01890901504704513		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.01890901504704513 | validation: 0.016983181851517985]
	TIME [epoch: 11.5 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0200285463876101		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.0200285463876101 | validation: 0.027753918670249702]
	TIME [epoch: 11.6 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02425798214792813		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.02425798214792813 | validation: 0.029916637440570534]
	TIME [epoch: 11.5 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021701272369971908		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.021701272369971908 | validation: 0.021064386387795463]
	TIME [epoch: 11.5 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022977784779826864		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.022977784779826864 | validation: 0.033093347085839414]
	TIME [epoch: 11.5 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0205781401921639		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.0205781401921639 | validation: 0.026763904764642858]
	TIME [epoch: 11.5 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019984487243299227		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.019984487243299227 | validation: 0.022718811981602808]
	TIME [epoch: 11.5 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01890046486154574		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.01890046486154574 | validation: 0.028251321606588747]
	TIME [epoch: 11.5 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02027216722981451		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.02027216722981451 | validation: 0.02369473266478149]
	TIME [epoch: 11.5 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020389575247438143		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.020389575247438143 | validation: 0.026842851813114688]
	TIME [epoch: 11.5 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019977631564780433		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.019977631564780433 | validation: 0.024099042442454435]
	TIME [epoch: 11.5 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02660137089817538		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.02660137089817538 | validation: 0.022576984623720105]
	TIME [epoch: 11.5 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020627621231678772		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.020627621231678772 | validation: 0.02651950457044933]
	TIME [epoch: 11.5 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020118257035667688		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.020118257035667688 | validation: 0.022166317782189464]
	TIME [epoch: 11.5 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020365148380188255		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.020365148380188255 | validation: 0.032153197876510595]
	TIME [epoch: 11.5 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023041119496835596		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.023041119496835596 | validation: 0.028686602786503933]
	TIME [epoch: 11.5 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018943464772884274		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.018943464772884274 | validation: 0.02858935069822237]
	TIME [epoch: 11.5 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023081461984820015		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.023081461984820015 | validation: 0.028085168274423204]
	TIME [epoch: 11.5 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01944345479459888		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.01944345479459888 | validation: 0.0276943955406358]
	TIME [epoch: 11.5 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020482018757250916		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.020482018757250916 | validation: 0.029206119941487283]
	TIME [epoch: 11.5 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021212844422432375		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.021212844422432375 | validation: 0.011364004378579966]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240309_135637/states/model_tr_study4_1759.pth
	Model improved!!!
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02481140799158108		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.02481140799158108 | validation: 0.03222681865486069]
	TIME [epoch: 11.5 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023631196312387828		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.023631196312387828 | validation: 0.027563855159058927]
	TIME [epoch: 11.5 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022958996455870694		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.022958996455870694 | validation: 0.02417331354795361]
	TIME [epoch: 11.5 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02283072684441173		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.02283072684441173 | validation: 0.033267863678707106]
	TIME [epoch: 11.5 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020206564346776854		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.020206564346776854 | validation: 0.03158072392133564]
	TIME [epoch: 11.5 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020594184237845065		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.020594184237845065 | validation: 0.025495099995685506]
	TIME [epoch: 11.5 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02162921305882103		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.02162921305882103 | validation: 0.020186799133383254]
	TIME [epoch: 11.5 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020574681503454734		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.020574681503454734 | validation: 0.01996467896878686]
	TIME [epoch: 11.5 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020385955320044256		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.020385955320044256 | validation: 0.026439710613886627]
	TIME [epoch: 11.5 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02367258975344235		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.02367258975344235 | validation: 0.027113798499401015]
	TIME [epoch: 11.5 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02026838881325171		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.02026838881325171 | validation: 0.019401122352497815]
	TIME [epoch: 11.5 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023515559132849542		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.023515559132849542 | validation: 0.03205218581252143]
	TIME [epoch: 11.5 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01790922746464229		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.01790922746464229 | validation: 0.03025085727222814]
	TIME [epoch: 11.5 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020378303075437303		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.020378303075437303 | validation: 0.026415487806041832]
	TIME [epoch: 11.5 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017901001651176862		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.017901001651176862 | validation: 0.028513541549952462]
	TIME [epoch: 11.5 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019273222456167752		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.019273222456167752 | validation: 0.02671127038826093]
	TIME [epoch: 11.5 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019852049643667588		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.019852049643667588 | validation: 0.027552085258295708]
	TIME [epoch: 11.5 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019891342357614968		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.019891342357614968 | validation: 0.026015999605648734]
	TIME [epoch: 11.5 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020422371120644676		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.020422371120644676 | validation: 0.027934693093700586]
	TIME [epoch: 11.5 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021600363060843248		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.021600363060843248 | validation: 0.023552707847433282]
	TIME [epoch: 11.5 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02054971103338303		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.02054971103338303 | validation: 0.031797781243810296]
	TIME [epoch: 11.5 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019969568292092437		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.019969568292092437 | validation: 0.026917658653176336]
	TIME [epoch: 11.5 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02166818745632857		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.02166818745632857 | validation: 0.023566068291962932]
	TIME [epoch: 11.5 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021104147585494462		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.021104147585494462 | validation: 0.02248761992770394]
	TIME [epoch: 11.5 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02027300911862806		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.02027300911862806 | validation: 0.02538994681486772]
	TIME [epoch: 11.5 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021205572335563236		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.021205572335563236 | validation: 0.02750755127538941]
	TIME [epoch: 11.5 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02425581419444863		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.02425581419444863 | validation: 0.024219766392804577]
	TIME [epoch: 11.5 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018363205811414228		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.018363205811414228 | validation: 0.023930198674368634]
	TIME [epoch: 11.5 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017191215227578317		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.017191215227578317 | validation: 0.0235642414699693]
	TIME [epoch: 11.5 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01936040099432896		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.01936040099432896 | validation: 0.026249626257150674]
	TIME [epoch: 11.5 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018306289244622593		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.018306289244622593 | validation: 0.03531781380305103]
	TIME [epoch: 11.5 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021976548795835243		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.021976548795835243 | validation: 0.028671040935625555]
	TIME [epoch: 11.5 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022122422798977852		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.022122422798977852 | validation: 0.03171115684277709]
	TIME [epoch: 11.5 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021083632144539788		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.021083632144539788 | validation: 0.02823919506475546]
	TIME [epoch: 11.5 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02007901029685338		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.02007901029685338 | validation: 0.021961554895358205]
	TIME [epoch: 11.5 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02237850140875326		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.02237850140875326 | validation: 0.027066971232841956]
	TIME [epoch: 11.5 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019608898927501256		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.019608898927501256 | validation: 0.030131305229148923]
	TIME [epoch: 11.5 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021792716936596745		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.021792716936596745 | validation: 0.020874198944225646]
	TIME [epoch: 11.5 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02068206056523736		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.02068206056523736 | validation: 0.0268556427795566]
	TIME [epoch: 11.5 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02386601790457025		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.02386601790457025 | validation: 0.030009706526334466]
	TIME [epoch: 11.5 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022402839322973312		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.022402839322973312 | validation: 0.02617482550673663]
	TIME [epoch: 11.5 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022068511945891545		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.022068511945891545 | validation: 0.028567708439710834]
	TIME [epoch: 11.5 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019303372562405687		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.019303372562405687 | validation: 0.025731890226358335]
	TIME [epoch: 11.5 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021855547935058138		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.021855547935058138 | validation: 0.020455639639129358]
	TIME [epoch: 11.5 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02202763736255325		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.02202763736255325 | validation: 0.023947701639721455]
	TIME [epoch: 11.5 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020263740643314647		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.020263740643314647 | validation: 0.024251840555647438]
	TIME [epoch: 11.5 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020871095135181657		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.020871095135181657 | validation: 0.024731269014760093]
	TIME [epoch: 11.5 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020695301607145677		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.020695301607145677 | validation: 0.0283326756218012]
	TIME [epoch: 11.5 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02058619024668853		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.02058619024668853 | validation: 0.016407929643942453]
	TIME [epoch: 11.5 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0210182194580449		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.0210182194580449 | validation: 0.03168187094276901]
	TIME [epoch: 11.5 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021005528269171757		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.021005528269171757 | validation: 0.02520574405070595]
	TIME [epoch: 11.5 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02318413778549234		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.02318413778549234 | validation: 0.030911630421016523]
	TIME [epoch: 11.5 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023668171346715935		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.023668171346715935 | validation: 0.02492635357882799]
	TIME [epoch: 11.5 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0202199550026158		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.0202199550026158 | validation: 0.025074199598979625]
	TIME [epoch: 11.5 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02086293446324993		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.02086293446324993 | validation: 0.02678853115330672]
	TIME [epoch: 11.5 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019779223701879862		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.019779223701879862 | validation: 0.030218746759698118]
	TIME [epoch: 11.5 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01922441030454087		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.01922441030454087 | validation: 0.02304689080488983]
	TIME [epoch: 11.5 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023187016699752077		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.023187016699752077 | validation: 0.024301128842996116]
	TIME [epoch: 11.5 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021339540341474436		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.021339540341474436 | validation: 0.027994460811977262]
	TIME [epoch: 11.5 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01925848521177239		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.01925848521177239 | validation: 0.022820697487690344]
	TIME [epoch: 11.5 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018803068363505773		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.018803068363505773 | validation: 0.02176207404525126]
	TIME [epoch: 11.5 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023749933277744266		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.023749933277744266 | validation: 0.02060412662575479]
	TIME [epoch: 11.5 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021435551514090573		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.021435551514090573 | validation: 0.02545304235673962]
	TIME [epoch: 11.5 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022856313937160685		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.022856313937160685 | validation: 0.02293528536253998]
	TIME [epoch: 11.5 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01736918721190526		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.01736918721190526 | validation: 0.0216724776066241]
	TIME [epoch: 11.5 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02001711741661072		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.02001711741661072 | validation: 0.024435869553663326]
	TIME [epoch: 11.5 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020352780929874213		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.020352780929874213 | validation: 0.031263098869098095]
	TIME [epoch: 11.5 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02310648984020764		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.02310648984020764 | validation: 0.02777579530100027]
	TIME [epoch: 11.5 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019357252208793304		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.019357252208793304 | validation: 0.025941127091625854]
	TIME [epoch: 11.5 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0236788132249388		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.0236788132249388 | validation: 0.016945759267645976]
	TIME [epoch: 11.5 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0231748744682694		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.0231748744682694 | validation: 0.03779850210096713]
	TIME [epoch: 11.5 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018728660433299592		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.018728660433299592 | validation: 0.02536966137845524]
	TIME [epoch: 11.5 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020524083871163515		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.020524083871163515 | validation: 0.025081969667205915]
	TIME [epoch: 11.5 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02032131768182886		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.02032131768182886 | validation: 0.024321449803262018]
	TIME [epoch: 11.5 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02288134647788057		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.02288134647788057 | validation: 0.022291358746937575]
	TIME [epoch: 11.5 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020832893857517756		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.020832893857517756 | validation: 0.030031399163543766]
	TIME [epoch: 11.5 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01948049477339194		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.01948049477339194 | validation: 0.02008638674416078]
	TIME [epoch: 11.5 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02020103927934684		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.02020103927934684 | validation: 0.026830108330375493]
	TIME [epoch: 11.5 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01852249648487953		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.01852249648487953 | validation: 0.02800499372419371]
	TIME [epoch: 11.5 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021769946149113366		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.021769946149113366 | validation: 0.03588711079205988]
	TIME [epoch: 11.5 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017599143755971644		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.017599143755971644 | validation: 0.026849124109141698]
	TIME [epoch: 11.5 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021257161378692283		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.021257161378692283 | validation: 0.028176113446883536]
	TIME [epoch: 11.5 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018152645205674327		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.018152645205674327 | validation: 0.020170986130153837]
	TIME [epoch: 11.5 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02274421674270717		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.02274421674270717 | validation: 0.02760226328520842]
	TIME [epoch: 11.5 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019147438490276607		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.019147438490276607 | validation: 0.02952006232683078]
	TIME [epoch: 11.5 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02214663826325732		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.02214663826325732 | validation: 0.03384486268026127]
	TIME [epoch: 11.5 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024650241504702044		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.024650241504702044 | validation: 0.02511541883478439]
	TIME [epoch: 11.5 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01976763837465932		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.01976763837465932 | validation: 0.024183503345660343]
	TIME [epoch: 11.5 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021392893898395535		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.021392893898395535 | validation: 0.02849756121430951]
	TIME [epoch: 11.5 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02051206931775431		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.02051206931775431 | validation: 0.032484946476564025]
	TIME [epoch: 11.5 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021093431833396323		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.021093431833396323 | validation: 0.030710351545545286]
	TIME [epoch: 11.5 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02151079087224395		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.02151079087224395 | validation: 0.02208875242701252]
	TIME [epoch: 11.5 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017337532947305768		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.017337532947305768 | validation: 0.024931526549002134]
	TIME [epoch: 11.5 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01984669230931165		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.01984669230931165 | validation: 0.027965942711921665]
	TIME [epoch: 11.5 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01955034876790475		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.01955034876790475 | validation: 0.028218776823638263]
	TIME [epoch: 11.5 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022909425009151954		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.022909425009151954 | validation: 0.025566237896640757]
	TIME [epoch: 11.5 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018545272683540198		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.018545272683540198 | validation: 0.038062917277955924]
	TIME [epoch: 11.5 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02050926055381657		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.02050926055381657 | validation: 0.029607594287325078]
	TIME [epoch: 11.5 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020794372677715264		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.020794372677715264 | validation: 0.023552523109306618]
	TIME [epoch: 11.5 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02019438914432791		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.02019438914432791 | validation: 0.024523871321808634]
	TIME [epoch: 11.5 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019902553406318413		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.019902553406318413 | validation: 0.033680167735564606]
	TIME [epoch: 11.5 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021370448408666996		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.021370448408666996 | validation: 0.023590212154587845]
	TIME [epoch: 11.5 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022614359099368153		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.022614359099368153 | validation: 0.026147828160424127]
	TIME [epoch: 11.5 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021916931378615636		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.021916931378615636 | validation: 0.03072145837924487]
	TIME [epoch: 11.5 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019665806669976454		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.019665806669976454 | validation: 0.03051786586987917]
	TIME [epoch: 11.5 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021389957237370423		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.021389957237370423 | validation: 0.032964836564483395]
	TIME [epoch: 11.5 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018281651034192194		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.018281651034192194 | validation: 0.0349581576150532]
	TIME [epoch: 11.5 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021470245036028533		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.021470245036028533 | validation: 0.020133329779330484]
	TIME [epoch: 11.5 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02214139852891591		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.02214139852891591 | validation: 0.023994394407178234]
	TIME [epoch: 11.5 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01927054588931032		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.01927054588931032 | validation: 0.025908741407593163]
	TIME [epoch: 11.5 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02239180004403145		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.02239180004403145 | validation: 0.024825724346473912]
	TIME [epoch: 11.5 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022257330347542494		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.022257330347542494 | validation: 0.029893916172350047]
	TIME [epoch: 11.5 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022399029625800697		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.022399029625800697 | validation: 0.031523831231509536]
	TIME [epoch: 11.5 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021167839439269694		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.021167839439269694 | validation: 0.028036113218911397]
	TIME [epoch: 11.5 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020230224552381926		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.020230224552381926 | validation: 0.02101829882748398]
	TIME [epoch: 11.5 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02040046716845284		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.02040046716845284 | validation: 0.02515916866175747]
	TIME [epoch: 11.5 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02028668345724885		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.02028668345724885 | validation: 0.033628189622399884]
	TIME [epoch: 11.5 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021263962514606386		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.021263962514606386 | validation: 0.023947877762952804]
	TIME [epoch: 11.5 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023960306651824043		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.023960306651824043 | validation: 0.029776111705068328]
	TIME [epoch: 11.5 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01908840276186244		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.01908840276186244 | validation: 0.03218677540059679]
	TIME [epoch: 11.5 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02205289529258283		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.02205289529258283 | validation: 0.022695656790036045]
	TIME [epoch: 11.5 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018369604055973984		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.018369604055973984 | validation: 0.024999937471546056]
	TIME [epoch: 11.5 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021586921075085804		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.021586921075085804 | validation: 0.025221812469097556]
	TIME [epoch: 11.5 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02154092867401194		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.02154092867401194 | validation: 0.021065980948965543]
	TIME [epoch: 11.5 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022033246759475565		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.022033246759475565 | validation: 0.030491407703506886]
	TIME [epoch: 11.5 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021709955663495675		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.021709955663495675 | validation: 0.03500588779824853]
	TIME [epoch: 11.5 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020285942662954356		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.020285942662954356 | validation: 0.024120568027911446]
	TIME [epoch: 11.5 sec]
EPOCH 1887/2000:
	Training over batches...
