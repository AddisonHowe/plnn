Args:
Namespace(name='model_tr_study6', outdir='out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4', training_data='data/transition_rate_studies/tr_study6/tr_study6_training/r4', validation_data='data/transition_rate_studies/tr_study6/tr_study6_validation/r4', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3072464822

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.531926771425333		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.531926771425333 | validation: 9.301659334735268]
	TIME [epoch: 112 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.523750128574285		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.523750128574285 | validation: 8.108879997893837]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.830714409555443		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.830714409555443 | validation: 7.337261679095194]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.989543481769023		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.989543481769023 | validation: 6.842059003321079]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.356661327816626		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.356661327816626 | validation: 6.202218627466969]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.746951026388837		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.746951026388837 | validation: 5.819452571281715]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.3506626599139775		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.3506626599139775 | validation: 5.570028049030148]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.867338777564825		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.867338777564825 | validation: 4.730973157351748]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.73314220391747		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.73314220391747 | validation: 4.997938637083788]
	TIME [epoch: 24.8 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.35453014665693		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.35453014665693 | validation: 4.012546550071934]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.356814365706914		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.356814365706914 | validation: 3.9155570339948214]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.640986738829839		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.640986738829839 | validation: 3.507955900614718]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3566430208611395		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3566430208611395 | validation: 3.3845512229432915]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2721296186337865		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2721296186337865 | validation: 6.799672988645316]
	TIME [epoch: 24.7 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.804352377454602		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.804352377454602 | validation: 3.2526067109379193]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.168051223220529		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.168051223220529 | validation: 4.699839039198115]
	TIME [epoch: 24.8 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4941714554580265		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4941714554580265 | validation: 2.9954644371545895]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1573768247321397		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1573768247321397 | validation: 5.355393807678166]
	TIME [epoch: 24.8 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.0969886974393095		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.0969886974393095 | validation: 5.06226713334786]
	TIME [epoch: 24.8 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9144032242434927		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9144032242434927 | validation: 3.1425294923665246]
	TIME [epoch: 24.7 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2848129648441002		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2848129648441002 | validation: 3.33993540900531]
	TIME [epoch: 24.8 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0354510491550606		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0354510491550606 | validation: 2.9860595306268496]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7848936230904724		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7848936230904724 | validation: 2.6883211553457897]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.348592759052801		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.348592759052801 | validation: 7.568058993439284]
	TIME [epoch: 24.8 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.4539182986753545		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.4539182986753545 | validation: 4.711417138688651]
	TIME [epoch: 24.8 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.193531719813728		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.193531719813728 | validation: 4.066256823439714]
	TIME [epoch: 24.7 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.60177877856124		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.60177877856124 | validation: 3.4854553412787426]
	TIME [epoch: 24.8 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2870863404337864		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2870863404337864 | validation: 3.1598369173967797]
	TIME [epoch: 24.8 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.137978727861031		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.137978727861031 | validation: 3.8198313910944877]
	TIME [epoch: 24.7 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.682347533799537		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.682347533799537 | validation: 3.8683460481016216]
	TIME [epoch: 24.8 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.599603223064594		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.599603223064594 | validation: 3.0534049440518247]
	TIME [epoch: 24.8 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2952495161249167		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2952495161249167 | validation: 5.675919819926856]
	TIME [epoch: 24.7 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.05796377265866		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.05796377265866 | validation: 3.2388350034127447]
	TIME [epoch: 24.8 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.374843517000829		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.374843517000829 | validation: 4.394637965668515]
	TIME [epoch: 24.8 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5959890342101675		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5959890342101675 | validation: 3.6266449199571937]
	TIME [epoch: 24.8 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.081940400857871		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.081940400857871 | validation: 3.091620360259637]
	TIME [epoch: 24.8 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0625205204723316		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0625205204723316 | validation: 2.783197126593243]
	TIME [epoch: 24.8 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3178953185028446		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3178953185028446 | validation: 6.7090036225488126]
	TIME [epoch: 24.7 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.870971358819251		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.870971358819251 | validation: 3.5398005915614386]
	TIME [epoch: 24.8 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.22232016163603		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.22232016163603 | validation: 2.8811020459673586]
	TIME [epoch: 24.8 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.545361613513943		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.545361613513943 | validation: 3.048368765677194]
	TIME [epoch: 24.7 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.960956979529891		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.960956979529891 | validation: 7.945825148424305]
	TIME [epoch: 24.8 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.582117178518823		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.582117178518823 | validation: 4.087751639412414]
	TIME [epoch: 24.8 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5370789866950356		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5370789866950356 | validation: 3.1256575989583575]
	TIME [epoch: 24.7 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.105605860330817		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.105605860330817 | validation: 3.116712367921032]
	TIME [epoch: 24.8 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1450392217057535		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1450392217057535 | validation: 3.706296762799847]
	TIME [epoch: 24.8 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.120978624256629		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.120978624256629 | validation: 2.91196512381238]
	TIME [epoch: 24.7 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1970164602647073		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1970164602647073 | validation: 3.21157759744179]
	TIME [epoch: 24.8 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.988705621266325		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.988705621266325 | validation: 2.97820552386239]
	TIME [epoch: 24.8 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.026767858615022		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.026767858615022 | validation: 2.6701023688476555]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9031309000898804		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 2.9031309000898804 | validation: 8.097957276482855]
	TIME [epoch: 24.8 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.553169793118986		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 6.553169793118986 | validation: 4.721254873703316]
	TIME [epoch: 24.8 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.912287817650302		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 3.912287817650302 | validation: 3.1059135335224655]
	TIME [epoch: 24.7 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9129732187555066		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 2.9129732187555066 | validation: 3.383206257174896]
	TIME [epoch: 24.8 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9901617044789175		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 2.9901617044789175 | validation: 2.998784428132112]
	TIME [epoch: 24.8 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9637774151233534		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 2.9637774151233534 | validation: 2.624652091322427]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.849341545367391		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 2.849341545367391 | validation: 2.669826860957096]
	TIME [epoch: 24.8 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5228769273687033		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 3.5228769273687033 | validation: 3.5548485757702486]
	TIME [epoch: 24.8 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.483610642765659		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 3.483610642765659 | validation: 3.3366069559531177]
	TIME [epoch: 24.7 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0411451147051554		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 3.0411451147051554 | validation: 3.4284044062597445]
	TIME [epoch: 24.8 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.790406564502064		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 2.790406564502064 | validation: 2.8445939349804976]
	TIME [epoch: 24.8 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.958405690703346		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 2.958405690703346 | validation: 2.7452843331167402]
	TIME [epoch: 24.8 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.944739255888235		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 2.944739255888235 | validation: 3.0367797721030487]
	TIME [epoch: 24.8 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.60185707312213		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 2.60185707312213 | validation: 2.388025777316499]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_64.pth
	Model improved!!!
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.431788602406529		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 2.431788602406529 | validation: 2.275005529306529]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7924300141380836		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 2.7924300141380836 | validation: 2.7752616024634906]
	TIME [epoch: 24.8 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7630205983310945		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 2.7630205983310945 | validation: 2.490766835705357]
	TIME [epoch: 24.8 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.382798426246763		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 2.382798426246763 | validation: 2.458454082020456]
	TIME [epoch: 24.8 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.450196901235425		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 2.450196901235425 | validation: 2.577194546068749]
	TIME [epoch: 24.8 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7127047555448494		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 2.7127047555448494 | validation: 4.332665515069324]
	TIME [epoch: 24.8 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6298510634088013		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 3.6298510634088013 | validation: 2.4777874016316654]
	TIME [epoch: 24.8 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4307340414200587		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 2.4307340414200587 | validation: 2.2684256206578013]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.980786334832564		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 2.980786334832564 | validation: 3.2686842309625046]
	TIME [epoch: 24.8 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.746766551017837		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 2.746766551017837 | validation: 2.5256857325788933]
	TIME [epoch: 24.8 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1997185572057885		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 2.1997185572057885 | validation: 2.3017627865636365]
	TIME [epoch: 24.8 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.12581206675854		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 2.12581206675854 | validation: 2.706452987349778]
	TIME [epoch: 24.8 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.609525146603511		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 2.609525146603511 | validation: 2.067494395390903]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.194742013387049		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 2.194742013387049 | validation: 2.243608166205765]
	TIME [epoch: 24.8 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1394212047151897		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 2.1394212047151897 | validation: 2.0287936387706136]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.098356450231999		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 3.098356450231999 | validation: 2.6681883946503446]
	TIME [epoch: 24.7 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2074708919934496		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 2.2074708919934496 | validation: 2.370889872355938]
	TIME [epoch: 24.8 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.138014216642736		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 2.138014216642736 | validation: 1.8576490325861448]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_82.pth
	Model improved!!!
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9124377282003584		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 1.9124377282003584 | validation: 2.1744666512388346]
	TIME [epoch: 24.7 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9257389293461422		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 1.9257389293461422 | validation: 2.4642672628164566]
	TIME [epoch: 24.8 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9886872733439132		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 1.9886872733439132 | validation: 2.7297157840756645]
	TIME [epoch: 24.8 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.250655275779771		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 2.250655275779771 | validation: 1.721916337136799]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_86.pth
	Model improved!!!
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6919262085820577		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 1.6919262085820577 | validation: 1.8828242063020804]
	TIME [epoch: 24.8 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9439917413522094		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 1.9439917413522094 | validation: 1.8828158254359684]
	TIME [epoch: 24.8 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7675721908284694		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 1.7675721908284694 | validation: 1.5961952770596526]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_89.pth
	Model improved!!!
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5832480376600435		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 1.5832480376600435 | validation: 1.5639603615236999]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_90.pth
	Model improved!!!
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5572428650585388		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 1.5572428650585388 | validation: 1.695220813806406]
	TIME [epoch: 24.8 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9365970249164572		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 1.9365970249164572 | validation: 1.5707307555336223]
	TIME [epoch: 24.8 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5731586623465876		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 1.5731586623465876 | validation: 1.7123429241219321]
	TIME [epoch: 24.8 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6707174308764507		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 1.6707174308764507 | validation: 1.6461868859388198]
	TIME [epoch: 24.8 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5557101341034247		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 1.5557101341034247 | validation: 2.7117874874216574]
	TIME [epoch: 24.8 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9991278241190475		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 1.9991278241190475 | validation: 1.69548184715005]
	TIME [epoch: 24.9 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3757876246748704		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 1.3757876246748704 | validation: 1.497077555765216]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3504353945427454		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 1.3504353945427454 | validation: 1.1767743785379314]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_98.pth
	Model improved!!!
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.345053236561429		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 1.345053236561429 | validation: 1.2898354507115064]
	TIME [epoch: 24.8 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3553765985386024		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 1.3553765985386024 | validation: 1.6609191194328654]
	TIME [epoch: 24.8 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6628838398401409		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 1.6628838398401409 | validation: 1.5236021895717136]
	TIME [epoch: 24.8 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2109622059720566		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 1.2109622059720566 | validation: 1.0048283882972242]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_102.pth
	Model improved!!!
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1371220724999787		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 1.1371220724999787 | validation: 1.0288278403136477]
	TIME [epoch: 24.8 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.352630505942999		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 1.352630505942999 | validation: 0.917765295578113]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_104.pth
	Model improved!!!
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2990762768571031		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 1.2990762768571031 | validation: 1.5097750349137926]
	TIME [epoch: 24.8 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3622751715830792		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 1.3622751715830792 | validation: 1.013146156131465]
	TIME [epoch: 24.9 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.05259265149215		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 1.05259265149215 | validation: 1.2965780967194538]
	TIME [epoch: 24.7 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.285804172125198		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 1.285804172125198 | validation: 1.8283660595067812]
	TIME [epoch: 24.8 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2978013537025321		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 1.2978013537025321 | validation: 1.0824281745797004]
	TIME [epoch: 24.8 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9931907129037559		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.9931907129037559 | validation: 0.800082960641484]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_110.pth
	Model improved!!!
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8475677903384023		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 0.8475677903384023 | validation: 0.8522888695597741]
	TIME [epoch: 24.8 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2783902308720925		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 1.2783902308720925 | validation: 1.5549419492302314]
	TIME [epoch: 24.8 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4778537029071206		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 1.4778537029071206 | validation: 0.7959782142392792]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_113.pth
	Model improved!!!
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0159551263307434		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 1.0159551263307434 | validation: 1.0404521116538314]
	TIME [epoch: 24.8 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0316941074065156		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 1.0316941074065156 | validation: 0.7988436891398337]
	TIME [epoch: 24.8 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3238710101085318		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 1.3238710101085318 | validation: 1.8294044241956056]
	TIME [epoch: 24.7 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1572914197349955		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 1.1572914197349955 | validation: 0.8845179463876971]
	TIME [epoch: 24.8 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0785773766013627		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 1.0785773766013627 | validation: 0.7963703157952816]
	TIME [epoch: 24.8 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8986628813283684		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 0.8986628813283684 | validation: 0.72385166262175]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_119.pth
	Model improved!!!
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9122550102806343		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.9122550102806343 | validation: 0.7074973272613946]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_120.pth
	Model improved!!!
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7541655684315032		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 0.7541655684315032 | validation: 1.0034114382408175]
	TIME [epoch: 24.8 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8096306431962099		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 0.8096306431962099 | validation: 0.8150819297845726]
	TIME [epoch: 24.7 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7981475766298132		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 0.7981475766298132 | validation: 0.7384563705407805]
	TIME [epoch: 24.8 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7898026344585172		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 0.7898026344585172 | validation: 1.0267260472732285]
	TIME [epoch: 24.8 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0482976064255523		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 1.0482976064255523 | validation: 1.2008334494551893]
	TIME [epoch: 24.7 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0662067820163723		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 1.0662067820163723 | validation: 0.9549563672247661]
	TIME [epoch: 24.8 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0785276239091792		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 1.0785276239091792 | validation: 1.2898915261659278]
	TIME [epoch: 24.8 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3166983110148514		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 1.3166983110148514 | validation: 1.2842933622560082]
	TIME [epoch: 24.7 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9892603881248035		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 0.9892603881248035 | validation: 1.325935165418179]
	TIME [epoch: 24.8 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0304509700440245		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 1.0304509700440245 | validation: 0.6962113551646099]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_130.pth
	Model improved!!!
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8051582561420249		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 0.8051582561420249 | validation: 0.7349581294921811]
	TIME [epoch: 24.7 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1636409882137222		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 1.1636409882137222 | validation: 0.8939907985066906]
	TIME [epoch: 24.8 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0002581805312012		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 1.0002581805312012 | validation: 2.04950323205534]
	TIME [epoch: 24.8 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5001368567463516		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 1.5001368567463516 | validation: 1.3342387282892723]
	TIME [epoch: 24.7 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1580776240317303		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 1.1580776240317303 | validation: 0.876327421956695]
	TIME [epoch: 24.8 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9163390381645784		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.9163390381645784 | validation: 0.9164172849214322]
	TIME [epoch: 24.8 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0808641911687085		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 1.0808641911687085 | validation: 1.2281708479800042]
	TIME [epoch: 24.7 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9658695542418468		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 0.9658695542418468 | validation: 0.8222091924147447]
	TIME [epoch: 24.8 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8600243489042992		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 0.8600243489042992 | validation: 1.3803320007058906]
	TIME [epoch: 24.7 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9843546542626109		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.9843546542626109 | validation: 1.0865772000443825]
	TIME [epoch: 24.7 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2344742046766346		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 1.2344742046766346 | validation: 0.7233579257927921]
	TIME [epoch: 24.8 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8447678888583651		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.8447678888583651 | validation: 0.8775641308147221]
	TIME [epoch: 24.7 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9683650855412846		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.9683650855412846 | validation: 0.8421573990494179]
	TIME [epoch: 24.7 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9137559586081307		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 0.9137559586081307 | validation: 3.1947861666471704]
	TIME [epoch: 24.8 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.868100901534453		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 1.868100901534453 | validation: 1.069618198684868]
	TIME [epoch: 24.7 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9365118531762543		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.9365118531762543 | validation: 0.69696880282722]
	TIME [epoch: 24.7 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7993845556718806		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.7993845556718806 | validation: 0.8908987099290281]
	TIME [epoch: 24.8 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9511356688181105		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 0.9511356688181105 | validation: 0.9604244572315118]
	TIME [epoch: 24.7 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9352413628776047		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.9352413628776047 | validation: 0.981986424513761]
	TIME [epoch: 24.7 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8388236291369952		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.8388236291369952 | validation: 0.7275311485389641]
	TIME [epoch: 24.8 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9176070617857687		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.9176070617857687 | validation: 1.519514632442452]
	TIME [epoch: 24.7 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1137653515038195		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 1.1137653515038195 | validation: 0.7664946474111204]
	TIME [epoch: 24.7 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7393767988430587		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 0.7393767988430587 | validation: 0.7313185880210367]
	TIME [epoch: 24.8 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8548689297090477		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.8548689297090477 | validation: 1.0065704761085026]
	TIME [epoch: 24.7 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0409919822059814		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 1.0409919822059814 | validation: 0.9966787283816365]
	TIME [epoch: 24.7 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9533926766745834		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 0.9533926766745834 | validation: 0.743303527095438]
	TIME [epoch: 24.8 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8938297050116222		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 0.8938297050116222 | validation: 0.7411188240085912]
	TIME [epoch: 24.7 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7888815313336724		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 0.7888815313336724 | validation: 0.8636606555063869]
	TIME [epoch: 24.7 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1131738580105248		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 1.1131738580105248 | validation: 0.9907976987674304]
	TIME [epoch: 24.8 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.949145628759485		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.949145628759485 | validation: 0.9049154189060724]
	TIME [epoch: 24.7 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.447824709335809		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 1.447824709335809 | validation: 1.5288157010691623]
	TIME [epoch: 24.8 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3371084023318938		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 1.3371084023318938 | validation: 0.9091957506957343]
	TIME [epoch: 24.8 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9665052402992089		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.9665052402992089 | validation: 0.9649403023765304]
	TIME [epoch: 24.7 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9553349865630583		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.9553349865630583 | validation: 0.9039362269172426]
	TIME [epoch: 24.7 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.810753028283685		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 2.810753028283685 | validation: 1.2572213441876998]
	TIME [epoch: 24.8 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3452412499912327		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 1.3452412499912327 | validation: 2.1127478349405733]
	TIME [epoch: 24.7 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6409592484870543		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 1.6409592484870543 | validation: 0.9004820413837206]
	TIME [epoch: 24.7 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7757841651818729		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.7757841651818729 | validation: 0.7409721583837976]
	TIME [epoch: 24.8 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.734924264756373		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.734924264756373 | validation: 0.7371620903123739]
	TIME [epoch: 24.7 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6762442815518688		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.6762442815518688 | validation: 0.5855974278127957]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_170.pth
	Model improved!!!
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5114112569194253		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 1.5114112569194253 | validation: 1.63688169279881]
	TIME [epoch: 24.8 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2385488563900182		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 1.2385488563900182 | validation: 0.9857867948539547]
	TIME [epoch: 24.8 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0074810398939185		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 1.0074810398939185 | validation: 0.7250821677242877]
	TIME [epoch: 24.8 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7608220932160534		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.7608220932160534 | validation: 0.7408932714075783]
	TIME [epoch: 24.8 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8440875895454983		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.8440875895454983 | validation: 0.6984945373091435]
	TIME [epoch: 24.8 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8551009948010648		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 0.8551009948010648 | validation: 1.0535892402652436]
	TIME [epoch: 24.8 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1828565076542767		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 1.1828565076542767 | validation: 1.1108178826558806]
	TIME [epoch: 24.8 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5009454586290487		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 2.5009454586290487 | validation: 1.5981935878508386]
	TIME [epoch: 24.7 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1819113149897853		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 1.1819113149897853 | validation: 0.780070268141135]
	TIME [epoch: 24.8 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7413562777361313		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.7413562777361313 | validation: 0.7702817233813201]
	TIME [epoch: 24.8 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7911444171956148		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.7911444171956148 | validation: 1.1394870510873714]
	TIME [epoch: 24.7 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1194349187091541		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 1.1194349187091541 | validation: 1.4442429836957833]
	TIME [epoch: 24.8 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9840399373373667		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.9840399373373667 | validation: 0.9059032765284155]
	TIME [epoch: 24.8 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9833946046411565		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.9833946046411565 | validation: 0.9181150515432797]
	TIME [epoch: 24.7 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8619461433598102		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.8619461433598102 | validation: 0.7467603814462834]
	TIME [epoch: 24.8 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7638246086555038		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.7638246086555038 | validation: 0.8152225181658974]
	TIME [epoch: 24.8 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9060612587184542		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.9060612587184542 | validation: 0.7445696795866646]
	TIME [epoch: 24.7 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7355804161899611		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.7355804161899611 | validation: 0.9204840284079796]
	TIME [epoch: 24.8 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2378016527217717		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 1.2378016527217717 | validation: 0.8325170110476718]
	TIME [epoch: 24.8 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8412907862035375		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.8412907862035375 | validation: 0.7607851149735402]
	TIME [epoch: 24.7 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8035250724337301		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.8035250724337301 | validation: 0.7022928372911318]
	TIME [epoch: 24.8 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3295424773198392		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 1.3295424773198392 | validation: 0.7628688651817913]
	TIME [epoch: 24.8 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8824905814427113		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.8824905814427113 | validation: 1.2354426079436607]
	TIME [epoch: 24.8 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3788437853906972		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 1.3788437853906972 | validation: 0.7277511114928612]
	TIME [epoch: 24.8 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6980525707871902		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.6980525707871902 | validation: 0.8262404690533727]
	TIME [epoch: 24.8 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7572315854458049		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.7572315854458049 | validation: 0.7976564648106654]
	TIME [epoch: 24.7 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7854285249050983		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.7854285249050983 | validation: 0.8225424562783884]
	TIME [epoch: 24.8 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.766515003887128		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.766515003887128 | validation: 0.7713751203887311]
	TIME [epoch: 24.8 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7518222253737906		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.7518222253737906 | validation: 0.8265138852726845]
	TIME [epoch: 24.7 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7191777673918768		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.7191777673918768 | validation: 0.8723202056953587]
	TIME [epoch: 24.8 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0172271312734344		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 1.0172271312734344 | validation: 0.9427316540501335]
	TIME [epoch: 24.8 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9336446210153747		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.9336446210153747 | validation: 1.0392352035391397]
	TIME [epoch: 24.7 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0403887784634822		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 1.0403887784634822 | validation: 1.1002012047665666]
	TIME [epoch: 24.8 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.849238770558775		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.849238770558775 | validation: 0.6626737283619091]
	TIME [epoch: 24.8 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6747571530749755		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.6747571530749755 | validation: 0.7727320788526302]
	TIME [epoch: 24.7 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7127665858247147		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.7127665858247147 | validation: 0.7228127845121862]
	TIME [epoch: 24.8 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5956340495776062		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 1.5956340495776062 | validation: 1.6143258084041157]
	TIME [epoch: 24.8 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1686555658849298		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 1.1686555658849298 | validation: 0.860959460629876]
	TIME [epoch: 24.7 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9089878135675334		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.9089878135675334 | validation: 0.8492991292651025]
	TIME [epoch: 24.8 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8289020966132208		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.8289020966132208 | validation: 0.7236588819397036]
	TIME [epoch: 24.8 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9103104974441232		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.9103104974441232 | validation: 1.119596773663868]
	TIME [epoch: 24.7 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8821639367318018		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.8821639367318018 | validation: 0.743631579847131]
	TIME [epoch: 24.8 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7329469323029435		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.7329469323029435 | validation: 0.649770968494767]
	TIME [epoch: 24.8 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6679749060166628		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.6679749060166628 | validation: 0.7748808320855451]
	TIME [epoch: 24.7 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.708770035687453		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.708770035687453 | validation: 0.6613448524386011]
	TIME [epoch: 24.8 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7070534479042183		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.7070534479042183 | validation: 0.914613097055992]
	TIME [epoch: 24.8 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7461210856272383		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.7461210856272383 | validation: 0.7136034881260185]
	TIME [epoch: 24.7 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7387930447162945		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.7387930447162945 | validation: 0.7150475783746445]
	TIME [epoch: 24.8 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6641290135348326		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.6641290135348326 | validation: 0.712244764084362]
	TIME [epoch: 24.8 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7125349325656916		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.7125349325656916 | validation: 0.7090875540146188]
	TIME [epoch: 24.7 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7109402878126143		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.7109402878126143 | validation: 0.7312028931191265]
	TIME [epoch: 24.8 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7414402576647219		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.7414402576647219 | validation: 0.7934138166961434]
	TIME [epoch: 24.7 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2392653511073661		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 1.2392653511073661 | validation: 0.9424772679983372]
	TIME [epoch: 24.7 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7585434465939824		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.7585434465939824 | validation: 0.7342070777965617]
	TIME [epoch: 24.8 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8900767643338894		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.8900767643338894 | validation: 1.025664425148153]
	TIME [epoch: 24.8 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8340033042113514		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.8340033042113514 | validation: 2.1515317510903795]
	TIME [epoch: 24.7 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.55523583146366		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 1.55523583146366 | validation: 0.7140475048255778]
	TIME [epoch: 24.8 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.743572882656914		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.743572882656914 | validation: 0.8180048857691626]
	TIME [epoch: 24.8 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8319354941053148		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.8319354941053148 | validation: 0.8524933604103264]
	TIME [epoch: 24.8 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8588427604643447		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.8588427604643447 | validation: 0.8618338145267299]
	TIME [epoch: 24.9 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9694242779376223		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.9694242779376223 | validation: 0.947181515530026]
	TIME [epoch: 24.8 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.041071473005133		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 1.041071473005133 | validation: 0.9212946656596483]
	TIME [epoch: 24.8 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9420697405898071		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.9420697405898071 | validation: 0.893279885315815]
	TIME [epoch: 24.8 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8615015054456788		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.8615015054456788 | validation: 0.8175943612630624]
	TIME [epoch: 24.8 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8497905420273774		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.8497905420273774 | validation: 0.8752620186641826]
	TIME [epoch: 24.8 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9631512874909776		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.9631512874909776 | validation: 0.9360171720126249]
	TIME [epoch: 24.8 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.095225718315352		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 1.095225718315352 | validation: 0.9248830184117821]
	TIME [epoch: 24.8 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8860878036615755		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.8860878036615755 | validation: 0.8409537024698712]
	TIME [epoch: 24.8 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8498790783487153		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.8498790783487153 | validation: 0.8697461806786813]
	TIME [epoch: 24.8 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9307958787306856		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.9307958787306856 | validation: 0.8864835949928815]
	TIME [epoch: 24.8 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8613399662645527		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.8613399662645527 | validation: 1.9920270685074266]
	TIME [epoch: 24.8 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7811991105294205		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 1.7811991105294205 | validation: 1.2975207486225915]
	TIME [epoch: 24.8 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0711460846078857		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 1.0711460846078857 | validation: 0.9511746353306164]
	TIME [epoch: 24.8 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.756871888073023		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.756871888073023 | validation: 0.7619205999334437]
	TIME [epoch: 24.8 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6483724845465009		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.6483724845465009 | validation: 0.6256682304229145]
	TIME [epoch: 24.8 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8274283827848907		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.8274283827848907 | validation: 0.7671282801476446]
	TIME [epoch: 24.8 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6737265693787776		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.6737265693787776 | validation: 0.8698897589669596]
	TIME [epoch: 24.7 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.834448146473054		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 1.834448146473054 | validation: 0.9690142691335522]
	TIME [epoch: 24.8 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.777525674220551		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.777525674220551 | validation: 0.7642098116347196]
	TIME [epoch: 24.8 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6881982645981575		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.6881982645981575 | validation: 0.6643427240053441]
	TIME [epoch: 24.8 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7775419213362796		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.7775419213362796 | validation: 1.0483979699784798]
	TIME [epoch: 24.8 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8200938163397804		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.8200938163397804 | validation: 1.0336117693217284]
	TIME [epoch: 24.7 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8898035587293438		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.8898035587293438 | validation: 0.7015320158335631]
	TIME [epoch: 24.8 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6404192468648187		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.6404192468648187 | validation: 0.674028969529488]
	TIME [epoch: 24.8 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.686549078570007		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.686549078570007 | validation: 0.6607961473998517]
	TIME [epoch: 24.8 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7236466622504525		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.7236466622504525 | validation: 0.6803371440808911]
	TIME [epoch: 24.8 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7050098817437543		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.7050098817437543 | validation: 0.7178250198750543]
	TIME [epoch: 24.8 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8217636745067132		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.8217636745067132 | validation: 1.0530744227400968]
	TIME [epoch: 24.8 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9498754045005853		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.9498754045005853 | validation: 0.6714021226176674]
	TIME [epoch: 24.8 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6895439091576752		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.6895439091576752 | validation: 0.6738102804999074]
	TIME [epoch: 24.8 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7031298038172532		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.7031298038172532 | validation: 0.8695274636107798]
	TIME [epoch: 24.8 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7054927461646103		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.7054927461646103 | validation: 0.6396116728552551]
	TIME [epoch: 24.8 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6357428661652683		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.6357428661652683 | validation: 0.6032943917641957]
	TIME [epoch: 24.8 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6667666112052595		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.6667666112052595 | validation: 0.6383375774858382]
	TIME [epoch: 24.8 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6303224415683729		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.6303224415683729 | validation: 0.7985187622148087]
	TIME [epoch: 24.8 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8262281888892283		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.8262281888892283 | validation: 0.6670719215923694]
	TIME [epoch: 24.8 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.10273663022515		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 1.10273663022515 | validation: 1.0728846869126107]
	TIME [epoch: 24.8 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.983115931648563		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.983115931648563 | validation: 0.6108387481772054]
	TIME [epoch: 24.8 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7361209371283997		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.7361209371283997 | validation: 0.6171281608913949]
	TIME [epoch: 24.8 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6847327754392418		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.6847327754392418 | validation: 0.780175844360735]
	TIME [epoch: 24.8 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8889738190247849		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.8889738190247849 | validation: 1.1820653445510896]
	TIME [epoch: 24.8 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8970226256124859		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.8970226256124859 | validation: 0.5620141067644007]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_272.pth
	Model improved!!!
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6563313368837478		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.6563313368837478 | validation: 0.8472708324999492]
	TIME [epoch: 24.8 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7239961397908232		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.7239961397908232 | validation: 0.6902478071579822]
	TIME [epoch: 24.8 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2425212233242946		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 1.2425212233242946 | validation: 1.0859981108123542]
	TIME [epoch: 24.8 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8661001713849793		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.8661001713849793 | validation: 0.6358474399331746]
	TIME [epoch: 24.8 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9942643584769715		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.9942643584769715 | validation: 0.9102330837729793]
	TIME [epoch: 24.8 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7823181555927556		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.7823181555927556 | validation: 0.5845077143758163]
	TIME [epoch: 24.8 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5796240408273846		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.5796240408273846 | validation: 0.6747019372226063]
	TIME [epoch: 24.7 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7688512034190774		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.7688512034190774 | validation: 0.9570528652974523]
	TIME [epoch: 24.8 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7696282163307784		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.7696282163307784 | validation: 1.3173187853738808]
	TIME [epoch: 24.8 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1479536219916262		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 1.1479536219916262 | validation: 0.741636440424996]
	TIME [epoch: 24.7 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6696263523037056		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.6696263523037056 | validation: 0.5541356542999971]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_283.pth
	Model improved!!!
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7699572752071754		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.7699572752071754 | validation: 0.8945984566600055]
	TIME [epoch: 24.8 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8627490061630119		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.8627490061630119 | validation: 0.6704649155972754]
	TIME [epoch: 24.7 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.610915028013118		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.610915028013118 | validation: 1.2762072000964877]
	TIME [epoch: 24.7 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3725402707073586		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 2.3725402707073586 | validation: 2.6693908352609186]
	TIME [epoch: 24.8 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9390276318426247		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 2.9390276318426247 | validation: 3.0585229363355975]
	TIME [epoch: 24.7 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.043126534577603		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 3.043126534577603 | validation: 3.1384871985052736]
	TIME [epoch: 24.8 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.105214859923945		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 3.105214859923945 | validation: 3.100346071149557]
	TIME [epoch: 24.8 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0638805012169357		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 3.0638805012169357 | validation: 3.0698206507525323]
	TIME [epoch: 24.7 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0222578887198575		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 3.0222578887198575 | validation: 3.0371203334433523]
	TIME [epoch: 24.8 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0200818225265325		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 3.0200818225265325 | validation: 3.0201276464180826]
	TIME [epoch: 24.8 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9911204999465166		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 2.9911204999465166 | validation: 3.08699025983831]
	TIME [epoch: 24.7 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9097480059390994		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 2.9097480059390994 | validation: 2.7596207638904597]
	TIME [epoch: 24.8 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7763413503233862		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 1.7763413503233862 | validation: 0.9009242345681017]
	TIME [epoch: 24.8 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7962863619631946		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.7962863619631946 | validation: 0.7041640868285817]
	TIME [epoch: 24.8 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7131811047585341		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.7131811047585341 | validation: 0.7468941296363326]
	TIME [epoch: 24.8 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8953379384647482		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.8953379384647482 | validation: 0.6089397792498794]
	TIME [epoch: 24.8 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.694309362924946		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.694309362924946 | validation: 0.9781371800750932]
	TIME [epoch: 24.7 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7691089710619606		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.7691089710619606 | validation: 0.6859389167578125]
	TIME [epoch: 24.8 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7759396958139566		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.7759396958139566 | validation: 0.68241002600823]
	TIME [epoch: 24.8 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6957655954640408		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.6957655954640408 | validation: 0.7106322288269041]
	TIME [epoch: 24.7 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6766161611502752		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.6766161611502752 | validation: 0.4800471144041925]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_304.pth
	Model improved!!!
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5884886258399589		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.5884886258399589 | validation: 0.6264099670724221]
	TIME [epoch: 24.7 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8526771388585139		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.8526771388585139 | validation: 1.645173960548764]
	TIME [epoch: 24.7 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2879949067108507		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 1.2879949067108507 | validation: 0.7224066398766184]
	TIME [epoch: 24.7 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.815338312709895		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.815338312709895 | validation: 0.7284509566358021]
	TIME [epoch: 24.8 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7826739145444819		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.7826739145444819 | validation: 0.6726207199016873]
	TIME [epoch: 24.7 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6564484828808128		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.6564484828808128 | validation: 0.7374317944033666]
	TIME [epoch: 24.8 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6865368890286181		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.6865368890286181 | validation: 0.5626648565034756]
	TIME [epoch: 24.8 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5813151439866435		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.5813151439866435 | validation: 0.49256997740341407]
	TIME [epoch: 24.7 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.637162153308677		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.637162153308677 | validation: 0.6484250118130231]
	TIME [epoch: 24.8 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5810977057416153		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.5810977057416153 | validation: 0.4780344884643896]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_314.pth
	Model improved!!!
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5330858178043183		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.5330858178043183 | validation: 0.4812951856033786]
	TIME [epoch: 24.8 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5263709571486538		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.5263709571486538 | validation: 0.5633712456270992]
	TIME [epoch: 24.8 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6207132582652676		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.6207132582652676 | validation: 0.5408881716185779]
	TIME [epoch: 24.8 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3667860546315533		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 1.3667860546315533 | validation: 1.9849521379120996]
	TIME [epoch: 24.7 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3696995216556842		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 1.3696995216556842 | validation: 1.022622485100813]
	TIME [epoch: 24.8 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8288278288032609		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.8288278288032609 | validation: 0.6267617479803037]
	TIME [epoch: 24.8 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6429797580148946		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.6429797580148946 | validation: 0.6025979015485706]
	TIME [epoch: 24.7 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5825562004242681		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.5825562004242681 | validation: 0.5611865840305826]
	TIME [epoch: 24.8 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6053623703113226		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.6053623703113226 | validation: 0.6427756751621353]
	TIME [epoch: 24.7 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6498111004191581		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.6498111004191581 | validation: 0.7276093982857653]
	TIME [epoch: 24.8 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8454052443145379		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.8454052443145379 | validation: 0.6461960698998667]
	TIME [epoch: 24.8 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6916366143421995		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.6916366143421995 | validation: 1.126854472532911]
	TIME [epoch: 24.8 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1174865683997655		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 1.1174865683997655 | validation: 0.7474543030622357]
	TIME [epoch: 24.8 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6750759845282419		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.6750759845282419 | validation: 0.5952670591398311]
	TIME [epoch: 24.8 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6228517527659388		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.6228517527659388 | validation: 0.6136008209868575]
	TIME [epoch: 24.8 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6800094343429226		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.6800094343429226 | validation: 0.6190418026777269]
	TIME [epoch: 24.8 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5950693035394778		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.5950693035394778 | validation: 0.6639291486683894]
	TIME [epoch: 24.8 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8676001787431655		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.8676001787431655 | validation: 0.8179455847971522]
	TIME [epoch: 24.8 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7124602291926075		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.7124602291926075 | validation: 0.7971760453032184]
	TIME [epoch: 24.8 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.833572492247515		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.833572492247515 | validation: 0.7819001714694156]
	TIME [epoch: 24.8 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8102361695763636		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.8102361695763636 | validation: 0.7720164481894309]
	TIME [epoch: 24.8 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7447994473038956		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.7447994473038956 | validation: 0.7281633281143755]
	TIME [epoch: 24.8 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7482973360613834		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.7482973360613834 | validation: 0.7389377018687675]
	TIME [epoch: 24.8 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7933769439771646		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.7933769439771646 | validation: 0.6873722335535364]
	TIME [epoch: 24.8 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7306681666897581		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.7306681666897581 | validation: 0.7458487658698901]
	TIME [epoch: 24.8 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7567998556223442		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.7567998556223442 | validation: 0.8480030041736027]
	TIME [epoch: 24.8 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8070306545201074		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.8070306545201074 | validation: 0.7969511820401559]
	TIME [epoch: 24.8 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9314767870204007		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.9314767870204007 | validation: 0.8131444422658141]
	TIME [epoch: 24.8 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.764860369306092		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.764860369306092 | validation: 0.5950959219836234]
	TIME [epoch: 24.8 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5877289019805709		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.5877289019805709 | validation: 0.6233513610134905]
	TIME [epoch: 24.8 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6244895824784829		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.6244895824784829 | validation: 0.6664473227715482]
	TIME [epoch: 24.8 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5778098492278961		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.5778098492278961 | validation: 0.5569041158876832]
	TIME [epoch: 24.8 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5288717007521483		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.5288717007521483 | validation: 0.5840182864755101]
	TIME [epoch: 24.8 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6629418462959739		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.6629418462959739 | validation: 0.6775319367004115]
	TIME [epoch: 24.8 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6490782918410021		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.6490782918410021 | validation: 0.5807823060950394]
	TIME [epoch: 24.8 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6030181854415558		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.6030181854415558 | validation: 0.5080402798397471]
	TIME [epoch: 24.8 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5269001425732152		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.5269001425732152 | validation: 0.619740469455029]
	TIME [epoch: 24.7 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6767587630526798		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.6767587630526798 | validation: 0.8119638114297811]
	TIME [epoch: 24.8 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.461021967071785		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 1.461021967071785 | validation: 1.0216440351941969]
	TIME [epoch: 24.7 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7884636054451781		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.7884636054451781 | validation: 0.665195500262006]
	TIME [epoch: 24.8 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6391908398203614		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.6391908398203614 | validation: 0.5933074753506048]
	TIME [epoch: 24.8 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5880380973225504		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.5880380973225504 | validation: 0.6302561605626269]
	TIME [epoch: 24.8 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6448816588575903		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.6448816588575903 | validation: 0.5916777117134119]
	TIME [epoch: 24.7 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5396332691080877		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.5396332691080877 | validation: 0.4468949399455579]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_358.pth
	Model improved!!!
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49715799271938976		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.49715799271938976 | validation: 0.45801417204131994]
	TIME [epoch: 24.8 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5616260801017887		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.5616260801017887 | validation: 0.6550433185814849]
	TIME [epoch: 24.8 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6047342536620985		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.6047342536620985 | validation: 0.5488297234620062]
	TIME [epoch: 24.8 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.558427658096259		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.558427658096259 | validation: 0.4571548898200468]
	TIME [epoch: 24.8 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48812398785078365		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.48812398785078365 | validation: 0.4753143179401328]
	TIME [epoch: 24.8 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5031423042742786		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.5031423042742786 | validation: 0.7390305867900054]
	TIME [epoch: 24.8 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6494085709014645		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.6494085709014645 | validation: 0.5614495467575796]
	TIME [epoch: 24.7 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5220618164003495		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.5220618164003495 | validation: 0.5710172982013427]
	TIME [epoch: 24.8 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5557379721549656		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.5557379721549656 | validation: 0.5876669718867256]
	TIME [epoch: 24.8 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5519293026273189		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.5519293026273189 | validation: 0.5229124422370259]
	TIME [epoch: 24.8 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5963849012508605		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.5963849012508605 | validation: 0.5798535997135577]
	TIME [epoch: 24.8 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.612946288184476		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.612946288184476 | validation: 0.6132691187002007]
	TIME [epoch: 24.8 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.614060252440004		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.614060252440004 | validation: 0.5161034239713738]
	TIME [epoch: 24.7 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5693596108149018		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.5693596108149018 | validation: 0.5675414629284632]
	TIME [epoch: 24.8 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5815620219429025		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.5815620219429025 | validation: 0.5649402057873463]
	TIME [epoch: 24.8 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.705900793041327		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.705900793041327 | validation: 0.6671157772238465]
	TIME [epoch: 24.7 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6178463140985946		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.6178463140985946 | validation: 0.687050283787579]
	TIME [epoch: 24.8 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6118866226911358		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.6118866226911358 | validation: 0.5434361663483913]
	TIME [epoch: 24.8 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5289645912388178		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.5289645912388178 | validation: 0.44281970699435114]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_377.pth
	Model improved!!!
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45026324827628184		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.45026324827628184 | validation: 0.48047047069478416]
	TIME [epoch: 24.8 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46092950973338803		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.46092950973338803 | validation: 0.3956886679163084]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_379.pth
	Model improved!!!
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4259576021804483		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.4259576021804483 | validation: 0.434422903330913]
	TIME [epoch: 24.7 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5143651887463678		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.5143651887463678 | validation: 0.756430994922516]
	TIME [epoch: 24.8 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6899175610204992		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.6899175610204992 | validation: 0.5115508017011796]
	TIME [epoch: 24.8 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5343092520816818		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.5343092520816818 | validation: 0.5759534725680492]
	TIME [epoch: 24.8 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5075080976805596		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.5075080976805596 | validation: 0.43213858577652553]
	TIME [epoch: 24.8 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.59033591198281		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.59033591198281 | validation: 0.6972001796702335]
	TIME [epoch: 24.8 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6136052793911411		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.6136052793911411 | validation: 0.523265261061616]
	TIME [epoch: 24.8 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5754697989823445		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.5754697989823445 | validation: 0.65440142091241]
	TIME [epoch: 24.8 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7220401066967008		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.7220401066967008 | validation: 0.5795194404657683]
	TIME [epoch: 24.8 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7699838751708357		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.7699838751708357 | validation: 0.5561516859928689]
	TIME [epoch: 24.8 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46491069057717044		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.46491069057717044 | validation: 0.5919046497209774]
	TIME [epoch: 24.8 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5208632414319156		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.5208632414319156 | validation: 0.5303287109030541]
	TIME [epoch: 24.8 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.500074404199222		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.500074404199222 | validation: 0.5953232947465489]
	TIME [epoch: 24.8 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6743242984928938		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.6743242984928938 | validation: 0.5969473475067916]
	TIME [epoch: 24.8 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5348865814380673		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.5348865814380673 | validation: 0.43880921285838953]
	TIME [epoch: 24.8 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4869485925636481		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.4869485925636481 | validation: 0.585741322367101]
	TIME [epoch: 24.7 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5547099564866562		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.5547099564866562 | validation: 0.5486489006755509]
	TIME [epoch: 24.8 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5967857160323166		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.5967857160323166 | validation: 0.844485203102141]
	TIME [epoch: 24.8 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8422033005329184		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.8422033005329184 | validation: 0.6666676296951605]
	TIME [epoch: 24.7 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5567167851928982		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.5567167851928982 | validation: 0.42591744176613405]
	TIME [epoch: 24.8 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.409546191471185		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.409546191471185 | validation: 0.41738583758526915]
	TIME [epoch: 24.8 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4352242348362122		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.4352242348362122 | validation: 0.3872103407535411]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_401.pth
	Model improved!!!
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45229895152104715		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.45229895152104715 | validation: 0.45997846360526085]
	TIME [epoch: 24.8 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5724538292120853		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.5724538292120853 | validation: 0.5748486527447113]
	TIME [epoch: 24.8 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4803154949703022		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.4803154949703022 | validation: 0.39613052923092207]
	TIME [epoch: 24.7 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4140170556073688		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.4140170556073688 | validation: 0.37438316428255475]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_405.pth
	Model improved!!!
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38959083073908496		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.38959083073908496 | validation: 0.3801728052002777]
	TIME [epoch: 24.8 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5536026111326366		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.5536026111326366 | validation: 0.5396540670137611]
	TIME [epoch: 24.7 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5186930318227452		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.5186930318227452 | validation: 0.4811319621708565]
	TIME [epoch: 24.7 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4891309817126152		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.4891309817126152 | validation: 0.46814980691360275]
	TIME [epoch: 24.8 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5773283747294371		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.5773283747294371 | validation: 0.7830345199551877]
	TIME [epoch: 24.7 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6593415308843324		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.6593415308843324 | validation: 0.46443378946553354]
	TIME [epoch: 24.7 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47350636809968916		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.47350636809968916 | validation: 0.38208083745373245]
	TIME [epoch: 24.7 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45391403168934014		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.45391403168934014 | validation: 0.4645785280671313]
	TIME [epoch: 24.8 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5908785905895138		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.5908785905895138 | validation: 0.4534848936936335]
	TIME [epoch: 24.8 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46976946212922743		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.46976946212922743 | validation: 0.36097230471046693]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_415.pth
	Model improved!!!
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39794239398755227		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.39794239398755227 | validation: 0.38811837502866164]
	TIME [epoch: 24.8 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.53477075672606		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.53477075672606 | validation: 0.5427261364182354]
	TIME [epoch: 24.8 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6348542130863235		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.6348542130863235 | validation: 1.256282917430675]
	TIME [epoch: 24.8 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9487274454965857		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.9487274454965857 | validation: 0.5345619821941293]
	TIME [epoch: 24.8 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49836900188922245		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.49836900188922245 | validation: 0.4603971133030032]
	TIME [epoch: 24.8 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5452136137366925		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.5452136137366925 | validation: 0.5388321625102277]
	TIME [epoch: 24.8 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6540470944282215		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.6540470944282215 | validation: 0.5269830964576931]
	TIME [epoch: 24.8 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4843635594712331		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.4843635594712331 | validation: 0.4929950861141245]
	TIME [epoch: 24.8 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4693989168975913		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.4693989168975913 | validation: 0.4178728029434362]
	TIME [epoch: 24.8 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46469115180470355		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.46469115180470355 | validation: 0.42430730984402615]
	TIME [epoch: 24.8 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49086182102271936		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.49086182102271936 | validation: 0.41606661222452984]
	TIME [epoch: 24.8 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47572291974498093		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.47572291974498093 | validation: 0.537750172601614]
	TIME [epoch: 24.8 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4938606959611338		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.4938606959611338 | validation: 0.37940165045788377]
	TIME [epoch: 24.8 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4265587911872002		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.4265587911872002 | validation: 0.4814533643828679]
	TIME [epoch: 24.8 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4745651098213002		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.4745651098213002 | validation: 0.4794646101230782]
	TIME [epoch: 24.8 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44118974301122293		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.44118974301122293 | validation: 0.48002996358801997]
	TIME [epoch: 24.7 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45808038317256056		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.45808038317256056 | validation: 0.37168645261447836]
	TIME [epoch: 24.7 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4772023913670171		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.4772023913670171 | validation: 0.5674182844223818]
	TIME [epoch: 24.8 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.491558996044287		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.491558996044287 | validation: 0.4639833778224076]
	TIME [epoch: 24.7 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.539604152988377		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.539604152988377 | validation: 0.4675422685399168]
	TIME [epoch: 24.8 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4762793578728395		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.4762793578728395 | validation: 0.40191680070429214]
	TIME [epoch: 24.8 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45723662542790167		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.45723662542790167 | validation: 0.5995117920953258]
	TIME [epoch: 24.8 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7571002831199412		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.7571002831199412 | validation: 0.6263068071253121]
	TIME [epoch: 24.8 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5039568222684614		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.5039568222684614 | validation: 0.39101300588804416]
	TIME [epoch: 24.7 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.456327198094854		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.456327198094854 | validation: 0.4585475784876128]
	TIME [epoch: 24.8 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4876669058675891		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.4876669058675891 | validation: 0.49331626790325905]
	TIME [epoch: 24.8 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4925823814568302		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.4925823814568302 | validation: 0.3834240854096191]
	TIME [epoch: 24.8 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5676028879997801		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.5676028879997801 | validation: 0.5653043092530484]
	TIME [epoch: 24.8 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49518942512888037		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.49518942512888037 | validation: 0.36450157465714783]
	TIME [epoch: 24.8 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40022490733887833		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.40022490733887833 | validation: 0.45960123066906144]
	TIME [epoch: 24.8 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42672120188834756		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.42672120188834756 | validation: 0.4021861710722564]
	TIME [epoch: 24.8 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45904473670776624		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.45904473670776624 | validation: 0.8180474849821259]
	TIME [epoch: 24.8 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7862696008485701		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.7862696008485701 | validation: 0.837202039158163]
	TIME [epoch: 24.8 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7020507494842991		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.7020507494842991 | validation: 0.6562353802871084]
	TIME [epoch: 24.8 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5871698719069643		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.5871698719069643 | validation: 0.5274459337567994]
	TIME [epoch: 24.8 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4990060548715527		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.4990060548715527 | validation: 0.45107132543062844]
	TIME [epoch: 24.8 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4384102619501987		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.4384102619501987 | validation: 0.40334693350765316]
	TIME [epoch: 24.8 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4363054536535876		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.4363054536535876 | validation: 0.43065239647251546]
	TIME [epoch: 24.8 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46589574865905786		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.46589574865905786 | validation: 0.8147855784890572]
	TIME [epoch: 24.8 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8667908171621828		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.8667908171621828 | validation: 0.5317229876351479]
	TIME [epoch: 24.8 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5528085602183028		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.5528085602183028 | validation: 0.5776673363837425]
	TIME [epoch: 24.8 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5063791222007544		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.5063791222007544 | validation: 0.3936902217546948]
	TIME [epoch: 24.8 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4605605902492703		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.4605605902492703 | validation: 0.45452251261279614]
	TIME [epoch: 24.8 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4627209502221802		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.4627209502221802 | validation: 0.6252871867667013]
	TIME [epoch: 24.8 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.535864415877415		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.535864415877415 | validation: 0.41132865292202936]
	TIME [epoch: 24.8 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41789032202602705		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.41789032202602705 | validation: 0.34355887461702805]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_461.pth
	Model improved!!!
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39151769702289585		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.39151769702289585 | validation: 0.3512594534911198]
	TIME [epoch: 24.8 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43633075893000184		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.43633075893000184 | validation: 0.5519654952999326]
	TIME [epoch: 24.8 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5118029370489365		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.5118029370489365 | validation: 0.4102295963886196]
	TIME [epoch: 24.8 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.411956540020716		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.411956540020716 | validation: 0.3895446483463062]
	TIME [epoch: 24.8 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3729030951070391		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.3729030951070391 | validation: 0.3545236223430958]
	TIME [epoch: 24.8 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.393085143120403		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.393085143120403 | validation: 0.5731832484970913]
	TIME [epoch: 24.8 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5026425117235093		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.5026425117235093 | validation: 0.3807897800371896]
	TIME [epoch: 24.8 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4005882543867524		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.4005882543867524 | validation: 0.49574169467825296]
	TIME [epoch: 24.8 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47513213333145876		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.47513213333145876 | validation: 0.5308729432936906]
	TIME [epoch: 24.8 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4745667546614774		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.4745667546614774 | validation: 0.5127049200165362]
	TIME [epoch: 24.8 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44518892300199975		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.44518892300199975 | validation: 0.8591445137214956]
	TIME [epoch: 24.8 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0732734435849807		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 1.0732734435849807 | validation: 0.6546925923839896]
	TIME [epoch: 24.8 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5850167954509295		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.5850167954509295 | validation: 0.43600003463873643]
	TIME [epoch: 24.8 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.445705358802188		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.445705358802188 | validation: 0.4295437179865854]
	TIME [epoch: 24.8 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42548103452467234		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.42548103452467234 | validation: 0.4490903986787014]
	TIME [epoch: 24.8 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5117821362736446		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.5117821362736446 | validation: 0.825197984530417]
	TIME [epoch: 24.8 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7132920384867244		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.7132920384867244 | validation: 0.5898517136106465]
	TIME [epoch: 24.8 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6252236758274277		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.6252236758274277 | validation: 0.8100360088373654]
	TIME [epoch: 24.8 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6583029066741809		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.6583029066741809 | validation: 0.3961631043796502]
	TIME [epoch: 24.8 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5082676627463882		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.5082676627463882 | validation: 0.5428649965439013]
	TIME [epoch: 24.8 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7484607665108072		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.7484607665108072 | validation: 0.6339897089180625]
	TIME [epoch: 24.8 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6003371166195863		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.6003371166195863 | validation: 0.5236683986869114]
	TIME [epoch: 24.8 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5381591222060204		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.5381591222060204 | validation: 0.5153876393621271]
	TIME [epoch: 24.8 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5620260769919219		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.5620260769919219 | validation: 0.4933176232854394]
	TIME [epoch: 24.7 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49149605194807483		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.49149605194807483 | validation: 0.7471302134738694]
	TIME [epoch: 24.7 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6649188034538891		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.6649188034538891 | validation: 0.5333726305222016]
	TIME [epoch: 24.7 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5104845102278072		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.5104845102278072 | validation: 0.48057116229763025]
	TIME [epoch: 24.7 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4746660929184354		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.4746660929184354 | validation: 0.37954470034129484]
	TIME [epoch: 24.7 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40714655023713975		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.40714655023713975 | validation: 0.35257313193247686]
	TIME [epoch: 24.7 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36253246139770956		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.36253246139770956 | validation: 0.36678433382991815]
	TIME [epoch: 24.7 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41742786372525664		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.41742786372525664 | validation: 0.36005127194988445]
	TIME [epoch: 24.7 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4351597463188491		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.4351597463188491 | validation: 0.3498004683581773]
	TIME [epoch: 24.7 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37856699150831286		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.37856699150831286 | validation: 0.36783812586239495]
	TIME [epoch: 24.7 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38182428723808076		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.38182428723808076 | validation: 0.4138554021013037]
	TIME [epoch: 24.7 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3916853563230925		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.3916853563230925 | validation: 0.3710921385560475]
	TIME [epoch: 24.7 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4223457316778133		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.4223457316778133 | validation: 0.36465627418426777]
	TIME [epoch: 24.7 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38116215488781413		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.38116215488781413 | validation: 0.36456888282082317]
	TIME [epoch: 24.7 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4326964934773405		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.4326964934773405 | validation: 0.6161115541026453]
	TIME [epoch: 24.7 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5542851155471081		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.5542851155471081 | validation: 0.5898275994186118]
	TIME [epoch: 24.7 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6557524499347065		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.6557524499347065 | validation: 0.4150446248913713]
	TIME [epoch: 24.7 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4190224789282665		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.4190224789282665 | validation: 0.3661176250884522]
	TIME [epoch: 24.7 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38711799632134547		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.38711799632134547 | validation: 0.40566212067049917]
	TIME [epoch: 24.8 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4279670725722766		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.4279670725722766 | validation: 0.5655462468993685]
	TIME [epoch: 24.8 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4965026122689933		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.4965026122689933 | validation: 0.4906205215538647]
	TIME [epoch: 24.8 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5476031006377354		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.5476031006377354 | validation: 0.638945444800682]
	TIME [epoch: 24.8 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5116117541737741		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.5116117541737741 | validation: 0.39411550292116276]
	TIME [epoch: 24.7 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49921180925114983		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.49921180925114983 | validation: 0.5225215737209538]
	TIME [epoch: 24.8 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5001255686169289		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.5001255686169289 | validation: 0.3977732387949966]
	TIME [epoch: 24.8 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38234112247997015		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.38234112247997015 | validation: 0.33055664714697097]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_510.pth
	Model improved!!!
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43449977125328754		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.43449977125328754 | validation: 0.6356428630341614]
	TIME [epoch: 24.8 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49215918122825436		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.49215918122825436 | validation: 0.4669918181008911]
	TIME [epoch: 24.8 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3769704989666716		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.3769704989666716 | validation: 0.31798606506537885]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_513.pth
	Model improved!!!
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38395661117539825		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.38395661117539825 | validation: 0.5051785614303073]
	TIME [epoch: 24.8 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6038846221596514		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.6038846221596514 | validation: 0.5653078146184963]
	TIME [epoch: 24.8 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7217123483257786		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.7217123483257786 | validation: 0.6674784183477657]
	TIME [epoch: 24.8 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.525776096246122		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.525776096246122 | validation: 0.3923154206063662]
	TIME [epoch: 24.8 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8162900866424713		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.8162900866424713 | validation: 0.9232073550801994]
	TIME [epoch: 24.8 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6408530404874783		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.6408530404874783 | validation: 0.4209517535497122]
	TIME [epoch: 24.8 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5271944507147369		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.5271944507147369 | validation: 0.5413390353066634]
	TIME [epoch: 24.8 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49590602848552023		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.49590602848552023 | validation: 0.43831807529557865]
	TIME [epoch: 24.8 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43934506005683494		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.43934506005683494 | validation: 0.6267654008657081]
	TIME [epoch: 24.8 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5763840097619091		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.5763840097619091 | validation: 0.7321571372943868]
	TIME [epoch: 24.7 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.654856382670157		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.654856382670157 | validation: 0.40594796517451587]
	TIME [epoch: 24.8 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3621551229753071		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.3621551229753071 | validation: 0.4652122443040237]
	TIME [epoch: 24.8 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5300416713804574		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.5300416713804574 | validation: 0.5818451294230604]
	TIME [epoch: 24.8 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6131750972896789		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.6131750972896789 | validation: 0.7402554303529115]
	TIME [epoch: 24.8 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.716126277720438		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.716126277720438 | validation: 0.7260313924359144]
	TIME [epoch: 24.8 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5266648642177327		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.5266648642177327 | validation: 0.3532610701665297]
	TIME [epoch: 24.8 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37070319333035273		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.37070319333035273 | validation: 0.3130711200308299]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_530.pth
	Model improved!!!
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36644507359366757		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.36644507359366757 | validation: 0.4732271637393855]
	TIME [epoch: 24.8 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4220628598707742		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.4220628598707742 | validation: 0.38525307346401716]
	TIME [epoch: 24.8 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37149294552334633		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.37149294552334633 | validation: 0.4208267396614716]
	TIME [epoch: 24.8 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46156288231541376		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.46156288231541376 | validation: 0.5325220909323531]
	TIME [epoch: 24.8 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4241568883623804		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.4241568883623804 | validation: 0.3897528282028486]
	TIME [epoch: 24.8 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3556936716934598		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.3556936716934598 | validation: 0.355324246122835]
	TIME [epoch: 24.8 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32042319961924814		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.32042319961924814 | validation: 0.3281698571568502]
	TIME [epoch: 24.8 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41649117758883114		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.41649117758883114 | validation: 0.3707817614079461]
	TIME [epoch: 24.8 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3846597312777959		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.3846597312777959 | validation: 0.3545654747382064]
	TIME [epoch: 24.8 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3927294797230588		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.3927294797230588 | validation: 0.40880793182615605]
	TIME [epoch: 24.8 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39957896488891165		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.39957896488891165 | validation: 0.44114676621698634]
	TIME [epoch: 24.8 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3917790793971842		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.3917790793971842 | validation: 0.3354390341441936]
	TIME [epoch: 24.8 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4302499732908128		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.4302499732908128 | validation: 0.39349363647155977]
	TIME [epoch: 24.8 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3576137333171985		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.3576137333171985 | validation: 0.31753863107399527]
	TIME [epoch: 24.8 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3856882517354039		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.3856882517354039 | validation: 0.5210898457325859]
	TIME [epoch: 24.8 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5630066960443614		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.5630066960443614 | validation: 0.3292621864875415]
	TIME [epoch: 24.8 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38724524885124223		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.38724524885124223 | validation: 0.4507043843472897]
	TIME [epoch: 24.8 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4045458171567322		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.4045458171567322 | validation: 0.3353237877232558]
	TIME [epoch: 24.8 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36813486143810237		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.36813486143810237 | validation: 0.41955272953256]
	TIME [epoch: 24.8 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4221605340770589		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.4221605340770589 | validation: 0.4067492926757008]
	TIME [epoch: 24.7 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36841672641320833		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.36841672641320833 | validation: 0.32286841184030424]
	TIME [epoch: 24.7 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3685866624057933		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.3685866624057933 | validation: 0.3287476606898475]
	TIME [epoch: 24.8 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3476144472440688		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.3476144472440688 | validation: 0.42475291689085637]
	TIME [epoch: 24.8 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35387963503739556		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.35387963503739556 | validation: 0.32786772439227163]
	TIME [epoch: 24.8 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3447782230331684		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.3447782230331684 | validation: 0.2966586362581525]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_555.pth
	Model improved!!!
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32427083935098927		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.32427083935098927 | validation: 0.4245886103933609]
	TIME [epoch: 24.7 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48619902184153696		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.48619902184153696 | validation: 0.4838839500868602]
	TIME [epoch: 24.8 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5453463035363341		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.5453463035363341 | validation: 0.43909605871118135]
	TIME [epoch: 24.7 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4019427813078559		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.4019427813078559 | validation: 0.4096471906831569]
	TIME [epoch: 24.7 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4326529450169586		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.4326529450169586 | validation: 0.4073401504033186]
	TIME [epoch: 24.8 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37771549547183814		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.37771549547183814 | validation: 0.4691634391831269]
	TIME [epoch: 24.7 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40542642424085784		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.40542642424085784 | validation: 0.38637065519902203]
	TIME [epoch: 24.7 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3527702684345692		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.3527702684345692 | validation: 0.3304100327997294]
	TIME [epoch: 24.8 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3684584481011584		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.3684584481011584 | validation: 0.3730948464156471]
	TIME [epoch: 24.7 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34135015008081665		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.34135015008081665 | validation: 0.31129091942745774]
	TIME [epoch: 24.7 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3209036649307322		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.3209036649307322 | validation: 0.3865304130801424]
	TIME [epoch: 24.8 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36070419374843554		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.36070419374843554 | validation: 0.39727834481941265]
	TIME [epoch: 24.7 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35901231400335065		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.35901231400335065 | validation: 0.31539292733360946]
	TIME [epoch: 24.7 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3663217247197726		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.3663217247197726 | validation: 0.4464382363204005]
	TIME [epoch: 24.8 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4071556932456565		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.4071556932456565 | validation: 0.3257659720267222]
	TIME [epoch: 24.7 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3556371041577766		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.3556371041577766 | validation: 0.32508511733349027]
	TIME [epoch: 24.7 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37350442825418384		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.37350442825418384 | validation: 0.45721883391398344]
	TIME [epoch: 24.8 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48018418630488147		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.48018418630488147 | validation: 0.6435366257348124]
	TIME [epoch: 24.7 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6338299489603979		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.6338299489603979 | validation: 0.4529086637419252]
	TIME [epoch: 24.7 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45609264276662365		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.45609264276662365 | validation: 0.5089431184375006]
	TIME [epoch: 24.8 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44897558160541107		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.44897558160541107 | validation: 0.4405341345656528]
	TIME [epoch: 24.7 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4475503080145255		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.4475503080145255 | validation: 0.4392259244367533]
	TIME [epoch: 24.7 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43043291231544056		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.43043291231544056 | validation: 0.4090840787626614]
	TIME [epoch: 24.8 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3948617037462116		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.3948617037462116 | validation: 0.3540918676716882]
	TIME [epoch: 24.7 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3578892406275283		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.3578892406275283 | validation: 0.35560894871071624]
	TIME [epoch: 24.7 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35126401016587455		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.35126401016587455 | validation: 0.31657956964186784]
	TIME [epoch: 24.8 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3228151444611958		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.3228151444611958 | validation: 0.3082225129018256]
	TIME [epoch: 24.7 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3357831825545762		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.3357831825545762 | validation: 0.4055436609758249]
	TIME [epoch: 24.7 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3660602648862926		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.3660602648862926 | validation: 0.3291763926048594]
	TIME [epoch: 24.8 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5502968782282527		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.5502968782282527 | validation: 0.829247237775956]
	TIME [epoch: 24.7 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6621024118877078		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.6621024118877078 | validation: 0.3754340160353406]
	TIME [epoch: 24.7 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3507265662767618		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.3507265662767618 | validation: 0.3133161304797915]
	TIME [epoch: 24.8 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35156318179474233		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.35156318179474233 | validation: 0.3174857093907806]
	TIME [epoch: 24.7 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3623710675051601		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.3623710675051601 | validation: 0.32116136083524555]
	TIME [epoch: 24.7 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34442529592986815		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.34442529592986815 | validation: 0.38897027633307596]
	TIME [epoch: 24.8 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4009346673650564		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.4009346673650564 | validation: 0.30931923618757223]
	TIME [epoch: 24.7 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3491872871190067		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.3491872871190067 | validation: 0.33039473875603415]
	TIME [epoch: 24.7 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3429554107654149		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.3429554107654149 | validation: 0.30729749308454296]
	TIME [epoch: 24.8 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37234597690174515		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.37234597690174515 | validation: 0.424696996629387]
	TIME [epoch: 24.7 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.364687240414154		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.364687240414154 | validation: 0.31742293532085014]
	TIME [epoch: 24.8 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3236562890543424		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.3236562890543424 | validation: 0.29767349898061457]
	TIME [epoch: 24.8 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33472470658257714		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.33472470658257714 | validation: 0.45665944320931706]
	TIME [epoch: 24.7 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5373626977160446		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.5373626977160446 | validation: 0.5010887544970271]
	TIME [epoch: 24.7 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5644727548088455		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.5644727548088455 | validation: 0.599642802741498]
	TIME [epoch: 24.8 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5582415176290573		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.5582415176290573 | validation: 0.4585966443403325]
	TIME [epoch: 24.7 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4059042251538912		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.4059042251538912 | validation: 0.4015519255227424]
	TIME [epoch: 24.7 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4079332837124451		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.4079332837124451 | validation: 0.4239046172049919]
	TIME [epoch: 24.8 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40608287797103243		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.40608287797103243 | validation: 0.4576683611116923]
	TIME [epoch: 24.7 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.410930298533419		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.410930298533419 | validation: 0.3411562676182148]
	TIME [epoch: 24.7 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4437299606295977		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.4437299606295977 | validation: 0.4482824128423363]
	TIME [epoch: 24.7 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4358587436617783		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.4358587436617783 | validation: 0.36117633633631463]
	TIME [epoch: 24.7 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37490602270524437		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.37490602270524437 | validation: 0.36376249543122013]
	TIME [epoch: 24.7 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38767246121143273		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.38767246121143273 | validation: 0.2983424859535289]
	TIME [epoch: 24.7 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33906237119367755		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.33906237119367755 | validation: 0.344118458618577]
	TIME [epoch: 24.7 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35244298035499966		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.35244298035499966 | validation: 0.351018035419882]
	TIME [epoch: 24.7 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42597611936466767		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.42597611936466767 | validation: 0.3354568666593456]
	TIME [epoch: 24.8 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33350431480434467		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.33350431480434467 | validation: 0.3015014459800522]
	TIME [epoch: 24.7 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37224516746315356		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.37224516746315356 | validation: 0.35959440508042056]
	TIME [epoch: 24.7 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4379832511075977		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.4379832511075977 | validation: 0.4133853279241061]
	TIME [epoch: 24.8 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38886081163751596		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.38886081163751596 | validation: 0.3791493346258188]
	TIME [epoch: 24.7 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34978380110295326		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.34978380110295326 | validation: 0.30780488663690875]
	TIME [epoch: 24.8 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3370371827695037		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.3370371827695037 | validation: 0.35170701972301793]
	TIME [epoch: 24.8 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33089829426704165		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.33089829426704165 | validation: 0.3225789626979277]
	TIME [epoch: 24.7 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45504688461435727		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.45504688461435727 | validation: 0.38703817504605104]
	TIME [epoch: 24.8 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3657264899468523		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.3657264899468523 | validation: 0.3768389257222404]
	TIME [epoch: 24.8 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.455152075232239		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.455152075232239 | validation: 0.5753129950098399]
	TIME [epoch: 24.7 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7519930260617925		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.7519930260617925 | validation: 0.5784713329190546]
	TIME [epoch: 24.8 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5416474301792737		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.5416474301792737 | validation: 0.4640415470998058]
	TIME [epoch: 24.7 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4616543034735758		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.4616543034735758 | validation: 0.3717464423860528]
	TIME [epoch: 24.7 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38991460530768496		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.38991460530768496 | validation: 0.3687295874039676]
	TIME [epoch: 24.8 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3998109053116159		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.3998109053116159 | validation: 0.4143038421368722]
	TIME [epoch: 24.8 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4781042354090774		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.4781042354090774 | validation: 0.3905742141046749]
	TIME [epoch: 24.7 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4019827133626802		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.4019827133626802 | validation: 0.36172942186686086]
	TIME [epoch: 24.8 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37726392969756095		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.37726392969756095 | validation: 0.3348210675312114]
	TIME [epoch: 24.8 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36903971172554		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.36903971172554 | validation: 0.3358665999582259]
	TIME [epoch: 24.7 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36138681042171417		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.36138681042171417 | validation: 0.3317137106162346]
	TIME [epoch: 24.8 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3565055838225941		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.3565055838225941 | validation: 0.36503168491867755]
	TIME [epoch: 24.8 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3693372463085654		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.3693372463085654 | validation: 0.3593189432624606]
	TIME [epoch: 24.7 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37448665171599144		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.37448665171599144 | validation: 0.37244915017977287]
	TIME [epoch: 24.8 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45543643484132157		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.45543643484132157 | validation: 0.40723160780924345]
	TIME [epoch: 24.8 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3673369707548285		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.3673369707548285 | validation: 0.3487107119221454]
	TIME [epoch: 24.7 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.351771156477764		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.351771156477764 | validation: 0.410150515347645]
	TIME [epoch: 24.8 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39136352227404825		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.39136352227404825 | validation: 0.3353917461620082]
	TIME [epoch: 24.8 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3473853198400948		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.3473853198400948 | validation: 0.3248472055846463]
	TIME [epoch: 24.7 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3091265307953338		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.3091265307953338 | validation: 0.3127161605745571]
	TIME [epoch: 24.8 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35956621760637975		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.35956621760637975 | validation: 0.37799622331908195]
	TIME [epoch: 24.8 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4523223727908716		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.4523223727908716 | validation: 0.4436550359278541]
	TIME [epoch: 24.7 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4841349432713721		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.4841349432713721 | validation: 0.37463326834468524]
	TIME [epoch: 24.8 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39962247881626045		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.39962247881626045 | validation: 0.3395380104289248]
	TIME [epoch: 24.8 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3990664695480284		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.3990664695480284 | validation: 0.35878910363113276]
	TIME [epoch: 24.7 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41082861916339075		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.41082861916339075 | validation: 0.34763303929338946]
	TIME [epoch: 24.8 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3344264423418618		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.3344264423418618 | validation: 0.3375169104852747]
	TIME [epoch: 24.8 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3272470893726978		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.3272470893726978 | validation: 0.30339169177493924]
	TIME [epoch: 24.7 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3656666699375461		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.3656666699375461 | validation: 0.3592315415777841]
	TIME [epoch: 24.8 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4070086083707407		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.4070086083707407 | validation: 0.5651997323698004]
	TIME [epoch: 24.8 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5098965798868447		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.5098965798868447 | validation: 0.353834943114762]
	TIME [epoch: 24.7 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35531277927787186		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.35531277927787186 | validation: 0.30782262629002943]
	TIME [epoch: 24.8 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.339602147697773		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.339602147697773 | validation: 0.29143405862210797]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_653.pth
	Model improved!!!
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3112651575002453		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.3112651575002453 | validation: 0.2916478266644691]
	TIME [epoch: 24.7 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.329307286833877		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.329307286833877 | validation: 0.34278076521034045]
	TIME [epoch: 24.7 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3440568357141689		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.3440568357141689 | validation: 0.31351898146008367]
	TIME [epoch: 24.7 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32764488588419816		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.32764488588419816 | validation: 0.30007711207639304]
	TIME [epoch: 24.7 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3872260081787933		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.3872260081787933 | validation: 0.48152501650132196]
	TIME [epoch: 24.7 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5778224670769592		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.5778224670769592 | validation: 0.7873803728400383]
	TIME [epoch: 24.7 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7496927852214761		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.7496927852214761 | validation: 0.44045950156755936]
	TIME [epoch: 24.7 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41464324316535295		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.41464324316535295 | validation: 0.47311364783937715]
	TIME [epoch: 24.7 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4321312321937488		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.4321312321937488 | validation: 0.2781152539634369]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_662.pth
	Model improved!!!
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3873514519462732		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.3873514519462732 | validation: 0.5353260241184462]
	TIME [epoch: 24.8 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5852044083570431		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.5852044083570431 | validation: 0.4161057015653422]
	TIME [epoch: 24.8 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40517969991953123		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.40517969991953123 | validation: 0.356074622638762]
	TIME [epoch: 24.7 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43182354232085685		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.43182354232085685 | validation: 0.5556518214335417]
	TIME [epoch: 24.8 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5579821032507608		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.5579821032507608 | validation: 0.6006926348954449]
	TIME [epoch: 24.8 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47115532671798044		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.47115532671798044 | validation: 0.3238729018209232]
	TIME [epoch: 24.8 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45743803550774353		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.45743803550774353 | validation: 0.728914008683972]
	TIME [epoch: 24.7 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7595523212105796		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.7595523212105796 | validation: 0.47195907069402104]
	TIME [epoch: 24.8 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39362124187010694		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.39362124187010694 | validation: 0.3327830938747647]
	TIME [epoch: 24.8 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.351761945357629		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.351761945357629 | validation: 0.4510987866564129]
	TIME [epoch: 24.8 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47335882685513114		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.47335882685513114 | validation: 0.3560032909876876]
	TIME [epoch: 24.8 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3717675154488655		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.3717675154488655 | validation: 0.3434696257659141]
	TIME [epoch: 24.8 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4035590576332426		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.4035590576332426 | validation: 0.4159237101479078]
	TIME [epoch: 24.8 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4258394979567782		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.4258394979567782 | validation: 0.4139501687452736]
	TIME [epoch: 24.8 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4068865501031353		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.4068865501031353 | validation: 0.3293067346000474]
	TIME [epoch: 24.8 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3232537620304072		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.3232537620304072 | validation: 0.29387365392772996]
	TIME [epoch: 24.8 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40812672103149256		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.40812672103149256 | validation: 0.3935637026821429]
	TIME [epoch: 24.8 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33950713753818423		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.33950713753818423 | validation: 0.30016984123093504]
	TIME [epoch: 24.8 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32301053419121895		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.32301053419121895 | validation: 0.2818751764005105]
	TIME [epoch: 24.8 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2968409763515104		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.2968409763515104 | validation: 0.2745202646778147]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_682.pth
	Model improved!!!
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28909458006125155		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.28909458006125155 | validation: 0.27706391819885634]
	TIME [epoch: 24.8 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3013225870892678		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.3013225870892678 | validation: 0.31420549165164696]
	TIME [epoch: 24.8 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3091462565436666		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.3091462565436666 | validation: 0.3679742130155674]
	TIME [epoch: 24.8 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3541715748640375		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.3541715748640375 | validation: 0.33856545542461663]
	TIME [epoch: 24.8 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34257468717737705		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.34257468717737705 | validation: 0.32629240334986626]
	TIME [epoch: 24.8 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31220079491424657		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.31220079491424657 | validation: 0.27247886516275194]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_688.pth
	Model improved!!!
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3109278892198277		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.3109278892198277 | validation: 0.3406146794984033]
	TIME [epoch: 24.8 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33036356771109765		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.33036356771109765 | validation: 0.28448984214982853]
	TIME [epoch: 24.7 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2775178553004466		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.2775178553004466 | validation: 0.25237794423524085]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_691.pth
	Model improved!!!
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2658957886934802		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.2658957886934802 | validation: 0.28934998630637987]
	TIME [epoch: 24.8 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30481656308572697		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.30481656308572697 | validation: 0.2660832916724897]
	TIME [epoch: 24.8 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2679795182841458		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.2679795182841458 | validation: 0.24009666179979897]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_694.pth
	Model improved!!!
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.274051231182		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.274051231182 | validation: 0.298366596269083]
	TIME [epoch: 24.8 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29758377829077065		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.29758377829077065 | validation: 0.2376740898875117]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_696.pth
	Model improved!!!
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27612022784421936		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.27612022784421936 | validation: 0.2622767700355122]
	TIME [epoch: 24.8 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28249660619551087		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.28249660619551087 | validation: 0.28447377298646515]
	TIME [epoch: 24.8 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48989975914704426		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.48989975914704426 | validation: 0.7654657733148451]
	TIME [epoch: 24.7 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6745935228691846		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.6745935228691846 | validation: 0.44816637465772835]
	TIME [epoch: 24.8 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5753650645206663		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.5753650645206663 | validation: 0.493192389233058]
	TIME [epoch: 24.8 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.402933865271463		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.402933865271463 | validation: 0.3296481467693995]
	TIME [epoch: 24.8 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3219318875553906		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.3219318875553906 | validation: 0.3568455020593858]
	TIME [epoch: 24.8 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3689846765828539		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.3689846765828539 | validation: 0.3201450563612117]
	TIME [epoch: 24.8 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31722754665352293		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.31722754665352293 | validation: 0.31597529635690275]
	TIME [epoch: 24.8 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3499787667871106		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.3499787667871106 | validation: 0.4323139927320666]
	TIME [epoch: 24.8 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4581587342638864		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.4581587342638864 | validation: 0.3777863529828137]
	TIME [epoch: 24.8 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38480459794148086		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.38480459794148086 | validation: 0.379300800869227]
	TIME [epoch: 24.8 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3709224260134413		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.3709224260134413 | validation: 0.3565641009056745]
	TIME [epoch: 24.8 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3400950272821097		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.3400950272821097 | validation: 0.31779532356734563]
	TIME [epoch: 24.8 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35884875743238304		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.35884875743238304 | validation: 0.3249432350372932]
	TIME [epoch: 24.8 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3691799500622455		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.3691799500622455 | validation: 0.3770940492935204]
	TIME [epoch: 24.8 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3341934120925498		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.3341934120925498 | validation: 0.29152507564935265]
	TIME [epoch: 24.8 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37573776990692775		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.37573776990692775 | validation: 0.3517853245821529]
	TIME [epoch: 24.8 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3380267683586927		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.3380267683586927 | validation: 0.30346049692790733]
	TIME [epoch: 24.8 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32043988061935597		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.32043988061935597 | validation: 0.27627247156775087]
	TIME [epoch: 24.7 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3511719387514484		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.3511719387514484 | validation: 0.41832732333962663]
	TIME [epoch: 24.8 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3952189573935828		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.3952189573935828 | validation: 0.2964438458298064]
	TIME [epoch: 24.8 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30954380712444524		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.30954380712444524 | validation: 0.306346297645706]
	TIME [epoch: 24.8 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2993894190726527		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.2993894190726527 | validation: 0.2524910025635513]
	TIME [epoch: 24.8 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2674290802248874		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.2674290802248874 | validation: 0.29821624725674434]
	TIME [epoch: 24.8 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3623834765783769		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.3623834765783769 | validation: 0.2859729741891065]
	TIME [epoch: 24.7 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29117742070042674		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.29117742070042674 | validation: 0.29689325988060117]
	TIME [epoch: 24.8 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2709773578553789		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.2709773578553789 | validation: 0.2791060994085667]
	TIME [epoch: 24.8 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26871484863988593		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.26871484863988593 | validation: 0.2606808214597453]
	TIME [epoch: 24.7 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2573265819629462		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.2573265819629462 | validation: 0.2528412273519179]
	TIME [epoch: 24.8 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26062376600032827		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.26062376600032827 | validation: 0.2392549960123227]
	TIME [epoch: 24.8 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2675050587983872		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.2675050587983872 | validation: 0.33857281210941526]
	TIME [epoch: 24.8 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37962289266309035		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.37962289266309035 | validation: 0.3868312952414027]
	TIME [epoch: 24.8 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4944367155369799		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.4944367155369799 | validation: 0.5591822839822297]
	TIME [epoch: 24.8 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.54837447130177		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.54837447130177 | validation: 0.36052494014528835]
	TIME [epoch: 24.8 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3236767820554617		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.3236767820554617 | validation: 0.26199271064742535]
	TIME [epoch: 24.8 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2842788769714103		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.2842788769714103 | validation: 0.24633426564887487]
	TIME [epoch: 24.8 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29146800008070295		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.29146800008070295 | validation: 0.34954391959452064]
	TIME [epoch: 24.8 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3810257325162486		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.3810257325162486 | validation: 0.4506555395663871]
	TIME [epoch: 24.8 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35787035539542483		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.35787035539542483 | validation: 0.25336372621261893]
	TIME [epoch: 24.8 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2749665573596475		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.2749665573596475 | validation: 0.29017568062394306]
	TIME [epoch: 24.8 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2776201163788808		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.2776201163788808 | validation: 0.28309897244027227]
	TIME [epoch: 24.8 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3781601025098652		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.3781601025098652 | validation: 0.4805421427478619]
	TIME [epoch: 24.8 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5810925121420325		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.5810925121420325 | validation: 0.5798140595265471]
	TIME [epoch: 24.8 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4999966351810147		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.4999966351810147 | validation: 0.4289547756416694]
	TIME [epoch: 24.8 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4129539010363119		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.4129539010363119 | validation: 0.42711552784809687]
	TIME [epoch: 24.8 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42009810299949246		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.42009810299949246 | validation: 0.3333307453360365]
	TIME [epoch: 24.8 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3093740609251074		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.3093740609251074 | validation: 0.3028151119018745]
	TIME [epoch: 24.8 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3104837595187074		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.3104837595187074 | validation: 0.2689762744104969]
	TIME [epoch: 24.8 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28609708506042125		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.28609708506042125 | validation: 0.2506864078199646]
	TIME [epoch: 24.8 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2525285170115012		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.2525285170115012 | validation: 0.24001937363969453]
	TIME [epoch: 24.8 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2585789013965793		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.2585789013965793 | validation: 0.2491978964823015]
	TIME [epoch: 24.8 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2624445674395576		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.2624445674395576 | validation: 0.25653645293087196]
	TIME [epoch: 24.8 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24845424430259838		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.24845424430259838 | validation: 0.2351943891896273]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_750.pth
	Model improved!!!
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24957681157669462		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.24957681157669462 | validation: 0.2644123046470535]
	TIME [epoch: 24.8 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3507439495807987		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.3507439495807987 | validation: 0.49336196506756425]
	TIME [epoch: 24.8 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5137231724473089		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.5137231724473089 | validation: 0.4569221080372051]
	TIME [epoch: 24.8 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.367488957475026		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.367488957475026 | validation: 0.25202534759134854]
	TIME [epoch: 24.8 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25504610848369974		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.25504610848369974 | validation: 0.23998768858560973]
	TIME [epoch: 24.8 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24490432223459108		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.24490432223459108 | validation: 0.24253071204458188]
	TIME [epoch: 24.8 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26577460205856585		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.26577460205856585 | validation: 0.2418990472767068]
	TIME [epoch: 24.8 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24518032562332237		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.24518032562332237 | validation: 0.2283723220451217]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r4_20240309_135747/states/model_tr_study6_758.pth
	Model improved!!!
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23912485297588937		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.23912485297588937 | validation: 0.26549375044719886]
	TIME [epoch: 24.8 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.346483907830423		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.346483907830423 | validation: 0.3424642333836488]
	TIME [epoch: 24.8 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36182917523378466		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.36182917523378466 | validation: 0.3113914073590162]
	TIME [epoch: 24.8 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28758882096221067		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.28758882096221067 | validation: 0.2729619170695362]
	TIME [epoch: 24.8 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3325118063851897		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.3325118063851897 | validation: 0.34443675408866425]
	TIME [epoch: 24.8 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30298196987400583		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.30298196987400583 | validation: 0.3068845853775551]
	TIME [epoch: 24.8 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3494205011046675		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.3494205011046675 | validation: 0.37448984569327565]
	TIME [epoch: 24.8 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47858961727730165		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.47858961727730165 | validation: 0.5098177184805092]
	TIME [epoch: 24.8 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42860089533220447		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.42860089533220447 | validation: 0.3541958963014419]
	TIME [epoch: 24.8 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31940673688660487		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.31940673688660487 | validation: 0.31388860578338035]
	TIME [epoch: 24.8 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34202528182269487		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.34202528182269487 | validation: 0.31841314842738727]
	TIME [epoch: 24.8 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29980818111123364		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.29980818111123364 | validation: 0.26653993363925754]
	TIME [epoch: 24.8 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2915523967631753		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.2915523967631753 | validation: 0.2930076492147343]
	TIME [epoch: 24.8 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31492330693470005		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.31492330693470005 | validation: 0.3206742312563717]
	TIME [epoch: 24.8 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30458586707084545		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.30458586707084545 | validation: 0.2872012102891634]
	TIME [epoch: 24.8 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28448808861393227		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.28448808861393227 | validation: 0.267427127168899]
	TIME [epoch: 24.8 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29120619286188065		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.29120619286188065 | validation: 0.3615258523671229]
	TIME [epoch: 24.8 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31997367995617565		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.31997367995617565 | validation: 0.28910293413667265]
	TIME [epoch: 24.8 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29203460109142976		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.29203460109142976 | validation: 0.32736439976400844]
	TIME [epoch: 24.8 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33498150609281824		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.33498150609281824 | validation: 0.3410500664648147]
	TIME [epoch: 24.8 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32197188095551765		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.32197188095551765 | validation: 0.3194465433576806]
	TIME [epoch: 24.8 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30698664194163516		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.30698664194163516 | validation: 0.2970704123039409]
	TIME [epoch: 24.8 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3013361152995362		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.3013361152995362 | validation: 0.36120946122143155]
	TIME [epoch: 24.8 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36436523047406943		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.36436523047406943 | validation: 0.3812379071803476]
	TIME [epoch: 24.8 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3619415811584724		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.3619415811584724 | validation: 0.27840654238957463]
	TIME [epoch: 24.8 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2802018519597931		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.2802018519597931 | validation: 0.2914706847733947]
	TIME [epoch: 24.8 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28752071264306706		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.28752071264306706 | validation: 0.2797457209557467]
	TIME [epoch: 24.8 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2921015680617819		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.2921015680617819 | validation: 0.2936664450850977]
	TIME [epoch: 24.8 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29371476166613764		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.29371476166613764 | validation: 0.254744171310185]
	TIME [epoch: 24.8 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2642443509126194		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.2642443509126194 | validation: 0.2759784603452358]
	TIME [epoch: 24.8 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.292565770195655		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.292565770195655 | validation: 0.2736909965017407]
	TIME [epoch: 24.8 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27272408538228815		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.27272408538228815 | validation: 0.39294468074314]
	TIME [epoch: 24.8 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41904159646729633		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.41904159646729633 | validation: 0.3986584446067419]
	TIME [epoch: 24.8 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3670712506046202		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.3670712506046202 | validation: 0.3323466836971369]
	TIME [epoch: 24.8 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3183656981701362		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.3183656981701362 | validation: 0.32059202474728915]
	TIME [epoch: 24.8 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30340194927317277		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.30340194927317277 | validation: 0.30032376758162505]
	TIME [epoch: 24.8 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36280962623302804		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.36280962623302804 | validation: 0.4262627220826152]
	TIME [epoch: 24.8 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3512896666962329		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.3512896666962329 | validation: 0.2780298486207839]
	TIME [epoch: 24.8 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28996067199999787		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.28996067199999787 | validation: 0.31734227342299487]
	TIME [epoch: 24.8 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3544221292879278		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.3544221292879278 | validation: 0.3278797474656122]
	TIME [epoch: 24.8 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30935347918161127		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.30935347918161127 | validation: 0.30867203386046166]
	TIME [epoch: 24.9 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29349893451226833		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.29349893451226833 | validation: 0.29022499788913714]
	TIME [epoch: 24.8 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30424850547372156		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.30424850547372156 | validation: 0.30138052960984346]
	TIME [epoch: 24.8 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2864475152435296		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.2864475152435296 | validation: 0.2924042002562714]
	TIME [epoch: 24.8 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2761854262013886		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.2761854262013886 | validation: 0.2694690961642083]
	TIME [epoch: 24.8 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27674692556146563		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.27674692556146563 | validation: 0.29830522446235486]
	TIME [epoch: 24.8 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2854116924986103		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.2854116924986103 | validation: 0.26065244754335054]
	TIME [epoch: 24.8 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.274127810184927		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.274127810184927 | validation: 0.2671228114449914]
	TIME [epoch: 24.8 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26762264627510446		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.26762264627510446 | validation: 0.28038939447391126]
	TIME [epoch: 24.8 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2966346069151688		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.2966346069151688 | validation: 0.2704702836751963]
	TIME [epoch: 24.8 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26685868154043585		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.26685868154043585 | validation: 0.2987377845249266]
	TIME [epoch: 24.8 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2851693461063573		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.2851693461063573 | validation: 0.24984412794210137]
	TIME [epoch: 24.8 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.260232114808739		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.260232114808739 | validation: 0.2910080593835979]
	TIME [epoch: 24.8 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30758493764639006		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.30758493764639006 | validation: 0.3273382269731079]
	TIME [epoch: 24.8 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3428749914120504		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.3428749914120504 | validation: 0.4243510438173397]
	TIME [epoch: 24.8 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4973335000794654		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.4973335000794654 | validation: 0.4183725044763897]
	TIME [epoch: 24.8 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36555132932517825		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.36555132932517825 | validation: 0.30797029282076405]
	TIME [epoch: 24.8 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28419781007283834		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.28419781007283834 | validation: 0.29326263415827375]
	TIME [epoch: 24.8 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28796726149843		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.28796726149843 | validation: 0.27348252948733515]
	TIME [epoch: 24.8 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2747476239342336		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.2747476239342336 | validation: 0.27909653856267863]
	TIME [epoch: 24.8 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3230448697903194		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.3230448697903194 | validation: 0.4148893238065236]
	TIME [epoch: 24.8 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4473626479695168		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.4473626479695168 | validation: 0.40528599829397466]
	TIME [epoch: 24.8 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3433229976686262		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.3433229976686262 | validation: 0.3141411112969925]
	TIME [epoch: 24.8 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31385443996079393		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.31385443996079393 | validation: 0.30617558590054544]
	TIME [epoch: 24.8 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31397950551621645		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.31397950551621645 | validation: 0.33553988220386893]
	TIME [epoch: 24.8 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3113465183153093		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.3113465183153093 | validation: 0.3090436611744192]
	TIME [epoch: 24.8 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2998494116694933		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.2998494116694933 | validation: 0.27368046928166845]
	TIME [epoch: 24.8 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2745269711423655		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.2745269711423655 | validation: 0.3073590298310131]
	TIME [epoch: 24.8 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3006968507771226		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.3006968507771226 | validation: 0.27371516303762056]
	TIME [epoch: 24.8 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.286320659740338		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.286320659740338 | validation: 0.2624405535948906]
	TIME [epoch: 24.8 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25764461253833165		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.25764461253833165 | validation: 0.24338575005863364]
	TIME [epoch: 24.8 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2637086409859852		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.2637086409859852 | validation: 0.27087291823529436]
	TIME [epoch: 24.8 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.291080953695518		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.291080953695518 | validation: 0.305948557613576]
	TIME [epoch: 24.8 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.292407515719587		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.292407515719587 | validation: 0.2639958376512172]
	TIME [epoch: 24.8 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2666957105076543		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.2666957105076543 | validation: 0.24722759534442718]
	TIME [epoch: 24.8 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25759277704291905		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.25759277704291905 | validation: 0.23363710095809637]
	TIME [epoch: 24.8 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24462029879173508		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.24462029879173508 | validation: 0.23939460532515214]
	TIME [epoch: 24.8 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2527514258927522		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.2527514258927522 | validation: 0.24607423862487476]
	TIME [epoch: 24.8 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26590232210701314		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.26590232210701314 | validation: 0.2894260635289853]
	TIME [epoch: 24.8 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2910848634508698		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.2910848634508698 | validation: 0.24350516944625875]
	TIME [epoch: 24.8 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2587351327288351		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.2587351327288351 | validation: 0.2467840394545673]
	TIME [epoch: 24.8 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25219935973816376		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.25219935973816376 | validation: 0.264676171282606]
	TIME [epoch: 24.8 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29142905842042105		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.29142905842042105 | validation: 0.2827488142055332]
	TIME [epoch: 24.8 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30362807848455553		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.30362807848455553 | validation: 0.33525705075863527]
	TIME [epoch: 24.8 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3008900901932723		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.3008900901932723 | validation: 0.2513598810190524]
	TIME [epoch: 24.8 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2515010598105338		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.2515010598105338 | validation: 0.2393748185206691]
	TIME [epoch: 24.8 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24985871274211496		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.24985871274211496 | validation: 0.22912524338127874]
	TIME [epoch: 24.8 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24789734079622439		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.24789734079622439 | validation: 0.24109803440479866]
	TIME [epoch: 24.8 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25349543199448726		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.25349543199448726 | validation: 0.2432831744614679]
	TIME [epoch: 24.8 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2618144867365954		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.2618144867365954 | validation: 0.27226731375730434]
	TIME [epoch: 24.8 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30794718582046016		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.30794718582046016 | validation: 0.24828823801861455]
	TIME [epoch: 24.8 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2535242822231364		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.2535242822231364 | validation: 0.23644120494276674]
	TIME [epoch: 24.8 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24267625283913596		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.24267625283913596 | validation: 0.2313876265862509]
	TIME [epoch: 24.8 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25849845048102893		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.25849845048102893 | validation: 0.3103423974602661]
	TIME [epoch: 24.8 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3682403103430754		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.3682403103430754 | validation: 0.39821847380846964]
	TIME [epoch: 24.8 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4751982128575104		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.4751982128575104 | validation: 0.3802538658614023]
	TIME [epoch: 24.8 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.334419051002389		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.334419051002389 | validation: 0.2813633571155367]
	TIME [epoch: 24.8 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29941243418695457		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.29941243418695457 | validation: 0.2740394078504976]
	TIME [epoch: 24.8 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28788063298887734		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.28788063298887734 | validation: 0.27215952617389216]
	TIME [epoch: 24.8 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27626187833095533		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.27626187833095533 | validation: 0.32373722078110784]
	TIME [epoch: 24.8 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4367956667913676		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.4367956667913676 | validation: 0.3880090399875343]
	TIME [epoch: 24.8 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3294664186124849		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.3294664186124849 | validation: 0.24931044069953764]
	TIME [epoch: 24.8 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2573951214301331		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.2573951214301331 | validation: 0.2482572570269091]
	TIME [epoch: 24.8 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25091268959898905		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.25091268959898905 | validation: 0.2395117157240756]
	TIME [epoch: 24.8 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27329905611832667		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.27329905611832667 | validation: 0.2801251405397487]
	TIME [epoch: 24.8 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2999110408064104		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.2999110408064104 | validation: 0.2804434567044594]
	TIME [epoch: 24.8 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.279949125832539		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.279949125832539 | validation: 0.24745170469740813]
	TIME [epoch: 24.8 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26756567675314		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.26756567675314 | validation: 0.25252933450916765]
	TIME [epoch: 24.8 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2557588702712358		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.2557588702712358 | validation: 0.2684211304173866]
	TIME [epoch: 24.8 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2766499471339762		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.2766499471339762 | validation: 0.2656061070954083]
	TIME [epoch: 24.8 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27328205018453144		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.27328205018453144 | validation: 0.30887056531948404]
	TIME [epoch: 24.8 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31089945163151556		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.31089945163151556 | validation: 0.28650732215068503]
	TIME [epoch: 24.8 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28277943224181024		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.28277943224181024 | validation: 0.2504051632075354]
	TIME [epoch: 24.8 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2576539013581909		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.2576539013581909 | validation: 0.2330092024755991]
	TIME [epoch: 24.8 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2560152614040917		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.2560152614040917 | validation: 0.2529291397542234]
	TIME [epoch: 24.8 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2755840894599381		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.2755840894599381 | validation: 0.2452850673207228]
	TIME [epoch: 24.8 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26367893116797314		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.26367893116797314 | validation: 0.2902243531476053]
	TIME [epoch: 24.8 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27984277573334926		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.27984277573334926 | validation: 0.2588650408458228]
	TIME [epoch: 24.8 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26044574664699066		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.26044574664699066 | validation: 0.26212804817336516]
	TIME [epoch: 24.8 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2663541966815161		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.2663541966815161 | validation: 0.2439844164612155]
	TIME [epoch: 24.8 sec]
EPOCH 879/2000:
	Training over batches...
