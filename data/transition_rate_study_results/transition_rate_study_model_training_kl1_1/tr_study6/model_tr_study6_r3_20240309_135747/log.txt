Args:
Namespace(name='model_tr_study6', outdir='out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3', training_data='data/transition_rate_studies/tr_study6/tr_study6_training/r3', validation_data='data/transition_rate_studies/tr_study6/tr_study6_validation/r3', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 115540899

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.559093468681513		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.559093468681513 | validation: 5.4760987712482185]
	TIME [epoch: 113 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.367289263578327		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.367289263578327 | validation: 5.294386075408493]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.796591066086132		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.796591066086132 | validation: 4.303918152017621]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.412989971138999		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.412989971138999 | validation: 4.113525619012982]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.691788494476045		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.691788494476045 | validation: 4.712021923654791]
	TIME [epoch: 24.8 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.094090989650608		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.094090989650608 | validation: 3.691316450243536]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7955391227519186		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7955391227519186 | validation: 3.5844753507016627]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.749622744853432		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.749622744853432 | validation: 4.286150324553553]
	TIME [epoch: 24.9 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7571910511425517		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7571910511425517 | validation: 3.4591396291937615]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7502504182898044		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7502504182898044 | validation: 3.734605092154615]
	TIME [epoch: 24.9 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5567779459251057		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5567779459251057 | validation: 3.2845682389214317]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3732039768322646		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3732039768322646 | validation: 3.9875520857589244]
	TIME [epoch: 24.9 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.543271406728498		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.543271406728498 | validation: 3.364617150560612]
	TIME [epoch: 24.9 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4758851460446336		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4758851460446336 | validation: 3.205337415410183]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8179170432896985		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8179170432896985 | validation: 3.513229121767286]
	TIME [epoch: 24.9 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.616881066588938		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.616881066588938 | validation: 3.3045182716335995]
	TIME [epoch: 24.8 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.521992320347651		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.521992320347651 | validation: 3.235890274754794]
	TIME [epoch: 24.9 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3720646187273204		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3720646187273204 | validation: 3.591677561348368]
	TIME [epoch: 24.9 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2696595219056097		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2696595219056097 | validation: 3.319203190819197]
	TIME [epoch: 24.8 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1441869099252893		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1441869099252893 | validation: 3.2131946455280374]
	TIME [epoch: 24.9 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1065157212220593		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1065157212220593 | validation: 4.993865455675374]
	TIME [epoch: 24.9 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.4150232902663795		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.4150232902663795 | validation: 3.8513572112158876]
	TIME [epoch: 24.8 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7564179982498827		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7564179982498827 | validation: 3.245273258683564]
	TIME [epoch: 24.9 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2342038123348105		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2342038123348105 | validation: 3.097828734501619]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1889512762437384		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1889512762437384 | validation: 2.9011125287164647]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1327392532642975		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1327392532642975 | validation: 3.1363589872672697]
	TIME [epoch: 24.8 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1473323783806366		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1473323783806366 | validation: 2.967222522550898]
	TIME [epoch: 24.8 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1804871598247155		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1804871598247155 | validation: 3.10550258029799]
	TIME [epoch: 24.8 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4611925615884807		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4611925615884807 | validation: 3.7197902683374777]
	TIME [epoch: 24.8 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.677113037343661		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.677113037343661 | validation: 3.2510692124147558]
	TIME [epoch: 24.8 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.172356364258374		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.172356364258374 | validation: 3.8074311891506536]
	TIME [epoch: 24.8 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.4270221313479965		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.4270221313479965 | validation: 5.448006683427785]
	TIME [epoch: 24.8 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6430578072597006		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6430578072597006 | validation: 3.1051416720805003]
	TIME [epoch: 24.8 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0893729873240976		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0893729873240976 | validation: 2.861514167449156]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9845889348677197		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9845889348677197 | validation: 2.829467213490303]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.317873454178187		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.317873454178187 | validation: 3.363462959111207]
	TIME [epoch: 24.9 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9905729980263063		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9905729980263063 | validation: 2.821889111585702]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.297232535191756		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.297232535191756 | validation: 3.1211449074228175]
	TIME [epoch: 24.8 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.304760891397115		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.304760891397115 | validation: 3.7988527343205285]
	TIME [epoch: 24.9 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.306928569778499		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.306928569778499 | validation: 2.669877495108326]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8644148005487278		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8644148005487278 | validation: 2.5724971664572234]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0100671876150216		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0100671876150216 | validation: 3.0826657563369606]
	TIME [epoch: 24.8 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8956313469167125		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8956313469167125 | validation: 3.9005826615385377]
	TIME [epoch: 24.8 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.767393104666975		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.767393104666975 | validation: 4.5156520230204436]
	TIME [epoch: 24.8 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7812638048276774		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7812638048276774 | validation: 2.8592780466889436]
	TIME [epoch: 24.8 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.351331954566623		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.351331954566623 | validation: 4.364957775301686]
	TIME [epoch: 24.8 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.912316744868592		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.912316744868592 | validation: 3.0397295562707884]
	TIME [epoch: 24.8 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.432599944905861		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.432599944905861 | validation: 3.044803289803757]
	TIME [epoch: 24.8 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4780646504904693		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4780646504904693 | validation: 2.590413929133086]
	TIME [epoch: 24.8 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6682248385241625		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6682248385241625 | validation: 5.410332267816367]
	TIME [epoch: 24.8 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.739738708010386		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 3.739738708010386 | validation: 2.5957136648705905]
	TIME [epoch: 24.8 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.694516764485641		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 2.694516764485641 | validation: 2.9441113874080385]
	TIME [epoch: 24.8 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.147441159983419		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 3.147441159983419 | validation: 2.8148265899944778]
	TIME [epoch: 24.8 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.916947159331061		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 2.916947159331061 | validation: 2.703670639617116]
	TIME [epoch: 24.8 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.45206572697463		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 3.45206572697463 | validation: 3.9833244243369412]
	TIME [epoch: 24.8 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.479339770660501		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 3.479339770660501 | validation: 3.2473411109469077]
	TIME [epoch: 24.8 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1430685376634298		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 3.1430685376634298 | validation: 2.78163367071556]
	TIME [epoch: 24.8 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.763433846341449		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 2.763433846341449 | validation: 3.1299029301767396]
	TIME [epoch: 24.8 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.055900820236182		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 3.055900820236182 | validation: 2.8042989903479363]
	TIME [epoch: 24.8 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.717586863686409		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 2.717586863686409 | validation: 2.525207823685604]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.981537074443663		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 4.981537074443663 | validation: 7.962955186838342]
	TIME [epoch: 24.8 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.713629705638473		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 5.713629705638473 | validation: 2.7286956501917055]
	TIME [epoch: 24.8 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.103004870574143		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 3.103004870574143 | validation: 2.975938542653042]
	TIME [epoch: 24.8 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.530318579989284		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 3.530318579989284 | validation: 4.802331375003048]
	TIME [epoch: 24.8 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.85443087510768		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 4.85443087510768 | validation: 4.2006391771357405]
	TIME [epoch: 24.9 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5748385966573286		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 3.5748385966573286 | validation: 2.9428479937527348]
	TIME [epoch: 24.8 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0342604776190534		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 3.0342604776190534 | validation: 3.1187239854557594]
	TIME [epoch: 24.8 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0048776838605225		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 3.0048776838605225 | validation: 3.2113675086805564]
	TIME [epoch: 24.9 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0473036898707315		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 4.0473036898707315 | validation: 3.5134407496616507]
	TIME [epoch: 24.8 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1710101177479673		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 3.1710101177479673 | validation: 2.5863190066278277]
	TIME [epoch: 24.8 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.156325305403006		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 3.156325305403006 | validation: 4.511883899604004]
	TIME [epoch: 24.9 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.014290082651037		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 4.014290082651037 | validation: 2.968796110367388]
	TIME [epoch: 24.9 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.954990382580182		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 2.954990382580182 | validation: 2.651608187578511]
	TIME [epoch: 24.8 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.777367199226777		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 2.777367199226777 | validation: 2.6039079279617443]
	TIME [epoch: 24.8 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7912122922392566		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 2.7912122922392566 | validation: 2.7028202892915965]
	TIME [epoch: 24.9 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7062987328027015		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 2.7062987328027015 | validation: 2.5261120607442407]
	TIME [epoch: 24.8 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.514689543749112		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 2.514689543749112 | validation: 2.3284590249629216]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6237758672113514		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 2.6237758672113514 | validation: 3.011477188750654]
	TIME [epoch: 24.9 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.199434565103453		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 3.199434565103453 | validation: 2.8244716132066783]
	TIME [epoch: 24.8 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.909269598459815		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 2.909269598459815 | validation: 2.5037085946]
	TIME [epoch: 24.9 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3994382440745174		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 2.3994382440745174 | validation: 2.33693414484291]
	TIME [epoch: 24.8 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5381415561556393		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 2.5381415561556393 | validation: 2.3776123437611716]
	TIME [epoch: 24.8 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.701370893333303		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 2.701370893333303 | validation: 2.4432147292800503]
	TIME [epoch: 24.8 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.497547910659223		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 2.497547910659223 | validation: 2.4958392082646683]
	TIME [epoch: 24.8 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.497025574497819		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 2.497025574497819 | validation: 2.9971779719031053]
	TIME [epoch: 24.9 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.636303016100353		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 2.636303016100353 | validation: 2.388712802178375]
	TIME [epoch: 24.8 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.317558178421627		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 2.317558178421627 | validation: 2.369288701352181]
	TIME [epoch: 24.8 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.395352445839299		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 2.395352445839299 | validation: 2.4094923830295416]
	TIME [epoch: 24.8 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0183362785515757		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 3.0183362785515757 | validation: 2.182645266151875]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_89.pth
	Model improved!!!
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4852411969680817		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 2.4852411969680817 | validation: 2.6755550556082133]
	TIME [epoch: 24.9 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8132973403551462		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 2.8132973403551462 | validation: 3.6419561265667997]
	TIME [epoch: 24.8 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7783422445661667		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 2.7783422445661667 | validation: 2.4335552521668316]
	TIME [epoch: 24.8 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.251425695660831		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 2.251425695660831 | validation: 1.9702940819941257]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_93.pth
	Model improved!!!
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4116776459363		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 2.4116776459363 | validation: 2.66505122217539]
	TIME [epoch: 24.9 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.354300811753857		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 2.354300811753857 | validation: 1.9577594991821587]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_95.pth
	Model improved!!!
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.244738891915199		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 2.244738891915199 | validation: 2.2753096097273224]
	TIME [epoch: 24.9 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1678133816737155		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 2.1678133816737155 | validation: 2.293588139535448]
	TIME [epoch: 24.9 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.190468297260966		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 2.190468297260966 | validation: 2.098584295061288]
	TIME [epoch: 24.9 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9893209377872552		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 1.9893209377872552 | validation: 2.44011862838762]
	TIME [epoch: 24.9 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3186397682305375		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 2.3186397682305375 | validation: 1.7644496306184407]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_100.pth
	Model improved!!!
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0661351756555706		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 2.0661351756555706 | validation: 4.090438827648416]
	TIME [epoch: 24.9 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.887876729931275		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 2.887876729931275 | validation: 2.3337866133184857]
	TIME [epoch: 24.9 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0998104958296366		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 2.0998104958296366 | validation: 2.030225796351295]
	TIME [epoch: 24.9 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4536445596627416		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 2.4536445596627416 | validation: 2.079041049754571]
	TIME [epoch: 24.9 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2455134659432723		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 2.2455134659432723 | validation: 3.1451988709970546]
	TIME [epoch: 24.9 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.551362136361339		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 2.551362136361339 | validation: 2.2832844953198204]
	TIME [epoch: 24.8 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1216580558384557		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 2.1216580558384557 | validation: 2.1476259635887875]
	TIME [epoch: 24.9 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.021164802648778		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 2.021164802648778 | validation: 2.524275444007632]
	TIME [epoch: 24.9 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.227737538721006		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 2.227737538721006 | validation: 1.7059967704968921]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_109.pth
	Model improved!!!
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.549081801181231		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 2.549081801181231 | validation: 3.887489782922222]
	TIME [epoch: 24.8 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.75992610908734		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 2.75992610908734 | validation: 2.6632911276619327]
	TIME [epoch: 24.9 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9931046234794616		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 2.9931046234794616 | validation: 2.9367805123009028]
	TIME [epoch: 24.9 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9590557949977905		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 2.9590557949977905 | validation: 2.6257584582612976]
	TIME [epoch: 24.9 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4381552441599474		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 3.4381552441599474 | validation: 2.554593883985996]
	TIME [epoch: 24.9 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8497406762936257		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 2.8497406762936257 | validation: 2.3745822749076657]
	TIME [epoch: 24.9 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.379296161674587		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 2.379296161674587 | validation: 2.0070122110943474]
	TIME [epoch: 24.9 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3239863100104357		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 2.3239863100104357 | validation: 3.1074206284838723]
	TIME [epoch: 24.8 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1518622672110794		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 2.1518622672110794 | validation: 2.1938225287979547]
	TIME [epoch: 24.9 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9656424852143732		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 1.9656424852143732 | validation: 1.6787202197886633]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_119.pth
	Model improved!!!
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7737563379743009		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 1.7737563379743009 | validation: 1.6535409890864219]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_120.pth
	Model improved!!!
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.61344540522238		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 1.61344540522238 | validation: 1.5636180900173322]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_121.pth
	Model improved!!!
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5930828458422381		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 1.5930828458422381 | validation: 1.4357628400318527]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_122.pth
	Model improved!!!
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5728852582938027		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 1.5728852582938027 | validation: 2.5321825269711637]
	TIME [epoch: 24.8 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6473201144136036		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 2.6473201144136036 | validation: 4.462898970836689]
	TIME [epoch: 24.8 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.681401431953597		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 4.681401431953597 | validation: 1.785161552377175]
	TIME [epoch: 24.8 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.205741752827635		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 2.205741752827635 | validation: 2.6842121279802846]
	TIME [epoch: 24.9 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.782350532248682		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 2.782350532248682 | validation: 3.410120469704858]
	TIME [epoch: 24.8 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3323433158013285		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 3.3323433158013285 | validation: 1.9564324535342539]
	TIME [epoch: 24.8 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.215149447688643		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 2.215149447688643 | validation: 2.6753148006933425]
	TIME [epoch: 24.8 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.239674383574149		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 2.239674383574149 | validation: 1.732497334989368]
	TIME [epoch: 24.8 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7018222071764912		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 1.7018222071764912 | validation: 2.225008494374139]
	TIME [epoch: 24.8 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.063933179430519		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 2.063933179430519 | validation: 2.1190716108447085]
	TIME [epoch: 24.8 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7105355859814297		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 1.7105355859814297 | validation: 1.6062153695420092]
	TIME [epoch: 24.9 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6342019084289512		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 1.6342019084289512 | validation: 1.414041560519465]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_134.pth
	Model improved!!!
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5146308667351802		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 1.5146308667351802 | validation: 1.4050777059094832]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_135.pth
	Model improved!!!
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4796961140440104		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 1.4796961140440104 | validation: 1.2500831536571522]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_136.pth
	Model improved!!!
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3457943345925245		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 1.3457943345925245 | validation: 1.2270378936258246]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_137.pth
	Model improved!!!
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.625899030421059		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 1.625899030421059 | validation: 1.482757161515101]
	TIME [epoch: 24.8 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3648426697648808		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 1.3648426697648808 | validation: 1.2798460915038632]
	TIME [epoch: 24.8 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.004694749660218		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 2.004694749660218 | validation: 1.9304046963424961]
	TIME [epoch: 24.9 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1811682375977295		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 2.1811682375977295 | validation: 1.223372468651274]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_141.pth
	Model improved!!!
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2913135778740057		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 1.2913135778740057 | validation: 1.439773532407285]
	TIME [epoch: 24.8 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3748648940262236		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 1.3748648940262236 | validation: 1.3288803358013304]
	TIME [epoch: 24.9 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2566558825802945		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 1.2566558825802945 | validation: 1.1375714496045632]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_144.pth
	Model improved!!!
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6021251892239732		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 1.6021251892239732 | validation: 1.7893391901753068]
	TIME [epoch: 24.8 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.65253162251938		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 1.65253162251938 | validation: 1.2066452470858555]
	TIME [epoch: 24.8 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.326458953361869		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 1.326458953361869 | validation: 1.0504494058702687]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_147.pth
	Model improved!!!
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.219481477233652		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 1.219481477233652 | validation: 3.959743089370055]
	TIME [epoch: 24.8 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1765337280647077		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 2.1765337280647077 | validation: 1.6331580577493103]
	TIME [epoch: 24.8 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4456310760499893		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 1.4456310760499893 | validation: 1.5242393369796037]
	TIME [epoch: 24.8 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3362440374667375		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 1.3362440374667375 | validation: 1.2234251780005252]
	TIME [epoch: 24.8 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5347073267933835		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 1.5347073267933835 | validation: 1.5331399506983214]
	TIME [epoch: 24.8 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2750180230173227		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 1.2750180230173227 | validation: 1.325150229292612]
	TIME [epoch: 24.8 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4319825188869892		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 1.4319825188869892 | validation: 1.8117139171287073]
	TIME [epoch: 24.8 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4192647081702057		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 1.4192647081702057 | validation: 1.1763458845629695]
	TIME [epoch: 24.8 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.413243209042262		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 2.413243209042262 | validation: 2.604471356188971]
	TIME [epoch: 24.8 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.309958894978354		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 2.309958894978354 | validation: 2.862639846397187]
	TIME [epoch: 24.8 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7507495698493847		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 1.7507495698493847 | validation: 1.183557144110892]
	TIME [epoch: 24.8 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3503088316588017		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 1.3503088316588017 | validation: 1.278398551837637]
	TIME [epoch: 24.8 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2960040362174183		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 1.2960040362174183 | validation: 1.1017028381411513]
	TIME [epoch: 24.8 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0839057594139527		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 1.0839057594139527 | validation: 1.0949153442080701]
	TIME [epoch: 24.8 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.047342743545649		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 1.047342743545649 | validation: 1.0940868174083425]
	TIME [epoch: 24.8 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0611297124615533		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 1.0611297124615533 | validation: 1.1471357371752087]
	TIME [epoch: 24.8 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0797885518524943		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 1.0797885518524943 | validation: 1.0354877772741513]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_164.pth
	Model improved!!!
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7392289322643508		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 1.7392289322643508 | validation: 1.8113689947003813]
	TIME [epoch: 24.8 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2957570419385938		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 1.2957570419385938 | validation: 1.7965210102048343]
	TIME [epoch: 24.8 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2362325485366816		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 1.2362325485366816 | validation: 1.0089586374049233]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_167.pth
	Model improved!!!
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9273923481971982		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.9273923481971982 | validation: 1.1108820215644244]
	TIME [epoch: 24.8 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.985095005121599		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.985095005121599 | validation: 1.1085299688891224]
	TIME [epoch: 24.8 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.071544231353665		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 1.071544231353665 | validation: 1.4251251638237]
	TIME [epoch: 24.8 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4539242048529364		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 1.4539242048529364 | validation: 1.7596667398197259]
	TIME [epoch: 24.7 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2504560660457098		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 1.2504560660457098 | validation: 1.1174323755449438]
	TIME [epoch: 24.8 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.973253410668359		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.973253410668359 | validation: 1.0201035416561848]
	TIME [epoch: 24.8 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1558287523663768		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 1.1558287523663768 | validation: 1.4691255098047118]
	TIME [epoch: 24.8 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2983642651554663		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 1.2983642651554663 | validation: 1.0460778901755339]
	TIME [epoch: 24.8 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9695487304239324		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 0.9695487304239324 | validation: 1.0359050157130634]
	TIME [epoch: 24.9 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0536743960010428		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 1.0536743960010428 | validation: 1.3193968264726095]
	TIME [epoch: 24.8 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6299299511295609		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 1.6299299511295609 | validation: 1.1443252673332036]
	TIME [epoch: 24.8 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.013057088669313		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 1.013057088669313 | validation: 0.9902253647544537]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_179.pth
	Model improved!!!
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8559190267093589		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.8559190267093589 | validation: 1.0938264647038045]
	TIME [epoch: 24.8 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8978882119813869		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.8978882119813869 | validation: 0.8652890656650684]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_181.pth
	Model improved!!!
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8858100667477311		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.8858100667477311 | validation: 0.9157047084546486]
	TIME [epoch: 24.8 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8960020487508409		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.8960020487508409 | validation: 1.0319290262978726]
	TIME [epoch: 24.8 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9720821023558156		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.9720821023558156 | validation: 0.8983424095741606]
	TIME [epoch: 24.8 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1118882127763774		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 1.1118882127763774 | validation: 1.1390425380919869]
	TIME [epoch: 24.8 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0403466364855265		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 1.0403466364855265 | validation: 0.9653373921271657]
	TIME [epoch: 24.8 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9160757177905836		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.9160757177905836 | validation: 1.0283213723359383]
	TIME [epoch: 24.8 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8304192820062933		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.8304192820062933 | validation: 0.8034613367331784]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_188.pth
	Model improved!!!
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8680674770583734		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.8680674770583734 | validation: 0.9340797843458253]
	TIME [epoch: 24.8 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8026893164615655		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.8026893164615655 | validation: 0.7796522330426287]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_190.pth
	Model improved!!!
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8641874295415075		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.8641874295415075 | validation: 0.8120549067564296]
	TIME [epoch: 24.8 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7809214238854759		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.7809214238854759 | validation: 0.6875485325817381]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_192.pth
	Model improved!!!
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8793312276575035		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.8793312276575035 | validation: 1.1764145215214226]
	TIME [epoch: 24.9 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.162924843317017		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 1.162924843317017 | validation: 0.8178894088013475]
	TIME [epoch: 24.8 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5117531386744387		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 1.5117531386744387 | validation: 1.5267681620276223]
	TIME [epoch: 24.8 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2218184014982025		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 1.2218184014982025 | validation: 0.862945040572966]
	TIME [epoch: 24.8 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8301900760095906		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.8301900760095906 | validation: 0.9024612045601554]
	TIME [epoch: 24.9 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.811870636457533		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.811870636457533 | validation: 0.8874955658864668]
	TIME [epoch: 24.8 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7954834054330612		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.7954834054330612 | validation: 0.7545631893300455]
	TIME [epoch: 24.8 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7780432125485531		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.7780432125485531 | validation: 0.8250728100865539]
	TIME [epoch: 24.8 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0391867551355227		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 1.0391867551355227 | validation: 0.7941259358564144]
	TIME [epoch: 24.9 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8597279548954693		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.8597279548954693 | validation: 1.0334911900082773]
	TIME [epoch: 24.9 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.893374195471677		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.893374195471677 | validation: 1.4075173388480229]
	TIME [epoch: 24.8 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9706047758060741		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.9706047758060741 | validation: 0.7470744597721688]
	TIME [epoch: 24.8 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.783571943184462		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.783571943184462 | validation: 0.7536206272924564]
	TIME [epoch: 24.9 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6857712900329601		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.6857712900329601 | validation: 0.8791603968350574]
	TIME [epoch: 24.8 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8478548371558379		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.8478548371558379 | validation: 0.7208886752348624]
	TIME [epoch: 24.8 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7331846116303481		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.7331846116303481 | validation: 0.774751839255072]
	TIME [epoch: 24.9 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7337150094734526		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.7337150094734526 | validation: 0.7220609552212833]
	TIME [epoch: 24.9 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9628504486635855		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.9628504486635855 | validation: 1.1622396639927426]
	TIME [epoch: 24.8 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9930221908080764		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.9930221908080764 | validation: 0.8083847201142692]
	TIME [epoch: 24.8 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7622694688369807		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.7622694688369807 | validation: 0.7560810045528922]
	TIME [epoch: 24.8 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7558931391673448		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.7558931391673448 | validation: 1.0019910792926376]
	TIME [epoch: 24.8 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1205879689682305		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 1.1205879689682305 | validation: 0.8559013553372847]
	TIME [epoch: 24.8 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7987347134095668		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.7987347134095668 | validation: 1.371482456697181]
	TIME [epoch: 24.8 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0145173190371726		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 1.0145173190371726 | validation: 0.9189951301202156]
	TIME [epoch: 24.8 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8309816087298764		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.8309816087298764 | validation: 0.7681532198986212]
	TIME [epoch: 24.8 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8162072208127131		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.8162072208127131 | validation: 0.8678479092767699]
	TIME [epoch: 24.8 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.003170270375744		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 1.003170270375744 | validation: 0.9607889948890211]
	TIME [epoch: 24.8 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7246779088421571		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.7246779088421571 | validation: 0.7907077463925589]
	TIME [epoch: 24.8 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.820291488124437		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.820291488124437 | validation: 0.9701913205057671]
	TIME [epoch: 24.8 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9594781441610014		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.9594781441610014 | validation: 0.7979739801208189]
	TIME [epoch: 24.8 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6831497872247689		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.6831497872247689 | validation: 0.758479554178944]
	TIME [epoch: 24.8 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6837889625025835		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.6837889625025835 | validation: 0.5382814241669533]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_224.pth
	Model improved!!!
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1060129777971985		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 1.1060129777971985 | validation: 0.7085462676215698]
	TIME [epoch: 24.8 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6615233343978267		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.6615233343978267 | validation: 0.569560268867448]
	TIME [epoch: 24.9 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6587800911994846		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.6587800911994846 | validation: 0.924247409235571]
	TIME [epoch: 24.8 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7333108355858992		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.7333108355858992 | validation: 0.7386298178287717]
	TIME [epoch: 24.8 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6576531425468828		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.6576531425468828 | validation: 0.6160000779443215]
	TIME [epoch: 24.9 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7340797567074859		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.7340797567074859 | validation: 0.6453320737014338]
	TIME [epoch: 24.9 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6641164160390618		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.6641164160390618 | validation: 1.351259747119815]
	TIME [epoch: 24.9 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0207392628463408		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 1.0207392628463408 | validation: 0.5991346095749347]
	TIME [epoch: 24.8 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5906056750451999		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.5906056750451999 | validation: 0.8662108863342097]
	TIME [epoch: 24.9 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8074656301702894		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.8074656301702894 | validation: 1.3578008260857257]
	TIME [epoch: 24.9 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0706484058566117		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 1.0706484058566117 | validation: 0.7453802904770184]
	TIME [epoch: 24.8 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6824709033998885		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.6824709033998885 | validation: 0.7007935249220649]
	TIME [epoch: 24.8 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6399887262931464		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.6399887262931464 | validation: 0.668617071678144]
	TIME [epoch: 24.9 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6201700298339047		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.6201700298339047 | validation: 0.7184125432005298]
	TIME [epoch: 24.9 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.661725490728436		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.661725490728436 | validation: 0.6964796561410885]
	TIME [epoch: 24.8 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7816315969806087		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 1.7816315969806087 | validation: 1.5671765430678368]
	TIME [epoch: 24.9 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0673848389888714		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 1.0673848389888714 | validation: 1.2634361754984422]
	TIME [epoch: 24.9 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3355514827528328		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 1.3355514827528328 | validation: 1.2745612104378752]
	TIME [epoch: 24.8 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8981273127091546		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.8981273127091546 | validation: 0.7464377760310525]
	TIME [epoch: 24.8 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6530955123857298		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.6530955123857298 | validation: 0.7891708507588553]
	TIME [epoch: 24.9 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1763939335071043		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 1.1763939335071043 | validation: 0.8658549227816903]
	TIME [epoch: 24.9 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6568363262261538		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.6568363262261538 | validation: 0.5981961263889426]
	TIME [epoch: 24.8 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.148575359800689		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 1.148575359800689 | validation: 1.1472910501329883]
	TIME [epoch: 24.9 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8392607707693476		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.8392607707693476 | validation: 0.746677693961084]
	TIME [epoch: 24.9 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8114806527858479		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.8114806527858479 | validation: 0.6644968014387536]
	TIME [epoch: 24.8 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6320507614067952		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.6320507614067952 | validation: 0.6450429724285072]
	TIME [epoch: 24.8 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.566624602627743		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.566624602627743 | validation: 0.6855800548811977]
	TIME [epoch: 24.9 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6022793642557589		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.6022793642557589 | validation: 0.877100577284564]
	TIME [epoch: 24.9 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8026293593607177		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.8026293593607177 | validation: 0.6668914740925547]
	TIME [epoch: 24.8 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8048749255994625		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.8048749255994625 | validation: 0.5341153294117135]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_254.pth
	Model improved!!!
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6853721824797252		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.6853721824797252 | validation: 0.722401168514728]
	TIME [epoch: 24.9 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8231221920514402		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.8231221920514402 | validation: 0.960373371273503]
	TIME [epoch: 25.1 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7268536876793774		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.7268536876793774 | validation: 0.596433559078847]
	TIME [epoch: 24.8 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.868513652528071		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.868513652528071 | validation: 1.1353889923493035]
	TIME [epoch: 24.8 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9597663695932802		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.9597663695932802 | validation: 0.6020367497742103]
	TIME [epoch: 24.8 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6152295655343291		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.6152295655343291 | validation: 0.8407783484215]
	TIME [epoch: 24.8 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1582141086110098		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 1.1582141086110098 | validation: 1.5078181510130446]
	TIME [epoch: 24.8 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0273802265601173		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 1.0273802265601173 | validation: 0.7706036111008737]
	TIME [epoch: 24.8 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6303669900887467		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.6303669900887467 | validation: 0.802481010691983]
	TIME [epoch: 24.8 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7878874335786121		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.7878874335786121 | validation: 0.5728536427820023]
	TIME [epoch: 24.8 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9149352045275116		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.9149352045275116 | validation: 1.517833911663646]
	TIME [epoch: 24.8 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0886904897720415		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 1.0886904897720415 | validation: 0.6616856164338168]
	TIME [epoch: 24.8 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6102958279102051		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.6102958279102051 | validation: 0.5427599104290848]
	TIME [epoch: 24.8 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6024014039934177		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.6024014039934177 | validation: 0.7948287105021897]
	TIME [epoch: 24.8 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8704740909942622		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.8704740909942622 | validation: 0.738025930641135]
	TIME [epoch: 24.8 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6944912867234314		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.6944912867234314 | validation: 0.5414254857186707]
	TIME [epoch: 24.8 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4926233649381019		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.4926233649381019 | validation: 0.5255542650917129]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_271.pth
	Model improved!!!
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7058532319987172		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.7058532319987172 | validation: 1.4606691784583206]
	TIME [epoch: 24.8 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.942486651350747		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.942486651350747 | validation: 0.6682261631528192]
	TIME [epoch: 24.8 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5331782969165043		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.5331782969165043 | validation: 0.5018703613828204]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_274.pth
	Model improved!!!
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7236823157243112		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.7236823157243112 | validation: 0.5988854663462503]
	TIME [epoch: 24.8 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5445932260579835		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.5445932260579835 | validation: 0.5669887646157004]
	TIME [epoch: 24.8 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6319343459446591		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.6319343459446591 | validation: 0.65147531610648]
	TIME [epoch: 24.8 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6354157032270795		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.6354157032270795 | validation: 0.8575528710984418]
	TIME [epoch: 24.8 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7410034170132342		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.7410034170132342 | validation: 0.5164719090983696]
	TIME [epoch: 24.8 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49077382636089023		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.49077382636089023 | validation: 0.577787462301172]
	TIME [epoch: 24.8 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6983609872491751		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.6983609872491751 | validation: 0.7846299880755049]
	TIME [epoch: 24.8 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7317856586852775		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.7317856586852775 | validation: 0.5416095790706008]
	TIME [epoch: 24.8 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5314718811247782		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.5314718811247782 | validation: 0.6064818593858551]
	TIME [epoch: 24.8 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5647490373203706		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.5647490373203706 | validation: 0.512193553410161]
	TIME [epoch: 24.8 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6691255886866264		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.6691255886866264 | validation: 0.8520916112845184]
	TIME [epoch: 24.8 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6497666056559996		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.6497666056559996 | validation: 0.6116780621359048]
	TIME [epoch: 24.8 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0958839948301469		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 1.0958839948301469 | validation: 1.1533948034172543]
	TIME [epoch: 24.8 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9302355179835348		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.9302355179835348 | validation: 0.5471815544638962]
	TIME [epoch: 24.8 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7176408799816273		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.7176408799816273 | validation: 1.1081482391058828]
	TIME [epoch: 24.8 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8288780159698089		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.8288780159698089 | validation: 0.8827779195789591]
	TIME [epoch: 24.8 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7023471377418151		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.7023471377418151 | validation: 0.6650494253288196]
	TIME [epoch: 24.8 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9866476729297113		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.9866476729297113 | validation: 1.2380599370248593]
	TIME [epoch: 24.8 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8552712479225544		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.8552712479225544 | validation: 0.5224065487483371]
	TIME [epoch: 24.8 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5049431329611651		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.5049431329611651 | validation: 0.5048782190520071]
	TIME [epoch: 24.8 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47471788026149375		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.47471788026149375 | validation: 0.5201802397171723]
	TIME [epoch: 24.8 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4713875021591817		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.4713875021591817 | validation: 0.48583321380588146]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_296.pth
	Model improved!!!
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5682427550921421		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.5682427550921421 | validation: 0.6394428053971959]
	TIME [epoch: 24.8 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.531137711815672		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.531137711815672 | validation: 0.5000949119034624]
	TIME [epoch: 24.8 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.711797847142949		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.711797847142949 | validation: 0.7596313610597218]
	TIME [epoch: 24.8 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.715692739691365		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.715692739691365 | validation: 0.5449324440640555]
	TIME [epoch: 24.8 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5405094425420397		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.5405094425420397 | validation: 0.602700368190005]
	TIME [epoch: 24.8 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6224464471596316		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.6224464471596316 | validation: 1.2036688302867637]
	TIME [epoch: 24.8 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0036556805576764		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 1.0036556805576764 | validation: 0.7620016096957931]
	TIME [epoch: 24.8 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6974265592665781		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.6974265592665781 | validation: 0.6736609219436099]
	TIME [epoch: 24.8 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5848339932071331		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.5848339932071331 | validation: 0.5075746037223228]
	TIME [epoch: 24.8 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5713922837932436		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.5713922837932436 | validation: 0.5548802701851971]
	TIME [epoch: 24.8 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5245248164988965		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.5245248164988965 | validation: 0.711475878702082]
	TIME [epoch: 24.8 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6261190969077063		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.6261190969077063 | validation: 0.9270026394828972]
	TIME [epoch: 24.8 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8132862498256559		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.8132862498256559 | validation: 0.8448199267847327]
	TIME [epoch: 24.8 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6272417880043002		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.6272417880043002 | validation: 0.49014717561414795]
	TIME [epoch: 24.8 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5026676888827618		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.5026676888827618 | validation: 0.5229054467343883]
	TIME [epoch: 24.8 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7665447215371048		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.7665447215371048 | validation: 0.5279814607717422]
	TIME [epoch: 24.8 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5423246083430757		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.5423246083430757 | validation: 0.6147160957717868]
	TIME [epoch: 24.8 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5402450133000191		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.5402450133000191 | validation: 0.5050630405787553]
	TIME [epoch: 24.8 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6574112105830643		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.6574112105830643 | validation: 0.7830414351922901]
	TIME [epoch: 24.8 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6530564628816227		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.6530564628816227 | validation: 0.5172740507779862]
	TIME [epoch: 24.8 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5669850964156394		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.5669850964156394 | validation: 0.6884920207915355]
	TIME [epoch: 24.7 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6979249876961923		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.6979249876961923 | validation: 0.8087919947814932]
	TIME [epoch: 24.8 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6868299875741257		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.6868299875741257 | validation: 0.5269328729317073]
	TIME [epoch: 24.8 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4729623749344248		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.4729623749344248 | validation: 0.6202143094145708]
	TIME [epoch: 24.8 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6083768915586782		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.6083768915586782 | validation: 0.7222795994991621]
	TIME [epoch: 24.8 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6215362842242323		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.6215362842242323 | validation: 0.8524674742699528]
	TIME [epoch: 24.8 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7195684750473893		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.7195684750473893 | validation: 0.47204166605336634]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_323.pth
	Model improved!!!
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49039712729179125		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.49039712729179125 | validation: 0.6890225720647379]
	TIME [epoch: 24.8 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.58534020147925		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.58534020147925 | validation: 0.5432180218527879]
	TIME [epoch: 24.8 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5966867826302537		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.5966867826302537 | validation: 0.5477250284407529]
	TIME [epoch: 24.8 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6409488224270916		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.6409488224270916 | validation: 0.7368390647721093]
	TIME [epoch: 24.8 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.722267363517619		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.722267363517619 | validation: 0.6238492226406167]
	TIME [epoch: 24.8 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5796099157769706		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.5796099157769706 | validation: 0.6224439634677679]
	TIME [epoch: 24.8 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.555759438769698		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.555759438769698 | validation: 0.6584321247587579]
	TIME [epoch: 24.8 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8851750390360102		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.8851750390360102 | validation: 0.8611309702195817]
	TIME [epoch: 24.8 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7073627180676577		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.7073627180676577 | validation: 0.5797850764044982]
	TIME [epoch: 24.8 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6198173991835305		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.6198173991835305 | validation: 0.6007461343267267]
	TIME [epoch: 24.8 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8489286689628399		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.8489286689628399 | validation: 0.7179596839101744]
	TIME [epoch: 24.8 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6167250537947369		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.6167250537947369 | validation: 0.6288278793826264]
	TIME [epoch: 24.8 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6329000753601087		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.6329000753601087 | validation: 0.691152775207759]
	TIME [epoch: 24.8 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7179146797907843		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.7179146797907843 | validation: 0.6090466418338742]
	TIME [epoch: 24.8 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5597525911404418		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.5597525911404418 | validation: 0.7478382066044881]
	TIME [epoch: 24.8 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7163796038972395		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.7163796038972395 | validation: 0.6363198334576474]
	TIME [epoch: 24.8 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6914054577010552		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.6914054577010552 | validation: 0.6322487539705411]
	TIME [epoch: 24.8 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6507134767798397		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.6507134767798397 | validation: 0.6040856095542637]
	TIME [epoch: 24.8 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5824280290700048		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.5824280290700048 | validation: 0.5451193339657037]
	TIME [epoch: 24.7 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6130755492672774		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.6130755492672774 | validation: 0.5207343982839354]
	TIME [epoch: 24.8 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5441551573140354		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.5441551573140354 | validation: 0.719874949941922]
	TIME [epoch: 24.8 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9921443195215929		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.9921443195215929 | validation: 0.812961012276366]
	TIME [epoch: 24.8 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8986829584155305		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.8986829584155305 | validation: 0.7635986478115774]
	TIME [epoch: 24.8 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6536020562643473		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.6536020562643473 | validation: 0.5707532263216012]
	TIME [epoch: 24.8 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6970896392073629		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.6970896392073629 | validation: 0.5780583534408147]
	TIME [epoch: 24.8 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7742745471355268		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.7742745471355268 | validation: 0.5935406704309705]
	TIME [epoch: 24.7 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5724756837834287		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.5724756837834287 | validation: 0.6271347017799681]
	TIME [epoch: 24.8 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5593205074929751		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.5593205074929751 | validation: 0.615093439704695]
	TIME [epoch: 24.8 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6091012703802208		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.6091012703802208 | validation: 1.153754884943824]
	TIME [epoch: 24.8 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0291895910295872		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 1.0291895910295872 | validation: 0.6532766906751561]
	TIME [epoch: 24.8 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6629963501716041		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.6629963501716041 | validation: 0.6431981267788901]
	TIME [epoch: 24.8 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6140076287372433		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.6140076287372433 | validation: 0.664894737551525]
	TIME [epoch: 24.8 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6138411386194653		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.6138411386194653 | validation: 0.5506080915935625]
	TIME [epoch: 24.7 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7030321656669514		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.7030321656669514 | validation: 1.0555435881908501]
	TIME [epoch: 24.8 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9552068557843345		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.9552068557843345 | validation: 0.6415088220914228]
	TIME [epoch: 24.8 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5576716990994547		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.5576716990994547 | validation: 0.5321169978745212]
	TIME [epoch: 24.8 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5664151648506909		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.5664151648506909 | validation: 0.5624053903663131]
	TIME [epoch: 24.8 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5936274344370892		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.5936274344370892 | validation: 0.6942330061397088]
	TIME [epoch: 24.8 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6180996664640971		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.6180996664640971 | validation: 0.5608953765954013]
	TIME [epoch: 24.8 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5684559309592504		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.5684559309592504 | validation: 0.5016934400326146]
	TIME [epoch: 24.7 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48493046131876055		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.48493046131876055 | validation: 0.4903143370869819]
	TIME [epoch: 24.8 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4976025993055626		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.4976025993055626 | validation: 0.4949504542897218]
	TIME [epoch: 24.8 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.495863728317673		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.495863728317673 | validation: 0.512933964090808]
	TIME [epoch: 24.8 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5400522582170973		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.5400522582170973 | validation: 0.5994697303403379]
	TIME [epoch: 24.8 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5682652195186808		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.5682652195186808 | validation: 0.9525031643115847]
	TIME [epoch: 24.8 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8769773062087038		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.8769773062087038 | validation: 0.5577656810525986]
	TIME [epoch: 24.8 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.609492210796011		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.609492210796011 | validation: 0.5873574671288964]
	TIME [epoch: 24.7 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5650743743445006		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.5650743743445006 | validation: 0.491776546952953]
	TIME [epoch: 24.8 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5887699753030794		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.5887699753030794 | validation: 0.5280849117384377]
	TIME [epoch: 24.8 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5246003106693258		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.5246003106693258 | validation: 0.5995699753074843]
	TIME [epoch: 24.8 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5478513834066786		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.5478513834066786 | validation: 0.4696620279749713]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_374.pth
	Model improved!!!
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5278604676511548		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.5278604676511548 | validation: 0.6539607443408909]
	TIME [epoch: 24.8 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5021372734108465		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.5021372734108465 | validation: 0.5466449139123705]
	TIME [epoch: 24.8 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6104580399185445		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.6104580399185445 | validation: 0.6480667240891657]
	TIME [epoch: 24.8 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8285574829707261		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.8285574829707261 | validation: 0.6544846933503135]
	TIME [epoch: 24.8 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5436198231114919		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.5436198231114919 | validation: 0.45505480417022115]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_379.pth
	Model improved!!!
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47872553909111915		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.47872553909111915 | validation: 0.5129723708148595]
	TIME [epoch: 24.8 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5377069815168909		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.5377069815168909 | validation: 0.5891709346126704]
	TIME [epoch: 24.7 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5324930971642188		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.5324930971642188 | validation: 0.44795075786125005]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_382.pth
	Model improved!!!
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44532195867570146		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.44532195867570146 | validation: 0.4004268518835469]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_383.pth
	Model improved!!!
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4179418824750644		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.4179418824750644 | validation: 0.40115218157600824]
	TIME [epoch: 24.8 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4416480240193485		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.4416480240193485 | validation: 0.49679703785358603]
	TIME [epoch: 24.8 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4937692789874435		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.4937692789874435 | validation: 0.49336044741991736]
	TIME [epoch: 24.8 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4909658874245526		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.4909658874245526 | validation: 0.48217239651978033]
	TIME [epoch: 24.8 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4454812225938833		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.4454812225938833 | validation: 0.4854519837015465]
	TIME [epoch: 24.7 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43629710759017837		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.43629710759017837 | validation: 0.47006728876368314]
	TIME [epoch: 24.8 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5263073663955393		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.5263073663955393 | validation: 0.49860715043766035]
	TIME [epoch: 24.8 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6837408514576626		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.6837408514576626 | validation: 0.7368352995729777]
	TIME [epoch: 24.8 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6292446918343154		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.6292446918343154 | validation: 0.554406722729373]
	TIME [epoch: 24.8 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4703527899342743		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.4703527899342743 | validation: 0.4342506879839486]
	TIME [epoch: 24.8 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43257420510838646		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.43257420510838646 | validation: 0.4349819033623993]
	TIME [epoch: 24.8 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4198582153879387		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.4198582153879387 | validation: 0.47897205664965214]
	TIME [epoch: 24.7 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6130407955100889		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.6130407955100889 | validation: 0.5418963688476951]
	TIME [epoch: 24.8 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5723073475812064		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.5723073475812064 | validation: 0.5613970667346766]
	TIME [epoch: 24.8 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6163024434184212		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.6163024434184212 | validation: 0.5776442130532969]
	TIME [epoch: 24.8 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4976534116962624		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.4976534116962624 | validation: 0.48917642247505216]
	TIME [epoch: 24.8 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5064382512429112		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.5064382512429112 | validation: 0.5914802212339171]
	TIME [epoch: 24.8 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5955407317273489		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.5955407317273489 | validation: 0.6290816695990554]
	TIME [epoch: 24.8 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6159381164771364		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.6159381164771364 | validation: 0.5018955437802577]
	TIME [epoch: 24.8 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5126443647157287		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.5126443647157287 | validation: 0.5465165128886623]
	TIME [epoch: 24.8 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5147695450716158		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.5147695450716158 | validation: 0.5144241017626486]
	TIME [epoch: 24.8 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5238935683267333		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.5238935683267333 | validation: 0.5171901618209711]
	TIME [epoch: 24.8 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45159091143479313		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.45159091143479313 | validation: 0.4218783145075847]
	TIME [epoch: 24.7 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5641060738082094		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.5641060738082094 | validation: 0.7925120712106228]
	TIME [epoch: 24.8 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9951926657225433		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.9951926657225433 | validation: 0.6660278145116507]
	TIME [epoch: 24.8 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7172266310787858		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.7172266310787858 | validation: 0.8928902857812377]
	TIME [epoch: 24.7 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8036919600302597		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.8036919600302597 | validation: 0.6674824020813059]
	TIME [epoch: 24.8 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5340955229248281		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.5340955229248281 | validation: 0.4577367913318984]
	TIME [epoch: 24.8 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6879857886719557		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.6879857886719557 | validation: 1.0439992226793597]
	TIME [epoch: 24.8 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0698419451917145		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 1.0698419451917145 | validation: 0.6523497903229054]
	TIME [epoch: 24.7 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6383633530888584		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.6383633530888584 | validation: 0.5947667412964817]
	TIME [epoch: 24.8 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6089576768093967		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.6089576768093967 | validation: 0.659030923711407]
	TIME [epoch: 24.8 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8093300992581344		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.8093300992581344 | validation: 0.7204710494025537]
	TIME [epoch: 24.8 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.668290421566048		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.668290421566048 | validation: 0.637462704631586]
	TIME [epoch: 24.8 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.590340580236885		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.590340580236885 | validation: 0.448394816729291]
	TIME [epoch: 24.8 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5329830901805608		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.5329830901805608 | validation: 0.5218362749048808]
	TIME [epoch: 24.8 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5001127481894966		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.5001127481894966 | validation: 0.5608757469112196]
	TIME [epoch: 24.7 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5772943961503367		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.5772943961503367 | validation: 0.7265945896699421]
	TIME [epoch: 24.8 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7086894401850641		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.7086894401850641 | validation: 0.7408979925132677]
	TIME [epoch: 24.8 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6252615796003922		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.6252615796003922 | validation: 0.5833388146835754]
	TIME [epoch: 24.8 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48216246839899574		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.48216246839899574 | validation: 0.5209387188528208]
	TIME [epoch: 24.8 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48419653614903074		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.48419653614903074 | validation: 0.5417516676359945]
	TIME [epoch: 24.8 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4972703598048418		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.4972703598048418 | validation: 0.6183625431223431]
	TIME [epoch: 24.8 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6718447402076475		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.6718447402076475 | validation: 0.5379592970021266]
	TIME [epoch: 24.7 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6015285855878146		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.6015285855878146 | validation: 0.5381843102396409]
	TIME [epoch: 24.8 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6109116843533863		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.6109116843533863 | validation: 0.6316930860635263]
	TIME [epoch: 24.8 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5814773800675099		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.5814773800675099 | validation: 0.4713882905168935]
	TIME [epoch: 24.8 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.511983656708524		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.511983656708524 | validation: 0.5050026897433033]
	TIME [epoch: 24.8 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4921684034263344		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.4921684034263344 | validation: 0.5003022649874121]
	TIME [epoch: 24.8 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5441067216195234		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.5441067216195234 | validation: 0.6544721208806693]
	TIME [epoch: 24.8 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6820383083050547		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.6820383083050547 | validation: 0.6463603754487671]
	TIME [epoch: 24.7 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5976299708830026		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.5976299708830026 | validation: 0.5421200992710626]
	TIME [epoch: 24.8 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49655129924654084		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.49655129924654084 | validation: 0.5095499088197392]
	TIME [epoch: 24.8 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5409979851815859		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.5409979851815859 | validation: 0.6197385097877508]
	TIME [epoch: 24.8 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6551415155226818		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.6551415155226818 | validation: 0.6312665307899925]
	TIME [epoch: 24.7 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6586025948184349		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.6586025948184349 | validation: 0.573715309244494]
	TIME [epoch: 24.8 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7900157716200757		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.7900157716200757 | validation: 0.7054811027239434]
	TIME [epoch: 24.8 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6130621444490696		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.6130621444490696 | validation: 0.5774544907340556]
	TIME [epoch: 24.7 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.532360750390402		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.532360750390402 | validation: 0.537001040904557]
	TIME [epoch: 24.8 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5219530067995619		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.5219530067995619 | validation: 0.48620456369171616]
	TIME [epoch: 24.8 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5332083908725807		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.5332083908725807 | validation: 0.46988783658076744]
	TIME [epoch: 24.8 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4502448842056275		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.4502448842056275 | validation: 0.4830961240498827]
	TIME [epoch: 24.7 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6877779876375845		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.6877779876375845 | validation: 0.7734609075289826]
	TIME [epoch: 24.8 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6712926902318654		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.6712926902318654 | validation: 0.47343122356950007]
	TIME [epoch: 24.8 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4618442798087535		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.4618442798087535 | validation: 0.4787722370022657]
	TIME [epoch: 24.7 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47049040838939554		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.47049040838939554 | validation: 0.5025840085441302]
	TIME [epoch: 24.8 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4722524092811835		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.4722524092811835 | validation: 0.441586549554226]
	TIME [epoch: 24.8 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5629636993149176		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.5629636993149176 | validation: 0.6198194367525202]
	TIME [epoch: 24.8 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5890354055588958		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.5890354055588958 | validation: 0.46485036844726246]
	TIME [epoch: 24.7 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4578057310795688		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.4578057310795688 | validation: 0.47069787280238823]
	TIME [epoch: 24.8 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48120844277462266		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.48120844277462266 | validation: 0.46002909814709525]
	TIME [epoch: 24.8 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5182577285755331		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.5182577285755331 | validation: 0.4789349001140545]
	TIME [epoch: 24.8 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47582480345706357		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.47582480345706357 | validation: 0.48123313435630255]
	TIME [epoch: 24.8 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45253270074757573		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.45253270074757573 | validation: 0.4680466804666422]
	TIME [epoch: 24.8 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6212909652135635		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.6212909652135635 | validation: 0.7334531685818175]
	TIME [epoch: 24.8 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.827579793808764		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.827579793808764 | validation: 0.7632031970745]
	TIME [epoch: 24.7 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7641063774997345		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.7641063774997345 | validation: 0.5373750926723421]
	TIME [epoch: 24.8 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4905942225942177		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.4905942225942177 | validation: 0.4781323231038841]
	TIME [epoch: 24.8 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45372039884456117		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.45372039884456117 | validation: 0.49390141301863194]
	TIME [epoch: 24.7 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.472689319459073		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.472689319459073 | validation: 0.480025602359527]
	TIME [epoch: 24.8 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4359582721564212		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.4359582721564212 | validation: 0.450524626397055]
	TIME [epoch: 24.8 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47423454432016077		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.47423454432016077 | validation: 0.52056381312961]
	TIME [epoch: 24.8 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4893966444573366		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.4893966444573366 | validation: 0.472910635166332]
	TIME [epoch: 24.7 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5258582863918091		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.5258582863918091 | validation: 0.452427721419503]
	TIME [epoch: 24.8 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4513135665674523		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.4513135665674523 | validation: 0.4878837456715057]
	TIME [epoch: 24.8 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4727309543805683		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.4727309543805683 | validation: 0.44431764492092113]
	TIME [epoch: 24.7 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5157614834394171		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.5157614834394171 | validation: 0.6566216279995644]
	TIME [epoch: 24.8 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9299366611877562		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.9299366611877562 | validation: 0.7229768998010203]
	TIME [epoch: 24.8 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6084758036090699		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.6084758036090699 | validation: 0.521644062342083]
	TIME [epoch: 24.8 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47802160401357247		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.47802160401357247 | validation: 0.448282642152606]
	TIME [epoch: 24.7 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49147341993787386		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.49147341993787386 | validation: 0.5773275059406765]
	TIME [epoch: 24.8 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5269457334520292		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.5269457334520292 | validation: 0.544071715261946]
	TIME [epoch: 24.8 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6206551897779081		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.6206551897779081 | validation: 0.688698382347171]
	TIME [epoch: 24.8 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6833415160702991		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.6833415160702991 | validation: 0.7120920828016033]
	TIME [epoch: 24.8 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6756493976156184		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.6756493976156184 | validation: 0.6941689392427535]
	TIME [epoch: 24.8 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5843451994084121		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.5843451994084121 | validation: 0.5455245252734264]
	TIME [epoch: 24.8 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5029221558820652		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.5029221558820652 | validation: 0.5179924439902717]
	TIME [epoch: 24.7 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5680755285628011		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.5680755285628011 | validation: 0.5449207207906775]
	TIME [epoch: 24.8 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5315582497988558		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.5315582497988558 | validation: 0.5765877496117592]
	TIME [epoch: 24.8 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5727450004027947		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.5727450004027947 | validation: 0.41546737907866077]
	TIME [epoch: 24.7 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4303857557079401		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.4303857557079401 | validation: 0.47044013279235086]
	TIME [epoch: 24.8 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45739498013880586		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.45739498013880586 | validation: 0.593686105152722]
	TIME [epoch: 24.8 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6298280403201266		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.6298280403201266 | validation: 0.6773072937738681]
	TIME [epoch: 24.8 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6239024238511656		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.6239024238511656 | validation: 0.6712804073645355]
	TIME [epoch: 24.7 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5918168213869656		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.5918168213869656 | validation: 0.5665362783706107]
	TIME [epoch: 24.8 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.526089145978407		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.526089145978407 | validation: 0.5045742921834572]
	TIME [epoch: 24.8 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48759625747294966		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.48759625747294966 | validation: 0.48682766398993194]
	TIME [epoch: 24.8 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4791884341514217		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.4791884341514217 | validation: 0.5708592865630782]
	TIME [epoch: 24.8 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5061938001386173		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.5061938001386173 | validation: 0.6150467639308068]
	TIME [epoch: 24.8 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5714653580681481		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.5714653580681481 | validation: 0.6202261795911952]
	TIME [epoch: 24.8 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5655017825009503		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.5655017825009503 | validation: 0.5226725029030211]
	TIME [epoch: 24.7 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49277143273310603		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.49277143273310603 | validation: 0.48912308364828977]
	TIME [epoch: 24.8 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6056137209935538		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.6056137209935538 | validation: 0.6008936396186121]
	TIME [epoch: 24.8 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5484655876439617		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.5484655876439617 | validation: 0.4487254788515487]
	TIME [epoch: 24.8 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4727244684178336		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.4727244684178336 | validation: 0.4808331147587752]
	TIME [epoch: 24.8 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4869141555553103		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.4869141555553103 | validation: 0.6146099275798386]
	TIME [epoch: 24.8 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5176238491827891		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.5176238491827891 | validation: 0.5246105311723138]
	TIME [epoch: 24.8 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4872233384477406		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.4872233384477406 | validation: 0.4723700129600154]
	TIME [epoch: 24.7 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5556895007554024		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.5556895007554024 | validation: 0.5841073730119546]
	TIME [epoch: 24.8 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6694660084540727		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.6694660084540727 | validation: 0.5086788802700847]
	TIME [epoch: 24.8 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.478010657366875		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.478010657366875 | validation: 0.5753610403651284]
	TIME [epoch: 24.8 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5315662117104226		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.5315662117104226 | validation: 0.4249603244310535]
	TIME [epoch: 24.8 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40972254180813883		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.40972254180813883 | validation: 0.5181236821760218]
	TIME [epoch: 24.8 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5468691390103013		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.5468691390103013 | validation: 0.6281248824294473]
	TIME [epoch: 24.8 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5967271669955553		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.5967271669955553 | validation: 0.6938840784130761]
	TIME [epoch: 24.8 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.627092097725069		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.627092097725069 | validation: 0.8931424017811992]
	TIME [epoch: 24.8 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7105803489357768		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.7105803489357768 | validation: 0.6062429382236547]
	TIME [epoch: 24.8 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.479588012325083		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.479588012325083 | validation: 0.5047960722281224]
	TIME [epoch: 24.8 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43288721926946344		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.43288721926946344 | validation: 0.4289234307393164]
	TIME [epoch: 24.8 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42545182297192896		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.42545182297192896 | validation: 0.47202873175734467]
	TIME [epoch: 24.8 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4545003544701195		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.4545003544701195 | validation: 0.483419665800037]
	TIME [epoch: 24.8 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48115295935173297		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.48115295935173297 | validation: 0.5374775246503585]
	TIME [epoch: 24.8 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48304719090985687		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.48304719090985687 | validation: 0.5741710222284876]
	TIME [epoch: 24.8 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4745516727652508		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.4745516727652508 | validation: 0.5320368773949941]
	TIME [epoch: 24.8 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47739060389879207		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.47739060389879207 | validation: 0.47453595616183897]
	TIME [epoch: 24.8 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47055619823114797		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.47055619823114797 | validation: 0.5077224407836484]
	TIME [epoch: 24.7 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47200566773601427		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.47200566773601427 | validation: 0.4965635710963629]
	TIME [epoch: 24.8 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5408919875610934		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.5408919875610934 | validation: 0.7732229361766128]
	TIME [epoch: 24.8 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9341999363776003		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.9341999363776003 | validation: 0.7060380876871147]
	TIME [epoch: 24.8 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5703289674107459		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.5703289674107459 | validation: 0.5710252809818677]
	TIME [epoch: 24.8 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5239211781886456		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.5239211781886456 | validation: 0.6812907373800376]
	TIME [epoch: 24.8 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5592468502725149		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.5592468502725149 | validation: 0.5533862878745305]
	TIME [epoch: 24.8 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5177614917644754		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.5177614917644754 | validation: 0.5469615361260077]
	TIME [epoch: 24.7 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4764801838807895		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.4764801838807895 | validation: 0.5871394499907489]
	TIME [epoch: 24.8 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48841365519627267		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.48841365519627267 | validation: 0.692929775544622]
	TIME [epoch: 24.8 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5744764229598422		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.5744764229598422 | validation: 0.576148353694098]
	TIME [epoch: 24.8 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4816540689194977		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.4816540689194977 | validation: 0.5257533579425481]
	TIME [epoch: 24.8 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4982621637690104		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.4982621637690104 | validation: 0.5373504609974118]
	TIME [epoch: 24.8 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4515482792053005		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.4515482792053005 | validation: 0.5180347121566683]
	TIME [epoch: 24.8 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4800559302945372		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.4800559302945372 | validation: 0.5678624632467306]
	TIME [epoch: 24.7 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5150081355663727		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.5150081355663727 | validation: 0.5849090149642028]
	TIME [epoch: 24.8 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5013271510985366		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.5013271510985366 | validation: 0.5356213946183588]
	TIME [epoch: 24.8 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48310774422804026		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.48310774422804026 | validation: 0.553842102167225]
	TIME [epoch: 24.8 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4705507730180546		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.4705507730180546 | validation: 0.5288850403704877]
	TIME [epoch: 24.8 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4628803852451987		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.4628803852451987 | validation: 0.5113203154801825]
	TIME [epoch: 24.8 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48417861850345456		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.48417861850345456 | validation: 0.5410566972741107]
	TIME [epoch: 24.8 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44813367102769697		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.44813367102769697 | validation: 0.5247649950563037]
	TIME [epoch: 24.8 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45271754460630886		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.45271754460630886 | validation: 0.4324197629980914]
	TIME [epoch: 24.8 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42258969336266317		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.42258969336266317 | validation: 0.4420755812578379]
	TIME [epoch: 24.8 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41539350439105205		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.41539350439105205 | validation: 0.4155806147345026]
	TIME [epoch: 24.8 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3962110144083189		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.3962110144083189 | validation: 0.4150542733668204]
	TIME [epoch: 24.8 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4121303055666296		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.4121303055666296 | validation: 0.38415368884649426]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_545.pth
	Model improved!!!
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39586095814109346		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.39586095814109346 | validation: 0.4596569411094469]
	TIME [epoch: 24.8 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4252880773538668		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.4252880773538668 | validation: 0.4716841671190518]
	TIME [epoch: 24.8 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44680820248583936		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.44680820248583936 | validation: 0.4672007324212348]
	TIME [epoch: 24.8 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.418368963526759		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.418368963526759 | validation: 0.3940741809334894]
	TIME [epoch: 24.8 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37202940684356		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.37202940684356 | validation: 0.4393800355122459]
	TIME [epoch: 24.8 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5082389794632592		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.5082389794632592 | validation: 0.4610499458381618]
	TIME [epoch: 24.7 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5456679421938558		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.5456679421938558 | validation: 0.4789414123767385]
	TIME [epoch: 24.8 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5042114415350087		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.5042114415350087 | validation: 0.39464420006304063]
	TIME [epoch: 24.8 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43648251490231527		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.43648251490231527 | validation: 0.4167569087881029]
	TIME [epoch: 24.8 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3990138256497442		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.3990138256497442 | validation: 0.41254056433053765]
	TIME [epoch: 24.8 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.422706070439115		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.422706070439115 | validation: 0.5476420971297644]
	TIME [epoch: 24.8 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4600322939814798		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.4600322939814798 | validation: 0.41648890198839766]
	TIME [epoch: 24.8 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41366385023954905		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.41366385023954905 | validation: 0.4396788844829749]
	TIME [epoch: 24.7 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3996734024507723		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.3996734024507723 | validation: 0.36082062727882297]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_559.pth
	Model improved!!!
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38504872171935567		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.38504872171935567 | validation: 0.40262588264753574]
	TIME [epoch: 24.8 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40769694970519993		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.40769694970519993 | validation: 0.39285589864965004]
	TIME [epoch: 24.8 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4000390700125819		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.4000390700125819 | validation: 0.3978852558184866]
	TIME [epoch: 24.8 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4157744073185628		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.4157744073185628 | validation: 0.431282224321898]
	TIME [epoch: 24.8 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4116324602389001		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.4116324602389001 | validation: 0.3685064951680701]
	TIME [epoch: 24.8 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3958337671271615		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.3958337671271615 | validation: 0.3701627859693542]
	TIME [epoch: 24.8 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37116802103305047		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.37116802103305047 | validation: 0.38980216560784015]
	TIME [epoch: 24.8 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3996679692105728		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.3996679692105728 | validation: 0.36418490938763043]
	TIME [epoch: 24.8 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37129050460087365		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.37129050460087365 | validation: 0.3618741416237033]
	TIME [epoch: 24.8 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36118748437614234		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.36118748437614234 | validation: 0.40847160918764075]
	TIME [epoch: 24.8 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3749024296430989		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.3749024296430989 | validation: 0.4200553753411223]
	TIME [epoch: 24.8 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39237455163161344		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.39237455163161344 | validation: 0.3784298764581859]
	TIME [epoch: 24.8 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36589428120744694		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.36589428120744694 | validation: 0.3549669163609832]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_572.pth
	Model improved!!!
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36565611152470556		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.36565611152470556 | validation: 0.37327140212570037]
	TIME [epoch: 24.8 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40296573887064807		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.40296573887064807 | validation: 0.4120226181291753]
	TIME [epoch: 24.8 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39906638862005617		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.39906638862005617 | validation: 0.3755232081605587]
	TIME [epoch: 24.8 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.387366418807205		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.387366418807205 | validation: 0.3797128358284833]
	TIME [epoch: 24.8 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40040914558177626		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.40040914558177626 | validation: 0.4290435211407534]
	TIME [epoch: 24.8 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48699105619636085		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.48699105619636085 | validation: 0.36409023658787143]
	TIME [epoch: 24.8 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36588366097842895		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.36588366097842895 | validation: 0.3685267739820761]
	TIME [epoch: 24.8 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3627738207851365		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.3627738207851365 | validation: 0.4138028936953364]
	TIME [epoch: 24.8 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39462036189093797		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.39462036189093797 | validation: 0.3579054750957985]
	TIME [epoch: 24.8 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36424907107504645		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.36424907107504645 | validation: 0.37099405121512663]
	TIME [epoch: 24.8 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4945827186992051		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.4945827186992051 | validation: 0.576404426553307]
	TIME [epoch: 24.8 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5213440303693748		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.5213440303693748 | validation: 0.3769126296407866]
	TIME [epoch: 24.8 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35872307215295096		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.35872307215295096 | validation: 0.39188617660027186]
	TIME [epoch: 24.8 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41191366836782106		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.41191366836782106 | validation: 0.40390564521829236]
	TIME [epoch: 24.8 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3538901418345422		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.3538901418345422 | validation: 0.3557723229097578]
	TIME [epoch: 24.8 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34218252662637155		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.34218252662637155 | validation: 0.35161727258981856]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_588.pth
	Model improved!!!
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37526143487573305		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.37526143487573305 | validation: 0.3605287027813079]
	TIME [epoch: 24.8 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.384645216628319		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.384645216628319 | validation: 0.34777775723988924]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_590.pth
	Model improved!!!
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3400677554323018		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.3400677554323018 | validation: 0.3449499135668495]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_591.pth
	Model improved!!!
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3504921884966085		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.3504921884966085 | validation: 0.36473137350459683]
	TIME [epoch: 24.8 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3411738200371581		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.3411738200371581 | validation: 0.3555642877642542]
	TIME [epoch: 24.8 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42695350576812635		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.42695350576812635 | validation: 0.4761392839581034]
	TIME [epoch: 24.8 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4104042537786273		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.4104042537786273 | validation: 0.34384168518053787]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_595.pth
	Model improved!!!
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36038989058024173		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.36038989058024173 | validation: 0.3786226810077902]
	TIME [epoch: 24.8 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.410078990047215		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.410078990047215 | validation: 0.36033486137550436]
	TIME [epoch: 24.7 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3604968688685763		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.3604968688685763 | validation: 0.4073323256023676]
	TIME [epoch: 24.8 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3792366675969057		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.3792366675969057 | validation: 0.3548052738818291]
	TIME [epoch: 24.8 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35176517263290075		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.35176517263290075 | validation: 0.35697732710519847]
	TIME [epoch: 24.8 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37661801890870084		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.37661801890870084 | validation: 0.39502213485854326]
	TIME [epoch: 24.7 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47571705484340476		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.47571705484340476 | validation: 0.4456214647130291]
	TIME [epoch: 24.8 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38194151981659213		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.38194151981659213 | validation: 0.3692509739504583]
	TIME [epoch: 24.8 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3611527156144082		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.3611527156144082 | validation: 0.4483777960440778]
	TIME [epoch: 24.8 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36982940701295236		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.36982940701295236 | validation: 0.4086991720814139]
	TIME [epoch: 24.8 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38843619509584637		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.38843619509584637 | validation: 0.40445433844071743]
	TIME [epoch: 24.8 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38748347261507937		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.38748347261507937 | validation: 0.4682393302165122]
	TIME [epoch: 24.8 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44042210496829415		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.44042210496829415 | validation: 0.4932193274615472]
	TIME [epoch: 24.7 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4616225931006815		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.4616225931006815 | validation: 0.4497355762042439]
	TIME [epoch: 24.8 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40006051699077894		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.40006051699077894 | validation: 0.4414564278789105]
	TIME [epoch: 24.8 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3719182506407348		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.3719182506407348 | validation: 0.39873360030660215]
	TIME [epoch: 24.7 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3643086267520333		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.3643086267520333 | validation: 0.3729058007960073]
	TIME [epoch: 24.8 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3612120166092076		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.3612120166092076 | validation: 0.37078424864277737]
	TIME [epoch: 24.8 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34914403410317346		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.34914403410317346 | validation: 0.35636644788735367]
	TIME [epoch: 24.8 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36021674913693363		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.36021674913693363 | validation: 0.38912183195438166]
	TIME [epoch: 24.7 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3419516435628036		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.3419516435628036 | validation: 0.3340086093359095]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_616.pth
	Model improved!!!
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3296905336037015		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.3296905336037015 | validation: 0.3780927549688795]
	TIME [epoch: 24.8 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33759240746863706		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.33759240746863706 | validation: 0.3367359595281612]
	TIME [epoch: 24.7 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32469668892728565		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.32469668892728565 | validation: 0.3407475272482789]
	TIME [epoch: 24.8 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.343684919008558		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.343684919008558 | validation: 0.38246310443440595]
	TIME [epoch: 24.8 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.380110023537344		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.380110023537344 | validation: 0.47328744546052876]
	TIME [epoch: 24.8 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49707197010822435		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.49707197010822435 | validation: 0.5995794176572282]
	TIME [epoch: 24.7 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48167491274474916		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.48167491274474916 | validation: 0.3995145061147399]
	TIME [epoch: 24.8 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3526500089686044		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.3526500089686044 | validation: 0.34034059037411096]
	TIME [epoch: 24.8 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31733226433567535		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.31733226433567535 | validation: 0.35549532897866315]
	TIME [epoch: 24.7 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34475321903364947		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.34475321903364947 | validation: 0.3717196000215279]
	TIME [epoch: 24.8 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3682400586847141		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.3682400586847141 | validation: 0.443700271975922]
	TIME [epoch: 24.8 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3782601542411089		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.3782601542411089 | validation: 0.4197979427060355]
	TIME [epoch: 24.8 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3922478139199048		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.3922478139199048 | validation: 0.5131978305353243]
	TIME [epoch: 24.7 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4106105407484023		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.4106105407484023 | validation: 0.37998375902064363]
	TIME [epoch: 24.8 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3270150598896607		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.3270150598896607 | validation: 0.37196302965017347]
	TIME [epoch: 24.8 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.340511472253318		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.340511472253318 | validation: 0.35875220584872614]
	TIME [epoch: 24.8 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32204141636203937		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.32204141636203937 | validation: 0.3553402435608156]
	TIME [epoch: 24.7 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35207919810036187		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.35207919810036187 | validation: 0.4319555343792794]
	TIME [epoch: 24.8 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3938891904326803		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.3938891904326803 | validation: 0.41945325728112454]
	TIME [epoch: 24.8 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3623639707501851		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.3623639707501851 | validation: 0.40006420988095726]
	TIME [epoch: 24.7 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36376875421618554		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.36376875421618554 | validation: 0.3611241157127893]
	TIME [epoch: 24.8 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3405541375437981		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.3405541375437981 | validation: 0.35006113509386266]
	TIME [epoch: 24.8 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37004170104396156		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.37004170104396156 | validation: 0.32807297192546253]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_639.pth
	Model improved!!!
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3352688596675149		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.3352688596675149 | validation: 0.3788143859909158]
	TIME [epoch: 24.8 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4496924101716069		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.4496924101716069 | validation: 0.4125271937159238]
	TIME [epoch: 24.8 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.455507414124073		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.455507414124073 | validation: 0.3971959610452613]
	TIME [epoch: 24.8 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40207693174487635		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.40207693174487635 | validation: 0.3563675603607696]
	TIME [epoch: 24.8 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33229255754617004		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.33229255754617004 | validation: 0.3114998559083177]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_644.pth
	Model improved!!!
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32508004283015246		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.32508004283015246 | validation: 0.318209407574251]
	TIME [epoch: 24.8 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.329195821636352		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.329195821636352 | validation: 0.35267434630758915]
	TIME [epoch: 24.8 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3326904072901049		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.3326904072901049 | validation: 0.3611180892538119]
	TIME [epoch: 24.7 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3222605315749024		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.3222605315749024 | validation: 0.30679819357896826]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_648.pth
	Model improved!!!
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3195680591676128		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.3195680591676128 | validation: 0.32844115802394647]
	TIME [epoch: 24.8 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31955059480829456		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.31955059480829456 | validation: 0.31688376207067004]
	TIME [epoch: 24.8 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3472259378481485		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.3472259378481485 | validation: 0.3545386470135501]
	TIME [epoch: 24.8 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34561659299777575		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.34561659299777575 | validation: 0.3197858200736238]
	TIME [epoch: 24.8 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35934976846846384		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.35934976846846384 | validation: 0.3281432107392624]
	TIME [epoch: 24.8 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3296907070418775		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.3296907070418775 | validation: 0.30939431823463887]
	TIME [epoch: 24.7 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3224783335626829		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.3224783335626829 | validation: 0.3270401241917445]
	TIME [epoch: 24.8 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34730122519753254		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.34730122519753254 | validation: 0.367312122589949]
	TIME [epoch: 24.8 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41508213696886537		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.41508213696886537 | validation: 0.40266656742681955]
	TIME [epoch: 24.8 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4316855381945699		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.4316855381945699 | validation: 0.3259060928965674]
	TIME [epoch: 24.8 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33772476316353006		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.33772476316353006 | validation: 0.3553545250125737]
	TIME [epoch: 24.8 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38198532360463316		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.38198532360463316 | validation: 0.3368502169627071]
	TIME [epoch: 24.8 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34397327891365675		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.34397327891365675 | validation: 0.3851628177495405]
	TIME [epoch: 24.7 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3726900815188124		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.3726900815188124 | validation: 0.32239442515935024]
	TIME [epoch: 24.8 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33631430381414334		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.33631430381414334 | validation: 0.3385888703714055]
	TIME [epoch: 24.8 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3689759450824519		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.3689759450824519 | validation: 0.3557230389555197]
	TIME [epoch: 24.8 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3501352076214294		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.3501352076214294 | validation: 0.3823454460302636]
	TIME [epoch: 24.7 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38488071812514046		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.38488071812514046 | validation: 0.33567900559536007]
	TIME [epoch: 24.8 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3360074270234276		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.3360074270234276 | validation: 0.3370780611191114]
	TIME [epoch: 24.8 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3440605759513505		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.3440605759513505 | validation: 0.3261221882744625]
	TIME [epoch: 24.7 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35965948506748496		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.35965948506748496 | validation: 0.36425416582004333]
	TIME [epoch: 24.8 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5229365466797659		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.5229365466797659 | validation: 0.4721042780349693]
	TIME [epoch: 24.8 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46966037585881615		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.46966037585881615 | validation: 0.4468403708112429]
	TIME [epoch: 24.8 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4393967188856645		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.4393967188856645 | validation: 0.3563945793310559]
	TIME [epoch: 24.7 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3523581981977511		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.3523581981977511 | validation: 0.32186727953880623]
	TIME [epoch: 24.8 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3644276985197808		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.3644276985197808 | validation: 0.3560924995327837]
	TIME [epoch: 24.8 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35479792657685744		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.35479792657685744 | validation: 0.34379587563470865]
	TIME [epoch: 24.7 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.342952223666125		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.342952223666125 | validation: 0.31347461585931047]
	TIME [epoch: 24.8 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32341927520706215		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.32341927520706215 | validation: 0.3389188820188636]
	TIME [epoch: 24.8 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31441252539324605		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.31441252539324605 | validation: 0.3326032327844149]
	TIME [epoch: 24.8 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3356516061636812		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.3356516061636812 | validation: 0.40243996244062247]
	TIME [epoch: 24.8 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.387975907993705		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.387975907993705 | validation: 0.3913354804396269]
	TIME [epoch: 24.8 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3579693510815465		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.3579693510815465 | validation: 0.3900823869433793]
	TIME [epoch: 24.8 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35456886476850563		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.35456886476850563 | validation: 0.41808963667797927]
	TIME [epoch: 24.8 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46635136255602094		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.46635136255602094 | validation: 0.6216827359437795]
	TIME [epoch: 24.8 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6026386233814474		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.6026386233814474 | validation: 0.5228714691192826]
	TIME [epoch: 24.8 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43642542277594054		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.43642542277594054 | validation: 0.4394876373586988]
	TIME [epoch: 24.8 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5287587354490424		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.5287587354490424 | validation: 0.6854090637503936]
	TIME [epoch: 24.8 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6108190161613529		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.6108190161613529 | validation: 0.5104081916662766]
	TIME [epoch: 24.8 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3981126132901856		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.3981126132901856 | validation: 0.4017342553012627]
	TIME [epoch: 24.8 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.371256321279367		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.371256321279367 | validation: 0.3991263826408279]
	TIME [epoch: 24.8 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.353385399972586		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.353385399972586 | validation: 0.37371304647127546]
	TIME [epoch: 24.8 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34105929406010127		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.34105929406010127 | validation: 0.32681026053684903]
	TIME [epoch: 24.8 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31153876221461585		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.31153876221461585 | validation: 0.36853779741880277]
	TIME [epoch: 24.8 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33594544948086436		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.33594544948086436 | validation: 0.32806259925336306]
	TIME [epoch: 24.8 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3056519490944004		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.3056519490944004 | validation: 0.3072107084217871]
	TIME [epoch: 24.8 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31643266964106415		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.31643266964106415 | validation: 0.30637136588712105]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_695.pth
	Model improved!!!
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3138869867535399		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.3138869867535399 | validation: 0.3365086997941159]
	TIME [epoch: 24.8 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.339107173936273		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.339107173936273 | validation: 0.32088525792112754]
	TIME [epoch: 24.8 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34588257551810425		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.34588257551810425 | validation: 0.38524918228879707]
	TIME [epoch: 24.8 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40149614889336677		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.40149614889336677 | validation: 0.3349027496878269]
	TIME [epoch: 24.8 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3326675342918064		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.3326675342918064 | validation: 0.3415036135788839]
	TIME [epoch: 24.7 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31293565545036744		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.31293565545036744 | validation: 0.3123866582346157]
	TIME [epoch: 24.8 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3070793438457293		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.3070793438457293 | validation: 0.3246661277258336]
	TIME [epoch: 24.8 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.302999328592893		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.302999328592893 | validation: 0.3210999432740438]
	TIME [epoch: 24.8 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3331871508617311		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.3331871508617311 | validation: 0.3889338362576096]
	TIME [epoch: 24.8 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3361591473679216		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.3361591473679216 | validation: 0.3302459338682489]
	TIME [epoch: 24.8 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3056172990070972		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.3056172990070972 | validation: 0.37605388597101425]
	TIME [epoch: 24.8 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34039003505002513		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.34039003505002513 | validation: 0.3228441625051325]
	TIME [epoch: 24.7 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3168129238552605		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.3168129238552605 | validation: 0.34020053563604263]
	TIME [epoch: 24.8 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32420760481129685		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.32420760481129685 | validation: 0.3274758228998447]
	TIME [epoch: 24.8 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35131730670347483		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.35131730670347483 | validation: 0.34404210399040386]
	TIME [epoch: 24.7 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36324261679131153		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.36324261679131153 | validation: 0.3480825091468552]
	TIME [epoch: 24.7 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34837924459937525		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.34837924459937525 | validation: 0.33162995086947034]
	TIME [epoch: 24.8 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32745666276930974		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.32745666276930974 | validation: 0.31811007296013943]
	TIME [epoch: 24.8 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33456684360694977		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.33456684360694977 | validation: 0.35050559440953066]
	TIME [epoch: 24.7 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42259629837511964		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.42259629837511964 | validation: 0.417341585065491]
	TIME [epoch: 24.8 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5020653284196658		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.5020653284196658 | validation: 0.4440622789827701]
	TIME [epoch: 24.8 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4406862667891244		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.4406862667891244 | validation: 0.4078755905476359]
	TIME [epoch: 24.8 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41668665639543934		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.41668665639543934 | validation: 0.39576876134930244]
	TIME [epoch: 24.7 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4050289784887666		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.4050289784887666 | validation: 0.3584919528148965]
	TIME [epoch: 24.8 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37036860620086		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.37036860620086 | validation: 0.3360185640715674]
	TIME [epoch: 24.8 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30970265995600943		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.30970265995600943 | validation: 0.32241921194980633]
	TIME [epoch: 24.7 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31117146921887884		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.31117146921887884 | validation: 0.3284817026470304]
	TIME [epoch: 24.8 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32206240255061547		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.32206240255061547 | validation: 0.30898355378775294]
	TIME [epoch: 24.8 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2932266685666116		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.2932266685666116 | validation: 0.2923647265816469]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_724.pth
	Model improved!!!
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32280882459473836		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.32280882459473836 | validation: 0.3709101755882472]
	TIME [epoch: 24.8 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3611544390163334		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.3611544390163334 | validation: 0.3309085235426845]
	TIME [epoch: 24.8 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3573023134364778		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.3573023134364778 | validation: 0.379823586969815]
	TIME [epoch: 24.8 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.386981579060769		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.386981579060769 | validation: 0.3731617570169185]
	TIME [epoch: 24.8 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3626891976926817		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.3626891976926817 | validation: 0.39123031229113664]
	TIME [epoch: 24.8 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35925530726241733		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.35925530726241733 | validation: 0.36779000619768754]
	TIME [epoch: 24.8 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41336204052708136		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.41336204052708136 | validation: 0.5285921992848025]
	TIME [epoch: 24.8 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5465386067540614		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.5465386067540614 | validation: 0.4845437247638433]
	TIME [epoch: 24.7 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43674912991399684		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.43674912991399684 | validation: 0.45893986109968643]
	TIME [epoch: 24.8 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4597538278119452		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.4597538278119452 | validation: 0.4953804358277353]
	TIME [epoch: 24.8 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4992674008497886		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.4992674008497886 | validation: 0.6227535267124588]
	TIME [epoch: 24.7 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6328295084680424		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.6328295084680424 | validation: 0.5843705526861475]
	TIME [epoch: 24.8 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5343395999506615		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.5343395999506615 | validation: 0.5654486297274222]
	TIME [epoch: 24.8 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49190671266954067		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.49190671266954067 | validation: 0.42559690827830454]
	TIME [epoch: 24.8 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37352984554817215		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.37352984554817215 | validation: 0.35092114432288085]
	TIME [epoch: 24.7 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3209478595467451		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.3209478595467451 | validation: 0.35743818684188894]
	TIME [epoch: 24.8 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33141238051407873		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.33141238051407873 | validation: 0.3591770732253083]
	TIME [epoch: 24.8 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34726978291896204		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.34726978291896204 | validation: 0.39041822391211994]
	TIME [epoch: 24.8 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35034834711002727		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.35034834711002727 | validation: 0.3496445672996704]
	TIME [epoch: 24.8 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3362062703820846		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.3362062703820846 | validation: 0.332955900539844]
	TIME [epoch: 24.8 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3171348193122617		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.3171348193122617 | validation: 0.37148191461447233]
	TIME [epoch: 24.8 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3835199152616542		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.3835199152616542 | validation: 0.4646206975273801]
	TIME [epoch: 24.8 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43748892458427413		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.43748892458427413 | validation: 0.5292157525244772]
	TIME [epoch: 24.8 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45503384766761973		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.45503384766761973 | validation: 0.47410336793456326]
	TIME [epoch: 24.8 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40622963113388233		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.40622963113388233 | validation: 0.4392465361895202]
	TIME [epoch: 24.8 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3992355150535309		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.3992355150535309 | validation: 0.42290851708918786]
	TIME [epoch: 24.8 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3570447270651146		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.3570447270651146 | validation: 0.3579481410334459]
	TIME [epoch: 24.8 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32920028577749366		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.32920028577749366 | validation: 0.355574352804953]
	TIME [epoch: 24.8 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32063233807226776		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.32063233807226776 | validation: 0.34816438198077804]
	TIME [epoch: 24.8 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3060174203772988		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.3060174203772988 | validation: 0.31304459971852167]
	TIME [epoch: 24.8 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2913324348187696		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.2913324348187696 | validation: 0.35369731748272126]
	TIME [epoch: 24.8 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3601972573386456		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.3601972573386456 | validation: 0.3632427005386511]
	TIME [epoch: 24.8 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3733515830435681		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.3733515830435681 | validation: 0.41199153592558985]
	TIME [epoch: 24.8 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4643907285658613		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.4643907285658613 | validation: 0.4700947623321022]
	TIME [epoch: 24.8 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41483170585953427		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.41483170585953427 | validation: 0.3840391274990327]
	TIME [epoch: 24.8 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3365008041488524		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.3365008041488524 | validation: 0.37579442266293916]
	TIME [epoch: 24.7 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3491442549371789		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.3491442549371789 | validation: 0.3103305255354249]
	TIME [epoch: 24.8 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3068748520734747		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.3068748520734747 | validation: 0.30915885169933066]
	TIME [epoch: 24.8 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3173366298846679		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.3173366298846679 | validation: 0.31825872491178075]
	TIME [epoch: 24.8 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31192051817921235		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.31192051817921235 | validation: 0.32111737738237867]
	TIME [epoch: 24.7 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30007223810625083		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.30007223810625083 | validation: 0.29513455260821886]
	TIME [epoch: 24.8 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31267133123312646		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.31267133123312646 | validation: 0.2970337802204925]
	TIME [epoch: 24.8 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3101566540418561		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.3101566540418561 | validation: 0.3207897902773082]
	TIME [epoch: 24.7 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3202812432511077		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.3202812432511077 | validation: 0.2947097963149027]
	TIME [epoch: 24.8 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29976222289378435		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.29976222289378435 | validation: 0.2909217650449922]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_769.pth
	Model improved!!!
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29327980395990527		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.29327980395990527 | validation: 0.2866746795755959]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_770.pth
	Model improved!!!
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3071054213630382		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.3071054213630382 | validation: 0.30292948773933764]
	TIME [epoch: 24.7 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3108445278481971		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.3108445278481971 | validation: 0.29310607148193746]
	TIME [epoch: 24.8 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2891293312015917		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.2891293312015917 | validation: 0.2837397598034289]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_773.pth
	Model improved!!!
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2716025207710174		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.2716025207710174 | validation: 0.31084821079843883]
	TIME [epoch: 24.8 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2860245531440754		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.2860245531440754 | validation: 0.3194040276708749]
	TIME [epoch: 24.8 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.311838395483836		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.311838395483836 | validation: 0.34687418372527445]
	TIME [epoch: 24.8 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31280011479254255		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.31280011479254255 | validation: 0.31081052089993216]
	TIME [epoch: 24.8 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33061392137007073		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.33061392137007073 | validation: 0.35210438816050954]
	TIME [epoch: 24.7 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3144652830381954		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.3144652830381954 | validation: 0.30580414240093556]
	TIME [epoch: 24.8 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28368472928835897		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.28368472928835897 | validation: 0.3410663865390707]
	TIME [epoch: 24.8 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3008881330771752		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.3008881330771752 | validation: 0.3185655702473328]
	TIME [epoch: 24.8 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2943312069059302		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.2943312069059302 | validation: 0.3302490969948363]
	TIME [epoch: 24.8 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3108645519102638		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.3108645519102638 | validation: 0.3622264307665532]
	TIME [epoch: 24.8 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31773772804477074		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.31773772804477074 | validation: 0.3693944911921216]
	TIME [epoch: 24.8 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31539936462293894		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.31539936462293894 | validation: 0.3202601870261118]
	TIME [epoch: 24.8 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29428487239146733		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.29428487239146733 | validation: 0.33332396989305163]
	TIME [epoch: 24.8 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33548389989110833		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.33548389989110833 | validation: 0.34711298110367245]
	TIME [epoch: 24.8 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32563239766129515		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.32563239766129515 | validation: 0.3032112174629202]
	TIME [epoch: 24.8 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.293048711184824		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.293048711184824 | validation: 0.31218832861059304]
	TIME [epoch: 24.8 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3302850668579041		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.3302850668579041 | validation: 0.44245031846395905]
	TIME [epoch: 24.8 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3816057275732476		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.3816057275732476 | validation: 0.37661785333017983]
	TIME [epoch: 24.8 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3218023671265006		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.3218023671265006 | validation: 0.3405936748019782]
	TIME [epoch: 24.8 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3334364741723702		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.3334364741723702 | validation: 0.39025483667632954]
	TIME [epoch: 24.8 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3717836165055539		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.3717836165055539 | validation: 0.4259116252565195]
	TIME [epoch: 24.8 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36767801124725064		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.36767801124725064 | validation: 0.3817962974733768]
	TIME [epoch: 24.8 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3356314366795271		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.3356314366795271 | validation: 0.3534565953606375]
	TIME [epoch: 24.7 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.362912821724962		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.362912821724962 | validation: 0.39108880090494297]
	TIME [epoch: 24.8 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3671058422810945		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.3671058422810945 | validation: 0.38761365357419664]
	TIME [epoch: 24.8 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3698927148205126		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.3698927148205126 | validation: 0.37758951593442275]
	TIME [epoch: 24.8 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3646193674644902		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.3646193674644902 | validation: 0.3782854521405177]
	TIME [epoch: 24.8 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34719715374666404		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.34719715374666404 | validation: 0.3435216378793297]
	TIME [epoch: 24.8 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3079486526817358		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.3079486526817358 | validation: 0.33073244184856365]
	TIME [epoch: 24.8 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3215973868974821		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.3215973868974821 | validation: 0.3326405520471933]
	TIME [epoch: 24.7 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30246028328653685		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.30246028328653685 | validation: 0.3473640313914192]
	TIME [epoch: 24.8 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35697427321256586		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.35697427321256586 | validation: 0.40914183409747223]
	TIME [epoch: 24.8 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3945260943574266		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.3945260943574266 | validation: 0.4387715799929561]
	TIME [epoch: 24.8 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40888365391708814		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.40888365391708814 | validation: 0.4248500040803178]
	TIME [epoch: 24.8 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36712999792972395		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.36712999792972395 | validation: 0.3591887100321863]
	TIME [epoch: 24.8 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3100712146387543		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.3100712146387543 | validation: 0.33996098468640085]
	TIME [epoch: 24.8 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3371097248955429		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.3371097248955429 | validation: 0.38840122478752703]
	TIME [epoch: 24.7 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34569177998344974		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.34569177998344974 | validation: 0.3482134200885463]
	TIME [epoch: 24.8 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3347625633559604		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.3347625633559604 | validation: 0.3554289471013098]
	TIME [epoch: 24.8 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3087164538498059		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.3087164538498059 | validation: 0.3158402756905006]
	TIME [epoch: 24.8 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29840541728437653		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.29840541728437653 | validation: 0.31952692014943984]
	TIME [epoch: 24.7 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3008831776335883		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.3008831776335883 | validation: 0.3287968695250793]
	TIME [epoch: 24.8 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31035145950290305		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.31035145950290305 | validation: 0.34453605990013086]
	TIME [epoch: 24.8 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34111707075111874		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.34111707075111874 | validation: 0.35791882312200907]
	TIME [epoch: 24.7 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3614377247284203		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.3614377247284203 | validation: 0.32778296544628815]
	TIME [epoch: 24.8 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3194078518329563		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.3194078518329563 | validation: 0.30576238225699454]
	TIME [epoch: 24.8 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3088805650774058		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.3088805650774058 | validation: 0.3002497231060986]
	TIME [epoch: 24.8 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28739728743092424		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.28739728743092424 | validation: 0.286404338388657]
	TIME [epoch: 24.7 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3012280301973719		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.3012280301973719 | validation: 0.30355726959505874]
	TIME [epoch: 24.8 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3206596530630347		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.3206596530630347 | validation: 0.31011375454516105]
	TIME [epoch: 24.8 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3123524411631303		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.3123524411631303 | validation: 0.3497026346343418]
	TIME [epoch: 24.7 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32666975141109156		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.32666975141109156 | validation: 0.33630258308687105]
	TIME [epoch: 24.8 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32253293137670935		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.32253293137670935 | validation: 0.32482428397928026]
	TIME [epoch: 24.8 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31569985753648644		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.31569985753648644 | validation: 0.3157229531507763]
	TIME [epoch: 24.8 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30129748833299036		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.30129748833299036 | validation: 0.31457034680247403]
	TIME [epoch: 24.8 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29301307645909985		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.29301307645909985 | validation: 0.30922117106293634]
	TIME [epoch: 24.8 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2929783254126722		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.2929783254126722 | validation: 0.33108631597723387]
	TIME [epoch: 24.8 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31890243800538115		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.31890243800538115 | validation: 0.3360385772938856]
	TIME [epoch: 24.8 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31903217990576593		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.31903217990576593 | validation: 0.3230640985779792]
	TIME [epoch: 24.8 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33784440633172164		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.33784440633172164 | validation: 0.3672173697632836]
	TIME [epoch: 24.8 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3348885627840247		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.3348885627840247 | validation: 0.34111763598694855]
	TIME [epoch: 24.8 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28642614615903617		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.28642614615903617 | validation: 0.2893504947158201]
	TIME [epoch: 24.7 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2672361887496931		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.2672361887496931 | validation: 0.2635638512152987]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_836.pth
	Model improved!!!
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2668816162247001		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.2668816162247001 | validation: 0.2843591608735743]
	TIME [epoch: 24.8 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.270917770619389		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.270917770619389 | validation: 0.2710186512888362]
	TIME [epoch: 24.8 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26815676351833606		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.26815676351833606 | validation: 0.2708505659317551]
	TIME [epoch: 24.8 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2629162671391391		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.2629162671391391 | validation: 0.28125835780602354]
	TIME [epoch: 24.8 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2783260108134298		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.2783260108134298 | validation: 0.28972226211540886]
	TIME [epoch: 24.8 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28166902827862256		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.28166902827862256 | validation: 0.3048037338013889]
	TIME [epoch: 24.7 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2804752373211499		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.2804752373211499 | validation: 0.276912182068292]
	TIME [epoch: 24.8 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26597772271833553		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.26597772271833553 | validation: 0.2693127223472356]
	TIME [epoch: 24.8 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26105833502299036		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.26105833502299036 | validation: 0.263563059198718]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_845.pth
	Model improved!!!
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2639774322039669		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.2639774322039669 | validation: 0.2520361674455748]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240309_135747/states/model_tr_study6_846.pth
	Model improved!!!
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.262551236209487		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.262551236209487 | validation: 0.2632308436058273]
	TIME [epoch: 24.8 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26287875996235427		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.26287875996235427 | validation: 0.2925820917459121]
	TIME [epoch: 24.8 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26933889351759877		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.26933889351759877 | validation: 0.2748771358384855]
	TIME [epoch: 24.7 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2583346788288161		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.2583346788288161 | validation: 0.2735038116160494]
	TIME [epoch: 24.8 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2646174468747755		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.2646174468747755 | validation: 0.2555154220535799]
	TIME [epoch: 24.8 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2690228964654862		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.2690228964654862 | validation: 0.2743183373983028]
	TIME [epoch: 24.8 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2775608813291359		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.2775608813291359 | validation: 0.2968193576698095]
	TIME [epoch: 24.8 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28780413547568273		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.28780413547568273 | validation: 0.2807934953235616]
	TIME [epoch: 24.8 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2782439570143962		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.2782439570143962 | validation: 0.2853410173203373]
	TIME [epoch: 24.8 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2852861527264139		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.2852861527264139 | validation: 0.2794130381862119]
	TIME [epoch: 24.7 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.273959595172253		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.273959595172253 | validation: 0.26221570498189545]
	TIME [epoch: 24.8 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2671040783234244		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.2671040783234244 | validation: 0.2763473027601743]
	TIME [epoch: 24.8 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2733807070919985		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.2733807070919985 | validation: 0.274247522530336]
	TIME [epoch: 24.8 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28223467433652344		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.28223467433652344 | validation: 0.2803175815033269]
	TIME [epoch: 24.7 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27200880321180343		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.27200880321180343 | validation: 0.2791661990759875]
	TIME [epoch: 24.8 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26061651626644694		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.26061651626644694 | validation: 0.28158582510294755]
	TIME [epoch: 24.8 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2778415769167465		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.2778415769167465 | validation: 0.2985604588174161]
	TIME [epoch: 24.8 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27968963329558183		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.27968963329558183 | validation: 0.2900152981887977]
	TIME [epoch: 24.8 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27023628044300346		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.27023628044300346 | validation: 0.29647482463762814]
	TIME [epoch: 24.8 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28411183321922107		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.28411183321922107 | validation: 0.2952779349631895]
	TIME [epoch: 24.8 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2873932351211935		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.2873932351211935 | validation: 0.27732909327923577]
	TIME [epoch: 24.7 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2754506874575372		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.2754506874575372 | validation: 0.27450232313778944]
	TIME [epoch: 24.8 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27429917739980786		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.27429917739980786 | validation: 0.26648804344142785]
	TIME [epoch: 24.8 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26978735863471903		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.26978735863471903 | validation: 0.27564077100170964]
	TIME [epoch: 24.8 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2683437379950295		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.2683437379950295 | validation: 0.26314412940330323]
	TIME [epoch: 24.8 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27189104924664614		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.27189104924664614 | validation: 0.2797451197043171]
	TIME [epoch: 24.8 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32481860014525676		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.32481860014525676 | validation: 0.32637867868023945]
	TIME [epoch: 24.8 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33097119782378287		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.33097119782378287 | validation: 0.3122198658453557]
	TIME [epoch: 24.7 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32594447104448876		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.32594447104448876 | validation: 0.29537532953108503]
	TIME [epoch: 24.8 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2993272885186795		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.2993272885186795 | validation: 0.28434123104696163]
	TIME [epoch: 24.8 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2847282856032955		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.2847282856032955 | validation: 0.27276345962981674]
	TIME [epoch: 24.8 sec]
EPOCH 878/2000:
	Training over batches...
