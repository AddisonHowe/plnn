Args:
Namespace(name='model_tr_study6', outdir='out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5', training_data='data/transition_rate_studies/tr_study6/tr_study6_training/r5', validation_data='data/transition_rate_studies/tr_study6/tr_study6_validation/r5', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3595658395

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.782600063934375		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.782600063934375 | validation: 8.462976781043086]
	TIME [epoch: 112 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.802442746502292		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.802442746502292 | validation: 8.790733948633545]
	TIME [epoch: 25 sec]
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.973742097773814		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.973742097773814 | validation: 8.514778188042886]
	TIME [epoch: 24.9 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.6402909461835185		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.6402909461835185 | validation: 7.253072347582597]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.892563391631258		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.892563391631258 | validation: 7.523128413899911]
	TIME [epoch: 25 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.126354464589614		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.126354464589614 | validation: 6.149942038325819]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.303106038477757		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.303106038477757 | validation: 5.80147523234863]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.345398880177493		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.345398880177493 | validation: 5.649964108191032]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.75341044818627		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.75341044818627 | validation: 5.458467854043853]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.576398270245376		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.576398270245376 | validation: 5.499589087205545]
	TIME [epoch: 25 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.352323059732957		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.352323059732957 | validation: 6.6699077981779356]
	TIME [epoch: 25 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.733949255835698		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.733949255835698 | validation: 4.95032295703787]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.851322750620828		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.851322750620828 | validation: 4.563742070337439]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.488837274984124		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.488837274984124 | validation: 4.300155224320844]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.259628645819262		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.259628645819262 | validation: 4.116092615639694]
	TIME [epoch: 25.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.049530926147775		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.049530926147775 | validation: 3.9182144575799738]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.289340930643082		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.289340930643082 | validation: 3.780332812431248]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.85900296618927		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.85900296618927 | validation: 3.718301384743967]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7046632780859543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7046632780859543 | validation: 3.5636432488408283]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.480866245446328		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.480866245446328 | validation: 3.521755984935509]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.436760431550855		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.436760431550855 | validation: 3.9346939564569006]
	TIME [epoch: 24.9 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.412974606429424		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.412974606429424 | validation: 5.399305193626945]
	TIME [epoch: 24.9 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.429057743377383		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.429057743377383 | validation: 3.7245097730189674]
	TIME [epoch: 24.9 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5824630725359805		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5824630725359805 | validation: 3.3304938049560553]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.45306501524966		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.45306501524966 | validation: 3.2397000403206686]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4203937281599344		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4203937281599344 | validation: 3.569566807189158]
	TIME [epoch: 24.9 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.283270697820639		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.283270697820639 | validation: 3.1808572090768963]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3529557913545536		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3529557913545536 | validation: 3.5060796998212607]
	TIME [epoch: 25 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4177168656542545		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4177168656542545 | validation: 3.0938213487687545]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.360623636269615		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.360623636269615 | validation: 3.177216834822977]
	TIME [epoch: 25 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.188703033078052		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.188703033078052 | validation: 2.692263356189909]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.2021561414906285		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.2021561414906285 | validation: 5.195447540274152]
	TIME [epoch: 25 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.175332290476093		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.175332290476093 | validation: 4.819621894796785]
	TIME [epoch: 25 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.962690832078647		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.962690832078647 | validation: 3.398876461060066]
	TIME [epoch: 25 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0603697387594435		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0603697387594435 | validation: 3.022154966365857]
	TIME [epoch: 25 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1243598354988675		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1243598354988675 | validation: 3.541579083598075]
	TIME [epoch: 24.9 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0220759991047688		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0220759991047688 | validation: 2.8060140395216515]
	TIME [epoch: 25 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.073121095311846		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.073121095311846 | validation: 3.222834626568221]
	TIME [epoch: 24.9 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.17670958950894		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.17670958950894 | validation: 2.884071465048435]
	TIME [epoch: 24.9 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.861771954062574		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.861771954062574 | validation: 6.289998137511725]
	TIME [epoch: 24.9 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.332692299741109		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.332692299741109 | validation: 5.1044676459582385]
	TIME [epoch: 24.9 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.24240141657843		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.24240141657843 | validation: 3.9048553927164322]
	TIME [epoch: 24.9 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.29875395877879		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.29875395877879 | validation: 3.521403664526671]
	TIME [epoch: 25 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.046625476181818		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.046625476181818 | validation: 3.0244586920299223]
	TIME [epoch: 24.9 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1072150967283525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1072150967283525 | validation: 3.4010637816783245]
	TIME [epoch: 24.9 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.09033518741811		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.09033518741811 | validation: 2.8495537501722463]
	TIME [epoch: 25 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.992222179969587		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.992222179969587 | validation: 2.862845313892399]
	TIME [epoch: 24.9 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7763418747668696		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7763418747668696 | validation: 3.1560644510788123]
	TIME [epoch: 24.9 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7601843788152554		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7601843788152554 | validation: 2.6642031496701075]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.177788027335567		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.177788027335567 | validation: 4.437267247811234]
	TIME [epoch: 24.9 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4701085969851655		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 3.4701085969851655 | validation: 3.014637753107531]
	TIME [epoch: 24.9 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.976543267125231		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 2.976543267125231 | validation: 2.992733488297133]
	TIME [epoch: 24.9 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9350111922884548		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 2.9350111922884548 | validation: 3.808247741612531]
	TIME [epoch: 24.9 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2650741886628287		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 3.2650741886628287 | validation: 2.743218164522425]
	TIME [epoch: 24.9 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.645862925449419		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 2.645862925449419 | validation: 2.4406461283180643]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2863942138708913		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 3.2863942138708913 | validation: 4.550182226476415]
	TIME [epoch: 24.9 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.793651442522911		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 4.793651442522911 | validation: 4.122299295117274]
	TIME [epoch: 24.9 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.025066238555115		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 3.025066238555115 | validation: 2.5706183899849693]
	TIME [epoch: 24.9 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.939661388869206		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 2.939661388869206 | validation: 2.947349215280839]
	TIME [epoch: 24.9 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.624006488489473		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 2.624006488489473 | validation: 3.0184539121086007]
	TIME [epoch: 24.9 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.589581644290481		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 2.589581644290481 | validation: 2.413360737314977]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.561424661918572		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 2.561424661918572 | validation: 2.509997594376793]
	TIME [epoch: 24.9 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4994165565280926		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 2.4994165565280926 | validation: 2.5565517133116553]
	TIME [epoch: 24.9 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.410583201235045		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 2.410583201235045 | validation: 2.366568249913852]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_64.pth
	Model improved!!!
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2116821688553716		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 2.2116821688553716 | validation: 2.2138284071407233]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.164231647666486		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 2.164231647666486 | validation: 2.0029568568761045]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0607291475323533		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 2.0607291475323533 | validation: 2.228445293164102]
	TIME [epoch: 24.9 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3611791802441036		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 2.3611791802441036 | validation: 1.767834563186145]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9942970238236892		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 1.9942970238236892 | validation: 1.8714461770295596]
	TIME [epoch: 25 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9405056318218705		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 1.9405056318218705 | validation: 1.7434888550117418]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_70.pth
	Model improved!!!
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.027340954368036		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 2.027340954368036 | validation: 2.5447868819724877]
	TIME [epoch: 24.9 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0093973329344323		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 2.0093973329344323 | validation: 1.5570531222041808]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.832291460530596		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 1.832291460530596 | validation: 2.5200635843672656]
	TIME [epoch: 24.9 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.017625502054119		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 2.017625502054119 | validation: 2.7201314912766454]
	TIME [epoch: 25 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.395724500338252		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 2.395724500338252 | validation: 1.9428977083595311]
	TIME [epoch: 24.9 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7495654185797995		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 1.7495654185797995 | validation: 2.176131967574111]
	TIME [epoch: 24.9 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8371055394006186		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 1.8371055394006186 | validation: 1.4423032753375156]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7804347056413103		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 1.7804347056413103 | validation: 1.5186218926232482]
	TIME [epoch: 24.9 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6818861565007936		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 1.6818861565007936 | validation: 1.5527078412145587]
	TIME [epoch: 24.9 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.528483530582438		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 2.528483530582438 | validation: 1.316518651713033]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_80.pth
	Model improved!!!
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7463027882663877		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 1.7463027882663877 | validation: 1.911507169570557]
	TIME [epoch: 24.9 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5695957750196865		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 1.5695957750196865 | validation: 1.3554542818843334]
	TIME [epoch: 25 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2922865115430886		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 1.2922865115430886 | validation: 1.9279514693807607]
	TIME [epoch: 25 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.899127927360622		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 1.899127927360622 | validation: 1.4195350591549112]
	TIME [epoch: 24.9 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2903509254022316		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 1.2903509254022316 | validation: 1.1596850510727554]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_85.pth
	Model improved!!!
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2766212506275614		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 1.2766212506275614 | validation: 1.8346495351281191]
	TIME [epoch: 24.9 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5728522689064377		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 1.5728522689064377 | validation: 1.3821165766231878]
	TIME [epoch: 24.9 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4895020168170203		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 1.4895020168170203 | validation: 1.329941115476311]
	TIME [epoch: 24.9 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1801587410326582		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 1.1801587410326582 | validation: 1.1421271796955932]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_89.pth
	Model improved!!!
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2460690701984123		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 1.2460690701984123 | validation: 1.4704990136319478]
	TIME [epoch: 24.9 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.27440717452479		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 1.27440717452479 | validation: 1.5326583829490061]
	TIME [epoch: 24.9 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2156231228319576		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 1.2156231228319576 | validation: 1.1052741473446706]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_92.pth
	Model improved!!!
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1709003212418783		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 1.1709003212418783 | validation: 1.3903842986697776]
	TIME [epoch: 24.9 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.358896408087152		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 1.358896408087152 | validation: 1.260249881502243]
	TIME [epoch: 24.9 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3195024615300903		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 1.3195024615300903 | validation: 1.1013923407755133]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_95.pth
	Model improved!!!
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9798687258232539		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 0.9798687258232539 | validation: 2.1874297378409735]
	TIME [epoch: 24.9 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3247580862365826		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 1.3247580862365826 | validation: 0.9274786744210209]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.000875555727323		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 1.000875555727323 | validation: 0.8593826192934636]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_98.pth
	Model improved!!!
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1277887234566755		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 1.1277887234566755 | validation: 1.1799213857454882]
	TIME [epoch: 24.9 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9234841740041961		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.9234841740041961 | validation: 0.947201051657406]
	TIME [epoch: 24.9 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9969679715243748		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 0.9969679715243748 | validation: 0.8442254403118621]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_101.pth
	Model improved!!!
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9310533570331281		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 0.9310533570331281 | validation: 0.8966834159787398]
	TIME [epoch: 24.9 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0212529803942818		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 1.0212529803942818 | validation: 3.600524723957516]
	TIME [epoch: 24.9 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.675197086854905		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 1.675197086854905 | validation: 1.1840534797352273]
	TIME [epoch: 24.9 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7884425799253694		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 1.7884425799253694 | validation: 1.0900772139123769]
	TIME [epoch: 24.9 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2284281709090175		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 1.2284281709090175 | validation: 1.5733296848920015]
	TIME [epoch: 24.9 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6490742101046565		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 1.6490742101046565 | validation: 1.1789046972116242]
	TIME [epoch: 24.9 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9717586501675561		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 0.9717586501675561 | validation: 0.8257580963026939]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_108.pth
	Model improved!!!
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9985834626820123		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 0.9985834626820123 | validation: 1.57862923400966]
	TIME [epoch: 24.9 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1768146089028222		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 1.1768146089028222 | validation: 2.0965280071302086]
	TIME [epoch: 24.9 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3604706141938454		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 1.3604706141938454 | validation: 1.324653449611043]
	TIME [epoch: 24.9 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.467052305475131		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 1.467052305475131 | validation: 1.163530327717305]
	TIME [epoch: 24.9 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.041463763733094		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 1.041463763733094 | validation: 1.0957932574815166]
	TIME [epoch: 24.9 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9126190151335074		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 0.9126190151335074 | validation: 1.529969390164974]
	TIME [epoch: 24.9 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3717744320870775		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 1.3717744320870775 | validation: 0.8869861697426863]
	TIME [epoch: 24.9 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9694372527789014		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.9694372527789014 | validation: 1.4339996016443064]
	TIME [epoch: 24.9 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1536680071110796		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 1.1536680071110796 | validation: 1.1005559331932542]
	TIME [epoch: 24.9 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2046947718754808		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 1.2046947718754808 | validation: 0.8974709859087565]
	TIME [epoch: 24.9 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9832170073236493		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 0.9832170073236493 | validation: 0.9016336809106534]
	TIME [epoch: 24.9 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9827617333334857		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.9827617333334857 | validation: 0.910654186885962]
	TIME [epoch: 24.9 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9802837736749308		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 0.9802837736749308 | validation: 1.285560304950036]
	TIME [epoch: 24.9 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.460679145234563		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 1.460679145234563 | validation: 0.9574687254653363]
	TIME [epoch: 24.9 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0304244966840914		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 1.0304244966840914 | validation: 1.244860296187837]
	TIME [epoch: 24.9 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1212657489251947		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 1.1212657489251947 | validation: 0.956764021683038]
	TIME [epoch: 24.9 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.308216689043615		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 1.308216689043615 | validation: 0.9963959343538314]
	TIME [epoch: 24.9 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.076473406645702		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 1.076473406645702 | validation: 1.7124699449204435]
	TIME [epoch: 24.9 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2427601878051049		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 1.2427601878051049 | validation: 1.0025540696118325]
	TIME [epoch: 24.9 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9462449379266286		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 0.9462449379266286 | validation: 0.7778820289599953]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_128.pth
	Model improved!!!
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.816062967614851		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 0.816062967614851 | validation: 0.769525907324698]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_129.pth
	Model improved!!!
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9371402633404229		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.9371402633404229 | validation: 0.9536509565724554]
	TIME [epoch: 24.9 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8999523623788994		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 0.8999523623788994 | validation: 1.0576844343709428]
	TIME [epoch: 24.9 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9207880405414731		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 0.9207880405414731 | validation: 1.3104160401588902]
	TIME [epoch: 24.9 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.037234709570506		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 1.037234709570506 | validation: 0.9327797630719415]
	TIME [epoch: 24.9 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8797407360781396		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.8797407360781396 | validation: 0.8616810575966446]
	TIME [epoch: 24.9 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8736368222458506		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.8736368222458506 | validation: 1.0423778219712545]
	TIME [epoch: 24.9 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9347160127974442		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.9347160127974442 | validation: 0.9090126003419963]
	TIME [epoch: 24.9 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9363983790004691		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 0.9363983790004691 | validation: 0.7963790396787261]
	TIME [epoch: 24.9 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1025535328484675		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 1.1025535328484675 | validation: 0.7261095909946828]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_138.pth
	Model improved!!!
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8110226474711562		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 0.8110226474711562 | validation: 0.8584801467683891]
	TIME [epoch: 24.9 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9872309584978746		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.9872309584978746 | validation: 3.5526153152379014]
	TIME [epoch: 24.9 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5080614186705659		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 1.5080614186705659 | validation: 1.0713939766183644]
	TIME [epoch: 24.9 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.970411687543604		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.970411687543604 | validation: 0.8989678169840118]
	TIME [epoch: 24.9 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9472591293195292		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.9472591293195292 | validation: 0.9651533103817613]
	TIME [epoch: 24.9 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1605535647895462		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 1.1605535647895462 | validation: 1.5685957792269383]
	TIME [epoch: 24.9 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1334999400379187		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 1.1334999400379187 | validation: 0.8140830036123922]
	TIME [epoch: 24.9 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.873663644124086		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.873663644124086 | validation: 0.8300635686541793]
	TIME [epoch: 24.9 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8735775312375451		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.8735775312375451 | validation: 0.7909610793484646]
	TIME [epoch: 24.9 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3015179123634495		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 1.3015179123634495 | validation: 1.1932977397881446]
	TIME [epoch: 24.9 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.241197357541242		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 1.241197357541242 | validation: 0.8730341590235913]
	TIME [epoch: 24.9 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.959566856910636		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 1.959566856910636 | validation: 1.192271008444961]
	TIME [epoch: 24.9 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1094428927031779		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 1.1094428927031779 | validation: 0.9183652829310505]
	TIME [epoch: 24.9 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0320685774824168		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 1.0320685774824168 | validation: 1.0329240340933907]
	TIME [epoch: 24.9 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.235435323682088		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 1.235435323682088 | validation: 1.055336256315751]
	TIME [epoch: 24.9 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0232841678690923		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 1.0232841678690923 | validation: 0.8754398597303787]
	TIME [epoch: 24.9 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9266317094384584		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.9266317094384584 | validation: 1.5438588279879264]
	TIME [epoch: 24.9 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.256920058526578		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 1.256920058526578 | validation: 1.1936677146898966]
	TIME [epoch: 24.9 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5843415539634285		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 1.5843415539634285 | validation: 1.7661110960598678]
	TIME [epoch: 24.9 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3749188192907769		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 1.3749188192907769 | validation: 1.0359335864514017]
	TIME [epoch: 24.9 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1160576836954745		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 1.1160576836954745 | validation: 1.151723227638192]
	TIME [epoch: 24.9 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2119461906254922		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 1.2119461906254922 | validation: 1.0551882305480489]
	TIME [epoch: 24.9 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1736566933784922		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 1.1736566933784922 | validation: 1.0802069591362604]
	TIME [epoch: 24.9 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0634080898705334		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 1.0634080898705334 | validation: 1.510555958391674]
	TIME [epoch: 24.9 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3435277755739135		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 1.3435277755739135 | validation: 0.9981491476571845]
	TIME [epoch: 24.9 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8198622839396137		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 1.8198622839396137 | validation: 2.704193038508391]
	TIME [epoch: 24.9 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3608402958609087		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 3.3608402958609087 | validation: 3.245551586142038]
	TIME [epoch: 24.9 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4027122268720484		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 3.4027122268720484 | validation: 3.073103768947782]
	TIME [epoch: 24.9 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.307576049912421		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 3.307576049912421 | validation: 2.9911715599125785]
	TIME [epoch: 24.9 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.24051517748923		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 3.24051517748923 | validation: 2.9964277711325646]
	TIME [epoch: 24.9 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.271993716517744		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 3.271993716517744 | validation: 2.949459770335518]
	TIME [epoch: 24.9 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5061691002741444		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 2.5061691002741444 | validation: 1.2632402844921398]
	TIME [epoch: 24.9 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0891824183886456		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 1.0891824183886456 | validation: 1.075873521160565]
	TIME [epoch: 24.9 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0433638033875003		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 1.0433638033875003 | validation: 0.9776036669479458]
	TIME [epoch: 24.9 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8696907762666273		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.8696907762666273 | validation: 0.7864490573422068]
	TIME [epoch: 24.9 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8910705781633399		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.8910705781633399 | validation: 0.9362241976041501]
	TIME [epoch: 24.9 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8007259678513707		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.8007259678513707 | validation: 0.7599392517798796]
	TIME [epoch: 24.9 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1183709386239853		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 1.1183709386239853 | validation: 0.8551315531783695]
	TIME [epoch: 24.9 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7710671949012166		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.7710671949012166 | validation: 0.6894327485140929]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_177.pth
	Model improved!!!
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1444674773273227		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 1.1444674773273227 | validation: 0.9631090431990217]
	TIME [epoch: 24.9 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.980799489606428		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.980799489606428 | validation: 0.8094302964940198]
	TIME [epoch: 24.9 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7698198056191693		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.7698198056191693 | validation: 0.756928394921026]
	TIME [epoch: 24.9 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7492818860421802		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.7492818860421802 | validation: 0.8162453674200265]
	TIME [epoch: 24.9 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7542887886673295		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.7542887886673295 | validation: 0.9341237204214534]
	TIME [epoch: 24.9 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8706920778652831		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.8706920778652831 | validation: 0.7569348713269516]
	TIME [epoch: 24.9 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7530124816392986		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.7530124816392986 | validation: 0.7136959936413309]
	TIME [epoch: 24.9 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7506070146217912		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.7506070146217912 | validation: 0.749612712463132]
	TIME [epoch: 24.9 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7325864663365806		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.7325864663365806 | validation: 1.0594148234147953]
	TIME [epoch: 24.9 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9634001725151499		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.9634001725151499 | validation: 0.8098850603050036]
	TIME [epoch: 24.9 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.734837849381692		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.734837849381692 | validation: 0.6632683145596405]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_188.pth
	Model improved!!!
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6813915533611898		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.6813915533611898 | validation: 0.8375309418811306]
	TIME [epoch: 24.9 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7350840320363884		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.7350840320363884 | validation: 0.7454231758088017]
	TIME [epoch: 24.9 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6596944685947529		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.6596944685947529 | validation: 0.7132507092890669]
	TIME [epoch: 25 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7215816056539385		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.7215816056539385 | validation: 1.037338388273194]
	TIME [epoch: 24.9 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1822342047624903		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 1.1822342047624903 | validation: 1.3668611943716327]
	TIME [epoch: 24.9 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0455428523047972		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 1.0455428523047972 | validation: 0.7846031564100926]
	TIME [epoch: 24.9 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8981350643503309		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.8981350643503309 | validation: 0.9171949346673125]
	TIME [epoch: 25 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8576175005909881		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.8576175005909881 | validation: 0.9225376648005235]
	TIME [epoch: 24.9 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9602705365109168		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.9602705365109168 | validation: 0.7599345213035662]
	TIME [epoch: 25 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.755595467300797		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.755595467300797 | validation: 0.6961296795351544]
	TIME [epoch: 24.9 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7448366777467522		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.7448366777467522 | validation: 0.7545815762414914]
	TIME [epoch: 25 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8074091093604663		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.8074091093604663 | validation: 0.8678864043514867]
	TIME [epoch: 25 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6629203767739621		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.6629203767739621 | validation: 0.7910410623848096]
	TIME [epoch: 24.9 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6613367579683929		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.6613367579683929 | validation: 0.6429874087662378]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_202.pth
	Model improved!!!
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6516190817775763		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.6516190817775763 | validation: 0.8890905297161561]
	TIME [epoch: 25 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8135425330148497		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.8135425330148497 | validation: 0.7452216526221365]
	TIME [epoch: 25 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8082869252867477		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.8082869252867477 | validation: 1.3538020557203465]
	TIME [epoch: 25 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2406133775916828		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 1.2406133775916828 | validation: 0.8401422319585512]
	TIME [epoch: 25 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.846922945115985		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.846922945115985 | validation: 1.094664751911169]
	TIME [epoch: 24.9 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9378236172876381		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.9378236172876381 | validation: 0.7554556410132911]
	TIME [epoch: 24.9 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3330154900595084		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 1.3330154900595084 | validation: 1.0259584923427583]
	TIME [epoch: 24.9 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4158709613645386		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 1.4158709613645386 | validation: 0.9199037412281272]
	TIME [epoch: 24.9 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9065700193787362		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.9065700193787362 | validation: 0.8512363498179238]
	TIME [epoch: 24.9 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8855914416983262		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.8855914416983262 | validation: 1.3852260094013378]
	TIME [epoch: 25 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0256251917578734		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 1.0256251917578734 | validation: 0.8481420927569815]
	TIME [epoch: 25 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8572129868986029		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.8572129868986029 | validation: 0.8542614607035107]
	TIME [epoch: 25 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9174660057846482		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.9174660057846482 | validation: 1.168981684921287]
	TIME [epoch: 25 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9256730056545455		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.9256730056545455 | validation: 0.7025045880057736]
	TIME [epoch: 25 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8992425029503833		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.8992425029503833 | validation: 0.8015518765765347]
	TIME [epoch: 24.9 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8107052502572178		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.8107052502572178 | validation: 0.9265105978833694]
	TIME [epoch: 25 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8096466276243964		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.8096466276243964 | validation: 0.7264998043701563]
	TIME [epoch: 25 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8422081668487886		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.8422081668487886 | validation: 0.8873791367258608]
	TIME [epoch: 24.9 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5344044671614285		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 1.5344044671614285 | validation: 1.0198275356932192]
	TIME [epoch: 25 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0035599391511314		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 1.0035599391511314 | validation: 0.893119696222324]
	TIME [epoch: 25 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8813195916446379		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.8813195916446379 | validation: 1.0541386430402813]
	TIME [epoch: 24.9 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8985831942425382		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.8985831942425382 | validation: 1.0556763149083448]
	TIME [epoch: 25 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.319978259550362		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 1.319978259550362 | validation: 0.8113048755922219]
	TIME [epoch: 25 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8624517887140357		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.8624517887140357 | validation: 0.9617675379559131]
	TIME [epoch: 24.9 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9548144317722341		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.9548144317722341 | validation: 0.7773421731933182]
	TIME [epoch: 25 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.911011901679428		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.911011901679428 | validation: 0.7957331940571137]
	TIME [epoch: 25 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8543385250097375		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.8543385250097375 | validation: 0.8559878535186743]
	TIME [epoch: 24.9 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8455662377650264		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.8455662377650264 | validation: 0.8325185233506233]
	TIME [epoch: 25 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9007271704317757		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.9007271704317757 | validation: 0.8732316295690009]
	TIME [epoch: 24.9 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8706877738111904		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.8706877738111904 | validation: 0.7331253150261111]
	TIME [epoch: 24.9 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7971318768016473		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.7971318768016473 | validation: 0.9799313640193837]
	TIME [epoch: 25 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8136181649518905		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.8136181649518905 | validation: 0.7833472075495514]
	TIME [epoch: 24.9 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8045945078736207		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.8045945078736207 | validation: 0.8106287698047624]
	TIME [epoch: 24.9 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8661465811136968		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.8661465811136968 | validation: 0.9836178448181407]
	TIME [epoch: 25 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8243232480898093		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.8243232480898093 | validation: 0.7299263473788318]
	TIME [epoch: 24.9 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8140101362159871		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.8140101362159871 | validation: 0.7895449856967247]
	TIME [epoch: 24.9 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8114182597775654		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.8114182597775654 | validation: 0.8430335166547208]
	TIME [epoch: 25 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.80883161246474		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.80883161246474 | validation: 0.6637798764191382]
	TIME [epoch: 24.9 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.041715395300778		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 1.041715395300778 | validation: 0.8051906130900948]
	TIME [epoch: 24.9 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.884759124795564		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.884759124795564 | validation: 0.747132355387504]
	TIME [epoch: 24.9 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5504211259271422		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.5504211259271422 | validation: 0.7009785408499656]
	TIME [epoch: 25 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7811462849033189		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.7811462849033189 | validation: 2.324563067485071]
	TIME [epoch: 24.9 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0446018440502876		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 3.0446018440502876 | validation: 2.0236331238716447]
	TIME [epoch: 25 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.401710923623987		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 1.401710923623987 | validation: 1.000684076713708]
	TIME [epoch: 24.9 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8162172790126604		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.8162172790126604 | validation: 0.7757557133427301]
	TIME [epoch: 24.9 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0094333516608858		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 1.0094333516608858 | validation: 1.088868477757675]
	TIME [epoch: 25 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7975433799237939		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.7975433799237939 | validation: 0.6216906708130463]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_249.pth
	Model improved!!!
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5106978717737483		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.5106978717737483 | validation: 0.6141278706738063]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_250.pth
	Model improved!!!
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7923021987392905		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.7923021987392905 | validation: 0.9826716413445823]
	TIME [epoch: 25 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1414143760491573		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 1.1414143760491573 | validation: 0.5982078123673276]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_252.pth
	Model improved!!!
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6816772539005107		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.6816772539005107 | validation: 0.7834088092467395]
	TIME [epoch: 24.9 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7528138438393311		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.7528138438393311 | validation: 0.7788065685294079]
	TIME [epoch: 24.9 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9430565976859326		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.9430565976859326 | validation: 0.8770537244191923]
	TIME [epoch: 24.9 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6589201509955182		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.6589201509955182 | validation: 0.5603822961675557]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_256.pth
	Model improved!!!
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6610477367638814		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.6610477367638814 | validation: 0.8070555209209351]
	TIME [epoch: 25 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6199275021866919		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.6199275021866919 | validation: 0.6253104858397354]
	TIME [epoch: 24.9 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6096173330844044		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.6096173330844044 | validation: 0.6531067434783827]
	TIME [epoch: 24.9 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5952526861069103		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.5952526861069103 | validation: 0.5692563850883317]
	TIME [epoch: 24.9 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.652599016542682		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.652599016542682 | validation: 0.7415861134042779]
	TIME [epoch: 25 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.735408483767098		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.735408483767098 | validation: 0.7481661687189088]
	TIME [epoch: 24.9 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7709687789619378		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.7709687789619378 | validation: 0.8064975423393493]
	TIME [epoch: 25 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7856574000599884		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.7856574000599884 | validation: 0.7116856658396585]
	TIME [epoch: 25 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7564398023420835		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.7564398023420835 | validation: 0.6964604502457136]
	TIME [epoch: 24.9 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7571595107677707		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.7571595107677707 | validation: 0.7584526886165368]
	TIME [epoch: 25 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6801336899077601		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.6801336899077601 | validation: 0.6869863080725018]
	TIME [epoch: 25 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6441062655675042		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.6441062655675042 | validation: 0.9492061193608956]
	TIME [epoch: 24.9 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6877085042403759		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.6877085042403759 | validation: 1.1870823899201008]
	TIME [epoch: 25 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.48858023709025		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 1.48858023709025 | validation: 0.927511349744214]
	TIME [epoch: 25 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7834574781868722		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.7834574781868722 | validation: 0.7305249701205652]
	TIME [epoch: 24.9 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8353674132357773		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.8353674132357773 | validation: 0.8446598432000387]
	TIME [epoch: 25 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7812438053332654		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.7812438053332654 | validation: 0.5845960174405995]
	TIME [epoch: 25 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.675627274276625		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.675627274276625 | validation: 0.7856188492959245]
	TIME [epoch: 24.9 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8191435760217718		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.8191435760217718 | validation: 0.7460656770493553]
	TIME [epoch: 25 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7655620141364204		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.7655620141364204 | validation: 0.7215636156041666]
	TIME [epoch: 24.9 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7751850054330498		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.7751850054330498 | validation: 0.7149339839810536]
	TIME [epoch: 24.9 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8001311686510356		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.8001311686510356 | validation: 0.806972205457152]
	TIME [epoch: 24.9 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7641409722345422		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.7641409722345422 | validation: 0.6854986536052172]
	TIME [epoch: 25 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7745270405307585		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.7745270405307585 | validation: 0.7202011011333569]
	TIME [epoch: 24.9 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7718165046011882		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.7718165046011882 | validation: 0.7206968154141039]
	TIME [epoch: 25 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7250226875719462		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.7250226875719462 | validation: 0.8445987208880956]
	TIME [epoch: 25 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7452359699237519		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 1.7452359699237519 | validation: 1.8585831839612355]
	TIME [epoch: 24.9 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.504294419959798		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 1.504294419959798 | validation: 0.8939855996729666]
	TIME [epoch: 25 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6926322144195871		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.6926322144195871 | validation: 0.5904417854740295]
	TIME [epoch: 25 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.641996345547955		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.641996345547955 | validation: 0.9389589299203938]
	TIME [epoch: 24.9 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8549085790920199		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.8549085790920199 | validation: 0.7953681953821089]
	TIME [epoch: 25 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6297032664576282		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.6297032664576282 | validation: 0.7176714596369314]
	TIME [epoch: 25 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6238407871208388		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.6238407871208388 | validation: 0.7126513620707433]
	TIME [epoch: 24.9 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.754743761188011		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.754743761188011 | validation: 0.6833058678369653]
	TIME [epoch: 25 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5833829764192563		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.5833829764192563 | validation: 0.6033195854460508]
	TIME [epoch: 25 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.571822892884843		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.571822892884843 | validation: 0.5924678991123943]
	TIME [epoch: 24.9 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7325911941001171		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.7325911941001171 | validation: 1.2907558965053116]
	TIME [epoch: 25 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1480241560773932		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 1.1480241560773932 | validation: 0.7972451925284244]
	TIME [epoch: 25 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6334386211040912		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.6334386211040912 | validation: 0.6948400143411199]
	TIME [epoch: 24.9 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6398647621470198		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.6398647621470198 | validation: 0.7269681660927362]
	TIME [epoch: 25 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7813289766178386		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.7813289766178386 | validation: 0.7526868844851708]
	TIME [epoch: 24.9 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6749464247277743		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.6749464247277743 | validation: 0.7902331973378555]
	TIME [epoch: 24.9 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6647435811282271		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.6647435811282271 | validation: 0.7253907284671643]
	TIME [epoch: 24.9 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8529782495295827		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.8529782495295827 | validation: 0.9787888395103943]
	TIME [epoch: 24.9 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8924388492442072		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.8924388492442072 | validation: 0.7837796995870754]
	TIME [epoch: 24.9 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7036452706676839		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.7036452706676839 | validation: 0.6075145015678135]
	TIME [epoch: 24.9 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6243868557609742		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.6243868557609742 | validation: 1.1053820115508226]
	TIME [epoch: 24.9 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9034503548624766		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.9034503548624766 | validation: 0.5585292068396573]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_304.pth
	Model improved!!!
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6120738767679302		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.6120738767679302 | validation: 0.8430709686730237]
	TIME [epoch: 24.9 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6059148243486424		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.6059148243486424 | validation: 0.5704547552590628]
	TIME [epoch: 24.9 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5493442234644242		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.5493442234644242 | validation: 0.5976688102721381]
	TIME [epoch: 24.8 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.600167819661956		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.600167819661956 | validation: 0.811554318576851]
	TIME [epoch: 25 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7168403223417507		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.7168403223417507 | validation: 0.7572571742683576]
	TIME [epoch: 24.9 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6810692069174937		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.6810692069174937 | validation: 0.6184751739541027]
	TIME [epoch: 24.9 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5462644395554361		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.5462644395554361 | validation: 0.6901205716844981]
	TIME [epoch: 25 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7034207518845637		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.7034207518845637 | validation: 0.6930335747217623]
	TIME [epoch: 24.9 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6729759986830628		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.6729759986830628 | validation: 0.6273284330581494]
	TIME [epoch: 24.9 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7834163730433596		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.7834163730433596 | validation: 0.785001222299662]
	TIME [epoch: 24.9 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6551220342411872		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.6551220342411872 | validation: 0.6739396987190074]
	TIME [epoch: 25 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6333643533300031		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.6333643533300031 | validation: 0.6019765625651691]
	TIME [epoch: 24.9 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7055642602577353		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.7055642602577353 | validation: 0.8593497123534853]
	TIME [epoch: 24.9 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.81934517340783		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.81934517340783 | validation: 0.707623637823055]
	TIME [epoch: 24.9 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6701476439473437		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.6701476439473437 | validation: 0.6666689097626934]
	TIME [epoch: 24.9 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7234025140134301		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.7234025140134301 | validation: 0.7111696484772475]
	TIME [epoch: 24.9 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6867803840657183		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.6867803840657183 | validation: 0.6226983668348703]
	TIME [epoch: 25 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6137669990859083		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.6137669990859083 | validation: 0.627230318740375]
	TIME [epoch: 24.9 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5735947041623436		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.5735947041623436 | validation: 0.8681562550606259]
	TIME [epoch: 24.9 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.720848900345513		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.720848900345513 | validation: 0.5260694925565828]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_324.pth
	Model improved!!!
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4896410134213277		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.4896410134213277 | validation: 0.5487219162342811]
	TIME [epoch: 24.9 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5098620509544943		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.5098620509544943 | validation: 0.553123479235572]
	TIME [epoch: 24.9 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.690261375600557		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.690261375600557 | validation: 0.9603241437714095]
	TIME [epoch: 24.9 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9034327525651156		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.9034327525651156 | validation: 0.8349948185206477]
	TIME [epoch: 24.9 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6617219860904333		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.6617219860904333 | validation: 0.5776698238853545]
	TIME [epoch: 24.9 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5901965207463848		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.5901965207463848 | validation: 0.6228120513889538]
	TIME [epoch: 24.9 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5490084302158872		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.5490084302158872 | validation: 0.5629787445592045]
	TIME [epoch: 24.9 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5184159614440489		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.5184159614440489 | validation: 0.534280221428165]
	TIME [epoch: 25 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5207320437785434		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.5207320437785434 | validation: 0.5954663853796458]
	TIME [epoch: 24.9 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6100292934818174		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.6100292934818174 | validation: 0.6466707980918562]
	TIME [epoch: 24.9 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7618739067611292		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.7618739067611292 | validation: 0.7935147851559619]
	TIME [epoch: 24.9 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7838248717921701		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.7838248717921701 | validation: 0.6865687088933752]
	TIME [epoch: 24.9 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7006562763111127		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.7006562763111127 | validation: 0.7041100143685864]
	TIME [epoch: 24.9 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6615385822383015		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.6615385822383015 | validation: 0.6545696412869981]
	TIME [epoch: 24.9 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6169074286172427		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.6169074286172427 | validation: 0.5994388305282213]
	TIME [epoch: 24.9 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6015876572021485		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.6015876572021485 | validation: 1.0543678003587704]
	TIME [epoch: 24.9 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0022643216022848		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 1.0022643216022848 | validation: 0.7455298833013516]
	TIME [epoch: 24.9 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1087601178545132		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 1.1087601178545132 | validation: 1.2546405018593436]
	TIME [epoch: 24.9 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9440114515965248		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.9440114515965248 | validation: 1.0485801068526115]
	TIME [epoch: 24.9 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0048259237521462		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 1.0048259237521462 | validation: 0.9103488794817431]
	TIME [epoch: 25 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9945070085132238		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.9945070085132238 | validation: 0.8083282267223819]
	TIME [epoch: 24.9 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6614753950978051		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.6614753950978051 | validation: 0.5893098255301689]
	TIME [epoch: 24.9 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5431146415136239		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.5431146415136239 | validation: 0.5713227422137924]
	TIME [epoch: 25 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6491963944766099		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.6491963944766099 | validation: 0.7365919027957034]
	TIME [epoch: 24.9 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6806316608077704		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.6806316608077704 | validation: 0.58734501905554]
	TIME [epoch: 24.9 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5758825698439773		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.5758825698439773 | validation: 0.5919088540750242]
	TIME [epoch: 25 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5732053242316149		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.5732053242316149 | validation: 0.6719411759580917]
	TIME [epoch: 24.9 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5800626222264093		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.5800626222264093 | validation: 0.8660345677733488]
	TIME [epoch: 24.9 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.877798883532952		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.877798883532952 | validation: 0.7565595834523497]
	TIME [epoch: 24.9 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6673852960430661		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.6673852960430661 | validation: 0.6251348875603865]
	TIME [epoch: 24.9 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6259329505642676		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.6259329505642676 | validation: 0.8356959412238137]
	TIME [epoch: 24.9 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7726132472623727		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.7726132472623727 | validation: 0.7694810208323085]
	TIME [epoch: 25 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6829201053144905		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.6829201053144905 | validation: 0.6143005650703824]
	TIME [epoch: 24.9 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.598041411936282		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.598041411936282 | validation: 0.6499819329117119]
	TIME [epoch: 24.9 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6144757686647123		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.6144757686647123 | validation: 0.6222700435848253]
	TIME [epoch: 25 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5848181548736451		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.5848181548736451 | validation: 0.9911413100876643]
	TIME [epoch: 24.9 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5956956870999177		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 1.5956956870999177 | validation: 1.3306669731490095]
	TIME [epoch: 24.9 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9692190928666519		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.9692190928666519 | validation: 0.7887505843214477]
	TIME [epoch: 24.9 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8212989718111122		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.8212989718111122 | validation: 0.8725116740607056]
	TIME [epoch: 24.9 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7173044168916882		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.7173044168916882 | validation: 0.6782930967764409]
	TIME [epoch: 24.9 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.634486728897619		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.634486728897619 | validation: 0.644076370068908]
	TIME [epoch: 24.9 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6471811305824733		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.6471811305824733 | validation: 0.7957710444177788]
	TIME [epoch: 24.9 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8397452194156799		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.8397452194156799 | validation: 0.8916530580915074]
	TIME [epoch: 24.9 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8541054119560698		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.8541054119560698 | validation: 0.7858777399737261]
	TIME [epoch: 24.9 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8165382793530056		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.8165382793530056 | validation: 0.8043456165406508]
	TIME [epoch: 24.9 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7918308553412772		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.7918308553412772 | validation: 0.7885627616067166]
	TIME [epoch: 24.9 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7185472949289164		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.7185472949289164 | validation: 0.7239429507532142]
	TIME [epoch: 24.9 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6864487904920918		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.6864487904920918 | validation: 0.9350869408104197]
	TIME [epoch: 24.9 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8663337563076294		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.8663337563076294 | validation: 0.7739080887978412]
	TIME [epoch: 24.9 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6841298958920546		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.6841298958920546 | validation: 0.6755683994147325]
	TIME [epoch: 24.9 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7077440509362499		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.7077440509362499 | validation: 0.7120369197142415]
	TIME [epoch: 24.9 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7347398516349531		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.7347398516349531 | validation: 0.7129831146859283]
	TIME [epoch: 24.9 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7091101886762081		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.7091101886762081 | validation: 0.7239535589809885]
	TIME [epoch: 24.9 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7607015615519315		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.7607015615519315 | validation: 0.7792972578957827]
	TIME [epoch: 24.9 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7818962024518961		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.7818962024518961 | validation: 0.7431826439949293]
	TIME [epoch: 24.9 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7456923203717634		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.7456923203717634 | validation: 0.7529277259344422]
	TIME [epoch: 24.9 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6847799479387805		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.6847799479387805 | validation: 0.6247269551884594]
	TIME [epoch: 24.9 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.708141933015306		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.708141933015306 | validation: 0.6480150243097487]
	TIME [epoch: 24.9 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6213829286659663		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.6213829286659663 | validation: 0.6301289276961175]
	TIME [epoch: 24.9 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6220451808968341		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.6220451808968341 | validation: 0.6453454048133387]
	TIME [epoch: 24.9 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6270806590991799		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.6270806590991799 | validation: 0.6414194427353357]
	TIME [epoch: 24.9 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6771282173493841		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.6771282173493841 | validation: 0.6422840340086616]
	TIME [epoch: 24.9 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6687802581029734		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.6687802581029734 | validation: 0.7203116405179574]
	TIME [epoch: 24.9 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6919405864491055		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.6919405864491055 | validation: 0.6601901180013797]
	TIME [epoch: 24.9 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6370357937876556		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.6370357937876556 | validation: 0.6301799703715468]
	TIME [epoch: 24.9 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6012705716850246		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.6012705716850246 | validation: 0.6879076386808595]
	TIME [epoch: 24.9 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6495642997245268		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.6495642997245268 | validation: 0.7534006540182029]
	TIME [epoch: 24.9 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5830667158747875		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.5830667158747875 | validation: 0.8197819586281452]
	TIME [epoch: 24.9 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3380947905094085		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 1.3380947905094085 | validation: 2.3241305655264206]
	TIME [epoch: 24.9 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9285544443706117		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 1.9285544443706117 | validation: 1.0530935302124842]
	TIME [epoch: 24.9 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7457361549485865		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.7457361549485865 | validation: 0.6331079962905877]
	TIME [epoch: 24.9 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7917666256918665		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.7917666256918665 | validation: 1.8687264278563107]
	TIME [epoch: 24.9 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8105720838689923		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 1.8105720838689923 | validation: 1.4666331930115728]
	TIME [epoch: 24.9 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8608120931660213		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 1.8608120931660213 | validation: 1.8766440666424047]
	TIME [epoch: 24.9 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.777647196201471		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 1.777647196201471 | validation: 1.6400517800627785]
	TIME [epoch: 24.9 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.730933208192723		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 1.730933208192723 | validation: 1.7971959087619391]
	TIME [epoch: 24.9 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.523368478756463		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 1.523368478756463 | validation: 1.5650226895958241]
	TIME [epoch: 24.9 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2805348666952634		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 1.2805348666952634 | validation: 0.9965117862255604]
	TIME [epoch: 24.9 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8281502788825226		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.8281502788825226 | validation: 0.716174797922414]
	TIME [epoch: 24.9 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5899911799344575		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.5899911799344575 | validation: 0.6471951646401617]
	TIME [epoch: 25 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5879792857347613		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.5879792857347613 | validation: 0.7466793586442435]
	TIME [epoch: 24.9 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.648928822192325		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.648928822192325 | validation: 0.6410071841307899]
	TIME [epoch: 24.9 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5721268007262575		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.5721268007262575 | validation: 0.6390665559272983]
	TIME [epoch: 24.9 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5769361141988537		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.5769361141988537 | validation: 0.6582484267415788]
	TIME [epoch: 24.9 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6310885902928767		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.6310885902928767 | validation: 0.7302204296388893]
	TIME [epoch: 24.9 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.743272650485569		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.743272650485569 | validation: 0.8009813430225353]
	TIME [epoch: 24.9 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7374037752366284		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.7374037752366284 | validation: 0.6682146678511451]
	TIME [epoch: 24.9 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5838199835504911		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.5838199835504911 | validation: 0.6445893757941369]
	TIME [epoch: 24.9 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5435433749011237		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.5435433749011237 | validation: 0.6649562219996384]
	TIME [epoch: 24.9 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8443982977174167		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.8443982977174167 | validation: 0.9138705725098711]
	TIME [epoch: 24.9 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7891279184663813		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.7891279184663813 | validation: 0.6921087210171993]
	TIME [epoch: 24.9 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5764242618840263		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.5764242618840263 | validation: 0.6189515322164948]
	TIME [epoch: 24.9 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5605446822043774		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.5605446822043774 | validation: 0.9203659453114863]
	TIME [epoch: 24.9 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0348702394265992		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 1.0348702394265992 | validation: 1.2414787460622305]
	TIME [epoch: 24.9 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2201784532750641		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 1.2201784532750641 | validation: 1.1120523596358707]
	TIME [epoch: 24.9 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2258197362287442		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 1.2258197362287442 | validation: 1.0950624133536835]
	TIME [epoch: 24.9 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0064214008140346		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 1.0064214008140346 | validation: 0.863702109602947]
	TIME [epoch: 24.9 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7626850706517565		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.7626850706517565 | validation: 0.8625991632529042]
	TIME [epoch: 24.9 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7185611942984133		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.7185611942984133 | validation: 0.6358660527517417]
	TIME [epoch: 24.9 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5510069643829554		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.5510069643829554 | validation: 0.605691781668088]
	TIME [epoch: 24.9 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5847103628921424		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.5847103628921424 | validation: 0.5867101916038785]
	TIME [epoch: 24.9 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6105359874148664		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.6105359874148664 | validation: 0.7882103322534759]
	TIME [epoch: 24.9 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6227841709289461		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.6227841709289461 | validation: 0.5593105963665422]
	TIME [epoch: 24.9 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4883240471597782		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.4883240471597782 | validation: 0.5565223058670355]
	TIME [epoch: 24.9 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4840115279598344		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.4840115279598344 | validation: 0.5024277335786123]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_429.pth
	Model improved!!!
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46664570219168006		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.46664570219168006 | validation: 0.6406904223597617]
	TIME [epoch: 24.9 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6680241113118845		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.6680241113118845 | validation: 1.0889840850398798]
	TIME [epoch: 24.9 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8936292112077916		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.8936292112077916 | validation: 0.8680741000987254]
	TIME [epoch: 24.9 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6937875847895754		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.6937875847895754 | validation: 0.7354033147339536]
	TIME [epoch: 24.9 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6695849003370269		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.6695849003370269 | validation: 0.5413492021213417]
	TIME [epoch: 24.9 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5043824416729051		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.5043824416729051 | validation: 0.5552004796139742]
	TIME [epoch: 24.9 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5240064529012893		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.5240064529012893 | validation: 0.5773185514557744]
	TIME [epoch: 24.9 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5209087627229148		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.5209087627229148 | validation: 0.6030072140455749]
	TIME [epoch: 24.9 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5014852887877184		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.5014852887877184 | validation: 0.5941078354716357]
	TIME [epoch: 24.9 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5320949618340177		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.5320949618340177 | validation: 0.5769810590027242]
	TIME [epoch: 24.9 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5884035090476014		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.5884035090476014 | validation: 0.694828787067304]
	TIME [epoch: 25 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7213817530895554		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.7213817530895554 | validation: 0.5881133672658683]
	TIME [epoch: 25 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5179659011268212		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.5179659011268212 | validation: 0.5412968862489396]
	TIME [epoch: 24.9 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4927617706308167		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.4927617706308167 | validation: 0.5463938154329059]
	TIME [epoch: 24.9 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46549665344913976		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.46549665344913976 | validation: 0.5186063540520458]
	TIME [epoch: 25 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47726941348075697		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.47726941348075697 | validation: 0.7064152531335237]
	TIME [epoch: 24.9 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6293704879733804		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.6293704879733804 | validation: 0.6096824431774364]
	TIME [epoch: 24.9 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5772287626842696		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.5772287626842696 | validation: 0.6674132687193216]
	TIME [epoch: 24.9 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.615545985676597		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.615545985676597 | validation: 0.5916304794761873]
	TIME [epoch: 24.9 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4881268684891841		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.4881268684891841 | validation: 0.47605063751602333]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_449.pth
	Model improved!!!
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49878896395649575		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.49878896395649575 | validation: 0.4987679761829525]
	TIME [epoch: 24.9 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47669149265438376		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.47669149265438376 | validation: 0.5130759508289231]
	TIME [epoch: 24.9 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4498081757152994		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.4498081757152994 | validation: 0.4740536192411022]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_452.pth
	Model improved!!!
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42675024234631875		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.42675024234631875 | validation: 0.46966632612672854]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_453.pth
	Model improved!!!
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4998958085060389		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.4998958085060389 | validation: 0.48519087832610275]
	TIME [epoch: 24.9 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44753281943345236		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.44753281943345236 | validation: 0.5082274397001889]
	TIME [epoch: 24.9 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4268123114168413		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.4268123114168413 | validation: 0.4269974542945449]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_456.pth
	Model improved!!!
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4085667811898279		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.4085667811898279 | validation: 0.45589713948144367]
	TIME [epoch: 24.9 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42377356219559553		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.42377356219559553 | validation: 0.4911217848141706]
	TIME [epoch: 24.9 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41084121674576607		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.41084121674576607 | validation: 0.4796365268025457]
	TIME [epoch: 24.9 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.500080303752242		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.500080303752242 | validation: 0.4906567305245982]
	TIME [epoch: 24.9 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4319781049731078		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.4319781049731078 | validation: 0.45653892214824704]
	TIME [epoch: 24.9 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4123431837247047		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.4123431837247047 | validation: 0.7409147016896941]
	TIME [epoch: 24.9 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8270827435791421		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.8270827435791421 | validation: 0.8924087632725834]
	TIME [epoch: 24.9 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6771855986677047		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.6771855986677047 | validation: 0.5287773707074335]
	TIME [epoch: 24.9 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4127184623447721		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.4127184623447721 | validation: 0.4433138314644785]
	TIME [epoch: 24.9 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4303930885030545		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.4303930885030545 | validation: 0.49331495993232166]
	TIME [epoch: 24.9 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4447156245135898		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.4447156245135898 | validation: 0.479361646717239]
	TIME [epoch: 24.9 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4495674503022145		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.4495674503022145 | validation: 0.5374946608790636]
	TIME [epoch: 24.9 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5198105382031653		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.5198105382031653 | validation: 0.5485296125472862]
	TIME [epoch: 24.9 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4862167564816139		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.4862167564816139 | validation: 0.49124277767098423]
	TIME [epoch: 24.9 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45159801961543494		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.45159801961543494 | validation: 0.49647309560751957]
	TIME [epoch: 24.9 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36923024983724395		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.36923024983724395 | validation: 0.5011673172005789]
	TIME [epoch: 24.9 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5517239875846593		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.5517239875846593 | validation: 0.6692013620014329]
	TIME [epoch: 24.9 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6142514564699131		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.6142514564699131 | validation: 0.6249458048890035]
	TIME [epoch: 24.9 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5316994770717011		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.5316994770717011 | validation: 0.5818244779775532]
	TIME [epoch: 24.9 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4504606756096436		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.4504606756096436 | validation: 0.4983579029473982]
	TIME [epoch: 24.9 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5358305623877985		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.5358305623877985 | validation: 0.691196149305432]
	TIME [epoch: 24.9 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6225268877369396		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.6225268877369396 | validation: 0.6814573041751979]
	TIME [epoch: 24.9 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6467751936210995		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.6467751936210995 | validation: 0.616408810979355]
	TIME [epoch: 24.9 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48920013732714357		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.48920013732714357 | validation: 0.5583689099881363]
	TIME [epoch: 24.9 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44294209594112893		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.44294209594112893 | validation: 0.5068892633239201]
	TIME [epoch: 24.9 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45457137641189127		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.45457137641189127 | validation: 0.5986605448823434]
	TIME [epoch: 24.9 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5752370483485543		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.5752370483485543 | validation: 0.6250539911635674]
	TIME [epoch: 24.9 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5295248055992122		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.5295248055992122 | validation: 0.5510240858869929]
	TIME [epoch: 24.9 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5149942155328333		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.5149942155328333 | validation: 0.5386346701910377]
	TIME [epoch: 24.9 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4700155124094447		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.4700155124094447 | validation: 0.543754523383836]
	TIME [epoch: 24.9 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.540286468281427		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.540286468281427 | validation: 0.8444655167448621]
	TIME [epoch: 24.9 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6990809233585814		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.6990809233585814 | validation: 0.725520463855936]
	TIME [epoch: 24.9 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5666444397733714		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.5666444397733714 | validation: 0.5148394152041224]
	TIME [epoch: 24.9 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49202133734429865		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.49202133734429865 | validation: 0.5553310268835417]
	TIME [epoch: 24.9 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46831941787440273		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.46831941787440273 | validation: 0.6214381783616527]
	TIME [epoch: 24.9 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6715693937407444		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.6715693937407444 | validation: 0.9210338485126371]
	TIME [epoch: 24.9 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8155796923140393		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.8155796923140393 | validation: 0.7450307436364483]
	TIME [epoch: 24.9 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6513966740156015		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.6513966740156015 | validation: 0.6150713434955865]
	TIME [epoch: 24.9 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5508010773030587		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.5508010773030587 | validation: 0.7243281614068394]
	TIME [epoch: 24.9 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.525363256732675		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.525363256732675 | validation: 0.5279749087488105]
	TIME [epoch: 24.9 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46293475446592797		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.46293475446592797 | validation: 0.5181939195953171]
	TIME [epoch: 24.9 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4405245274741456		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.4405245274741456 | validation: 0.5210424180649607]
	TIME [epoch: 24.9 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4689347520986584		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.4689347520986584 | validation: 0.5242504944435319]
	TIME [epoch: 24.9 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43581481481214973		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.43581481481214973 | validation: 0.49116294715320147]
	TIME [epoch: 24.9 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4424836688966065		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.4424836688966065 | validation: 0.5688437845287011]
	TIME [epoch: 24.9 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5271862138567285		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.5271862138567285 | validation: 0.606413662734165]
	TIME [epoch: 24.9 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45588049187307833		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.45588049187307833 | validation: 0.4874811551703701]
	TIME [epoch: 24.9 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3792164065056236		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.3792164065056236 | validation: 0.5105156310934499]
	TIME [epoch: 24.9 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3820528106664679		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.3820528106664679 | validation: 0.4764842711358903]
	TIME [epoch: 24.9 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39247813022222855		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.39247813022222855 | validation: 0.5374877417145024]
	TIME [epoch: 24.9 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4338719497813891		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.4338719497813891 | validation: 0.5046833286277053]
	TIME [epoch: 24.9 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37710926802397393		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.37710926802397393 | validation: 0.4386185317574423]
	TIME [epoch: 24.9 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3805537935911243		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.3805537935911243 | validation: 0.49843316023764217]
	TIME [epoch: 24.9 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4328121165415658		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.4328121165415658 | validation: 0.5016764406738073]
	TIME [epoch: 24.9 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.427219207762728		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.427219207762728 | validation: 0.47644122839494446]
	TIME [epoch: 24.9 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5280402207301198		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.5280402207301198 | validation: 0.7052989251488841]
	TIME [epoch: 24.9 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6690526350976543		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.6690526350976543 | validation: 1.1444403428785497]
	TIME [epoch: 25 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2694565852381552		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 1.2694565852381552 | validation: 0.9575032141055896]
	TIME [epoch: 24.9 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7294728914898693		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.7294728914898693 | validation: 0.8180840534665379]
	TIME [epoch: 24.9 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7600669207063654		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.7600669207063654 | validation: 0.839264085809465]
	TIME [epoch: 24.9 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6951647745554512		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.6951647745554512 | validation: 0.5589869054396144]
	TIME [epoch: 24.9 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44099521370239203		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.44099521370239203 | validation: 0.460164704544665]
	TIME [epoch: 24.9 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3991450374297547		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.3991450374297547 | validation: 0.4739259180540728]
	TIME [epoch: 24.9 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3849533207252227		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.3849533207252227 | validation: 0.4547313833616334]
	TIME [epoch: 24.9 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3669182776652973		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.3669182776652973 | validation: 0.4286652447233238]
	TIME [epoch: 24.9 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.373457984466107		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.373457984466107 | validation: 0.41400420332707655]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_522.pth
	Model improved!!!
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36093391160258415		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.36093391160258415 | validation: 0.41656958880771283]
	TIME [epoch: 24.9 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39854728737378653		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.39854728737378653 | validation: 0.4825977956117788]
	TIME [epoch: 24.9 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44642336899035023		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.44642336899035023 | validation: 0.5149381775719342]
	TIME [epoch: 25 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4300448408956833		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.4300448408956833 | validation: 0.577948761503369]
	TIME [epoch: 24.9 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41531793428505326		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.41531793428505326 | validation: 0.4237482221468581]
	TIME [epoch: 24.9 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3469370218343453		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.3469370218343453 | validation: 0.41676168238632316]
	TIME [epoch: 24.9 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3573186192204955		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.3573186192204955 | validation: 0.49954651233874714]
	TIME [epoch: 24.9 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3667936518408581		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.3667936518408581 | validation: 0.4690102933477851]
	TIME [epoch: 25 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4060379174801171		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.4060379174801171 | validation: 0.43997415396293926]
	TIME [epoch: 24.9 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38248678573143524		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.38248678573143524 | validation: 0.4313356495844552]
	TIME [epoch: 24.9 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3650232354448608		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.3650232354448608 | validation: 0.4485619994508295]
	TIME [epoch: 24.9 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.372630221995984		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.372630221995984 | validation: 0.5414759563848408]
	TIME [epoch: 24.9 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3876686905816737		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.3876686905816737 | validation: 0.43411731313728646]
	TIME [epoch: 24.9 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4223358324868163		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.4223358324868163 | validation: 0.5065588897432811]
	TIME [epoch: 25 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4001407877623918		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.4001407877623918 | validation: 0.4542224865870155]
	TIME [epoch: 25 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3754995093573291		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.3754995093573291 | validation: 0.445221105830791]
	TIME [epoch: 24.9 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39393139780468045		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.39393139780468045 | validation: 0.5814888625498047]
	TIME [epoch: 24.9 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6312210513083735		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.6312210513083735 | validation: 0.7004713152848323]
	TIME [epoch: 24.9 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7031980229594896		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.7031980229594896 | validation: 0.820516180742136]
	TIME [epoch: 24.9 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5641232945436293		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.5641232945436293 | validation: 0.4955307208203705]
	TIME [epoch: 25 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3663593345065642		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.3663593345065642 | validation: 0.4320458250806514]
	TIME [epoch: 25 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35542961229968656		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.35542961229968656 | validation: 0.4040691467955874]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_544.pth
	Model improved!!!
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31874341976745857		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.31874341976745857 | validation: 0.398265935190894]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_545.pth
	Model improved!!!
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32071617511529216		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.32071617511529216 | validation: 0.3838362608063113]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_546.pth
	Model improved!!!
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40398435403027333		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.40398435403027333 | validation: 1.0864741712623769]
	TIME [epoch: 24.9 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9760743038710202		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.9760743038710202 | validation: 0.590191697994557]
	TIME [epoch: 25 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45770522798427055		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.45770522798427055 | validation: 0.44306758604668217]
	TIME [epoch: 25 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3579630443778703		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.3579630443778703 | validation: 0.42377959586394115]
	TIME [epoch: 24.9 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3325015402218737		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.3325015402218737 | validation: 0.38290092067359455]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_551.pth
	Model improved!!!
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31857442105056777		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.31857442105056777 | validation: 0.35892385424845713]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_552.pth
	Model improved!!!
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3060880082253543		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.3060880082253543 | validation: 0.5301074552022417]
	TIME [epoch: 24.9 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4141338486603839		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.4141338486603839 | validation: 0.3865906949119325]
	TIME [epoch: 24.9 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30365405115853145		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.30365405115853145 | validation: 0.3851651408031938]
	TIME [epoch: 24.9 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3331800040217018		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.3331800040217018 | validation: 0.43416175668806334]
	TIME [epoch: 24.9 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39336565193887196		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.39336565193887196 | validation: 0.3933067714345036]
	TIME [epoch: 24.9 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3051340962570879		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.3051340962570879 | validation: 0.4153090440331994]
	TIME [epoch: 24.9 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3143034504556151		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.3143034504556151 | validation: 0.4047359532824163]
	TIME [epoch: 24.9 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43911800963882086		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.43911800963882086 | validation: 0.7690896968554572]
	TIME [epoch: 24.9 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8094870412970594		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.8094870412970594 | validation: 0.657699946536805]
	TIME [epoch: 24.9 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5685139478584881		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.5685139478584881 | validation: 0.7509665577567963]
	TIME [epoch: 24.9 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9820964023102794		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.9820964023102794 | validation: 1.1112017831420824]
	TIME [epoch: 24.9 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1983094398056116		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 1.1983094398056116 | validation: 1.153720359946199]
	TIME [epoch: 24.9 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.821365709500802		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.821365709500802 | validation: 0.6262044466815394]
	TIME [epoch: 24.9 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5157891003656956		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.5157891003656956 | validation: 0.572781658701344]
	TIME [epoch: 24.9 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4525159536609464		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.4525159536609464 | validation: 0.4318120545095762]
	TIME [epoch: 24.9 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36876440614738476		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.36876440614738476 | validation: 0.425706549015302]
	TIME [epoch: 24.9 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34997869447170127		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.34997869447170127 | validation: 0.4461186999672724]
	TIME [epoch: 24.9 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37034647102908547		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.37034647102908547 | validation: 0.4228801322666645]
	TIME [epoch: 24.9 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3510003435640817		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.3510003435640817 | validation: 0.41996912230195405]
	TIME [epoch: 24.9 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36044477346349174		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.36044477346349174 | validation: 0.45086524537637096]
	TIME [epoch: 24.9 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38044597338272934		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.38044597338272934 | validation: 0.4402894238471129]
	TIME [epoch: 24.9 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3586165364689922		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.3586165364689922 | validation: 0.43574012034705323]
	TIME [epoch: 24.9 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38977658929821263		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.38977658929821263 | validation: 0.5427424853141108]
	TIME [epoch: 24.9 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43461324989770556		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.43461324989770556 | validation: 0.4755497850597384]
	TIME [epoch: 24.9 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40303564185236157		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.40303564185236157 | validation: 0.4731165752752696]
	TIME [epoch: 24.9 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44052677821286007		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.44052677821286007 | validation: 0.5109559575048315]
	TIME [epoch: 24.9 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40945061414016565		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.40945061414016565 | validation: 0.61420736515426]
	TIME [epoch: 24.9 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41135978188077266		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.41135978188077266 | validation: 0.4581279643685124]
	TIME [epoch: 24.9 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3170614279711699		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.3170614279711699 | validation: 0.46342831658220207]
	TIME [epoch: 24.9 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38168950994227774		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.38168950994227774 | validation: 0.45326953824847166]
	TIME [epoch: 24.9 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3497206955414382		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.3497206955414382 | validation: 0.44465916951862233]
	TIME [epoch: 24.9 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3605938173696063		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.3605938173696063 | validation: 0.4102281698768485]
	TIME [epoch: 24.9 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3245905964860567		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.3245905964860567 | validation: 0.4019376325629908]
	TIME [epoch: 24.9 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2972296523113936		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.2972296523113936 | validation: 0.38787799305135423]
	TIME [epoch: 24.9 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3572721697195701		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.3572721697195701 | validation: 0.43291906813384]
	TIME [epoch: 24.9 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36258646676973366		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.36258646676973366 | validation: 0.4542566671478836]
	TIME [epoch: 24.9 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3612018932286097		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.3612018932286097 | validation: 0.41501020934286026]
	TIME [epoch: 24.9 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35233878851046446		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.35233878851046446 | validation: 0.4692218981822407]
	TIME [epoch: 24.9 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4118095340964989		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.4118095340964989 | validation: 0.4891258335277368]
	TIME [epoch: 24.9 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3840510608310189		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.3840510608310189 | validation: 0.446535453703376]
	TIME [epoch: 24.9 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3558462611148071		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.3558462611148071 | validation: 0.4139953868926659]
	TIME [epoch: 24.9 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3143412289748348		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.3143412289748348 | validation: 0.4224795697852855]
	TIME [epoch: 24.9 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32645685331429325		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.32645685331429325 | validation: 0.4021387654741011]
	TIME [epoch: 24.9 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29847842697194116		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.29847842697194116 | validation: 0.4063616207008589]
	TIME [epoch: 24.9 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36388068068735396		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.36388068068735396 | validation: 0.5023451308722203]
	TIME [epoch: 24.9 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4227776060980881		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.4227776060980881 | validation: 0.49372708328688886]
	TIME [epoch: 24.9 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38928741626393926		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.38928741626393926 | validation: 0.43153651871614757]
	TIME [epoch: 24.9 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3758569292223026		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.3758569292223026 | validation: 0.518939415349672]
	TIME [epoch: 24.9 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36402970538501755		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.36402970538501755 | validation: 0.45441528818308796]
	TIME [epoch: 24.9 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35339670192545847		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.35339670192545847 | validation: 0.4175504617018497]
	TIME [epoch: 24.9 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3355819824463493		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.3355819824463493 | validation: 0.38198112144013396]
	TIME [epoch: 24.9 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3455808801860279		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.3455808801860279 | validation: 0.446977355273964]
	TIME [epoch: 24.9 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3716671195845569		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.3716671195845569 | validation: 0.4568495860971496]
	TIME [epoch: 24.9 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4300010500110193		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.4300010500110193 | validation: 0.538729002855713]
	TIME [epoch: 24.9 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43558605737628026		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.43558605737628026 | validation: 0.42892834426408044]
	TIME [epoch: 24.9 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4111499471186433		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.4111499471186433 | validation: 0.4631487389260836]
	TIME [epoch: 24.9 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35675894706864525		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.35675894706864525 | validation: 0.41312879510566264]
	TIME [epoch: 24.9 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34762393538835773		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.34762393538835773 | validation: 0.43449847429565963]
	TIME [epoch: 24.9 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3366727313356823		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.3366727313356823 | validation: 0.39271128500809527]
	TIME [epoch: 24.9 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3564366493024195		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.3564366493024195 | validation: 0.5524744503230931]
	TIME [epoch: 24.9 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45242350076725474		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.45242350076725474 | validation: 0.5548900087955362]
	TIME [epoch: 24.9 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4420718412064636		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.4420718412064636 | validation: 0.507959708017428]
	TIME [epoch: 24.9 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3774037694350997		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.3774037694350997 | validation: 0.4233679430674809]
	TIME [epoch: 24.9 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3421851609142953		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.3421851609142953 | validation: 0.42488656077212017]
	TIME [epoch: 24.9 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37256527882063395		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.37256527882063395 | validation: 0.5783173718360436]
	TIME [epoch: 24.9 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4763913877974367		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.4763913877974367 | validation: 0.5005710205591594]
	TIME [epoch: 24.9 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3865835115310031		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.3865835115310031 | validation: 0.4041460588899852]
	TIME [epoch: 24.9 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31494446507738905		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.31494446507738905 | validation: 0.4348579796035783]
	TIME [epoch: 24.9 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32556893828719347		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.32556893828719347 | validation: 0.3869271271915706]
	TIME [epoch: 24.9 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30709272474997307		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.30709272474997307 | validation: 0.4196589956901439]
	TIME [epoch: 24.9 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3112939728953395		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.3112939728953395 | validation: 0.39086492196597705]
	TIME [epoch: 24.9 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31715070195429806		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.31715070195429806 | validation: 0.41724665754939794]
	TIME [epoch: 24.9 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36151166741320945		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.36151166741320945 | validation: 0.4157746626026115]
	TIME [epoch: 24.9 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31343295656538556		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.31343295656538556 | validation: 0.4018357504940721]
	TIME [epoch: 24.9 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3358533682254119		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.3358533682254119 | validation: 0.4470477785903282]
	TIME [epoch: 24.9 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.371116869956298		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.371116869956298 | validation: 0.5266284424395504]
	TIME [epoch: 24.9 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.359162629619467		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.359162629619467 | validation: 0.40310317690071473]
	TIME [epoch: 24.9 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3331239774987219		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.3331239774987219 | validation: 0.45686209151398305]
	TIME [epoch: 24.9 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43147324170702994		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.43147324170702994 | validation: 0.4884332260246413]
	TIME [epoch: 24.9 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45757494847632046		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.45757494847632046 | validation: 0.5428172520761213]
	TIME [epoch: 24.9 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.471684496467074		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.471684496467074 | validation: 0.5017445547551489]
	TIME [epoch: 24.9 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3988574189464196		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.3988574189464196 | validation: 0.4059076482954816]
	TIME [epoch: 24.8 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32301811213282605		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.32301811213282605 | validation: 0.41138492411567884]
	TIME [epoch: 24.9 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30960651689160024		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.30960651689160024 | validation: 0.367281126115803]
	TIME [epoch: 24.9 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2684232135027369		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.2684232135027369 | validation: 0.3806330655037736]
	TIME [epoch: 24.9 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3113040801265379		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.3113040801265379 | validation: 0.42360620469947535]
	TIME [epoch: 25 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30581493898651035		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.30581493898651035 | validation: 0.34772712065917183]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_639.pth
	Model improved!!!
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2837007754850782		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.2837007754850782 | validation: 0.434486381884871]
	TIME [epoch: 25 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36031936683506927		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.36031936683506927 | validation: 0.39355484768906196]
	TIME [epoch: 25 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2888380850347638		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.2888380850347638 | validation: 0.36288925394669974]
	TIME [epoch: 24.9 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27743920048150505		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.27743920048150505 | validation: 0.36633423717808217]
	TIME [epoch: 24.9 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2856841671039576		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.2856841671039576 | validation: 0.34012376311959025]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_644.pth
	Model improved!!!
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2732983842067639		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.2732983842067639 | validation: 0.3553484981457734]
	TIME [epoch: 25 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2882020100195533		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.2882020100195533 | validation: 0.3593592307004584]
	TIME [epoch: 25 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2765594612876197		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.2765594612876197 | validation: 0.3894568644020526]
	TIME [epoch: 24.9 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3071158710647165		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.3071158710647165 | validation: 0.40362607403629597]
	TIME [epoch: 25 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3059086809699132		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.3059086809699132 | validation: 0.38766445448806336]
	TIME [epoch: 24.9 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35093116237122485		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.35093116237122485 | validation: 0.38472337484241564]
	TIME [epoch: 24.9 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32418068644887976		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.32418068644887976 | validation: 0.4599059442117068]
	TIME [epoch: 24.9 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31896515331990893		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.31896515331990893 | validation: 0.3761302526378771]
	TIME [epoch: 24.9 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2648520822991064		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.2648520822991064 | validation: 0.35784576937628826]
	TIME [epoch: 24.9 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2854627650869884		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.2854627650869884 | validation: 0.37817185159196764]
	TIME [epoch: 25 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3312156219574025		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.3312156219574025 | validation: 0.39623779906743195]
	TIME [epoch: 24.9 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3135012494542774		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.3135012494542774 | validation: 0.395524333845598]
	TIME [epoch: 24.9 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3409425229781806		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.3409425229781806 | validation: 0.3979769146642268]
	TIME [epoch: 24.9 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30711144193241446		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.30711144193241446 | validation: 0.3534947940698451]
	TIME [epoch: 24.9 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28120151163981555		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.28120151163981555 | validation: 0.38338038204928326]
	TIME [epoch: 24.9 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.326686195371071		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.326686195371071 | validation: 0.3821800231254639]
	TIME [epoch: 24.9 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3045213405501001		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.3045213405501001 | validation: 0.39228859533305405]
	TIME [epoch: 24.9 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2916234908365113		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.2916234908365113 | validation: 0.3979066890327033]
	TIME [epoch: 24.9 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30463583124359667		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.30463583124359667 | validation: 0.42037375184550824]
	TIME [epoch: 25 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3896629185501726		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.3896629185501726 | validation: 0.7073062965894505]
	TIME [epoch: 24.9 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5218835236429792		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.5218835236429792 | validation: 0.48528888670869036]
	TIME [epoch: 24.9 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3552773378325603		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.3552773378325603 | validation: 0.3835031060832486]
	TIME [epoch: 24.9 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32191475879225373		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.32191475879225373 | validation: 0.40440917809370186]
	TIME [epoch: 24.9 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29900571991963776		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.29900571991963776 | validation: 0.36977131545121433]
	TIME [epoch: 24.9 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2861355739009295		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.2861355739009295 | validation: 0.34885582255195347]
	TIME [epoch: 25 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2898888088091423		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.2898888088091423 | validation: 0.3986164751444571]
	TIME [epoch: 24.9 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34402651998546235		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.34402651998546235 | validation: 0.44562902277057653]
	TIME [epoch: 24.9 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43986897882527365		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.43986897882527365 | validation: 0.5711432195253686]
	TIME [epoch: 24.9 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39858024055040137		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.39858024055040137 | validation: 0.39605441245626494]
	TIME [epoch: 24.9 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3081111474292728		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.3081111474292728 | validation: 0.3556617584310196]
	TIME [epoch: 24.9 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2802913677396279		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.2802913677396279 | validation: 0.36292564161713275]
	TIME [epoch: 25 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28566984462941175		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.28566984462941175 | validation: 0.38316060857700524]
	TIME [epoch: 24.9 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2964367454859459		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.2964367454859459 | validation: 0.3580381023531149]
	TIME [epoch: 24.9 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2779528782810635		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.2779528782810635 | validation: 0.34801523579242644]
	TIME [epoch: 25 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27504937976276306		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.27504937976276306 | validation: 0.3569346904879649]
	TIME [epoch: 24.9 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27292281337010194		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.27292281337010194 | validation: 0.36098986441196246]
	TIME [epoch: 24.9 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27209833403248773		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.27209833403248773 | validation: 0.3548583308635774]
	TIME [epoch: 24.9 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27993629577999934		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.27993629577999934 | validation: 0.3615887554832187]
	TIME [epoch: 24.9 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2766425828128656		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.2766425828128656 | validation: 0.35313950922646364]
	TIME [epoch: 24.9 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2802666677909439		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.2802666677909439 | validation: 0.36833115038516334]
	TIME [epoch: 25 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2855522777507067		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.2855522777507067 | validation: 0.3803365284223212]
	TIME [epoch: 24.9 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3011207082612714		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.3011207082612714 | validation: 0.38394251697561443]
	TIME [epoch: 24.9 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3078352746106288		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.3078352746106288 | validation: 0.3766434413549294]
	TIME [epoch: 24.9 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2760589398193241		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.2760589398193241 | validation: 0.34440732567678056]
	TIME [epoch: 24.9 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2842389400195617		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.2842389400195617 | validation: 0.35993016346439033]
	TIME [epoch: 24.9 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2809101776085083		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.2809101776085083 | validation: 0.36914592505742166]
	TIME [epoch: 24.9 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3187266478720079		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.3187266478720079 | validation: 0.3878292428700969]
	TIME [epoch: 24.9 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2947374454139207		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.2947374454139207 | validation: 0.4184303651342218]
	TIME [epoch: 24.9 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30492506170212286		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.30492506170212286 | validation: 0.3610073420829352]
	TIME [epoch: 24.9 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28551387483862334		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.28551387483862334 | validation: 0.37095568762469755]
	TIME [epoch: 24.9 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.289445842828967		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.289445842828967 | validation: 0.351748293335124]
	TIME [epoch: 24.9 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28320166927415147		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.28320166927415147 | validation: 0.38123825895776475]
	TIME [epoch: 24.9 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3576090889327697		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.3576090889327697 | validation: 0.602175617119559]
	TIME [epoch: 24.9 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43486250829271694		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.43486250829271694 | validation: 0.5099593975679579]
	TIME [epoch: 24.9 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41050717786279933		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.41050717786279933 | validation: 0.44179005747233774]
	TIME [epoch: 25 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3354923295379549		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.3354923295379549 | validation: 0.3817088194760899]
	TIME [epoch: 24.9 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3040842070861006		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.3040842070861006 | validation: 0.4009822715245424]
	TIME [epoch: 24.9 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33567018658465175		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.33567018658465175 | validation: 0.4042150240509942]
	TIME [epoch: 24.9 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33619989179472226		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.33619989179472226 | validation: 0.4080457295743192]
	TIME [epoch: 24.9 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36409073758369664		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.36409073758369664 | validation: 0.4720641846691415]
	TIME [epoch: 24.9 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3693685671441522		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.3693685671441522 | validation: 0.4025368808293145]
	TIME [epoch: 25 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3267911421951572		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.3267911421951572 | validation: 0.4019002841255002]
	TIME [epoch: 24.9 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36293904451488296		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.36293904451488296 | validation: 0.5086232143994139]
	TIME [epoch: 24.9 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4678117770340826		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.4678117770340826 | validation: 0.5032237599054951]
	TIME [epoch: 25 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4167960362697287		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.4167960362697287 | validation: 0.4119444925211314]
	TIME [epoch: 24.9 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3215014662173193		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.3215014662173193 | validation: 0.3717636535690599]
	TIME [epoch: 24.9 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30999951434930106		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.30999951434930106 | validation: 0.41062470796763917]
	TIME [epoch: 24.9 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3229791457776547		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.3229791457776547 | validation: 0.373715736583201]
	TIME [epoch: 24.9 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3175806663931613		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.3175806663931613 | validation: 0.3952262800909225]
	TIME [epoch: 24.9 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34024211147845945		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.34024211147845945 | validation: 0.3974949337458141]
	TIME [epoch: 25 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37636541984368393		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.37636541984368393 | validation: 0.4571188313676886]
	TIME [epoch: 24.9 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4087426027383644		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.4087426027383644 | validation: 0.46965725747299336]
	TIME [epoch: 24.9 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40969335177848887		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.40969335177848887 | validation: 0.5274091236682739]
	TIME [epoch: 24.9 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47120118506614705		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.47120118506614705 | validation: 0.5500669100566639]
	TIME [epoch: 24.9 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4701342151068842		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.4701342151068842 | validation: 0.4908355201559655]
	TIME [epoch: 24.9 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38360491671171504		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.38360491671171504 | validation: 0.4008768539753665]
	TIME [epoch: 25 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30062627806840114		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.30062627806840114 | validation: 0.42203645618793173]
	TIME [epoch: 24.9 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32282659328654384		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.32282659328654384 | validation: 0.5061601486843179]
	TIME [epoch: 24.9 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.431628573663623		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.431628573663623 | validation: 0.7685416619696639]
	TIME [epoch: 24.9 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6067653322569009		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.6067653322569009 | validation: 0.4589916528757591]
	TIME [epoch: 25 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3800091487203062		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.3800091487203062 | validation: 0.5651880770448079]
	TIME [epoch: 24.9 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45597361841257633		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.45597361841257633 | validation: 0.5316456732006938]
	TIME [epoch: 25 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.385024225290547		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.385024225290547 | validation: 0.4134492779973747]
	TIME [epoch: 24.9 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3359626962412725		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.3359626962412725 | validation: 0.38760100542983905]
	TIME [epoch: 24.9 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30423286907632635		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.30423286907632635 | validation: 0.3910996125230824]
	TIME [epoch: 24.9 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33147060725222954		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.33147060725222954 | validation: 0.3900823171971143]
	TIME [epoch: 24.9 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3019244055344788		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.3019244055344788 | validation: 0.35162753189877466]
	TIME [epoch: 24.9 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2805597778299631		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.2805597778299631 | validation: 0.37418727860022033]
	TIME [epoch: 25 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2892274175202344		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.2892274175202344 | validation: 0.34872849700731917]
	TIME [epoch: 24.9 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2754942024261454		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.2754942024261454 | validation: 0.3409016341173643]
	TIME [epoch: 24.9 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27116006622404454		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.27116006622404454 | validation: 0.3408480047208368]
	TIME [epoch: 25 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.267251969639104		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.267251969639104 | validation: 0.3525898027318852]
	TIME [epoch: 24.9 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2859959942600595		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.2859959942600595 | validation: 0.33673741355451386]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_737.pth
	Model improved!!!
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27698270397732877		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.27698270397732877 | validation: 0.3568488727510984]
	TIME [epoch: 25 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27095684718883917		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.27095684718883917 | validation: 0.33604635655550946]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_739.pth
	Model improved!!!
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2704227134571223		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.2704227134571223 | validation: 0.37962439962843136]
	TIME [epoch: 24.9 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3031778685607914		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.3031778685607914 | validation: 0.3737636291723198]
	TIME [epoch: 24.9 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35174874680262		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.35174874680262 | validation: 0.6527346758213634]
	TIME [epoch: 24.9 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5205591037314394		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.5205591037314394 | validation: 0.5040099387911654]
	TIME [epoch: 24.9 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39315469565244854		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.39315469565244854 | validation: 0.45340225927904554]
	TIME [epoch: 24.9 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4117962808008856		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.4117962808008856 | validation: 0.46468469672041607]
	TIME [epoch: 25 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3654826660042222		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.3654826660042222 | validation: 0.4462808477201774]
	TIME [epoch: 24.9 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3359467775207223		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.3359467775207223 | validation: 0.376954923618669]
	TIME [epoch: 25 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29367010181995923		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.29367010181995923 | validation: 0.3765821342816135]
	TIME [epoch: 24.9 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29089644543485693		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.29089644543485693 | validation: 0.36424293224185017]
	TIME [epoch: 24.9 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2960524870563458		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.2960524870563458 | validation: 0.36315680177449805]
	TIME [epoch: 25 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2953549724616604		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.2953549724616604 | validation: 0.36008415821401146]
	TIME [epoch: 24.9 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27323789159419654		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.27323789159419654 | validation: 0.3358287833181474]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_752.pth
	Model improved!!!
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2766616355779101		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.2766616355779101 | validation: 0.43864158271841436]
	TIME [epoch: 25 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38443128179522307		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.38443128179522307 | validation: 0.46880865616131184]
	TIME [epoch: 25 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43955532055181423		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.43955532055181423 | validation: 0.6805485781156861]
	TIME [epoch: 24.9 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5309816407568376		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.5309816407568376 | validation: 0.448342954418208]
	TIME [epoch: 25 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35922691748673724		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.35922691748673724 | validation: 0.428594190883955]
	TIME [epoch: 25 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34464997697772737		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.34464997697772737 | validation: 0.49099998996664435]
	TIME [epoch: 24.9 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4018610473635305		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.4018610473635305 | validation: 0.44441257404138457]
	TIME [epoch: 24.9 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39680175137930435		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.39680175137930435 | validation: 0.5346433940921353]
	TIME [epoch: 24.9 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43065070762182434		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.43065070762182434 | validation: 0.550306688593863]
	TIME [epoch: 24.9 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4629218956214917		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.4629218956214917 | validation: 0.5173759165917149]
	TIME [epoch: 25 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4325222074124041		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.4325222074124041 | validation: 0.47242778999339613]
	TIME [epoch: 24.9 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3600971172038889		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.3600971172038889 | validation: 0.4405506786179205]
	TIME [epoch: 24.9 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39999627554652917		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.39999627554652917 | validation: 0.536606597449058]
	TIME [epoch: 24.9 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4404623498563509		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.4404623498563509 | validation: 0.49031809446399544]
	TIME [epoch: 24.9 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4191216426391306		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.4191216426391306 | validation: 0.4408349978021449]
	TIME [epoch: 24.9 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3501808744244387		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.3501808744244387 | validation: 0.37569366730878584]
	TIME [epoch: 24.9 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32432826342797505		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.32432826342797505 | validation: 0.42164558825926923]
	TIME [epoch: 24.9 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38138998715754185		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.38138998715754185 | validation: 0.5210330570776857]
	TIME [epoch: 24.9 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.435889958488008		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.435889958488008 | validation: 0.4525553412909695]
	TIME [epoch: 24.9 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35225665711613496		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.35225665711613496 | validation: 0.4850770758371099]
	TIME [epoch: 24.9 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42624095407328255		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.42624095407328255 | validation: 0.5342315391788869]
	TIME [epoch: 24.9 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5502448391128558		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.5502448391128558 | validation: 0.707536658283484]
	TIME [epoch: 25 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6205103860831708		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.6205103860831708 | validation: 0.6641654523265254]
	TIME [epoch: 24.9 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5739593038634196		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.5739593038634196 | validation: 0.7614768174654648]
	TIME [epoch: 24.8 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6167964362579141		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.6167964362579141 | validation: 0.5502818450162392]
	TIME [epoch: 24.9 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49965622821692585		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.49965622821692585 | validation: 0.6037232250003144]
	TIME [epoch: 24.9 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47787765430174284		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.47787765430174284 | validation: 0.507778222193886]
	TIME [epoch: 24.9 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4546689140307681		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.4546689140307681 | validation: 0.5157521251370659]
	TIME [epoch: 24.9 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3884431018876335		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.3884431018876335 | validation: 0.45551517701239164]
	TIME [epoch: 24.9 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34092524799714186		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.34092524799714186 | validation: 0.41304311937828503]
	TIME [epoch: 24.9 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32914600779147096		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.32914600779147096 | validation: 0.3979948652706851]
	TIME [epoch: 24.9 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3305977468134938		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.3305977468134938 | validation: 0.3838174566225453]
	TIME [epoch: 24.9 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28788398645441915		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.28788398645441915 | validation: 0.35554130062556427]
	TIME [epoch: 24.9 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28736368907539067		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.28736368907539067 | validation: 0.38968188815230903]
	TIME [epoch: 24.9 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3310533254121937		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.3310533254121937 | validation: 0.49276838827573166]
	TIME [epoch: 24.9 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4390647572984708		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.4390647572984708 | validation: 0.578489008084062]
	TIME [epoch: 24.9 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46114454970521035		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.46114454970521035 | validation: 0.4735284281375982]
	TIME [epoch: 24.9 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4172130617596793		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.4172130617596793 | validation: 0.47323674420352346]
	TIME [epoch: 24.9 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39462100381813237		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.39462100381813237 | validation: 0.4628863594382947]
	TIME [epoch: 24.9 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48583265705659073		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.48583265705659073 | validation: 0.6653096382115191]
	TIME [epoch: 24.9 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49075173749281914		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.49075173749281914 | validation: 0.4777864784018256]
	TIME [epoch: 24.9 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38049093488280794		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.38049093488280794 | validation: 0.4701953605802082]
	TIME [epoch: 24.9 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38968144703046176		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.38968144703046176 | validation: 0.5168099552927581]
	TIME [epoch: 24.9 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3897235232262172		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.3897235232262172 | validation: 0.45115341705215484]
	TIME [epoch: 24.9 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3657516678773741		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.3657516678773741 | validation: 0.4669846921505909]
	TIME [epoch: 24.9 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3944708881030088		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.3944708881030088 | validation: 0.46975316950155765]
	TIME [epoch: 24.9 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3991659549446791		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.3991659549446791 | validation: 0.4570378705020821]
	TIME [epoch: 24.9 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3836108154332169		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.3836108154332169 | validation: 0.42691607144772875]
	TIME [epoch: 24.9 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3340220858597941		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.3340220858597941 | validation: 0.41453650033076395]
	TIME [epoch: 25 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37144243747844674		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.37144243747844674 | validation: 0.4451982859809108]
	TIME [epoch: 24.9 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.374936852051899		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.374936852051899 | validation: 0.429342782660473]
	TIME [epoch: 24.9 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3563876499316093		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.3563876499316093 | validation: 0.48016714293602164]
	TIME [epoch: 24.9 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3781618675578309		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.3781618675578309 | validation: 0.38128892019744276]
	TIME [epoch: 24.9 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28651393381601253		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.28651393381601253 | validation: 0.37998849403732965]
	TIME [epoch: 24.9 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3092638135788298		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.3092638135788298 | validation: 0.38350691348581467]
	TIME [epoch: 24.9 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30683095596084603		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.30683095596084603 | validation: 0.3835046695046242]
	TIME [epoch: 24.9 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29210632955957605		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.29210632955957605 | validation: 0.3799850772297812]
	TIME [epoch: 24.9 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3211940104452595		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.3211940104452595 | validation: 0.4016615562073939]
	TIME [epoch: 24.9 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3222909002745513		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.3222909002745513 | validation: 0.40280000788287806]
	TIME [epoch: 24.9 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31198452649257874		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.31198452649257874 | validation: 0.39209238505859667]
	TIME [epoch: 24.9 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31368318386678		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.31368318386678 | validation: 0.39065210433097947]
	TIME [epoch: 25 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31958227397469996		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.31958227397469996 | validation: 0.40183419674346466]
	TIME [epoch: 25 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33210639384605195		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.33210639384605195 | validation: 0.38686236443841443]
	TIME [epoch: 24.9 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3218479148728898		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.3218479148728898 | validation: 0.4136054335489756]
	TIME [epoch: 24.9 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34344160192038997		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.34344160192038997 | validation: 0.42445293443004595]
	TIME [epoch: 24.9 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3674284263361257		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.3674284263361257 | validation: 0.4365326240222831]
	TIME [epoch: 24.9 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36491615632292557		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.36491615632292557 | validation: 0.4162934891718304]
	TIME [epoch: 25 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3612507044186053		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.3612507044186053 | validation: 0.46128998146257316]
	TIME [epoch: 24.9 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40563383194994873		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.40563383194994873 | validation: 0.47096819671241963]
	TIME [epoch: 24.9 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.398253032711892		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.398253032711892 | validation: 0.4277803888427842]
	TIME [epoch: 24.9 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3407889052486966		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.3407889052486966 | validation: 0.38728728186434214]
	TIME [epoch: 24.9 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30295992433092656		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.30295992433092656 | validation: 0.3663031666486808]
	TIME [epoch: 24.9 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28744396780225234		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.28744396780225234 | validation: 0.35063838252675256]
	TIME [epoch: 25 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26190194856253496		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.26190194856253496 | validation: 0.3218074194185771]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_826.pth
	Model improved!!!
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24619079288834736		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.24619079288834736 | validation: 0.3371466592300179]
	TIME [epoch: 24.9 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2501331248286236		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.2501331248286236 | validation: 0.3211234975008946]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_828.pth
	Model improved!!!
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24546176385551458		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.24546176385551458 | validation: 0.33447380977562385]
	TIME [epoch: 24.9 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24857795873198277		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.24857795873198277 | validation: 0.330716849227593]
	TIME [epoch: 24.8 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2538137472720734		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.2538137472720734 | validation: 0.34165895453694894]
	TIME [epoch: 24.9 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26315431461022337		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.26315431461022337 | validation: 0.3421568653450369]
	TIME [epoch: 24.9 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.262305361035629		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.262305361035629 | validation: 0.34976070913177126]
	TIME [epoch: 24.9 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27327486291381997		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.27327486291381997 | validation: 0.3522597221241993]
	TIME [epoch: 24.9 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2693751031062814		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.2693751031062814 | validation: 0.33014738694691065]
	TIME [epoch: 24.9 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2458825916934174		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.2458825916934174 | validation: 0.3187276486215398]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240309_135747/states/model_tr_study6_836.pth
	Model improved!!!
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24324374888473987		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.24324374888473987 | validation: 0.322823526018209]
	TIME [epoch: 24.9 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24934221708868082		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.24934221708868082 | validation: 0.32800155049825014]
	TIME [epoch: 24.9 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26135872223636314		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.26135872223636314 | validation: 0.3379473016302908]
	TIME [epoch: 24.9 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24906725527790555		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.24906725527790555 | validation: 0.3248523177769468]
	TIME [epoch: 24.9 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23712700978982057		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.23712700978982057 | validation: 0.3192375598396336]
	TIME [epoch: 24.9 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2515428668900025		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.2515428668900025 | validation: 0.3215420938530217]
	TIME [epoch: 24.9 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25246073298888966		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.25246073298888966 | validation: 0.3302244645513954]
	TIME [epoch: 24.9 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25500981999862254		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.25500981999862254 | validation: 0.3450808482940542]
	TIME [epoch: 24.9 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2859858364641271		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.2859858364641271 | validation: 0.3502871509975637]
	TIME [epoch: 24.9 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3101790849227798		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.3101790849227798 | validation: 0.42361356051947596]
	TIME [epoch: 24.9 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3562437917463088		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.3562437917463088 | validation: 0.39362275110119205]
	TIME [epoch: 24.9 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3297756042155552		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.3297756042155552 | validation: 0.3537686248491618]
	TIME [epoch: 24.9 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26681936370519244		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.26681936370519244 | validation: 0.3309978059908788]
	TIME [epoch: 24.9 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2630768181989359		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.2630768181989359 | validation: 0.3489355294517887]
	TIME [epoch: 24.9 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27708947472381007		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.27708947472381007 | validation: 0.34608066955437594]
	TIME [epoch: 24.9 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2628466600741644		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.2628466600741644 | validation: 0.3493606714818155]
	TIME [epoch: 24.9 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28087525996332746		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.28087525996332746 | validation: 0.36493573654442435]
	TIME [epoch: 24.9 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2871129146943745		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.2871129146943745 | validation: 0.35276909449052496]
	TIME [epoch: 24.9 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2860056656119874		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.2860056656119874 | validation: 0.36402998221528593]
	TIME [epoch: 24.9 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31235081420662886		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.31235081420662886 | validation: 0.3822077508860835]
	TIME [epoch: 24.9 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31220993160231275		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.31220993160231275 | validation: 0.37576076844897843]
	TIME [epoch: 24.9 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29495530547882715		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.29495530547882715 | validation: 0.3384098209525346]
	TIME [epoch: 24.9 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2765048282609076		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.2765048282609076 | validation: 0.3344004104756168]
	TIME [epoch: 24.9 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2801938656915903		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.2801938656915903 | validation: 0.34623404146916814]
	TIME [epoch: 24.9 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27812706795575043		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.27812706795575043 | validation: 0.3526702345112298]
	TIME [epoch: 24.9 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2975619496063436		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.2975619496063436 | validation: 0.38125817162339515]
	TIME [epoch: 24.9 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31130155445974705		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.31130155445974705 | validation: 0.35034534476809515]
	TIME [epoch: 24.9 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27719828594725937		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.27719828594725937 | validation: 0.346961690001249]
	TIME [epoch: 24.9 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2833299877749231		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.2833299877749231 | validation: 0.36785883540840586]
	TIME [epoch: 24.9 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2812356839132999		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.2812356839132999 | validation: 0.3541942645204537]
	TIME [epoch: 24.9 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2755010076908738		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.2755010076908738 | validation: 0.36646592988512056]
	TIME [epoch: 24.9 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28161744077289746		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.28161744077289746 | validation: 0.3427873764441243]
	TIME [epoch: 24.9 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25611741563475254		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.25611741563475254 | validation: 0.3446754460530191]
	TIME [epoch: 24.9 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2584392889633653		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.2584392889633653 | validation: 0.34473898571979855]
	TIME [epoch: 24.9 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24510401122579012		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.24510401122579012 | validation: 0.32216665439844194]
	TIME [epoch: 25 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24093140513412734		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.24093140513412734 | validation: 0.32438942212117455]
	TIME [epoch: 24.9 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24496922376320182		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.24496922376320182 | validation: 0.32510401223339486]
	TIME [epoch: 25 sec]
EPOCH 874/2000:
	Training over batches...
