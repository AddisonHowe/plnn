Args:
Namespace(name='model_tr_study6', outdir='out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2', training_data='data/transition_rate_studies/tr_study6/tr_study6_training/r2', validation_data='data/transition_rate_studies/tr_study6/tr_study6_validation/r2', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2487614463

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.365111931087057		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.365111931087057 | validation: 8.121754436764444]
	TIME [epoch: 112 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.821158509503407		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.821158509503407 | validation: 6.9763497314912275]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.25214370941135		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.25214370941135 | validation: 8.057315313058782]
	TIME [epoch: 24.9 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.602185788519677		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.602185788519677 | validation: 6.568668232520718]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.65748183491735		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.65748183491735 | validation: 6.306439995619674]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.10715415944987		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.10715415944987 | validation: 5.6395671994304575]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.920126330189101		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.920126330189101 | validation: 6.2373458646073185]
	TIME [epoch: 25 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.965114636733631		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.965114636733631 | validation: 5.350835716852412]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.6922683906378255		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.6922683906378255 | validation: 5.7534226691976915]
	TIME [epoch: 24.9 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.4669416550819		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.4669416550819 | validation: 4.929701056791913]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.940595443831237		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.940595443831237 | validation: 4.614537107678638]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.522911792294495		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.522911792294495 | validation: 4.145395294966022]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.070499355526698		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.070499355526698 | validation: 3.756829394660589]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.078461449255954		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.078461449255954 | validation: 3.918012305111239]
	TIME [epoch: 25 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8976645576974738		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8976645576974738 | validation: 3.74809607343534]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6756509714724226		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6756509714724226 | validation: 3.5365553392708073]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.517083617525798		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.517083617525798 | validation: 3.544201345825038]
	TIME [epoch: 25 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.428526557295544		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.428526557295544 | validation: 3.2916611906001423]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4085335536592085		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4085335536592085 | validation: 3.688402181643281]
	TIME [epoch: 25 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4639117617686033		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4639117617686033 | validation: 3.20703264832762]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3412349942777926		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3412349942777926 | validation: 3.0902672658167423]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0076250396640636		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0076250396640636 | validation: 3.062760302054929]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.02033993692951		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.02033993692951 | validation: 3.0439996558513758]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8731070101120304		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8731070101120304 | validation: 4.070567522781804]
	TIME [epoch: 24.9 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.342563274947669		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.342563274947669 | validation: 2.959873990150768]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.7824399773378925		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.7824399773378925 | validation: 5.469192646415648]
	TIME [epoch: 25 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8828455325278854		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8828455325278854 | validation: 5.663711012927987]
	TIME [epoch: 24.9 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.350213954758868		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.350213954758868 | validation: 3.4760545069282593]
	TIME [epoch: 25 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.99274721186222		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.99274721186222 | validation: 3.076636928236411]
	TIME [epoch: 24.9 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3035291383430394		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3035291383430394 | validation: 2.7719450148909948]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8669817219111104		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8669817219111104 | validation: 2.8989929699883885]
	TIME [epoch: 25 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9267857985400547		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9267857985400547 | validation: 2.756645710286658]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.634287337308023		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.634287337308023 | validation: 2.4675217733570403]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.473604877236722		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.473604877236722 | validation: 2.472845869273601]
	TIME [epoch: 25 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.454160381160251		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.454160381160251 | validation: 2.99167680488146]
	TIME [epoch: 24.9 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6018540697602286		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6018540697602286 | validation: 2.237828885446593]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5044055342066858		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5044055342066858 | validation: 3.0522572207719345]
	TIME [epoch: 25 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.43225958641777		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.43225958641777 | validation: 2.9225028249057696]
	TIME [epoch: 24.9 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4506582733652325		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4506582733652325 | validation: 2.2215342351981464]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2930986421325423		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2930986421325423 | validation: 2.0832669758400035]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1158063589331126		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1158063589331126 | validation: 2.5919038000166394]
	TIME [epoch: 24.9 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3617446836661933		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3617446836661933 | validation: 1.9969906922026668]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.997110506463692		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.997110506463692 | validation: 2.4427579143369544]
	TIME [epoch: 25 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.206396832868395		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.206396832868395 | validation: 1.98400078914883]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0523862189537034		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0523862189537034 | validation: 1.7750046940790725]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9626904120706345		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9626904120706345 | validation: 3.0761576018465053]
	TIME [epoch: 24.9 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4026444989471605		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4026444989471605 | validation: 1.728099083578082]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6699385282489898		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6699385282489898 | validation: 1.9271347924570155]
	TIME [epoch: 24.9 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9288975654214964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9288975654214964 | validation: 2.0424316246027883]
	TIME [epoch: 24.9 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.824171315444266		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.824171315444266 | validation: 1.556405150340252]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6855922158090175		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 1.6855922158090175 | validation: 1.8255242627237045]
	TIME [epoch: 24.9 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9657770391797285		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 1.9657770391797285 | validation: 1.5502828288467743]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6039386976564505		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 1.6039386976564505 | validation: 1.457907318736264]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5457393505825139		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 1.5457393505825139 | validation: 1.5588161113295531]
	TIME [epoch: 25 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5216281228125015		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 1.5216281228125015 | validation: 1.4645944849977344]
	TIME [epoch: 25 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5989518464556187		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 1.5989518464556187 | validation: 1.2763735541807504]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4385200212994274		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 1.4385200212994274 | validation: 1.1950900075652564]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3126201037715823		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 1.3126201037715823 | validation: 1.1812502711679345]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1788386487921003		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 1.1788386487921003 | validation: 1.0419933396023797]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1018032657806196		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 1.1018032657806196 | validation: 1.5260199191599133]
	TIME [epoch: 25 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9359173133263978		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 1.9359173133263978 | validation: 1.5323171035350402]
	TIME [epoch: 25 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.412772787928532		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 1.412772787928532 | validation: 1.1553289984108763]
	TIME [epoch: 25 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1586044029716431		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 1.1586044029716431 | validation: 0.8456453983177242]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9393706112431245		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 0.9393706112431245 | validation: 1.7887872577194037]
	TIME [epoch: 25 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4758163345611013		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 1.4758163345611013 | validation: 1.7378397984550582]
	TIME [epoch: 25 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.606925163557754		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 1.606925163557754 | validation: 1.5281919145105718]
	TIME [epoch: 25 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2729204183366254		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 1.2729204183366254 | validation: 0.8267661677674137]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0477989564648413		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 1.0477989564648413 | validation: 1.3502439410798126]
	TIME [epoch: 25 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0513854985692634		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 1.0513854985692634 | validation: 0.8700119918410733]
	TIME [epoch: 25 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.183996974054273		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 1.183996974054273 | validation: 1.2597170737046102]
	TIME [epoch: 25 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4768264114841925		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 1.4768264114841925 | validation: 2.0660434688956824]
	TIME [epoch: 25 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2247442607763854		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 1.2247442607763854 | validation: 0.8705657755749835]
	TIME [epoch: 25 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9936361261757642		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 0.9936361261757642 | validation: 1.7032295175351118]
	TIME [epoch: 25 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5492651628639655		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 1.5492651628639655 | validation: 1.159562984695692]
	TIME [epoch: 24.9 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9742945242030409		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.9742945242030409 | validation: 0.8181039272906659]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_75.pth
	Model improved!!!
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4847915503472813		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 1.4847915503472813 | validation: 1.924786201228912]
	TIME [epoch: 25 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2560431798179612		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 1.2560431798179612 | validation: 0.7984984227777381]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8945229665398078		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 0.8945229665398078 | validation: 0.9053362609917572]
	TIME [epoch: 24.9 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7779138484996815		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 0.7779138484996815 | validation: 0.8208557593842157]
	TIME [epoch: 25 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8172246489266344		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.8172246489266344 | validation: 0.6192261967038428]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_80.pth
	Model improved!!!
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7761902424482465		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 0.7761902424482465 | validation: 0.929847750550565]
	TIME [epoch: 24.9 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8771466290899648		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 0.8771466290899648 | validation: 0.6996722673645297]
	TIME [epoch: 25 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.937022635495188		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 0.937022635495188 | validation: 0.6128932093345348]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_83.pth
	Model improved!!!
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7196101454009126		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 0.7196101454009126 | validation: 0.7473031221017107]
	TIME [epoch: 24.9 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.838928138304399		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.838928138304399 | validation: 1.792404393478314]
	TIME [epoch: 25 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3327646352230529		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 1.3327646352230529 | validation: 0.9791243917485176]
	TIME [epoch: 24.9 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.108810415696462		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 3.108810415696462 | validation: 3.486770324987708]
	TIME [epoch: 24.9 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.072872770473191		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 2.072872770473191 | validation: 1.0352525662347705]
	TIME [epoch: 25 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1567515170043752		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 1.1567515170043752 | validation: 1.1823300944441133]
	TIME [epoch: 25 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1686423481025423		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 1.1686423481025423 | validation: 1.4586465143393768]
	TIME [epoch: 24.9 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4497248048427305		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 1.4497248048427305 | validation: 1.0418974528716023]
	TIME [epoch: 25 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1812474829137882		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 1.1812474829137882 | validation: 1.0502732687323788]
	TIME [epoch: 25 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0315611964059435		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 1.0315611964059435 | validation: 0.811591446072205]
	TIME [epoch: 24.9 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9980842238139488		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 0.9980842238139488 | validation: 0.9136150328048332]
	TIME [epoch: 25 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.92553793428106		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.92553793428106 | validation: 0.733271224830191]
	TIME [epoch: 24.9 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.924299148096775		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 0.924299148096775 | validation: 0.7077206719896216]
	TIME [epoch: 24.9 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.509800635365755		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 1.509800635365755 | validation: 1.4295402555449226]
	TIME [epoch: 24.9 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0763357403001161		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 1.0763357403001161 | validation: 0.8165229841942271]
	TIME [epoch: 25 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8534622606124969		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 0.8534622606124969 | validation: 0.7801612189185849]
	TIME [epoch: 24.9 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8851298997981975		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.8851298997981975 | validation: 0.8008231545471466]
	TIME [epoch: 25 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9322505659364182		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 0.9322505659364182 | validation: 0.860465790253679]
	TIME [epoch: 25 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0875984153671772		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 1.0875984153671772 | validation: 0.8119378934981158]
	TIME [epoch: 24.9 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9065917645361735		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 0.9065917645361735 | validation: 0.6486323336965879]
	TIME [epoch: 24.9 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8117944402128556		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 0.8117944402128556 | validation: 0.7311883449413884]
	TIME [epoch: 25 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8133715776971782		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.8133715776971782 | validation: 0.6385791718242506]
	TIME [epoch: 24.9 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7517279721166544		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 0.7517279721166544 | validation: 0.821842594518991]
	TIME [epoch: 25 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9220656796760051		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.9220656796760051 | validation: 1.0652339862265723]
	TIME [epoch: 25 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.050573087534576		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 1.050573087534576 | validation: 0.9539245449105123]
	TIME [epoch: 25 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0624790853800374		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 1.0624790853800374 | validation: 0.9038877734501302]
	TIME [epoch: 25 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8545166438114655		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.8545166438114655 | validation: 1.0426082622237263]
	TIME [epoch: 25 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8894378326438235		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 0.8894378326438235 | validation: 0.8548709066865109]
	TIME [epoch: 24.9 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7907523606201636		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 0.7907523606201636 | validation: 1.0149571245486235]
	TIME [epoch: 25 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3793620510885078		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 1.3793620510885078 | validation: 1.6808145145551578]
	TIME [epoch: 24.9 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.112219619710002		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 1.112219619710002 | validation: 1.8796907263412999]
	TIME [epoch: 24.9 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.708156099544191		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 1.708156099544191 | validation: 1.0300853838964912]
	TIME [epoch: 25 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1976415342806601		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 1.1976415342806601 | validation: 1.2681082641867258]
	TIME [epoch: 25 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0144324083282519		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 1.0144324083282519 | validation: 0.7733885937545266]
	TIME [epoch: 24.9 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7955472660158573		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 0.7955472660158573 | validation: 0.711276534460674]
	TIME [epoch: 25 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7040151154344689		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 0.7040151154344689 | validation: 0.8382520290824498]
	TIME [epoch: 25 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0039015638024935		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 1.0039015638024935 | validation: 0.8240438301140155]
	TIME [epoch: 24.9 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9678904079493647		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 0.9678904079493647 | validation: 1.2290879956770189]
	TIME [epoch: 25 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9377718369516018		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 0.9377718369516018 | validation: 0.7299637037797283]
	TIME [epoch: 25 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7880717736627971		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 0.7880717736627971 | validation: 0.8251369339570022]
	TIME [epoch: 24.9 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9190230086548803		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 0.9190230086548803 | validation: 0.9455757627350373]
	TIME [epoch: 25 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0304466551646347		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 1.0304466551646347 | validation: 0.9056053617421509]
	TIME [epoch: 25 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9268551234529698		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 0.9268551234529698 | validation: 0.8608377252041988]
	TIME [epoch: 24.9 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8068199445087287		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 0.8068199445087287 | validation: 0.9240339823147172]
	TIME [epoch: 25 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7738888254126132		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 0.7738888254126132 | validation: 0.7425797218244928]
	TIME [epoch: 25 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8555329509598619		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 0.8555329509598619 | validation: 0.9167701327484236]
	TIME [epoch: 24.9 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.758713432829103		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.758713432829103 | validation: 0.999420008220044]
	TIME [epoch: 25 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0403724529950076		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 1.0403724529950076 | validation: 0.9055242827269484]
	TIME [epoch: 24.9 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8686156169845196		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 0.8686156169845196 | validation: 1.1694062455205236]
	TIME [epoch: 24.9 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9765486902033997		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 0.9765486902033997 | validation: 0.7423810653699389]
	TIME [epoch: 24.9 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8612473342304412		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.8612473342304412 | validation: 0.780718095574876]
	TIME [epoch: 24.9 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6962690266601017		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.6962690266601017 | validation: 0.6740395107916549]
	TIME [epoch: 24.9 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7082565877790431		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.7082565877790431 | validation: 0.6584720801061633]
	TIME [epoch: 25 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6989740870719883		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 0.6989740870719883 | validation: 1.3055318464301038]
	TIME [epoch: 25 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8004980659666605		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 1.8004980659666605 | validation: 0.8510348232952365]
	TIME [epoch: 24.9 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9512656982344432		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 0.9512656982344432 | validation: 0.7140739923017669]
	TIME [epoch: 25 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8535232696843023		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.8535232696843023 | validation: 1.0036803943850376]
	TIME [epoch: 25 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0554482721240321		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 1.0554482721240321 | validation: 0.9681600340051837]
	TIME [epoch: 24.9 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8727821745397607		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.8727821745397607 | validation: 0.8014815820134175]
	TIME [epoch: 24.9 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.796200218505125		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.796200218505125 | validation: 0.8902217620727534]
	TIME [epoch: 25 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9228261535939173		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 0.9228261535939173 | validation: 0.951491487692513]
	TIME [epoch: 24.9 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8696258885777077		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.8696258885777077 | validation: 0.7864139734843056]
	TIME [epoch: 25 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7708278372072046		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.7708278372072046 | validation: 0.7972223049323108]
	TIME [epoch: 25 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7783845545663867		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.7783845545663867 | validation: 1.4370913805372882]
	TIME [epoch: 24.9 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1852428431934607		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 1.1852428431934607 | validation: 0.7208903503772914]
	TIME [epoch: 24.9 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7796274581694158		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.7796274581694158 | validation: 0.6655578426175527]
	TIME [epoch: 25 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7760315998135486		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.7760315998135486 | validation: 0.8421521124636178]
	TIME [epoch: 24.9 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7116866957089794		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.7116866957089794 | validation: 0.7549475361966702]
	TIME [epoch: 25 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6980693480939714		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.6980693480939714 | validation: 0.7773422865744296]
	TIME [epoch: 25 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7877126336505502		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 0.7877126336505502 | validation: 0.9971924507257822]
	TIME [epoch: 24.9 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8418719539275207		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.8418719539275207 | validation: 0.7610687702575046]
	TIME [epoch: 25 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7227918835264985		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.7227918835264985 | validation: 0.768633949675974]
	TIME [epoch: 25 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7143026407458767		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 0.7143026407458767 | validation: 0.6887032984274265]
	TIME [epoch: 24.9 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8185252143308066		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 0.8185252143308066 | validation: 0.7694804136333749]
	TIME [epoch: 25 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7534575164509818		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 0.7534575164509818 | validation: 0.8239877837884382]
	TIME [epoch: 25 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.786358505480153		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.786358505480153 | validation: 0.7398133575036205]
	TIME [epoch: 24.9 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8064505879513333		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.8064505879513333 | validation: 0.9117480175685685]
	TIME [epoch: 25 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8576808913952367		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.8576808913952367 | validation: 0.8587531911339447]
	TIME [epoch: 25 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8022284987101368		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.8022284987101368 | validation: 0.768645357535179]
	TIME [epoch: 24.9 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0594957471551982		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 1.0594957471551982 | validation: 1.5180884353688628]
	TIME [epoch: 25 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9216495427085235		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.9216495427085235 | validation: 0.7018091112364668]
	TIME [epoch: 25 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9892294245697775		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.9892294245697775 | validation: 1.4247474344822764]
	TIME [epoch: 24.9 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.879443125444775		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 0.879443125444775 | validation: 0.788122729040997]
	TIME [epoch: 25 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7728580456874484		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 0.7728580456874484 | validation: 0.7152960024402664]
	TIME [epoch: 25 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7761071447063312		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.7761071447063312 | validation: 0.7832668955077309]
	TIME [epoch: 24.9 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7360311500853121		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.7360311500853121 | validation: 0.6674315174201949]
	TIME [epoch: 25 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6801730904239711		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.6801730904239711 | validation: 0.7925626179270588]
	TIME [epoch: 25 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7409585160564945		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.7409585160564945 | validation: 0.7001948889220364]
	TIME [epoch: 25 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.684089602458224		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.684089602458224 | validation: 0.6169214882721655]
	TIME [epoch: 25 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7728850042568729		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.7728850042568729 | validation: 0.7291609585166938]
	TIME [epoch: 25 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7295601684926274		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.7295601684926274 | validation: 0.6933398930672848]
	TIME [epoch: 24.9 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7038443814965262		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.7038443814965262 | validation: 0.7667017925431995]
	TIME [epoch: 25 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9406743882185358		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 0.9406743882185358 | validation: 1.200208229399221]
	TIME [epoch: 25 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7761895533650034		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 1.7761895533650034 | validation: 1.2247826656684742]
	TIME [epoch: 24.9 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9647406790782023		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.9647406790782023 | validation: 0.69202165174301]
	TIME [epoch: 25 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7978690601985099		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.7978690601985099 | validation: 1.014794330622361]
	TIME [epoch: 25 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8999425095849163		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.8999425095849163 | validation: 0.7425648609312789]
	TIME [epoch: 24.9 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9026241677211122		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.9026241677211122 | validation: 0.8961509858253329]
	TIME [epoch: 25 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7909998630242163		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.7909998630242163 | validation: 0.6577532672237183]
	TIME [epoch: 25 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6918217897181221		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.6918217897181221 | validation: 0.8348172099222668]
	TIME [epoch: 25 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.748189963613233		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.748189963613233 | validation: 0.8118693035913761]
	TIME [epoch: 25 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8059764466246302		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.8059764466246302 | validation: 0.8040617039081872]
	TIME [epoch: 25 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8792652186725538		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.8792652186725538 | validation: 1.170035463386436]
	TIME [epoch: 24.9 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9908151432222971		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.9908151432222971 | validation: 0.7727507163795971]
	TIME [epoch: 25 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7495623048427461		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.7495623048427461 | validation: 0.6801215137847106]
	TIME [epoch: 25 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6937996511646489		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.6937996511646489 | validation: 0.7827940708389565]
	TIME [epoch: 24.9 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8586259567171014		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.8586259567171014 | validation: 0.6258234799294481]
	TIME [epoch: 25 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7708449481119819		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.7708449481119819 | validation: 1.0849655838184262]
	TIME [epoch: 25 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8882474059737678		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.8882474059737678 | validation: 0.6944322096147997]
	TIME [epoch: 24.9 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8764149114748124		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.8764149114748124 | validation: 0.9564863717694683]
	TIME [epoch: 25 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.925645399128981		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.925645399128981 | validation: 0.8545946045884065]
	TIME [epoch: 25 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9432849537091283		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.9432849537091283 | validation: 0.9132189519196646]
	TIME [epoch: 25 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8609292934065381		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.8609292934065381 | validation: 1.1537827635918045]
	TIME [epoch: 25 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.922329340955724		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.922329340955724 | validation: 0.794649802959992]
	TIME [epoch: 25 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7897067304162387		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.7897067304162387 | validation: 1.3318540644912984]
	TIME [epoch: 24.9 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4118703747482666		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 1.4118703747482666 | validation: 1.1443492042628645]
	TIME [epoch: 25 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0055167549272195		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 1.0055167549272195 | validation: 0.8938548481289061]
	TIME [epoch: 25 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8122061125995639		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.8122061125995639 | validation: 0.7219583446859721]
	TIME [epoch: 25 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7715700140130923		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.7715700140130923 | validation: 0.6847085623070857]
	TIME [epoch: 25 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7424395315365001		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.7424395315365001 | validation: 0.6252265938709757]
	TIME [epoch: 25 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6457664081415249		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.6457664081415249 | validation: 0.6384663243560982]
	TIME [epoch: 25 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6827218200580396		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.6827218200580396 | validation: 0.7918947446854808]
	TIME [epoch: 25 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7282001482785063		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.7282001482785063 | validation: 0.5733224216397276]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_206.pth
	Model improved!!!
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6303950362345161		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.6303950362345161 | validation: 0.6120672009153715]
	TIME [epoch: 24.9 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6025847459654656		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.6025847459654656 | validation: 0.5808181818077262]
	TIME [epoch: 25 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6084903378786009		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.6084903378786009 | validation: 0.5323081258301868]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_209.pth
	Model improved!!!
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7748740603066924		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.7748740603066924 | validation: 1.252248187476245]
	TIME [epoch: 24.9 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0263468352592469		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 1.0263468352592469 | validation: 0.8292493356492427]
	TIME [epoch: 24.9 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8167880844910675		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.8167880844910675 | validation: 0.8959855407593552]
	TIME [epoch: 24.9 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7684354372308617		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.7684354372308617 | validation: 0.6438275413046196]
	TIME [epoch: 24.9 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7105638073189195		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.7105638073189195 | validation: 0.5908086539315321]
	TIME [epoch: 24.9 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.797758515377563		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.797758515377563 | validation: 0.9046693476436388]
	TIME [epoch: 24.9 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8812119862932002		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.8812119862932002 | validation: 0.7055362291409426]
	TIME [epoch: 24.9 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7544744188919394		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.7544744188919394 | validation: 0.6520672031671424]
	TIME [epoch: 24.9 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.644689439204443		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.644689439204443 | validation: 0.5707303399752681]
	TIME [epoch: 24.9 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.796240767039412		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.796240767039412 | validation: 0.9134322750579591]
	TIME [epoch: 24.9 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8462397977631537		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.8462397977631537 | validation: 0.5603991836922718]
	TIME [epoch: 24.9 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6643758471063046		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.6643758471063046 | validation: 0.7329222470403189]
	TIME [epoch: 24.9 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8154022670019606		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.8154022670019606 | validation: 0.6558714135002613]
	TIME [epoch: 24.9 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7546762809115231		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.7546762809115231 | validation: 0.6426634202886011]
	TIME [epoch: 24.9 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5905057960117065		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.5905057960117065 | validation: 0.6425857478384848]
	TIME [epoch: 24.9 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6332359898514666		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.6332359898514666 | validation: 0.6061695263257525]
	TIME [epoch: 24.9 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.650901919076697		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.650901919076697 | validation: 0.9170236063798488]
	TIME [epoch: 24.9 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.70293305741557		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.70293305741557 | validation: 0.6407092362112232]
	TIME [epoch: 24.9 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9299254165417383		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.9299254165417383 | validation: 1.0442200180761012]
	TIME [epoch: 24.9 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8410381038773453		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.8410381038773453 | validation: 0.6432737791043016]
	TIME [epoch: 24.9 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6508213676232071		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.6508213676232071 | validation: 0.670679363172307]
	TIME [epoch: 24.9 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6449961345928601		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.6449961345928601 | validation: 0.6622484866063825]
	TIME [epoch: 24.9 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6363351377614104		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.6363351377614104 | validation: 0.6299455583606094]
	TIME [epoch: 24.9 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6977016995175311		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.6977016995175311 | validation: 0.8962871296059589]
	TIME [epoch: 24.9 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8721251021159507		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.8721251021159507 | validation: 0.9940635048066634]
	TIME [epoch: 24.9 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9329028662001496		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.9329028662001496 | validation: 0.8121620958630547]
	TIME [epoch: 24.9 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6463465763859123		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.6463465763859123 | validation: 0.6163348234503866]
	TIME [epoch: 24.9 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.667325426439846		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.667325426439846 | validation: 0.6945525350801803]
	TIME [epoch: 24.9 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7318354925416222		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.7318354925416222 | validation: 0.5757857818920784]
	TIME [epoch: 24.9 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6439403552500862		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.6439403552500862 | validation: 0.6262908270189944]
	TIME [epoch: 24.9 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7101432431614518		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.7101432431614518 | validation: 0.6968475195416585]
	TIME [epoch: 24.9 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6659717231596668		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.6659717231596668 | validation: 0.6894523324815068]
	TIME [epoch: 24.9 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7118826977984778		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.7118826977984778 | validation: 0.6163153725955299]
	TIME [epoch: 24.9 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7207314519505458		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.7207314519505458 | validation: 0.6303726350523807]
	TIME [epoch: 24.9 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6159416543883817		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.6159416543883817 | validation: 1.141425244315506]
	TIME [epoch: 24.9 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9023381125405393		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.9023381125405393 | validation: 0.6486357279530444]
	TIME [epoch: 24.9 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.625722828074829		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.625722828074829 | validation: 0.5465936679138454]
	TIME [epoch: 24.9 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6404472431199693		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.6404472431199693 | validation: 0.5403163974553595]
	TIME [epoch: 24.9 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5812733072202996		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.5812733072202996 | validation: 0.5712312736733085]
	TIME [epoch: 24.9 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6548283000317906		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.6548283000317906 | validation: 0.7765084318855331]
	TIME [epoch: 24.9 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0218869483700415		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 1.0218869483700415 | validation: 0.7617564551839838]
	TIME [epoch: 24.9 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6927544174609508		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.6927544174609508 | validation: 0.7321424593548701]
	TIME [epoch: 24.9 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9096857082786456		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.9096857082786456 | validation: 0.6447852747376288]
	TIME [epoch: 24.9 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.848031493702058		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.848031493702058 | validation: 1.1077622885868292]
	TIME [epoch: 24.9 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9157663208351693		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.9157663208351693 | validation: 0.7612489989416084]
	TIME [epoch: 24.9 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.835521812672962		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.835521812672962 | validation: 0.7018033870955963]
	TIME [epoch: 24.9 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7088526479105853		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.7088526479105853 | validation: 0.6210957014664519]
	TIME [epoch: 24.9 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8149952518312773		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.8149952518312773 | validation: 0.6271613836969908]
	TIME [epoch: 24.9 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6104282289855713		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.6104282289855713 | validation: 0.6094467395969899]
	TIME [epoch: 24.9 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5748594631428602		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.5748594631428602 | validation: 0.5434214942081144]
	TIME [epoch: 24.9 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6044515044381991		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.6044515044381991 | validation: 0.6973298446593422]
	TIME [epoch: 24.9 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6255050544678371		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.6255050544678371 | validation: 0.5522456014903616]
	TIME [epoch: 24.9 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6162646635868281		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.6162646635868281 | validation: 0.6259358471491211]
	TIME [epoch: 24.9 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6660847601897951		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.6660847601897951 | validation: 0.9991823943791349]
	TIME [epoch: 24.9 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7694006229458508		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.7694006229458508 | validation: 0.631544371794017]
	TIME [epoch: 24.9 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6846030485457003		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.6846030485457003 | validation: 0.49247617097143603]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_265.pth
	Model improved!!!
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6145664449216564		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.6145664449216564 | validation: 0.6570451840677649]
	TIME [epoch: 24.9 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5893237301087104		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.5893237301087104 | validation: 0.5393378045072652]
	TIME [epoch: 24.9 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5462212097549352		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.5462212097549352 | validation: 0.6436806676011432]
	TIME [epoch: 24.9 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5410178570098461		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.5410178570098461 | validation: 0.49901832541286284]
	TIME [epoch: 24.9 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.540622009961705		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.540622009961705 | validation: 0.6607197375275194]
	TIME [epoch: 24.9 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5780855656473551		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.5780855656473551 | validation: 0.6089377664495735]
	TIME [epoch: 24.9 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5898231522974275		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.5898231522974275 | validation: 0.7392483791261032]
	TIME [epoch: 24.9 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8062380099669606		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.8062380099669606 | validation: 0.6457242855194314]
	TIME [epoch: 24.9 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5990080064896863		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.5990080064896863 | validation: 0.7014031340289715]
	TIME [epoch: 24.9 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6829772777616636		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.6829772777616636 | validation: 0.5543733797024012]
	TIME [epoch: 24.9 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6025672788413658		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.6025672788413658 | validation: 0.7726225329011034]
	TIME [epoch: 24.9 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6392064619657956		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.6392064619657956 | validation: 0.5960163157959572]
	TIME [epoch: 24.9 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5564203936123423		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.5564203936123423 | validation: 0.49810452696162943]
	TIME [epoch: 24.9 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.570940368512644		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.570940368512644 | validation: 0.6496329599951096]
	TIME [epoch: 24.9 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6464149460414442		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.6464149460414442 | validation: 0.4880921463537837]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_280.pth
	Model improved!!!
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8475568360132706		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.8475568360132706 | validation: 0.7802341308033158]
	TIME [epoch: 24.9 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7123364533103765		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.7123364533103765 | validation: 0.609474235842853]
	TIME [epoch: 25 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6793867827100316		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.6793867827100316 | validation: 1.0983601789512094]
	TIME [epoch: 24.9 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9001450913222038		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.9001450913222038 | validation: 0.7228990950249741]
	TIME [epoch: 24.9 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7656065999830735		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.7656065999830735 | validation: 0.614678971352644]
	TIME [epoch: 24.9 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6017672730886662		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.6017672730886662 | validation: 0.8699896874767871]
	TIME [epoch: 24.9 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.735918306410482		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.735918306410482 | validation: 0.7567248361801885]
	TIME [epoch: 24.9 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6427991955121363		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.6427991955121363 | validation: 0.7609962728629919]
	TIME [epoch: 24.9 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6941738893581121		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.6941738893581121 | validation: 0.5740839628217363]
	TIME [epoch: 24.9 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7663915648673914		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.7663915648673914 | validation: 0.87750764420607]
	TIME [epoch: 24.9 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7549498617574528		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.7549498617574528 | validation: 0.7094460348863797]
	TIME [epoch: 24.9 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8904453167446259		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.8904453167446259 | validation: 0.662229263800154]
	TIME [epoch: 24.9 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6760102972889657		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.6760102972889657 | validation: 0.9697692832810936]
	TIME [epoch: 24.9 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8294925559353186		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.8294925559353186 | validation: 0.5958840003416809]
	TIME [epoch: 24.9 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5972271515983016		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.5972271515983016 | validation: 0.5289207247864356]
	TIME [epoch: 24.9 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5493957008553942		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.5493957008553942 | validation: 0.5826590854021358]
	TIME [epoch: 24.9 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5795343079017916		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.5795343079017916 | validation: 0.5799042491008253]
	TIME [epoch: 24.9 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5495935495563657		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.5495935495563657 | validation: 0.5471425722148265]
	TIME [epoch: 24.9 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.739255171838116		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.739255171838116 | validation: 0.7167435219450067]
	TIME [epoch: 24.9 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6561022610122715		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.6561022610122715 | validation: 0.5918040943695548]
	TIME [epoch: 24.9 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5695635976723143		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.5695635976723143 | validation: 0.4947745756955817]
	TIME [epoch: 24.9 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6230708423976089		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.6230708423976089 | validation: 0.7342728493341711]
	TIME [epoch: 24.9 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5909428405610099		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.5909428405610099 | validation: 0.5501629545708565]
	TIME [epoch: 24.9 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5649134901141599		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.5649134901141599 | validation: 0.5472239868035124]
	TIME [epoch: 24.9 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5871938821918061		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.5871938821918061 | validation: 0.5555652149994927]
	TIME [epoch: 24.9 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6310169331286282		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.6310169331286282 | validation: 1.0102051189270056]
	TIME [epoch: 24.9 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6463938170165042		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.6463938170165042 | validation: 0.543963441855947]
	TIME [epoch: 24.9 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7170077641767238		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.7170077641767238 | validation: 0.5147715986690669]
	TIME [epoch: 24.9 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6261714894494745		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.6261714894494745 | validation: 0.7396746062526508]
	TIME [epoch: 24.9 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.714079235566742		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.714079235566742 | validation: 0.8559905937279086]
	TIME [epoch: 24.9 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.174136879963398		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 1.174136879963398 | validation: 0.7518557705948655]
	TIME [epoch: 24.9 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6655468598643401		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.6655468598643401 | validation: 0.7205725388406767]
	TIME [epoch: 24.9 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6126316878578955		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.6126316878578955 | validation: 0.5964211089079031]
	TIME [epoch: 24.9 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5560132337968468		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.5560132337968468 | validation: 0.5631959783954068]
	TIME [epoch: 24.9 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.519314057315907		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.519314057315907 | validation: 0.6334825723397226]
	TIME [epoch: 24.9 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5888995824467591		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.5888995824467591 | validation: 0.6815452190561183]
	TIME [epoch: 24.9 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7035372290441257		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.7035372290441257 | validation: 0.7460517489591888]
	TIME [epoch: 24.9 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7380865804299276		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.7380865804299276 | validation: 0.5161707126697914]
	TIME [epoch: 24.9 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4946747942288631		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.4946747942288631 | validation: 0.5190755529164841]
	TIME [epoch: 24.9 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47896479979317574		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.47896479979317574 | validation: 0.4756771776175584]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_320.pth
	Model improved!!!
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47999434743364466		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.47999434743364466 | validation: 0.5930284321446717]
	TIME [epoch: 24.9 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5141012195322906		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.5141012195322906 | validation: 1.1856709906950276]
	TIME [epoch: 25 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9738636898695068		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.9738636898695068 | validation: 0.586687938442875]
	TIME [epoch: 25 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5968639291714302		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.5968639291714302 | validation: 0.6764994106654979]
	TIME [epoch: 25 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6415554262863853		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.6415554262863853 | validation: 0.6375000786375222]
	TIME [epoch: 25 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6256493659525055		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.6256493659525055 | validation: 0.664124251938082]
	TIME [epoch: 25 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6066009632963927		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.6066009632963927 | validation: 0.6262235240070131]
	TIME [epoch: 25 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6274891638787038		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.6274891638787038 | validation: 0.5817584382377817]
	TIME [epoch: 25 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6066473726572992		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.6066473726572992 | validation: 0.6191726708055871]
	TIME [epoch: 25 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7043927184357003		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.7043927184357003 | validation: 0.6265679298060407]
	TIME [epoch: 25 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6890222270663721		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.6890222270663721 | validation: 0.7149346793484138]
	TIME [epoch: 25 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6278291204058819		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.6278291204058819 | validation: 0.5783978781492314]
	TIME [epoch: 25 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7147921191721264		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.7147921191721264 | validation: 0.6033554172900258]
	TIME [epoch: 25 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6917662976655214		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.6917662976655214 | validation: 0.7981420442280817]
	TIME [epoch: 24.9 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6960722716893615		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.6960722716893615 | validation: 0.7080846226970604]
	TIME [epoch: 25 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6714054946865845		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.6714054946865845 | validation: 0.6718536461408335]
	TIME [epoch: 25 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.664022465577826		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.664022465577826 | validation: 0.5606961192366713]
	TIME [epoch: 25 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6576029487537977		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.6576029487537977 | validation: 1.2218660449816863]
	TIME [epoch: 25 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0029499986977624		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 1.0029499986977624 | validation: 0.7111338158052533]
	TIME [epoch: 25 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6374962183003706		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.6374962183003706 | validation: 0.5537983048269461]
	TIME [epoch: 25 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5921929416249583		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.5921929416249583 | validation: 0.5964816984164284]
	TIME [epoch: 25 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6544356312803108		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.6544356312803108 | validation: 0.704484883063441]
	TIME [epoch: 25 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6749277660026453		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.6749277660026453 | validation: 0.656095981703082]
	TIME [epoch: 25 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6545395382062993		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.6545395382062993 | validation: 0.5843121423424809]
	TIME [epoch: 25 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5634274880098733		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.5634274880098733 | validation: 0.5609182193308422]
	TIME [epoch: 25 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6048589483605356		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.6048589483605356 | validation: 0.7475255002610561]
	TIME [epoch: 25 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6799545766942225		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.6799545766942225 | validation: 0.6116356240658035]
	TIME [epoch: 25 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6210285249410006		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.6210285249410006 | validation: 0.6599941825862404]
	TIME [epoch: 25 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6312299658329217		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.6312299658329217 | validation: 0.6856431847640659]
	TIME [epoch: 24.9 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.653096636216196		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.653096636216196 | validation: 0.7983625766034324]
	TIME [epoch: 25 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.052337925717402		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 1.052337925717402 | validation: 0.9516138234260736]
	TIME [epoch: 25 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7159354676760725		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.7159354676760725 | validation: 0.5846794283099549]
	TIME [epoch: 25 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5897814065097722		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.5897814065097722 | validation: 0.6228736435291979]
	TIME [epoch: 25 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6544958172052963		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.6544958172052963 | validation: 0.6225449730319041]
	TIME [epoch: 25 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6540305246779953		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.6540305246779953 | validation: 0.5993473780974196]
	TIME [epoch: 25 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6258701989436511		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.6258701989436511 | validation: 0.6547251750682901]
	TIME [epoch: 25 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7051012806268679		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.7051012806268679 | validation: 0.6587127464990996]
	TIME [epoch: 25 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6260607181414882		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.6260607181414882 | validation: 0.6507680776077853]
	TIME [epoch: 25 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6650777801886634		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.6650777801886634 | validation: 0.634113679144646]
	TIME [epoch: 25 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.637664004997465		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.637664004997465 | validation: 0.7684224132512466]
	TIME [epoch: 25 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.858256839534302		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.858256839534302 | validation: 0.6478552885892219]
	TIME [epoch: 25 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6730332494681294		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.6730332494681294 | validation: 0.5840840540521582]
	TIME [epoch: 25 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6054358226412059		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.6054358226412059 | validation: 0.5543365545145681]
	TIME [epoch: 25 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5590497467759213		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.5590497467759213 | validation: 0.6455957190857916]
	TIME [epoch: 25 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7930938948133546		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.7930938948133546 | validation: 0.8819629763461493]
	TIME [epoch: 25 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8516552289372868		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.8516552289372868 | validation: 0.6444927812337548]
	TIME [epoch: 25 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5887229081301124		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.5887229081301124 | validation: 0.6082324351348257]
	TIME [epoch: 25 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6527099612618835		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.6527099612618835 | validation: 0.6795220227354394]
	TIME [epoch: 25 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6840950025072275		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.6840950025072275 | validation: 0.6445242486822201]
	TIME [epoch: 25 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7047533381143901		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.7047533381143901 | validation: 0.6848905299416191]
	TIME [epoch: 25 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7729653239831072		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.7729653239831072 | validation: 0.8467152374569747]
	TIME [epoch: 25 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7074693800576921		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.7074693800576921 | validation: 0.6518039118679562]
	TIME [epoch: 25 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6248634700617778		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.6248634700617778 | validation: 0.6000998654263994]
	TIME [epoch: 25 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5842677086191226		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.5842677086191226 | validation: 0.5496089648493346]
	TIME [epoch: 25 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5904221201487281		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.5904221201487281 | validation: 0.7169735710111393]
	TIME [epoch: 25 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6563954747733285		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.6563954747733285 | validation: 0.6876326548096157]
	TIME [epoch: 24.9 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7087869910502048		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.7087869910502048 | validation: 0.7125467045692753]
	TIME [epoch: 24.9 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7135237157402833		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.7135237157402833 | validation: 0.6359598175364451]
	TIME [epoch: 24.9 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6206409072537749		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.6206409072537749 | validation: 0.5748939353308617]
	TIME [epoch: 25 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6650407775416176		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.6650407775416176 | validation: 0.7131385480817423]
	TIME [epoch: 25 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7380697200658767		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.7380697200658767 | validation: 0.8277168713400889]
	TIME [epoch: 25 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8040838298691224		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.8040838298691224 | validation: 0.6144886315234716]
	TIME [epoch: 24.9 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.695205365290084		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.695205365290084 | validation: 0.7540620004462093]
	TIME [epoch: 25 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7924156268869256		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.7924156268869256 | validation: 0.7958384788405704]
	TIME [epoch: 25 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7008266056252417		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.7008266056252417 | validation: 0.6121501473626183]
	TIME [epoch: 24.9 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5775704452428906		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.5775704452428906 | validation: 0.6492381187651305]
	TIME [epoch: 25 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6189849846675033		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.6189849846675033 | validation: 0.5367219769612125]
	TIME [epoch: 25 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5526564713988407		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.5526564713988407 | validation: 0.5332869422733153]
	TIME [epoch: 24.9 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5199307210270594		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.5199307210270594 | validation: 0.5753841308881134]
	TIME [epoch: 25 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5310839717052759		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.5310839717052759 | validation: 0.550665318073893]
	TIME [epoch: 24.9 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5361415672050195		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.5361415672050195 | validation: 0.5093082336452648]
	TIME [epoch: 24.9 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47072732115179944		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.47072732115179944 | validation: 0.4763963593536717]
	TIME [epoch: 25 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4872708542674107		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.4872708542674107 | validation: 0.4700964161617093]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_393.pth
	Model improved!!!
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4713563901410447		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.4713563901410447 | validation: 0.4935609786673517]
	TIME [epoch: 24.9 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4949357943584046		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.4949357943584046 | validation: 0.8445679911112015]
	TIME [epoch: 25 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8074912174085145		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.8074912174085145 | validation: 0.6956214025724984]
	TIME [epoch: 25 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.662764477358005		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.662764477358005 | validation: 0.4946085471669859]
	TIME [epoch: 24.9 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5451483996694356		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.5451483996694356 | validation: 0.5821485526526629]
	TIME [epoch: 25 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5480399829067497		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.5480399829067497 | validation: 0.570640538442632]
	TIME [epoch: 24.9 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5929305415030293		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.5929305415030293 | validation: 0.5509683962616501]
	TIME [epoch: 24.9 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5449586932704535		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.5449586932704535 | validation: 0.5018615982470075]
	TIME [epoch: 24.9 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5614026713555997		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.5614026713555997 | validation: 1.0187428365405462]
	TIME [epoch: 25 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8945336079889034		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.8945336079889034 | validation: 0.6029184737008769]
	TIME [epoch: 25 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5647334022725539		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.5647334022725539 | validation: 0.5921761262726876]
	TIME [epoch: 25 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5512924478745322		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.5512924478745322 | validation: 0.5512167758335607]
	TIME [epoch: 24.9 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5154856886964903		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.5154856886964903 | validation: 0.47901096738005067]
	TIME [epoch: 24.9 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5229851170076232		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.5229851170076232 | validation: 0.6199974243143912]
	TIME [epoch: 25 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6446126425404186		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.6446126425404186 | validation: 0.5052332144031835]
	TIME [epoch: 25 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5472345169548947		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.5472345169548947 | validation: 0.5576468176497078]
	TIME [epoch: 24.9 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5386167331566974		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.5386167331566974 | validation: 0.5087710678326701]
	TIME [epoch: 25 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5083431628846831		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.5083431628846831 | validation: 0.5477514460258697]
	TIME [epoch: 25 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5183205348639853		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.5183205348639853 | validation: 0.6127981426766353]
	TIME [epoch: 24.9 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6541271209780417		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.6541271209780417 | validation: 0.7018683595642415]
	TIME [epoch: 25 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6130217604613976		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.6130217604613976 | validation: 0.5147832180531795]
	TIME [epoch: 24.9 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5136631006319153		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.5136631006319153 | validation: 0.4588885006014749]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_415.pth
	Model improved!!!
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47673740430759254		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.47673740430759254 | validation: 0.48526297746624525]
	TIME [epoch: 24.9 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5004593275387412		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.5004593275387412 | validation: 0.7692356534479108]
	TIME [epoch: 25 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8481788449041032		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.8481788449041032 | validation: 0.7558343525039808]
	TIME [epoch: 24.9 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6129470978342026		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.6129470978342026 | validation: 0.5614973298949665]
	TIME [epoch: 24.9 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5208325133036844		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.5208325133036844 | validation: 0.5243015092703901]
	TIME [epoch: 25 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6526696869526922		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.6526696869526922 | validation: 1.0016411499947182]
	TIME [epoch: 24.9 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8520010792640902		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.8520010792640902 | validation: 0.622239795897671]
	TIME [epoch: 25 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5487979934202625		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.5487979934202625 | validation: 0.5293565412698265]
	TIME [epoch: 25 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6533956837480738		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.6533956837480738 | validation: 0.9849374885488204]
	TIME [epoch: 24.9 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.848067347723241		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.848067347723241 | validation: 0.6921223126700438]
	TIME [epoch: 25 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7624200851636282		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.7624200851636282 | validation: 0.9031422353818739]
	TIME [epoch: 25 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8771314564734624		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.8771314564734624 | validation: 0.765438576243719]
	TIME [epoch: 24.9 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7359561044308887		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.7359561044308887 | validation: 0.5161601590436544]
	TIME [epoch: 24.9 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5235891263308301		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.5235891263308301 | validation: 0.5473420043101208]
	TIME [epoch: 24.9 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5251650051281765		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.5251650051281765 | validation: 0.4906196737698686]
	TIME [epoch: 25 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5332388647683742		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.5332388647683742 | validation: 0.5491086744662512]
	TIME [epoch: 24.9 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5445357938709547		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.5445357938709547 | validation: 0.7068034724647015]
	TIME [epoch: 24.9 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7759380933730521		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.7759380933730521 | validation: 0.8344943408016449]
	TIME [epoch: 24.9 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7358629898442469		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.7358629898442469 | validation: 0.6358531973716274]
	TIME [epoch: 25 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7679602664871658		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.7679602664871658 | validation: 0.9011288136239786]
	TIME [epoch: 24.9 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8381210722607233		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.8381210722607233 | validation: 0.5943816538354196]
	TIME [epoch: 25 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5655811530218381		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.5655811530218381 | validation: 0.527838506910791]
	TIME [epoch: 24.9 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5144536778293491		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.5144536778293491 | validation: 0.5236738616286774]
	TIME [epoch: 25 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5347900610202672		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.5347900610202672 | validation: 0.531484250717309]
	TIME [epoch: 24.9 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5844902657374254		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.5844902657374254 | validation: 0.6467017336932877]
	TIME [epoch: 24.9 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.609852830056567		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.609852830056567 | validation: 0.6047716014221364]
	TIME [epoch: 24.9 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5839172600871596		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.5839172600871596 | validation: 0.6224359324264634]
	TIME [epoch: 24.9 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.647371857630082		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.647371857630082 | validation: 0.8664409680256877]
	TIME [epoch: 25 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8006004428401441		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.8006004428401441 | validation: 0.6389262702594393]
	TIME [epoch: 25 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5656728762201737		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.5656728762201737 | validation: 0.6582516842798981]
	TIME [epoch: 24.9 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5964276234745784		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.5964276234745784 | validation: 0.5708917122834152]
	TIME [epoch: 24.9 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5524843583310426		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.5524843583310426 | validation: 0.5356615902302474]
	TIME [epoch: 25 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6287558283496371		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.6287558283496371 | validation: 0.8214529253439489]
	TIME [epoch: 24.9 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0601343643415673		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 1.0601343643415673 | validation: 0.9610076102634869]
	TIME [epoch: 24.9 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8301083012057974		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.8301083012057974 | validation: 0.6495959079667861]
	TIME [epoch: 25 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6312942891196888		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.6312942891196888 | validation: 0.538841906261712]
	TIME [epoch: 24.9 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5676503016512018		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.5676503016512018 | validation: 0.5892425713382552]
	TIME [epoch: 24.9 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8302757732090011		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.8302757732090011 | validation: 1.0001106486877336]
	TIME [epoch: 24.9 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1685219142238563		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 1.1685219142238563 | validation: 1.664170563688382]
	TIME [epoch: 24.9 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6552297687947424		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 1.6552297687947424 | validation: 0.9793582168422543]
	TIME [epoch: 24.9 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9744778984965439		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.9744778984965439 | validation: 0.837391125815337]
	TIME [epoch: 25 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7977169150897009		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.7977169150897009 | validation: 0.8700749505378045]
	TIME [epoch: 24.9 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8494441034115644		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.8494441034115644 | validation: 0.8649646682194166]
	TIME [epoch: 24.9 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.853744166150327		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.853744166150327 | validation: 0.6864906453760046]
	TIME [epoch: 25 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7122782776825434		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.7122782776825434 | validation: 0.6026353138212519]
	TIME [epoch: 24.9 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5840663402301864		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.5840663402301864 | validation: 0.5900112415411294]
	TIME [epoch: 24.9 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7251709127100248		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.7251709127100248 | validation: 0.7144223393103084]
	TIME [epoch: 25 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6453097517127203		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.6453097517127203 | validation: 0.5676257653315492]
	TIME [epoch: 24.9 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5804707797888563		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.5804707797888563 | validation: 0.5422351797118934]
	TIME [epoch: 25 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5618573551844407		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.5618573551844407 | validation: 0.544520704729546]
	TIME [epoch: 24.9 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5429369272517772		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.5429369272517772 | validation: 0.5192863878107608]
	TIME [epoch: 24.9 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5926901533469835		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.5926901533469835 | validation: 0.5858431169616036]
	TIME [epoch: 24.9 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5843982725255981		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.5843982725255981 | validation: 0.5763517728481855]
	TIME [epoch: 25 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6510921693097532		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.6510921693097532 | validation: 0.6410332926736437]
	TIME [epoch: 24.9 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6289499824737431		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.6289499824737431 | validation: 0.5939564832726019]
	TIME [epoch: 25 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.629484622394378		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.629484622394378 | validation: 0.5960720224029186]
	TIME [epoch: 25 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5686146165668483		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.5686146165668483 | validation: 0.533307104597729]
	TIME [epoch: 24.9 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5410088116974119		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.5410088116974119 | validation: 0.5589851049986095]
	TIME [epoch: 24.9 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5575803151520896		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.5575803151520896 | validation: 0.5122479675091841]
	TIME [epoch: 24.9 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5335246792158002		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.5335246792158002 | validation: 0.54367635547323]
	TIME [epoch: 24.9 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5646308085189178		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.5646308085189178 | validation: 0.5325466422493063]
	TIME [epoch: 24.9 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5224651591407011		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.5224651591407011 | validation: 0.4805663491772706]
	TIME [epoch: 25 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5508108633483378		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.5508108633483378 | validation: 0.6247402552614004]
	TIME [epoch: 24.9 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6529915732542294		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.6529915732542294 | validation: 0.630728967796305]
	TIME [epoch: 24.9 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.625226708727964		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.625226708727964 | validation: 0.5187417056653617]
	TIME [epoch: 25 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5053488948347155		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.5053488948347155 | validation: 0.4972328910216261]
	TIME [epoch: 24.9 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5648259865129558		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.5648259865129558 | validation: 0.6771466223733826]
	TIME [epoch: 24.9 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6153459991931004		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.6153459991931004 | validation: 0.5304306319222191]
	TIME [epoch: 25 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6599307641565801		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.6599307641565801 | validation: 0.6707387857631631]
	TIME [epoch: 24.9 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6075787142263257		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.6075787142263257 | validation: 0.5165654282405775]
	TIME [epoch: 25 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5456199591358286		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.5456199591358286 | validation: 0.6149694459174536]
	TIME [epoch: 25 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5909665334172097		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.5909665334172097 | validation: 0.5405768297428268]
	TIME [epoch: 24.9 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5221113296957126		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.5221113296957126 | validation: 0.4649560031488103]
	TIME [epoch: 24.9 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4789495775716459		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.4789495775716459 | validation: 0.611514427964739]
	TIME [epoch: 25 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6815170032316535		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.6815170032316535 | validation: 0.7549429423927921]
	TIME [epoch: 24.9 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.965424679376857		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.965424679376857 | validation: 0.8082296533726304]
	TIME [epoch: 24.9 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7304916372199814		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.7304916372199814 | validation: 0.6936897614255909]
	TIME [epoch: 24.9 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7527974404970623		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.7527974404970623 | validation: 0.6594374390201699]
	TIME [epoch: 24.9 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6204756029344132		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.6204756029344132 | validation: 0.5944527153584601]
	TIME [epoch: 24.9 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6267023639370594		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.6267023639370594 | validation: 0.638154086641951]
	TIME [epoch: 24.9 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6487528302819296		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.6487528302819296 | validation: 0.5839865532666803]
	TIME [epoch: 24.9 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.599997914531012		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.599997914531012 | validation: 0.5454769323034541]
	TIME [epoch: 24.9 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5587888534764132		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.5587888534764132 | validation: 0.5495489677293017]
	TIME [epoch: 25 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5521624208779248		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.5521624208779248 | validation: 0.5396522366485783]
	TIME [epoch: 25 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5838676782254223		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.5838676782254223 | validation: 0.6697001387447519]
	TIME [epoch: 24.9 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6925094064896905		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.6925094064896905 | validation: 0.7988864433876799]
	TIME [epoch: 24.9 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7658031458523226		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.7658031458523226 | validation: 0.6663852638473222]
	TIME [epoch: 25 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5967589295663905		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.5967589295663905 | validation: 0.532455646592422]
	TIME [epoch: 25 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47301075031241474		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.47301075031241474 | validation: 0.5033748834132289]
	TIME [epoch: 24.9 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4476812989431584		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.4476812989431584 | validation: 0.5014836549420857]
	TIME [epoch: 25 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49913771384680844		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.49913771384680844 | validation: 0.4724612952427357]
	TIME [epoch: 24.9 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4511145057122345		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.4511145057122345 | validation: 0.48356085963665735]
	TIME [epoch: 25 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49747720033658593		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.49747720033658593 | validation: 0.5197949836278241]
	TIME [epoch: 24.9 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6396805301283199		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.6396805301283199 | validation: 0.5933179982071733]
	TIME [epoch: 24.9 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5553331495182977		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.5553331495182977 | validation: 0.49950909883789535]
	TIME [epoch: 25 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5662506415111696		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.5662506415111696 | validation: 0.6000457122256898]
	TIME [epoch: 24.9 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5261657395280422		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.5261657395280422 | validation: 0.441088536218934]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_512.pth
	Model improved!!!
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42171695944608273		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.42171695944608273 | validation: 0.5092426043084102]
	TIME [epoch: 24.9 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48594567345066453		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.48594567345066453 | validation: 0.44747613143698844]
	TIME [epoch: 24.9 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38235152660409333		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.38235152660409333 | validation: 0.4669521313677889]
	TIME [epoch: 24.9 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46335815039286166		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.46335815039286166 | validation: 0.5095814804412919]
	TIME [epoch: 25 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.507436771611163		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.507436771611163 | validation: 0.4337503092859896]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_517.pth
	Model improved!!!
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3811311240114129		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.3811311240114129 | validation: 0.43685625847616066]
	TIME [epoch: 24.9 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4139363034792195		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.4139363034792195 | validation: 0.46276615747652855]
	TIME [epoch: 25 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43908262058166175		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.43908262058166175 | validation: 0.3724421203197714]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_520.pth
	Model improved!!!
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39539686815584246		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.39539686815584246 | validation: 0.4196305372631191]
	TIME [epoch: 24.9 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40382663971755706		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.40382663971755706 | validation: 0.3901419928769143]
	TIME [epoch: 25 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34532683165803624		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.34532683165803624 | validation: 0.36534688404752563]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_523.pth
	Model improved!!!
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37005796522698947		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.37005796522698947 | validation: 0.514012409721287]
	TIME [epoch: 24.9 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4743950568085993		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.4743950568085993 | validation: 0.44171688266077236]
	TIME [epoch: 24.9 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40303851882418834		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.40303851882418834 | validation: 0.4380062279063671]
	TIME [epoch: 24.9 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43103298498063247		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.43103298498063247 | validation: 0.5539984985351721]
	TIME [epoch: 24.9 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4525691860644893		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.4525691860644893 | validation: 0.3963658400457251]
	TIME [epoch: 24.9 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43749775698019455		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.43749775698019455 | validation: 0.7034701916759885]
	TIME [epoch: 24.9 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.616767663945019		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.616767663945019 | validation: 0.436525126768114]
	TIME [epoch: 24.9 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42814086797342576		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.42814086797342576 | validation: 0.5717483040237636]
	TIME [epoch: 24.9 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4707971869672734		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.4707971869672734 | validation: 0.4900808437895559]
	TIME [epoch: 24.9 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4441075742293683		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.4441075742293683 | validation: 0.5268962768407959]
	TIME [epoch: 24.9 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49404895931683346		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.49404895931683346 | validation: 0.4642193311343947]
	TIME [epoch: 24.9 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40554738881254826		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.40554738881254826 | validation: 0.47329826311519607]
	TIME [epoch: 24.9 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4216980646199634		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.4216980646199634 | validation: 0.43138860463307993]
	TIME [epoch: 24.9 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38972161198353733		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.38972161198353733 | validation: 0.4649393685741833]
	TIME [epoch: 24.9 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3897836305345415		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.3897836305345415 | validation: 0.39906654656951224]
	TIME [epoch: 24.9 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37180741923711813		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.37180741923711813 | validation: 0.41647703035392925]
	TIME [epoch: 24.9 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3663230957545244		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.3663230957545244 | validation: 0.47863652218034874]
	TIME [epoch: 24.9 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44041579355082194		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.44041579355082194 | validation: 0.49537978098663915]
	TIME [epoch: 24.9 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4057627071362097		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.4057627071362097 | validation: 0.44457473159720795]
	TIME [epoch: 24.9 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44140663701533467		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.44140663701533467 | validation: 0.5202651927583685]
	TIME [epoch: 24.9 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4129268572991099		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.4129268572991099 | validation: 0.37761415892928724]
	TIME [epoch: 24.9 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3879579407782744		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.3879579407782744 | validation: 0.4300268475901382]
	TIME [epoch: 24.9 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37808302972187247		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.37808302972187247 | validation: 0.3856969812477836]
	TIME [epoch: 24.9 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3460445658920093		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.3460445658920093 | validation: 0.38104313625730074]
	TIME [epoch: 24.9 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37234757216946984		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.37234757216946984 | validation: 0.3918851398666817]
	TIME [epoch: 24.9 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37518584612300304		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.37518584612300304 | validation: 0.4053766386537209]
	TIME [epoch: 24.9 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3949954152814114		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.3949954152814114 | validation: 0.4655465999093762]
	TIME [epoch: 24.9 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40907381885518623		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.40907381885518623 | validation: 0.42755493262848904]
	TIME [epoch: 24.9 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45101549636455224		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.45101549636455224 | validation: 0.4088755752899735]
	TIME [epoch: 24.9 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37447499469256273		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.37447499469256273 | validation: 0.4242575888806108]
	TIME [epoch: 24.9 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3857429258830839		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.3857429258830839 | validation: 0.42034423033326435]
	TIME [epoch: 24.9 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4253040099612242		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.4253040099612242 | validation: 0.48092295229736054]
	TIME [epoch: 24.9 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4111491359100805		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.4111491359100805 | validation: 0.3819544037682243]
	TIME [epoch: 24.9 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3524807579407474		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.3524807579407474 | validation: 0.35091192422945255]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_557.pth
	Model improved!!!
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3403600692428869		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.3403600692428869 | validation: 0.37424198632364947]
	TIME [epoch: 24.9 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3443451818932322		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.3443451818932322 | validation: 0.38837918954064476]
	TIME [epoch: 24.9 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39034479762427743		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.39034479762427743 | validation: 0.4272548722147059]
	TIME [epoch: 24.9 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39656658820638074		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.39656658820638074 | validation: 0.5004508817484203]
	TIME [epoch: 24.9 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43839176328994156		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.43839176328994156 | validation: 0.4562851628742367]
	TIME [epoch: 24.9 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3810519476334499		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.3810519476334499 | validation: 0.35520317288762265]
	TIME [epoch: 24.9 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33539137539636227		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.33539137539636227 | validation: 0.3760005734652383]
	TIME [epoch: 24.9 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3509052983437362		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.3509052983437362 | validation: 0.336304186008301]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_565.pth
	Model improved!!!
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34266784133337136		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.34266784133337136 | validation: 0.40149082727190866]
	TIME [epoch: 24.9 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3653015341282057		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.3653015341282057 | validation: 0.4391070273762333]
	TIME [epoch: 24.9 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47634199765339297		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.47634199765339297 | validation: 0.5135337192594702]
	TIME [epoch: 24.9 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6321600363646422		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.6321600363646422 | validation: 0.5838472423609431]
	TIME [epoch: 24.9 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5734456698150668		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.5734456698150668 | validation: 0.40959239529491215]
	TIME [epoch: 24.9 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3875598312685202		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.3875598312685202 | validation: 0.38377477384878333]
	TIME [epoch: 24.9 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36839951341606203		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.36839951341606203 | validation: 0.4017732037617631]
	TIME [epoch: 24.9 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3333494294869695		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.3333494294869695 | validation: 0.3389369800511027]
	TIME [epoch: 24.9 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38827960631894337		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.38827960631894337 | validation: 0.4781444402417233]
	TIME [epoch: 24.9 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41456954959921355		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.41456954959921355 | validation: 0.33655406521751524]
	TIME [epoch: 24.9 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3359922322314301		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.3359922322314301 | validation: 0.39917018706316215]
	TIME [epoch: 24.9 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5019191253186343		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.5019191253186343 | validation: 0.42058213703086766]
	TIME [epoch: 24.9 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38581291707062176		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.38581291707062176 | validation: 0.36068808144600717]
	TIME [epoch: 24.9 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3500988899926876		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.3500988899926876 | validation: 0.36211811887080086]
	TIME [epoch: 24.9 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34340204192072277		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.34340204192072277 | validation: 0.36543081819260914]
	TIME [epoch: 24.9 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36360104880671695		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.36360104880671695 | validation: 0.39259683354627045]
	TIME [epoch: 24.9 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3489863364973699		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.3489863364973699 | validation: 0.33338446648114145]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_582.pth
	Model improved!!!
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3177315513854462		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.3177315513854462 | validation: 0.3807661643380456]
	TIME [epoch: 24.9 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44427959865245503		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.44427959865245503 | validation: 0.4911107918121854]
	TIME [epoch: 24.9 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4148570097444839		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.4148570097444839 | validation: 0.3467274270393908]
	TIME [epoch: 24.9 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33099770372245074		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.33099770372245074 | validation: 0.36265600883745064]
	TIME [epoch: 24.9 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3353704982050824		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.3353704982050824 | validation: 0.3426554940253094]
	TIME [epoch: 24.9 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32085272399606424		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.32085272399606424 | validation: 0.3117842763939886]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_588.pth
	Model improved!!!
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3140659636429047		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.3140659636429047 | validation: 0.34117765650591636]
	TIME [epoch: 24.9 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3353776260027147		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.3353776260027147 | validation: 0.41224641080250196]
	TIME [epoch: 24.9 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3342568122794392		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.3342568122794392 | validation: 0.32030811694858813]
	TIME [epoch: 24.9 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3268853314834699		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.3268853314834699 | validation: 0.32193126789071785]
	TIME [epoch: 24.9 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2940074571303558		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.2940074571303558 | validation: 0.32448113123647404]
	TIME [epoch: 24.9 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3455967289079761		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.3455967289079761 | validation: 0.3512457381470099]
	TIME [epoch: 24.9 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36083290313596067		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.36083290313596067 | validation: 0.41145254427177436]
	TIME [epoch: 24.9 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35604688499665815		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.35604688499665815 | validation: 0.352028315990063]
	TIME [epoch: 24.9 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3438411427103361		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.3438411427103361 | validation: 0.32359279171587185]
	TIME [epoch: 24.9 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37056808134790925		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.37056808134790925 | validation: 0.4624850992727413]
	TIME [epoch: 24.9 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42013464666361056		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.42013464666361056 | validation: 0.40671097455067384]
	TIME [epoch: 24.9 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3689105118956663		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.3689105118956663 | validation: 0.42668766428557275]
	TIME [epoch: 24.9 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36486668916986453		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.36486668916986453 | validation: 0.4041017207977404]
	TIME [epoch: 24.9 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.345937833772557		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.345937833772557 | validation: 0.3711796521098772]
	TIME [epoch: 24.9 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3538924162710149		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.3538924162710149 | validation: 0.43681812622711297]
	TIME [epoch: 24.9 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35595271509302984		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.35595271509302984 | validation: 0.42959696973173395]
	TIME [epoch: 24.9 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4807136396518804		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.4807136396518804 | validation: 0.5453646840014916]
	TIME [epoch: 24.9 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43397504930729147		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.43397504930729147 | validation: 0.42663846906464076]
	TIME [epoch: 24.9 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38033292350947584		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.38033292350947584 | validation: 0.4742495687076992]
	TIME [epoch: 24.9 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3863580252990378		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.3863580252990378 | validation: 0.40253705183183697]
	TIME [epoch: 24.9 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3694580761384919		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.3694580761384919 | validation: 0.4151929226093296]
	TIME [epoch: 24.9 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4440447737868969		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.4440447737868969 | validation: 0.4550388048524215]
	TIME [epoch: 24.9 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3779650762436935		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.3779650762436935 | validation: 0.359237879921994]
	TIME [epoch: 24.9 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3472908672288041		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.3472908672288041 | validation: 0.4039855276430866]
	TIME [epoch: 24.9 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3660205100311565		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.3660205100311565 | validation: 0.42861860305059724]
	TIME [epoch: 24.9 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46332070227269007		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.46332070227269007 | validation: 0.48331459614199923]
	TIME [epoch: 24.9 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3895662177609872		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.3895662177609872 | validation: 0.33119840056630395]
	TIME [epoch: 24.9 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3442327416485848		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.3442327416485848 | validation: 0.3825886196872484]
	TIME [epoch: 24.9 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36256365584166994		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.36256365584166994 | validation: 0.38227024218841194]
	TIME [epoch: 24.9 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38920624367535567		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.38920624367535567 | validation: 0.41389610462437426]
	TIME [epoch: 24.9 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45238752575758145		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.45238752575758145 | validation: 0.5221485432185808]
	TIME [epoch: 24.9 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43159176003796934		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.43159176003796934 | validation: 0.3475386294146143]
	TIME [epoch: 24.9 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30627711082757336		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.30627711082757336 | validation: 0.35118523213611985]
	TIME [epoch: 24.9 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34456659401722745		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.34456659401722745 | validation: 0.34252715305423054]
	TIME [epoch: 24.9 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3170750354238698		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.3170750354238698 | validation: 0.39933562506929166]
	TIME [epoch: 24.9 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4015851245113083		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.4015851245113083 | validation: 0.4566442133292564]
	TIME [epoch: 24.9 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3887969025745394		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.3887969025745394 | validation: 0.3899446342064301]
	TIME [epoch: 24.9 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35088499871720064		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.35088499871720064 | validation: 0.3555804037180022]
	TIME [epoch: 24.9 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32422702580842616		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.32422702580842616 | validation: 0.3194026120364471]
	TIME [epoch: 24.9 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.297815545694869		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.297815545694869 | validation: 0.3450173102534586]
	TIME [epoch: 24.9 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4750185953068655		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.4750185953068655 | validation: 0.5859109566275861]
	TIME [epoch: 24.9 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4238163017961001		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.4238163017961001 | validation: 0.44397748298553774]
	TIME [epoch: 24.9 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40733204925131855		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.40733204925131855 | validation: 0.4079362391489575]
	TIME [epoch: 24.9 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35351098325783786		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.35351098325783786 | validation: 0.4150975641090183]
	TIME [epoch: 24.9 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46479089139747604		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.46479089139747604 | validation: 0.3598401956244079]
	TIME [epoch: 24.9 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32222103210986797		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.32222103210986797 | validation: 0.3500245121537985]
	TIME [epoch: 24.9 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32345600839229016		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.32345600839229016 | validation: 0.3311167697495581]
	TIME [epoch: 24.9 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34761535822232087		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.34761535822232087 | validation: 0.38540017551588834]
	TIME [epoch: 24.9 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33855076295918174		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.33855076295918174 | validation: 0.3625581903330334]
	TIME [epoch: 24.9 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3450915656342959		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.3450915656342959 | validation: 0.3243455135665427]
	TIME [epoch: 24.9 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30341184228875867		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.30341184228875867 | validation: 0.3203900539973713]
	TIME [epoch: 24.9 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3251557328727072		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.3251557328727072 | validation: 0.3809698142998042]
	TIME [epoch: 24.9 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37026862073526035		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.37026862073526035 | validation: 0.36359097239575394]
	TIME [epoch: 24.9 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34449208699571265		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.34449208699571265 | validation: 0.358902002300359]
	TIME [epoch: 24.9 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3641124656421544		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.3641124656421544 | validation: 0.3437454789808861]
	TIME [epoch: 24.9 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32024504219178324		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.32024504219178324 | validation: 0.39537152893323874]
	TIME [epoch: 24.9 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37089062122297844		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.37089062122297844 | validation: 0.38026046718254036]
	TIME [epoch: 24.9 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3326470783744533		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.3326470783744533 | validation: 0.4199935133187111]
	TIME [epoch: 24.9 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4024114686737187		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.4024114686737187 | validation: 0.4094977919106208]
	TIME [epoch: 24.9 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3301437654680175		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.3301437654680175 | validation: 0.3512546233140933]
	TIME [epoch: 24.9 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3390303792593583		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.3390303792593583 | validation: 0.3522673573146902]
	TIME [epoch: 24.9 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.295072193899924		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.295072193899924 | validation: 0.29726583834600245]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_650.pth
	Model improved!!!
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30734953150638555		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.30734953150638555 | validation: 0.36863800997500035]
	TIME [epoch: 24.9 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3311519597144531		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.3311519597144531 | validation: 0.3791678212512885]
	TIME [epoch: 24.9 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32148853310415215		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.32148853310415215 | validation: 0.33003776068998575]
	TIME [epoch: 24.9 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3042263037603174		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.3042263037603174 | validation: 0.3848626624523287]
	TIME [epoch: 24.9 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3489189991173943		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.3489189991173943 | validation: 0.3063622861363296]
	TIME [epoch: 24.9 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2916386644610307		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.2916386644610307 | validation: 0.31883352790778346]
	TIME [epoch: 24.9 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3066099299377726		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.3066099299377726 | validation: 0.3296834048309767]
	TIME [epoch: 24.9 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34359218424840726		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.34359218424840726 | validation: 0.32765502298767724]
	TIME [epoch: 24.9 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2932088819674178		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.2932088819674178 | validation: 0.3523082259724187]
	TIME [epoch: 24.9 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3065912826559044		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.3065912826559044 | validation: 0.3449368277211819]
	TIME [epoch: 24.9 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3447284282033188		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.3447284282033188 | validation: 0.3596205235533956]
	TIME [epoch: 24.9 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33886030057568595		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.33886030057568595 | validation: 0.37302713229791223]
	TIME [epoch: 24.9 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31697768913291513		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.31697768913291513 | validation: 0.3728454058192459]
	TIME [epoch: 24.9 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35688531807747076		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.35688531807747076 | validation: 0.3507735257333097]
	TIME [epoch: 25 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3318318138175006		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.3318318138175006 | validation: 0.3671704094037852]
	TIME [epoch: 24.9 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32412502551776556		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.32412502551776556 | validation: 0.32124346857785335]
	TIME [epoch: 25 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3143203619566103		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.3143203619566103 | validation: 0.34426651630800226]
	TIME [epoch: 24.9 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3383872134317196		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.3383872134317196 | validation: 0.3620327364437565]
	TIME [epoch: 24.9 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3122023108676142		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.3122023108676142 | validation: 0.34060064809644064]
	TIME [epoch: 24.9 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33865940030926145		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.33865940030926145 | validation: 0.3570151062198947]
	TIME [epoch: 25 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36055807502998694		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.36055807502998694 | validation: 0.40359606876921994]
	TIME [epoch: 24.9 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4236188387142955		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.4236188387142955 | validation: 0.3590621409344445]
	TIME [epoch: 25 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34351112279342083		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.34351112279342083 | validation: 0.35879016971654965]
	TIME [epoch: 24.9 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.323279180703406		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.323279180703406 | validation: 0.3433505609686165]
	TIME [epoch: 24.9 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3250814365175356		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.3250814365175356 | validation: 0.3476252806702642]
	TIME [epoch: 24.9 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37086161837761794		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.37086161837761794 | validation: 0.38267263805904905]
	TIME [epoch: 25 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36364062093566596		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.36364062093566596 | validation: 0.36674729198731]
	TIME [epoch: 24.9 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3765365837895158		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.3765365837895158 | validation: 0.4152596617326138]
	TIME [epoch: 24.9 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3658112531742017		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.3658112531742017 | validation: 0.399019938789871]
	TIME [epoch: 24.9 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34750634499514227		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.34750634499514227 | validation: 0.3883568736441266]
	TIME [epoch: 24.9 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3410129818865863		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.3410129818865863 | validation: 0.330698644191083]
	TIME [epoch: 24.9 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30866004215217824		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.30866004215217824 | validation: 0.3280755113802746]
	TIME [epoch: 24.9 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3052703069337822		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.3052703069337822 | validation: 0.3113758164670659]
	TIME [epoch: 24.9 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29957186047192397		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.29957186047192397 | validation: 0.36133935926182476]
	TIME [epoch: 25 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34074054644239166		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.34074054644239166 | validation: 0.4195472401327717]
	TIME [epoch: 24.9 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38846428717942677		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.38846428717942677 | validation: 0.40926320649663905]
	TIME [epoch: 24.9 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3822820170373785		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.3822820170373785 | validation: 0.38590367598842934]
	TIME [epoch: 24.9 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3601697980903611		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.3601697980903611 | validation: 0.32690955187663434]
	TIME [epoch: 24.9 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30657050031111427		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.30657050031111427 | validation: 0.3039633470342599]
	TIME [epoch: 24.9 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29394015763074144		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.29394015763074144 | validation: 0.28589516203165516]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_690.pth
	Model improved!!!
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2842441713722089		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.2842441713722089 | validation: 0.3384340970040051]
	TIME [epoch: 25 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3202228307686542		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.3202228307686542 | validation: 0.3242372318374649]
	TIME [epoch: 25 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3243338556091563		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.3243338556091563 | validation: 0.3358259704456718]
	TIME [epoch: 24.9 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32883384668974797		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.32883384668974797 | validation: 0.33569423176367497]
	TIME [epoch: 25 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3029553868685683		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.3029553868685683 | validation: 0.29822357564462804]
	TIME [epoch: 24.9 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28296805518501866		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.28296805518501866 | validation: 0.30909121795404393]
	TIME [epoch: 24.9 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.292302241545254		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.292302241545254 | validation: 0.31269658600831607]
	TIME [epoch: 25 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3242560541323082		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.3242560541323082 | validation: 0.31942589364996155]
	TIME [epoch: 25 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.315457347366298		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.315457347366298 | validation: 0.3221464029087675]
	TIME [epoch: 25 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3074479522184776		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.3074479522184776 | validation: 0.31856949854913874]
	TIME [epoch: 24.9 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34274134652201643		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.34274134652201643 | validation: 0.3628713187866927]
	TIME [epoch: 24.9 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3320666462329497		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.3320666462329497 | validation: 0.36041343460011677]
	TIME [epoch: 24.9 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3533284046682158		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.3533284046682158 | validation: 0.35019648677650794]
	TIME [epoch: 25 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3378763026023796		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.3378763026023796 | validation: 0.3088169657128565]
	TIME [epoch: 24.9 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2913387297546646		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.2913387297546646 | validation: 0.29193340446181554]
	TIME [epoch: 25 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3112973691844558		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.3112973691844558 | validation: 0.4019754788863733]
	TIME [epoch: 25 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3597389367914508		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.3597389367914508 | validation: 0.3171067159297498]
	TIME [epoch: 24.9 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3052269851502377		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.3052269851502377 | validation: 0.307900599703965]
	TIME [epoch: 25 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30278625644251483		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.30278625644251483 | validation: 0.294213665089173]
	TIME [epoch: 25 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3116477929591029		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.3116477929591029 | validation: 0.3009217621610391]
	TIME [epoch: 24.9 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28308638150122334		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.28308638150122334 | validation: 0.27423772337686325]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_711.pth
	Model improved!!!
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3015752681741358		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.3015752681741358 | validation: 0.3401265023090639]
	TIME [epoch: 24.9 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35008964272328047		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.35008964272328047 | validation: 0.3512843284040043]
	TIME [epoch: 24.9 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3511130777164491		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.3511130777164491 | validation: 0.33621379558276154]
	TIME [epoch: 24.9 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33615470479961307		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.33615470479961307 | validation: 0.3414396363764412]
	TIME [epoch: 25 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34186653224985486		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.34186653224985486 | validation: 0.3847806571313698]
	TIME [epoch: 24.9 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40083952215767915		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.40083952215767915 | validation: 0.5029729730427245]
	TIME [epoch: 25 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44532426877635145		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.44532426877635145 | validation: 0.3535443693709357]
	TIME [epoch: 24.9 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3372109433541055		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.3372109433541055 | validation: 0.36260586327658373]
	TIME [epoch: 24.9 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3618281597178402		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.3618281597178402 | validation: 0.37520752988167333]
	TIME [epoch: 24.9 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3563882113882293		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.3563882113882293 | validation: 0.340209725450941]
	TIME [epoch: 24.9 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32362217116978514		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.32362217116978514 | validation: 0.36199117541913844]
	TIME [epoch: 24.9 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39080959692339085		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.39080959692339085 | validation: 0.3441475403472508]
	TIME [epoch: 24.9 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3379624946931259		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.3379624946931259 | validation: 0.35910991778781365]
	TIME [epoch: 25 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3257255187242032		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.3257255187242032 | validation: 0.29912098197867104]
	TIME [epoch: 24.9 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27846048672372403		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.27846048672372403 | validation: 0.28819594121192]
	TIME [epoch: 25 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28075928917263526		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.28075928917263526 | validation: 0.30949183074932524]
	TIME [epoch: 24.9 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30289844101304797		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.30289844101304797 | validation: 0.28114342600306946]
	TIME [epoch: 25 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28959902765058065		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.28959902765058065 | validation: 0.30081056414088847]
	TIME [epoch: 24.9 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2908993014089672		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.2908993014089672 | validation: 0.3021246363733838]
	TIME [epoch: 25 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3289029571094818		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.3289029571094818 | validation: 0.4460078674486126]
	TIME [epoch: 24.9 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5086583228887375		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.5086583228887375 | validation: 0.5999298952099236]
	TIME [epoch: 25 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4867388883246989		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.4867388883246989 | validation: 0.3457499817314922]
	TIME [epoch: 24.9 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30990549784256693		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.30990549784256693 | validation: 0.2897894706657932]
	TIME [epoch: 25 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2819170610514595		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.2819170610514595 | validation: 0.2954730681224886]
	TIME [epoch: 24.9 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.284096985955655		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.284096985955655 | validation: 0.26555066298543517]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_736.pth
	Model improved!!!
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2724311879882425		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.2724311879882425 | validation: 0.3066161485969227]
	TIME [epoch: 24.9 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31051492068468195		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.31051492068468195 | validation: 0.29435129400737764]
	TIME [epoch: 24.9 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3129395302404021		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.3129395302404021 | validation: 0.30940985372096164]
	TIME [epoch: 25 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31499163874396097		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.31499163874396097 | validation: 0.29510997431390534]
	TIME [epoch: 25 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30969881012705697		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.30969881012705697 | validation: 0.3278522011557795]
	TIME [epoch: 24.9 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33976453052887146		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.33976453052887146 | validation: 0.34328219111995917]
	TIME [epoch: 25 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.337893872500661		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.337893872500661 | validation: 0.31348899328941177]
	TIME [epoch: 24.9 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29060860717395515		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.29060860717395515 | validation: 0.29877454467669073]
	TIME [epoch: 24.9 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31729569535960994		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.31729569535960994 | validation: 0.3414885695363955]
	TIME [epoch: 25 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29446079970222555		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.29446079970222555 | validation: 0.2781489890888272]
	TIME [epoch: 24.9 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27968711672364444		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.27968711672364444 | validation: 0.34717454731235436]
	TIME [epoch: 24.9 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30940632003251595		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.30940632003251595 | validation: 0.29399863144090427]
	TIME [epoch: 25 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28349621760200144		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.28349621760200144 | validation: 0.29893194893064917]
	TIME [epoch: 24.9 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26263596457112287		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.26263596457112287 | validation: 0.28736620761979487]
	TIME [epoch: 24.9 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25939843038631377		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.25939843038631377 | validation: 0.2832188271859495]
	TIME [epoch: 24.9 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2597076295804615		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.2597076295804615 | validation: 0.26606142225656015]
	TIME [epoch: 24.9 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2578371072070381		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.2578371072070381 | validation: 0.26045220495721005]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_753.pth
	Model improved!!!
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25122114379743804		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.25122114379743804 | validation: 0.2682239503327794]
	TIME [epoch: 25 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2665657116885539		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.2665657116885539 | validation: 0.2793508414509601]
	TIME [epoch: 24.9 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25516914820206954		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.25516914820206954 | validation: 0.28151397922089266]
	TIME [epoch: 24.9 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27261814395159223		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.27261814395159223 | validation: 0.281661345489011]
	TIME [epoch: 24.9 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30422825725922953		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.30422825725922953 | validation: 0.3804105392182353]
	TIME [epoch: 24.9 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3177381631692894		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.3177381631692894 | validation: 0.27233131791058585]
	TIME [epoch: 24.9 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25620547281762207		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.25620547281762207 | validation: 0.2703296019392283]
	TIME [epoch: 24.9 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26330487125036245		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.26330487125036245 | validation: 0.2891920560670637]
	TIME [epoch: 25 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2812405101423421		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.2812405101423421 | validation: 0.2974134070656764]
	TIME [epoch: 24.9 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2759548424179218		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.2759548424179218 | validation: 0.2794152757899049]
	TIME [epoch: 24.9 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25959964167326904		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.25959964167326904 | validation: 0.3121640470661359]
	TIME [epoch: 24.9 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34208629271421875		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.34208629271421875 | validation: 0.45236619576507303]
	TIME [epoch: 24.9 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37889603174734887		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.37889603174734887 | validation: 0.34698822326751994]
	TIME [epoch: 24.9 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3357075839267496		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.3357075839267496 | validation: 0.3547332011059396]
	TIME [epoch: 24.9 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31633774792867864		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.31633774792867864 | validation: 0.3205951697735891]
	TIME [epoch: 24.9 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.296075659662124		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.296075659662124 | validation: 0.2998222133124155]
	TIME [epoch: 24.9 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2926195100542125		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.2926195100542125 | validation: 0.3094499909666233]
	TIME [epoch: 24.9 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31665430251426385		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.31665430251426385 | validation: 0.3578276951642188]
	TIME [epoch: 24.9 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3336343236309866		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.3336343236309866 | validation: 0.3688995249346427]
	TIME [epoch: 25 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3401560581108686		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.3401560581108686 | validation: 0.35667787261562295]
	TIME [epoch: 24.9 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33818073623182315		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.33818073623182315 | validation: 0.32774566743760686]
	TIME [epoch: 24.9 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2914652166510485		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.2914652166510485 | validation: 0.2813824846171444]
	TIME [epoch: 24.9 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2751812849332326		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.2751812849332326 | validation: 0.26673187257479597]
	TIME [epoch: 24.9 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25236325024031553		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.25236325024031553 | validation: 0.26331340272692433]
	TIME [epoch: 24.9 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2541867163582844		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.2541867163582844 | validation: 0.29426943391414023]
	TIME [epoch: 25 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2890141370966674		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.2890141370966674 | validation: 0.31734105078330677]
	TIME [epoch: 24.9 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3637899522648196		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.3637899522648196 | validation: 0.43718590921250056]
	TIME [epoch: 24.9 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38105835715370673		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.38105835715370673 | validation: 0.344006983672352]
	TIME [epoch: 25 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3569080752611645		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.3569080752611645 | validation: 0.3281928152192321]
	TIME [epoch: 25 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2866054550087994		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.2866054550087994 | validation: 0.29398801319179785]
	TIME [epoch: 25 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.266394241838967		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.266394241838967 | validation: 0.294513101678837]
	TIME [epoch: 24.9 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2687519306059095		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.2687519306059095 | validation: 0.28516695718918833]
	TIME [epoch: 24.9 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25156183647518404		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.25156183647518404 | validation: 0.26776412571141867]
	TIME [epoch: 24.9 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.258059608104542		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.258059608104542 | validation: 0.29561715018025925]
	TIME [epoch: 24.9 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2663705043567107		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.2663705043567107 | validation: 0.25813684523265823]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_788.pth
	Model improved!!!
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.255737852072494		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.255737852072494 | validation: 0.2598159813547506]
	TIME [epoch: 24.9 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25840115483578224		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.25840115483578224 | validation: 0.2826914974751063]
	TIME [epoch: 25 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27182909389323995		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.27182909389323995 | validation: 0.3130176615975767]
	TIME [epoch: 24.9 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29079001748762123		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.29079001748762123 | validation: 0.33124731281759906]
	TIME [epoch: 24.9 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29407918399790095		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.29407918399790095 | validation: 0.30780801674750785]
	TIME [epoch: 24.9 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28141721053495145		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.28141721053495145 | validation: 0.27552857907213174]
	TIME [epoch: 24.9 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28873020409175354		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.28873020409175354 | validation: 0.35374032341461187]
	TIME [epoch: 24.9 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4361977979587832		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.4361977979587832 | validation: 0.5412243732312737]
	TIME [epoch: 24.9 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.508527962839771		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.508527962839771 | validation: 0.39420524494477294]
	TIME [epoch: 25 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34182447919217673		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.34182447919217673 | validation: 0.30696992817185154]
	TIME [epoch: 24.9 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28349277624292496		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.28349277624292496 | validation: 0.27532842202525915]
	TIME [epoch: 25.2 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2690886149390131		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.2690886149390131 | validation: 0.29910571035889527]
	TIME [epoch: 24.9 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.278435359399555		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.278435359399555 | validation: 0.28716651802437787]
	TIME [epoch: 24.9 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30679760019827307		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.30679760019827307 | validation: 0.26923071444560714]
	TIME [epoch: 24.9 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2535682084320302		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.2535682084320302 | validation: 0.2656649181054932]
	TIME [epoch: 24.9 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25235595806170275		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.25235595806170275 | validation: 0.2654786061582019]
	TIME [epoch: 24.9 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25021105859802606		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.25021105859802606 | validation: 0.27551944042275056]
	TIME [epoch: 24.9 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24974525757793847		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.24974525757793847 | validation: 0.276923902710179]
	TIME [epoch: 24.9 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2490172924550157		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.2490172924550157 | validation: 0.2650586999711254]
	TIME [epoch: 24.9 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25355709070423327		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.25355709070423327 | validation: 0.2714870659664673]
	TIME [epoch: 24.9 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29142952755482154		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.29142952755482154 | validation: 0.33906643616167886]
	TIME [epoch: 24.9 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3595370559370794		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.3595370559370794 | validation: 0.35755276086639143]
	TIME [epoch: 24.9 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3659330547713108		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.3659330547713108 | validation: 0.3228426213985625]
	TIME [epoch: 24.9 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30787094597590003		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.30787094597590003 | validation: 0.32119157610089133]
	TIME [epoch: 24.9 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30889051148482394		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.30889051148482394 | validation: 0.3247463357492771]
	TIME [epoch: 24.9 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33454380784755455		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.33454380784755455 | validation: 0.3489903597474263]
	TIME [epoch: 24.9 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3058897080241432		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.3058897080241432 | validation: 0.3145281404196183]
	TIME [epoch: 24.9 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28152116396628146		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.28152116396628146 | validation: 0.30167249309644556]
	TIME [epoch: 24.9 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2823993957996831		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.2823993957996831 | validation: 0.3006834882307044]
	TIME [epoch: 24.9 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28708012008691874		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.28708012008691874 | validation: 0.3049362963971401]
	TIME [epoch: 24.9 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2690453112404158		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.2690453112404158 | validation: 0.2885929312378527]
	TIME [epoch: 24.9 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2970755596291504		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.2970755596291504 | validation: 0.3326212310307316]
	TIME [epoch: 24.9 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29325929035293624		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.29325929035293624 | validation: 0.2750515989545209]
	TIME [epoch: 24.9 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2512998325127206		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.2512998325127206 | validation: 0.2754113481232268]
	TIME [epoch: 24.9 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25682659902028626		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.25682659902028626 | validation: 0.28018628528058387]
	TIME [epoch: 24.9 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24813324400865105		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.24813324400865105 | validation: 0.26125241077479094]
	TIME [epoch: 24.9 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24418720146697453		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.24418720146697453 | validation: 0.2636108388650811]
	TIME [epoch: 24.9 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24961719319695752		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.24961719319695752 | validation: 0.29889365052714506]
	TIME [epoch: 24.9 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26685993603354874		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.26685993603354874 | validation: 0.26817654386685824]
	TIME [epoch: 24.9 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2558342750118325		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.2558342750118325 | validation: 0.2931016256178339]
	TIME [epoch: 24.9 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.276014085370635		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.276014085370635 | validation: 0.36869083589486706]
	TIME [epoch: 24.9 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39508649402843865		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.39508649402843865 | validation: 0.4237471393612667]
	TIME [epoch: 24.9 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35221283084216265		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.35221283084216265 | validation: 0.29497606441785934]
	TIME [epoch: 24.9 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2581066078243534		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.2581066078243534 | validation: 0.27850047698967845]
	TIME [epoch: 24.9 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26271385548498694		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.26271385548498694 | validation: 0.2829868119982507]
	TIME [epoch: 24.9 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.261464537898008		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.261464537898008 | validation: 0.2716242661333273]
	TIME [epoch: 24.9 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.254171486751483		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.254171486751483 | validation: 0.2789101462630482]
	TIME [epoch: 24.9 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25408360903357835		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.25408360903357835 | validation: 0.28532552726829424]
	TIME [epoch: 24.9 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2522006927986004		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.2522006927986004 | validation: 0.27123591811146774]
	TIME [epoch: 24.9 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2589415004129012		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.2589415004129012 | validation: 0.2759032842887832]
	TIME [epoch: 24.9 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2465570843569478		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.2465570843569478 | validation: 0.27034543695595065]
	TIME [epoch: 24.9 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24460108675798037		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.24460108675798037 | validation: 0.28395291459249744]
	TIME [epoch: 24.9 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2545062229245655		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.2545062229245655 | validation: 0.2752703445900442]
	TIME [epoch: 24.9 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2524988554967843		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.2524988554967843 | validation: 0.2689460446922085]
	TIME [epoch: 24.9 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25272216396145863		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.25272216396145863 | validation: 0.298957325114718]
	TIME [epoch: 24.9 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2806820395820765		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.2806820395820765 | validation: 0.3014351763292581]
	TIME [epoch: 24.9 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25693067174613893		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.25693067174613893 | validation: 0.26908999449634935]
	TIME [epoch: 24.9 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24380605836504088		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.24380605836504088 | validation: 0.26626731246074564]
	TIME [epoch: 24.9 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24164257091103		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.24164257091103 | validation: 0.25502281816578687]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240309_135747/states/model_tr_study6_847.pth
	Model improved!!!
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23845503781651659		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.23845503781651659 | validation: 0.2663106604127884]
	TIME [epoch: 24.9 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25290206665748116		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.25290206665748116 | validation: 0.26507192596307866]
	TIME [epoch: 24.9 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24863287936500733		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.24863287936500733 | validation: 0.2729489027176672]
	TIME [epoch: 24.9 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2480945890880521		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.2480945890880521 | validation: 0.25904329102569046]
	TIME [epoch: 24.9 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2474257591754318		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.2474257591754318 | validation: 0.26338636727597936]
	TIME [epoch: 24.9 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25511792512327214		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.25511792512327214 | validation: 0.27049082626400306]
	TIME [epoch: 24.9 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.256920312743577		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.256920312743577 | validation: 0.277835422757698]
	TIME [epoch: 24.9 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25974302942660177		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.25974302942660177 | validation: 0.28817455747771387]
	TIME [epoch: 24.9 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27020873562527203		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.27020873562527203 | validation: 0.2750649000683681]
	TIME [epoch: 24.9 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2755153930574038		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.2755153930574038 | validation: 0.2880286029360229]
	TIME [epoch: 24.9 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2610688824525113		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.2610688824525113 | validation: 0.2801175364842882]
	TIME [epoch: 24.9 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25607614718812016		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.25607614718812016 | validation: 0.30945907552576524]
	TIME [epoch: 24.9 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30584751212598693		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.30584751212598693 | validation: 0.3244607484549582]
	TIME [epoch: 24.9 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3041734192489547		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.3041734192489547 | validation: 0.3566568075229705]
	TIME [epoch: 24.9 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37143990453338604		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.37143990453338604 | validation: 0.3726822820574482]
	TIME [epoch: 24.9 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.320049884988616		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.320049884988616 | validation: 0.30330830371077366]
	TIME [epoch: 24.9 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2747152045139206		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.2747152045139206 | validation: 0.2929622783094176]
	TIME [epoch: 24.9 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2891015396754059		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.2891015396754059 | validation: 0.28873962758608424]
	TIME [epoch: 24.9 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.284153845187425		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.284153845187425 | validation: 0.28372149155736165]
	TIME [epoch: 24.9 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25802259410088535		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.25802259410088535 | validation: 0.28094440389914527]
	TIME [epoch: 24.9 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25870261932518895		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.25870261932518895 | validation: 0.31059291904384123]
	TIME [epoch: 24.9 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27400546055229036		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.27400546055229036 | validation: 0.338148304494131]
	TIME [epoch: 24.9 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.291240678514011		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.291240678514011 | validation: 0.3074838456535964]
	TIME [epoch: 24.9 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26662754289148316		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.26662754289148316 | validation: 0.32879613883906955]
	TIME [epoch: 24.9 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2972380374622674		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.2972380374622674 | validation: 0.302062241341221]
	TIME [epoch: 24.9 sec]
EPOCH 873/2000:
	Training over batches...
