Args:
Namespace(name='model_tr_study1', outdir='out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4', training_data='data/transition_rate_studies/tr_study1/tr_study1_training/r4', validation_data='data/transition_rate_studies/tr_study1/tr_study1_validation/r4', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1245024937

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.159330006382822		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.159330006382822 | validation: 10.569971162513935]
	TIME [epoch: 82.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.526410450881531		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.526410450881531 | validation: 11.63610776797392]
	TIME [epoch: 6.43 sec]
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.376283915722116		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.376283915722116 | validation: 9.68624475108746]
	TIME [epoch: 6.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.337867489577407		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.337867489577407 | validation: 9.39091077234609]
	TIME [epoch: 6.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.811242827685186		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.811242827685186 | validation: 9.869379591221323]
	TIME [epoch: 6.41 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.964700437173658		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.964700437173658 | validation: 7.188185662708129]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.996439542877783		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.996439542877783 | validation: 7.7050049173808475]
	TIME [epoch: 6.4 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.764773887762468		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.764773887762468 | validation: 6.497722073210643]
	TIME [epoch: 6.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.280329247753497		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.280329247753497 | validation: 6.228929598105602]
	TIME [epoch: 6.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.0506054660027475		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.0506054660027475 | validation: 6.198399706579388]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.9397262021712836		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.9397262021712836 | validation: 6.548839421073492]
	TIME [epoch: 6.4 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.019100235488204		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.019100235488204 | validation: 5.859564817835405]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.710018286850099		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.710018286850099 | validation: 5.853822999845797]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.644671841798905		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.644671841798905 | validation: 5.6913764860198475]
	TIME [epoch: 6.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.532478193855237		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.532478193855237 | validation: 5.716333195172155]
	TIME [epoch: 6.41 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.396423098261219		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.396423098261219 | validation: 5.63677440135579]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.362999869842165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.362999869842165 | validation: 5.931063148437979]
	TIME [epoch: 6.39 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.6930584596766165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.6930584596766165 | validation: 5.249661737587693]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.1119093264041355		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.1119093264041355 | validation: 5.062871181145885]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.176606691164224		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.176606691164224 | validation: 5.426978618294288]
	TIME [epoch: 6.39 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.955270720041764		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.955270720041764 | validation: 4.637950739545157]
	TIME [epoch: 6.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.582590716658956		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.582590716658956 | validation: 4.489286814027998]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.412178916986396		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.412178916986396 | validation: 4.147529810255595]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.407010685318555		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.407010685318555 | validation: 4.22217448243515]
	TIME [epoch: 6.39 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.138288182239922		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.138288182239922 | validation: 3.8835444336770717]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.058161081214183		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.058161081214183 | validation: 4.043335486063217]
	TIME [epoch: 6.4 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8360622865353653		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8360622865353653 | validation: 3.459527505340617]
	TIME [epoch: 6.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5261865734803886		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5261865734803886 | validation: 3.621726557164543]
	TIME [epoch: 6.4 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2875808432787457		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2875808432787457 | validation: 3.0292983631236776]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6532088676075842		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6532088676075842 | validation: 4.363150185411456]
	TIME [epoch: 6.38 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4417579448391766		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4417579448391766 | validation: 3.237724969780871]
	TIME [epoch: 6.38 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3505736060470417		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3505736060470417 | validation: 2.908216156267869]
	TIME [epoch: 6.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.780834297615714		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.780834297615714 | validation: 3.982112286117982]
	TIME [epoch: 6.39 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.387441145277661		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.387441145277661 | validation: 4.341145937156703]
	TIME [epoch: 6.41 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.375258020638512		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.375258020638512 | validation: 2.899602307954818]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8401012100197534		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8401012100197534 | validation: 2.839916224583301]
	TIME [epoch: 6.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8531690487870973		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8531690487870973 | validation: 2.5594258294307077]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8840339162498316		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8840339162498316 | validation: 2.5349589344413466]
	TIME [epoch: 6.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.577243385663988		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.577243385663988 | validation: 2.6687781671229978]
	TIME [epoch: 6.39 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.45358618608404		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.45358618608404 | validation: 2.593052300618027]
	TIME [epoch: 6.42 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7960581078559086		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7960581078559086 | validation: 2.404246699123933]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.557105141767526		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.557105141767526 | validation: 2.7661527249677613]
	TIME [epoch: 6.38 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8058126075060774		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8058126075060774 | validation: 2.5261006879525776]
	TIME [epoch: 6.38 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7024699445475004		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7024699445475004 | validation: 2.5664251812037917]
	TIME [epoch: 6.38 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.402309688546772		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.402309688546772 | validation: 3.082487125581262]
	TIME [epoch: 6.39 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.619259037399405		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.619259037399405 | validation: 2.431067248948653]
	TIME [epoch: 6.39 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.336806941424144		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.336806941424144 | validation: 2.8516234256006747]
	TIME [epoch: 6.41 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.369892794843839		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.369892794843839 | validation: 2.4962149931941293]
	TIME [epoch: 6.39 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3395179538375688		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3395179538375688 | validation: 3.0676217469220957]
	TIME [epoch: 6.38 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.52071314415694		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.52071314415694 | validation: 2.295158836001725]
	TIME [epoch: 6.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.360965986131261		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 2.360965986131261 | validation: 2.76768644521693]
	TIME [epoch: 6.39 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.288590517911359		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 2.288590517911359 | validation: 3.2339649780644253]
	TIME [epoch: 6.39 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3324736753386004		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 2.3324736753386004 | validation: 2.1781260619359064]
	TIME [epoch: 6.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.032279414459255		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 2.032279414459255 | validation: 3.1943329083405168]
	TIME [epoch: 6.4 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4864750506111917		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 2.4864750506111917 | validation: 3.2244927045448186]
	TIME [epoch: 6.39 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.681034076838499		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 2.681034076838499 | validation: 3.1319461437027525]
	TIME [epoch: 6.42 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7968357071728773		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 2.7968357071728773 | validation: 2.092264637615473]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1792433058476868		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 2.1792433058476868 | validation: 2.098400856846642]
	TIME [epoch: 6.39 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.269945619307876		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 2.269945619307876 | validation: 2.397256410337295]
	TIME [epoch: 6.4 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1136907128379767		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 2.1136907128379767 | validation: 2.081897150665451]
	TIME [epoch: 6.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.066167786169556		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 2.066167786169556 | validation: 1.986172631628552]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2764865361677518		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 2.2764865361677518 | validation: 2.1156434604960794]
	TIME [epoch: 6.4 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2634006625216196		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 2.2634006625216196 | validation: 2.14245088861201]
	TIME [epoch: 6.4 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.917166046048869		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 1.917166046048869 | validation: 2.8134204274473507]
	TIME [epoch: 6.4 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3084828820718686		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 2.3084828820718686 | validation: 2.8848381281692856]
	TIME [epoch: 6.4 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3852495393816557		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 2.3852495393816557 | validation: 2.2486803638815718]
	TIME [epoch: 6.43 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.354015398617957		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 2.354015398617957 | validation: 2.39233349418836]
	TIME [epoch: 6.41 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.130646537582236		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 2.130646537582236 | validation: 2.0964563842871224]
	TIME [epoch: 6.4 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8867572045339873		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 1.8867572045339873 | validation: 2.6551122878262903]
	TIME [epoch: 6.4 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.186375563153248		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 2.186375563153248 | validation: 2.3339472745187715]
	TIME [epoch: 6.4 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.073877842300056		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 2.073877842300056 | validation: 2.1972262540882572]
	TIME [epoch: 6.4 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.134470444051295		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 2.134470444051295 | validation: 1.9154107613715718]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8692546440346873		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 1.8692546440346873 | validation: 1.9330494578240636]
	TIME [epoch: 6.44 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9698067255254315		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 1.9698067255254315 | validation: 2.0461605129994105]
	TIME [epoch: 6.41 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.94749746717951		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 1.94749746717951 | validation: 2.158258214483235]
	TIME [epoch: 6.4 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9755245561649497		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 1.9755245561649497 | validation: 2.6174181665005425]
	TIME [epoch: 6.4 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9795892141000175		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 1.9795892141000175 | validation: 2.0478598204560217]
	TIME [epoch: 6.41 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7295699021977815		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 1.7295699021977815 | validation: 2.1691160816267927]
	TIME [epoch: 6.4 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9520658427298838		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 1.9520658427298838 | validation: 1.9593056050281978]
	TIME [epoch: 6.42 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8289624752943594		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 1.8289624752943594 | validation: 2.773399371636431]
	TIME [epoch: 6.42 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.272317024273798		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 2.272317024273798 | validation: 3.1480181481903577]
	TIME [epoch: 6.4 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1154087202342162		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 2.1154087202342162 | validation: 1.8537429673171633]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_82.pth
	Model improved!!!
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6332813188262651		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 1.6332813188262651 | validation: 3.648325993950469]
	TIME [epoch: 6.4 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2312469924171		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 2.2312469924171 | validation: 1.6458321817557744]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_84.pth
	Model improved!!!
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9965246182721617		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 1.9965246182721617 | validation: 1.9643703437222488]
	TIME [epoch: 6.4 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7256709008543636		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 1.7256709008543636 | validation: 2.336381143511583]
	TIME [epoch: 6.43 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9542884252547779		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 1.9542884252547779 | validation: 3.1325393342627774]
	TIME [epoch: 6.41 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.105515418724042		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 2.105515418724042 | validation: 2.6829872408715767]
	TIME [epoch: 6.39 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8987102174361399		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 1.8987102174361399 | validation: 2.2049620882686414]
	TIME [epoch: 6.39 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8709660134837365		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 1.8709660134837365 | validation: 2.0237066745341528]
	TIME [epoch: 6.4 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1555374874432665		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 2.1555374874432665 | validation: 1.7442320261868773]
	TIME [epoch: 6.4 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.036632549691986		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 2.036632549691986 | validation: 1.814611430402056]
	TIME [epoch: 6.4 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5670920105893003		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 1.5670920105893003 | validation: 2.1035457889440874]
	TIME [epoch: 6.43 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7531758269052606		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 1.7531758269052606 | validation: 1.688817690179665]
	TIME [epoch: 6.4 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5801562285981336		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 1.5801562285981336 | validation: 1.6723862048265736]
	TIME [epoch: 6.4 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6034674569028904		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 1.6034674569028904 | validation: 2.1535736788423674]
	TIME [epoch: 6.4 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9560749581948587		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 1.9560749581948587 | validation: 1.7567565855093785]
	TIME [epoch: 6.41 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7829589987689185		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 1.7829589987689185 | validation: 1.5720559602195407]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_98.pth
	Model improved!!!
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.455619518613455		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 1.455619518613455 | validation: 3.237484398880247]
	TIME [epoch: 6.41 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.235403726609128		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 2.235403726609128 | validation: 1.6702184822781723]
	TIME [epoch: 6.42 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5809733962034356		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 1.5809733962034356 | validation: 2.0388825352325872]
	TIME [epoch: 6.41 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3958964013693307		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 1.3958964013693307 | validation: 2.1854835541472686]
	TIME [epoch: 6.4 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6776504738213394		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 1.6776504738213394 | validation: 1.6889735128556527]
	TIME [epoch: 6.4 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4704981389848548		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 1.4704981389848548 | validation: 1.7946429155108317]
	TIME [epoch: 6.41 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7672049993500263		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 1.7672049993500263 | validation: 1.5921060655853665]
	TIME [epoch: 6.41 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5613648481212294		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 1.5613648481212294 | validation: 1.9234313646900651]
	TIME [epoch: 6.43 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6365827966894064		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 1.6365827966894064 | validation: 1.5492364589671275]
	TIME [epoch: 6.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_107.pth
	Model improved!!!
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6523531777325808		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 1.6523531777325808 | validation: 3.8471148913547677]
	TIME [epoch: 6.4 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7653540005796988		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 1.7653540005796988 | validation: 2.316605613476586]
	TIME [epoch: 6.4 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.463566598070514		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 1.463566598070514 | validation: 1.4852433019009732]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_110.pth
	Model improved!!!
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.347657464160143		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 1.347657464160143 | validation: 2.0543798283975394]
	TIME [epoch: 6.41 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6040946809733485		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 1.6040946809733485 | validation: 1.8107158687978235]
	TIME [epoch: 6.42 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5628750493517565		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 1.5628750493517565 | validation: 2.525364578117542]
	TIME [epoch: 6.42 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5084678961314633		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 1.5084678961314633 | validation: 1.5358166555872237]
	TIME [epoch: 6.41 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4191466393500813		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 1.4191466393500813 | validation: 3.796869343216074]
	TIME [epoch: 6.4 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6748185911198707		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 1.6748185911198707 | validation: 1.5594647564735804]
	TIME [epoch: 6.4 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4759229006515575		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 1.4759229006515575 | validation: 1.3989607357952099]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_117.pth
	Model improved!!!
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.274850593225227		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 1.274850593225227 | validation: 1.4033252455590515]
	TIME [epoch: 6.4 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1532993778893958		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 1.1532993778893958 | validation: 1.6538404565645846]
	TIME [epoch: 6.43 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3464410804169247		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 1.3464410804169247 | validation: 1.7465307026691077]
	TIME [epoch: 6.42 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4763996058577542		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 1.4763996058577542 | validation: 1.7403757892821348]
	TIME [epoch: 6.4 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.405231851451868		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 1.405231851451868 | validation: 1.4525955909117836]
	TIME [epoch: 6.41 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2122632817331094		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 1.2122632817331094 | validation: 2.4264735972017433]
	TIME [epoch: 6.4 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.335423731277745		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 1.335423731277745 | validation: 1.808754496057518]
	TIME [epoch: 6.4 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.518656468086406		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 1.518656468086406 | validation: 1.4241312009808718]
	TIME [epoch: 6.4 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.320449064571227		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 1.320449064571227 | validation: 1.307681053733658]
	TIME [epoch: 6.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_126.pth
	Model improved!!!
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2931658982081156		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 1.2931658982081156 | validation: 1.991646764681822]
	TIME [epoch: 6.4 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1610196436443514		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 1.1610196436443514 | validation: 1.6316628460002465]
	TIME [epoch: 6.4 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2113436357396796		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 1.2113436357396796 | validation: 1.3308862944649342]
	TIME [epoch: 6.4 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5065322278668667		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 1.5065322278668667 | validation: 1.5117883789419988]
	TIME [epoch: 6.41 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4848346131254202		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 1.4848346131254202 | validation: 1.3404414621592222]
	TIME [epoch: 6.4 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1566016170552689		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 1.1566016170552689 | validation: 1.3789873985211898]
	TIME [epoch: 6.42 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.603272685823984		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 1.603272685823984 | validation: 1.6792674633471905]
	TIME [epoch: 6.42 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6178061619215507		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 1.6178061619215507 | validation: 1.5894629070341217]
	TIME [epoch: 6.4 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4541249699234613		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 1.4541249699234613 | validation: 1.739581017100549]
	TIME [epoch: 6.4 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2392555160956202		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 1.2392555160956202 | validation: 2.400464195695595]
	TIME [epoch: 6.41 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4299747324949759		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 1.4299747324949759 | validation: 1.554615031281021]
	TIME [epoch: 6.4 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2217943298245668		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 1.2217943298245668 | validation: 1.5396780193475206]
	TIME [epoch: 6.41 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1848664118423167		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 1.1848664118423167 | validation: 1.8753843712809761]
	TIME [epoch: 6.43 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.157278130249543		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 1.157278130249543 | validation: 1.4590503070886367]
	TIME [epoch: 6.42 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2542203717398075		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 1.2542203717398075 | validation: 1.6173342179638968]
	TIME [epoch: 6.41 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1235518480623936		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 1.1235518480623936 | validation: 1.962876579961648]
	TIME [epoch: 6.41 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2295689379785266		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 1.2295689379785266 | validation: 1.3049649004098098]
	TIME [epoch: 6.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_143.pth
	Model improved!!!
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.200948101993537		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 1.200948101993537 | validation: 1.997844226200906]
	TIME [epoch: 6.4 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4280746834364224		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 1.4280746834364224 | validation: 1.340182038392546]
	TIME [epoch: 6.41 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1766545926377447		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 1.1766545926377447 | validation: 1.260381365227461]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_146.pth
	Model improved!!!
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0189492886852713		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 1.0189492886852713 | validation: 1.5563545365536617]
	TIME [epoch: 6.4 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0995156781485647		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 1.0995156781485647 | validation: 2.0646818855361495]
	TIME [epoch: 6.4 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0179037131334083		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 2.0179037131334083 | validation: 1.7606397199999442]
	TIME [epoch: 6.4 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6085764814979766		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 1.6085764814979766 | validation: 2.3619511984706048]
	TIME [epoch: 6.4 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.577651548013086		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 1.577651548013086 | validation: 1.7219117056982784]
	TIME [epoch: 6.4 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4551764946639603		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 1.4551764946639603 | validation: 1.352326699812457]
	TIME [epoch: 6.43 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.32077553690876		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 1.32077553690876 | validation: 1.5136341950347254]
	TIME [epoch: 6.41 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.379472119131678		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 1.379472119131678 | validation: 1.6586308006151855]
	TIME [epoch: 6.4 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3946072156615834		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 1.3946072156615834 | validation: 1.3593374218120642]
	TIME [epoch: 6.41 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.16894188320727		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 1.16894188320727 | validation: 1.8967818876336313]
	TIME [epoch: 6.4 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.42952976028901		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 1.42952976028901 | validation: 1.3386085829706726]
	TIME [epoch: 6.4 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1385023438548043		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 1.1385023438548043 | validation: 1.5329823990214237]
	TIME [epoch: 6.4 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3050973644525208		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 1.3050973644525208 | validation: 2.1227034214594034]
	TIME [epoch: 6.44 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.339505713363533		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 1.339505713363533 | validation: 1.739568856889299]
	TIME [epoch: 6.41 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4154396173194288		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 1.4154396173194288 | validation: 1.4280065817523695]
	TIME [epoch: 6.4 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9211977365109443		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.9211977365109443 | validation: 1.140305147803333]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_162.pth
	Model improved!!!
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9608886391266647		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.9608886391266647 | validation: 1.368307573579728]
	TIME [epoch: 6.4 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9564529945654172		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.9564529945654172 | validation: 1.203047992721885]
	TIME [epoch: 6.4 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0740033828398536		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 1.0740033828398536 | validation: 0.9817853988328181]
	TIME [epoch: 6.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_165.pth
	Model improved!!!
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0103771129415868		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 1.0103771129415868 | validation: 1.2324111194536576]
	TIME [epoch: 6.42 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8980294875753919		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 0.8980294875753919 | validation: 1.0785848730286143]
	TIME [epoch: 6.41 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9568201396934894		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.9568201396934894 | validation: 1.2267036663277164]
	TIME [epoch: 6.4 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8390466490258224		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.8390466490258224 | validation: 2.2967792757080345]
	TIME [epoch: 6.4 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1727504870275656		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 1.1727504870275656 | validation: 1.26588044002501]
	TIME [epoch: 6.4 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2293433349603622		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 1.2293433349603622 | validation: 1.3943945325099025]
	TIME [epoch: 6.4 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1124097212780324		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 1.1124097212780324 | validation: 1.112197428637138]
	TIME [epoch: 6.43 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8508567451063141		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.8508567451063141 | validation: 1.6016989749118131]
	TIME [epoch: 6.41 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8925609422089673		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.8925609422089673 | validation: 1.1405365057078445]
	TIME [epoch: 6.4 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0028465199276921		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 1.0028465199276921 | validation: 1.8232808229193374]
	TIME [epoch: 6.4 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9378942293383608		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 0.9378942293383608 | validation: 1.2173561165699178]
	TIME [epoch: 6.41 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2483563456363893		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 1.2483563456363893 | validation: 1.2789730330461582]
	TIME [epoch: 6.41 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8081751463241609		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.8081751463241609 | validation: 1.8319885575842483]
	TIME [epoch: 6.41 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9330326711802905		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.9330326711802905 | validation: 1.0794218328344516]
	TIME [epoch: 6.43 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9478952164329018		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.9478952164329018 | validation: 1.6023323933797913]
	TIME [epoch: 6.4 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.016470724397364		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 1.016470724397364 | validation: 1.158264181766762]
	TIME [epoch: 6.4 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7369504511987423		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.7369504511987423 | validation: 1.039099876535057]
	TIME [epoch: 6.41 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4094706754927768		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 1.4094706754927768 | validation: 1.202636779282105]
	TIME [epoch: 6.4 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9864265330367489		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.9864265330367489 | validation: 1.0929350124345527]
	TIME [epoch: 6.41 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0164795251770167		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 1.0164795251770167 | validation: 1.323413966021052]
	TIME [epoch: 6.42 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8069378068097539		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.8069378068097539 | validation: 1.050554585661406]
	TIME [epoch: 6.42 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8702117004367496		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.8702117004367496 | validation: 1.5216967400147883]
	TIME [epoch: 6.41 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2453403472375415		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 1.2453403472375415 | validation: 1.2963254999905092]
	TIME [epoch: 6.41 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0818752093626567		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 1.0818752093626567 | validation: 1.2944350474232686]
	TIME [epoch: 6.41 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1158405364196278		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 1.1158405364196278 | validation: 1.1748137454417071]
	TIME [epoch: 6.41 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0727337349184625		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 1.0727337349184625 | validation: 1.1558321587522096]
	TIME [epoch: 6.41 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0005566273179913		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 1.0005566273179913 | validation: 1.2231114286680906]
	TIME [epoch: 6.43 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2126102939440155		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 2.2126102939440155 | validation: 1.6055439234580506]
	TIME [epoch: 6.42 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.386322885407579		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 1.386322885407579 | validation: 1.286403394614248]
	TIME [epoch: 6.4 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0629756749029842		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 1.0629756749029842 | validation: 1.1414682625890178]
	TIME [epoch: 6.4 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0686943338250765		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 1.0686943338250765 | validation: 1.0667762759042856]
	TIME [epoch: 6.41 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1618712094504469		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 1.1618712094504469 | validation: 1.4040936273265103]
	TIME [epoch: 6.41 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2128934246476109		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 1.2128934246476109 | validation: 1.7014914780894776]
	TIME [epoch: 6.41 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1044954397150677		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 1.1044954397150677 | validation: 1.8585772474988063]
	TIME [epoch: 6.43 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1271052559242132		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 1.1271052559242132 | validation: 1.3319117540784613]
	TIME [epoch: 6.41 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9419294527869808		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.9419294527869808 | validation: 1.0703189581199057]
	TIME [epoch: 6.41 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8768436207062917		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.8768436207062917 | validation: 0.9670396674130922]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_202.pth
	Model improved!!!
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9956644779296391		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.9956644779296391 | validation: 0.9993772993677822]
	TIME [epoch: 6.4 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.281707493331192		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 1.281707493331192 | validation: 1.065582476501192]
	TIME [epoch: 6.4 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0236751273357485		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 1.0236751273357485 | validation: 1.1555739750529295]
	TIME [epoch: 6.41 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9537393829419079		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.9537393829419079 | validation: 1.5010819449301505]
	TIME [epoch: 6.42 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0129847989621346		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 1.0129847989621346 | validation: 1.041394726645589]
	TIME [epoch: 6.41 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0081536218360223		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 1.0081536218360223 | validation: 1.1626172964488242]
	TIME [epoch: 6.4 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8775581881784607		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.8775581881784607 | validation: 1.2479550809025801]
	TIME [epoch: 6.4 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9794992026868363		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.9794992026868363 | validation: 1.0369492123530961]
	TIME [epoch: 6.4 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1070628719957454		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 1.1070628719957454 | validation: 1.0505071514791515]
	TIME [epoch: 6.4 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0812642553022271		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 1.0812642553022271 | validation: 0.9411450247592944]
	TIME [epoch: 6.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_212.pth
	Model improved!!!
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8951924212040462		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.8951924212040462 | validation: 1.4700021999557924]
	TIME [epoch: 6.42 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0925068522694072		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 1.0925068522694072 | validation: 1.0862396178708686]
	TIME [epoch: 6.41 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0899059660558483		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 1.0899059660558483 | validation: 1.062504241063858]
	TIME [epoch: 6.4 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8510433357684635		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.8510433357684635 | validation: 1.2398906114757382]
	TIME [epoch: 6.41 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9500933774518426		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.9500933774518426 | validation: 1.0338426638952383]
	TIME [epoch: 6.39 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.810671348408635		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.810671348408635 | validation: 1.222748046793612]
	TIME [epoch: 6.41 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0138057040768076		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 1.0138057040768076 | validation: 1.063066427376472]
	TIME [epoch: 6.42 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8673183436823242		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.8673183436823242 | validation: 0.7666493484161653]
	TIME [epoch: 6.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_220.pth
	Model improved!!!
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8620627267374956		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.8620627267374956 | validation: 1.3241510260060587]
	TIME [epoch: 6.39 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8153373979774333		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.8153373979774333 | validation: 1.0159952060926518]
	TIME [epoch: 6.39 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7603176306981914		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.7603176306981914 | validation: 1.1605854442246757]
	TIME [epoch: 6.41 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.954183926423027		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.954183926423027 | validation: 0.9616088509041159]
	TIME [epoch: 6.39 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8104534130276845		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.8104534130276845 | validation: 0.9795619466618567]
	TIME [epoch: 6.4 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8144672986975449		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.8144672986975449 | validation: 1.002002165420456]
	TIME [epoch: 6.43 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8078657028966105		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.8078657028966105 | validation: 0.8023941875434897]
	TIME [epoch: 6.4 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1220978768349936		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 1.1220978768349936 | validation: 1.6404759678316994]
	TIME [epoch: 6.4 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9901992861594234		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.9901992861594234 | validation: 0.9850200955002612]
	TIME [epoch: 6.39 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8583247598224686		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.8583247598224686 | validation: 1.078850480304215]
	TIME [epoch: 6.4 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0043488167962389		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 1.0043488167962389 | validation: 0.9769473732808291]
	TIME [epoch: 6.39 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8039159461530037		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.8039159461530037 | validation: 1.4905065643698276]
	TIME [epoch: 6.43 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6742727028123152		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.6742727028123152 | validation: 0.7692784283703901]
	TIME [epoch: 6.4 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6952415029391349		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.6952415029391349 | validation: 0.8800331592952586]
	TIME [epoch: 6.39 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6681633613140093		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.6681633613140093 | validation: 0.6710459969481031]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_235.pth
	Model improved!!!
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6113600672970677		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.6113600672970677 | validation: 0.9472088625985073]
	TIME [epoch: 6.41 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7395320399406817		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.7395320399406817 | validation: 0.9582695710604611]
	TIME [epoch: 6.4 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8548489568321653		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.8548489568321653 | validation: 0.8370506665161412]
	TIME [epoch: 6.4 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6508316228319098		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.6508316228319098 | validation: 0.8877231528751913]
	TIME [epoch: 6.42 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5919678777160873		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.5919678777160873 | validation: 0.7752566092071641]
	TIME [epoch: 6.4 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6277840024058919		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.6277840024058919 | validation: 0.6141431269564199]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_241.pth
	Model improved!!!
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6253418217548118		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.6253418217548118 | validation: 0.5907721768512731]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_242.pth
	Model improved!!!
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7006665431000119		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.7006665431000119 | validation: 1.51370518785403]
	TIME [epoch: 6.39 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0026551577409757		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 1.0026551577409757 | validation: 0.6110480921530224]
	TIME [epoch: 6.39 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8044411774300482		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.8044411774300482 | validation: 0.8121461513726471]
	TIME [epoch: 6.42 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.615507669596877		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.615507669596877 | validation: 0.5077382067797255]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_246.pth
	Model improved!!!
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5903677961184155		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.5903677961184155 | validation: 0.680355572984982]
	TIME [epoch: 6.41 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6372082890623173		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.6372082890623173 | validation: 1.1608700400899072]
	TIME [epoch: 6.41 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9480393669038717		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.9480393669038717 | validation: 1.18551593268032]
	TIME [epoch: 6.41 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9759332769360302		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.9759332769360302 | validation: 0.9105557853916868]
	TIME [epoch: 6.41 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7439032666939761		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.7439032666939761 | validation: 0.8470050898389115]
	TIME [epoch: 6.41 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.687120024086269		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.687120024086269 | validation: 0.8413142845952679]
	TIME [epoch: 6.44 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.832072784902361		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.832072784902361 | validation: 0.739635249783237]
	TIME [epoch: 6.41 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7638412599510207		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.7638412599510207 | validation: 0.8476837629768079]
	TIME [epoch: 6.41 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6812252958938021		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.6812252958938021 | validation: 1.0532826429361706]
	TIME [epoch: 6.41 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7207519484422964		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.7207519484422964 | validation: 0.814699101954908]
	TIME [epoch: 6.41 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6841091082172922		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.6841091082172922 | validation: 0.6742348484205727]
	TIME [epoch: 6.41 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5130720772931909		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.5130720772931909 | validation: 0.7973657175186071]
	TIME [epoch: 6.43 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5841715217029398		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.5841715217029398 | validation: 0.6455317571646346]
	TIME [epoch: 6.44 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5753394842449144		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.5753394842449144 | validation: 0.6501898811344751]
	TIME [epoch: 6.4 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6357659025063038		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.6357659025063038 | validation: 0.8504049805819653]
	TIME [epoch: 6.41 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7067054160335549		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.7067054160335549 | validation: 0.6986520176419562]
	TIME [epoch: 6.41 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5987180048627988		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.5987180048627988 | validation: 0.4884754753400873]
	TIME [epoch: 6.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_263.pth
	Model improved!!!
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45097122762630243		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.45097122762630243 | validation: 1.182778075166259]
	TIME [epoch: 6.4 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7147672728081685		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.7147672728081685 | validation: 0.9879498199697448]
	TIME [epoch: 6.43 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7228143681241541		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.7228143681241541 | validation: 0.5738974022323986]
	TIME [epoch: 6.41 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.608515570581943		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.608515570581943 | validation: 1.1632836244941682]
	TIME [epoch: 6.4 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6168491249201941		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.6168491249201941 | validation: 0.9692174388521649]
	TIME [epoch: 6.4 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5988831122813975		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.5988831122813975 | validation: 0.6676570937069485]
	TIME [epoch: 6.4 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5725245499216765		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.5725245499216765 | validation: 0.642003304054818]
	TIME [epoch: 6.4 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6143460674185426		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.6143460674185426 | validation: 0.474089882813351]
	TIME [epoch: 6.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_271.pth
	Model improved!!!
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4492910900696149		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.4492910900696149 | validation: 0.5249885683016566]
	TIME [epoch: 6.42 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6241449695842721		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.6241449695842721 | validation: 0.36685313660859065]
	TIME [epoch: 6.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_273.pth
	Model improved!!!
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5110336160141267		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.5110336160141267 | validation: 0.6185277314395847]
	TIME [epoch: 6.4 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4771671915279587		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.4771671915279587 | validation: 0.8290893642902947]
	TIME [epoch: 6.4 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5440471834717753		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.5440471834717753 | validation: 0.6699481914438448]
	TIME [epoch: 6.4 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5604055838540623		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.5604055838540623 | validation: 0.7227374432252424]
	TIME [epoch: 6.4 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5136111840749382		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.5136111840749382 | validation: 0.8015128300731883]
	TIME [epoch: 6.43 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6948847157992687		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.6948847157992687 | validation: 1.366237397592774]
	TIME [epoch: 6.41 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7732969979131035		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.7732969979131035 | validation: 0.7995072041442869]
	TIME [epoch: 6.4 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6228828990908163		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.6228828990908163 | validation: 0.5583456298517537]
	TIME [epoch: 6.41 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4537787631362353		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.4537787631362353 | validation: 0.47104577906032746]
	TIME [epoch: 6.41 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44167090031901496		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.44167090031901496 | validation: 0.4600669158121685]
	TIME [epoch: 6.41 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33493500895011424		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.33493500895011424 | validation: 0.5796742896216154]
	TIME [epoch: 6.42 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4980824540220371		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.4980824540220371 | validation: 0.815527748434619]
	TIME [epoch: 6.44 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3886031632793706		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.3886031632793706 | validation: 0.8830899819017808]
	TIME [epoch: 6.42 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6991072366149818		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.6991072366149818 | validation: 0.6399558016724053]
	TIME [epoch: 6.41 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6056275921976233		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.6056275921976233 | validation: 0.5243602678275142]
	TIME [epoch: 6.41 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49339111958858217		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.49339111958858217 | validation: 0.5237060077086914]
	TIME [epoch: 6.41 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35784360696140816		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.35784360696140816 | validation: 0.5466594313605242]
	TIME [epoch: 6.42 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5971250256882241		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.5971250256882241 | validation: 0.6482803967857244]
	TIME [epoch: 6.42 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5523430617760289		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.5523430617760289 | validation: 0.6873093751142506]
	TIME [epoch: 6.43 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.556843646951904		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.556843646951904 | validation: 0.5920995924647335]
	TIME [epoch: 6.42 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4954507266330858		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.4954507266330858 | validation: 0.8698154328576675]
	TIME [epoch: 6.41 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5976414957560441		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.5976414957560441 | validation: 0.7712659269853873]
	TIME [epoch: 6.4 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5908914145865705		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.5908914145865705 | validation: 0.4942351920894286]
	TIME [epoch: 6.4 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5142400952472284		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.5142400952472284 | validation: 0.4166414482837146]
	TIME [epoch: 6.4 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6770599345793336		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.6770599345793336 | validation: 0.5113814136191703]
	TIME [epoch: 6.43 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5237507680670705		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.5237507680670705 | validation: 0.33840382593182183]
	TIME [epoch: 6.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_299.pth
	Model improved!!!
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44622576532276853		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.44622576532276853 | validation: 0.4609995675996818]
	TIME [epoch: 6.41 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38960241329674805		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.38960241329674805 | validation: 0.4281354621788154]
	TIME [epoch: 6.41 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5803272510704998		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.5803272510704998 | validation: 0.36852554939788007]
	TIME [epoch: 6.41 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38531248138687824		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.38531248138687824 | validation: 0.8009796313158938]
	TIME [epoch: 6.41 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4985236008204708		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.4985236008204708 | validation: 0.6575920468941681]
	TIME [epoch: 6.42 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4856798737858856		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.4856798737858856 | validation: 0.5615484632017713]
	TIME [epoch: 6.44 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8096876856026454		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.8096876856026454 | validation: 1.3214965064675852]
	TIME [epoch: 6.41 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6620614970039682		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.6620614970039682 | validation: 0.5561610057727432]
	TIME [epoch: 6.41 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5200774411979963		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.5200774411979963 | validation: 0.6166595071427851]
	TIME [epoch: 6.41 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.577875719912076		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.577875719912076 | validation: 0.7855269541349174]
	TIME [epoch: 6.4 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5172098038773394		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.5172098038773394 | validation: 0.6040853264018738]
	TIME [epoch: 6.41 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6199107234269983		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.6199107234269983 | validation: 0.8638316444420963]
	TIME [epoch: 6.42 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4837179673850532		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.4837179673850532 | validation: 0.43454598022472773]
	TIME [epoch: 6.42 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4772994540198243		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.4772994540198243 | validation: 0.5279499704695]
	TIME [epoch: 6.4 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4324401713628895		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.4324401713628895 | validation: 0.353305068129418]
	TIME [epoch: 6.4 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44676707722869075		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.44676707722869075 | validation: 0.30067265795390635]
	TIME [epoch: 6.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_315.pth
	Model improved!!!
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3589262098491103		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.3589262098491103 | validation: 1.0675906059403797]
	TIME [epoch: 6.4 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5405502525069589		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.5405502525069589 | validation: 0.4984700504901587]
	TIME [epoch: 6.4 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5078994784312527		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.5078994784312527 | validation: 0.3839243657545302]
	TIME [epoch: 6.43 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.322282052824964		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.322282052824964 | validation: 0.42211035667799435]
	TIME [epoch: 6.41 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41205177560221856		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.41205177560221856 | validation: 0.7548001737130534]
	TIME [epoch: 6.4 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44857321922652443		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.44857321922652443 | validation: 0.43986790202445863]
	TIME [epoch: 6.41 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4156032907112409		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.4156032907112409 | validation: 0.4072114101615382]
	TIME [epoch: 6.41 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4271346179406708		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.4271346179406708 | validation: 0.3817514921572541]
	TIME [epoch: 6.41 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35494643382547536		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.35494643382547536 | validation: 0.3353655080716333]
	TIME [epoch: 6.41 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5655823564854747		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.5655823564854747 | validation: 0.6081079988145723]
	TIME [epoch: 6.44 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6495763634428762		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.6495763634428762 | validation: 0.582511370058182]
	TIME [epoch: 6.41 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3726878213203775		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.3726878213203775 | validation: 0.6475587167335155]
	TIME [epoch: 6.41 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4081663120242076		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.4081663120242076 | validation: 0.41595735241489734]
	TIME [epoch: 6.41 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38590677772106596		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.38590677772106596 | validation: 0.45807762059557583]
	TIME [epoch: 6.41 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3828575405940194		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.3828575405940194 | validation: 0.3127659363817342]
	TIME [epoch: 6.41 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35984570998688		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.35984570998688 | validation: 0.6616699339119493]
	TIME [epoch: 6.43 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4294575627617576		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.4294575627617576 | validation: 0.4093600462147583]
	TIME [epoch: 6.43 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3746586062679596		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.3746586062679596 | validation: 0.2984613829829976]
	TIME [epoch: 6.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_333.pth
	Model improved!!!
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4748628473249964		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.4748628473249964 | validation: 0.6526556691639565]
	TIME [epoch: 6.4 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40972473808030885		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.40972473808030885 | validation: 0.3567140426458504]
	TIME [epoch: 6.41 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3860739186451857		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.3860739186451857 | validation: 0.4674731542789665]
	TIME [epoch: 6.41 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4806951510557824		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.4806951510557824 | validation: 0.7071505124791284]
	TIME [epoch: 6.41 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5141951364716315		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.5141951364716315 | validation: 0.5336698675212785]
	TIME [epoch: 6.44 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2899404482961301		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.2899404482961301 | validation: 0.5680713436700271]
	TIME [epoch: 6.41 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4231865668038588		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.4231865668038588 | validation: 0.36941073805187385]
	TIME [epoch: 6.41 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7641514965829537		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.7641514965829537 | validation: 0.5047441226442441]
	TIME [epoch: 6.41 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.338684015366836		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.338684015366836 | validation: 0.35666151242106864]
	TIME [epoch: 6.41 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.380344219899473		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.380344219899473 | validation: 0.49713365500822276]
	TIME [epoch: 6.41 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3628221666994123		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.3628221666994123 | validation: 0.463146257095418]
	TIME [epoch: 6.42 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4599767760214746		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.4599767760214746 | validation: 0.523862550240876]
	TIME [epoch: 6.43 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38510857996868797		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.38510857996868797 | validation: 0.39885018240722714]
	TIME [epoch: 6.41 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27357999820232604		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.27357999820232604 | validation: 0.9211637713641965]
	TIME [epoch: 6.41 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6125004817095321		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.6125004817095321 | validation: 0.3491580814680373]
	TIME [epoch: 6.4 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28879414508393325		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.28879414508393325 | validation: 0.5858857233584814]
	TIME [epoch: 6.42 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.408965888220526		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.408965888220526 | validation: 0.34378457135090995]
	TIME [epoch: 6.41 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3271810750898009		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.3271810750898009 | validation: 0.7461238559084713]
	TIME [epoch: 6.45 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44198108608047865		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.44198108608047865 | validation: 0.5759559260527782]
	TIME [epoch: 6.43 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3541541981743399		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.3541541981743399 | validation: 0.47234268092483306]
	TIME [epoch: 6.42 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35875184645723324		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.35875184645723324 | validation: 0.7337754231886316]
	TIME [epoch: 6.42 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43740703415363225		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.43740703415363225 | validation: 0.5949164366629145]
	TIME [epoch: 6.41 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39300361466754163		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.39300361466754163 | validation: 0.35828685499899027]
	TIME [epoch: 6.42 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29180983760766477		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.29180983760766477 | validation: 0.5922232991952479]
	TIME [epoch: 6.42 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3673041370490709		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.3673041370490709 | validation: 0.7843335050866983]
	TIME [epoch: 6.45 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3675250942142551		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.3675250942142551 | validation: 0.35163385725990937]
	TIME [epoch: 6.42 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33148404513334606		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.33148404513334606 | validation: 0.31070189319365304]
	TIME [epoch: 6.42 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30917531405661003		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.30917531405661003 | validation: 0.3996746412051624]
	TIME [epoch: 6.42 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39399310610083144		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.39399310610083144 | validation: 0.5534029289528424]
	TIME [epoch: 6.41 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35122207638379044		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.35122207638379044 | validation: 0.40588258506691277]
	TIME [epoch: 6.41 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41919694402453644		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.41919694402453644 | validation: 0.41513798043239525]
	TIME [epoch: 6.43 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41648348598957524		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.41648348598957524 | validation: 0.7157912340699872]
	TIME [epoch: 6.43 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4426421409623255		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.4426421409623255 | validation: 0.5332703156260088]
	TIME [epoch: 6.41 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33149348826689096		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.33149348826689096 | validation: 0.372446720656949]
	TIME [epoch: 6.41 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31830923532039523		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.31830923532039523 | validation: 0.4298076000000582]
	TIME [epoch: 6.41 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8042209969916408		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.8042209969916408 | validation: 0.7580446590956266]
	TIME [epoch: 6.4 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4723306608851876		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.4723306608851876 | validation: 0.5649909388207235]
	TIME [epoch: 6.41 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3718055976830977		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.3718055976830977 | validation: 0.6161536880267002]
	TIME [epoch: 6.43 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39988717740779794		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.39988717740779794 | validation: 0.9638475508881501]
	TIME [epoch: 6.42 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5518933195187891		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.5518933195187891 | validation: 0.6652982785673593]
	TIME [epoch: 6.41 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4198027578761493		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.4198027578761493 | validation: 0.42989847729479846]
	TIME [epoch: 6.4 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3512917627003764		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.3512917627003764 | validation: 0.39786434783442576]
	TIME [epoch: 6.41 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34664751759780665		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.34664751759780665 | validation: 0.7419648778163047]
	TIME [epoch: 6.41 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36896565845792145		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.36896565845792145 | validation: 0.47563173217158716]
	TIME [epoch: 6.41 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3523411949291364		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.3523411949291364 | validation: 0.4775723436519973]
	TIME [epoch: 6.44 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43041837983706016		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.43041837983706016 | validation: 0.5815154459753785]
	TIME [epoch: 6.42 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4021650267233938		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.4021650267233938 | validation: 0.8032944208782198]
	TIME [epoch: 6.41 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5737772833721002		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.5737772833721002 | validation: 0.5791605584446273]
	TIME [epoch: 6.41 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4148309388393725		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.4148309388393725 | validation: 0.3507094064961548]
	TIME [epoch: 6.4 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43000839498773213		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.43000839498773213 | validation: 0.31310785562837556]
	TIME [epoch: 6.41 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3258461557979893		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.3258461557979893 | validation: 0.21129297382210357]
	TIME [epoch: 6.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_384.pth
	Model improved!!!
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3182515748546199		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.3182515748546199 | validation: 0.3530776539222636]
	TIME [epoch: 6.43 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22675823527929712		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.22675823527929712 | validation: 0.7412155660029379]
	TIME [epoch: 6.41 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3765530236327582		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.3765530236327582 | validation: 0.2716617087011683]
	TIME [epoch: 6.41 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33342187136957646		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.33342187136957646 | validation: 0.39972351543601803]
	TIME [epoch: 6.41 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2648548994901418		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.2648548994901418 | validation: 0.2920861864722155]
	TIME [epoch: 6.41 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2925341319584264		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.2925341319584264 | validation: 0.3434366225804143]
	TIME [epoch: 6.4 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29880223870324796		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.29880223870324796 | validation: 0.5183009085663243]
	TIME [epoch: 6.44 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32510361105658686		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.32510361105658686 | validation: 0.3481726603065417]
	TIME [epoch: 6.43 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26461595388859604		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.26461595388859604 | validation: 0.42450306817335093]
	TIME [epoch: 6.42 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3509468940231129		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.3509468940231129 | validation: 0.48191777408697234]
	TIME [epoch: 6.43 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39310985130045184		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.39310985130045184 | validation: 0.23134058209059724]
	TIME [epoch: 6.42 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3070056677580972		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.3070056677580972 | validation: 0.3992641336931063]
	TIME [epoch: 6.43 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36670711592687744		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.36670711592687744 | validation: 0.3487845294690194]
	TIME [epoch: 6.43 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4279849715578926		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.4279849715578926 | validation: 0.3751142220744605]
	TIME [epoch: 6.46 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24142288020106417		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.24142288020106417 | validation: 0.31933628089389954]
	TIME [epoch: 6.44 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2721236393612963		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.2721236393612963 | validation: 0.37482735507688963]
	TIME [epoch: 6.43 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4286783132047288		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.4286783132047288 | validation: 0.2894204194185472]
	TIME [epoch: 6.42 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3321784471845179		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.3321784471845179 | validation: 0.5136811493749691]
	TIME [epoch: 6.42 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2665533703253631		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.2665533703253631 | validation: 0.27131069018773757]
	TIME [epoch: 6.43 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26415615490901195		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.26415615490901195 | validation: 0.4202044534925237]
	TIME [epoch: 6.44 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2645078864681487		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.2645078864681487 | validation: 0.2746777120928731]
	TIME [epoch: 6.45 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2319524534123682		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.2319524534123682 | validation: 0.34567726701056345]
	TIME [epoch: 6.43 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2407240955373373		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.2407240955373373 | validation: 0.20919023421277963]
	TIME [epoch: 6.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_407.pth
	Model improved!!!
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2318894817288994		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.2318894817288994 | validation: 0.5064108892598023]
	TIME [epoch: 6.43 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0138053133800622		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 1.0138053133800622 | validation: 0.24787654320872093]
	TIME [epoch: 6.42 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40693355224415795		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.40693355224415795 | validation: 0.7523200656302714]
	TIME [epoch: 6.41 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5093144989610726		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.5093144989610726 | validation: 0.3184678570726226]
	TIME [epoch: 6.46 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4557235439957493		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.4557235439957493 | validation: 0.4374010186198209]
	TIME [epoch: 6.43 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34614277040850766		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.34614277040850766 | validation: 0.20405956063565278]
	TIME [epoch: 6.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_413.pth
	Model improved!!!
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2347974935272247		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.2347974935272247 | validation: 0.3595859092512499]
	TIME [epoch: 6.41 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2386801841917559		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.2386801841917559 | validation: 0.2346548735238436]
	TIME [epoch: 6.42 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27345806142866563		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.27345806142866563 | validation: 0.4458693426790446]
	TIME [epoch: 6.43 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32362145988565844		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.32362145988565844 | validation: 0.2780142571977233]
	TIME [epoch: 6.42 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2763271812556508		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.2763271812556508 | validation: 0.3797252519811709]
	TIME [epoch: 6.45 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32235870499758784		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.32235870499758784 | validation: 0.306661601536206]
	TIME [epoch: 6.42 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25377097117603825		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.25377097117603825 | validation: 0.29453895494036353]
	TIME [epoch: 6.42 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2620356701521726		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.2620356701521726 | validation: 0.5228439522903244]
	TIME [epoch: 6.42 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2641181706987087		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.2641181706987087 | validation: 0.18135254079073065]
	TIME [epoch: 6.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_422.pth
	Model improved!!!
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2491862162430878		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.2491862162430878 | validation: 0.42293932860235517]
	TIME [epoch: 6.4 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22993732764357983		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.22993732764357983 | validation: 0.25225239352248624]
	TIME [epoch: 6.44 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27062749642631234		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.27062749642631234 | validation: 0.20557726445995117]
	TIME [epoch: 6.43 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.332346683005788		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.332346683005788 | validation: 0.4104904735896088]
	TIME [epoch: 6.4 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26327081514501754		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.26327081514501754 | validation: 0.43742903479417294]
	TIME [epoch: 6.42 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21923291832289823		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.21923291832289823 | validation: 0.29844419909101194]
	TIME [epoch: 6.4 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18071022459554686		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.18071022459554686 | validation: 0.28252594822681404]
	TIME [epoch: 6.43 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3088592399820231		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.3088592399820231 | validation: 0.4333786593893721]
	TIME [epoch: 6.42 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41708890132282894		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.41708890132282894 | validation: 0.43811308984612085]
	TIME [epoch: 6.46 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3200558104800019		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.3200558104800019 | validation: 0.4598459018890636]
	TIME [epoch: 6.41 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28220686389715266		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.28220686389715266 | validation: 0.24140014502827775]
	TIME [epoch: 6.42 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32050642607637947		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.32050642607637947 | validation: 0.4862080632861235]
	TIME [epoch: 6.41 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31291432605086755		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.31291432605086755 | validation: 0.286335780345752]
	TIME [epoch: 6.43 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26845147267631436		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.26845147267631436 | validation: 0.3137131677325954]
	TIME [epoch: 6.43 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23221143346342793		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.23221143346342793 | validation: 0.37764898159496285]
	TIME [epoch: 6.44 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2458544068481504		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.2458544068481504 | validation: 0.2324693717229152]
	TIME [epoch: 6.45 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25540331975333397		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.25540331975333397 | validation: 0.642928196079142]
	TIME [epoch: 6.43 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34152632152215723		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.34152632152215723 | validation: 0.22262272341370673]
	TIME [epoch: 6.41 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24144186513842053		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.24144186513842053 | validation: 0.20799820327635046]
	TIME [epoch: 6.43 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20447443099820292		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.20447443099820292 | validation: 0.33128806080558937]
	TIME [epoch: 6.41 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23700000401695204		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.23700000401695204 | validation: 0.2586734525871619]
	TIME [epoch: 6.42 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20723090019138185		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.20723090019138185 | validation: 0.3454696989202995]
	TIME [epoch: 6.45 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21337808929380475		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.21337808929380475 | validation: 0.3933195536229039]
	TIME [epoch: 6.42 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2310237421053578		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.2310237421053578 | validation: 0.3163513402504152]
	TIME [epoch: 6.4 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23197776602816522		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.23197776602816522 | validation: 0.2560655196764917]
	TIME [epoch: 6.41 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2363346615360965		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.2363346615360965 | validation: 0.2820361703882455]
	TIME [epoch: 6.41 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19353032001131518		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.19353032001131518 | validation: 0.32412230602842157]
	TIME [epoch: 6.41 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2097776928345052		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.2097776928345052 | validation: 0.3457003639993619]
	TIME [epoch: 6.42 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2816686745829323		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.2816686745829323 | validation: 0.41334763340837555]
	TIME [epoch: 6.44 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2709743434365477		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.2709743434365477 | validation: 0.3462906239158906]
	TIME [epoch: 6.42 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2535999563420371		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.2535999563420371 | validation: 0.22731110342470773]
	TIME [epoch: 6.41 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19278976316364943		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.19278976316364943 | validation: 0.4030905507384367]
	TIME [epoch: 6.41 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3697072004429619		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.3697072004429619 | validation: 0.25979932607186196]
	TIME [epoch: 6.4 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2591674941477324		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.2591674941477324 | validation: 0.3447385699138597]
	TIME [epoch: 6.41 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2623480269696758		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.2623480269696758 | validation: 0.3538118956358966]
	TIME [epoch: 6.42 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24263799550053183		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.24263799550053183 | validation: 0.45762844605012293]
	TIME [epoch: 6.45 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39728970939133684		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.39728970939133684 | validation: 0.3482927855798927]
	TIME [epoch: 6.4 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24346758750056724		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.24346758750056724 | validation: 0.4515877536984668]
	TIME [epoch: 6.4 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20401008917199454		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.20401008917199454 | validation: 0.3051114193707942]
	TIME [epoch: 6.41 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24665572770596		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.24665572770596 | validation: 0.2737114831813766]
	TIME [epoch: 6.4 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49173310879074295		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.49173310879074295 | validation: 0.39401902892834706]
	TIME [epoch: 6.39 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35299460335024946		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.35299460335024946 | validation: 0.32350435044777853]
	TIME [epoch: 6.42 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26543166053300127		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.26543166053300127 | validation: 0.4976149565213687]
	TIME [epoch: 6.41 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21905608780462588		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.21905608780462588 | validation: 0.34899020920602775]
	TIME [epoch: 6.41 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1740946953058986		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.1740946953058986 | validation: 0.36054622969287264]
	TIME [epoch: 6.41 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22615806923397075		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.22615806923397075 | validation: 0.24364151822297614]
	TIME [epoch: 6.4 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18136580744122915		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.18136580744122915 | validation: 0.32317308750983287]
	TIME [epoch: 6.4 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22011425373494908		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.22011425373494908 | validation: 0.3348704437286309]
	TIME [epoch: 6.41 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20717372868178013		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.20717372868178013 | validation: 0.46238941570936193]
	TIME [epoch: 6.44 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2455288715520878		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.2455288715520878 | validation: 0.29427109052319267]
	TIME [epoch: 6.41 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20254275600238247		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.20254275600238247 | validation: 0.8900189633139027]
	TIME [epoch: 6.41 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.51093842128658		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.51093842128658 | validation: 0.31945404852974363]
	TIME [epoch: 6.41 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25910920513567504		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.25910920513567504 | validation: 0.2877102259861891]
	TIME [epoch: 6.4 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1518254923542379		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.1518254923542379 | validation: 0.3516387495579668]
	TIME [epoch: 6.42 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19350951568488475		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.19350951568488475 | validation: 0.44655536323538464]
	TIME [epoch: 6.42 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2610551344907772		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.2610551344907772 | validation: 0.4155365136353825]
	TIME [epoch: 6.44 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18937329400380964		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.18937329400380964 | validation: 0.4461948899947777]
	TIME [epoch: 6.41 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2605698805956669		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.2605698805956669 | validation: 0.37223761558010354]
	TIME [epoch: 6.4 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17450685604370503		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.17450685604370503 | validation: 0.26368665236476135]
	TIME [epoch: 6.42 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19655358869518386		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.19655358869518386 | validation: 0.21764406705528408]
	TIME [epoch: 6.41 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28410018520384434		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.28410018520384434 | validation: 0.3477179139474877]
	TIME [epoch: 6.41 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25302296191492957		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.25302296191492957 | validation: 0.28819209209782576]
	TIME [epoch: 6.45 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17762612653198664		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.17762612653198664 | validation: 0.18328476694543086]
	TIME [epoch: 6.41 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28652635664674997		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.28652635664674997 | validation: 0.3709588438176145]
	TIME [epoch: 6.4 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2755542890739021		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.2755542890739021 | validation: 0.2800377675021576]
	TIME [epoch: 6.4 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23941918660910444		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.23941918660910444 | validation: 0.28465160834985953]
	TIME [epoch: 6.42 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21622420180018442		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.21622420180018442 | validation: 0.20188152021590391]
	TIME [epoch: 6.43 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2966453589253766		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.2966453589253766 | validation: 0.27943812638762483]
	TIME [epoch: 6.41 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.290044135468825		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.290044135468825 | validation: 0.2797171317354706]
	TIME [epoch: 6.44 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21075966240028873		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.21075966240028873 | validation: 0.19295564593971537]
	TIME [epoch: 6.41 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18757566799884134		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.18757566799884134 | validation: 0.2008674044374139]
	TIME [epoch: 6.4 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17858794159817476		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.17858794159817476 | validation: 0.3044639893157445]
	TIME [epoch: 6.41 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.259346771526413		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.259346771526413 | validation: 0.20450432385490425]
	TIME [epoch: 6.4 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20192892821473676		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.20192892821473676 | validation: 0.23879604998989223]
	TIME [epoch: 6.41 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18773605989935935		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.18773605989935935 | validation: 0.22667115956221714]
	TIME [epoch: 6.43 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18451307054025481		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.18451307054025481 | validation: 0.23491095133527093]
	TIME [epoch: 6.43 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22851662263429232		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.22851662263429232 | validation: 0.23109981803455207]
	TIME [epoch: 6.42 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19643577916392901		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.19643577916392901 | validation: 0.1816897421202402]
	TIME [epoch: 6.42 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16233170179751688		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.16233170179751688 | validation: 0.25747983832525306]
	TIME [epoch: 6.41 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20295249668964843		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.20295249668964843 | validation: 0.4039125550511116]
	TIME [epoch: 6.41 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29028774492521453		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.29028774492521453 | validation: 0.23804468580100094]
	TIME [epoch: 6.42 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19509688421727234		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.19509688421727234 | validation: 0.2749186924361473]
	TIME [epoch: 6.45 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23479001984033007		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.23479001984033007 | validation: 0.19324062253658197]
	TIME [epoch: 6.42 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1848517595371455		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.1848517595371455 | validation: 0.2587166538844432]
	TIME [epoch: 6.42 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18792689725414127		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.18792689725414127 | validation: 0.4586739468022394]
	TIME [epoch: 6.41 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.209938761106712		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.209938761106712 | validation: 0.3383027003224376]
	TIME [epoch: 6.43 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21419883893340644		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.21419883893340644 | validation: 0.2982618858172283]
	TIME [epoch: 6.42 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.273195863032444		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.273195863032444 | validation: 0.35601910658828334]
	TIME [epoch: 6.43 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24797627907918332		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.24797627907918332 | validation: 0.9788795933129276]
	TIME [epoch: 6.46 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4380149880280705		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.4380149880280705 | validation: 0.27893487300580033]
	TIME [epoch: 6.4 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19735365980640213		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.19735365980640213 | validation: 0.2811083561616402]
	TIME [epoch: 6.42 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20432558694906341		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.20432558694906341 | validation: 0.4028232446852703]
	TIME [epoch: 6.41 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27299809594755037		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.27299809594755037 | validation: 0.3026886734094581]
	TIME [epoch: 6.4 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1699898676020728		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.1699898676020728 | validation: 0.25094790464374134]
	TIME [epoch: 6.41 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19843747974549758		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.19843747974549758 | validation: 0.48463998393175983]
	TIME [epoch: 6.43 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21414023647033853		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.21414023647033853 | validation: 0.23956181982643898]
	TIME [epoch: 6.44 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20373279473589512		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.20373279473589512 | validation: 0.18552139307366347]
	TIME [epoch: 6.41 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18565103765813923		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.18565103765813923 | validation: 0.3014763551104733]
	TIME [epoch: 6.41 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24422840279910984		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.24422840279910984 | validation: 0.3621927300277876]
	TIME [epoch: 6.42 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30832521759564707		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.30832521759564707 | validation: 0.24096888746477926]
	TIME [epoch: 6.42 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1913132958459324		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.1913132958459324 | validation: 0.267487229172751]
	TIME [epoch: 6.43 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22953540119654087		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.22953540119654087 | validation: 0.4655430605851376]
	TIME [epoch: 6.45 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2631768554038247		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.2631768554038247 | validation: 0.1951623893654707]
	TIME [epoch: 6.42 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22452317009842315		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.22452317009842315 | validation: 0.2986960932763256]
	TIME [epoch: 6.41 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3640863798019228		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.3640863798019228 | validation: 0.3796589405033066]
	TIME [epoch: 6.42 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2619736675444182		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.2619736675444182 | validation: 0.23664634819499292]
	TIME [epoch: 6.41 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1626021305682765		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.1626021305682765 | validation: 0.26772472731280483]
	TIME [epoch: 6.42 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2356119794310923		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.2356119794310923 | validation: 0.31545705828659615]
	TIME [epoch: 6.42 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18569452614092108		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.18569452614092108 | validation: 0.3876621056065369]
	TIME [epoch: 6.45 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2816854183982389		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.2816854183982389 | validation: 0.29152414039461]
	TIME [epoch: 6.41 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18520356849885575		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.18520356849885575 | validation: 0.4384883587352267]
	TIME [epoch: 6.42 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22569835913842062		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.22569835913842062 | validation: 0.3515058864972754]
	TIME [epoch: 6.41 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20635924263731975		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.20635924263731975 | validation: 0.31919390987107277]
	TIME [epoch: 6.42 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2168574835333455		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.2168574835333455 | validation: 0.3809315118989317]
	TIME [epoch: 6.42 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1781089019262937		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.1781089019262937 | validation: 0.42055176608305145]
	TIME [epoch: 6.44 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19628374111494207		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.19628374111494207 | validation: 0.4378211320352395]
	TIME [epoch: 6.44 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25274601401529384		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.25274601401529384 | validation: 0.3589867467047714]
	TIME [epoch: 6.43 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2688497019641197		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.2688497019641197 | validation: 0.21797002491225775]
	TIME [epoch: 6.42 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1889873254921864		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.1889873254921864 | validation: 0.2155950665501917]
	TIME [epoch: 6.42 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18676845967280487		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.18676845967280487 | validation: 0.17986890840188424]
	TIME [epoch: 6.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_542.pth
	Model improved!!!
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22116746263321954		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.22116746263321954 | validation: 0.17841803239841675]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_543.pth
	Model improved!!!
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17159693692114958		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.17159693692114958 | validation: 0.2934221086709829]
	TIME [epoch: 6.43 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17104454015120024		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.17104454015120024 | validation: 0.31261354393085605]
	TIME [epoch: 6.4 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19716031093612837		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.19716031093612837 | validation: 0.2969863908525632]
	TIME [epoch: 6.4 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22774389000193537		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.22774389000193537 | validation: 0.21508912653564538]
	TIME [epoch: 6.4 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17057790996134578		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.17057790996134578 | validation: 0.3511610233813991]
	TIME [epoch: 6.4 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17708618590143949		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.17708618590143949 | validation: 0.23785977630827312]
	TIME [epoch: 6.4 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1669632660950014		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.1669632660950014 | validation: 0.28210298741102313]
	TIME [epoch: 6.41 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18516015289103796		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.18516015289103796 | validation: 0.3030467886231666]
	TIME [epoch: 6.42 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17639438245305064		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.17639438245305064 | validation: 0.30694079424699816]
	TIME [epoch: 6.4 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20238600108809435		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.20238600108809435 | validation: 0.33953597087286375]
	TIME [epoch: 6.39 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19632170733648857		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.19632170733648857 | validation: 0.31807239479081717]
	TIME [epoch: 6.4 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20646131304649268		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.20646131304649268 | validation: 0.4497278813917932]
	TIME [epoch: 6.4 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19322212881427803		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.19322212881427803 | validation: 0.19509250645851836]
	TIME [epoch: 6.4 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17293044399591895		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.17293044399591895 | validation: 0.20036281303878387]
	TIME [epoch: 6.43 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18882112838644138		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.18882112838644138 | validation: 0.2395228059457117]
	TIME [epoch: 6.41 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23802608606004272		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.23802608606004272 | validation: 0.32603233306225754]
	TIME [epoch: 6.4 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15710593248763		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.15710593248763 | validation: 0.2693193733949353]
	TIME [epoch: 6.4 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15646691082562952		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.15646691082562952 | validation: 0.25817540868837363]
	TIME [epoch: 6.4 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21018425442497496		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.21018425442497496 | validation: 0.2626340644397166]
	TIME [epoch: 6.39 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1507335770321207		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.1507335770321207 | validation: 0.22844686195060548]
	TIME [epoch: 6.4 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15402341112428897		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.15402341112428897 | validation: 0.2590241881668806]
	TIME [epoch: 6.44 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28803592853369636		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.28803592853369636 | validation: 0.37496310356937546]
	TIME [epoch: 6.41 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2176778859767318		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.2176778859767318 | validation: 0.46049019769546945]
	TIME [epoch: 6.41 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25100460187572876		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.25100460187572876 | validation: 0.4345969458973667]
	TIME [epoch: 6.4 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2037634836468049		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.2037634836468049 | validation: 0.2526440085040184]
	TIME [epoch: 6.41 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18697446004286786		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.18697446004286786 | validation: 0.1631741662512979]
	TIME [epoch: 6.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_569.pth
	Model improved!!!
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1410037344931904		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.1410037344931904 | validation: 0.23806908629298093]
	TIME [epoch: 6.41 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18107898996915311		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.18107898996915311 | validation: 0.3083396232769576]
	TIME [epoch: 6.41 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23671973583179362		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.23671973583179362 | validation: 0.1578593724288503]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_572.pth
	Model improved!!!
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18884006731824812		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.18884006731824812 | validation: 0.1926579083942803]
	TIME [epoch: 6.4 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16577309822287634		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.16577309822287634 | validation: 0.21742556533822238]
	TIME [epoch: 6.4 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16691830453702808		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.16691830453702808 | validation: 0.2004036217558052]
	TIME [epoch: 6.39 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15382858774095265		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.15382858774095265 | validation: 0.18716729315371688]
	TIME [epoch: 6.39 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16285903071806868		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.16285903071806868 | validation: 0.15186178816484164]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_577.pth
	Model improved!!!
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17285662981207428		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.17285662981207428 | validation: 0.2846536128847338]
	TIME [epoch: 6.39 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24211214572112577		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.24211214572112577 | validation: 0.23935767946339134]
	TIME [epoch: 6.4 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.233962204407624		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.233962204407624 | validation: 0.38949419964157683]
	TIME [epoch: 6.41 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2970415101226431		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.2970415101226431 | validation: 0.30151065053384074]
	TIME [epoch: 6.4 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18673421352780956		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.18673421352780956 | validation: 0.19768200407992673]
	TIME [epoch: 6.4 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17602367346502917		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.17602367346502917 | validation: 0.26353060296772257]
	TIME [epoch: 6.41 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18886449624542825		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.18886449624542825 | validation: 0.20354101350232534]
	TIME [epoch: 6.42 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12424798806226749		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.12424798806226749 | validation: 0.3575203208485911]
	TIME [epoch: 6.41 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20504867348985414		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.20504867348985414 | validation: 0.23317531757926233]
	TIME [epoch: 6.4 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1966475347413893		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.1966475347413893 | validation: 0.19318108370274809]
	TIME [epoch: 6.4 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1773987151543313		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.1773987151543313 | validation: 0.3530654306844689]
	TIME [epoch: 6.41 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22453779738702212		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.22453779738702212 | validation: 0.23483179140908775]
	TIME [epoch: 6.4 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1521057954422054		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.1521057954422054 | validation: 0.28502484367602243]
	TIME [epoch: 6.43 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17604748393573133		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.17604748393573133 | validation: 0.18126573967670953]
	TIME [epoch: 6.42 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16899987866738073		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.16899987866738073 | validation: 0.16765602089459003]
	TIME [epoch: 6.41 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17620391580041822		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.17620391580041822 | validation: 0.2920590455612187]
	TIME [epoch: 6.4 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1618165172039363		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.1618165172039363 | validation: 0.4116809008793011]
	TIME [epoch: 6.41 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24881489894974093		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.24881489894974093 | validation: 0.2712881969075189]
	TIME [epoch: 6.4 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13467188451654266		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.13467188451654266 | validation: 0.5428858164078296]
	TIME [epoch: 6.41 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23096572771982607		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.23096572771982607 | validation: 0.26992423005565963]
	TIME [epoch: 6.44 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17485978787720674		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.17485978787720674 | validation: 0.3646390067861859]
	TIME [epoch: 6.41 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18573068454954464		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.18573068454954464 | validation: 0.3388542069820619]
	TIME [epoch: 6.41 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2051841131858745		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.2051841131858745 | validation: 0.34792763196451887]
	TIME [epoch: 6.4 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2179185071019778		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.2179185071019778 | validation: 0.32383800711055133]
	TIME [epoch: 6.4 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2139718681403556		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.2139718681403556 | validation: 0.41411845679548764]
	TIME [epoch: 6.41 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1984483333849132		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.1984483333849132 | validation: 0.4725367659673043]
	TIME [epoch: 6.42 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2574166160771209		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.2574166160771209 | validation: 0.3965544032982557]
	TIME [epoch: 6.43 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2397125210450416		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.2397125210450416 | validation: 0.32846475096155514]
	TIME [epoch: 6.41 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16297435822567133		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.16297435822567133 | validation: 0.3122311165099155]
	TIME [epoch: 6.42 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2601884657792264		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.2601884657792264 | validation: 0.2738844651393748]
	TIME [epoch: 6.41 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19151367591454108		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.19151367591454108 | validation: 0.43339375478652237]
	TIME [epoch: 6.41 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19730185012011286		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.19730185012011286 | validation: 0.23586272359785831]
	TIME [epoch: 6.41 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24713246212360052		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.24713246212360052 | validation: 0.30327873575324743]
	TIME [epoch: 6.43 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2101656184620781		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.2101656184620781 | validation: 0.25752240230322093]
	TIME [epoch: 6.41 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1819615627977137		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.1819615627977137 | validation: 0.22292546635949964]
	TIME [epoch: 6.41 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16194152543937854		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.16194152543937854 | validation: 0.2673305658683393]
	TIME [epoch: 6.41 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2058352540073376		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.2058352540073376 | validation: 0.2188934340531714]
	TIME [epoch: 6.41 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1987622526095858		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.1987622526095858 | validation: 0.20526314407305196]
	TIME [epoch: 6.41 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22443447533123384		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.22443447533123384 | validation: 0.15079529297679148]
	TIME [epoch: 6.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_616.pth
	Model improved!!!
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16471467868523199		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.16471467868523199 | validation: 0.18239156327920034]
	TIME [epoch: 6.45 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13918696276790796		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.13918696276790796 | validation: 0.24250119782963311]
	TIME [epoch: 6.43 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12259079036000872		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.12259079036000872 | validation: 0.22268473688870502]
	TIME [epoch: 6.41 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15631634218596072		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.15631634218596072 | validation: 0.2099121200141322]
	TIME [epoch: 6.43 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15527828066805238		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.15527828066805238 | validation: 0.21149728633845302]
	TIME [epoch: 6.43 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1453957747128037		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.1453957747128037 | validation: 0.20202470835724584]
	TIME [epoch: 6.43 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14974452365318663		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.14974452365318663 | validation: 0.408770145751766]
	TIME [epoch: 6.43 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18690274477972235		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.18690274477972235 | validation: 0.26786964013148334]
	TIME [epoch: 6.45 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19647228537310216		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.19647228537310216 | validation: 0.21100428861349685]
	TIME [epoch: 6.43 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15104894517655965		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.15104894517655965 | validation: 0.24716115298332042]
	TIME [epoch: 6.43 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1592754880617797		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.1592754880617797 | validation: 0.2200509591085195]
	TIME [epoch: 6.43 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13268377973324552		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.13268377973324552 | validation: 0.272287181075832]
	TIME [epoch: 6.43 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16478704923853926		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.16478704923853926 | validation: 0.192271002460307]
	TIME [epoch: 6.43 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15263026255929574		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.15263026255929574 | validation: 0.17567549422295578]
	TIME [epoch: 6.47 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12625661730742962		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.12625661730742962 | validation: 0.21091250792214644]
	TIME [epoch: 6.44 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14570091040322647		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.14570091040322647 | validation: 0.23836827663694032]
	TIME [epoch: 6.43 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1687653967097711		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.1687653967097711 | validation: 0.24731596433669117]
	TIME [epoch: 6.42 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1354173724431228		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.1354173724431228 | validation: 0.6262695580541054]
	TIME [epoch: 6.42 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41171478391013094		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.41171478391013094 | validation: 0.15299367910461775]
	TIME [epoch: 6.41 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16649232241181017		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.16649232241181017 | validation: 0.21129996823828773]
	TIME [epoch: 6.42 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11697990106701815		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.11697990106701815 | validation: 0.18124650106504078]
	TIME [epoch: 6.46 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13638300508773993		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.13638300508773993 | validation: 0.27106949347580656]
	TIME [epoch: 6.43 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1489463161486281		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.1489463161486281 | validation: 0.202252956314872]
	TIME [epoch: 6.43 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.153423321560221		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.153423321560221 | validation: 0.24634210254811806]
	TIME [epoch: 6.43 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16743939132362967		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.16743939132362967 | validation: 0.20309070158242093]
	TIME [epoch: 6.42 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17364345634929151		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.17364345634929151 | validation: 0.18324128656385735]
	TIME [epoch: 6.42 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1425124972283367		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.1425124972283367 | validation: 0.3718520448369131]
	TIME [epoch: 6.44 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13182753652049034		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.13182753652049034 | validation: 0.2898800987413518]
	TIME [epoch: 6.44 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1286477459834641		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.1286477459834641 | validation: 0.21390591914223808]
	TIME [epoch: 6.43 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12765776402580045		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.12765776402580045 | validation: 0.2785544476910311]
	TIME [epoch: 6.44 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11997016636382071		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.11997016636382071 | validation: 0.2289933451744408]
	TIME [epoch: 6.44 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1472425612447299		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.1472425612447299 | validation: 0.25084526752030256]
	TIME [epoch: 6.43 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2076876379502432		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.2076876379502432 | validation: 0.17069834599849848]
	TIME [epoch: 6.43 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14684045548410726		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.14684045548410726 | validation: 0.3867295748110483]
	TIME [epoch: 6.47 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1631532140230899		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.1631532140230899 | validation: 0.2904083812267458]
	TIME [epoch: 6.42 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15135496065988974		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.15135496065988974 | validation: 0.2535974366922549]
	TIME [epoch: 6.42 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15203172944023016		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.15203172944023016 | validation: 0.2658026662933245]
	TIME [epoch: 6.44 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1363368265291719		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.1363368265291719 | validation: 0.2391107381313907]
	TIME [epoch: 6.42 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13453163325385542		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.13453163325385542 | validation: 0.21026860925432866]
	TIME [epoch: 6.44 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11468843115709472		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.11468843115709472 | validation: 0.1955864906088043]
	TIME [epoch: 6.43 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11341039139651875		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.11341039139651875 | validation: 0.20431690487382242]
	TIME [epoch: 6.47 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14394114878649586		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.14394114878649586 | validation: 0.3358271007638608]
	TIME [epoch: 6.43 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1408176996369131		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.1408176996369131 | validation: 0.42256604792555985]
	TIME [epoch: 6.43 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20006866943014853		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.20006866943014853 | validation: 0.20933009164544736]
	TIME [epoch: 6.42 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17294616389920814		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.17294616389920814 | validation: 0.3831466334608777]
	TIME [epoch: 6.43 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23324007925992268		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.23324007925992268 | validation: 0.39020737285158646]
	TIME [epoch: 6.41 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22639491546762736		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.22639491546762736 | validation: 0.3651161556138075]
	TIME [epoch: 6.46 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26802099681547603		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.26802099681547603 | validation: 0.30088979620971384]
	TIME [epoch: 6.43 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.169545001073341		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.169545001073341 | validation: 0.21889494897165257]
	TIME [epoch: 6.44 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14143443952383783		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.14143443952383783 | validation: 0.39949499132244415]
	TIME [epoch: 6.42 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18871403279584212		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.18871403279584212 | validation: 0.28943871633098783]
	TIME [epoch: 6.43 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15898438292659264		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.15898438292659264 | validation: 0.25732686738984417]
	TIME [epoch: 6.43 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17179134617819966		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.17179134617819966 | validation: 0.37964283343459915]
	TIME [epoch: 6.43 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21142530143145066		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.21142530143145066 | validation: 0.35804782291893683]
	TIME [epoch: 6.46 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1471257924689274		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.1471257924689274 | validation: 0.27927193340569795]
	TIME [epoch: 6.45 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1780776665250463		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.1780776665250463 | validation: 0.22075756391115042]
	TIME [epoch: 6.42 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20470744779806138		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.20470744779806138 | validation: 0.2690419137641397]
	TIME [epoch: 6.44 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1372968506804766		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.1372968506804766 | validation: 0.20245675665995586]
	TIME [epoch: 6.42 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11476685132143236		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.11476685132143236 | validation: 0.17273535531259143]
	TIME [epoch: 6.44 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16686418621053078		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.16686418621053078 | validation: 0.31029772075604617]
	TIME [epoch: 6.43 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18162109344450844		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.18162109344450844 | validation: 0.26748426507482653]
	TIME [epoch: 6.45 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13451847752080423		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.13451847752080423 | validation: 0.24700943943760806]
	TIME [epoch: 6.43 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16154446117258855		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.16154446117258855 | validation: 0.19253884392057585]
	TIME [epoch: 6.43 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11952890166466852		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.11952890166466852 | validation: 0.30448451118689995]
	TIME [epoch: 6.43 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16604562017282765		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.16604562017282765 | validation: 0.3792208313460861]
	TIME [epoch: 6.43 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1417564255115068		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.1417564255115068 | validation: 0.24535056087241203]
	TIME [epoch: 6.42 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14380244302838063		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.14380244302838063 | validation: 0.1991578181102146]
	TIME [epoch: 6.46 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11518390720612585		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.11518390720612585 | validation: 0.27478822487231586]
	TIME [epoch: 6.43 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15750509742786226		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.15750509742786226 | validation: 0.3253880877974582]
	TIME [epoch: 6.43 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14355876086660063		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.14355876086660063 | validation: 0.2129901828118187]
	TIME [epoch: 6.42 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1735466924166792		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.1735466924166792 | validation: 0.2084189208904028]
	TIME [epoch: 6.43 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16702654830346478		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.16702654830346478 | validation: 0.22588635528505985]
	TIME [epoch: 6.42 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1446757499571183		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.1446757499571183 | validation: 0.25496426462162014]
	TIME [epoch: 6.43 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12060270107571884		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.12060270107571884 | validation: 0.18943409981824402]
	TIME [epoch: 6.45 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12031826196394471		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.12031826196394471 | validation: 0.2728443364009169]
	TIME [epoch: 6.43 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12009596061666605		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.12009596061666605 | validation: 0.32655469146976396]
	TIME [epoch: 6.42 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17188777404677846		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.17188777404677846 | validation: 0.22478430266801985]
	TIME [epoch: 6.43 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11489964571214228		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.11489964571214228 | validation: 0.2126620739863352]
	TIME [epoch: 6.43 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12836174352151034		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.12836174352151034 | validation: 0.27559866161093705]
	TIME [epoch: 6.43 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18232248868137346		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.18232248868137346 | validation: 0.3898485369512365]
	TIME [epoch: 6.43 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16660274485203022		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.16660274485203022 | validation: 0.2927138776694493]
	TIME [epoch: 6.46 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.192163168297231		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.192163168297231 | validation: 0.3369108726275573]
	TIME [epoch: 6.42 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16593662527467834		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.16593662527467834 | validation: 0.30268743116363245]
	TIME [epoch: 6.44 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13415480563522791		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.13415480563522791 | validation: 0.225344460547759]
	TIME [epoch: 6.42 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14849948482432396		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.14849948482432396 | validation: 0.27239824928975453]
	TIME [epoch: 6.43 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1536435974234991		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.1536435974234991 | validation: 0.2598750370461976]
	TIME [epoch: 6.41 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1631328514843274		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.1631328514843274 | validation: 0.22746991618241624]
	TIME [epoch: 6.45 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14096960517560023		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.14096960517560023 | validation: 0.2987467800414058]
	TIME [epoch: 6.42 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1497948357879224		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.1497948357879224 | validation: 0.24025766043958965]
	TIME [epoch: 6.43 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14151593717894506		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.14151593717894506 | validation: 0.28821276215732233]
	TIME [epoch: 6.41 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1281132224893938		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.1281132224893938 | validation: 0.26627455957991336]
	TIME [epoch: 6.43 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11961316599381878		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.11961316599381878 | validation: 0.2068729758979434]
	TIME [epoch: 6.41 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11499765041241947		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.11499765041241947 | validation: 0.2442791222035546]
	TIME [epoch: 6.42 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11351239259769834		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.11351239259769834 | validation: 0.22139612716488047]
	TIME [epoch: 6.45 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12732698231988457		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.12732698231988457 | validation: 0.2628884635988029]
	TIME [epoch: 6.44 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13069932122116332		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.13069932122116332 | validation: 0.26393327168570574]
	TIME [epoch: 6.42 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13895426418536339		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.13895426418536339 | validation: 0.23274030815336116]
	TIME [epoch: 6.43 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13446986602566646		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.13446986602566646 | validation: 0.21863278709172712]
	TIME [epoch: 6.41 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14055624474039416		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.14055624474039416 | validation: 0.21132040037916344]
	TIME [epoch: 6.44 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.126745381513244		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.126745381513244 | validation: 0.22074321063187674]
	TIME [epoch: 6.43 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18028006404303604		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.18028006404303604 | validation: 0.6703533670234307]
	TIME [epoch: 6.46 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3841994962875523		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.3841994962875523 | validation: 0.38112980374976524]
	TIME [epoch: 6.42 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22965526192661026		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.22965526192661026 | validation: 0.4139598813514624]
	TIME [epoch: 6.43 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22054724526243802		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.22054724526243802 | validation: 0.2908974894780301]
	TIME [epoch: 6.41 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20960075530627792		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.20960075530627792 | validation: 0.30470709277867986]
	TIME [epoch: 6.43 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2009507311146677		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.2009507311146677 | validation: 0.34173018779775843]
	TIME [epoch: 6.41 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2107552392903265		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.2107552392903265 | validation: 0.32018315082687465]
	TIME [epoch: 6.46 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1679396164120851		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.1679396164120851 | validation: 0.2816987093932499]
	TIME [epoch: 6.43 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13916385701247616		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.13916385701247616 | validation: 0.29360169999013636]
	TIME [epoch: 6.44 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20924866741810158		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.20924866741810158 | validation: 0.27845392857047296]
	TIME [epoch: 6.42 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17837979705209228		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.17837979705209228 | validation: 0.2114491725187637]
	TIME [epoch: 6.43 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16076813952407526		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.16076813952407526 | validation: 0.21334749539909922]
	TIME [epoch: 6.42 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12121505426321477		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.12121505426321477 | validation: 0.18589396494132232]
	TIME [epoch: 6.44 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.114053359041075		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.114053359041075 | validation: 0.2980114600726793]
	TIME [epoch: 6.46 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15620586019693583		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.15620586019693583 | validation: 0.246195625654307]
	TIME [epoch: 6.43 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16971296944218187		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.16971296944218187 | validation: 0.2429242604933659]
	TIME [epoch: 6.41 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1267347086437021		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.1267347086437021 | validation: 0.1516691370640075]
	TIME [epoch: 6.43 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1208132580807064		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.1208132580807064 | validation: 0.16329114560240965]
	TIME [epoch: 6.42 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14605718805336504		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.14605718805336504 | validation: 0.202675329830647]
	TIME [epoch: 6.43 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16631157496591192		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.16631157496591192 | validation: 0.33097776135116513]
	TIME [epoch: 6.44 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13766356632944382		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.13766356632944382 | validation: 0.22350170781196685]
	TIME [epoch: 6.44 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2180664984261338		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.2180664984261338 | validation: 0.13738361161294557]
	TIME [epoch: 6.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_738.pth
	Model improved!!!
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1111042448415264		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.1111042448415264 | validation: 0.1913488633546388]
	TIME [epoch: 6.42 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13992491832264836		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.13992491832264836 | validation: 0.1992244264785115]
	TIME [epoch: 6.41 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11681708163498561		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.11681708163498561 | validation: 0.23272559853388916]
	TIME [epoch: 6.42 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12151098368432496		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.12151098368432496 | validation: 0.23306912657218776]
	TIME [epoch: 6.39 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10162098244235294		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.10162098244235294 | validation: 0.208408102949791]
	TIME [epoch: 6.43 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1301963755696834		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.1301963755696834 | validation: 0.15669815540863544]
	TIME [epoch: 6.39 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1719533618427664		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.1719533618427664 | validation: 0.3041269159762417]
	TIME [epoch: 6.4 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16061276938869073		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.16061276938869073 | validation: 0.24951464672941182]
	TIME [epoch: 6.39 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12992737826203943		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.12992737826203943 | validation: 0.40845795957453124]
	TIME [epoch: 6.4 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14546232874583132		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.14546232874583132 | validation: 0.20955462037488481]
	TIME [epoch: 6.39 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10939949708585636		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.10939949708585636 | validation: 0.28004570435208964]
	TIME [epoch: 6.41 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17953168835004119		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.17953168835004119 | validation: 0.3766787452659648]
	TIME [epoch: 6.43 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1447993631991596		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.1447993631991596 | validation: 0.300268387123434]
	TIME [epoch: 6.4 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1464277971715085		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.1464277971715085 | validation: 0.30525968419492566]
	TIME [epoch: 6.4 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13237104355367338		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.13237104355367338 | validation: 0.311753878147976]
	TIME [epoch: 6.42 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11993179585846964		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.11993179585846964 | validation: 0.22920397932597245]
	TIME [epoch: 6.42 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13118217499870333		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.13118217499870333 | validation: 0.2354822449652946]
	TIME [epoch: 6.41 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10895670660311739		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.10895670660311739 | validation: 0.30302826023081536]
	TIME [epoch: 6.43 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10476531023590974		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.10476531023590974 | validation: 0.24315505271100205]
	TIME [epoch: 6.4 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.096287877268495		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.096287877268495 | validation: 0.2565942146568459]
	TIME [epoch: 6.4 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14964539978026115		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.14964539978026115 | validation: 0.24703007687000536]
	TIME [epoch: 6.41 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10423481099861848		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.10423481099861848 | validation: 0.2313666158215647]
	TIME [epoch: 6.4 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11367097488482122		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.11367097488482122 | validation: 0.27392469511880657]
	TIME [epoch: 6.42 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13949412038171577		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.13949412038171577 | validation: 0.31034542689102507]
	TIME [epoch: 6.42 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12862660942576393		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.12862660942576393 | validation: 0.26472926440660116]
	TIME [epoch: 6.43 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12318329379260484		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.12318329379260484 | validation: 0.22747033543918563]
	TIME [epoch: 6.4 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09657853296681387		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.09657853296681387 | validation: 0.24796068885145645]
	TIME [epoch: 6.42 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10647918234417152		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.10647918234417152 | validation: 0.21114049971850943]
	TIME [epoch: 6.4 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11117479800992519		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.11117479800992519 | validation: 0.19564778343713157]
	TIME [epoch: 6.43 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10684054708713617		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.10684054708713617 | validation: 0.37552079592247767]
	TIME [epoch: 6.4 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31835089693724		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.31835089693724 | validation: 0.30718163031692025]
	TIME [epoch: 6.43 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1517253946594876		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.1517253946594876 | validation: 0.23760780264934508]
	TIME [epoch: 6.44 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12677700161573802		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.12677700161573802 | validation: 0.20617427046376396]
	TIME [epoch: 6.41 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13172896758516117		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.13172896758516117 | validation: 0.37086597574046337]
	TIME [epoch: 6.41 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1394509454631156		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.1394509454631156 | validation: 0.23447725869670039]
	TIME [epoch: 6.41 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13440097643975768		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.13440097643975768 | validation: 0.32355538047617827]
	TIME [epoch: 6.41 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14153084212781858		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.14153084212781858 | validation: 0.3180473963952848]
	TIME [epoch: 6.41 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13416144038800973		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.13416144038800973 | validation: 0.26399290520668817]
	TIME [epoch: 6.44 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24345176918796635		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.24345176918796635 | validation: 0.5775274534192885]
	TIME [epoch: 6.41 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19406916620914194		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.19406916620914194 | validation: 0.3869430314368761]
	TIME [epoch: 6.4 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21684183055939607		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.21684183055939607 | validation: 0.35891212193086075]
	TIME [epoch: 6.4 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12800326408906743		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.12800326408906743 | validation: 0.2954852839532863]
	TIME [epoch: 6.42 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10992337705632525		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.10992337705632525 | validation: 0.2817037308608587]
	TIME [epoch: 6.42 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11115421973852518		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.11115421973852518 | validation: 0.22621339011663782]
	TIME [epoch: 6.43 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11612106303850508		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.11612106303850508 | validation: 0.1875389604947751]
	TIME [epoch: 6.45 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09561371621417764		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.09561371621417764 | validation: 0.23263142169243245]
	TIME [epoch: 6.41 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11669770067788698		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.11669770067788698 | validation: 0.2082320620154337]
	TIME [epoch: 6.41 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12503072697365114		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.12503072697365114 | validation: 0.1746670520277619]
	TIME [epoch: 6.4 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11989355819858441		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.11989355819858441 | validation: 0.4285517914396387]
	TIME [epoch: 6.4 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.310271165656867		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.310271165656867 | validation: 0.31196965052270903]
	TIME [epoch: 6.39 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1138915104838409		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.1138915104838409 | validation: 0.21927498903239456]
	TIME [epoch: 6.41 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11144752668357438		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.11144752668357438 | validation: 0.2361004575643546]
	TIME [epoch: 6.42 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10543404669343531		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.10543404669343531 | validation: 0.1888533199886944]
	TIME [epoch: 6.39 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09361983695039823		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.09361983695039823 | validation: 0.27135732659154166]
	TIME [epoch: 6.41 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12765717386376638		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.12765717386376638 | validation: 0.21938936753277724]
	TIME [epoch: 6.41 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1414370470907771		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.1414370470907771 | validation: 0.20702896109555863]
	TIME [epoch: 6.4 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09907793186026327		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.09907793186026327 | validation: 0.27922215896487745]
	TIME [epoch: 6.41 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1172151371577148		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.1172151371577148 | validation: 0.3348672453612063]
	TIME [epoch: 6.44 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14363023058747423		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.14363023058747423 | validation: 0.25986356335004906]
	TIME [epoch: 6.42 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10717363644356553		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.10717363644356553 | validation: 0.1949590200288413]
	TIME [epoch: 6.41 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10760854098439143		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.10760854098439143 | validation: 0.2279816654711402]
	TIME [epoch: 6.41 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12989592484564244		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.12989592484564244 | validation: 0.3214360057981193]
	TIME [epoch: 6.4 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21525888847990546		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.21525888847990546 | validation: 0.3211355841818782]
	TIME [epoch: 6.41 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11733883291606165		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.11733883291606165 | validation: 0.21184782399605495]
	TIME [epoch: 6.41 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1052219315793395		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.1052219315793395 | validation: 0.19810951439321678]
	TIME [epoch: 6.44 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08029331581988253		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.08029331581988253 | validation: 0.21447573228658948]
	TIME [epoch: 6.42 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09357588067900158		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.09357588067900158 | validation: 0.24260335592827104]
	TIME [epoch: 6.41 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10920671345890715		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.10920671345890715 | validation: 0.15748796696533]
	TIME [epoch: 6.41 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08324719665182291		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.08324719665182291 | validation: 0.18418023457836108]
	TIME [epoch: 6.4 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1093884647141649		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.1093884647141649 | validation: 0.21309803268394711]
	TIME [epoch: 6.42 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1321137330437025		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.1321137330437025 | validation: 0.3576933829088849]
	TIME [epoch: 6.42 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12769745490877582		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.12769745490877582 | validation: 0.34426496305638876]
	TIME [epoch: 6.45 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1317944847172586		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.1317944847172586 | validation: 0.32173103595344515]
	TIME [epoch: 6.41 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12128322438628011		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.12128322438628011 | validation: 0.23337266871013135]
	TIME [epoch: 6.43 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09887570135815366		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.09887570135815366 | validation: 0.232497002344983]
	TIME [epoch: 6.42 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10943659666626264		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.10943659666626264 | validation: 0.15836890328649467]
	TIME [epoch: 6.42 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09897070567411191		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.09897070567411191 | validation: 0.1744962719190993]
	TIME [epoch: 6.42 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11628663592162738		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.11628663592162738 | validation: 0.21264119288927183]
	TIME [epoch: 6.46 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12873310481486183		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.12873310481486183 | validation: 0.2053391150122746]
	TIME [epoch: 6.42 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12310141942502933		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.12310141942502933 | validation: 0.22237411823651237]
	TIME [epoch: 6.42 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16242457472569333		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.16242457472569333 | validation: 0.33322477950272467]
	TIME [epoch: 6.42 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17951375418662724		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.17951375418662724 | validation: 0.21134166304565477]
	TIME [epoch: 6.43 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13225826080527245		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.13225826080527245 | validation: 0.14991928679105745]
	TIME [epoch: 6.4 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11685098923312248		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.11685098923312248 | validation: 0.2537733422040104]
	TIME [epoch: 6.43 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13279712210466516		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.13279712210466516 | validation: 0.16272307341679118]
	TIME [epoch: 6.45 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12173118639324826		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.12173118639324826 | validation: 0.23122899317977272]
	TIME [epoch: 6.43 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1536281427301311		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.1536281427301311 | validation: 0.16740696391564006]
	TIME [epoch: 6.41 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11460376245778897		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.11460376245778897 | validation: 0.15931078431806492]
	TIME [epoch: 6.43 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13064138407918877		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.13064138407918877 | validation: 0.26577945854456314]
	TIME [epoch: 6.42 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14009526423082297		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.14009526423082297 | validation: 0.16743222730679297]
	TIME [epoch: 6.43 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12877368757921157		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.12877368757921157 | validation: 0.20306100215643214]
	TIME [epoch: 6.43 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10269489210549082		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.10269489210549082 | validation: 0.15898594693754206]
	TIME [epoch: 6.44 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11572364994196216		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.11572364994196216 | validation: 0.1586085425744326]
	TIME [epoch: 6.42 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10175480319105569		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.10175480319105569 | validation: 0.21816298635250977]
	TIME [epoch: 6.41 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11292599986539441		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.11292599986539441 | validation: 0.23564819597237496]
	TIME [epoch: 6.4 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12577175280873273		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.12577175280873273 | validation: 0.2759856896783687]
	TIME [epoch: 6.4 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11673210247732316		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.11673210247732316 | validation: 0.2002709837954556]
	TIME [epoch: 6.4 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1177511888576299		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.1177511888576299 | validation: 0.25147689369204257]
	TIME [epoch: 6.45 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12393945547525045		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.12393945547525045 | validation: 0.19353065989443574]
	TIME [epoch: 6.41 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11041065879966469		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.11041065879966469 | validation: 0.14793418756266982]
	TIME [epoch: 6.41 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10608498123454067		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.10608498123454067 | validation: 0.19191823000634348]
	TIME [epoch: 6.42 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09453847522370554		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.09453847522370554 | validation: 0.2523762214230912]
	TIME [epoch: 6.42 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1349576414312425		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.1349576414312425 | validation: 0.3067434871986049]
	TIME [epoch: 6.42 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15140529024414084		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.15140529024414084 | validation: 0.2777156550407351]
	TIME [epoch: 6.42 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1381601570905807		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.1381601570905807 | validation: 0.20714565290383533]
	TIME [epoch: 6.45 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09877878324514422		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.09877878324514422 | validation: 0.21990712765079995]
	TIME [epoch: 6.42 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10621748768722147		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.10621748768722147 | validation: 0.24188575845483523]
	TIME [epoch: 6.43 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10563372475850627		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.10563372475850627 | validation: 0.2329346623179076]
	TIME [epoch: 6.43 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09225022641688552		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.09225022641688552 | validation: 0.19874209915119484]
	TIME [epoch: 6.43 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09738466981090937		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.09738466981090937 | validation: 0.21180183400747168]
	TIME [epoch: 6.41 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09732141053655893		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.09732141053655893 | validation: 0.2596577708628699]
	TIME [epoch: 6.45 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1406519985852326		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.1406519985852326 | validation: 0.33621046126488696]
	TIME [epoch: 6.42 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10983531194947421		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.10983531194947421 | validation: 0.258755463967186]
	TIME [epoch: 6.42 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12185020757859184		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.12185020757859184 | validation: 0.19110314364053063]
	TIME [epoch: 6.42 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08938488067151587		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.08938488067151587 | validation: 0.2026647984854385]
	TIME [epoch: 6.42 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08528485220816515		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.08528485220816515 | validation: 0.17402154405228687]
	TIME [epoch: 6.42 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1085492654854576		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.1085492654854576 | validation: 0.239114991995528]
	TIME [epoch: 6.42 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11691724548800185		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.11691724548800185 | validation: 0.15662878524917517]
	TIME [epoch: 6.46 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08519381137467896		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.08519381137467896 | validation: 0.24583718221481943]
	TIME [epoch: 6.41 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1041007395317984		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.1041007395317984 | validation: 0.23631058728517054]
	TIME [epoch: 6.41 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.093433943695816		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.093433943695816 | validation: 0.1747948472732237]
	TIME [epoch: 6.42 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11363263090947923		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.11363263090947923 | validation: 0.1676690188223475]
	TIME [epoch: 6.41 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10618584196019662		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.10618584196019662 | validation: 0.24863837581590717]
	TIME [epoch: 6.41 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12625527973759015		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.12625527973759015 | validation: 0.20208136064220802]
	TIME [epoch: 6.42 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09404028431677024		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.09404028431677024 | validation: 0.1997811028949562]
	TIME [epoch: 6.45 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13521522361425034		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.13521522361425034 | validation: 0.18950708863357085]
	TIME [epoch: 6.41 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09801935188003047		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.09801935188003047 | validation: 0.17847275605982377]
	TIME [epoch: 6.41 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0991094477197618		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.0991094477197618 | validation: 0.17314010992870846]
	TIME [epoch: 6.41 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13236515973745785		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.13236515973745785 | validation: 0.16891287352193105]
	TIME [epoch: 6.41 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11539801673065489		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.11539801673065489 | validation: 0.1810037136567951]
	TIME [epoch: 6.4 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09311944362710829		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.09311944362710829 | validation: 0.19722838061849743]
	TIME [epoch: 6.44 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08208843995414133		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.08208843995414133 | validation: 0.17406143269539862]
	TIME [epoch: 6.42 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08252335631833882		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.08252335631833882 | validation: 0.20752279287067743]
	TIME [epoch: 6.43 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09117068984545565		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.09117068984545565 | validation: 0.24907599938555605]
	TIME [epoch: 6.43 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10176147090317378		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.10176147090317378 | validation: 0.18142953601927633]
	TIME [epoch: 6.43 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09733398621925383		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.09733398621925383 | validation: 0.16850435126256133]
	TIME [epoch: 6.43 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0826392640778248		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.0826392640778248 | validation: 0.2076721725552977]
	TIME [epoch: 6.43 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12621157979848402		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.12621157979848402 | validation: 0.2922707901862655]
	TIME [epoch: 6.46 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1157793558453174		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.1157793558453174 | validation: 0.2623509737529352]
	TIME [epoch: 6.43 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12062723029686824		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.12062723029686824 | validation: 0.20859845088360537]
	TIME [epoch: 6.43 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10283960545527104		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.10283960545527104 | validation: 0.2875829195151048]
	TIME [epoch: 6.42 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1079758882515465		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.1079758882515465 | validation: 0.26328960398142953]
	TIME [epoch: 6.43 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10861793536061645		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.10861793536061645 | validation: 0.18897506419276497]
	TIME [epoch: 6.4 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07853508447098		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.07853508447098 | validation: 0.19173118143333753]
	TIME [epoch: 6.43 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11861432817796463		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.11861432817796463 | validation: 0.24884405373410154]
	TIME [epoch: 6.44 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10052568993171618		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.10052568993171618 | validation: 0.23176526956090449]
	TIME [epoch: 6.42 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09509951473379978		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.09509951473379978 | validation: 0.26507893294073315]
	TIME [epoch: 6.42 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11383173109427817		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.11383173109427817 | validation: 0.30644804340996096]
	TIME [epoch: 6.42 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11141005827363366		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.11141005827363366 | validation: 0.282919416450021]
	TIME [epoch: 6.41 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09676083887852308		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.09676083887852308 | validation: 0.21338630156525443]
	TIME [epoch: 6.41 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08349510601088772		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.08349510601088772 | validation: 0.22109171204940115]
	TIME [epoch: 6.44 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09689009604531677		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.09689009604531677 | validation: 0.2829143267741781]
	TIME [epoch: 6.43 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10980280149868879		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.10980280149868879 | validation: 0.23611879438366526]
	TIME [epoch: 6.41 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1099445302806594		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.1099445302806594 | validation: 0.2668236665225422]
	TIME [epoch: 6.42 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10791229933159506		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.10791229933159506 | validation: 0.27448948284447533]
	TIME [epoch: 6.41 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13517272883792775		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.13517272883792775 | validation: 0.17466011271186518]
	TIME [epoch: 6.43 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10846738412082724		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.10846738412082724 | validation: 0.27522707194608115]
	TIME [epoch: 6.43 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11211061614488997		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.11211061614488997 | validation: 0.163858962161615]
	TIME [epoch: 6.45 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10526875749296091		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.10526875749296091 | validation: 0.19984786969361154]
	TIME [epoch: 6.44 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1026147639216423		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.1026147639216423 | validation: 0.21445416471739376]
	TIME [epoch: 6.43 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10113906832890071		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.10113906832890071 | validation: 0.2395897579753673]
	TIME [epoch: 6.43 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09257009056281859		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.09257009056281859 | validation: 0.21298965493081398]
	TIME [epoch: 6.41 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07684743388098493		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.07684743388098493 | validation: 0.18463552418104928]
	TIME [epoch: 6.43 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08119205344226707		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.08119205344226707 | validation: 0.21547451348854071]
	TIME [epoch: 6.44 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08633716391098847		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.08633716391098847 | validation: 0.23103286580855176]
	TIME [epoch: 6.46 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09789680546559933		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.09789680546559933 | validation: 0.22048144997822833]
	TIME [epoch: 6.41 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09736922779653542		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.09736922779653542 | validation: 0.1790221273109591]
	TIME [epoch: 6.43 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09349820738846132		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.09349820738846132 | validation: 0.18717065463318766]
	TIME [epoch: 6.42 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09823585781192043		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.09823585781192043 | validation: 0.2331226917917319]
	TIME [epoch: 6.43 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09613120581931427		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.09613120581931427 | validation: 0.18336904101587898]
	TIME [epoch: 6.41 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09503079745633902		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.09503079745633902 | validation: 0.16639646771938096]
	TIME [epoch: 6.44 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08714221622652668		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.08714221622652668 | validation: 0.20489501314272318]
	TIME [epoch: 6.43 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10298925290702325		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.10298925290702325 | validation: 0.16674403487874392]
	TIME [epoch: 6.41 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08531701607977916		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.08531701607977916 | validation: 0.20522146957540713]
	TIME [epoch: 6.42 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09026354345827427		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.09026354345827427 | validation: 0.18173654950836843]
	TIME [epoch: 6.43 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09897837239491716		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.09897837239491716 | validation: 0.1559652776132665]
	TIME [epoch: 6.42 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13711932426883966		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.13711932426883966 | validation: 0.19608278893541178]
	TIME [epoch: 6.41 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11697563744021913		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.11697563744021913 | validation: 0.24501413145932296]
	TIME [epoch: 6.44 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10981492078684302		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.10981492078684302 | validation: 0.214635136962148]
	TIME [epoch: 6.41 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1029897660465936		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.1029897660465936 | validation: 0.2754033639112107]
	TIME [epoch: 6.4 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10244789773946475		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.10244789773946475 | validation: 0.19588069772157396]
	TIME [epoch: 6.4 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10301081358465909		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.10301081358465909 | validation: 0.2889920228544541]
	TIME [epoch: 6.39 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10042250782162478		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.10042250782162478 | validation: 0.2544210252659714]
	TIME [epoch: 6.4 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10319369494833079		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.10319369494833079 | validation: 0.21952640578357455]
	TIME [epoch: 6.41 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09206218118816539		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.09206218118816539 | validation: 0.22150301834220906]
	TIME [epoch: 6.43 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09875889362223866		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.09875889362223866 | validation: 0.2201474513696242]
	TIME [epoch: 6.4 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08658469273748243		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.08658469273748243 | validation: 0.21513325274146922]
	TIME [epoch: 6.4 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08742718938610977		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.08742718938610977 | validation: 0.2325083078727663]
	TIME [epoch: 6.4 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08394307724284086		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.08394307724284086 | validation: 0.17660832382920924]
	TIME [epoch: 6.42 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07746233363621201		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.07746233363621201 | validation: 0.17285737280595853]
	TIME [epoch: 6.41 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0832087072279271		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.0832087072279271 | validation: 0.2155618006984983]
	TIME [epoch: 6.46 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08583011410845282		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.08583011410845282 | validation: 0.2802788987113792]
	TIME [epoch: 6.42 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11955048320767875		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.11955048320767875 | validation: 0.3061233414527616]
	TIME [epoch: 6.41 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1192465924536971		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.1192465924536971 | validation: 0.2146008414702358]
	TIME [epoch: 6.41 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09155626103320277		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.09155626103320277 | validation: 0.2469229391329082]
	TIME [epoch: 6.42 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09653906918243044		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.09653906918243044 | validation: 0.1775447265688464]
	TIME [epoch: 6.42 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08452234347039442		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.08452234347039442 | validation: 0.215579092859238]
	TIME [epoch: 6.42 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0942857392108756		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.0942857392108756 | validation: 0.18668855364912076]
	TIME [epoch: 6.45 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07766585780336685		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.07766585780336685 | validation: 0.24506230855959082]
	TIME [epoch: 6.42 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09010230609251875		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.09010230609251875 | validation: 0.24762648945361182]
	TIME [epoch: 6.42 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1090569014881245		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.1090569014881245 | validation: 0.22189102192506738]
	TIME [epoch: 6.42 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09703554984515227		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.09703554984515227 | validation: 0.23913287548161236]
	TIME [epoch: 6.42 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09624714697886201		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.09624714697886201 | validation: 0.20861169898739534]
	TIME [epoch: 6.43 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08255928927023767		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.08255928927023767 | validation: 0.22119696292938604]
	TIME [epoch: 6.43 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08479556661402857		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.08479556661402857 | validation: 0.20300506216359593]
	TIME [epoch: 6.45 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11992200183745252		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.11992200183745252 | validation: 0.25060123128772427]
	TIME [epoch: 6.42 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10890551649475211		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.10890551649475211 | validation: 0.17306763431592298]
	TIME [epoch: 6.42 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08653988085414657		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.08653988085414657 | validation: 0.20251123916211491]
	TIME [epoch: 6.42 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09810435562277804		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.09810435562277804 | validation: 0.17773470700676158]
	TIME [epoch: 6.42 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07918442719860443		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.07918442719860443 | validation: 0.1982699281744175]
	TIME [epoch: 6.42 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08344905806079032		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.08344905806079032 | validation: 0.2038236584993279]
	TIME [epoch: 6.45 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10500524457724343		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.10500524457724343 | validation: 0.2152235373784732]
	TIME [epoch: 6.43 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10430757170066497		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.10430757170066497 | validation: 0.21345765714096676]
	TIME [epoch: 6.42 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11390691582810325		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.11390691582810325 | validation: 0.2345947022517827]
	TIME [epoch: 6.42 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10301538822543985		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.10301538822543985 | validation: 0.22371347473114866]
	TIME [epoch: 6.42 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09649958516874658		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.09649958516874658 | validation: 0.23073102649381796]
	TIME [epoch: 6.42 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1007315403927988		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.1007315403927988 | validation: 0.22967723864560627]
	TIME [epoch: 6.44 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0956232003915489		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.0956232003915489 | validation: 0.21544673164734235]
	TIME [epoch: 6.45 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08730323734343519		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.08730323734343519 | validation: 0.17240163360659672]
	TIME [epoch: 6.43 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09221382297557408		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.09221382297557408 | validation: 0.20328543071290028]
	TIME [epoch: 6.42 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09923979725823484		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.09923979725823484 | validation: 0.1905960704787833]
	TIME [epoch: 6.42 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10821305476840315		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.10821305476840315 | validation: 0.24673827920561583]
	TIME [epoch: 6.42 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13591870908907183		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.13591870908907183 | validation: 0.24209191810515868]
	TIME [epoch: 6.41 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13880388684071893		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.13880388684071893 | validation: 0.20878768574335793]
	TIME [epoch: 6.43 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12251601556841119		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.12251601556841119 | validation: 0.17900287587824373]
	TIME [epoch: 6.4 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11434128460683722		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.11434128460683722 | validation: 0.2028078606303989]
	TIME [epoch: 6.4 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1188789627623429		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.1188789627623429 | validation: 0.18757823464238427]
	TIME [epoch: 6.4 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09434757486305544		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.09434757486305544 | validation: 0.20281438897939885]
	TIME [epoch: 6.4 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0826947057067985		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.0826947057067985 | validation: 0.182455739581684]
	TIME [epoch: 6.4 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08909547745171702		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.08909547745171702 | validation: 0.1686048969034546]
	TIME [epoch: 6.4 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0895555614688762		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.0895555614688762 | validation: 0.23671770381360943]
	TIME [epoch: 6.43 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0995463492549864		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.0995463492549864 | validation: 0.21503867994068188]
	TIME [epoch: 6.39 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08436247149167408		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.08436247149167408 | validation: 0.21004558616978414]
	TIME [epoch: 6.39 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07127532138252095		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.07127532138252095 | validation: 0.15099909438226788]
	TIME [epoch: 6.4 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07930172511247095		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.07930172511247095 | validation: 0.1961730280296986]
	TIME [epoch: 6.4 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09376914525487819		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.09376914525487819 | validation: 0.19207732672586236]
	TIME [epoch: 6.4 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07643495803002076		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.07643495803002076 | validation: 0.17394495972933222]
	TIME [epoch: 6.4 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08253985493828316		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.08253985493828316 | validation: 0.1687326198289636]
	TIME [epoch: 6.42 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09102681307598873		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.09102681307598873 | validation: 0.2183819822063857]
	TIME [epoch: 6.42 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10328692753224983		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.10328692753224983 | validation: 0.2081745570390766]
	TIME [epoch: 6.4 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09309254474718454		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.09309254474718454 | validation: 0.24345297369506413]
	TIME [epoch: 6.4 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10049465913649638		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.10049465913649638 | validation: 0.2096527456337744]
	TIME [epoch: 6.4 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09379318513905167		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.09379318513905167 | validation: 0.20368565659076093]
	TIME [epoch: 6.4 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10707913233300664		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.10707913233300664 | validation: 0.19665471132659826]
	TIME [epoch: 6.43 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09096810962603218		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.09096810962603218 | validation: 0.21192490131880093]
	TIME [epoch: 6.41 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08636861354215714		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.08636861354215714 | validation: 0.2130779928797881]
	TIME [epoch: 6.41 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09457640926604223		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.09457640926604223 | validation: 0.2025142308726195]
	TIME [epoch: 6.39 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08487668862511266		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.08487668862511266 | validation: 0.18679135696629548]
	TIME [epoch: 6.4 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07803402712168013		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.07803402712168013 | validation: 0.25014686089399796]
	TIME [epoch: 6.4 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12296915778187212		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.12296915778187212 | validation: 0.29027568991384156]
	TIME [epoch: 6.4 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11602854123956528		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.11602854123956528 | validation: 0.22500160234628352]
	TIME [epoch: 6.44 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10879945332054192		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.10879945332054192 | validation: 0.24680943616907988]
	TIME [epoch: 6.4 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08874045541958432		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.08874045541958432 | validation: 0.21511270858626]
	TIME [epoch: 6.4 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08313523021087132		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.08313523021087132 | validation: 0.19018346443856754]
	TIME [epoch: 6.42 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08305067227062252		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.08305067227062252 | validation: 0.20564058727488743]
	TIME [epoch: 6.41 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0827375790229039		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.0827375790229039 | validation: 0.19097181315391282]
	TIME [epoch: 6.44 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08899012729727464		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.08899012729727464 | validation: 0.23166800915491437]
	TIME [epoch: 6.42 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09260053171625418		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.09260053171625418 | validation: 0.23345947846827142]
	TIME [epoch: 6.44 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08365164128681002		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.08365164128681002 | validation: 0.23193983021680226]
	TIME [epoch: 6.41 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09397538143910536		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.09397538143910536 | validation: 0.28012913103722675]
	TIME [epoch: 6.42 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09550461973309121		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.09550461973309121 | validation: 0.21272426414546444]
	TIME [epoch: 6.41 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0962479259968271		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.0962479259968271 | validation: 0.18629343300785517]
	TIME [epoch: 6.41 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10123370491256292		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.10123370491256292 | validation: 0.17754009045449362]
	TIME [epoch: 6.41 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07566066247076086		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.07566066247076086 | validation: 0.19000666229566335]
	TIME [epoch: 6.44 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07127048903528094		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.07127048903528094 | validation: 0.1753947936547703]
	TIME [epoch: 6.43 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07509343030905122		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.07509343030905122 | validation: 0.2006063751879274]
	TIME [epoch: 6.43 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07990059053775317		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.07990059053775317 | validation: 0.21660385032802004]
	TIME [epoch: 6.41 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07737367619700573		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.07737367619700573 | validation: 0.17859113049746556]
	TIME [epoch: 6.41 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08620319461301162		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.08620319461301162 | validation: 0.18200428177197644]
	TIME [epoch: 6.42 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08046024484251901		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.08046024484251901 | validation: 0.17425352653983922]
	TIME [epoch: 6.42 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08562126946175844		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.08562126946175844 | validation: 0.17563294782052744]
	TIME [epoch: 6.44 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0786215840164312		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.0786215840164312 | validation: 0.1607570033636531]
	TIME [epoch: 6.42 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0807263175398453		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.0807263175398453 | validation: 0.1980120997439787]
	TIME [epoch: 6.43 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07952859347611971		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.07952859347611971 | validation: 0.21567212148712095]
	TIME [epoch: 6.41 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09461067950380109		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.09461067950380109 | validation: 0.2215407801068632]
	TIME [epoch: 6.44 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08973332410647952		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.08973332410647952 | validation: 0.20987679913277504]
	TIME [epoch: 6.41 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08996077694965729		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.08996077694965729 | validation: 0.2087111675870893]
	TIME [epoch: 6.43 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09516568310788129		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.09516568310788129 | validation: 0.1525875473503151]
	TIME [epoch: 6.43 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07876307802312632		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.07876307802312632 | validation: 0.1692711614312155]
	TIME [epoch: 6.41 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09337755233250156		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.09337755233250156 | validation: 0.1534819223259403]
	TIME [epoch: 6.41 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08312351812963659		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.08312351812963659 | validation: 0.18171599804862618]
	TIME [epoch: 6.43 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08569715050383708		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.08569715050383708 | validation: 0.19599849523114243]
	TIME [epoch: 6.42 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07934889091893971		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.07934889091893971 | validation: 0.1741038206974127]
	TIME [epoch: 6.43 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08814913497203189		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.08814913497203189 | validation: 0.22658898247686604]
	TIME [epoch: 6.45 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08401431862888631		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.08401431862888631 | validation: 0.2024525995127266]
	TIME [epoch: 6.43 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08085221938918202		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.08085221938918202 | validation: 0.19841288115154693]
	TIME [epoch: 6.41 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09171350743582657		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.09171350743582657 | validation: 0.26694723692003175]
	TIME [epoch: 6.42 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10079502281918822		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.10079502281918822 | validation: 0.2752794165852057]
	TIME [epoch: 6.41 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10516591262239608		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.10516591262239608 | validation: 0.3053776037869636]
	TIME [epoch: 6.41 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09655605606677284		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.09655605606677284 | validation: 0.2256324290500938]
	TIME [epoch: 6.41 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08778708969533763		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.08778708969533763 | validation: 0.22958579028858717]
	TIME [epoch: 6.44 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10597914915101585		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.10597914915101585 | validation: 0.26253185744601043]
	TIME [epoch: 6.41 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0995164581901759		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.0995164581901759 | validation: 0.31270261072232813]
	TIME [epoch: 6.41 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11899568839281441		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.11899568839281441 | validation: 0.25839080052918356]
	TIME [epoch: 6.42 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09928826067345603		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.09928826067345603 | validation: 0.24662154041380469]
	TIME [epoch: 6.42 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09553366845425049		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.09553366845425049 | validation: 0.22835675095554156]
	TIME [epoch: 6.42 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10244858371576629		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.10244858371576629 | validation: 0.21336381824846531]
	TIME [epoch: 6.42 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11867306225837405		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.11867306225837405 | validation: 0.21138714110533535]
	TIME [epoch: 6.42 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09612860590560302		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.09612860590560302 | validation: 0.21311218955249012]
	TIME [epoch: 6.41 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08388809274073157		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.08388809274073157 | validation: 0.19870580253828454]
	TIME [epoch: 6.4 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0824229193951086		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.0824229193951086 | validation: 0.2084317141667505]
	TIME [epoch: 6.41 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0917989119104498		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.0917989119104498 | validation: 0.18497861507154562]
	TIME [epoch: 6.41 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09239534561782015		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.09239534561782015 | validation: 0.2085644594556824]
	TIME [epoch: 6.42 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09108490805913147		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.09108490805913147 | validation: 0.2189841810447907]
	TIME [epoch: 6.46 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10161669390403394		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.10161669390403394 | validation: 0.20904089951698254]
	TIME [epoch: 6.41 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09120258987287161		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.09120258987287161 | validation: 0.20170361764230785]
	TIME [epoch: 6.4 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07921295534400538		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.07921295534400538 | validation: 0.17619471846725415]
	TIME [epoch: 6.41 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07526215189743243		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.07526215189743243 | validation: 0.14786918445977462]
	TIME [epoch: 6.4 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08229412604546762		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.08229412604546762 | validation: 0.15458508180851901]
	TIME [epoch: 6.41 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07542084340614127		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.07542084340614127 | validation: 0.17614055933860137]
	TIME [epoch: 6.41 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07252286043741203		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.07252286043741203 | validation: 0.1671352659695472]
	TIME [epoch: 6.44 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08791394085999721		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.08791394085999721 | validation: 0.139327408747249]
	TIME [epoch: 6.42 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.087998684737736		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.087998684737736 | validation: 0.15778776426269664]
	TIME [epoch: 6.42 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08224871801438816		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.08224871801438816 | validation: 0.1887696938034715]
	TIME [epoch: 6.43 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08013694373691532		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.08013694373691532 | validation: 0.2130777486396223]
	TIME [epoch: 6.41 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09089397388550269		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.09089397388550269 | validation: 0.18070654301437333]
	TIME [epoch: 6.4 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08040996503133563		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.08040996503133563 | validation: 0.1780000280916678]
	TIME [epoch: 6.4 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08340148398074454		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.08340148398074454 | validation: 0.2050113829364979]
	TIME [epoch: 6.42 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0910610389048782		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.0910610389048782 | validation: 0.20197980861838766]
	TIME [epoch: 6.38 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08811438875799538		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.08811438875799538 | validation: 0.18785094937147276]
	TIME [epoch: 6.41 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09651294250646902		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.09651294250646902 | validation: 0.2168833605483875]
	TIME [epoch: 6.4 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09992692948398292		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.09992692948398292 | validation: 0.1830183841096766]
	TIME [epoch: 6.41 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09047471275606875		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.09047471275606875 | validation: 0.15996415725241747]
	TIME [epoch: 6.41 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08187642821872382		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.08187642821872382 | validation: 0.1849018883275126]
	TIME [epoch: 6.45 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08121328782611295		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.08121328782611295 | validation: 0.20978500954469073]
	TIME [epoch: 6.41 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08662589030987038		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.08662589030987038 | validation: 0.15327716194549465]
	TIME [epoch: 6.41 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07898012165515095		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.07898012165515095 | validation: 0.1921790076973068]
	TIME [epoch: 6.41 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07247634988334674		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.07247634988334674 | validation: 0.20563566189897345]
	TIME [epoch: 6.41 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07146261422117385		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.07146261422117385 | validation: 0.17485183052418776]
	TIME [epoch: 6.39 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08040615527147406		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.08040615527147406 | validation: 0.1966563197826737]
	TIME [epoch: 6.42 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07455611796656492		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.07455611796656492 | validation: 0.17680269178541316]
	TIME [epoch: 6.46 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07872241636556991		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.07872241636556991 | validation: 0.1834800391393193]
	TIME [epoch: 6.42 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07588150693194076		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.07588150693194076 | validation: 0.16541172481856933]
	TIME [epoch: 6.43 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08135938980402319		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.08135938980402319 | validation: 0.15339293383058525]
	TIME [epoch: 6.42 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09138789524320674		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.09138789524320674 | validation: 0.18062104270880683]
	TIME [epoch: 6.43 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09205223999722667		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.09205223999722667 | validation: 0.18670979787104142]
	TIME [epoch: 6.4 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09270584506957875		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.09270584506957875 | validation: 0.18334418868993396]
	TIME [epoch: 6.44 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09716917412087869		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.09716917412087869 | validation: 0.21081308486519107]
	TIME [epoch: 6.41 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09613287172901258		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.09613287172901258 | validation: 0.22556562325716814]
	TIME [epoch: 6.42 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09408097336712881		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.09408097336712881 | validation: 0.21031076335779209]
	TIME [epoch: 6.42 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08885891415034264		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.08885891415034264 | validation: 0.18799156509114884]
	TIME [epoch: 6.42 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08318608459427379		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.08318608459427379 | validation: 0.16231474979357713]
	TIME [epoch: 6.43 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08359825535749643		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.08359825535749643 | validation: 0.15968373799205635]
	TIME [epoch: 6.41 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0765993629778612		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.0765993629778612 | validation: 0.2018654793376409]
	TIME [epoch: 6.46 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08744820701029772		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.08744820701029772 | validation: 0.2298766434430353]
	TIME [epoch: 6.43 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0944528268033231		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.0944528268033231 | validation: 0.20617717695432256]
	TIME [epoch: 6.42 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07805142868952876		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.07805142868952876 | validation: 0.18466696687606907]
	TIME [epoch: 6.43 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08775104707780228		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.08775104707780228 | validation: 0.2054848358471348]
	TIME [epoch: 6.42 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11128936907529235		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.11128936907529235 | validation: 0.23792139097199505]
	TIME [epoch: 6.43 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09373103477871259		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.09373103477871259 | validation: 0.20015283740990408]
	TIME [epoch: 6.44 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10625264149344815		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.10625264149344815 | validation: 0.22602591614571002]
	TIME [epoch: 6.46 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09611567388507285		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.09611567388507285 | validation: 0.2029535942983953]
	TIME [epoch: 6.44 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0962174876005111		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.0962174876005111 | validation: 0.1988892233687649]
	TIME [epoch: 6.43 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08489789496306208		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.08489789496306208 | validation: 0.16715810604494427]
	TIME [epoch: 6.43 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08188084954336879		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.08188084954336879 | validation: 0.1682612118730702]
	TIME [epoch: 6.43 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07330354598158409		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.07330354598158409 | validation: 0.16632379076332715]
	TIME [epoch: 6.43 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0783792211098003		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.0783792211098003 | validation: 0.16583647905176224]
	TIME [epoch: 6.46 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08881089569995948		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.08881089569995948 | validation: 0.1865016740474384]
	TIME [epoch: 6.44 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0965602974501636		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.0965602974501636 | validation: 0.20552476460683763]
	TIME [epoch: 6.43 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10014783529187822		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.10014783529187822 | validation: 0.1887596208269789]
	TIME [epoch: 6.43 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08239921071453739		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.08239921071453739 | validation: 0.17421481010378145]
	TIME [epoch: 6.43 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07796302844365086		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.07796302844365086 | validation: 0.187448189264883]
	TIME [epoch: 6.42 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07754263763339514		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.07754263763339514 | validation: 0.1693965109677496]
	TIME [epoch: 6.42 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07040194076934705		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.07040194076934705 | validation: 0.17174304542092667]
	TIME [epoch: 6.46 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07859759739250478		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.07859759739250478 | validation: 0.20273810653410881]
	TIME [epoch: 6.43 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0890590316225464		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.0890590316225464 | validation: 0.21137513929875704]
	TIME [epoch: 6.41 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08722387677118142		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.08722387677118142 | validation: 0.1879619063400189]
	TIME [epoch: 6.41 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07437580567014733		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.07437580567014733 | validation: 0.17522256396410987]
	TIME [epoch: 6.43 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08487221061534772		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.08487221061534772 | validation: 0.1869416310495432]
	TIME [epoch: 6.43 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09044889361043033		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.09044889361043033 | validation: 0.17923479076955848]
	TIME [epoch: 6.43 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09446723398432035		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.09446723398432035 | validation: 0.1798622447009877]
	TIME [epoch: 6.43 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09084487107550292		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.09084487107550292 | validation: 0.1635438909086416]
	TIME [epoch: 6.42 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11945113170547701		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.11945113170547701 | validation: 0.1799588264595738]
	TIME [epoch: 6.42 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08897114897138868		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.08897114897138868 | validation: 0.17426164809524644]
	TIME [epoch: 6.4 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08903835689101813		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.08903835689101813 | validation: 0.1911495261565824]
	TIME [epoch: 6.4 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07635030996994388		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.07635030996994388 | validation: 0.17464761510134175]
	TIME [epoch: 6.41 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08484382236435253		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.08484382236435253 | validation: 0.16538337416514243]
	TIME [epoch: 6.44 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08048005379190296		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.08048005379190296 | validation: 0.16348823811659094]
	TIME [epoch: 6.41 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08510580928963438		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.08510580928963438 | validation: 0.14552294682471562]
	TIME [epoch: 6.41 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07944484771787505		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.07944484771787505 | validation: 0.14895563195526715]
	TIME [epoch: 6.4 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07776688816565769		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.07776688816565769 | validation: 0.17342314075087437]
	TIME [epoch: 6.41 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07192133605696482		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.07192133605696482 | validation: 0.16105624166175986]
	TIME [epoch: 6.41 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07358648287368741		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.07358648287368741 | validation: 0.21247911941609146]
	TIME [epoch: 6.41 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09917782923982058		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.09917782923982058 | validation: 0.21667783387060666]
	TIME [epoch: 6.44 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09685597841479723		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.09685597841479723 | validation: 0.2219889533749516]
	TIME [epoch: 6.4 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08350095775364043		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.08350095775364043 | validation: 0.15755788687489558]
	TIME [epoch: 6.4 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08179416608819173		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.08179416608819173 | validation: 0.18195238493199747]
	TIME [epoch: 6.4 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0789841353787362		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.0789841353787362 | validation: 0.15712190240786172]
	TIME [epoch: 6.41 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07567289442123938		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.07567289442123938 | validation: 0.17563151710123237]
	TIME [epoch: 6.41 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0835934868440265		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.0835934868440265 | validation: 0.23869824403504786]
	TIME [epoch: 6.43 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09662980542267383		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.09662980542267383 | validation: 0.1901219389810586]
	TIME [epoch: 6.46 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06997674017090162		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.06997674017090162 | validation: 0.1944632145614416]
	TIME [epoch: 6.42 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06639961522290695		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.06639961522290695 | validation: 0.1699695793399239]
	TIME [epoch: 6.42 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0837510982736039		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.0837510982736039 | validation: 0.1826682475022766]
	TIME [epoch: 6.42 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08153513054586264		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.08153513054586264 | validation: 0.1590786074383605]
	TIME [epoch: 6.41 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0740958869429088		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.0740958869429088 | validation: 0.17863031974049903]
	TIME [epoch: 6.41 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08240520907186738		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.08240520907186738 | validation: 0.16728837173163058]
	TIME [epoch: 6.46 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07608564803536925		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.07608564803536925 | validation: 0.1765060524806723]
	TIME [epoch: 6.42 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07135379129511732		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.07135379129511732 | validation: 0.18048166153904469]
	TIME [epoch: 6.42 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07331538379960909		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.07331538379960909 | validation: 0.1855206802972863]
	TIME [epoch: 6.42 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07235430684720709		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.07235430684720709 | validation: 0.1771254929637999]
	TIME [epoch: 6.41 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07556179362800286		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.07556179362800286 | validation: 0.15419730960696953]
	TIME [epoch: 6.42 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07553042859632347		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.07553042859632347 | validation: 0.15537230590601142]
	TIME [epoch: 6.42 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07649381378449344		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.07649381378449344 | validation: 0.16969814716772255]
	TIME [epoch: 6.46 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07977812150645823		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.07977812150645823 | validation: 0.18232167033780988]
	TIME [epoch: 6.43 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0850132570121111		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.0850132570121111 | validation: 0.21682209622218238]
	TIME [epoch: 6.42 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08177290613347768		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.08177290613347768 | validation: 0.18693346214276696]
	TIME [epoch: 6.42 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07649619582705741		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.07649619582705741 | validation: 0.1888400818819988]
	TIME [epoch: 6.42 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08538863413375344		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.08538863413375344 | validation: 0.19492274934898796]
	TIME [epoch: 6.43 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07925117579476822		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.07925117579476822 | validation: 0.21203088697389685]
	TIME [epoch: 6.44 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09541579705204861		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.09541579705204861 | validation: 0.2030021352639417]
	TIME [epoch: 6.43 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09051205481591572		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.09051205481591572 | validation: 0.1616785004645953]
	TIME [epoch: 6.43 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08568815635934658		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.08568815635934658 | validation: 0.194471363857864]
	TIME [epoch: 6.41 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08580770436936859		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.08580770436936859 | validation: 0.2092717466354206]
	TIME [epoch: 6.43 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10268867492080294		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.10268867492080294 | validation: 0.20906194410500922]
	TIME [epoch: 6.41 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09760870942817704		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.09760870942817704 | validation: 0.19711889297062202]
	TIME [epoch: 6.42 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09026374438326075		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.09026374438326075 | validation: 0.1905088653906119]
	TIME [epoch: 6.45 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09062540804506371		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.09062540804506371 | validation: 0.17732604180956166]
	TIME [epoch: 6.43 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0904332577794752		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.0904332577794752 | validation: 0.16890004493479918]
	TIME [epoch: 6.43 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0776090174030711		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.0776090174030711 | validation: 0.18588026339788186]
	TIME [epoch: 6.43 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08820056441943425		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.08820056441943425 | validation: 0.16628733637575632]
	TIME [epoch: 6.42 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07353975218844157		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.07353975218844157 | validation: 0.19399320531456024]
	TIME [epoch: 6.43 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07675228820302275		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.07675228820302275 | validation: 0.20383084100813306]
	TIME [epoch: 6.43 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07926438069041715		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.07926438069041715 | validation: 0.1743403820161694]
	TIME [epoch: 6.44 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08115218241593763		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.08115218241593763 | validation: 0.17388587464755545]
	TIME [epoch: 6.43 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09095284760377222		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.09095284760377222 | validation: 0.16687414379679794]
	TIME [epoch: 6.42 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0892712972017973		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.0892712972017973 | validation: 0.1705224669033669]
	TIME [epoch: 6.42 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08026940643372685		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.08026940643372685 | validation: 0.16174386417598097]
	TIME [epoch: 6.41 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07650046935597868		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.07650046935597868 | validation: 0.15304701394498935]
	TIME [epoch: 6.42 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.078670336580388		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.078670336580388 | validation: 0.14902208069293185]
	TIME [epoch: 6.45 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08204416432763739		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.08204416432763739 | validation: 0.19276327033628618]
	TIME [epoch: 6.43 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08743052086800127		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.08743052086800127 | validation: 0.18328243694073543]
	TIME [epoch: 6.43 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07607399690331798		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.07607399690331798 | validation: 0.1894003150778147]
	TIME [epoch: 6.43 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07081238723406505		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.07081238723406505 | validation: 0.1817504459083115]
	TIME [epoch: 6.42 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0741551229160136		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.0741551229160136 | validation: 0.20271969065221385]
	TIME [epoch: 6.44 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07571475177349996		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.07571475177349996 | validation: 0.18552138369079557]
	TIME [epoch: 6.42 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07215598638050741		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.07215598638050741 | validation: 0.17989267896647312]
	TIME [epoch: 6.44 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07288990544920974		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.07288990544920974 | validation: 0.196724691581014]
	TIME [epoch: 6.43 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07189218138994445		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.07189218138994445 | validation: 0.19591810722430908]
	TIME [epoch: 6.42 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07064096038213169		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.07064096038213169 | validation: 0.2033047550267743]
	TIME [epoch: 6.42 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08055510208076949		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.08055510208076949 | validation: 0.20547754631309198]
	TIME [epoch: 6.43 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07331349069663723		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.07331349069663723 | validation: 0.20495769390077828]
	TIME [epoch: 6.42 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07653059283942748		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.07653059283942748 | validation: 0.20682816696794207]
	TIME [epoch: 6.43 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08909442767381827		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.08909442767381827 | validation: 0.22132340281683868]
	TIME [epoch: 6.46 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10398959419301948		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.10398959419301948 | validation: 0.1647943594135231]
	TIME [epoch: 6.42 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09461794200947711		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.09461794200947711 | validation: 0.1536749526500818]
	TIME [epoch: 6.43 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09694582146108183		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.09694582146108183 | validation: 0.15388966372812196]
	TIME [epoch: 6.42 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08924843444485601		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.08924843444485601 | validation: 0.14798909928667903]
	TIME [epoch: 6.42 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08668074581791961		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.08668074581791961 | validation: 0.1602854159928747]
	TIME [epoch: 6.42 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07522784721622264		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.07522784721622264 | validation: 0.15045881820666307]
	TIME [epoch: 6.45 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08433007195840148		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.08433007195840148 | validation: 0.18930582781833594]
	TIME [epoch: 6.43 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09761249365959657		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.09761249365959657 | validation: 0.20437527402289557]
	TIME [epoch: 6.42 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0976620442659823		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.0976620442659823 | validation: 0.20741477707189998]
	TIME [epoch: 6.43 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09770054942677223		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.09770054942677223 | validation: 0.21464280605557334]
	TIME [epoch: 6.42 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09985824969463825		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.09985824969463825 | validation: 0.2091192316324402]
	TIME [epoch: 6.41 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08243510055136408		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.08243510055136408 | validation: 0.20081887460921038]
	TIME [epoch: 6.43 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08040557296707723		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.08040557296707723 | validation: 0.19015020772969]
	TIME [epoch: 6.46 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07306916983486171		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.07306916983486171 | validation: 0.1856217914598188]
	TIME [epoch: 6.42 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07417945629307839		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.07417945629307839 | validation: 0.15930734431479418]
	TIME [epoch: 6.43 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07338155240477062		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.07338155240477062 | validation: 0.17212605195715944]
	TIME [epoch: 6.42 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06764551897119586		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.06764551897119586 | validation: 0.15136662721578237]
	TIME [epoch: 6.43 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07276007562544017		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.07276007562544017 | validation: 0.17965755482650167]
	TIME [epoch: 6.42 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08567243524468589		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.08567243524468589 | validation: 0.19592972730043923]
	TIME [epoch: 6.43 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09097261398309799		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.09097261398309799 | validation: 0.1907890016665068]
	TIME [epoch: 6.45 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07543786582884603		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.07543786582884603 | validation: 0.16720841173083087]
	TIME [epoch: 6.42 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08014524644800936		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.08014524644800936 | validation: 0.15894094417244067]
	TIME [epoch: 6.42 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07438919125686917		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.07438919125686917 | validation: 0.15073958971421206]
	TIME [epoch: 6.42 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07628649206026893		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.07628649206026893 | validation: 0.17907592344305592]
	TIME [epoch: 6.42 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07047869684587671		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.07047869684587671 | validation: 0.17761048907851376]
	TIME [epoch: 6.42 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06793589186006084		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.06793589186006084 | validation: 0.17080778251480033]
	TIME [epoch: 6.46 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07508668669029256		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.07508668669029256 | validation: 0.16235929648383182]
	TIME [epoch: 6.44 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07300760819745425		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.07300760819745425 | validation: 0.15958875701887423]
	TIME [epoch: 6.42 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07740824227133822		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.07740824227133822 | validation: 0.17958309702191858]
	TIME [epoch: 6.42 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07438177185048173		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.07438177185048173 | validation: 0.18340395960260975]
	TIME [epoch: 6.42 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0713625515799843		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.0713625515799843 | validation: 0.1881157801169237]
	TIME [epoch: 6.42 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06831146752929484		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.06831146752929484 | validation: 0.1648894408584875]
	TIME [epoch: 6.43 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06918016897814233		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.06918016897814233 | validation: 0.18064582080201005]
	TIME [epoch: 6.45 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06975738958664698		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.06975738958664698 | validation: 0.17745446127084724]
	TIME [epoch: 6.43 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07316058562069054		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.07316058562069054 | validation: 0.18195271983874248]
	TIME [epoch: 6.43 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09334672038733118		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.09334672038733118 | validation: 0.17180476686446133]
	TIME [epoch: 6.43 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0894759265324038		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.0894759265324038 | validation: 0.15707855564670659]
	TIME [epoch: 6.43 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0802883733940737		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.0802883733940737 | validation: 0.15924248445328437]
	TIME [epoch: 6.43 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07322211220292563		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.07322211220292563 | validation: 0.164751992223428]
	TIME [epoch: 6.46 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07449701147896555		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.07449701147896555 | validation: 0.17055036782136904]
	TIME [epoch: 6.44 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07988375669639247		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.07988375669639247 | validation: 0.1771084388731039]
	TIME [epoch: 6.42 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07412260056901128		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.07412260056901128 | validation: 0.19481991448731864]
	TIME [epoch: 6.42 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07506016766608319		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.07506016766608319 | validation: 0.172303893939762]
	TIME [epoch: 6.42 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07539167523860496		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.07539167523860496 | validation: 0.1811682758945961]
	TIME [epoch: 6.42 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07475824361817952		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.07475824361817952 | validation: 0.1775758512049969]
	TIME [epoch: 6.43 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06999218577107207		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.06999218577107207 | validation: 0.146960117632921]
	TIME [epoch: 6.47 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08372250133105057		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.08372250133105057 | validation: 0.17588111150654043]
	TIME [epoch: 6.43 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09434008857415725		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.09434008857415725 | validation: 0.17947277200298]
	TIME [epoch: 6.43 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08660387569768772		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.08660387569768772 | validation: 0.17418514168136598]
	TIME [epoch: 6.42 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07219948165639492		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.07219948165639492 | validation: 0.18206510079910768]
	TIME [epoch: 6.43 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07259390091274752		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.07259390091274752 | validation: 0.16741879917791871]
	TIME [epoch: 6.44 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07186986760165757		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.07186986760165757 | validation: 0.19297870955010282]
	TIME [epoch: 6.44 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07506352458340673		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.07506352458340673 | validation: 0.19730462689615152]
	TIME [epoch: 6.46 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07544716001657947		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.07544716001657947 | validation: 0.18224027383438463]
	TIME [epoch: 6.43 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07556811105278319		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.07556811105278319 | validation: 0.1640785667987479]
	TIME [epoch: 6.43 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07477444211935727		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.07477444211935727 | validation: 0.16128432849723642]
	TIME [epoch: 6.43 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0740997076272113		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.0740997076272113 | validation: 0.15576293519522924]
	TIME [epoch: 6.42 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07460183893660001		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.07460183893660001 | validation: 0.16021524549586388]
	TIME [epoch: 6.42 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07662920466185319		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.07662920466185319 | validation: 0.17607190819909613]
	TIME [epoch: 6.45 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08094675313517229		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.08094675313517229 | validation: 0.14989330379880683]
	TIME [epoch: 6.45 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08446792653476655		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.08446792653476655 | validation: 0.17674905553175305]
	TIME [epoch: 6.42 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10395351214082837		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.10395351214082837 | validation: 0.17956933466136718]
	TIME [epoch: 6.43 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09452638128708679		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.09452638128708679 | validation: 0.15794824140015606]
	TIME [epoch: 6.42 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08216219497105846		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.08216219497105846 | validation: 0.1721132280768827]
	TIME [epoch: 6.42 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0862960568399938		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.0862960568399938 | validation: 0.17788078969223795]
	TIME [epoch: 6.43 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07587224040292663		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.07587224040292663 | validation: 0.18221380797724096]
	TIME [epoch: 6.45 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08143292060286221		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.08143292060286221 | validation: 0.16569430565287774]
	TIME [epoch: 6.42 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07706105634637102		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.07706105634637102 | validation: 0.17457142154181074]
	TIME [epoch: 6.42 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07289085140089811		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.07289085140089811 | validation: 0.16703558434603863]
	TIME [epoch: 6.44 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0752689096407684		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.0752689096407684 | validation: 0.18533912666782928]
	TIME [epoch: 6.42 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07790507113726072		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.07790507113726072 | validation: 0.19395645583547935]
	TIME [epoch: 6.43 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0770011518222422		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.0770011518222422 | validation: 0.17917455864209772]
	TIME [epoch: 6.45 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07286403423011026		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.07286403423011026 | validation: 0.18100304822786834]
	TIME [epoch: 6.46 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07216232343859791		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.07216232343859791 | validation: 0.18194312421136602]
	TIME [epoch: 6.42 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07279914520810916		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.07279914520810916 | validation: 0.19370932843227182]
	TIME [epoch: 6.42 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08391209762629404		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.08391209762629404 | validation: 0.18262810634929635]
	TIME [epoch: 6.42 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07393058256517708		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.07393058256517708 | validation: 0.1437722170232289]
	TIME [epoch: 6.44 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07972900123207192		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.07972900123207192 | validation: 0.15051926597287]
	TIME [epoch: 6.42 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08017091144342822		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.08017091144342822 | validation: 0.17392466886721533]
	TIME [epoch: 6.46 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08525562423013565		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.08525562423013565 | validation: 0.18105705318985563]
	TIME [epoch: 6.42 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08037985334354641		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.08037985334354641 | validation: 0.16316185422955806]
	TIME [epoch: 6.42 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09134961323524526		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.09134961323524526 | validation: 0.15547541700591438]
	TIME [epoch: 6.42 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08829882932770924		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.08829882932770924 | validation: 0.14650373501174555]
	TIME [epoch: 6.43 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07613348963888544		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.07613348963888544 | validation: 0.17118977552574896]
	TIME [epoch: 6.42 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07426689079100803		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.07426689079100803 | validation: 0.18328721005064288]
	TIME [epoch: 6.42 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07402272933301107		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.07402272933301107 | validation: 0.1731387789956864]
	TIME [epoch: 6.46 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07081894294292729		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.07081894294292729 | validation: 0.14304782647813438]
	TIME [epoch: 6.42 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07562424640636911		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.07562424640636911 | validation: 0.15333310975350065]
	TIME [epoch: 6.42 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07846731077304697		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.07846731077304697 | validation: 0.17509729741258326]
	TIME [epoch: 6.41 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07801153011587345		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.07801153011587345 | validation: 0.17670690967091132]
	TIME [epoch: 6.41 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08198279041826181		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.08198279041826181 | validation: 0.18344482475286306]
	TIME [epoch: 6.42 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07832281833547165		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.07832281833547165 | validation: 0.19859271505302126]
	TIME [epoch: 6.45 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08615639837336138		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.08615639837336138 | validation: 0.2158536652243975]
	TIME [epoch: 6.43 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07970152641944728		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.07970152641944728 | validation: 0.21964820770613322]
	TIME [epoch: 6.42 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08687055802252053		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.08687055802252053 | validation: 0.2134875693439173]
	TIME [epoch: 6.42 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08187078926651392		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.08187078926651392 | validation: 0.2192965383263937]
	TIME [epoch: 6.42 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0809873795620438		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.0809873795620438 | validation: 0.2028367388945739]
	TIME [epoch: 6.42 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07706110525291535		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.07706110525291535 | validation: 0.19407865929345833]
	TIME [epoch: 6.42 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07426283000864234		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.07426283000864234 | validation: 0.18960521354936466]
	TIME [epoch: 6.45 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07833282556436619		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.07833282556436619 | validation: 0.17932170576229237]
	TIME [epoch: 6.43 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07403803784481626		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.07403803784481626 | validation: 0.19346431757477045]
	TIME [epoch: 6.42 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0804712344217252		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.0804712344217252 | validation: 0.19555044161768312]
	TIME [epoch: 6.42 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0796982933925024		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.0796982933925024 | validation: 0.2009151656439433]
	TIME [epoch: 6.41 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07727823291300971		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.07727823291300971 | validation: 0.1997792442540915]
	TIME [epoch: 6.41 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08361970086510909		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.08361970086510909 | validation: 0.1693655784231327]
	TIME [epoch: 6.43 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08058508541130864		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.08058508541130864 | validation: 0.16487777923508629]
	TIME [epoch: 6.44 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07361519627994588		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.07361519627994588 | validation: 0.1355361353085274]
	TIME [epoch: 6.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r4_20240309_135700/states/model_tr_study1_1289.pth
	Model improved!!!
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07843481589668555		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.07843481589668555 | validation: 0.14520729105094707]
	TIME [epoch: 6.41 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08495592489876988		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.08495592489876988 | validation: 0.16411365325858668]
	TIME [epoch: 6.41 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07374108234135646		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.07374108234135646 | validation: 0.15857303239844295]
	TIME [epoch: 6.42 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07093667231764353		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.07093667231764353 | validation: 0.17928123077342675]
	TIME [epoch: 6.43 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07485622314508669		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.07485622314508669 | validation: 0.1945233129560581]
	TIME [epoch: 6.45 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07569205950002358		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.07569205950002358 | validation: 0.19682269601536853]
	TIME [epoch: 6.43 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07768195582037837		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.07768195582037837 | validation: 0.1932446159911332]
	TIME [epoch: 6.41 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07095372755894346		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.07095372755894346 | validation: 0.15543527184862163]
	TIME [epoch: 6.41 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06792414142447822		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.06792414142447822 | validation: 0.16270969383873926]
	TIME [epoch: 6.41 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0759834315530285		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.0759834315530285 | validation: 0.16398504661925306]
	TIME [epoch: 6.41 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07504154072230829		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.07504154072230829 | validation: 0.17151767406489832]
	TIME [epoch: 6.42 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06012651275643527		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.06012651275643527 | validation: 0.17088973893570103]
	TIME [epoch: 6.45 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06982403201552712		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.06982403201552712 | validation: 0.16711885325449505]
	TIME [epoch: 6.41 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07094368228058125		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.07094368228058125 | validation: 0.17334074294608257]
	TIME [epoch: 6.41 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06575295270835324		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.06575295270835324 | validation: 0.16293518026278797]
	TIME [epoch: 6.41 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06676205516110242		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.06676205516110242 | validation: 0.19470607539379883]
	TIME [epoch: 6.41 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07069709486446335		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.07069709486446335 | validation: 0.2082674072195544]
	TIME [epoch: 6.41 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07168160350813785		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.07168160350813785 | validation: 0.18565211150014363]
	TIME [epoch: 6.43 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06932061317259552		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.06932061317259552 | validation: 0.17478363220639725]
	TIME [epoch: 6.44 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07898424873019813		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.07898424873019813 | validation: 0.19468431669066547]
	TIME [epoch: 6.41 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0696318452890338		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.0696318452890338 | validation: 0.1629697497066833]
	TIME [epoch: 6.41 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06815490415317316		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.06815490415317316 | validation: 0.17713141095762833]
	TIME [epoch: 6.42 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0645273320203628		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.0645273320203628 | validation: 0.16329140692387534]
	TIME [epoch: 6.42 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07331449292638222		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.07331449292638222 | validation: 0.18053473210804818]
	TIME [epoch: 6.41 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06817941547388379		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.06817941547388379 | validation: 0.19066943678138298]
	TIME [epoch: 6.45 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06613540746294246		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.06613540746294246 | validation: 0.1890253654161905]
	TIME [epoch: 6.42 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06876665163231743		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.06876665163231743 | validation: 0.18776962933559962]
	TIME [epoch: 6.41 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06561858842693127		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.06561858842693127 | validation: 0.18042974425890393]
	TIME [epoch: 6.42 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06746210253799738		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.06746210253799738 | validation: 0.18691263749451054]
	TIME [epoch: 6.41 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0728658583155118		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.0728658583155118 | validation: 0.18261875152293633]
	TIME [epoch: 6.42 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07502822406236552		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.07502822406236552 | validation: 0.1639325559755627]
	TIME [epoch: 6.41 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0753163123691804		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.0753163123691804 | validation: 0.17097492309623266]
	TIME [epoch: 6.45 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06886017804778478		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.06886017804778478 | validation: 0.19169555965096227]
	TIME [epoch: 6.41 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07535752783956501		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.07535752783956501 | validation: 0.17050408220681326]
	TIME [epoch: 6.41 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07105866534190503		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.07105866534190503 | validation: 0.18065838140208393]
	TIME [epoch: 6.41 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07213766765522493		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.07213766765522493 | validation: 0.1800600736345534]
	TIME [epoch: 6.41 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07305627936174047		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.07305627936174047 | validation: 0.1847056018153276]
	TIME [epoch: 6.41 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07484863037276004		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.07484863037276004 | validation: 0.20821477176203257]
	TIME [epoch: 6.45 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06944717406426844		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.06944717406426844 | validation: 0.19982462407797408]
	TIME [epoch: 6.44 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07196235955754049		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.07196235955754049 | validation: 0.19396381468784463]
	TIME [epoch: 6.42 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06926996105829852		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.06926996105829852 | validation: 0.18143356280652942]
	TIME [epoch: 6.43 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06946807049436893		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.06946807049436893 | validation: 0.18266701750442166]
	TIME [epoch: 6.42 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06890921965867643		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.06890921965867643 | validation: 0.1753382430134463]
	TIME [epoch: 6.42 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07134194652071657		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.07134194652071657 | validation: 0.18342436997822098]
	TIME [epoch: 6.41 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08480940843765776		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.08480940843765776 | validation: 0.19476104339363723]
	TIME [epoch: 6.45 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07511797362455966		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.07511797362455966 | validation: 0.21781598668081237]
	TIME [epoch: 6.41 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07590707350317649		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.07590707350317649 | validation: 0.23111129229528574]
	TIME [epoch: 6.41 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08082541215793718		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.08082541215793718 | validation: 0.2247674871476406]
	TIME [epoch: 6.43 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07636075253915484		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.07636075253915484 | validation: 0.1939694962278063]
	TIME [epoch: 6.42 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06534157849485059		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.06534157849485059 | validation: 0.1844210083139366]
	TIME [epoch: 6.42 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07151215525896452		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.07151215525896452 | validation: 0.1777680720306152]
	TIME [epoch: 6.45 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06941628131725597		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.06941628131725597 | validation: 0.17757098893425408]
	TIME [epoch: 6.46 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06829834926647725		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.06829834926647725 | validation: 0.17884150970023016]
	TIME [epoch: 6.44 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07069734855691259		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.07069734855691259 | validation: 0.16828254878849896]
	TIME [epoch: 6.43 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07174040134445471		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.07174040134445471 | validation: 0.15687725212307166]
	TIME [epoch: 6.43 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07304474987170395		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.07304474987170395 | validation: 0.17200445785748344]
	TIME [epoch: 6.43 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07749611601242673		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.07749611601242673 | validation: 0.1665687764956911]
	TIME [epoch: 6.43 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08019235953225665		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.08019235953225665 | validation: 0.17170676853773803]
	TIME [epoch: 6.47 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08774505157162886		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.08774505157162886 | validation: 0.17632751541581754]
	TIME [epoch: 6.44 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08348117574885232		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.08348117574885232 | validation: 0.15715215679215055]
	TIME [epoch: 6.44 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07727653670693477		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.07727653670693477 | validation: 0.1559829274563186]
	TIME [epoch: 6.43 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07933516150741754		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.07933516150741754 | validation: 0.15247920347840815]
	TIME [epoch: 6.44 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07446075540314082		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.07446075540314082 | validation: 0.16524260825121367]
	TIME [epoch: 6.43 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06897748103166176		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.06897748103166176 | validation: 0.167299904867412]
	TIME [epoch: 6.44 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07337950229937067		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.07337950229937067 | validation: 0.1615780580718479]
	TIME [epoch: 6.47 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07165857702261813		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.07165857702261813 | validation: 0.17608903388319647]
	TIME [epoch: 6.44 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06855975953055776		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.06855975953055776 | validation: 0.17427166296433835]
	TIME [epoch: 6.43 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07493233682626653		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.07493233682626653 | validation: 0.1832215350276641]
	TIME [epoch: 6.41 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07142653828633669		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.07142653828633669 | validation: 0.17177499991810663]
	TIME [epoch: 6.42 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07169986178467133		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.07169986178467133 | validation: 0.18179197912111747]
	TIME [epoch: 6.42 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07495119567188713		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.07495119567188713 | validation: 0.17482071842938773]
	TIME [epoch: 6.43 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07863737817245033		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.07863737817245033 | validation: 0.1819681651950447]
	TIME [epoch: 6.44 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0740435524149786		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.0740435524149786 | validation: 0.16803420035255268]
	TIME [epoch: 6.42 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07079609958082503		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.07079609958082503 | validation: 0.16614852686976433]
	TIME [epoch: 6.41 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07191472640193541		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.07191472640193541 | validation: 0.19115059053124397]
	TIME [epoch: 6.42 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0783460235771663		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.0783460235771663 | validation: 0.18101942483415953]
	TIME [epoch: 6.41 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07924624589277333		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.07924624589277333 | validation: 0.17537586859504484]
	TIME [epoch: 6.42 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07048073843958665		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.07048073843958665 | validation: 0.15824930009457197]
	TIME [epoch: 6.44 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07157197465908191		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.07157197465908191 | validation: 0.17347217599755438]
	TIME [epoch: 6.41 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07255328724601774		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.07255328724601774 | validation: 0.1691119420279546]
	TIME [epoch: 6.42 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07285370373962187		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.07285370373962187 | validation: 0.17664792568669]
	TIME [epoch: 6.41 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07489256370231276		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.07489256370231276 | validation: 0.17414118499510436]
	TIME [epoch: 6.41 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07102664601316624		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.07102664601316624 | validation: 0.16347342257668324]
	TIME [epoch: 6.42 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0709832743728855		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.0709832743728855 | validation: 0.15896167773758887]
	TIME [epoch: 6.42 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07194011337260174		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.07194011337260174 | validation: 0.1563820414196693]
	TIME [epoch: 6.45 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07095169529378909		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.07095169529378909 | validation: 0.1779315719909439]
	TIME [epoch: 6.4 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06967739244533848		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.06967739244533848 | validation: 0.1657582007892121]
	TIME [epoch: 6.42 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07550251616559359		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.07550251616559359 | validation: 0.18071572958502785]
	TIME [epoch: 6.42 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07653814680040817		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.07653814680040817 | validation: 0.19864149410753348]
	TIME [epoch: 6.41 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08145813399054612		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.08145813399054612 | validation: 0.2169011624810106]
	TIME [epoch: 6.42 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0855827615919255		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.0855827615919255 | validation: 0.21742950511084402]
	TIME [epoch: 6.43 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08445952582680064		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.08445952582680064 | validation: 0.2116815043443666]
	TIME [epoch: 6.44 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07142110010862057		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.07142110010862057 | validation: 0.18503235774022922]
	TIME [epoch: 6.42 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07115733977200561		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.07115733977200561 | validation: 0.17033337038327645]
	TIME [epoch: 6.43 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06919559667645467		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.06919559667645467 | validation: 0.15856856902156607]
	TIME [epoch: 6.43 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06823528235932406		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.06823528235932406 | validation: 0.17842607673463412]
	TIME [epoch: 6.43 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06846139577435946		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.06846139577435946 | validation: 0.17581338132231147]
	TIME [epoch: 6.43 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07111333886548162		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.07111333886548162 | validation: 0.16243057774839537]
	TIME [epoch: 6.46 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06487360725009217		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.06487360725009217 | validation: 0.16808660967612965]
	TIME [epoch: 6.42 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0700047154773436		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.0700047154773436 | validation: 0.1862423215536774]
	TIME [epoch: 6.41 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06985039230925799		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.06985039230925799 | validation: 0.1849453109518676]
	TIME [epoch: 6.41 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07199275068705797		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.07199275068705797 | validation: 0.176338615194005]
	TIME [epoch: 6.39 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06472364885365867		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.06472364885365867 | validation: 0.17416540233010153]
	TIME [epoch: 6.4 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07284583736534224		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.07284583736534224 | validation: 0.17943541675268804]
	TIME [epoch: 6.42 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06941840259468891		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.06941840259468891 | validation: 0.1638974424484588]
	TIME [epoch: 6.46 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06498931036149055		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.06498931036149055 | validation: 0.17100057026233934]
	TIME [epoch: 6.4 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06869550553904602		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.06869550553904602 | validation: 0.17428809946690152]
	TIME [epoch: 6.4 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06823727858650568		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.06823727858650568 | validation: 0.17252553242201946]
	TIME [epoch: 6.4 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07022028845618156		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.07022028845618156 | validation: 0.1796209141569353]
	TIME [epoch: 6.43 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06360635333535453		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.06360635333535453 | validation: 0.17028811846585004]
	TIME [epoch: 6.42 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06527992301359009		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.06527992301359009 | validation: 0.17714181102787988]
	TIME [epoch: 6.47 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06664152016931359		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.06664152016931359 | validation: 0.1766301205020793]
	TIME [epoch: 6.41 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06851410191151255		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.06851410191151255 | validation: 0.16066308918167552]
	TIME [epoch: 6.42 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06671138345231313		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.06671138345231313 | validation: 0.16810565503417566]
	TIME [epoch: 6.42 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.063104274327024		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.063104274327024 | validation: 0.17122911533849355]
	TIME [epoch: 6.42 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06555361655297152		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.06555361655297152 | validation: 0.17611436947143586]
	TIME [epoch: 6.42 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06807908153142575		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.06807908153142575 | validation: 0.1730305450487059]
	TIME [epoch: 6.42 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06192997787399849		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.06192997787399849 | validation: 0.177296592795714]
	TIME [epoch: 6.46 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0681056009795545		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.0681056009795545 | validation: 0.17264682034366677]
	TIME [epoch: 6.43 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07086611762262468		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.07086611762262468 | validation: 0.189468193231017]
	TIME [epoch: 6.42 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06668434967026282		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.06668434967026282 | validation: 0.1795614269967523]
	TIME [epoch: 6.42 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07132530473733521		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.07132530473733521 | validation: 0.17345205261392443]
	TIME [epoch: 6.42 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07256119276066278		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.07256119276066278 | validation: 0.17801533411564335]
	TIME [epoch: 6.42 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06948452034704718		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.06948452034704718 | validation: 0.18732351361813243]
	TIME [epoch: 6.43 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07126340795494936		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.07126340795494936 | validation: 0.18046048919817678]
	TIME [epoch: 6.45 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06657641896442121		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.06657641896442121 | validation: 0.19750679286562395]
	TIME [epoch: 6.42 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06881141465047405		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.06881141465047405 | validation: 0.20858842905483876]
	TIME [epoch: 6.43 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06822937043724357		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.06822937043724357 | validation: 0.18504878579970094]
	TIME [epoch: 6.43 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06913878274671045		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.06913878274671045 | validation: 0.18486369962350283]
	TIME [epoch: 6.43 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06611707522104389		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.06611707522104389 | validation: 0.1765684876438487]
	TIME [epoch: 6.42 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0647520132147365		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.0647520132147365 | validation: 0.18163284848786163]
	TIME [epoch: 6.45 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06932417829631546		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.06932417829631546 | validation: 0.1891600928839452]
	TIME [epoch: 6.43 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06744937506771295		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.06744937506771295 | validation: 0.16915473715540916]
	TIME [epoch: 6.43 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06777014389570896		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.06777014389570896 | validation: 0.17730999342827083]
	TIME [epoch: 6.41 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06917234556362657		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.06917234556362657 | validation: 0.19406984975214697]
	TIME [epoch: 6.44 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07231622309922826		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.07231622309922826 | validation: 0.1861179904397149]
	TIME [epoch: 6.43 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07100345320431152		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.07100345320431152 | validation: 0.16941194863638476]
	TIME [epoch: 6.42 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06541550663339023		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.06541550663339023 | validation: 0.18577351647638388]
	TIME [epoch: 6.45 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06798606489076212		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.06798606489076212 | validation: 0.18306361928308953]
	TIME [epoch: 6.44 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06721461884249233		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.06721461884249233 | validation: 0.18413097351345475]
	TIME [epoch: 6.42 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06763043491473407		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.06763043491473407 | validation: 0.1630544682009252]
	TIME [epoch: 6.44 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06902278697212728		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.06902278697212728 | validation: 0.16362974942717848]
	TIME [epoch: 6.42 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06695437695540488		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.06695437695540488 | validation: 0.1718916879900948]
	TIME [epoch: 6.42 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06923487837641355		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.06923487837641355 | validation: 0.18720362805026514]
	TIME [epoch: 6.43 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08363214855803648		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.08363214855803648 | validation: 0.17880437948303887]
	TIME [epoch: 6.44 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0689533321081232		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.0689533321081232 | validation: 0.16773425041695889]
	TIME [epoch: 6.43 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07053655652342798		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.07053655652342798 | validation: 0.18611003695478132]
	TIME [epoch: 6.41 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07291229495350449		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.07291229495350449 | validation: 0.2070052417797691]
	TIME [epoch: 6.43 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07155681782948321		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.07155681782948321 | validation: 0.19408271442784794]
	TIME [epoch: 6.42 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07286014589708222		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.07286014589708222 | validation: 0.1905518914558434]
	TIME [epoch: 6.42 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06892121547687731		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.06892121547687731 | validation: 0.193768328790519]
	TIME [epoch: 6.45 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0720107713563091		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.0720107713563091 | validation: 0.18402597639084092]
	TIME [epoch: 6.44 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06652786415525393		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.06652786415525393 | validation: 0.17370905602616546]
	TIME [epoch: 6.42 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06753555252644879		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.06753555252644879 | validation: 0.18107568739073812]
	TIME [epoch: 6.44 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06743896020171102		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.06743896020171102 | validation: 0.19191559401516123]
	TIME [epoch: 6.41 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07283011589345922		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.07283011589345922 | validation: 0.20229350858935932]
	TIME [epoch: 6.42 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07033479439489311		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.07033479439489311 | validation: 0.20756375268519558]
	TIME [epoch: 6.42 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06936186943556734		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.06936186943556734 | validation: 0.19470190847129154]
	TIME [epoch: 6.47 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07158541951967874		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.07158541951967874 | validation: 0.19060085660993495]
	TIME [epoch: 6.42 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0708437676421548		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.0708437676421548 | validation: 0.19050238506950437]
	TIME [epoch: 6.44 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07318078341836236		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.07318078341836236 | validation: 0.20763250542512596]
	TIME [epoch: 6.44 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07401313125871738		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.07401313125871738 | validation: 0.19593448448405912]
	TIME [epoch: 6.44 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0700480686799064		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.0700480686799064 | validation: 0.17920942006194487]
	TIME [epoch: 6.44 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06798601619179069		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.06798601619179069 | validation: 0.18854537038332594]
	TIME [epoch: 6.45 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07108430737596108		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.07108430737596108 | validation: 0.18393211531634077]
	TIME [epoch: 6.44 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0662891217882053		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.0662891217882053 | validation: 0.18754423279377702]
	TIME [epoch: 6.42 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06811231627937278		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.06811231627937278 | validation: 0.18484111272790624]
	TIME [epoch: 6.42 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06766088101749246		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.06766088101749246 | validation: 0.18265596111636448]
	TIME [epoch: 6.42 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06855289682372206		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.06855289682372206 | validation: 0.1787791690153454]
	TIME [epoch: 6.4 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06642085822229964		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.06642085822229964 | validation: 0.17531155754632566]
	TIME [epoch: 6.41 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06625490144405946		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.06625490144405946 | validation: 0.1573782664797532]
	TIME [epoch: 6.43 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07039950839693493		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.07039950839693493 | validation: 0.16337775478571337]
	TIME [epoch: 6.41 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07176750455955647		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.07176750455955647 | validation: 0.17578613988107872]
	TIME [epoch: 6.41 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07753126610696122		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.07753126610696122 | validation: 0.18706731640359578]
	TIME [epoch: 6.41 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07905330458805897		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.07905330458805897 | validation: 0.18448431039387422]
	TIME [epoch: 6.41 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07091368681589297		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.07091368681589297 | validation: 0.18312176541711778]
	TIME [epoch: 6.41 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06912743769747696		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.06912743769747696 | validation: 0.18609648772327567]
	TIME [epoch: 6.42 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06731017387614933		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.06731017387614933 | validation: 0.1846943631391232]
	TIME [epoch: 6.44 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06818475171357892		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.06818475171357892 | validation: 0.1826752769949057]
	TIME [epoch: 6.42 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06781114894957078		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.06781114894957078 | validation: 0.18967877636784153]
	TIME [epoch: 6.41 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07005753507934458		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.07005753507934458 | validation: 0.1914144618974668]
	TIME [epoch: 6.41 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07154328346186357		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.07154328346186357 | validation: 0.17486934449866873]
	TIME [epoch: 6.42 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06629529661980267		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.06629529661980267 | validation: 0.1855719759084598]
	TIME [epoch: 6.39 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06785242973738671		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.06785242973738671 | validation: 0.1790048791708052]
	TIME [epoch: 6.44 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06919245451187074		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.06919245451187074 | validation: 0.19649349407739147]
	TIME [epoch: 6.43 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06952641607020231		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.06952641607020231 | validation: 0.1936806688293581]
	TIME [epoch: 6.42 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06891812377480266		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.06891812377480266 | validation: 0.19169956545312927]
	TIME [epoch: 6.42 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07369451811623479		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.07369451811623479 | validation: 0.18763336409106748]
	TIME [epoch: 6.42 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06771644699908137		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.06771644699908137 | validation: 0.17846563613321295]
	TIME [epoch: 6.42 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06454590052455211		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.06454590052455211 | validation: 0.17879406413920973]
	TIME [epoch: 6.42 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0646958868235033		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.0646958868235033 | validation: 0.18746658210865297]
	TIME [epoch: 6.46 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06467613608010558		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.06467613608010558 | validation: 0.1751436280009112]
	TIME [epoch: 6.43 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06469505166961265		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.06469505166961265 | validation: 0.195040747578189]
	TIME [epoch: 6.43 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06808583222325387		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.06808583222325387 | validation: 0.18087991871165315]
	TIME [epoch: 6.43 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06955376152153805		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.06955376152153805 | validation: 0.20098232650851608]
	TIME [epoch: 6.44 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0703853240805559		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.0703853240805559 | validation: 0.19175791889830865]
	TIME [epoch: 6.43 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06845341750191324		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.06845341750191324 | validation: 0.16848949540937608]
	TIME [epoch: 6.44 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06979962700247272		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.06979962700247272 | validation: 0.1747040565939509]
	TIME [epoch: 6.46 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06567875877390716		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.06567875877390716 | validation: 0.17683147466875376]
	TIME [epoch: 6.43 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07069850558151225		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.07069850558151225 | validation: 0.1929267602054745]
	TIME [epoch: 6.43 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06880047005788234		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.06880047005788234 | validation: 0.18335968218230853]
	TIME [epoch: 6.43 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06666314787147981		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.06666314787147981 | validation: 0.18062704053435683]
	TIME [epoch: 6.43 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06506467130088002		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.06506467130088002 | validation: 0.18150686873688276]
	TIME [epoch: 6.43 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06821272821316984		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.06821272821316984 | validation: 0.1886342253759016]
	TIME [epoch: 6.47 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06941030356012735		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.06941030356012735 | validation: 0.18468841668803834]
	TIME [epoch: 6.43 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06616679450426541		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.06616679450426541 | validation: 0.18260733151928385]
	TIME [epoch: 6.43 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06630826855775486		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.06630826855775486 | validation: 0.18134545049792117]
	TIME [epoch: 6.43 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06606698162197656		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.06606698162197656 | validation: 0.19428213751816714]
	TIME [epoch: 6.42 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07038488296391321		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.07038488296391321 | validation: 0.18232754483435082]
	TIME [epoch: 6.43 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06628947112583075		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.06628947112583075 | validation: 0.18239089134613592]
	TIME [epoch: 6.42 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.068351696081805		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.068351696081805 | validation: 0.18557368829540863]
	TIME [epoch: 6.47 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0683674631225401		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.0683674631225401 | validation: 0.18205572116354574]
	TIME [epoch: 6.44 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0707272194543744		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.0707272194543744 | validation: 0.17662838635263511]
	TIME [epoch: 6.43 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06752411339529146		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.06752411339529146 | validation: 0.17897666827341246]
	TIME [epoch: 6.43 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07000908156553451		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.07000908156553451 | validation: 0.1824116544169078]
	TIME [epoch: 6.43 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06538367965119099		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.06538367965119099 | validation: 0.18350212586317255]
	TIME [epoch: 6.43 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06864690687357886		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.06864690687357886 | validation: 0.18803301188916607]
	TIME [epoch: 6.47 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06832999214072794		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.06832999214072794 | validation: 0.1706182667262104]
	TIME [epoch: 6.44 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06299762988159116		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.06299762988159116 | validation: 0.1631047137666922]
	TIME [epoch: 6.43 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06550656811927114		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.06550656811927114 | validation: 0.16726200300411273]
	TIME [epoch: 6.43 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06807669825321644		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.06807669825321644 | validation: 0.16634810818171109]
	TIME [epoch: 6.43 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07109783958976171		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.07109783958976171 | validation: 0.16513246070902354]
	TIME [epoch: 6.41 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07081611071234661		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.07081611071234661 | validation: 0.17308621748507244]
	TIME [epoch: 6.42 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06646802031630211		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.06646802031630211 | validation: 0.17241825792303458]
	TIME [epoch: 6.46 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06257965924822481		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.06257965924822481 | validation: 0.17880180694697406]
	TIME [epoch: 6.42 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06650041541340412		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.06650041541340412 | validation: 0.17129171386133227]
	TIME [epoch: 6.42 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07204183845716489		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.07204183845716489 | validation: 0.18949001958780465]
	TIME [epoch: 6.42 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07045529971454403		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.07045529971454403 | validation: 0.17053779094559995]
	TIME [epoch: 6.42 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0686215404049912		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.0686215404049912 | validation: 0.1789218981246921]
	TIME [epoch: 6.41 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0671854774484172		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.0671854774484172 | validation: 0.16975420077556266]
	TIME [epoch: 6.42 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06706413700810956		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.06706413700810956 | validation: 0.16724460707400707]
	TIME [epoch: 6.45 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06544338922693443		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.06544338922693443 | validation: 0.1718253291474116]
	TIME [epoch: 6.42 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06558795005406508		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.06558795005406508 | validation: 0.1631200528661275]
	TIME [epoch: 6.42 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06419261639987464		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.06419261639987464 | validation: 0.16261874952988503]
	TIME [epoch: 6.42 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06863179884482078		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.06863179884482078 | validation: 0.1759239964138414]
	TIME [epoch: 6.42 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06873508637117465		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.06873508637117465 | validation: 0.16865078888441765]
	TIME [epoch: 6.42 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06749446716107524		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.06749446716107524 | validation: 0.17444758702968197]
	TIME [epoch: 6.45 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06714932908838131		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.06714932908838131 | validation: 0.18125534424150452]
	TIME [epoch: 6.43 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06421141821981194		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.06421141821981194 | validation: 0.16791597680795875]
	TIME [epoch: 6.42 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06763671428121962		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.06763671428121962 | validation: 0.1691871778311453]
	TIME [epoch: 6.42 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06910738034628375		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.06910738034628375 | validation: 0.18983246450656438]
	TIME [epoch: 6.43 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0696258157217132		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.0696258157217132 | validation: 0.17993406658392444]
	TIME [epoch: 6.44 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06269660007475776		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.06269660007475776 | validation: 0.18655429856539116]
	TIME [epoch: 6.44 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06829948690608217		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.06829948690608217 | validation: 0.20476392019883866]
	TIME [epoch: 6.47 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07115109645755051		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.07115109645755051 | validation: 0.20013936890226317]
	TIME [epoch: 6.44 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07166595794316877		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.07166595794316877 | validation: 0.19870145507608925]
	TIME [epoch: 6.44 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0753699785012683		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.0753699785012683 | validation: 0.20710403759836907]
	TIME [epoch: 6.43 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07290932024900108		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.07290932024900108 | validation: 0.19562883660665187]
	TIME [epoch: 6.43 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06660560902878991		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.06660560902878991 | validation: 0.18975487145807188]
	TIME [epoch: 6.43 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06548026383856191		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.06548026383856191 | validation: 0.18532949928611295]
	TIME [epoch: 6.44 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06924808746520181		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.06924808746520181 | validation: 0.1837684869387973]
	TIME [epoch: 6.46 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06674770856970147		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.06674770856970147 | validation: 0.17321673363308748]
	TIME [epoch: 6.43 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06390963529480712		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.06390963529480712 | validation: 0.17529333857019638]
	TIME [epoch: 6.43 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07039397873135834		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.07039397873135834 | validation: 0.17558824580066965]
	TIME [epoch: 6.43 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06917253059479048		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.06917253059479048 | validation: 0.1825312992872516]
	TIME [epoch: 6.42 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06715262395164773		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.06715262395164773 | validation: 0.18371001687548982]
	TIME [epoch: 6.44 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06933661551210041		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.06933661551210041 | validation: 0.17840988445829317]
	TIME [epoch: 6.45 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0695914565185299		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.0695914565185299 | validation: 0.17193232082166404]
	TIME [epoch: 6.44 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05974179467580029		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.05974179467580029 | validation: 0.17145623619014702]
	TIME [epoch: 6.43 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06663849590073145		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.06663849590073145 | validation: 0.1587030921991257]
	TIME [epoch: 6.43 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06374133313449919		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.06374133313449919 | validation: 0.1558034302281596]
	TIME [epoch: 6.41 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06911211952302583		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.06911211952302583 | validation: 0.1706257871523097]
	TIME [epoch: 6.42 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06443371196959283		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.06443371196959283 | validation: 0.1609807674803745]
	TIME [epoch: 6.44 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06812308469948801		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.06812308469948801 | validation: 0.16625038350818547]
	TIME [epoch: 6.47 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06498238892560901		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.06498238892560901 | validation: 0.17532135527458487]
	TIME [epoch: 6.44 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06436696625463258		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.06436696625463258 | validation: 0.17406439679576324]
	TIME [epoch: 6.44 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0700601991378873		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.0700601991378873 | validation: 0.17338177250335624]
	TIME [epoch: 6.42 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06560418777466505		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.06560418777466505 | validation: 0.17266679422182904]
	TIME [epoch: 6.42 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06660281109112828		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.06660281109112828 | validation: 0.17160164521824833]
	TIME [epoch: 6.42 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07063019871433718		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.07063019871433718 | validation: 0.18069026920022435]
	TIME [epoch: 6.45 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06891720203873176		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.06891720203873176 | validation: 0.17878915286457264]
	TIME [epoch: 6.43 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0657795903658753		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.0657795903658753 | validation: 0.18219434165446707]
	TIME [epoch: 6.42 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07106824485471233		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.07106824485471233 | validation: 0.18048510027772344]
	TIME [epoch: 6.42 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06422811640143554		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.06422811640143554 | validation: 0.16928227105746638]
	TIME [epoch: 6.42 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0685271364706608		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.0685271364706608 | validation: 0.17277377910255204]
	TIME [epoch: 6.43 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06803575153617214		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.06803575153617214 | validation: 0.1829130071475374]
	TIME [epoch: 6.43 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07150635984692359		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.07150635984692359 | validation: 0.19058039219805342]
	TIME [epoch: 6.46 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07009798872502634		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.07009798872502634 | validation: 0.18137782931651508]
	TIME [epoch: 6.43 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07094843396868127		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.07094843396868127 | validation: 0.1970337959724779]
	TIME [epoch: 6.43 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07271199101063554		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.07271199101063554 | validation: 0.18587068264052115]
	TIME [epoch: 6.43 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07481194850905028		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.07481194850905028 | validation: 0.18913377885195395]
	TIME [epoch: 6.44 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06544791309947769		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.06544791309947769 | validation: 0.17717469948949152]
	TIME [epoch: 6.44 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06680659360847208		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.06680659360847208 | validation: 0.1674996971544425]
	TIME [epoch: 6.43 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06713618058321257		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.06713618058321257 | validation: 0.18515422642503984]
	TIME [epoch: 6.46 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06942927078892179		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.06942927078892179 | validation: 0.17945387919425707]
	TIME [epoch: 6.42 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06756332618972084		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.06756332618972084 | validation: 0.17830426228064106]
	TIME [epoch: 6.42 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0676114527797074		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.0676114527797074 | validation: 0.1781520135302082]
	TIME [epoch: 6.42 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06646104536247088		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.06646104536247088 | validation: 0.17770969688994862]
	TIME [epoch: 6.42 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06333446942587062		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.06333446942587062 | validation: 0.17065457225023672]
	TIME [epoch: 6.43 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06243288401865837		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.06243288401865837 | validation: 0.17314165130100975]
	TIME [epoch: 6.46 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06722111553469691		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.06722111553469691 | validation: 0.1746483477200603]
	TIME [epoch: 6.44 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06889677052788429		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.06889677052788429 | validation: 0.1866419967836811]
	TIME [epoch: 6.43 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06793595295455486		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.06793595295455486 | validation: 0.1798412243085871]
	TIME [epoch: 6.42 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.067110083853022		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.067110083853022 | validation: 0.18242949403640155]
	TIME [epoch: 6.43 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06757659539554217		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.06757659539554217 | validation: 0.19122018572989727]
	TIME [epoch: 6.43 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06446124514583051		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.06446124514583051 | validation: 0.19518749721756684]
	TIME [epoch: 6.44 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06755164250484841		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.06755164250484841 | validation: 0.17563178000034177]
	TIME [epoch: 6.46 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06361510693357893		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.06361510693357893 | validation: 0.17214350047103522]
	TIME [epoch: 6.42 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0633883795045049		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.0633883795045049 | validation: 0.17199346710771948]
	TIME [epoch: 6.42 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0629197104503906		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.0629197104503906 | validation: 0.1720489263937498]
	TIME [epoch: 6.42 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0677695413214593		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.0677695413214593 | validation: 0.17547737569354588]
	TIME [epoch: 6.43 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06804650202255462		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.06804650202255462 | validation: 0.16117024456946025]
	TIME [epoch: 6.44 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06467435531129963		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.06467435531129963 | validation: 0.16335387950166172]
	TIME [epoch: 6.43 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06541963940190976		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.06541963940190976 | validation: 0.17635727578233681]
	TIME [epoch: 6.44 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06810649124118207		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.06810649124118207 | validation: 0.16889298859561158]
	TIME [epoch: 6.42 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06203635876666748		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.06203635876666748 | validation: 0.16742616908478197]
	TIME [epoch: 6.42 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06381672923357007		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.06381672923357007 | validation: 0.17224164185743404]
	TIME [epoch: 6.43 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06169109400930968		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.06169109400930968 | validation: 0.15501678107595976]
	TIME [epoch: 6.42 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0635925070196591		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.0635925070196591 | validation: 0.1709617009506791]
	TIME [epoch: 6.43 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06534294488930356		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.06534294488930356 | validation: 0.15570131554006167]
	TIME [epoch: 6.46 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06493590872932337		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.06493590872932337 | validation: 0.15543597634693362]
	TIME [epoch: 6.44 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.068630636960543		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.068630636960543 | validation: 0.1579429700841796]
	TIME [epoch: 6.43 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06508980892441467		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.06508980892441467 | validation: 0.14932420926873]
	TIME [epoch: 6.42 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06685408335536105		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.06685408335536105 | validation: 0.1468870700973129]
	TIME [epoch: 6.42 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06573847794611153		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.06573847794611153 | validation: 0.16489599867253035]
	TIME [epoch: 6.44 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06774883866505194		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.06774883866505194 | validation: 0.1660763174313653]
	TIME [epoch: 6.44 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06221935154736352		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.06221935154736352 | validation: 0.16215246946442727]
	TIME [epoch: 6.46 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06451042134160548		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.06451042134160548 | validation: 0.1732600340181004]
	TIME [epoch: 6.43 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06625408889631162		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.06625408889631162 | validation: 0.16340884746178921]
	TIME [epoch: 6.43 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06475850014295302		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.06475850014295302 | validation: 0.15928652756282727]
	TIME [epoch: 6.42 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06501412272520499		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.06501412272520499 | validation: 0.15904557977620493]
	TIME [epoch: 6.44 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0687672870770785		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.0687672870770785 | validation: 0.1659907263483025]
	TIME [epoch: 6.43 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06588323427728832		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.06588323427728832 | validation: 0.1680128478489465]
	TIME [epoch: 6.47 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0687222650118541		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.0687222650118541 | validation: 0.17510799401303564]
	TIME [epoch: 6.43 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06769220084134861		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.06769220084134861 | validation: 0.1694781308699956]
	TIME [epoch: 6.43 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0679997304288732		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.0679997304288732 | validation: 0.1815222947735367]
	TIME [epoch: 6.42 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0674477254566624		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.0674477254566624 | validation: 0.16803298323838115]
	TIME [epoch: 6.43 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0636198526656808		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.0636198526656808 | validation: 0.18725639281832293]
	TIME [epoch: 6.43 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0651740499611191		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.0651740499611191 | validation: 0.17657711894686176]
	TIME [epoch: 6.43 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06541559540927237		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.06541559540927237 | validation: 0.17225102601214054]
	TIME [epoch: 6.45 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06531623529074632		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.06531623529074632 | validation: 0.17341825789905083]
	TIME [epoch: 6.42 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06890094616572343		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.06890094616572343 | validation: 0.17038718453971163]
	TIME [epoch: 6.42 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06850154070257523		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.06850154070257523 | validation: 0.1858337776014659]
	TIME [epoch: 6.42 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06787270724823931		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.06787270724823931 | validation: 0.18044708738226078]
	TIME [epoch: 6.43 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06832295651589845		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.06832295651589845 | validation: 0.1818716710898587]
	TIME [epoch: 6.43 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06616417661587676		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.06616417661587676 | validation: 0.17879455802706254]
	TIME [epoch: 6.43 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06190885543918301		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.06190885543918301 | validation: 0.17481819140876334]
	TIME [epoch: 6.46 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0663488096852536		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.0663488096852536 | validation: 0.17470674712863474]
	TIME [epoch: 6.43 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06887774489398744		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.06887774489398744 | validation: 0.1734551312322607]
	TIME [epoch: 6.43 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058662223787585906		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.058662223787585906 | validation: 0.17662928385326904]
	TIME [epoch: 6.42 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06517410391991964		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.06517410391991964 | validation: 0.19277799332658319]
	TIME [epoch: 6.43 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06401634818682984		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.06401634818682984 | validation: 0.1800151377238145]
	TIME [epoch: 6.43 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06831113029355183		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.06831113029355183 | validation: 0.1736546857066174]
	TIME [epoch: 6.48 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06435858503310304		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.06435858503310304 | validation: 0.16788971570349756]
	TIME [epoch: 6.43 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06836243414302733		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.06836243414302733 | validation: 0.16311375406792053]
	TIME [epoch: 6.42 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06587353173737544		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.06587353173737544 | validation: 0.17753817930876906]
	TIME [epoch: 6.42 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05961524397771057		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.05961524397771057 | validation: 0.16574176543944416]
	TIME [epoch: 6.43 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06821674557222734		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.06821674557222734 | validation: 0.17585855425234104]
	TIME [epoch: 6.42 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06656921796285264		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.06656921796285264 | validation: 0.16868684241920615]
	TIME [epoch: 6.43 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06824176843029947		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.06824176843029947 | validation: 0.17399604664376384]
	TIME [epoch: 6.46 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0653481996258739		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.0653481996258739 | validation: 0.1662562673021396]
	TIME [epoch: 6.42 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06149206188625593		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.06149206188625593 | validation: 0.15821338376566485]
	TIME [epoch: 6.43 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06288345603226818		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.06288345603226818 | validation: 0.1681606913653939]
	TIME [epoch: 6.42 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0659623581148152		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.0659623581148152 | validation: 0.177366270740102]
	TIME [epoch: 6.41 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06766113780808818		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.06766113780808818 | validation: 0.1616350114906863]
	TIME [epoch: 6.42 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06586697171031755		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.06586697171031755 | validation: 0.1776163687022288]
	TIME [epoch: 6.46 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06583554396706057		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.06583554396706057 | validation: 0.18533139132881424]
	TIME [epoch: 6.43 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06836529499934219		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.06836529499934219 | validation: 0.18121516349234815]
	TIME [epoch: 6.42 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06850506207442159		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.06850506207442159 | validation: 0.1773442454992927]
	TIME [epoch: 6.42 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06717081323862915		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.06717081323862915 | validation: 0.17595780918601073]
	TIME [epoch: 6.42 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06736842056615844		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.06736842056615844 | validation: 0.1787363481580939]
	TIME [epoch: 6.42 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06574407079505538		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.06574407079505538 | validation: 0.17093142563471148]
	TIME [epoch: 6.41 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06349996686906245		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.06349996686906245 | validation: 0.16151911146968626]
	TIME [epoch: 6.46 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0647619519148861		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.0647619519148861 | validation: 0.1652932659631837]
	TIME [epoch: 6.43 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06685596330616103		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.06685596330616103 | validation: 0.17854425892025652]
	TIME [epoch: 6.42 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06899419607523652		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.06899419607523652 | validation: 0.17632466137179972]
	TIME [epoch: 6.43 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06911691512373663		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.06911691512373663 | validation: 0.1741161370546393]
	TIME [epoch: 6.42 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06342635703748077		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.06342635703748077 | validation: 0.1757575621138801]
	TIME [epoch: 6.43 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06655293301095216		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.06655293301095216 | validation: 0.18092319132620532]
	TIME [epoch: 6.43 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06510928640448004		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.06510928640448004 | validation: 0.17901272049494704]
	TIME [epoch: 6.45 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06695244720302718		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.06695244720302718 | validation: 0.1621398801613919]
	TIME [epoch: 6.42 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06719174962268745		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.06719174962268745 | validation: 0.17781424467494839]
	TIME [epoch: 6.42 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06549947776640722		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.06549947776640722 | validation: 0.1805580837299566]
	TIME [epoch: 6.43 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062193741869208535		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.062193741869208535 | validation: 0.17026480653647916]
	TIME [epoch: 6.41 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06758297336748799		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.06758297336748799 | validation: 0.16769727307490512]
	TIME [epoch: 6.42 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06911225412367894		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.06911225412367894 | validation: 0.16406064059435657]
	TIME [epoch: 6.45 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0652074809424921		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.0652074809424921 | validation: 0.17528777418434058]
	TIME [epoch: 6.44 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06479894413509546		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.06479894413509546 | validation: 0.16886833732074563]
	TIME [epoch: 6.43 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06466217128283486		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.06466217128283486 | validation: 0.16971864631990058]
	TIME [epoch: 6.43 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06524238922728062		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.06524238922728062 | validation: 0.16643280250322856]
	TIME [epoch: 6.42 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06450460316647726		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.06450460316647726 | validation: 0.16543195706280986]
	TIME [epoch: 6.42 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06346045906076198		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.06346045906076198 | validation: 0.17749743256093045]
	TIME [epoch: 6.42 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0677614897593052		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.0677614897593052 | validation: 0.1658432595341156]
	TIME [epoch: 6.46 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06315226258212354		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.06315226258212354 | validation: 0.1708654511948428]
	TIME [epoch: 6.44 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06633696231366915		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.06633696231366915 | validation: 0.16618303351585795]
	TIME [epoch: 6.42 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06143710507429227		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.06143710507429227 | validation: 0.1781654671264721]
	TIME [epoch: 6.41 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06839215099794876		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.06839215099794876 | validation: 0.1654114980868107]
	TIME [epoch: 6.42 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06362386289284816		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.06362386289284816 | validation: 0.16641764277086857]
	TIME [epoch: 6.42 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06742856175200657		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.06742856175200657 | validation: 0.1700050584141216]
	TIME [epoch: 6.44 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06510005463074689		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.06510005463074689 | validation: 0.18350724692087855]
	TIME [epoch: 6.44 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06749819131107732		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.06749819131107732 | validation: 0.18347044740417195]
	TIME [epoch: 6.42 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06516650066320168		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.06516650066320168 | validation: 0.1833852222647225]
	TIME [epoch: 6.43 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06404831935480935		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.06404831935480935 | validation: 0.17473241921160743]
	TIME [epoch: 6.44 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060485466491538215		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.060485466491538215 | validation: 0.17688433726669672]
	TIME [epoch: 6.42 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06325768475068186		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.06325768475068186 | validation: 0.16174965791549561]
	TIME [epoch: 6.42 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06658843295476236		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.06658843295476236 | validation: 0.16910635731407894]
	TIME [epoch: 6.46 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06462287296337088		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.06462287296337088 | validation: 0.17654839780138026]
	TIME [epoch: 6.42 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06554623984573693		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.06554623984573693 | validation: 0.15724583476442966]
	TIME [epoch: 6.42 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06341692874316995		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.06341692874316995 | validation: 0.1667570442932389]
	TIME [epoch: 6.42 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06583062958429119		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.06583062958429119 | validation: 0.17648842354005573]
	TIME [epoch: 6.42 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06827148883405515		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.06827148883405515 | validation: 0.18514973206423566]
	TIME [epoch: 6.43 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06848917572508106		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.06848917572508106 | validation: 0.17191518392241173]
	TIME [epoch: 6.43 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06201473979133582		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.06201473979133582 | validation: 0.17947393948332407]
	TIME [epoch: 6.47 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0633468495203251		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.0633468495203251 | validation: 0.18557993667468267]
	TIME [epoch: 6.44 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06376138090512412		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.06376138090512412 | validation: 0.1698395756565708]
	TIME [epoch: 6.43 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06609845773968442		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.06609845773968442 | validation: 0.18146980687428169]
	TIME [epoch: 6.43 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06622851246679896		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.06622851246679896 | validation: 0.18280918945091088]
	TIME [epoch: 6.43 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06551667587690654		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.06551667587690654 | validation: 0.17541821954787812]
	TIME [epoch: 6.43 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06307209140396405		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.06307209140396405 | validation: 0.1714066093572992]
	TIME [epoch: 6.45 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059725775074925616		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.059725775074925616 | validation: 0.15879551440414]
	TIME [epoch: 6.44 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06258103547314542		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.06258103547314542 | validation: 0.1790179835722819]
	TIME [epoch: 6.43 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06249970300913035		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.06249970300913035 | validation: 0.17428139021337735]
	TIME [epoch: 6.42 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06844462404710122		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.06844462404710122 | validation: 0.16937110065559866]
	TIME [epoch: 6.43 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06645300703555947		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.06645300703555947 | validation: 0.16497629071018682]
	TIME [epoch: 6.43 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06636192586653883		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.06636192586653883 | validation: 0.15940451556897664]
	TIME [epoch: 6.42 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061475446816932316		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.061475446816932316 | validation: 0.16412227601854215]
	TIME [epoch: 6.47 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06428594182806174		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.06428594182806174 | validation: 0.16912128861689182]
	TIME [epoch: 6.43 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06205108761346827		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.06205108761346827 | validation: 0.1682227160925585]
	TIME [epoch: 6.43 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06629598334922669		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.06629598334922669 | validation: 0.1648928253679377]
	TIME [epoch: 6.42 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.066389984858565		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.066389984858565 | validation: 0.1648745240283664]
	TIME [epoch: 6.42 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06516460098865474		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.06516460098865474 | validation: 0.16757372879679502]
	TIME [epoch: 6.43 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06702488643918703		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.06702488643918703 | validation: 0.1651663755926497]
	TIME [epoch: 6.43 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06681778424010554		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.06681778424010554 | validation: 0.17326877217663558]
	TIME [epoch: 6.45 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06818473542748132		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.06818473542748132 | validation: 0.1760777079153911]
	TIME [epoch: 6.43 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06306476766043205		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.06306476766043205 | validation: 0.17387354482084727]
	TIME [epoch: 6.43 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062393340509791534		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.062393340509791534 | validation: 0.1652440481817414]
	TIME [epoch: 6.42 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06475451261183303		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.06475451261183303 | validation: 0.17419900512618902]
	TIME [epoch: 6.41 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0644011010255234		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.0644011010255234 | validation: 0.17151377380548746]
	TIME [epoch: 6.43 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06774211860791512		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.06774211860791512 | validation: 0.17689360428181217]
	TIME [epoch: 6.46 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06305645206762561		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.06305645206762561 | validation: 0.1605799485097085]
	TIME [epoch: 6.43 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06606117820661145		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.06606117820661145 | validation: 0.1643692944937184]
	TIME [epoch: 6.42 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06505358026905159		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.06505358026905159 | validation: 0.1706431276264223]
	TIME [epoch: 6.42 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06622689437273066		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.06622689437273066 | validation: 0.17353755973377744]
	TIME [epoch: 6.42 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06544213623110418		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.06544213623110418 | validation: 0.17169795579961603]
	TIME [epoch: 6.43 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06559656788539882		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.06559656788539882 | validation: 0.16777379662617434]
	TIME [epoch: 6.43 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06608771659632001		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.06608771659632001 | validation: 0.17056451340465625]
	TIME [epoch: 6.46 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06424853017072535		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.06424853017072535 | validation: 0.17060708078687065]
	TIME [epoch: 6.43 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06219356384860637		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.06219356384860637 | validation: 0.16653872260355318]
	TIME [epoch: 6.42 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05865012438624684		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.05865012438624684 | validation: 0.1644557530187085]
	TIME [epoch: 6.43 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06495048617372291		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.06495048617372291 | validation: 0.16587410279030423]
	TIME [epoch: 6.43 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062263525315899876		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.062263525315899876 | validation: 0.15182270129449346]
	TIME [epoch: 6.43 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06676008708343888		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.06676008708343888 | validation: 0.17187877751337755]
	TIME [epoch: 6.45 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06716580611833915		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.06716580611833915 | validation: 0.17340967078660413]
	TIME [epoch: 6.45 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06666656753740907		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.06666656753740907 | validation: 0.1849329825733736]
	TIME [epoch: 6.43 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07020991097409529		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.07020991097409529 | validation: 0.17897923986185915]
	TIME [epoch: 6.43 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06879792254149376		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.06879792254149376 | validation: 0.17477192991494597]
	TIME [epoch: 6.44 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06269588854381677		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.06269588854381677 | validation: 0.17107434988744827]
	TIME [epoch: 6.43 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06333462893394141		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.06333462893394141 | validation: 0.1578166538650371]
	TIME [epoch: 6.43 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06523664651564742		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.06523664651564742 | validation: 0.1625145672635732]
	TIME [epoch: 6.47 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06336348100862031		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.06336348100862031 | validation: 0.1656493438701324]
	TIME [epoch: 6.44 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06223939787407009		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.06223939787407009 | validation: 0.17603864719956344]
	TIME [epoch: 6.42 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05946031295199117		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.05946031295199117 | validation: 0.16492932380420683]
	TIME [epoch: 6.42 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06652427955990815		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.06652427955990815 | validation: 0.15652256019937386]
	TIME [epoch: 6.42 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06879892003251564		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.06879892003251564 | validation: 0.15138271717890311]
	TIME [epoch: 6.42 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06450460085785631		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.06450460085785631 | validation: 0.15441629103884327]
	TIME [epoch: 6.43 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06396299060049665		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.06396299060049665 | validation: 0.16289884207016456]
	TIME [epoch: 6.45 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06166583701895914		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.06166583701895914 | validation: 0.15870243980407414]
	TIME [epoch: 6.41 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06245034747664928		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.06245034747664928 | validation: 0.16420636844670428]
	TIME [epoch: 6.4 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06513811245448797		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.06513811245448797 | validation: 0.162748617430682]
	TIME [epoch: 6.4 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06284554244224441		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.06284554244224441 | validation: 0.1600942072615802]
	TIME [epoch: 6.42 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06306681655892352		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.06306681655892352 | validation: 0.15552784444779252]
	TIME [epoch: 6.4 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06757828077547803		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.06757828077547803 | validation: 0.17160299562853276]
	TIME [epoch: 6.45 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06554298949721636		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.06554298949721636 | validation: 0.17689408063900794]
	TIME [epoch: 6.41 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0672474233292055		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.0672474233292055 | validation: 0.17379311637007738]
	TIME [epoch: 6.42 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062284928074150314		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.062284928074150314 | validation: 0.16295555877670326]
	TIME [epoch: 6.41 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06489638535427218		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.06489638535427218 | validation: 0.18325947459616845]
	TIME [epoch: 6.42 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06863813454098633		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.06863813454098633 | validation: 0.18432022423953823]
	TIME [epoch: 6.41 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06741068958119548		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.06741068958119548 | validation: 0.17598846988894784]
	TIME [epoch: 6.42 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0667098802623431		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.0667098802623431 | validation: 0.1770144906077222]
	TIME [epoch: 6.44 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06608462182860987		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.06608462182860987 | validation: 0.17498336965002353]
	TIME [epoch: 6.43 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06693522835006474		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.06693522835006474 | validation: 0.17365174612352705]
	TIME [epoch: 6.4 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06464843123712187		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.06464843123712187 | validation: 0.17737970000486997]
	TIME [epoch: 6.42 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06298165007040532		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.06298165007040532 | validation: 0.16601136112868958]
	TIME [epoch: 6.42 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06170116926601685		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.06170116926601685 | validation: 0.16312899703678532]
	TIME [epoch: 6.4 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06586780899031061		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.06586780899031061 | validation: 0.15693644935412296]
	TIME [epoch: 6.41 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0650559472328231		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.0650559472328231 | validation: 0.15622095974077105]
	TIME [epoch: 6.44 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06472616485956445		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.06472616485956445 | validation: 0.15666717317206355]
	TIME [epoch: 6.42 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061997407396669715		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.061997407396669715 | validation: 0.16371050609190746]
	TIME [epoch: 6.4 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06752831815174103		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.06752831815174103 | validation: 0.1463962514436441]
	TIME [epoch: 6.41 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06350332257033728		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.06350332257033728 | validation: 0.161538952571046]
	TIME [epoch: 6.4 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06801813148494662		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.06801813148494662 | validation: 0.15512340432457156]
	TIME [epoch: 6.4 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06142260409307952		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.06142260409307952 | validation: 0.15269506116477322]
	TIME [epoch: 6.43 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06264505376332374		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.06264505376332374 | validation: 0.15611156612126048]
	TIME [epoch: 6.43 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06566582638562882		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.06566582638562882 | validation: 0.15598826780785927]
	TIME [epoch: 6.4 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06167149632925051		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.06167149632925051 | validation: 0.16171483652584467]
	TIME [epoch: 6.42 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06437068472395405		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.06437068472395405 | validation: 0.16805830405797578]
	TIME [epoch: 6.41 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0653552106752221		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.0653552106752221 | validation: 0.15955133067732516]
	TIME [epoch: 6.43 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06269910626774466		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.06269910626774466 | validation: 0.1553709633737198]
	TIME [epoch: 6.42 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06592928666259032		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.06592928666259032 | validation: 0.16176861248808827]
	TIME [epoch: 6.47 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06293221356304787		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.06293221356304787 | validation: 0.15821761202936693]
	TIME [epoch: 6.43 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06302103235767686		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.06302103235767686 | validation: 0.16239352028876256]
	TIME [epoch: 6.43 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0647621271291388		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.0647621271291388 | validation: 0.16229203945611873]
	TIME [epoch: 6.42 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06344401080981028		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.06344401080981028 | validation: 0.15977857276859145]
	TIME [epoch: 6.44 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0641641532560462		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.0641641532560462 | validation: 0.1682769018219918]
	TIME [epoch: 6.42 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06161784427806359		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.06161784427806359 | validation: 0.16484774100776062]
	TIME [epoch: 6.45 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06328833877868631		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.06328833877868631 | validation: 0.16641093412364952]
	TIME [epoch: 6.45 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06622056702877405		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.06622056702877405 | validation: 0.17023539270812835]
	TIME [epoch: 6.44 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06444244968067672		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.06444244968067672 | validation: 0.16677849400831904]
	TIME [epoch: 6.42 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06191229203197127		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.06191229203197127 | validation: 0.1659692606552283]
	TIME [epoch: 6.43 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06486338658863092		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.06486338658863092 | validation: 0.15802672447995147]
	TIME [epoch: 6.43 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06581720274758528		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.06581720274758528 | validation: 0.17016079702289105]
	TIME [epoch: 6.42 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06294596548492001		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.06294596548492001 | validation: 0.17285602465148783]
	TIME [epoch: 6.48 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06644605854803731		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.06644605854803731 | validation: 0.17009209827188662]
	TIME [epoch: 6.43 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06690867875219875		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.06690867875219875 | validation: 0.17360901501587947]
	TIME [epoch: 6.43 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06364649037584459		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.06364649037584459 | validation: 0.15774998359464976]
	TIME [epoch: 6.42 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06512605228606863		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.06512605228606863 | validation: 0.16427413106714753]
	TIME [epoch: 6.42 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06395400924473517		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.06395400924473517 | validation: 0.1700628879674824]
	TIME [epoch: 6.42 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06400670734860528		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.06400670734860528 | validation: 0.1764994066309793]
	TIME [epoch: 6.44 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06316601504509624		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.06316601504509624 | validation: 0.17134215628572474]
	TIME [epoch: 6.45 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06404879209966918		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.06404879209966918 | validation: 0.16933383907639893]
	TIME [epoch: 6.44 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06314014299724313		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.06314014299724313 | validation: 0.17624051582350783]
	TIME [epoch: 6.43 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06752248773027246		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.06752248773027246 | validation: 0.1604992104665961]
	TIME [epoch: 6.42 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06769398139711921		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.06769398139711921 | validation: 0.17830411332253035]
	TIME [epoch: 6.42 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06502402134577183		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.06502402134577183 | validation: 0.15772596889466495]
	TIME [epoch: 6.42 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06295105036182416		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.06295105036182416 | validation: 0.16242651196214258]
	TIME [epoch: 6.45 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0636230305810997		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.0636230305810997 | validation: 0.16907190422313598]
	TIME [epoch: 6.44 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06386198602190866		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.06386198602190866 | validation: 0.1735795050651636]
	TIME [epoch: 6.43 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05993582421082767		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.05993582421082767 | validation: 0.16456126792446654]
	TIME [epoch: 6.41 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06287557172160124		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.06287557172160124 | validation: 0.15887260638978798]
	TIME [epoch: 6.42 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06604464704204441		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.06604464704204441 | validation: 0.163069226022646]
	TIME [epoch: 6.43 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06397301725877298		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.06397301725877298 | validation: 0.16567738485587594]
	TIME [epoch: 6.43 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0678752707027002		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.0678752707027002 | validation: 0.1679584372499093]
	TIME [epoch: 6.45 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0622124146268595		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.0622124146268595 | validation: 0.158195968603681]
	TIME [epoch: 6.44 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0663706818404035		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.0663706818404035 | validation: 0.16005559968487507]
	TIME [epoch: 6.43 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06698305072603941		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.06698305072603941 | validation: 0.16961375886653052]
	TIME [epoch: 6.42 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06408036968831884		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.06408036968831884 | validation: 0.16761051668727003]
	TIME [epoch: 6.43 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06510322860902788		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.06510322860902788 | validation: 0.16908093298937737]
	TIME [epoch: 6.42 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0638681274247224		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.0638681274247224 | validation: 0.16862754039032887]
	TIME [epoch: 6.45 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06356514904770504		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.06356514904770504 | validation: 0.16736185172226087]
	TIME [epoch: 6.44 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0639063109080527		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.0639063109080527 | validation: 0.1650872027099654]
	TIME [epoch: 6.44 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06343364919494013		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.06343364919494013 | validation: 0.16575646311357062]
	TIME [epoch: 6.43 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06871257077783745		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.06871257077783745 | validation: 0.17302612518003466]
	TIME [epoch: 6.44 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06221995744480879		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.06221995744480879 | validation: 0.16404181613339103]
	TIME [epoch: 6.43 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06390719361381579		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.06390719361381579 | validation: 0.17123738628559398]
	TIME [epoch: 6.44 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06482137627884678		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.06482137627884678 | validation: 0.17510408675171665]
	TIME [epoch: 6.46 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0621668072461723		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.0621668072461723 | validation: 0.16882568706728568]
	TIME [epoch: 6.44 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06534572185500989		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.06534572185500989 | validation: 0.1763831111987198]
	TIME [epoch: 6.44 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06621577388107525		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.06621577388107525 | validation: 0.17140285362111793]
	TIME [epoch: 6.44 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06550804937632083		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.06550804937632083 | validation: 0.16989918157574907]
	TIME [epoch: 6.44 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06716495324944582		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.06716495324944582 | validation: 0.17116456986724216]
	TIME [epoch: 6.43 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0655223025738789		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.0655223025738789 | validation: 0.16868724574969662]
	TIME [epoch: 6.44 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0643007695496444		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.0643007695496444 | validation: 0.17496151637379226]
	TIME [epoch: 6.47 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06314032727619483		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.06314032727619483 | validation: 0.16752505454556763]
	TIME [epoch: 6.44 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06654871486011507		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.06654871486011507 | validation: 0.16797397290549654]
	TIME [epoch: 6.44 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06307154213251773		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.06307154213251773 | validation: 0.1746436246532299]
	TIME [epoch: 6.42 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062369493608043655		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.062369493608043655 | validation: 0.16284463550214306]
	TIME [epoch: 6.44 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0652998263354939		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.0652998263354939 | validation: 0.16571667224542985]
	TIME [epoch: 6.44 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06362178845767855		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.06362178845767855 | validation: 0.17578480004865368]
	TIME [epoch: 6.47 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06260944017531944		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.06260944017531944 | validation: 0.1635939855704444]
	TIME [epoch: 6.45 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06716267529690934		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.06716267529690934 | validation: 0.16399760225783136]
	TIME [epoch: 6.42 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06287061367563726		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.06287061367563726 | validation: 0.16143264834745755]
	TIME [epoch: 6.44 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06619861667607255		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.06619861667607255 | validation: 0.17635137153995054]
	TIME [epoch: 6.42 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06451042192766503		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.06451042192766503 | validation: 0.1600193716640576]
	TIME [epoch: 6.43 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0620501177946845		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.0620501177946845 | validation: 0.15489717908675396]
	TIME [epoch: 6.43 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06551833724914809		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.06551833724914809 | validation: 0.16517117178268603]
	TIME [epoch: 6.47 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06638007088166663		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.06638007088166663 | validation: 0.14741204439161779]
	TIME [epoch: 6.42 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06289915250430542		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.06289915250430542 | validation: 0.16501895488941237]
	TIME [epoch: 6.44 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06380524935381472		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.06380524935381472 | validation: 0.16943934522060908]
	TIME [epoch: 6.43 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06446846284173072		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.06446846284173072 | validation: 0.17552423998776198]
	TIME [epoch: 6.43 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06319387676421148		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.06319387676421148 | validation: 0.1739271752011328]
	TIME [epoch: 6.42 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06330457765381689		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.06330457765381689 | validation: 0.17279465068835634]
	TIME [epoch: 6.44 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06468797507866991		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.06468797507866991 | validation: 0.1707110297722684]
	TIME [epoch: 6.44 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0664520606484573		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.0664520606484573 | validation: 0.16367212113655127]
	TIME [epoch: 6.44 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060843015662301325		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.060843015662301325 | validation: 0.1670739645924763]
	TIME [epoch: 6.43 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06317240892725698		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.06317240892725698 | validation: 0.16866758480589922]
	TIME [epoch: 6.43 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06506872835280955		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.06506872835280955 | validation: 0.16672068285884975]
	TIME [epoch: 6.42 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06438165026684414		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.06438165026684414 | validation: 0.16390490730676774]
	TIME [epoch: 6.44 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0627833127721175		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.0627833127721175 | validation: 0.16506283356902565]
	TIME [epoch: 6.47 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0632327003750564		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.0632327003750564 | validation: 0.16871368043292007]
	TIME [epoch: 6.44 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06235700986147691		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.06235700986147691 | validation: 0.1687264867581821]
	TIME [epoch: 6.43 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06247728050415924		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.06247728050415924 | validation: 0.16940530117141728]
	TIME [epoch: 6.43 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06776659211778474		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.06776659211778474 | validation: 0.17171171735414373]
	TIME [epoch: 6.43 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06555422741865011		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.06555422741865011 | validation: 0.1733934752880078]
	TIME [epoch: 6.42 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06247990614060246		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.06247990614060246 | validation: 0.1753034783804696]
	TIME [epoch: 6.43 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06749967841296345		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.06749967841296345 | validation: 0.16622296414401627]
	TIME [epoch: 6.47 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06470241232092044		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.06470241232092044 | validation: 0.16897023385295726]
	TIME [epoch: 6.42 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06035065785723079		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.06035065785723079 | validation: 0.16475829736468345]
	TIME [epoch: 6.43 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06528112719953516		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.06528112719953516 | validation: 0.1597582994892601]
	TIME [epoch: 6.41 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06660084167486915		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.06660084167486915 | validation: 0.173068698944918]
	TIME [epoch: 6.42 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06386144954331179		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.06386144954331179 | validation: 0.1542973456875107]
	TIME [epoch: 6.42 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0672288058851262		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.0672288058851262 | validation: 0.16125267665139734]
	TIME [epoch: 6.47 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06653683694945262		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.06653683694945262 | validation: 0.1659664300640307]
	TIME [epoch: 6.43 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06450273140653208		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.06450273140653208 | validation: 0.16411360178894488]
	TIME [epoch: 6.43 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06291765659087438		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.06291765659087438 | validation: 0.1579729277945703]
	TIME [epoch: 6.42 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06461298625039677		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.06461298625039677 | validation: 0.16891147623426275]
	TIME [epoch: 6.43 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06184298743536748		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.06184298743536748 | validation: 0.16751576644056448]
	TIME [epoch: 6.42 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06579726464609101		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.06579726464609101 | validation: 0.1617313397976049]
	TIME [epoch: 6.42 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06319718043734457		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.06319718043734457 | validation: 0.17135471971702998]
	TIME [epoch: 6.48 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06403202229584974		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.06403202229584974 | validation: 0.1725272821477117]
	TIME [epoch: 6.42 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0632045555866595		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.0632045555866595 | validation: 0.1585995335507005]
	TIME [epoch: 6.43 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06480962616780683		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.06480962616780683 | validation: 0.16227176477422078]
	TIME [epoch: 6.41 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06837638312153499		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.06837638312153499 | validation: 0.16665607873692295]
	TIME [epoch: 6.43 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06248538530257179		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.06248538530257179 | validation: 0.16741878410569427]
	TIME [epoch: 6.42 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06467229262853305		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.06467229262853305 | validation: 0.16252159287781862]
	TIME [epoch: 6.43 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05905847961960298		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.05905847961960298 | validation: 0.16235268361661853]
	TIME [epoch: 6.45 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06209485522618126		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.06209485522618126 | validation: 0.1672067986541689]
	TIME [epoch: 6.42 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06441601718729413		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.06441601718729413 | validation: 0.15975197704263325]
	TIME [epoch: 6.43 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06702934752646371		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.06702934752646371 | validation: 0.1687117131549874]
	TIME [epoch: 6.43 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06046177343495541		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.06046177343495541 | validation: 0.16943369527611374]
	TIME [epoch: 6.42 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06605742964876835		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.06605742964876835 | validation: 0.1575156595082736]
	TIME [epoch: 6.42 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0618540573245414		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.0618540573245414 | validation: 0.1636766327635359]
	TIME [epoch: 6.44 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0660384272133622		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.0660384272133622 | validation: 0.1738310525654251]
	TIME [epoch: 6.42 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06615766130543103		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.06615766130543103 | validation: 0.16878791710604396]
	TIME [epoch: 6.41 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06408181048994953		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.06408181048994953 | validation: 0.16998019368097086]
	TIME [epoch: 6.42 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06141060935852109		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.06141060935852109 | validation: 0.16966198959420442]
	TIME [epoch: 6.42 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06552976021192587		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.06552976021192587 | validation: 0.17512625240982296]
	TIME [epoch: 6.43 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06686438348122806		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.06686438348122806 | validation: 0.1623662057245478]
	TIME [epoch: 6.44 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0676397970619117		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.0676397970619117 | validation: 0.1682879834273117]
	TIME [epoch: 6.47 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062385452548358145		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.062385452548358145 | validation: 0.15885825960929606]
	TIME [epoch: 6.44 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06780793716899484		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.06780793716899484 | validation: 0.17145072108505613]
	TIME [epoch: 6.43 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06527178068888065		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.06527178068888065 | validation: 0.1681656562837096]
	TIME [epoch: 6.44 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06578986161686042		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.06578986161686042 | validation: 0.176390732025961]
	TIME [epoch: 6.43 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0644327095293658		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.0644327095293658 | validation: 0.178245388443691]
	TIME [epoch: 6.44 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0631372311847821		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.0631372311847821 | validation: 0.1725856477117948]
	TIME [epoch: 6.45 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06321357568309804		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.06321357568309804 | validation: 0.16444502114309992]
	TIME [epoch: 6.46 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06487188812043301		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.06487188812043301 | validation: 0.16997277260616717]
	TIME [epoch: 6.43 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0625801509182228		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.0625801509182228 | validation: 0.15670473772498547]
	TIME [epoch: 6.44 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06222395725483413		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.06222395725483413 | validation: 0.1644784898402005]
	TIME [epoch: 6.41 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06424938643642465		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.06424938643642465 | validation: 0.17548487789604983]
	TIME [epoch: 6.42 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06845010106001534		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.06845010106001534 | validation: 0.1742086330413259]
	TIME [epoch: 6.42 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06457616463324804		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.06457616463324804 | validation: 0.16220737782865632]
	TIME [epoch: 6.46 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06293486685540725		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.06293486685540725 | validation: 0.16869975185128194]
	TIME [epoch: 6.42 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06017937745826328		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.06017937745826328 | validation: 0.1677128216801998]
	TIME [epoch: 6.41 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06462135765780723		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.06462135765780723 | validation: 0.17382576470023225]
	TIME [epoch: 6.4 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06399971850745091		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.06399971850745091 | validation: 0.17481872007824378]
	TIME [epoch: 6.4 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061024797761022105		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.061024797761022105 | validation: 0.17585197882659517]
	TIME [epoch: 6.39 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06493739246143804		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.06493739246143804 | validation: 0.16883039783641007]
	TIME [epoch: 6.4 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06489594037650889		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.06489594037650889 | validation: 0.17247262889530415]
	TIME [epoch: 6.43 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06745595957271261		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.06745595957271261 | validation: 0.1744800296322144]
	TIME [epoch: 6.39 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06614997840973347		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.06614997840973347 | validation: 0.17744195940777713]
	TIME [epoch: 6.4 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06629558962037108		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.06629558962037108 | validation: 0.17554495721889957]
	TIME [epoch: 6.4 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06773957110700557		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.06773957110700557 | validation: 0.17359152890152896]
	TIME [epoch: 6.4 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06897562385256481		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.06897562385256481 | validation: 0.16558691826223762]
	TIME [epoch: 6.4 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060184715358699375		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.060184715358699375 | validation: 0.16795037695877582]
	TIME [epoch: 6.43 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06380152880119914		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.06380152880119914 | validation: 0.17490944740930317]
	TIME [epoch: 6.41 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06080488743534618		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.06080488743534618 | validation: 0.16106996029345086]
	TIME [epoch: 6.4 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0666523154980621		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.0666523154980621 | validation: 0.15525572857294095]
	TIME [epoch: 6.4 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06144113750512912		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.06144113750512912 | validation: 0.1684700854068109]
	TIME [epoch: 6.4 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06615092854453639		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.06615092854453639 | validation: 0.16203893703177016]
	TIME [epoch: 6.39 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06356077973302252		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.06356077973302252 | validation: 0.159214533353157]
	TIME [epoch: 6.4 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06598601544942778		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.06598601544942778 | validation: 0.1653503111629039]
	TIME [epoch: 6.44 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06520960219170886		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.06520960219170886 | validation: 0.17208416030310048]
	TIME [epoch: 6.42 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06297998266208503		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.06297998266208503 | validation: 0.16483009700940549]
	TIME [epoch: 6.42 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06637961109583318		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.06637961109583318 | validation: 0.16552523986713502]
	TIME [epoch: 6.43 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06290531755286084		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.06290531755286084 | validation: 0.1661801741615809]
	TIME [epoch: 6.42 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06287451541838114		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.06287451541838114 | validation: 0.1613186948909922]
	TIME [epoch: 6.43 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06384726193652782		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.06384726193652782 | validation: 0.1662782314638816]
	TIME [epoch: 6.45 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06262369274438434		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.06262369274438434 | validation: 0.1675511404586408]
	TIME [epoch: 6.46 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06388364415891853		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.06388364415891853 | validation: 0.176751237526803]
	TIME [epoch: 6.44 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0628719532457225		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.0628719532457225 | validation: 0.16409247178727093]
	TIME [epoch: 6.43 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06449201397974783		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.06449201397974783 | validation: 0.17139977560795863]
	TIME [epoch: 6.43 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062465382799923336		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.062465382799923336 | validation: 0.16478799307961078]
	TIME [epoch: 6.43 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06358592150895119		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.06358592150895119 | validation: 0.17058379458592382]
	TIME [epoch: 6.43 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06254288860254016		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.06254288860254016 | validation: 0.17192118858025726]
	TIME [epoch: 6.47 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06518207764810377		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.06518207764810377 | validation: 0.16211674661824077]
	TIME [epoch: 6.44 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06583054338290598		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.06583054338290598 | validation: 0.16900465386661087]
	TIME [epoch: 6.44 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06475982854561242		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.06475982854561242 | validation: 0.1687439491733923]
	TIME [epoch: 6.44 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06466475653623148		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.06466475653623148 | validation: 0.1698391585849481]
	TIME [epoch: 6.42 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06256039841062062		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.06256039841062062 | validation: 0.16459586788303257]
	TIME [epoch: 6.42 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0644461634388836		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.0644461634388836 | validation: 0.16148087194608748]
	TIME [epoch: 6.42 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062106324286865085		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.062106324286865085 | validation: 0.16186227708913387]
	TIME [epoch: 6.45 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061674010326053894		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.061674010326053894 | validation: 0.17095916329772695]
	TIME [epoch: 6.43 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06320532928454094		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.06320532928454094 | validation: 0.1568014486978846]
	TIME [epoch: 6.43 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06345155830279131		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.06345155830279131 | validation: 0.16660809606351124]
	TIME [epoch: 6.43 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06469706006413091		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.06469706006413091 | validation: 0.15274441073834402]
	TIME [epoch: 6.44 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0637712159520934		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.0637712159520934 | validation: 0.15033185596837992]
	TIME [epoch: 6.42 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06525692488354662		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.06525692488354662 | validation: 0.14834371644027766]
	TIME [epoch: 6.44 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0648725483980803		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.0648725483980803 | validation: 0.15654367250595408]
	TIME [epoch: 6.44 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06116596226266208		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.06116596226266208 | validation: 0.16677070086236603]
	TIME [epoch: 6.42 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06157507650847796		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.06157507650847796 | validation: 0.16289387566963273]
	TIME [epoch: 6.43 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061962851458371465		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.061962851458371465 | validation: 0.1428142772535112]
	TIME [epoch: 6.42 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06492435597905909		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.06492435597905909 | validation: 0.15303861090523208]
	TIME [epoch: 6.42 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0654721196786099		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.0654721196786099 | validation: 0.1619576084671542]
	TIME [epoch: 6.41 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0655225056805583		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.0655225056805583 | validation: 0.158514280548215]
	TIME [epoch: 6.46 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06223729589098376		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.06223729589098376 | validation: 0.15347259471816796]
	TIME [epoch: 6.43 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06374533305335651		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.06374533305335651 | validation: 0.15826061511154527]
	TIME [epoch: 6.41 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0614232791055664		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.0614232791055664 | validation: 0.16601157050674373]
	TIME [epoch: 6.41 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06624320032680013		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.06624320032680013 | validation: 0.16390211735152968]
	TIME [epoch: 6.42 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06402094055043737		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.06402094055043737 | validation: 0.16255835354768117]
	TIME [epoch: 6.42 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05819175490542573		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.05819175490542573 | validation: 0.15950769891017846]
	TIME [epoch: 6.42 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0632143106394157		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.0632143106394157 | validation: 0.15793447406192868]
	TIME [epoch: 6.43 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06087463849275578		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.06087463849275578 | validation: 0.151135791155094]
	TIME [epoch: 6.41 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06388134761608		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.06388134761608 | validation: 0.16008338217436366]
	TIME [epoch: 6.4 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06351334046530441		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.06351334046530441 | validation: 0.16460207893632642]
	TIME [epoch: 6.41 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06601999915035328		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.06601999915035328 | validation: 0.1655635731286001]
	TIME [epoch: 6.42 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06279786475731047		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.06279786475731047 | validation: 0.16568985762226862]
	TIME [epoch: 6.41 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06531860587101587		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.06531860587101587 | validation: 0.1510709117512745]
	TIME [epoch: 6.44 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06160608453183358		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.06160608453183358 | validation: 0.1533534416683913]
	TIME [epoch: 6.42 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06750557762724205		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.06750557762724205 | validation: 0.1599535094839122]
	TIME [epoch: 6.41 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0654181946000176		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.0654181946000176 | validation: 0.15376072505124]
	TIME [epoch: 6.4 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06359101206860028		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.06359101206860028 | validation: 0.15752719783550728]
	TIME [epoch: 6.41 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06587523681830404		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.06587523681830404 | validation: 0.15862600135513658]
	TIME [epoch: 6.41 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06577417856372354		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.06577417856372354 | validation: 0.15856342497469475]
	TIME [epoch: 6.41 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06299223996177103		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.06299223996177103 | validation: 0.16805301772657402]
	TIME [epoch: 6.45 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06475785854899839		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.06475785854899839 | validation: 0.14851594217510927]
	TIME [epoch: 6.4 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06668420325632246		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.06668420325632246 | validation: 0.16321117291951942]
	TIME [epoch: 6.42 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06324814319887678		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.06324814319887678 | validation: 0.15844166505015797]
	TIME [epoch: 6.39 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06559892521311232		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.06559892521311232 | validation: 0.16374507371324457]
	TIME [epoch: 6.41 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06513817602781606		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.06513817602781606 | validation: 0.1536131872581623]
	TIME [epoch: 6.41 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06242688603476572		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.06242688603476572 | validation: 0.1592290158726708]
	TIME [epoch: 6.42 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0627898384213384		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.0627898384213384 | validation: 0.15415547334736276]
	TIME [epoch: 6.45 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06415319616954415		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.06415319616954415 | validation: 0.16207282747586818]
	TIME [epoch: 6.42 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06543178205149353		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.06543178205149353 | validation: 0.1624328823391218]
	TIME [epoch: 6.42 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06425735829617693		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.06425735829617693 | validation: 0.16895076306830784]
	TIME [epoch: 6.43 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06552820281959282		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.06552820281959282 | validation: 0.16781553520550319]
	TIME [epoch: 6.43 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06611145824300005		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.06611145824300005 | validation: 0.17049504283636208]
	TIME [epoch: 6.44 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06083138532820549		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.06083138532820549 | validation: 0.16723218101433673]
	TIME [epoch: 6.46 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06366240342557657		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.06366240342557657 | validation: 0.16059453661816253]
	TIME [epoch: 6.43 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06217940387097216		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.06217940387097216 | validation: 0.16524902654425877]
	TIME [epoch: 6.43 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06132996820953285		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.06132996820953285 | validation: 0.16117739967219633]
	TIME [epoch: 6.42 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0620344224225108		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.0620344224225108 | validation: 0.1654647656678739]
	TIME [epoch: 6.43 sec]
Finished training in 13045.957 seconds.
