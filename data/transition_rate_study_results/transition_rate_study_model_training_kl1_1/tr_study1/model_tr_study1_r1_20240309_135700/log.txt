Args:
Namespace(name='model_tr_study1', outdir='out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1', training_data='data/transition_rate_studies/tr_study1/tr_study1_training/r1', validation_data='data/transition_rate_studies/tr_study1/tr_study1_validation/r1', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 153762745

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.486940618380974		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.486940618380974 | validation: 13.000829333853808]
	TIME [epoch: 87.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.629975644716865		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.629975644716865 | validation: 7.254727615197923]
	TIME [epoch: 6.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.877841334575448		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.877841334575448 | validation: 9.162257258471744]
	TIME [epoch: 6.57 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.245825706580806		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.245825706580806 | validation: 6.376715817684835]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.826761487044358		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.826761487044358 | validation: 6.477066728798827]
	TIME [epoch: 6.47 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.931495819912649		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.931495819912649 | validation: 6.333317873512388]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.838206528561386		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.838206528561386 | validation: 6.576651227914031]
	TIME [epoch: 6.52 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.883649748746657		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.883649748746657 | validation: 6.5174023580593055]
	TIME [epoch: 6.46 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.872653526989008		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.872653526989008 | validation: 6.548738691175274]
	TIME [epoch: 6.45 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7808071885163965		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.7808071885163965 | validation: 6.2164507339528186]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.820520911478907		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.820520911478907 | validation: 6.364206269623644]
	TIME [epoch: 6.54 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.864530554903473		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.864530554903473 | validation: 6.168844725353281]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.597143268785397		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.597143268785397 | validation: 6.134747028146596]
	TIME [epoch: 6.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.647111455474192		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.647111455474192 | validation: 6.012108294052923]
	TIME [epoch: 6.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.519168924467598		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.519168924467598 | validation: 5.967884505452169]
	TIME [epoch: 6.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.555563748327527		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.555563748327527 | validation: 6.587773646515252]
	TIME [epoch: 6.51 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.689829400903057		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.689829400903057 | validation: 6.048230342410074]
	TIME [epoch: 6.47 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.736287317474419		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.736287317474419 | validation: 5.991824296695482]
	TIME [epoch: 6.46 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.431333238086914		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.431333238086914 | validation: 5.867621865128512]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.9250244774354375		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.9250244774354375 | validation: 6.478241014361453]
	TIME [epoch: 6.46 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.669556581410357		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.669556581410357 | validation: 5.788986403232639]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.198361881581777		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.198361881581777 | validation: 5.776022790418336]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.124600687944003		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.124600687944003 | validation: 5.605840930506497]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.252767257232978		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.252767257232978 | validation: 5.509963376713297]
	TIME [epoch: 6.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.852801300160577		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.852801300160577 | validation: 5.359416831390316]
	TIME [epoch: 6.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.120949389187626		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.120949389187626 | validation: 5.391616977340764]
	TIME [epoch: 6.56 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.870719730818212		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.870719730818212 | validation: 5.19578637541371]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.9011212672536635		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.9011212672536635 | validation: 5.811381682974805]
	TIME [epoch: 6.55 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.037969634053235		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.037969634053235 | validation: 5.214278437972557]
	TIME [epoch: 6.47 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5361681135452425		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.5361681135452425 | validation: 5.111168452518813]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.634908147972157		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.634908147972157 | validation: 5.06938010264719]
	TIME [epoch: 6.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.014480869436308		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.014480869436308 | validation: 5.472401168863292]
	TIME [epoch: 6.47 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.701716912676942		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.701716912676942 | validation: 5.016531655259609]
	TIME [epoch: 6.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.44818401234704		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.44818401234704 | validation: 4.825015096767592]
	TIME [epoch: 6.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.305610669139886		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.305610669139886 | validation: 4.956704865793951]
	TIME [epoch: 6.46 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.250152369353202		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.250152369353202 | validation: 4.8783810729099395]
	TIME [epoch: 6.46 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4780584726874215		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.4780584726874215 | validation: 4.776482319873513]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.18306823854545		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.18306823854545 | validation: 4.836241255386339]
	TIME [epoch: 6.5 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.227806372378029		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.227806372378029 | validation: 5.09699859611955]
	TIME [epoch: 6.48 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.158830931832869		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.158830931832869 | validation: 4.835140621817317]
	TIME [epoch: 6.48 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.153374074545333		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.153374074545333 | validation: 4.737626452288335]
	TIME [epoch: 6.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.052322372552467		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.052322372552467 | validation: 4.504150026335525]
	TIME [epoch: 6.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.378329168623003		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.378329168623003 | validation: 4.723203267514413]
	TIME [epoch: 6.54 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.086069541941713		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.086069541941713 | validation: 4.729010696892774]
	TIME [epoch: 6.48 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.973247901477897		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.973247901477897 | validation: 4.439981712200277]
	TIME [epoch: 6.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.769679577374875		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.769679577374875 | validation: 4.9921126003380705]
	TIME [epoch: 6.57 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.039785296535384		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.039785296535384 | validation: 4.58474609895945]
	TIME [epoch: 6.45 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.736254946256934		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.736254946256934 | validation: 4.705425068388502]
	TIME [epoch: 6.45 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8240114843306947		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8240114843306947 | validation: 4.748075835795673]
	TIME [epoch: 6.46 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.774647548921208		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.774647548921208 | validation: 4.51613771503848]
	TIME [epoch: 6.45 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7144181976606245		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 3.7144181976606245 | validation: 4.639664648379296]
	TIME [epoch: 6.46 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7394837167152764		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 3.7394837167152764 | validation: 4.836069905058544]
	TIME [epoch: 6.49 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7436024214368495		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 3.7436024214368495 | validation: 5.149278435574895]
	TIME [epoch: 6.46 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.756312041282185		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 3.756312041282185 | validation: 4.428934047682648]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.013467098214186		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 4.013467098214186 | validation: 4.291395241999982]
	TIME [epoch: 6.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5768176554521567		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 3.5768176554521567 | validation: 4.179046055935461]
	TIME [epoch: 6.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5255633791313548		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 3.5255633791313548 | validation: 4.46983655695103]
	TIME [epoch: 6.55 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6907669853345357		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 3.6907669853345357 | validation: 4.149260937184602]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.509851285892392		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 3.509851285892392 | validation: 4.234403332623266]
	TIME [epoch: 6.56 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5805291438573734		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 3.5805291438573734 | validation: 4.399696900711826]
	TIME [epoch: 6.44 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6210557249784703		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 3.6210557249784703 | validation: 3.995890179112547]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5488282942374667		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 3.5488282942374667 | validation: 4.004315341713209]
	TIME [epoch: 6.54 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.463663273866493		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 3.463663273866493 | validation: 3.964073208371521]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.328188477642712		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 3.328188477642712 | validation: 4.110809433743588]
	TIME [epoch: 6.51 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.673609080096836		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 3.673609080096836 | validation: 4.165608040850795]
	TIME [epoch: 6.46 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.412033925127779		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 3.412033925127779 | validation: 3.9125674970680384]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.220778661389169		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 3.220778661389169 | validation: 3.9722799389431254]
	TIME [epoch: 6.45 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2748822771688584		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 3.2748822771688584 | validation: 4.335002582433636]
	TIME [epoch: 6.45 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.325516116794625		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 3.325516116794625 | validation: 3.8032475256490805]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.136865273915186		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 3.136865273915186 | validation: 3.741824713320399]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_70.pth
	Model improved!!!
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9760797214811525		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 2.9760797214811525 | validation: 3.376645028393631]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1173990885074505		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 3.1173990885074505 | validation: 3.5897099833240067]
	TIME [epoch: 6.55 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8656022317516974		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 2.8656022317516974 | validation: 3.2688693253480086]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5725107123533113		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 2.5725107123533113 | validation: 2.991206424081209]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_74.pth
	Model improved!!!
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.864313178424759		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 3.864313178424759 | validation: 3.8023139212421397]
	TIME [epoch: 6.52 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8485857275991657		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 2.8485857275991657 | validation: 3.4268505957566373]
	TIME [epoch: 6.45 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3379007151579585		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 2.3379007151579585 | validation: 1.5630167890657973]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3457394026799574		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 1.3457394026799574 | validation: 1.2327846275919239]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3578632796054209		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 1.3578632796054209 | validation: 3.2668210864446388]
	TIME [epoch: 6.5 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8713690013932558		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 1.8713690013932558 | validation: 1.3798812102439184]
	TIME [epoch: 6.48 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.387568358617344		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 1.387568358617344 | validation: 1.1411798807755171]
	TIME [epoch: 6.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_81.pth
	Model improved!!!
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3967402683300991		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 1.3967402683300991 | validation: 1.3495813018837455]
	TIME [epoch: 6.51 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1882793468037605		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 1.1882793468037605 | validation: 0.8752689339307875]
	TIME [epoch: 6.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_83.pth
	Model improved!!!
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1614901764512657		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 1.1614901764512657 | validation: 1.701730036662915]
	TIME [epoch: 6.54 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.369802897281057		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 1.369802897281057 | validation: 1.6988363491086573]
	TIME [epoch: 6.46 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4695060289859416		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 1.4695060289859416 | validation: 1.3200864455249213]
	TIME [epoch: 6.49 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1075709534522407		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 1.1075709534522407 | validation: 0.8292903072456146]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_87.pth
	Model improved!!!
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.205293931806237		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 1.205293931806237 | validation: 0.8396238425143375]
	TIME [epoch: 6.46 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3902795042301312		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 1.3902795042301312 | validation: 1.1033818808916507]
	TIME [epoch: 6.46 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1578538164742769		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 1.1578538164742769 | validation: 0.9486392237378073]
	TIME [epoch: 6.46 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.066522235160639		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 1.066522235160639 | validation: 0.9207337063420861]
	TIME [epoch: 6.47 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2391263800505228		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 1.2391263800505228 | validation: 1.2368100844145908]
	TIME [epoch: 6.45 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0182071557634946		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 1.0182071557634946 | validation: 1.6307997131604663]
	TIME [epoch: 6.49 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1714250130558523		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 1.1714250130558523 | validation: 0.9537703292176768]
	TIME [epoch: 6.46 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.098694003225273		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 1.098694003225273 | validation: 1.4137752034035629]
	TIME [epoch: 6.45 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0832969999981619		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 1.0832969999981619 | validation: 0.8796756697792724]
	TIME [epoch: 6.45 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.92420179719472		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 0.92420179719472 | validation: 1.399765575236669]
	TIME [epoch: 6.45 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4159478053297516		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 1.4159478053297516 | validation: 2.503104724616779]
	TIME [epoch: 6.45 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5365815466863966		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 1.5365815466863966 | validation: 0.8040984102972215]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_99.pth
	Model improved!!!
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9307049270580374		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.9307049270580374 | validation: 0.7113986133078207]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_100.pth
	Model improved!!!
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0006461897064096		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 1.0006461897064096 | validation: 0.6476794778485949]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_101.pth
	Model improved!!!
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8517630369103151		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 0.8517630369103151 | validation: 1.1733761089612444]
	TIME [epoch: 6.45 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9793781375773198		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 0.9793781375773198 | validation: 2.3901546098848723]
	TIME [epoch: 6.45 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4082013838829073		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 1.4082013838829073 | validation: 1.3221080062532982]
	TIME [epoch: 6.45 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.086335772616371		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 1.086335772616371 | validation: 1.659178681919463]
	TIME [epoch: 6.45 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.977870874402195		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 0.977870874402195 | validation: 1.1296767918920847]
	TIME [epoch: 6.45 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.15710387563874		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 1.15710387563874 | validation: 0.6444964236321582]
	TIME [epoch: 6.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_107.pth
	Model improved!!!
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9757966984358402		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 0.9757966984358402 | validation: 2.086189780198947]
	TIME [epoch: 6.46 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.22614390177534		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 1.22614390177534 | validation: 0.7375534312511769]
	TIME [epoch: 6.45 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8507848445013233		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.8507848445013233 | validation: 0.9489686232159599]
	TIME [epoch: 6.46 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8828063974842612		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 0.8828063974842612 | validation: 1.075492346664008]
	TIME [epoch: 6.46 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7895814663660802		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 0.7895814663660802 | validation: 1.2827892742412872]
	TIME [epoch: 6.46 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9167091053166483		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 0.9167091053166483 | validation: 0.8035700475400903]
	TIME [epoch: 6.46 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.264604679309664		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 1.264604679309664 | validation: 1.0822675769156715]
	TIME [epoch: 6.49 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8670582712079529		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.8670582712079529 | validation: 0.6455954490391426]
	TIME [epoch: 6.47 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9575718882842159		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.9575718882842159 | validation: 0.932330473688843]
	TIME [epoch: 6.47 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.762626739754346		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 0.762626739754346 | validation: 0.9608252689113914]
	TIME [epoch: 6.47 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8269739965934325		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 0.8269739965934325 | validation: 0.9427881010262381]
	TIME [epoch: 6.47 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9242778077155155		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 0.9242778077155155 | validation: 0.8902217785831517]
	TIME [epoch: 6.48 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8614619384727729		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 1.8614619384727729 | validation: 0.7774162274916457]
	TIME [epoch: 6.47 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.807504211218092		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 1.807504211218092 | validation: 2.6054371677052695]
	TIME [epoch: 6.49 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6209254423554285		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 1.6209254423554285 | validation: 0.7798955502818461]
	TIME [epoch: 6.49 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7439930150235637		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 0.7439930150235637 | validation: 0.83483048961001]
	TIME [epoch: 6.48 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7920327234194029		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 0.7920327234194029 | validation: 0.9106617694790746]
	TIME [epoch: 6.48 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7085836677665774		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.7085836677665774 | validation: 0.5599698771851545]
	TIME [epoch: 6.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_125.pth
	Model improved!!!
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7393219787270003		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 0.7393219787270003 | validation: 0.5926275126461689]
	TIME [epoch: 6.53 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7174064232259719		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 0.7174064232259719 | validation: 1.414927874170363]
	TIME [epoch: 6.46 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0320508619887114		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 1.0320508619887114 | validation: 0.7639093739269369]
	TIME [epoch: 6.48 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7757830652889344		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 0.7757830652889344 | validation: 0.4220866393219986]
	TIME [epoch: 6.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_129.pth
	Model improved!!!
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7887820593839466		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.7887820593839466 | validation: 0.6146923539083476]
	TIME [epoch: 6.53 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5745020555038437		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 0.5745020555038437 | validation: 0.7438513379619217]
	TIME [epoch: 6.46 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7611629553012504		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 0.7611629553012504 | validation: 0.5544165959884754]
	TIME [epoch: 6.47 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6517182522251916		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 0.6517182522251916 | validation: 0.6165203158007337]
	TIME [epoch: 6.48 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7070548304818618		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.7070548304818618 | validation: 0.7371624757114181]
	TIME [epoch: 6.48 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7218016938360484		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.7218016938360484 | validation: 0.7465391223055188]
	TIME [epoch: 6.5 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8587748715995386		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.8587748715995386 | validation: 0.48618368019236513]
	TIME [epoch: 6.5 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6443231234922524		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 0.6443231234922524 | validation: 0.43504938028749957]
	TIME [epoch: 6.49 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8922295156982429		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 0.8922295156982429 | validation: 0.9669805591231093]
	TIME [epoch: 6.48 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6891448525492431		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 0.6891448525492431 | validation: 1.6417036530850055]
	TIME [epoch: 6.48 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9042672994578962		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.9042672994578962 | validation: 0.7910176735518732]
	TIME [epoch: 6.48 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.692646308022693		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 0.692646308022693 | validation: 0.5107929167046338]
	TIME [epoch: 6.48 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.54274697306551		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.54274697306551 | validation: 1.2030117650716197]
	TIME [epoch: 6.49 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7931439522595491		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.7931439522595491 | validation: 0.5049449546594081]
	TIME [epoch: 6.5 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6070553373710448		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 0.6070553373710448 | validation: 0.6146611659973188]
	TIME [epoch: 6.48 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6815065330281098		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.6815065330281098 | validation: 0.4742977966860466]
	TIME [epoch: 6.48 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.774490908988801		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.774490908988801 | validation: 0.42093533294323876]
	TIME [epoch: 6.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_146.pth
	Model improved!!!
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.699128732416149		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.699128732416149 | validation: 0.8876120968261478]
	TIME [epoch: 6.55 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6049971165873591		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 0.6049971165873591 | validation: 1.2625387875587648]
	TIME [epoch: 6.46 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7091259611241522		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.7091259611241522 | validation: 0.8537372289660983]
	TIME [epoch: 6.46 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7130766166225129		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.7130766166225129 | validation: 0.7060514797659974]
	TIME [epoch: 6.49 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7073508797407685		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.7073508797407685 | validation: 0.5249720333792578]
	TIME [epoch: 6.46 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.802209901991429		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.802209901991429 | validation: 0.6297855790169495]
	TIME [epoch: 6.46 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7520325597556647		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 0.7520325597556647 | validation: 0.6585532456165422]
	TIME [epoch: 6.46 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6011495394770554		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.6011495394770554 | validation: 0.6851873699555812]
	TIME [epoch: 6.46 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7321505670866478		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.7321505670866478 | validation: 0.8591540535896105]
	TIME [epoch: 6.46 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6461364105838455		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 0.6461364105838455 | validation: 1.8373416522412689]
	TIME [epoch: 6.46 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.855962834622043		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 0.855962834622043 | validation: 0.6689853706103901]
	TIME [epoch: 6.5 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6748871692064935		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 0.6748871692064935 | validation: 0.7043591195884654]
	TIME [epoch: 6.47 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.614265433320261		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.614265433320261 | validation: 0.38019332056559224]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_159.pth
	Model improved!!!
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.541120385523721		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.541120385523721 | validation: 0.5588891323986842]
	TIME [epoch: 6.53 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49650942834322637		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.49650942834322637 | validation: 0.7031334877122951]
	TIME [epoch: 6.46 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.786111931988235		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.786111931988235 | validation: 0.382245658596798]
	TIME [epoch: 6.46 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.52476991338803		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.52476991338803 | validation: 0.37085006151322814]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_163.pth
	Model improved!!!
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4679273251612419		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.4679273251612419 | validation: 0.832183724343532]
	TIME [epoch: 6.6 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9297518516639574		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.9297518516639574 | validation: 0.5864662775366472]
	TIME [epoch: 6.47 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5072201671553267		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 0.5072201671553267 | validation: 0.4000632272247786]
	TIME [epoch: 6.46 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.516808956718058		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 0.516808956718058 | validation: 0.684677915485989]
	TIME [epoch: 6.47 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5497509649128899		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.5497509649128899 | validation: 0.6849693015382908]
	TIME [epoch: 6.47 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5714863140538343		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.5714863140538343 | validation: 0.5690640242651268]
	TIME [epoch: 6.48 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4748973544662418		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.4748973544662418 | validation: 0.5316546667029863]
	TIME [epoch: 6.48 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6259887128275772		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.6259887128275772 | validation: 0.6305774229274416]
	TIME [epoch: 6.52 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5977876687966516		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.5977876687966516 | validation: 0.48172676053381014]
	TIME [epoch: 6.5 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6141558460258487		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.6141558460258487 | validation: 1.9411779088099355]
	TIME [epoch: 6.5 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0471763447029412		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 1.0471763447029412 | validation: 0.7084474335746458]
	TIME [epoch: 6.5 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5602318707303772		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.5602318707303772 | validation: 0.3592243111448531]
	TIME [epoch: 6.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_175.pth
	Model improved!!!
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5810750260049031		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 0.5810750260049031 | validation: 0.5047015279540337]
	TIME [epoch: 6.59 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6757551959512043		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.6757551959512043 | validation: 0.47338861032430274]
	TIME [epoch: 6.49 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5099677646683669		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.5099677646683669 | validation: 0.32665397183202793]
	TIME [epoch: 6.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_178.pth
	Model improved!!!
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41881087491006797		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.41881087491006797 | validation: 1.1208901296073848]
	TIME [epoch: 6.59 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5534461959763188		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.5534461959763188 | validation: 0.5298594673425938]
	TIME [epoch: 6.48 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.688894209353687		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.688894209353687 | validation: 0.5053010370209993]
	TIME [epoch: 6.48 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.646496604169947		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.646496604169947 | validation: 0.6640633462091377]
	TIME [epoch: 6.48 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39753969715941384		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.39753969715941384 | validation: 1.9024473058361588]
	TIME [epoch: 6.48 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8993072289852773		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.8993072289852773 | validation: 0.40396745817041224]
	TIME [epoch: 6.48 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5993691053459947		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.5993691053459947 | validation: 0.4134192595556252]
	TIME [epoch: 6.52 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5574221071923531		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.5574221071923531 | validation: 0.5824843836497804]
	TIME [epoch: 6.48 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5345907483809493		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.5345907483809493 | validation: 0.4317549580532414]
	TIME [epoch: 6.49 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5563667879354961		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.5563667879354961 | validation: 0.5452567980247504]
	TIME [epoch: 6.48 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4812590049332091		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.4812590049332091 | validation: 0.5941098332949284]
	TIME [epoch: 6.49 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6084166345104073		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.6084166345104073 | validation: 0.28940224573726175]
	TIME [epoch: 6.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_190.pth
	Model improved!!!
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4716323425753637		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.4716323425753637 | validation: 0.24833885297149208]
	TIME [epoch: 6.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_191.pth
	Model improved!!!
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3814154146329548		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.3814154146329548 | validation: 0.286320282346615]
	TIME [epoch: 6.6 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4348315720214971		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.4348315720214971 | validation: 0.7036381515781934]
	TIME [epoch: 6.46 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6621128952042374		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.6621128952042374 | validation: 0.5407455541938544]
	TIME [epoch: 6.48 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4792084347761536		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.4792084347761536 | validation: 0.38107010686387344]
	TIME [epoch: 6.48 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4342467017024867		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.4342467017024867 | validation: 0.8675892119619405]
	TIME [epoch: 6.47 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5037526961805916		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.5037526961805916 | validation: 0.573948445271037]
	TIME [epoch: 6.47 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43873129254788046		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.43873129254788046 | validation: 0.3490794534795271]
	TIME [epoch: 6.48 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5656658332031853		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.5656658332031853 | validation: 0.5635358433257524]
	TIME [epoch: 6.51 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6103325925177087		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.6103325925177087 | validation: 0.5432972994141615]
	TIME [epoch: 6.48 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5724129871033304		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.5724129871033304 | validation: 0.385051296395603]
	TIME [epoch: 6.48 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49309731682561797		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.49309731682561797 | validation: 0.905332490724161]
	TIME [epoch: 6.48 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.584593495180627		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.584593495180627 | validation: 0.5971238302073448]
	TIME [epoch: 6.48 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6159422708490511		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.6159422708490511 | validation: 0.5904944943991028]
	TIME [epoch: 6.48 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47568269967614024		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.47568269967614024 | validation: 0.3147279790470681]
	TIME [epoch: 6.48 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33630856609935844		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.33630856609935844 | validation: 0.7913306836631524]
	TIME [epoch: 6.51 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4705363019996298		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.4705363019996298 | validation: 0.4892648797687795]
	TIME [epoch: 6.49 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5604596261704456		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.5604596261704456 | validation: 0.46254904116300866]
	TIME [epoch: 6.49 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3945697877802102		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.3945697877802102 | validation: 0.6687702526990191]
	TIME [epoch: 6.49 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4136600034786231		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.4136600034786231 | validation: 0.32362248465471277]
	TIME [epoch: 6.49 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34293961968235825		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.34293961968235825 | validation: 0.22401011863092993]
	TIME [epoch: 6.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_211.pth
	Model improved!!!
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4059628202629906		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.4059628202629906 | validation: 0.2543051111002567]
	TIME [epoch: 6.57 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3803445269066804		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.3803445269066804 | validation: 0.8629013974374503]
	TIME [epoch: 6.51 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5137409485119758		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.5137409485119758 | validation: 0.20493889862787953]
	TIME [epoch: 6.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_214.pth
	Model improved!!!
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34382446178692316		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.34382446178692316 | validation: 1.2063373638844095]
	TIME [epoch: 6.58 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8005735617256121		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.8005735617256121 | validation: 0.7277623218143472]
	TIME [epoch: 6.48 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5808220094068666		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.5808220094068666 | validation: 0.3788173547503128]
	TIME [epoch: 6.49 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3324949345032815		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.3324949345032815 | validation: 0.5294009710670704]
	TIME [epoch: 6.5 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4217741881871854		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.4217741881871854 | validation: 0.7206898363108332]
	TIME [epoch: 6.5 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6367512529704059		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.6367512529704059 | validation: 0.7046137581797128]
	TIME [epoch: 6.54 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47139347831424594		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.47139347831424594 | validation: 0.38856425300959613]
	TIME [epoch: 6.53 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44620426206419717		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.44620426206419717 | validation: 0.21420660232663674]
	TIME [epoch: 6.51 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6173660696992711		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.6173660696992711 | validation: 0.2982439059919701]
	TIME [epoch: 6.5 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3770912075504257		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.3770912075504257 | validation: 0.3382994367579258]
	TIME [epoch: 6.5 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31865654444971087		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.31865654444971087 | validation: 0.4649832178561081]
	TIME [epoch: 6.5 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.496178219662723		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.496178219662723 | validation: 0.48026014864271105]
	TIME [epoch: 6.5 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41126016362416784		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.41126016362416784 | validation: 0.3036662228076046]
	TIME [epoch: 6.52 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35317249027092645		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.35317249027092645 | validation: 0.4748400942104311]
	TIME [epoch: 6.53 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4140752297368066		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.4140752297368066 | validation: 0.2798246201662578]
	TIME [epoch: 6.51 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3968634297823006		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.3968634297823006 | validation: 0.6335727607880304]
	TIME [epoch: 6.5 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5030128389149435		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.5030128389149435 | validation: 0.2578706816043998]
	TIME [epoch: 6.5 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2940848467138505		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.2940848467138505 | validation: 0.9461874072673178]
	TIME [epoch: 6.51 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4356130646515408		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.4356130646515408 | validation: 0.43858826172865334]
	TIME [epoch: 6.51 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6459993373947914		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.6459993373947914 | validation: 0.3743413972509211]
	TIME [epoch: 6.53 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6955123081293052		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.6955123081293052 | validation: 0.5752836992961471]
	TIME [epoch: 6.53 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4961139095842501		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.4961139095842501 | validation: 0.4273609826004799]
	TIME [epoch: 6.51 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4399881361005276		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.4399881361005276 | validation: 0.24001928417132026]
	TIME [epoch: 6.51 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6073643365559543		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.6073643365559543 | validation: 0.22936709830607502]
	TIME [epoch: 6.53 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3223724514597758		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.3223724514597758 | validation: 0.3860398073342857]
	TIME [epoch: 6.5 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5788116005421247		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.5788116005421247 | validation: 0.5159065110666008]
	TIME [epoch: 6.5 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3908478038090892		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.3908478038090892 | validation: 0.3485680223995618]
	TIME [epoch: 6.51 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4591239275040315		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.4591239275040315 | validation: 0.48629258170315853]
	TIME [epoch: 6.54 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4283396285007698		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.4283396285007698 | validation: 0.3943800817829635]
	TIME [epoch: 6.51 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.624511019262899		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.624511019262899 | validation: 0.6626292235936038]
	TIME [epoch: 6.51 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3803874716599218		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.3803874716599218 | validation: 0.4705017904899988]
	TIME [epoch: 6.51 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3356089320736655		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.3356089320736655 | validation: 1.0723992607683228]
	TIME [epoch: 6.5 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5880879660822865		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.5880879660822865 | validation: 0.254485984129842]
	TIME [epoch: 6.5 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30573920374001873		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.30573920374001873 | validation: 0.27346418931712724]
	TIME [epoch: 6.51 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3486105574513512		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.3486105574513512 | validation: 0.39905962614663465]
	TIME [epoch: 6.53 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40044667947747614		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.40044667947747614 | validation: 0.4047251501881335]
	TIME [epoch: 6.51 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5125127545314441		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.5125127545314441 | validation: 0.2825028404603339]
	TIME [epoch: 6.51 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28275070166240535		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.28275070166240535 | validation: 0.34322935132363325]
	TIME [epoch: 6.51 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3087348470642294		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.3087348470642294 | validation: 0.21218542975378124]
	TIME [epoch: 6.51 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45115703547762676		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.45115703547762676 | validation: 0.2358470671723267]
	TIME [epoch: 6.51 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3437449674978241		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.3437449674978241 | validation: 0.31428379938936873]
	TIME [epoch: 6.51 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3713608130473033		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.3713608130473033 | validation: 0.2203879645573729]
	TIME [epoch: 6.54 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2980231542191335		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.2980231542191335 | validation: 0.3317562806651375]
	TIME [epoch: 6.51 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5736812811139356		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.5736812811139356 | validation: 0.3362992784618649]
	TIME [epoch: 6.5 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37653007630300706		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.37653007630300706 | validation: 0.20470814646728605]
	TIME [epoch: 6.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_259.pth
	Model improved!!!
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3623027718320666		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.3623027718320666 | validation: 0.3844930652594674]
	TIME [epoch: 6.56 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.366000218488045		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.366000218488045 | validation: 0.42366919943037784]
	TIME [epoch: 6.5 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3628523372067244		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.3628523372067244 | validation: 0.415918517303646]
	TIME [epoch: 6.5 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4535165322857331		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.4535165322857331 | validation: 0.7499993333263502]
	TIME [epoch: 6.53 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6393409673876542		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.6393409673876542 | validation: 1.1121667024081805]
	TIME [epoch: 6.5 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6163100932647726		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.6163100932647726 | validation: 0.2654217998988351]
	TIME [epoch: 6.5 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35130986076831927		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.35130986076831927 | validation: 0.37820013366818056]
	TIME [epoch: 6.5 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34679021204925364		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.34679021204925364 | validation: 0.23798484660299488]
	TIME [epoch: 6.5 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3002816907493596		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.3002816907493596 | validation: 0.401437246491418]
	TIME [epoch: 6.5 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44531579679652716		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.44531579679652716 | validation: 0.28786956132987906]
	TIME [epoch: 6.51 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30001027531543534		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.30001027531543534 | validation: 0.5246436543441796]
	TIME [epoch: 6.54 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3729129677792661		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.3729129677792661 | validation: 0.49378366470927504]
	TIME [epoch: 6.51 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3703535739168226		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.3703535739168226 | validation: 0.21239479347633491]
	TIME [epoch: 6.5 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38007807702776		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.38007807702776 | validation: 0.6085894064255203]
	TIME [epoch: 6.5 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4680124186970992		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.4680124186970992 | validation: 0.19609545531005168]
	TIME [epoch: 6.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_274.pth
	Model improved!!!
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2629327053475628		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.2629327053475628 | validation: 0.4693905646160426]
	TIME [epoch: 6.58 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4540789937352516		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.4540789937352516 | validation: 0.337634800240527]
	TIME [epoch: 6.49 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30986250989681186		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.30986250989681186 | validation: 0.2576958725645947]
	TIME [epoch: 6.53 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2982795675229262		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.2982795675229262 | validation: 0.3049326037197033]
	TIME [epoch: 6.5 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2721993255054558		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.2721993255054558 | validation: 0.2996234915530186]
	TIME [epoch: 6.49 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3483693919858382		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.3483693919858382 | validation: 0.3803941220769062]
	TIME [epoch: 6.5 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38336490714652527		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.38336490714652527 | validation: 0.23512316464694863]
	TIME [epoch: 6.49 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21360891496506712		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.21360891496506712 | validation: 0.3217761223272004]
	TIME [epoch: 6.5 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32550047550419103		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.32550047550419103 | validation: 0.4454060689021217]
	TIME [epoch: 6.5 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41227860488796236		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.41227860488796236 | validation: 0.4270126347377772]
	TIME [epoch: 6.53 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44064781832622335		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.44064781832622335 | validation: 0.24272455611136792]
	TIME [epoch: 6.5 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33293014700669876		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.33293014700669876 | validation: 0.28653165345540155]
	TIME [epoch: 6.5 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3088641590655806		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.3088641590655806 | validation: 0.6052180442869859]
	TIME [epoch: 6.5 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6374641219866986		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.6374641219866986 | validation: 0.318341264580832]
	TIME [epoch: 6.5 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27344337080401315		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.27344337080401315 | validation: 0.3887497188006453]
	TIME [epoch: 6.51 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4022158962576454		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.4022158962576454 | validation: 0.37743385148943276]
	TIME [epoch: 6.5 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3871212239930289		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.3871212239930289 | validation: 0.5508091027491434]
	TIME [epoch: 6.54 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44475823709665213		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.44475823709665213 | validation: 0.3347282001219938]
	TIME [epoch: 6.51 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28842227627079736		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.28842227627079736 | validation: 0.23945791026678784]
	TIME [epoch: 6.5 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3337579964083828		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.3337579964083828 | validation: 0.28230764006204007]
	TIME [epoch: 6.5 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6034091069370527		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.6034091069370527 | validation: 0.4575817535351092]
	TIME [epoch: 6.5 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46068460193830485		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.46068460193830485 | validation: 0.30752272444023243]
	TIME [epoch: 6.5 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33574658289819126		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.33574658289819126 | validation: 0.27981152991614544]
	TIME [epoch: 6.5 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28106090058981403		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.28106090058981403 | validation: 0.29860018712333053]
	TIME [epoch: 6.52 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30919990458432983		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.30919990458432983 | validation: 0.6034776369592809]
	TIME [epoch: 6.52 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3395598525774019		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.3395598525774019 | validation: 0.45660590865731093]
	TIME [epoch: 6.5 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3780613926516621		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.3780613926516621 | validation: 0.36113558685665736]
	TIME [epoch: 6.51 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32655229106610384		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.32655229106610384 | validation: 0.6830301174655184]
	TIME [epoch: 6.5 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33154773366095985		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.33154773366095985 | validation: 0.3583250259062738]
	TIME [epoch: 6.5 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27211487982743954		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.27211487982743954 | validation: 0.5607643755157453]
	TIME [epoch: 6.5 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39924897427568246		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.39924897427568246 | validation: 0.42518524928932955]
	TIME [epoch: 6.51 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36151167559271397		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.36151167559271397 | validation: 0.27338679731492876]
	TIME [epoch: 6.51 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2956218386258705		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.2956218386258705 | validation: 0.2646571979854405]
	TIME [epoch: 6.49 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.301592911838932		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.301592911838932 | validation: 0.24847972420158151]
	TIME [epoch: 6.49 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31832710029679134		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.31832710029679134 | validation: 0.26845665999143736]
	TIME [epoch: 6.5 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18259928840701023		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.18259928840701023 | validation: 0.17648247018880397]
	TIME [epoch: 6.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_310.pth
	Model improved!!!
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2632703983888362		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.2632703983888362 | validation: 0.2979937361369384]
	TIME [epoch: 6.57 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2749303102635189		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.2749303102635189 | validation: 0.30142143418503525]
	TIME [epoch: 6.5 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42963763500623586		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.42963763500623586 | validation: 0.7607393216595898]
	TIME [epoch: 6.51 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4898749015857822		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.4898749015857822 | validation: 0.6253968043471781]
	TIME [epoch: 6.49 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3854285548913097		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.3854285548913097 | validation: 0.23470578017196553]
	TIME [epoch: 6.49 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24135930553328527		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.24135930553328527 | validation: 0.30818649865587716]
	TIME [epoch: 6.49 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3000675220867623		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.3000675220867623 | validation: 0.8054695442194071]
	TIME [epoch: 6.49 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5411538469641234		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.5411538469641234 | validation: 0.5290279504018014]
	TIME [epoch: 6.49 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38695340857177146		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.38695340857177146 | validation: 0.20349743786629806]
	TIME [epoch: 6.5 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.277412399814046		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.277412399814046 | validation: 0.16055488167803225]
	TIME [epoch: 6.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_320.pth
	Model improved!!!
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3324899833545357		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.3324899833545357 | validation: 0.22253826428697743]
	TIME [epoch: 6.55 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3250956922234673		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.3250956922234673 | validation: 0.25347852494676126]
	TIME [epoch: 6.48 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3209747555821256		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.3209747555821256 | validation: 0.23654287723655457]
	TIME [epoch: 6.48 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3040598351939507		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.3040598351939507 | validation: 0.5896270204347148]
	TIME [epoch: 6.48 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4097555641940673		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.4097555641940673 | validation: 0.41734989998456207]
	TIME [epoch: 6.48 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27192311593350904		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.27192311593350904 | validation: 0.2351945309842358]
	TIME [epoch: 6.49 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22468864736500996		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.22468864736500996 | validation: 0.6112781978053222]
	TIME [epoch: 6.52 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4169812705772584		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.4169812705772584 | validation: 0.4251466182878623]
	TIME [epoch: 6.49 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3146574433107443		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.3146574433107443 | validation: 0.17337745139266125]
	TIME [epoch: 6.49 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37502676218937303		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.37502676218937303 | validation: 0.32912283450417074]
	TIME [epoch: 6.49 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34355246436882275		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.34355246436882275 | validation: 0.24350908153687112]
	TIME [epoch: 6.49 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2660688890186768		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.2660688890186768 | validation: 0.19482660658247944]
	TIME [epoch: 6.5 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2972730174038425		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.2972730174038425 | validation: 0.20088915649113268]
	TIME [epoch: 6.51 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23515431889221533		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.23515431889221533 | validation: 0.28129026180308325]
	TIME [epoch: 6.53 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2261492194798578		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.2261492194798578 | validation: 0.17564840069603335]
	TIME [epoch: 6.51 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.313853586108956		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.313853586108956 | validation: 0.39830043391415665]
	TIME [epoch: 6.51 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29226275506478816		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.29226275506478816 | validation: 0.3837398400631154]
	TIME [epoch: 6.51 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31708291260791444		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.31708291260791444 | validation: 0.14104166423630649]
	TIME [epoch: 6.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_338.pth
	Model improved!!!
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21409079826318933		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.21409079826318933 | validation: 0.1624787750405239]
	TIME [epoch: 6.58 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15487842357981674		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.15487842357981674 | validation: 0.19158140880523342]
	TIME [epoch: 6.5 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2343103822356276		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.2343103822356276 | validation: 0.3673218460337243]
	TIME [epoch: 6.52 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32464704846434994		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.32464704846434994 | validation: 0.22393423846763663]
	TIME [epoch: 6.49 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21890408626120347		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.21890408626120347 | validation: 0.26828771649413674]
	TIME [epoch: 6.49 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30502547785704354		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.30502547785704354 | validation: 0.11442183706835302]
	TIME [epoch: 6.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_344.pth
	Model improved!!!
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21463395807465507		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.21463395807465507 | validation: 0.333155564919281]
	TIME [epoch: 6.58 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39358272907088854		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.39358272907088854 | validation: 0.6272202994562406]
	TIME [epoch: 6.48 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35760652285613814		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.35760652285613814 | validation: 0.37191849154747303]
	TIME [epoch: 6.49 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26469123621005863		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.26469123621005863 | validation: 0.391063730640144]
	TIME [epoch: 6.52 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2408403698760732		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.2408403698760732 | validation: 0.2873752874907159]
	TIME [epoch: 6.49 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22806805577328923		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.22806805577328923 | validation: 0.9473021312700124]
	TIME [epoch: 6.49 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4053456285822006		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.4053456285822006 | validation: 0.19340762784098506]
	TIME [epoch: 6.49 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21392198455413475		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.21392198455413475 | validation: 0.20856442698611155]
	TIME [epoch: 6.49 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19438638555536786		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.19438638555536786 | validation: 0.12308975337467129]
	TIME [epoch: 6.49 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20578804925382854		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.20578804925382854 | validation: 0.4064491886163532]
	TIME [epoch: 6.49 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.307647928806348		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.307647928806348 | validation: 0.20866141561354254]
	TIME [epoch: 6.53 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21324540415599408		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.21324540415599408 | validation: 0.20046982603549673]
	TIME [epoch: 6.51 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19756247042421754		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.19756247042421754 | validation: 0.2141865058565928]
	TIME [epoch: 6.49 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18704151881047523		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.18704151881047523 | validation: 0.26167290626782264]
	TIME [epoch: 6.49 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21252838011505515		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.21252838011505515 | validation: 0.2766578426173165]
	TIME [epoch: 6.5 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30250258656389084		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.30250258656389084 | validation: 0.30806748014293517]
	TIME [epoch: 6.5 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2775822651891416		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.2775822651891416 | validation: 0.18291059591310316]
	TIME [epoch: 6.5 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18177466663026137		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.18177466663026137 | validation: 0.2538277495716838]
	TIME [epoch: 6.54 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2286338362938664		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.2286338362938664 | validation: 0.3763155612329067]
	TIME [epoch: 6.52 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3493527126386827		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.3493527126386827 | validation: 0.21908073834172417]
	TIME [epoch: 6.5 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1918397318359714		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.1918397318359714 | validation: 0.14387760231714702]
	TIME [epoch: 6.51 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17844238589840078		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.17844238589840078 | validation: 0.13428132822990294]
	TIME [epoch: 6.51 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1692875840670771		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.1692875840670771 | validation: 0.3180172284143927]
	TIME [epoch: 6.51 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2870559092189416		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.2870559092189416 | validation: 0.35704779155449545]
	TIME [epoch: 6.51 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23700925471886725		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.23700925471886725 | validation: 0.14734400380038687]
	TIME [epoch: 6.54 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22320775048325547		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.22320775048325547 | validation: 0.16677244161081844]
	TIME [epoch: 6.51 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2147157267502176		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.2147157267502176 | validation: 0.33865868386723746]
	TIME [epoch: 6.51 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3278880584621755		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.3278880584621755 | validation: 0.2628645952829984]
	TIME [epoch: 6.5 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2249839042328486		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.2249839042328486 | validation: 0.17921946691864313]
	TIME [epoch: 6.51 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2564987606951322		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.2564987606951322 | validation: 0.2416739053427691]
	TIME [epoch: 6.51 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26538851419921144		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.26538851419921144 | validation: 0.24909087946328629]
	TIME [epoch: 6.51 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29181938393790435		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.29181938393790435 | validation: 0.20352790949768657]
	TIME [epoch: 6.55 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2183617620798301		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.2183617620798301 | validation: 0.134304735814514]
	TIME [epoch: 6.51 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20661155224135025		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.20661155224135025 | validation: 0.35524511596080727]
	TIME [epoch: 6.5 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24821894941877243		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.24821894941877243 | validation: 1.3642908868969108]
	TIME [epoch: 6.51 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7265799085902759		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.7265799085902759 | validation: 0.25703792123773733]
	TIME [epoch: 6.51 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21739696973860453		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.21739696973860453 | validation: 0.2739790459688672]
	TIME [epoch: 6.51 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22512323540096243		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.22512323540096243 | validation: 0.11151734354547874]
	TIME [epoch: 6.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_382.pth
	Model improved!!!
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.244652621064952		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.244652621064952 | validation: 0.2247997045740063]
	TIME [epoch: 6.59 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20219216086991654		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.20219216086991654 | validation: 0.25858870825546665]
	TIME [epoch: 6.49 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.253527967479056		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.253527967479056 | validation: 0.10771006367413337]
	TIME [epoch: 6.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_385.pth
	Model improved!!!
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18881352575651067		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.18881352575651067 | validation: 0.35708757200585667]
	TIME [epoch: 6.54 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29659069915183045		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.29659069915183045 | validation: 0.24201223631999824]
	TIME [epoch: 6.48 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28941397894723914		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.28941397894723914 | validation: 0.23872819113618335]
	TIME [epoch: 6.48 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2394416506138575		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.2394416506138575 | validation: 0.4443932683839354]
	TIME [epoch: 6.48 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.326354393042598		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.326354393042598 | validation: 0.4532231374731448]
	TIME [epoch: 6.5 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2106470859660942		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.2106470859660942 | validation: 0.12139147806639519]
	TIME [epoch: 6.5 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21192981234626668		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.21192981234626668 | validation: 0.11796208318529157]
	TIME [epoch: 6.49 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24178113516656824		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.24178113516656824 | validation: 0.13713690448743043]
	TIME [epoch: 6.48 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19627135192406572		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.19627135192406572 | validation: 0.1414849442716497]
	TIME [epoch: 6.49 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23972752295881394		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.23972752295881394 | validation: 0.29730031380024735]
	TIME [epoch: 6.49 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21237637357746697		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.21237637357746697 | validation: 0.19974927872811166]
	TIME [epoch: 6.49 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14169501625915412		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.14169501625915412 | validation: 0.31871193937668957]
	TIME [epoch: 6.51 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2564099792748248		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.2564099792748248 | validation: 0.07018127095370201]
	TIME [epoch: 6.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_398.pth
	Model improved!!!
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21383359912057717		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.21383359912057717 | validation: 0.2482893804149482]
	TIME [epoch: 6.55 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1755563341569737		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.1755563341569737 | validation: 0.17606479860058522]
	TIME [epoch: 6.49 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21531899561664256		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.21531899561664256 | validation: 0.3918152236822634]
	TIME [epoch: 6.49 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24872464701543098		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.24872464701543098 | validation: 0.36640216254633456]
	TIME [epoch: 6.48 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27773977025109575		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.27773977025109575 | validation: 0.3005076426848769]
	TIME [epoch: 6.48 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2505397782550994		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.2505397782550994 | validation: 0.2696600041650536]
	TIME [epoch: 6.51 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22987886807744995		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.22987886807744995 | validation: 0.18057725613995587]
	TIME [epoch: 6.51 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23820938799748484		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.23820938799748484 | validation: 0.1588348786235646]
	TIME [epoch: 6.49 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25143768516608356		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.25143768516608356 | validation: 0.20894481182455912]
	TIME [epoch: 6.5 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2799059827773084		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.2799059827773084 | validation: 0.2693359117546921]
	TIME [epoch: 6.49 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1799050866421899		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.1799050866421899 | validation: 0.4083376237428894]
	TIME [epoch: 6.49 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2674107080838269		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.2674107080838269 | validation: 0.11491272430672547]
	TIME [epoch: 6.49 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16411750222968385		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.16411750222968385 | validation: 0.24439531115528573]
	TIME [epoch: 6.5 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3818270372068079		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.3818270372068079 | validation: 0.24786739617843512]
	TIME [epoch: 6.52 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.318065625125731		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.318065625125731 | validation: 0.14572086657142413]
	TIME [epoch: 6.5 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17779483334227858		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.17779483334227858 | validation: 0.15667641504559968]
	TIME [epoch: 6.5 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.151498597407717		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.151498597407717 | validation: 0.1917026121239872]
	TIME [epoch: 6.5 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1810270666298608		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.1810270666298608 | validation: 0.23215982427731405]
	TIME [epoch: 6.5 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3497113782293812		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.3497113782293812 | validation: 0.1299747683868654]
	TIME [epoch: 6.5 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18922049600569565		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.18922049600569565 | validation: 0.23700782363273873]
	TIME [epoch: 6.51 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.175515771729291		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.175515771729291 | validation: 0.2233625572169895]
	TIME [epoch: 6.53 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2275037768722934		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.2275037768722934 | validation: 0.13613070086658832]
	TIME [epoch: 6.5 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16511710453378733		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.16511710453378733 | validation: 0.22892961320001015]
	TIME [epoch: 6.5 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14967544252443502		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.14967544252443502 | validation: 0.21116526272458663]
	TIME [epoch: 6.51 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24121744700286357		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.24121744700286357 | validation: 0.174897524405653]
	TIME [epoch: 6.5 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24713244293486686		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.24713244293486686 | validation: 0.14821367153878867]
	TIME [epoch: 6.5 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17248482812559748		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.17248482812559748 | validation: 0.17378176449606386]
	TIME [epoch: 6.51 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1566550357556807		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.1566550357556807 | validation: 0.1530337937373008]
	TIME [epoch: 6.54 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20109998926425124		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.20109998926425124 | validation: 0.12363490683873073]
	TIME [epoch: 6.51 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2076193194929863		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.2076193194929863 | validation: 0.16369345735838997]
	TIME [epoch: 6.5 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2544275600271135		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.2544275600271135 | validation: 0.21744663710147222]
	TIME [epoch: 6.5 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28390218278051793		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.28390218278051793 | validation: 0.2502701196536007]
	TIME [epoch: 6.5 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24121551728304086		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.24121551728304086 | validation: 0.21828683230755622]
	TIME [epoch: 6.5 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1895626280183403		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.1895626280183403 | validation: 0.0941877199523834]
	TIME [epoch: 6.51 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12426949399661343		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.12426949399661343 | validation: 0.39836419060429634]
	TIME [epoch: 6.54 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2786277331665116		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.2786277331665116 | validation: 0.08265663821970744]
	TIME [epoch: 6.51 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1569875079514435		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.1569875079514435 | validation: 0.12887702541810034]
	TIME [epoch: 6.51 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16812680504939337		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.16812680504939337 | validation: 0.12390630438162882]
	TIME [epoch: 6.5 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2793190530316551		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.2793190530316551 | validation: 0.21061404237481962]
	TIME [epoch: 6.5 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13317048676492416		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.13317048676492416 | validation: 0.5631233810477101]
	TIME [epoch: 6.5 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27490600898149953		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.27490600898149953 | validation: 0.27643085427232694]
	TIME [epoch: 6.5 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1956398238354781		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.1956398238354781 | validation: 0.2814263001852248]
	TIME [epoch: 6.53 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22000465411210868		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.22000465411210868 | validation: 0.22842629227265523]
	TIME [epoch: 6.51 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1849133864758648		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.1849133864758648 | validation: 0.18382524371188985]
	TIME [epoch: 6.51 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19786676625238328		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.19786676625238328 | validation: 0.38292483609195255]
	TIME [epoch: 6.5 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20171328304840483		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.20171328304840483 | validation: 0.23122124836119806]
	TIME [epoch: 6.5 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20295430940173867		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.20295430940173867 | validation: 0.08681292441382815]
	TIME [epoch: 6.5 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16056907916988333		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.16056907916988333 | validation: 0.20062953376722634]
	TIME [epoch: 6.5 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19295691862293105		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.19295691862293105 | validation: 0.2254299472725235]
	TIME [epoch: 6.54 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23987318435143518		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.23987318435143518 | validation: 0.324974964709718]
	TIME [epoch: 6.51 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22043807689160233		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.22043807689160233 | validation: 0.25055917930257005]
	TIME [epoch: 6.5 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.254172428652626		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.254172428652626 | validation: 0.1725725329038656]
	TIME [epoch: 6.5 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19886193663063834		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.19886193663063834 | validation: 0.1744765136386482]
	TIME [epoch: 6.5 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23748092962994813		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.23748092962994813 | validation: 0.34359942931714943]
	TIME [epoch: 6.5 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2539708128568323		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.2539708128568323 | validation: 0.4358749954005282]
	TIME [epoch: 6.5 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26568208891968875		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.26568208891968875 | validation: 0.24226027626859875]
	TIME [epoch: 6.52 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15135986399611412		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.15135986399611412 | validation: 0.11255828103454363]
	TIME [epoch: 6.52 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16967171877566917		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.16967171877566917 | validation: 0.13792377299129446]
	TIME [epoch: 6.51 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21403823492938273		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.21403823492938273 | validation: 0.18492943576531967]
	TIME [epoch: 6.5 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15722769994427735		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.15722769994427735 | validation: 0.1179981554049424]
	TIME [epoch: 6.5 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13672778858870005		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.13672778858870005 | validation: 0.21138767373346087]
	TIME [epoch: 6.5 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15851055027704866		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.15851055027704866 | validation: 0.33626318735259797]
	TIME [epoch: 6.5 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35106424747254916		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.35106424747254916 | validation: 0.1240563379179652]
	TIME [epoch: 6.52 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1863198474936436		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.1863198474936436 | validation: 0.21543060964638977]
	TIME [epoch: 6.52 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17627192500420774		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.17627192500420774 | validation: 0.2160792006769833]
	TIME [epoch: 6.51 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2199933790853421		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.2199933790853421 | validation: 0.24423326388014238]
	TIME [epoch: 6.5 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26136053478327115		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.26136053478327115 | validation: 0.13046094327152166]
	TIME [epoch: 6.5 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1687679517824328		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.1687679517824328 | validation: 0.11241484199215931]
	TIME [epoch: 6.51 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1363826872790862		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.1363826872790862 | validation: 0.10736634095278326]
	TIME [epoch: 6.49 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18115466090807686		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.18115466090807686 | validation: 0.3213633939852264]
	TIME [epoch: 6.52 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1761881068284385		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.1761881068284385 | validation: 0.17103004808609693]
	TIME [epoch: 6.52 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17205314774766378		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.17205314774766378 | validation: 0.29551971530955423]
	TIME [epoch: 6.5 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2101653964189605		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.2101653964189605 | validation: 0.08738914081906632]
	TIME [epoch: 6.5 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1118881564089424		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.1118881564089424 | validation: 0.08308963304822982]
	TIME [epoch: 6.5 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16124612178335337		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.16124612178335337 | validation: 0.2246227084475391]
	TIME [epoch: 6.5 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1591803585462444		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.1591803585462444 | validation: 0.22205925278381117]
	TIME [epoch: 6.5 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16952557540181257		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.16952557540181257 | validation: 0.12038233231973194]
	TIME [epoch: 6.51 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1746407845647602		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.1746407845647602 | validation: 0.18569683261093775]
	TIME [epoch: 6.53 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12316688306844191		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.12316688306844191 | validation: 0.09552056310709346]
	TIME [epoch: 6.5 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18566800225208335		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.18566800225208335 | validation: 0.30434095847541925]
	TIME [epoch: 6.5 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.210244779895485		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.210244779895485 | validation: 0.260185972459557]
	TIME [epoch: 6.5 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1969907673280652		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.1969907673280652 | validation: 0.19504146893429508]
	TIME [epoch: 6.5 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14097352377394542		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.14097352377394542 | validation: 0.09352467180707354]
	TIME [epoch: 6.49 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1244651782354406		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.1244651782354406 | validation: 0.18425106667898397]
	TIME [epoch: 6.49 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17549316801389647		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.17549316801389647 | validation: 0.16980659152934266]
	TIME [epoch: 6.53 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1468528103642987		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.1468528103642987 | validation: 0.16327931355473937]
	TIME [epoch: 6.5 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1553671423270791		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.1553671423270791 | validation: 0.092481411140942]
	TIME [epoch: 6.49 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17842959931595057		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.17842959931595057 | validation: 0.14522826151812968]
	TIME [epoch: 6.49 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17772904547831408		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.17772904547831408 | validation: 0.0994407035782723]
	TIME [epoch: 6.49 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14279507700010308		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.14279507700010308 | validation: 0.7386013781448749]
	TIME [epoch: 6.49 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2794220117171865		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.2794220117171865 | validation: 0.14697287443541973]
	TIME [epoch: 6.5 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1162623082301222		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.1162623082301222 | validation: 0.1288492355323286]
	TIME [epoch: 6.53 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1459054656702998		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.1459054656702998 | validation: 0.1542058933639305]
	TIME [epoch: 6.49 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13531434314267646		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.13531434314267646 | validation: 0.10040146421224704]
	TIME [epoch: 6.5 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11980027666596244		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.11980027666596244 | validation: 0.37117348952514934]
	TIME [epoch: 6.51 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19644442226590134		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.19644442226590134 | validation: 0.27954906179728667]
	TIME [epoch: 6.49 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18862456318907955		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.18862456318907955 | validation: 0.16658099727755826]
	TIME [epoch: 6.49 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1927847706866521		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.1927847706866521 | validation: 0.35539262369241187]
	TIME [epoch: 6.49 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30673988552982334		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.30673988552982334 | validation: 0.1940761275766841]
	TIME [epoch: 6.53 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20288393422474058		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.20288393422474058 | validation: 0.12973322356952308]
	TIME [epoch: 6.5 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13035870576242506		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.13035870576242506 | validation: 0.22105209525846434]
	TIME [epoch: 6.49 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15867503417722045		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.15867503417722045 | validation: 0.19417165884736842]
	TIME [epoch: 6.5 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18678401386572013		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.18678401386572013 | validation: 0.123557575221089]
	TIME [epoch: 6.49 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10114117352122319		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.10114117352122319 | validation: 0.13238108594004935]
	TIME [epoch: 6.49 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10599832727577774		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.10599832727577774 | validation: 0.18528245502724705]
	TIME [epoch: 6.5 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15535409258838956		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.15535409258838956 | validation: 0.15048626272799212]
	TIME [epoch: 6.53 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10391578966679665		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.10391578966679665 | validation: 0.11375416886733333]
	TIME [epoch: 6.51 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1482347582426155		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.1482347582426155 | validation: 0.15623300640993476]
	TIME [epoch: 6.49 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21132945214377807		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.21132945214377807 | validation: 0.1834136917958091]
	TIME [epoch: 6.5 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14352424167346442		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.14352424167346442 | validation: 0.11583175701594352]
	TIME [epoch: 6.5 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15238453054781853		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.15238453054781853 | validation: 0.10659476908360216]
	TIME [epoch: 6.49 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14363088207629338		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.14363088207629338 | validation: 0.14780295409113228]
	TIME [epoch: 6.5 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14578175384966388		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.14578175384966388 | validation: 0.17860378570649368]
	TIME [epoch: 6.53 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11120667461775928		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.11120667461775928 | validation: 0.11506204074292133]
	TIME [epoch: 6.5 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14157295824056182		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.14157295824056182 | validation: 0.23472055923655735]
	TIME [epoch: 6.5 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13475027203679033		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.13475027203679033 | validation: 0.180537247457053]
	TIME [epoch: 6.49 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1591731023009139		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.1591731023009139 | validation: 0.09243409321165523]
	TIME [epoch: 6.5 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11903586303527602		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.11903586303527602 | validation: 0.11525010587243203]
	TIME [epoch: 6.51 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1344042968975991		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.1344042968975991 | validation: 0.07049541212574706]
	TIME [epoch: 6.5 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1371187418520716		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.1371187418520716 | validation: 0.18430832451329898]
	TIME [epoch: 6.52 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21256514962044754		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.21256514962044754 | validation: 0.15823293702173]
	TIME [epoch: 6.51 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15703990083119984		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.15703990083119984 | validation: 0.0680710737495062]
	TIME [epoch: 6.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_520.pth
	Model improved!!!
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13193087981208562		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.13193087981208562 | validation: 0.10978431673026709]
	TIME [epoch: 6.58 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13230267273501645		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.13230267273501645 | validation: 0.0821202738724789]
	TIME [epoch: 6.47 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08674165422502328		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.08674165422502328 | validation: 0.26759718617922856]
	TIME [epoch: 6.49 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2697113324679181		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.2697113324679181 | validation: 0.19284446935015007]
	TIME [epoch: 6.48 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2161995559013092		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.2161995559013092 | validation: 0.12739525652901398]
	TIME [epoch: 6.52 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12132103629751527		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.12132103629751527 | validation: 0.12376853315026586]
	TIME [epoch: 6.5 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15937526068966665		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.15937526068966665 | validation: 0.2806697832307273]
	TIME [epoch: 6.5 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17511674852096132		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.17511674852096132 | validation: 0.08849155646859636]
	TIME [epoch: 6.5 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13471003528420614		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.13471003528420614 | validation: 0.13304323386202715]
	TIME [epoch: 6.49 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10431386975832208		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.10431386975832208 | validation: 0.09915924981471137]
	TIME [epoch: 6.48 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1258413994536107		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.1258413994536107 | validation: 0.12861179582958063]
	TIME [epoch: 6.5 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11795046389752048		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.11795046389752048 | validation: 0.1351793352603645]
	TIME [epoch: 6.51 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28295152967435994		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.28295152967435994 | validation: 0.28603396116762775]
	TIME [epoch: 6.5 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16173393295201793		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.16173393295201793 | validation: 0.2490888094849842]
	TIME [epoch: 6.49 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1533187184816069		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.1533187184816069 | validation: 0.1900485345528261]
	TIME [epoch: 6.49 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18664881822090656		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.18664881822090656 | validation: 0.2902194591575415]
	TIME [epoch: 6.48 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14291742845189148		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.14291742845189148 | validation: 0.1890090029134587]
	TIME [epoch: 6.48 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14720592451024092		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.14720592451024092 | validation: 0.19827428002683825]
	TIME [epoch: 6.49 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14877642295713134		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.14877642295713134 | validation: 0.2522739051727518]
	TIME [epoch: 6.5 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23089722067216173		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.23089722067216173 | validation: 0.24782047321942535]
	TIME [epoch: 6.52 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2105471014086693		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.2105471014086693 | validation: 0.09464271845574873]
	TIME [epoch: 6.48 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1500668450155307		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.1500668450155307 | validation: 0.23334076636196183]
	TIME [epoch: 6.48 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1848252103721426		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.1848252103721426 | validation: 0.19504728445034755]
	TIME [epoch: 6.49 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1468674803878911		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.1468674803878911 | validation: 0.2188303769429718]
	TIME [epoch: 6.49 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2656467615954494		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.2656467615954494 | validation: 0.16380086615252445]
	TIME [epoch: 6.48 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12456886524425617		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.12456886524425617 | validation: 0.2544137037457263]
	TIME [epoch: 6.49 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17674556095982752		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.17674556095982752 | validation: 0.1760158509746526]
	TIME [epoch: 6.52 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14602512957367214		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.14602512957367214 | validation: 0.1884765769653207]
	TIME [epoch: 6.49 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14310629766427735		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.14310629766427735 | validation: 0.2012465137924061]
	TIME [epoch: 6.49 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14754161843360553		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.14754161843360553 | validation: 0.10297857930303322]
	TIME [epoch: 6.49 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11070105459379356		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.11070105459379356 | validation: 0.10416512627359137]
	TIME [epoch: 6.49 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15186809780285276		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.15186809780285276 | validation: 0.09920099999342988]
	TIME [epoch: 6.5 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11488822335897796		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.11488822335897796 | validation: 0.12683393221734643]
	TIME [epoch: 6.49 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17844565482975533		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.17844565482975533 | validation: 0.09317877168536082]
	TIME [epoch: 6.53 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09243478566661988		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.09243478566661988 | validation: 0.05997713671589144]
	TIME [epoch: 6.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_555.pth
	Model improved!!!
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10657796688809504		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.10657796688809504 | validation: 0.1851343371541006]
	TIME [epoch: 6.55 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16685078738801104		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.16685078738801104 | validation: 0.07291208314058864]
	TIME [epoch: 6.47 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14612450843578795		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.14612450843578795 | validation: 0.14203295892937554]
	TIME [epoch: 6.49 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13962091132535145		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.13962091132535145 | validation: 0.09108742753454539]
	TIME [epoch: 6.49 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12195974585561271		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.12195974585561271 | validation: 0.2722504186472764]
	TIME [epoch: 6.49 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20741339938204265		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.20741339938204265 | validation: 0.07773418437778865]
	TIME [epoch: 6.54 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1355811955833371		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.1355811955833371 | validation: 0.12027709075289629]
	TIME [epoch: 6.5 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0966121973776863		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.0966121973776863 | validation: 0.11402373276852873]
	TIME [epoch: 6.49 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08154373608068144		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.08154373608068144 | validation: 0.15374945017655925]
	TIME [epoch: 6.49 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09539761789361394		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.09539761789361394 | validation: 0.17589264540103614]
	TIME [epoch: 6.5 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1012231033906464		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.1012231033906464 | validation: 0.4467263756528861]
	TIME [epoch: 6.49 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1918347084448626		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.1918347084448626 | validation: 0.0977443464506413]
	TIME [epoch: 6.49 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11034747316565642		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.11034747316565642 | validation: 0.07030201577073934]
	TIME [epoch: 6.53 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12809993533833358		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.12809993533833358 | validation: 0.1681551447200429]
	TIME [epoch: 6.5 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13276582848869045		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.13276582848869045 | validation: 0.25629279296072105]
	TIME [epoch: 6.49 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16621258872478745		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.16621258872478745 | validation: 0.08216491392857479]
	TIME [epoch: 6.48 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11049426958781053		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.11049426958781053 | validation: 0.18625942563100423]
	TIME [epoch: 6.48 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18245918355520221		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.18245918355520221 | validation: 0.09764200879211402]
	TIME [epoch: 6.49 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09815844757250472		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.09815844757250472 | validation: 0.06462160491443167]
	TIME [epoch: 6.49 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11371092774645547		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.11371092774645547 | validation: 0.09064536911713743]
	TIME [epoch: 6.54 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09369040688431801		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.09369040688431801 | validation: 0.2523096971533192]
	TIME [epoch: 6.5 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17761964109821768		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.17761964109821768 | validation: 0.0953819629938678]
	TIME [epoch: 6.48 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09542236110803537		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.09542236110803537 | validation: 0.17417336234232117]
	TIME [epoch: 6.5 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13199918206361003		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.13199918206361003 | validation: 0.1053275253966298]
	TIME [epoch: 6.51 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16213086620580752		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.16213086620580752 | validation: 0.1359630711257386]
	TIME [epoch: 6.48 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11426160041806849		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.11426160041806849 | validation: 0.12705096162214144]
	TIME [epoch: 6.49 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11300456926457743		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.11300456926457743 | validation: 0.12428345324121313]
	TIME [epoch: 6.53 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09530152868179072		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.09530152868179072 | validation: 0.10704536264822459]
	TIME [epoch: 6.49 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14179655161794913		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.14179655161794913 | validation: 0.1243329546186744]
	TIME [epoch: 6.49 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1597454188915832		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.1597454188915832 | validation: 0.19096611709984282]
	TIME [epoch: 6.49 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14893911643474664		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.14893911643474664 | validation: 0.12445862713122101]
	TIME [epoch: 6.49 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15784369081566962		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.15784369081566962 | validation: 0.0889136858345213]
	TIME [epoch: 6.49 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1298223868845126		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.1298223868845126 | validation: 0.1937784441686443]
	TIME [epoch: 6.49 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14458701983854494		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.14458701983854494 | validation: 0.28392838737673226]
	TIME [epoch: 6.5 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17835017976552855		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.17835017976552855 | validation: 0.16185899707377735]
	TIME [epoch: 6.5 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13406812986418476		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.13406812986418476 | validation: 0.10559903081312902]
	TIME [epoch: 6.49 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10521810692611462		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.10521810692611462 | validation: 0.06654524705582766]
	TIME [epoch: 6.49 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07149683800295528		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.07149683800295528 | validation: 0.12865782862877154]
	TIME [epoch: 6.49 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09236699906989854		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.09236699906989854 | validation: 0.1440108322709256]
	TIME [epoch: 6.48 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11560114313870273		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.11560114313870273 | validation: 0.0755183028761363]
	TIME [epoch: 6.5 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10869913378748935		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.10869913378748935 | validation: 0.08933394537797681]
	TIME [epoch: 6.51 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11871876789505906		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.11871876789505906 | validation: 0.09929530327076361]
	TIME [epoch: 6.58 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10436938896731357		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.10436938896731357 | validation: 0.06993927450083316]
	TIME [epoch: 6.49 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10859716099168171		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.10859716099168171 | validation: 0.1979133908623664]
	TIME [epoch: 6.5 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13683370176202386		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.13683370176202386 | validation: 0.08986850818378565]
	TIME [epoch: 6.49 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12047017747807445		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.12047017747807445 | validation: 0.13600704828067745]
	TIME [epoch: 6.48 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.082724051814708		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.082724051814708 | validation: 0.07002627573933223]
	TIME [epoch: 6.49 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13012320598513114		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.13012320598513114 | validation: 0.07444284426252062]
	TIME [epoch: 6.5 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17558880911939617		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.17558880911939617 | validation: 0.20596396694674654]
	TIME [epoch: 6.53 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1513301041772523		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.1513301041772523 | validation: 0.11337447774986341]
	TIME [epoch: 6.5 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11375006545815299		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.11375006545815299 | validation: 0.1060042736276458]
	TIME [epoch: 6.49 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1224485749544715		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.1224485749544715 | validation: 0.13280556673482483]
	TIME [epoch: 6.5 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.126584341073119		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.126584341073119 | validation: 0.09005824548376429]
	TIME [epoch: 6.52 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07775444810186573		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.07775444810186573 | validation: 0.11163895817352903]
	TIME [epoch: 6.51 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10559394313445225		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.10559394313445225 | validation: 0.10894793886431942]
	TIME [epoch: 6.51 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08792628584891984		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.08792628584891984 | validation: 0.08548208494201803]
	TIME [epoch: 6.54 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08860499320772985		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.08860499320772985 | validation: 0.10297347129121201]
	TIME [epoch: 6.51 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10401536440532685		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.10401536440532685 | validation: 0.10361118030805798]
	TIME [epoch: 6.49 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11093637992496341		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.11093637992496341 | validation: 0.051168344231007454]
	TIME [epoch: 6.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_614.pth
	Model improved!!!
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08542561043126828		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.08542561043126828 | validation: 0.07055565596890709]
	TIME [epoch: 6.55 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10304785674598806		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.10304785674598806 | validation: 0.10076884027813277]
	TIME [epoch: 6.5 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10714909454284109		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.10714909454284109 | validation: 0.07966204040225053]
	TIME [epoch: 6.49 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13248624446332258		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.13248624446332258 | validation: 0.2122117101553031]
	TIME [epoch: 6.53 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19487688044066778		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.19487688044066778 | validation: 0.09131445562490939]
	TIME [epoch: 6.52 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09621270511059725		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.09621270511059725 | validation: 0.07646919494888912]
	TIME [epoch: 6.51 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11744216480913065		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.11744216480913065 | validation: 0.09581995417427676]
	TIME [epoch: 6.52 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08778272323517294		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.08778272323517294 | validation: 0.08427185848955784]
	TIME [epoch: 6.51 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09752626192912692		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.09752626192912692 | validation: 0.10461915978688065]
	TIME [epoch: 6.5 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12028323472166272		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.12028323472166272 | validation: 0.0632148264657183]
	TIME [epoch: 6.51 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11749649348554553		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.11749649348554553 | validation: 0.046583108982463844]
	TIME [epoch: 6.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_625.pth
	Model improved!!!
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09201197766812458		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.09201197766812458 | validation: 0.10668363718700594]
	TIME [epoch: 6.6 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11397186739018564		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.11397186739018564 | validation: 0.09993225978888322]
	TIME [epoch: 6.48 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11094347657108657		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.11094347657108657 | validation: 0.16031000408413737]
	TIME [epoch: 6.48 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12838113586452582		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.12838113586452582 | validation: 0.14198653494167762]
	TIME [epoch: 6.48 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11873021119265054		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.11873021119265054 | validation: 0.10640232803689284]
	TIME [epoch: 6.49 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1419045035778475		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.1419045035778475 | validation: 0.07772689582080108]
	TIME [epoch: 6.47 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09381779616006133		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.09381779616006133 | validation: 0.12592515480036004]
	TIME [epoch: 6.52 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09524678750394051		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.09524678750394051 | validation: 0.14297183596894383]
	TIME [epoch: 6.49 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1265391209913163		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.1265391209913163 | validation: 0.07759533211187658]
	TIME [epoch: 6.48 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09593525034212602		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.09593525034212602 | validation: 0.08700463161323256]
	TIME [epoch: 6.48 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09186157419593548		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.09186157419593548 | validation: 0.06350685172351724]
	TIME [epoch: 6.49 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1251271965283359		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.1251271965283359 | validation: 0.25252548907161393]
	TIME [epoch: 6.48 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12948591863026157		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.12948591863026157 | validation: 0.06047848199877333]
	TIME [epoch: 6.49 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10183275638205476		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.10183275638205476 | validation: 0.10207783397208849]
	TIME [epoch: 6.53 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09073034510878447		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.09073034510878447 | validation: 0.13270633043423924]
	TIME [epoch: 6.48 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10440813994852163		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.10440813994852163 | validation: 0.19950231685834005]
	TIME [epoch: 6.48 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12538961641139915		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.12538961641139915 | validation: 0.10034091276069539]
	TIME [epoch: 6.49 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10670348509611856		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.10670348509611856 | validation: 0.056194320555400606]
	TIME [epoch: 6.48 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0754614341698165		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.0754614341698165 | validation: 0.06892615204800143]
	TIME [epoch: 6.49 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10834013201677586		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.10834013201677586 | validation: 0.16327054829250096]
	TIME [epoch: 6.48 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11638214312547113		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.11638214312547113 | validation: 0.14383925149889876]
	TIME [epoch: 6.52 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1062770135156207		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.1062770135156207 | validation: 0.09974862906918577]
	TIME [epoch: 6.5 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09842811808602414		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.09842811808602414 | validation: 0.11943306015920511]
	TIME [epoch: 6.49 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.139695932803145		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.139695932803145 | validation: 0.1094085448552914]
	TIME [epoch: 6.49 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1123582027317304		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.1123582027317304 | validation: 0.07589699234784526]
	TIME [epoch: 6.5 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1157477417564372		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.1157477417564372 | validation: 0.13819596141019294]
	TIME [epoch: 6.49 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1109984890784485		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.1109984890784485 | validation: 0.09118620561253125]
	TIME [epoch: 6.49 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09095056448455982		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.09095056448455982 | validation: 0.06698795087408581]
	TIME [epoch: 6.51 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08213141943232731		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.08213141943232731 | validation: 0.07468938629295353]
	TIME [epoch: 6.48 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11281169644645228		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.11281169644645228 | validation: 0.06635714661898015]
	TIME [epoch: 6.48 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06911945419614746		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.06911945419614746 | validation: 0.0862755987191132]
	TIME [epoch: 6.48 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09398225763686692		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.09398225763686692 | validation: 0.08630784926944898]
	TIME [epoch: 6.48 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10913152189111801		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.10913152189111801 | validation: 0.1526641720294505]
	TIME [epoch: 6.48 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1131047633616635		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.1131047633616635 | validation: 0.07997436432643401]
	TIME [epoch: 6.47 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10205198421663704		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.10205198421663704 | validation: 0.12646432955569406]
	TIME [epoch: 6.5 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10438221278356632		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.10438221278356632 | validation: 0.07636207105753133]
	TIME [epoch: 6.5 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12833948869740647		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.12833948869740647 | validation: 0.09385381719529924]
	TIME [epoch: 6.48 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1090142088693404		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.1090142088693404 | validation: 0.20515913151953655]
	TIME [epoch: 6.48 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10350273261066148		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.10350273261066148 | validation: 0.07331052535764349]
	TIME [epoch: 6.48 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09242800232676479		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.09242800232676479 | validation: 0.06628960013073232]
	TIME [epoch: 6.47 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09498728707619031		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.09498728707619031 | validation: 0.13995804853491947]
	TIME [epoch: 6.48 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15057116952358612		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.15057116952358612 | validation: 0.15662757348068643]
	TIME [epoch: 6.5 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1925592274790096		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.1925592274790096 | validation: 0.30533293807827433]
	TIME [epoch: 6.5 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.154492059941629		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.154492059941629 | validation: 0.08488373470057034]
	TIME [epoch: 6.48 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09373159308288523		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.09373159308288523 | validation: 0.08655839171269897]
	TIME [epoch: 6.48 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11879682873655978		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.11879682873655978 | validation: 0.08138493488092471]
	TIME [epoch: 6.48 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10653952361514851		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.10653952361514851 | validation: 0.17497396987253885]
	TIME [epoch: 6.48 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14220198643055054		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.14220198643055054 | validation: 0.04536949155480993]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_673.pth
	Model improved!!!
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09566259011582655		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.09566259011582655 | validation: 0.08763327547509746]
	TIME [epoch: 6.58 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09858092245937543		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.09858092245937543 | validation: 0.08375376671692186]
	TIME [epoch: 6.5 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07067178455712866		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.07067178455712866 | validation: 0.0430391454568107]
	TIME [epoch: 6.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_676.pth
	Model improved!!!
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10354995873314424		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.10354995873314424 | validation: 0.14062200418292498]
	TIME [epoch: 6.56 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08924803429678035		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.08924803429678035 | validation: 0.056101533631997054]
	TIME [epoch: 6.48 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09552692124596043		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.09552692124596043 | validation: 0.07516623167511696]
	TIME [epoch: 6.48 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14754961215077766		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.14754961215077766 | validation: 0.10842642744003587]
	TIME [epoch: 6.49 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08813027508078924		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.08813027508078924 | validation: 0.05241147215358097]
	TIME [epoch: 6.51 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08181421688659535		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.08181421688659535 | validation: 0.1329002223103177]
	TIME [epoch: 6.5 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10322312013562059		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.10322312013562059 | validation: 0.08412338743872899]
	TIME [epoch: 6.48 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10447563741054816		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.10447563741054816 | validation: 0.15556601602657263]
	TIME [epoch: 6.48 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14232292693621407		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.14232292693621407 | validation: 0.1013552579376545]
	TIME [epoch: 6.48 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1030558338096032		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.1030558338096032 | validation: 0.07495376358921849]
	TIME [epoch: 6.48 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0888037764949485		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.0888037764949485 | validation: 0.0430449448254065]
	TIME [epoch: 6.49 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08518680653956463		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.08518680653956463 | validation: 0.0905805425335139]
	TIME [epoch: 6.5 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09223303809921056		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.09223303809921056 | validation: 0.09712915374800696]
	TIME [epoch: 6.52 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07657756702275098		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.07657756702275098 | validation: 0.05580615121346366]
	TIME [epoch: 6.51 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09051973224111501		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.09051973224111501 | validation: 0.06091495749381972]
	TIME [epoch: 6.5 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050734384469717383		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.050734384469717383 | validation: 0.03596132553942966]
	TIME [epoch: 6.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_692.pth
	Model improved!!!
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0968782603163284		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.0968782603163284 | validation: 0.14567680010389056]
	TIME [epoch: 6.6 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09804337740145516		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.09804337740145516 | validation: 0.09602549893603034]
	TIME [epoch: 6.48 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09001646202740475		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.09001646202740475 | validation: 0.11319496055570373]
	TIME [epoch: 6.49 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1123947445024035		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.1123947445024035 | validation: 0.10561418104442988]
	TIME [epoch: 6.53 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08063018753458537		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.08063018753458537 | validation: 0.12807506889343678]
	TIME [epoch: 6.5 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07590054139059549		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.07590054139059549 | validation: 0.0788067156816513]
	TIME [epoch: 6.49 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07505292589921057		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.07505292589921057 | validation: 0.05596508829194919]
	TIME [epoch: 6.48 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06023749759006316		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.06023749759006316 | validation: 0.08445422789245925]
	TIME [epoch: 6.5 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1464934252147099		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.1464934252147099 | validation: 0.09590174476578428]
	TIME [epoch: 6.49 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08456506207790089		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.08456506207790089 | validation: 0.04503312080419801]
	TIME [epoch: 6.5 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08173928605195156		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.08173928605195156 | validation: 0.08694603399120408]
	TIME [epoch: 6.53 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08408565377612667		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.08408565377612667 | validation: 0.05901155743533482]
	TIME [epoch: 6.51 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07670646101447896		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.07670646101447896 | validation: 0.09428048566582402]
	TIME [epoch: 6.51 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11245920084858523		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.11245920084858523 | validation: 0.07401479968857794]
	TIME [epoch: 6.5 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08160828554824844		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.08160828554824844 | validation: 0.06473723848153871]
	TIME [epoch: 6.5 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08028191777340334		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.08028191777340334 | validation: 0.10888200335348128]
	TIME [epoch: 6.49 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10629034809271878		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.10629034809271878 | validation: 0.07397954017474218]
	TIME [epoch: 6.51 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08483077620566457		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.08483077620566457 | validation: 0.12584752297520002]
	TIME [epoch: 6.54 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08973521442354859		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.08973521442354859 | validation: 0.0805950706204601]
	TIME [epoch: 6.51 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12843461383566354		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.12843461383566354 | validation: 0.06999517601141998]
	TIME [epoch: 6.5 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09583587055765054		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.09583587055765054 | validation: 0.0445297440615896]
	TIME [epoch: 6.51 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06369165810773816		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.06369165810773816 | validation: 0.09560581531448634]
	TIME [epoch: 6.49 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09195741182046129		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.09195741182046129 | validation: 0.0818817701763745]
	TIME [epoch: 6.5 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08943811906245036		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.08943811906245036 | validation: 0.08780191579902692]
	TIME [epoch: 6.49 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0756632580791575		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.0756632580791575 | validation: 0.06816268744861746]
	TIME [epoch: 6.55 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044027188838521955		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.044027188838521955 | validation: 0.04873875440592139]
	TIME [epoch: 6.5 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0707051495153237		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.0707051495153237 | validation: 0.042898408557472706]
	TIME [epoch: 6.51 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06535551993539616		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.06535551993539616 | validation: 0.09669522084083454]
	TIME [epoch: 6.5 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09712171808319092		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.09712171808319092 | validation: 0.034655952450449376]
	TIME [epoch: 6.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_721.pth
	Model improved!!!
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06654710160347614		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.06654710160347614 | validation: 0.05244090228225437]
	TIME [epoch: 6.61 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0727884205180823		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.0727884205180823 | validation: 0.03720045979401682]
	TIME [epoch: 6.5 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06398994118478551		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.06398994118478551 | validation: 0.1775195772868345]
	TIME [epoch: 6.54 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08750970824301717		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.08750970824301717 | validation: 0.05462184418184702]
	TIME [epoch: 6.51 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07265174451290894		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.07265174451290894 | validation: 0.056007006571960984]
	TIME [epoch: 6.51 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.163402180307979		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.163402180307979 | validation: 0.06546526211587393]
	TIME [epoch: 6.5 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0846930634780014		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.0846930634780014 | validation: 0.0542814004362157]
	TIME [epoch: 6.5 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0869155245491117		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.0869155245491117 | validation: 0.07815546880787437]
	TIME [epoch: 6.5 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07702201657314837		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.07702201657314837 | validation: 0.05482343741874829]
	TIME [epoch: 6.5 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05549652341588253		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.05549652341588253 | validation: 0.10067584365454707]
	TIME [epoch: 6.54 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.094384424889769		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.094384424889769 | validation: 0.08269031395224896]
	TIME [epoch: 6.51 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08080493095248865		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.08080493095248865 | validation: 0.07496938101832128]
	TIME [epoch: 6.5 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08743198081354472		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.08743198081354472 | validation: 0.0965911690848656]
	TIME [epoch: 6.5 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11524059349013194		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.11524059349013194 | validation: 0.11292681094823827]
	TIME [epoch: 6.5 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10092506791955846		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.10092506791955846 | validation: 0.33439802245420913]
	TIME [epoch: 6.5 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2005271516892353		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.2005271516892353 | validation: 0.15514987765965685]
	TIME [epoch: 6.5 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1621458133572526		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.1621458133572526 | validation: 0.11804234146826946]
	TIME [epoch: 6.54 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0861614644654996		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.0861614644654996 | validation: 0.09187106500287502]
	TIME [epoch: 6.51 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09993383873418074		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.09993383873418074 | validation: 0.13381580559667908]
	TIME [epoch: 6.5 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08249832881957103		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.08249832881957103 | validation: 0.060032588502273845]
	TIME [epoch: 6.5 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06845871940198087		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.06845871940198087 | validation: 0.0945934289935839]
	TIME [epoch: 6.5 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08968304210121762		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.08968304210121762 | validation: 0.04868067992488392]
	TIME [epoch: 6.5 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06506059673719858		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.06506059673719858 | validation: 0.036827266720619915]
	TIME [epoch: 6.5 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06620143213331099		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.06620143213331099 | validation: 0.06143781437222133]
	TIME [epoch: 6.52 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05514067236676125		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.05514067236676125 | validation: 0.06539480885664262]
	TIME [epoch: 6.51 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08388795568013975		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.08388795568013975 | validation: 0.05193255537361113]
	TIME [epoch: 6.49 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08921066116209209		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.08921066116209209 | validation: 0.11553513228455302]
	TIME [epoch: 6.49 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09776462870576089		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.09776462870576089 | validation: 0.10500720647016212]
	TIME [epoch: 6.49 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10112425218887096		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.10112425218887096 | validation: 0.06509144739530413]
	TIME [epoch: 6.48 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0799211819760091		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.0799211819760091 | validation: 0.052113074022579926]
	TIME [epoch: 6.49 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06328506591326995		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.06328506591326995 | validation: 0.049129337849607824]
	TIME [epoch: 6.51 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053255309577273015		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.053255309577273015 | validation: 0.06162049656228204]
	TIME [epoch: 6.51 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10458184605301488		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.10458184605301488 | validation: 0.05200863002543897]
	TIME [epoch: 6.49 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05045825272514747		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.05045825272514747 | validation: 0.05790694139392448]
	TIME [epoch: 6.49 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05285308868807309		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.05285308868807309 | validation: 0.08619202898736131]
	TIME [epoch: 6.49 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07963750214144283		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.07963750214144283 | validation: 0.10463795984997898]
	TIME [epoch: 6.49 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09750305406056217		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.09750305406056217 | validation: 0.06052075646556691]
	TIME [epoch: 6.5 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07194641543846153		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.07194641543846153 | validation: 0.06275684924466955]
	TIME [epoch: 6.52 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10232512501852793		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.10232512501852793 | validation: 0.13499392611627972]
	TIME [epoch: 6.52 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0791762714187946		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.0791762714187946 | validation: 0.08391843322950218]
	TIME [epoch: 6.48 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0765993729833152		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.0765993729833152 | validation: 0.061504577548794535]
	TIME [epoch: 6.5 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0683214818837969		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.0683214818837969 | validation: 0.06423181723383767]
	TIME [epoch: 6.5 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08201208304283493		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.08201208304283493 | validation: 0.10104211417778328]
	TIME [epoch: 6.5 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10241900941527196		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.10241900941527196 | validation: 0.09695552281771272]
	TIME [epoch: 6.5 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08849327775397507		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.08849327775397507 | validation: 0.08552804212284378]
	TIME [epoch: 6.49 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08594875688147767		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.08594875688147767 | validation: 0.0967246215379992]
	TIME [epoch: 6.52 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10360105402230654		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.10360105402230654 | validation: 0.05954877708846481]
	TIME [epoch: 6.51 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07073208361965637		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.07073208361965637 | validation: 0.08743833189171081]
	TIME [epoch: 6.51 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10054027624270852		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.10054027624270852 | validation: 0.046798661621762716]
	TIME [epoch: 6.5 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07443037203352683		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.07443037203352683 | validation: 0.09858971011066593]
	TIME [epoch: 6.5 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08722505021147374		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.08722505021147374 | validation: 0.07895312409960809]
	TIME [epoch: 6.5 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09792565969001255		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.09792565969001255 | validation: 0.0913975451129733]
	TIME [epoch: 6.5 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08624653034881727		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.08624653034881727 | validation: 0.12356685570397907]
	TIME [epoch: 6.54 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15360593409302672		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.15360593409302672 | validation: 0.06902336707433213]
	TIME [epoch: 6.5 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06433015102745751		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.06433015102745751 | validation: 0.07774541454284466]
	TIME [epoch: 6.51 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08639099001463399		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.08639099001463399 | validation: 0.07506309645347932]
	TIME [epoch: 6.49 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07251421895245133		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.07251421895245133 | validation: 0.0762777802007374]
	TIME [epoch: 6.5 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11442611277328302		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.11442611277328302 | validation: 0.07865663053160081]
	TIME [epoch: 6.5 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07361833715467189		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.07361833715467189 | validation: 0.09867576205699528]
	TIME [epoch: 6.5 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1148822507822054		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.1148822507822054 | validation: 0.10179117931443385]
	TIME [epoch: 6.55 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10085419799292508		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.10085419799292508 | validation: 0.060319797546751756]
	TIME [epoch: 6.5 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06448645458433826		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.06448645458433826 | validation: 0.10588254589077849]
	TIME [epoch: 6.5 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08580762456159906		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.08580762456159906 | validation: 0.08688385745281775]
	TIME [epoch: 6.5 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07514479458511601		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.07514479458511601 | validation: 0.03360635770909508]
	TIME [epoch: 6.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_785.pth
	Model improved!!!
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06760067281375202		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.06760067281375202 | validation: 0.06634873719782708]
	TIME [epoch: 6.59 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05839631309565875		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.05839631309565875 | validation: 0.04299889054738474]
	TIME [epoch: 6.49 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05833266605749746		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.05833266605749746 | validation: 0.07602107419641664]
	TIME [epoch: 6.51 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07130837692032384		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.07130837692032384 | validation: 0.07215028690671575]
	TIME [epoch: 6.49 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07109022932557754		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.07109022932557754 | validation: 0.101570561766166]
	TIME [epoch: 6.48 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09480695245063689		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.09480695245063689 | validation: 0.0812252761713703]
	TIME [epoch: 6.49 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07096799723324715		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.07096799723324715 | validation: 0.08478186278626809]
	TIME [epoch: 6.48 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07433478588506891		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.07433478588506891 | validation: 0.11559472955396637]
	TIME [epoch: 6.48 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08302524620289103		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.08302524620289103 | validation: 0.083400756234429]
	TIME [epoch: 6.5 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07302606518639032		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.07302606518639032 | validation: 0.06815308118965213]
	TIME [epoch: 6.52 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06882830361751457		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.06882830361751457 | validation: 0.07720175727787743]
	TIME [epoch: 6.49 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053163303497607665		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.053163303497607665 | validation: 0.05173383799285352]
	TIME [epoch: 6.48 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05467342403593704		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.05467342403593704 | validation: 0.0628581852461121]
	TIME [epoch: 6.48 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08278145962373834		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.08278145962373834 | validation: 0.046864855553120574]
	TIME [epoch: 6.48 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05745385218080148		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.05745385218080148 | validation: 0.05527172716348707]
	TIME [epoch: 6.48 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0621198739710098		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.0621198739710098 | validation: 0.06683693160444606]
	TIME [epoch: 6.48 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08466892738188612		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.08466892738188612 | validation: 0.08961400723377701]
	TIME [epoch: 6.52 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10337297036256483		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.10337297036256483 | validation: 0.06990764546389841]
	TIME [epoch: 6.5 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07270880276876372		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.07270880276876372 | validation: 0.07214516739697795]
	TIME [epoch: 6.48 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05459016297122236		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.05459016297122236 | validation: 0.05310557107484216]
	TIME [epoch: 6.48 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07486313309389249		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.07486313309389249 | validation: 0.13662800480254736]
	TIME [epoch: 6.5 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13903817399296914		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.13903817399296914 | validation: 0.09808739350124633]
	TIME [epoch: 6.48 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09085657285972612		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.09085657285972612 | validation: 0.07852619176021577]
	TIME [epoch: 6.48 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07370504278903467		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.07370504278903467 | validation: 0.05893257623091186]
	TIME [epoch: 6.52 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05958631742170133		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.05958631742170133 | validation: 0.06248375724472428]
	TIME [epoch: 6.48 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058789609213054934		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.058789609213054934 | validation: 0.05239140988584452]
	TIME [epoch: 6.48 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07823222442386749		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.07823222442386749 | validation: 0.07549398079570215]
	TIME [epoch: 6.48 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09513839873264361		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.09513839873264361 | validation: 0.041854071697704644]
	TIME [epoch: 6.6 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06275023884249882		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.06275023884249882 | validation: 0.041435677754466715]
	TIME [epoch: 6.49 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04676429434313343		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.04676429434313343 | validation: 0.056202623851958435]
	TIME [epoch: 6.5 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08440345406991455		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.08440345406991455 | validation: 0.07565242474334047]
	TIME [epoch: 6.52 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07878136860670781		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.07878136860670781 | validation: 0.10504531638485168]
	TIME [epoch: 6.52 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15427242369122612		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.15427242369122612 | validation: 0.07834207381688535]
	TIME [epoch: 6.49 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061572680098105896		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.061572680098105896 | validation: 0.07610541174844132]
	TIME [epoch: 6.49 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07735463784135499		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.07735463784135499 | validation: 0.0654892153823907]
	TIME [epoch: 6.5 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054599430855585766		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.054599430855585766 | validation: 0.037324007573898615]
	TIME [epoch: 6.5 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06551647597444184		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.06551647597444184 | validation: 0.03775513161787749]
	TIME [epoch: 6.49 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05618845812522607		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.05618845812522607 | validation: 0.053226176795673215]
	TIME [epoch: 6.52 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05713192036825213		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.05713192036825213 | validation: 0.05543450783409421]
	TIME [epoch: 6.52 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07418598748683186		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.07418598748683186 | validation: 0.046465572290637615]
	TIME [epoch: 6.49 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059503730372879114		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.059503730372879114 | validation: 0.03565737944555099]
	TIME [epoch: 6.5 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07431803666231598		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.07431803666231598 | validation: 0.08744153999694267]
	TIME [epoch: 6.48 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10985684444522287		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.10985684444522287 | validation: 0.13548366767202125]
	TIME [epoch: 6.49 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0821469909536702		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.0821469909536702 | validation: 0.03265625048946237]
	TIME [epoch: 6.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_829.pth
	Model improved!!!
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05905716080956532		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.05905716080956532 | validation: 0.061413893044144054]
	TIME [epoch: 6.56 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08000023780094438		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.08000023780094438 | validation: 0.043995614201951624]
	TIME [epoch: 6.48 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05190824274651634		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.05190824274651634 | validation: 0.05285014060027733]
	TIME [epoch: 6.48 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06197390612955829		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.06197390612955829 | validation: 0.053752644977443115]
	TIME [epoch: 6.47 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0588594407794814		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.0588594407794814 | validation: 0.05134549207484621]
	TIME [epoch: 6.48 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060789641088139355		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.060789641088139355 | validation: 0.04325634257075794]
	TIME [epoch: 6.48 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05327771846152812		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.05327771846152812 | validation: 0.05654823623911313]
	TIME [epoch: 6.48 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06345039566071187		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.06345039566071187 | validation: 0.07944752370349088]
	TIME [epoch: 6.48 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08173049507021224		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.08173049507021224 | validation: 0.04519899612256873]
	TIME [epoch: 6.52 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07964653938344263		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.07964653938344263 | validation: 0.06864548707412922]
	TIME [epoch: 6.48 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07508528073244793		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.07508528073244793 | validation: 0.052055537035897576]
	TIME [epoch: 6.48 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07318506154961076		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.07318506154961076 | validation: 0.09072340437391409]
	TIME [epoch: 6.47 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08465156310176525		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.08465156310176525 | validation: 0.08209347038559728]
	TIME [epoch: 6.48 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07287348497796406		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.07287348497796406 | validation: 0.07885581879156527]
	TIME [epoch: 6.49 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08825032936719311		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.08825032936719311 | validation: 0.06524637954462854]
	TIME [epoch: 6.5 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07443345716225055		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.07443345716225055 | validation: 0.07898541928888209]
	TIME [epoch: 6.53 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07948102619925987		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.07948102619925987 | validation: 0.09303981634909463]
	TIME [epoch: 6.49 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06906003600079025		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.06906003600079025 | validation: 0.043233664837485086]
	TIME [epoch: 6.47 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045498690390679344		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.045498690390679344 | validation: 0.04729098194752849]
	TIME [epoch: 6.47 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054809160449799395		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.054809160449799395 | validation: 0.04114819790735897]
	TIME [epoch: 6.48 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050102702599035306		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.050102702599035306 | validation: 0.04008975875894397]
	TIME [epoch: 6.5 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06407620748588744		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.06407620748588744 | validation: 0.05771286613372894]
	TIME [epoch: 6.5 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0642069665087128		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.0642069665087128 | validation: 0.04948104755983393]
	TIME [epoch: 6.54 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051844863561395144		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.051844863561395144 | validation: 0.07601310564715101]
	TIME [epoch: 6.5 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05959076991671104		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.05959076991671104 | validation: 0.03595214855397441]
	TIME [epoch: 6.49 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03708209709000055		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.03708209709000055 | validation: 0.03101966912131115]
	TIME [epoch: 6.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_855.pth
	Model improved!!!
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054358448605233006		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.054358448605233006 | validation: 0.043488438875446005]
	TIME [epoch: 6.57 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06161328162134318		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.06161328162134318 | validation: 0.07889024504839098]
	TIME [epoch: 6.48 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08742018998090945		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.08742018998090945 | validation: 0.07222672946520002]
	TIME [epoch: 6.48 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05921874992803833		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.05921874992803833 | validation: 0.044347067543312475]
	TIME [epoch: 6.52 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0451610408566894		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.0451610408566894 | validation: 0.041727879231908134]
	TIME [epoch: 6.48 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.071228229541967		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.071228229541967 | validation: 0.06543655150767902]
	TIME [epoch: 6.48 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053917597684464774		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.053917597684464774 | validation: 0.031430169504646735]
	TIME [epoch: 6.49 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05689356261911065		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.05689356261911065 | validation: 0.03142245204922891]
	TIME [epoch: 6.5 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07341222350348586		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.07341222350348586 | validation: 0.0347192537395383]
	TIME [epoch: 6.48 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046416487489709155		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.046416487489709155 | validation: 0.042785241579807204]
	TIME [epoch: 6.48 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04000141044735		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.04000141044735 | validation: 0.050445268682654414]
	TIME [epoch: 6.53 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06875504842496118		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.06875504842496118 | validation: 0.042839845181371024]
	TIME [epoch: 6.49 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05170190672430721		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.05170190672430721 | validation: 0.0910950856721095]
	TIME [epoch: 6.5 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10606602272863046		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.10606602272863046 | validation: 0.06108586321043137]
	TIME [epoch: 6.49 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060101356869444136		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.060101356869444136 | validation: 0.07656624547557918]
	TIME [epoch: 6.49 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061105973132565904		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.061105973132565904 | validation: 0.053610335855501505]
	TIME [epoch: 6.48 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05325758565644822		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.05325758565644822 | validation: 0.05619445900669469]
	TIME [epoch: 6.48 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05548004612845292		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.05548004612845292 | validation: 0.05766391393454875]
	TIME [epoch: 6.52 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05622857296621697		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.05622857296621697 | validation: 0.035949615411952796]
	TIME [epoch: 6.49 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04776701833450077		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.04776701833450077 | validation: 0.04451581245794886]
	TIME [epoch: 6.48 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056574945862320425		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.056574945862320425 | validation: 0.05262774678391574]
	TIME [epoch: 6.49 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04795468659801		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.04795468659801 | validation: 0.050786691310683196]
	TIME [epoch: 6.49 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048845019287427835		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.048845019287427835 | validation: 0.03637201664089767]
	TIME [epoch: 6.49 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06177687530698293		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.06177687530698293 | validation: 0.12098357272981466]
	TIME [epoch: 6.48 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08864704145717064		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.08864704145717064 | validation: 0.053646231554535344]
	TIME [epoch: 6.53 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07297085452282272		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.07297085452282272 | validation: 0.06215587010625674]
	TIME [epoch: 6.49 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06269271269510339		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.06269271269510339 | validation: 0.04431347001849093]
	TIME [epoch: 6.49 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047390153440845344		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.047390153440845344 | validation: 0.07068382891824015]
	TIME [epoch: 6.49 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07523696879790147		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.07523696879790147 | validation: 0.06782954560370787]
	TIME [epoch: 6.49 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06545748749530761		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.06545748749530761 | validation: 0.047480339005586285]
	TIME [epoch: 6.49 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058578911911363524		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.058578911911363524 | validation: 0.053341343583494946]
	TIME [epoch: 6.49 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06865685537567329		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.06865685537567329 | validation: 0.0768275060079173]
	TIME [epoch: 6.5 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06885300191883542		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.06885300191883542 | validation: 0.04639791608725938]
	TIME [epoch: 6.52 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06982501046103921		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.06982501046103921 | validation: 0.06961360252085665]
	TIME [epoch: 6.5 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05816637183267774		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.05816637183267774 | validation: 0.10262343155437624]
	TIME [epoch: 6.49 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09400272263197444		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.09400272263197444 | validation: 0.04722811368952939]
	TIME [epoch: 6.49 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06259829272042583		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.06259829272042583 | validation: 0.05754544144846305]
	TIME [epoch: 6.5 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052242178155494104		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.052242178155494104 | validation: 0.0436977370470022]
	TIME [epoch: 6.49 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047129695041691844		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.047129695041691844 | validation: 0.04470670779143543]
	TIME [epoch: 6.52 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06468244756152018		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.06468244756152018 | validation: 0.07444239363649606]
	TIME [epoch: 6.51 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059392872506500764		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.059392872506500764 | validation: 0.043587269277739225]
	TIME [epoch: 6.5 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054291012870011826		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.054291012870011826 | validation: 0.066279890799471]
	TIME [epoch: 6.49 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07472866323223075		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.07472866323223075 | validation: 0.09131149261835564]
	TIME [epoch: 6.49 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07378720479406489		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.07378720479406489 | validation: 0.06398427356840956]
	TIME [epoch: 6.49 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05752931829921512		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.05752931829921512 | validation: 0.06575977302297774]
	TIME [epoch: 6.49 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06382990341180624		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.06382990341180624 | validation: 0.04937869350536642]
	TIME [epoch: 6.51 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06862773320043208		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.06862773320043208 | validation: 0.07165080692384385]
	TIME [epoch: 6.54 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11015515957023753		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.11015515957023753 | validation: 0.11727482798999095]
	TIME [epoch: 6.49 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09323555522787623		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.09323555522787623 | validation: 0.06307126997543352]
	TIME [epoch: 6.49 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06135618803962418		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.06135618803962418 | validation: 0.04856234767684118]
	TIME [epoch: 6.49 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05648349568779959		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.05648349568779959 | validation: 0.05556739874206532]
	TIME [epoch: 6.49 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07401216761952689		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.07401216761952689 | validation: 0.06452000339284586]
	TIME [epoch: 6.49 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06761928606268967		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.06761928606268967 | validation: 0.04924193445953913]
	TIME [epoch: 6.51 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05518656323149962		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.05518656323149962 | validation: 0.04527195741507307]
	TIME [epoch: 6.53 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05952560066009914		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.05952560066009914 | validation: 0.09796530165087534]
	TIME [epoch: 6.51 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0659818625416582		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.0659818625416582 | validation: 0.05315868524223747]
	TIME [epoch: 6.48 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07156270948402639		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.07156270948402639 | validation: 0.08690069500972929]
	TIME [epoch: 6.5 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07027385313861395		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.07027385313861395 | validation: 0.06326558918784551]
	TIME [epoch: 6.49 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07560061965782329		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.07560061965782329 | validation: 0.052751702148811475]
	TIME [epoch: 6.49 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06473096695087667		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.06473096695087667 | validation: 0.0319534152830142]
	TIME [epoch: 6.5 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05482167256400172		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.05482167256400172 | validation: 0.0620924188036973]
	TIME [epoch: 6.53 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07091877924857484		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.07091877924857484 | validation: 0.0814270613815884]
	TIME [epoch: 6.51 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08145761400706839		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.08145761400706839 | validation: 0.053332477326466864]
	TIME [epoch: 6.49 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08332699317147678		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.08332699317147678 | validation: 0.11186996173841461]
	TIME [epoch: 6.5 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07416332585631369		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.07416332585631369 | validation: 0.03504725193164409]
	TIME [epoch: 6.5 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05183283297781181		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.05183283297781181 | validation: 0.02666612055814067]
	TIME [epoch: 6.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_921.pth
	Model improved!!!
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04527926968324075		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.04527926968324075 | validation: 0.04212623712824222]
	TIME [epoch: 6.58 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060305923234549516		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.060305923234549516 | validation: 0.07482081931851108]
	TIME [epoch: 6.53 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07129404213656207		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.07129404213656207 | validation: 0.03343401514446167]
	TIME [epoch: 6.49 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04692451685022857		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.04692451685022857 | validation: 0.032487382139918405]
	TIME [epoch: 6.49 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04688026403477816		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.04688026403477816 | validation: 0.035751679078411515]
	TIME [epoch: 6.49 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06948936107182277		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.06948936107182277 | validation: 0.05866087563775672]
	TIME [epoch: 6.49 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058890699380487306		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.058890699380487306 | validation: 0.03218587062291131]
	TIME [epoch: 6.5 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05335214849104436		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.05335214849104436 | validation: 0.05386611812150905]
	TIME [epoch: 6.51 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0672120835284816		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.0672120835284816 | validation: 0.06586630499116286]
	TIME [epoch: 6.53 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06036379725043674		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.06036379725043674 | validation: 0.05435166599075423]
	TIME [epoch: 6.5 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058583429257633254		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.058583429257633254 | validation: 0.04411679333055444]
	TIME [epoch: 6.49 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06968219836173578		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.06968219836173578 | validation: 0.05369808427012662]
	TIME [epoch: 6.49 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06392879579894865		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.06392879579894865 | validation: 0.04657466898706163]
	TIME [epoch: 6.49 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060760353123691824		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.060760353123691824 | validation: 0.0605108254745885]
	TIME [epoch: 6.51 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05223266243878147		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.05223266243878147 | validation: 0.05703297821723369]
	TIME [epoch: 6.49 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05719629211477997		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.05719629211477997 | validation: 0.035781555945141943]
	TIME [epoch: 6.54 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04343216664591318		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.04343216664591318 | validation: 0.03889932167250054]
	TIME [epoch: 6.51 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06007335572948348		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.06007335572948348 | validation: 0.054310867524010646]
	TIME [epoch: 6.49 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04305753547193979		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.04305753547193979 | validation: 0.03243489045455453]
	TIME [epoch: 6.5 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048455290362377584		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.048455290362377584 | validation: 0.06269563260302076]
	TIME [epoch: 6.49 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05732552761434611		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.05732552761434611 | validation: 0.05749288685851906]
	TIME [epoch: 6.5 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0712088594319235		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.0712088594319235 | validation: 0.05523741877576221]
	TIME [epoch: 6.49 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06363109768956493		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.06363109768956493 | validation: 0.06063398807981653]
	TIME [epoch: 6.52 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0544492233141336		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.0544492233141336 | validation: 0.0466896781449905]
	TIME [epoch: 6.5 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0518305047023887		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.0518305047023887 | validation: 0.05020449651714221]
	TIME [epoch: 6.5 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06336940844455403		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.06336940844455403 | validation: 0.09511113246675358]
	TIME [epoch: 6.48 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07077895782545826		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.07077895782545826 | validation: 0.04641150055231612]
	TIME [epoch: 6.49 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04846974737244834		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.04846974737244834 | validation: 0.040450206132284734]
	TIME [epoch: 6.5 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048968975489839126		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.048968975489839126 | validation: 0.07206892742093231]
	TIME [epoch: 6.5 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07222769078477542		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.07222769078477542 | validation: 0.04192319550172892]
	TIME [epoch: 6.51 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05396374226678412		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.05396374226678412 | validation: 0.03722194275090282]
	TIME [epoch: 6.5 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04281760040865328		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.04281760040865328 | validation: 0.021678688781074214]
	TIME [epoch: 6.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_953.pth
	Model improved!!!
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049339065987489154		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.049339065987489154 | validation: 0.04267162928863043]
	TIME [epoch: 6.58 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05511935233918145		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.05511935233918145 | validation: 0.056698726041320424]
	TIME [epoch: 6.48 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06399851481332017		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.06399851481332017 | validation: 0.05923502582902119]
	TIME [epoch: 6.49 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056639000750923825		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.056639000750923825 | validation: 0.07327461957490361]
	TIME [epoch: 6.47 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07759012883265334		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.07759012883265334 | validation: 0.04227329060113191]
	TIME [epoch: 6.51 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044982065436742914		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.044982065436742914 | validation: 0.044109557638010895]
	TIME [epoch: 6.5 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05012731691592681		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.05012731691592681 | validation: 0.041227716129943776]
	TIME [epoch: 6.49 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057950059785360865		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.057950059785360865 | validation: 0.055295416795702414]
	TIME [epoch: 6.48 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0572982998526026		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.0572982998526026 | validation: 0.03537452454008807]
	TIME [epoch: 6.47 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04223054113883516		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.04223054113883516 | validation: 0.04063406075103915]
	TIME [epoch: 6.47 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05240588052302381		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.05240588052302381 | validation: 0.028701932103869267]
	TIME [epoch: 6.47 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04701894663115044		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.04701894663115044 | validation: 0.044119184279154275]
	TIME [epoch: 6.48 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04824046313936754		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.04824046313936754 | validation: 0.029047892068723918]
	TIME [epoch: 6.49 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042107105793601066		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.042107105793601066 | validation: 0.04679776046009122]
	TIME [epoch: 6.48 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0493146210737314		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.0493146210737314 | validation: 0.054781687253594384]
	TIME [epoch: 6.47 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05805113945805398		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.05805113945805398 | validation: 0.04006099151200769]
	TIME [epoch: 6.48 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04779249029720911		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.04779249029720911 | validation: 0.05449228763137155]
	TIME [epoch: 6.47 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053226602287591795		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.053226602287591795 | validation: 0.05513138996740243]
	TIME [epoch: 6.48 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059811589767549606		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.059811589767549606 | validation: 0.06795219786863559]
	TIME [epoch: 6.49 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0800557628541453		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.0800557628541453 | validation: 0.042202585876607926]
	TIME [epoch: 6.49 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061860059137165774		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.061860059137165774 | validation: 0.038609211304514314]
	TIME [epoch: 6.47 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04621235766096866		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.04621235766096866 | validation: 0.04459057130723222]
	TIME [epoch: 6.47 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04656490821016606		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.04656490821016606 | validation: 0.0409563024425008]
	TIME [epoch: 6.46 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05840216347423499		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.05840216347423499 | validation: 0.07189442423392267]
	TIME [epoch: 6.47 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07089768884036061		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.07089768884036061 | validation: 0.0458316028345731]
	TIME [epoch: 6.49 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0595170362222529		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.0595170362222529 | validation: 0.05285025902330942]
	TIME [epoch: 6.49 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06581478006213416		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.06581478006213416 | validation: 0.04443356141493909]
	TIME [epoch: 6.52 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048144582099612435		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.048144582099612435 | validation: 0.0377171297761064]
	TIME [epoch: 6.48 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04892620598889015		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.04892620598889015 | validation: 0.045309956179336516]
	TIME [epoch: 6.47 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056128114948904045		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.056128114948904045 | validation: 0.04181562153447898]
	TIME [epoch: 6.49 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047782738217603676		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.047782738217603676 | validation: 0.04300359719165362]
	TIME [epoch: 6.49 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044677561399782836		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.044677561399782836 | validation: 0.05468413683114954]
	TIME [epoch: 6.48 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052721565893062455		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.052721565893062455 | validation: 0.053699089171030945]
	TIME [epoch: 6.49 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054398572117527744		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.054398572117527744 | validation: 0.0540149568725952]
	TIME [epoch: 6.53 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05874590880646733		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.05874590880646733 | validation: 0.04373716510731926]
	TIME [epoch: 6.5 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05994403748795356		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.05994403748795356 | validation: 0.04489417623075236]
	TIME [epoch: 6.5 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05659111853429422		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.05659111853429422 | validation: 0.05536107170251635]
	TIME [epoch: 6.5 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058117301443155876		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.058117301443155876 | validation: 0.06515238596052188]
	TIME [epoch: 6.49 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08412500989798946		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.08412500989798946 | validation: 0.04291016039708679]
	TIME [epoch: 6.51 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04302953467185318		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.04302953467185318 | validation: 0.04693206289323009]
	TIME [epoch: 6.49 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05026637547257869		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.05026637547257869 | validation: 0.06961108863528509]
	TIME [epoch: 6.54 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0690037857391185		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.0690037857391185 | validation: 0.09654471653306981]
	TIME [epoch: 6.49 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07480251633481917		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.07480251633481917 | validation: 0.05160945992124988]
	TIME [epoch: 6.5 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05835416262910925		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.05835416262910925 | validation: 0.05189945786915327]
	TIME [epoch: 6.49 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056939261253249204		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.056939261253249204 | validation: 0.062223136299046064]
	TIME [epoch: 6.5 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04911931444552864		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.04911931444552864 | validation: 0.05202293431855447]
	TIME [epoch: 6.5 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05038446469622825		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.05038446469622825 | validation: 0.03140198214556528]
	TIME [epoch: 6.5 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040691718599600996		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.040691718599600996 | validation: 0.03234381793940232]
	TIME [epoch: 6.54 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041897189918290986		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.041897189918290986 | validation: 0.026620564769438974]
	TIME [epoch: 6.5 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04052618021762214		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.04052618021762214 | validation: 0.03718452642198694]
	TIME [epoch: 6.5 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04162534022308921		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.04162534022308921 | validation: 0.03934753135936794]
	TIME [epoch: 6.5 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047563514108276875		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.047563514108276875 | validation: 0.04490381392947919]
	TIME [epoch: 6.5 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053679268135952765		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.053679268135952765 | validation: 0.06770127372974086]
	TIME [epoch: 6.49 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05336918821494286		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.05336918821494286 | validation: 0.029322817588926554]
	TIME [epoch: 6.5 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04251151364402513		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.04251151364402513 | validation: 0.028420315019006166]
	TIME [epoch: 6.53 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04741646716089577		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.04741646716089577 | validation: 0.049422430568772706]
	TIME [epoch: 6.51 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05506134022534409		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.05506134022534409 | validation: 0.05208203601592118]
	TIME [epoch: 6.5 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056085605588212586		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.056085605588212586 | validation: 0.0860835058313885]
	TIME [epoch: 6.5 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061281190243186213		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.061281190243186213 | validation: 0.0466965190413111]
	TIME [epoch: 6.5 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06746845114255574		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.06746845114255574 | validation: 0.06709272056950048]
	TIME [epoch: 6.51 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051944081594178224		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.051944081594178224 | validation: 0.05441370152039833]
	TIME [epoch: 6.5 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05991508086754009		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.05991508086754009 | validation: 0.06587938554768644]
	TIME [epoch: 6.54 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0512840862989461		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.0512840862989461 | validation: 0.03456036768018593]
	TIME [epoch: 6.5 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046776084482345735		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.046776084482345735 | validation: 0.0694348349606844]
	TIME [epoch: 6.5 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05720230340106213		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.05720230340106213 | validation: 0.04797120229810169]
	TIME [epoch: 6.51 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047219995464817976		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.047219995464817976 | validation: 0.05390394200910254]
	TIME [epoch: 6.5 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07872515815943071		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.07872515815943071 | validation: 0.07123217014572453]
	TIME [epoch: 6.49 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05818440339207608		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.05818440339207608 | validation: 0.04400676272867573]
	TIME [epoch: 6.49 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06030463771877018		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.06030463771877018 | validation: 0.05261639152147825]
	TIME [epoch: 6.52 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05348039647517258		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.05348039647517258 | validation: 0.046548045267433835]
	TIME [epoch: 6.52 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04698216429580306		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.04698216429580306 | validation: 0.037294223615390566]
	TIME [epoch: 6.5 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04735027507625969		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.04735027507625969 | validation: 0.043589134030622305]
	TIME [epoch: 6.5 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04446353147317635		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.04446353147317635 | validation: 0.052225849865076536]
	TIME [epoch: 6.5 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04740825078069674		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.04740825078069674 | validation: 0.05942663825658972]
	TIME [epoch: 6.5 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05227444357456623		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.05227444357456623 | validation: 0.05905896740658759]
	TIME [epoch: 6.49 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05219228070873395		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.05219228070873395 | validation: 0.05019859427610618]
	TIME [epoch: 6.52 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06063499724153068		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.06063499724153068 | validation: 0.04302594290282139]
	TIME [epoch: 6.52 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04559365641134525		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.04559365641134525 | validation: 0.05924726940482653]
	TIME [epoch: 6.51 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05844348448294211		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.05844348448294211 | validation: 0.044472764450950865]
	TIME [epoch: 6.5 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05541752686951068		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.05541752686951068 | validation: 0.06366502611553795]
	TIME [epoch: 6.49 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06980775709293698		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.06980775709293698 | validation: 0.05098241653924012]
	TIME [epoch: 6.49 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06549046104348445		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.06549046104348445 | validation: 0.07151707851492804]
	TIME [epoch: 6.5 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06218997784023082		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.06218997784023082 | validation: 0.05657855399784427]
	TIME [epoch: 6.52 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052484201582353215		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.052484201582353215 | validation: 0.03688882564512761]
	TIME [epoch: 6.53 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04480430870885867		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.04480430870885867 | validation: 0.04335202272248148]
	TIME [epoch: 6.51 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043264807128499644		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.043264807128499644 | validation: 0.04357262010703897]
	TIME [epoch: 6.5 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03954288404671781		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.03954288404671781 | validation: 0.037660803146706605]
	TIME [epoch: 6.5 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04228929430720657		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.04228929430720657 | validation: 0.04641824328566351]
	TIME [epoch: 6.5 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04512614175875225		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.04512614175875225 | validation: 0.05521921028441517]
	TIME [epoch: 6.5 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04763466752671974		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.04763466752671974 | validation: 0.035341588174094225]
	TIME [epoch: 6.5 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04084052313474331		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.04084052313474331 | validation: 0.036038908263967454]
	TIME [epoch: 6.53 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04962182586281724		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.04962182586281724 | validation: 0.036028336491395016]
	TIME [epoch: 6.49 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03885563950976498		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.03885563950976498 | validation: 0.03276481476183283]
	TIME [epoch: 6.5 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050090807674724507		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.050090807674724507 | validation: 0.06980882622013419]
	TIME [epoch: 6.5 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.067995205990792		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.067995205990792 | validation: 0.05598360349622226]
	TIME [epoch: 6.5 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057744718540020626		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.057744718540020626 | validation: 0.048560203341100866]
	TIME [epoch: 6.5 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047357445745504545		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.047357445745504545 | validation: 0.04760657873169721]
	TIME [epoch: 6.51 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05123120607096517		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.05123120607096517 | validation: 0.05581670982318122]
	TIME [epoch: 6.52 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06316282266302926		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.06316282266302926 | validation: 0.056223654273544296]
	TIME [epoch: 6.49 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06074874838019394		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.06074874838019394 | validation: 0.06967874808059292]
	TIME [epoch: 6.5 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058926808755606026		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.058926808755606026 | validation: 0.04747582279657963]
	TIME [epoch: 6.5 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040187813246591715		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.040187813246591715 | validation: 0.04180425810839477]
	TIME [epoch: 6.49 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04088405796092429		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.04088405796092429 | validation: 0.040614981315855746]
	TIME [epoch: 6.5 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05207269816556782		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.05207269816556782 | validation: 0.05167050680390032]
	TIME [epoch: 6.5 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049737499307029434		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.049737499307029434 | validation: 0.0529150128824697]
	TIME [epoch: 6.55 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05125393816154779		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.05125393816154779 | validation: 0.056632839561750394]
	TIME [epoch: 6.51 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0566605249636772		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.0566605249636772 | validation: 0.05109852276149763]
	TIME [epoch: 6.5 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056826842496160664		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.056826842496160664 | validation: 0.07160301940120171]
	TIME [epoch: 6.5 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07272664453301195		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.07272664453301195 | validation: 0.06344000019401959]
	TIME [epoch: 6.48 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06539936740338649		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.06539936740338649 | validation: 0.06966539677119284]
	TIME [epoch: 6.48 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05158042661037866		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.05158042661037866 | validation: 0.032325802460973684]
	TIME [epoch: 6.48 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04280364184101702		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.04280364184101702 | validation: 0.04934152764154273]
	TIME [epoch: 6.52 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05308865516263029		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.05308865516263029 | validation: 0.04826636662438965]
	TIME [epoch: 6.49 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05471364085954826		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.05471364085954826 | validation: 0.04882504993536438]
	TIME [epoch: 6.48 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04364005840115143		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.04364005840115143 | validation: 0.03691374832076437]
	TIME [epoch: 6.49 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0523628147251107		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.0523628147251107 | validation: 0.03938590007537537]
	TIME [epoch: 6.48 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04915794898919154		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.04915794898919154 | validation: 0.038868022900433834]
	TIME [epoch: 6.49 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0517666733166184		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.0517666733166184 | validation: 0.041249301810734704]
	TIME [epoch: 6.48 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04594232447623497		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.04594232447623497 | validation: 0.064475502488014]
	TIME [epoch: 6.52 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0640661347756299		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.0640661347756299 | validation: 0.03135348136630252]
	TIME [epoch: 6.49 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03974612600115542		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.03974612600115542 | validation: 0.03400777761910776]
	TIME [epoch: 6.48 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05467018525933639		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.05467018525933639 | validation: 0.03885500492827058]
	TIME [epoch: 6.48 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04614086094166639		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.04614086094166639 | validation: 0.0423621353551181]
	TIME [epoch: 6.48 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04742444159788429		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.04742444159788429 | validation: 0.042688490021352596]
	TIME [epoch: 6.49 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04949505367644788		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.04949505367644788 | validation: 0.04878033584641548]
	TIME [epoch: 6.49 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06297380540685453		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.06297380540685453 | validation: 0.05916319391392721]
	TIME [epoch: 6.52 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06366889352487647		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.06366889352487647 | validation: 0.03463888911317076]
	TIME [epoch: 6.5 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04976186134030329		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.04976186134030329 | validation: 0.06752467804801075]
	TIME [epoch: 6.49 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06473848080154165		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.06473848080154165 | validation: 0.05236732299490195]
	TIME [epoch: 6.49 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05854713002116444		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.05854713002116444 | validation: 0.04033765731779937]
	TIME [epoch: 6.49 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04930764181889571		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.04930764181889571 | validation: 0.038168433713281956]
	TIME [epoch: 6.49 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0426564362109307		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.0426564362109307 | validation: 0.0341314264875979]
	TIME [epoch: 6.49 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04415886771050786		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.04415886771050786 | validation: 0.041592253598378016]
	TIME [epoch: 6.51 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04230348112435811		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.04230348112435811 | validation: 0.05067518698290295]
	TIME [epoch: 6.51 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05768182268443598		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.05768182268443598 | validation: 0.053449591827978066]
	TIME [epoch: 6.49 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04127811565417672		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.04127811565417672 | validation: 0.05307006120605836]
	TIME [epoch: 6.5 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061739064921287876		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.061739064921287876 | validation: 0.04474672184921618]
	TIME [epoch: 6.5 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045911540527068515		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.045911540527068515 | validation: 0.04198054985005291]
	TIME [epoch: 6.5 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04525097878477634		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.04525097878477634 | validation: 0.03706116105109813]
	TIME [epoch: 6.49 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042431704107776615		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.042431704107776615 | validation: 0.025135626478635792]
	TIME [epoch: 6.5 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04114483995648976		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.04114483995648976 | validation: 0.0416665977925129]
	TIME [epoch: 6.51 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03820134610980403		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.03820134610980403 | validation: 0.022774371228471046]
	TIME [epoch: 6.48 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0433161885777123		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.0433161885777123 | validation: 0.04880669007495513]
	TIME [epoch: 6.49 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057822756549823905		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.057822756549823905 | validation: 0.024675566263919046]
	TIME [epoch: 6.5 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03753743735605561		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.03753743735605561 | validation: 0.03043276056451976]
	TIME [epoch: 6.49 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043370030285470956		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.043370030285470956 | validation: 0.05968336718618456]
	TIME [epoch: 6.49 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0568710572742689		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.0568710572742689 | validation: 0.0431561614028323]
	TIME [epoch: 6.51 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05379320265305907		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.05379320265305907 | validation: 0.040653602592583396]
	TIME [epoch: 6.51 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04240055339878667		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.04240055339878667 | validation: 0.05102649888870049]
	TIME [epoch: 6.49 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046104685255764985		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.046104685255764985 | validation: 0.050535426273723774]
	TIME [epoch: 6.48 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04799502870703404		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.04799502870703404 | validation: 0.040632573956073774]
	TIME [epoch: 6.48 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04770913933055323		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.04770913933055323 | validation: 0.028666388439174212]
	TIME [epoch: 6.48 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04173931089442978		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.04173931089442978 | validation: 0.026771177503921564]
	TIME [epoch: 6.49 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03930799191033582		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.03930799191033582 | validation: 0.03921382652749018]
	TIME [epoch: 6.5 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03798870874699368		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.03798870874699368 | validation: 0.047924913495690176]
	TIME [epoch: 6.52 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05175284128891826		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.05175284128891826 | validation: 0.04042722122297598]
	TIME [epoch: 6.49 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0393988419212141		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.0393988419212141 | validation: 0.03999756448030627]
	TIME [epoch: 6.5 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0519723454821506		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.0519723454821506 | validation: 0.05216526319621081]
	TIME [epoch: 6.49 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04559325651218542		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.04559325651218542 | validation: 0.04757593596770051]
	TIME [epoch: 6.5 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04979208424323425		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.04979208424323425 | validation: 0.03586435396938744]
	TIME [epoch: 6.48 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04638451242445071		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.04638451242445071 | validation: 0.05359503367431042]
	TIME [epoch: 6.5 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06282489309802361		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.06282489309802361 | validation: 0.05030707360953467]
	TIME [epoch: 6.52 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042301675858596816		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.042301675858596816 | validation: 0.03704738218573422]
	TIME [epoch: 6.5 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04065748499848878		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.04065748499848878 | validation: 0.03935072773427497]
	TIME [epoch: 6.48 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04462757758457907		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.04462757758457907 | validation: 0.032658656685812394]
	TIME [epoch: 6.5 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043751690604646454		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.043751690604646454 | validation: 0.0474971477539102]
	TIME [epoch: 6.49 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04150462108356155		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.04150462108356155 | validation: 0.027643189363898424]
	TIME [epoch: 6.49 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03777596114019265		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.03777596114019265 | validation: 0.03697293950501357]
	TIME [epoch: 6.48 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03723663785497279		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.03723663785497279 | validation: 0.04317865498965873]
	TIME [epoch: 6.54 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03828900834089154		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.03828900834089154 | validation: 0.03204843181740102]
	TIME [epoch: 6.5 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04449897416844713		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.04449897416844713 | validation: 0.040179181739341506]
	TIME [epoch: 6.48 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04649500190569487		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.04649500190569487 | validation: 0.026839321954441577]
	TIME [epoch: 6.49 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039681970096063474		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.039681970096063474 | validation: 0.03669766218559701]
	TIME [epoch: 6.49 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04387403919826341		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.04387403919826341 | validation: 0.031922278943822706]
	TIME [epoch: 6.49 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03680332896142695		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.03680332896142695 | validation: 0.03088937332068616]
	TIME [epoch: 6.5 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034116394239865545		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.034116394239865545 | validation: 0.03338435271122631]
	TIME [epoch: 6.52 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0535230852458487		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.0535230852458487 | validation: 0.038878049222886873]
	TIME [epoch: 6.5 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04703828848850197		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.04703828848850197 | validation: 0.04420236454026581]
	TIME [epoch: 6.5 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038590681206095316		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.038590681206095316 | validation: 0.03435856708776653]
	TIME [epoch: 6.48 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041502834929474534		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.041502834929474534 | validation: 0.0257762369047962]
	TIME [epoch: 6.48 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04078722675015812		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.04078722675015812 | validation: 0.03454661838239391]
	TIME [epoch: 6.48 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037365805186374446		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.037365805186374446 | validation: 0.03460996487842421]
	TIME [epoch: 6.48 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03928107547907646		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.03928107547907646 | validation: 0.040423759729195784]
	TIME [epoch: 6.51 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04066165520646556		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.04066165520646556 | validation: 0.03187740208188316]
	TIME [epoch: 6.49 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04158514660628902		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.04158514660628902 | validation: 0.032975518542298195]
	TIME [epoch: 6.47 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04732297485502193		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.04732297485502193 | validation: 0.04246480820027726]
	TIME [epoch: 6.47 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0365929831825966		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.0365929831825966 | validation: 0.03554410267593982]
	TIME [epoch: 6.47 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03665969592293078		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.03665969592293078 | validation: 0.026759689669244677]
	TIME [epoch: 6.46 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045152732377346766		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.045152732377346766 | validation: 0.04929999011037703]
	TIME [epoch: 6.47 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05063105547395192		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.05063105547395192 | validation: 0.03571455185349265]
	TIME [epoch: 6.5 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03677783794070456		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.03677783794070456 | validation: 0.03673714166971422]
	TIME [epoch: 6.48 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045197759722921324		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.045197759722921324 | validation: 0.04799519111909335]
	TIME [epoch: 6.46 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05315383065934161		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.05315383065934161 | validation: 0.04182720327558461]
	TIME [epoch: 6.48 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04482059191224894		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.04482059191224894 | validation: 0.03676988768809631]
	TIME [epoch: 6.47 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04276085927182847		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.04276085927182847 | validation: 0.040775731772896825]
	TIME [epoch: 6.47 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041527224072337894		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.041527224072337894 | validation: 0.03786072566990432]
	TIME [epoch: 6.47 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03752867284563553		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.03752867284563553 | validation: 0.04078962468762623]
	TIME [epoch: 6.49 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054274457548985064		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.054274457548985064 | validation: 0.04184266165978869]
	TIME [epoch: 6.49 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048544939936646034		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.048544939936646034 | validation: 0.04773895389983371]
	TIME [epoch: 6.47 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04051900595592688		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.04051900595592688 | validation: 0.04580755535331758]
	TIME [epoch: 6.49 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04487713011190775		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.04487713011190775 | validation: 0.04140504398344068]
	TIME [epoch: 6.46 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04109146180920535		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.04109146180920535 | validation: 0.03712249956174407]
	TIME [epoch: 6.48 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0408446122464478		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.0408446122464478 | validation: 0.037551502462183375]
	TIME [epoch: 6.48 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04996564757389354		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.04996564757389354 | validation: 0.04701360053791671]
	TIME [epoch: 6.49 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04629415748355502		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.04629415748355502 | validation: 0.04767271282830968]
	TIME [epoch: 6.51 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05150528852965994		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.05150528852965994 | validation: 0.04252071566141659]
	TIME [epoch: 6.49 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045407085621046596		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.045407085621046596 | validation: 0.043345279641344873]
	TIME [epoch: 6.47 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04972213565224174		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.04972213565224174 | validation: 0.053631158602110214]
	TIME [epoch: 6.48 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043939737602372506		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.043939737602372506 | validation: 0.04354742409480902]
	TIME [epoch: 6.48 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04823610759045545		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.04823610759045545 | validation: 0.04622087234147425]
	TIME [epoch: 6.48 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052160038171413285		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.052160038171413285 | validation: 0.0442671379823513]
	TIME [epoch: 6.5 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04472903355037554		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.04472903355037554 | validation: 0.04108845233948502]
	TIME [epoch: 6.52 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03924044533466974		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.03924044533466974 | validation: 0.04849824741481271]
	TIME [epoch: 6.48 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04717121205582764		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.04717121205582764 | validation: 0.04241823967115659]
	TIME [epoch: 6.5 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04098578729043918		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.04098578729043918 | validation: 0.043148839689552874]
	TIME [epoch: 6.48 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046589358740572136		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.046589358740572136 | validation: 0.041003344267789114]
	TIME [epoch: 6.49 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04332291208468153		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.04332291208468153 | validation: 0.04777347597972462]
	TIME [epoch: 6.49 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046861328609449325		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.046861328609449325 | validation: 0.03679827524507035]
	TIME [epoch: 6.5 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039653505561193084		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.039653505561193084 | validation: 0.03867785530854421]
	TIME [epoch: 6.52 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045252963327076054		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.045252963327076054 | validation: 0.04184435057780533]
	TIME [epoch: 6.51 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04481364471400048		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.04481364471400048 | validation: 0.03980972521670823]
	TIME [epoch: 6.48 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04758976742537055		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.04758976742537055 | validation: 0.03324202993907887]
	TIME [epoch: 6.5 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05882680685653659		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.05882680685653659 | validation: 0.06234348522966191]
	TIME [epoch: 6.49 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062288843724255735		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.062288843724255735 | validation: 0.04497663989117069]
	TIME [epoch: 6.48 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04667117674125902		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.04667117674125902 | validation: 0.03103277666837275]
	TIME [epoch: 6.5 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043895871909332106		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.043895871909332106 | validation: 0.04610387601209337]
	TIME [epoch: 6.53 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04615226497387563		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.04615226497387563 | validation: 0.039662294294098774]
	TIME [epoch: 6.48 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037478466055658896		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.037478466055658896 | validation: 0.023406427428480692]
	TIME [epoch: 6.5 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04321860624435067		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.04321860624435067 | validation: 0.039653120249103696]
	TIME [epoch: 6.48 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04286280230804117		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.04286280230804117 | validation: 0.03464576451756572]
	TIME [epoch: 6.49 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042166940826701846		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.042166940826701846 | validation: 0.028049571878196157]
	TIME [epoch: 6.49 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045880553717888906		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.045880553717888906 | validation: 0.03959585994519612]
	TIME [epoch: 6.49 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03882606729588706		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.03882606729588706 | validation: 0.03587972381871065]
	TIME [epoch: 6.52 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04474439635477158		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.04474439635477158 | validation: 0.03739754100718573]
	TIME [epoch: 6.5 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05112426504833829		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.05112426504833829 | validation: 0.043493171034531625]
	TIME [epoch: 6.48 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043761952246946		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.043761952246946 | validation: 0.03391629469343894]
	TIME [epoch: 6.49 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03734640882430729		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.03734640882430729 | validation: 0.03605060168945623]
	TIME [epoch: 6.49 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04128211408937081		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.04128211408937081 | validation: 0.04822726831046655]
	TIME [epoch: 6.49 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04641050779837018		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.04641050779837018 | validation: 0.03269528285924051]
	TIME [epoch: 6.51 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03808657897746045		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.03808657897746045 | validation: 0.034457587962223]
	TIME [epoch: 6.52 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03788418344545759		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.03788418344545759 | validation: 0.03422157606966156]
	TIME [epoch: 6.49 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03852388178095614		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.03852388178095614 | validation: 0.041660709886981076]
	TIME [epoch: 6.49 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04444825102158523		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.04444825102158523 | validation: 0.04214040399762048]
	TIME [epoch: 6.49 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042559654618986996		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.042559654618986996 | validation: 0.03701540437673372]
	TIME [epoch: 6.49 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0452505357020478		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.0452505357020478 | validation: 0.05553222763919712]
	TIME [epoch: 6.49 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04946534516157304		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.04946534516157304 | validation: 0.049695591607780205]
	TIME [epoch: 6.49 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041383065937177305		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.041383065937177305 | validation: 0.029089746846920814]
	TIME [epoch: 6.53 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034758328617202724		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.034758328617202724 | validation: 0.03798072296833402]
	TIME [epoch: 6.5 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03706673480702162		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.03706673480702162 | validation: 0.03355876536343095]
	TIME [epoch: 6.49 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041492084220904876		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.041492084220904876 | validation: 0.052751652724352456]
	TIME [epoch: 6.49 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04193084225093768		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.04193084225093768 | validation: 0.03764249790974979]
	TIME [epoch: 6.49 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035697170691254304		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.035697170691254304 | validation: 0.030064557675269492]
	TIME [epoch: 6.49 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041884636419977334		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.041884636419977334 | validation: 0.035511909829323514]
	TIME [epoch: 6.49 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03918909138245362		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.03918909138245362 | validation: 0.0437538754473567]
	TIME [epoch: 6.53 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0448234894375209		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.0448234894375209 | validation: 0.038968374312852785]
	TIME [epoch: 6.49 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04442952451536067		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.04442952451536067 | validation: 0.03845425807361612]
	TIME [epoch: 6.5 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03943051272840469		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.03943051272840469 | validation: 0.039520641229560304]
	TIME [epoch: 6.5 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03780090882143287		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.03780090882143287 | validation: 0.027939584110864387]
	TIME [epoch: 6.5 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035718713730190345		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.035718713730190345 | validation: 0.0326326521307938]
	TIME [epoch: 6.5 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040826088844606964		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.040826088844606964 | validation: 0.054780348579452624]
	TIME [epoch: 6.5 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040706464552054955		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.040706464552054955 | validation: 0.03570311995253695]
	TIME [epoch: 6.5 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03544058507172662		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.03544058507172662 | validation: 0.031980148810437266]
	TIME [epoch: 6.51 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03685717510264599		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.03685717510264599 | validation: 0.026575363256442136]
	TIME [epoch: 6.49 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03974070796306432		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.03974070796306432 | validation: 0.03970966649809895]
	TIME [epoch: 6.5 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035770137529893706		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.035770137529893706 | validation: 0.025557969982527684]
	TIME [epoch: 6.49 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04261575767663303		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.04261575767663303 | validation: 0.04492867599575993]
	TIME [epoch: 6.5 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04168090120269214		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.04168090120269214 | validation: 0.029715967600576924]
	TIME [epoch: 6.48 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035336123476035076		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.035336123476035076 | validation: 0.034353032071483866]
	TIME [epoch: 6.52 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03488314363683477		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.03488314363683477 | validation: 0.03195329347927643]
	TIME [epoch: 6.51 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040586987612591		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.040586987612591 | validation: 0.039000035410699144]
	TIME [epoch: 6.5 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04538079641437446		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.04538079641437446 | validation: 0.04760100287977562]
	TIME [epoch: 6.49 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04536994953382788		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.04536994953382788 | validation: 0.03910868258456987]
	TIME [epoch: 6.5 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04475387688774198		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.04475387688774198 | validation: 0.03225287810484739]
	TIME [epoch: 6.49 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03552612608675714		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.03552612608675714 | validation: 0.03558757202160706]
	TIME [epoch: 6.5 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04696915276837526		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.04696915276837526 | validation: 0.04853087954573337]
	TIME [epoch: 6.51 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05025413279663476		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.05025413279663476 | validation: 0.02949074746121126]
	TIME [epoch: 6.52 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03675341466986829		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.03675341466986829 | validation: 0.025833063108434588]
	TIME [epoch: 6.5 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03794951597386218		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.03794951597386218 | validation: 0.03910674921070848]
	TIME [epoch: 6.5 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04187774094520894		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.04187774094520894 | validation: 0.032764785177899776]
	TIME [epoch: 6.48 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038500792667514626		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.038500792667514626 | validation: 0.035000882668041224]
	TIME [epoch: 6.5 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03810453790880525		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.03810453790880525 | validation: 0.026966652581153352]
	TIME [epoch: 6.49 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04244977637106888		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.04244977637106888 | validation: 0.025992336445356923]
	TIME [epoch: 6.49 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03351745136987487		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.03351745136987487 | validation: 0.034747458853309605]
	TIME [epoch: 6.52 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0331611264366337		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.0331611264366337 | validation: 0.034889497213400775]
	TIME [epoch: 6.48 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03659374429792386		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.03659374429792386 | validation: 0.03696435641441307]
	TIME [epoch: 6.49 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03760758623900377		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.03760758623900377 | validation: 0.027118947382852365]
	TIME [epoch: 6.48 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041485857211114086		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.041485857211114086 | validation: 0.040517684707517106]
	TIME [epoch: 6.5 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0353812703639748		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.0353812703639748 | validation: 0.02929254274056922]
	TIME [epoch: 6.49 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03379388742429984		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.03379388742429984 | validation: 0.032327471520210614]
	TIME [epoch: 6.49 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03492389308613295		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.03492389308613295 | validation: 0.02484550927302788]
	TIME [epoch: 6.51 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03534654915501148		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.03534654915501148 | validation: 0.028440974500722305]
	TIME [epoch: 6.48 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035042640448917986		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.035042640448917986 | validation: 0.03474653349436012]
	TIME [epoch: 6.5 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043001954132066755		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.043001954132066755 | validation: 0.038142099577289396]
	TIME [epoch: 6.49 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05142341527367208		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.05142341527367208 | validation: 0.06872424322755986]
	TIME [epoch: 6.49 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062410506665696336		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.062410506665696336 | validation: 0.050597847271113515]
	TIME [epoch: 6.49 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05111715757967854		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.05111715757967854 | validation: 0.038937804273420654]
	TIME [epoch: 6.51 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03975857158890638		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.03975857158890638 | validation: 0.03170577353486978]
	TIME [epoch: 6.54 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03468147110032264		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.03468147110032264 | validation: 0.03019278179474382]
	TIME [epoch: 6.51 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031003444602466845		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.031003444602466845 | validation: 0.03284671265542794]
	TIME [epoch: 6.49 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03535309830596117		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.03535309830596117 | validation: 0.026864158176103454]
	TIME [epoch: 6.51 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04131497340394367		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.04131497340394367 | validation: 0.03172899499003493]
	TIME [epoch: 6.51 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0407676409059758		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.0407676409059758 | validation: 0.03095084648930075]
	TIME [epoch: 6.51 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03618695244419925		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.03618695244419925 | validation: 0.029227183541765345]
	TIME [epoch: 6.51 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04257691480661807		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.04257691480661807 | validation: 0.024637910841206097]
	TIME [epoch: 6.54 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03862423242081059		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.03862423242081059 | validation: 0.02843099198482451]
	TIME [epoch: 6.51 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03498924682696983		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.03498924682696983 | validation: 0.023063149117239955]
	TIME [epoch: 6.5 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037602336353215866		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.037602336353215866 | validation: 0.022877082460725326]
	TIME [epoch: 6.5 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03258194290924494		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.03258194290924494 | validation: 0.02732025850145871]
	TIME [epoch: 6.5 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0392955956430048		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.0392955956430048 | validation: 0.04682224615243893]
	TIME [epoch: 6.5 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0435829275106262		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.0435829275106262 | validation: 0.039212761357706426]
	TIME [epoch: 6.49 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04002669564795354		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.04002669564795354 | validation: 0.03347231787262671]
	TIME [epoch: 6.53 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04567316521364578		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.04567316521364578 | validation: 0.03327037973877711]
	TIME [epoch: 6.49 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04774581815227082		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.04774581815227082 | validation: 0.04249043512062177]
	TIME [epoch: 6.48 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04967002212425345		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.04967002212425345 | validation: 0.040630115235408784]
	TIME [epoch: 6.48 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0414750677865255		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.0414750677865255 | validation: 0.038821967450152615]
	TIME [epoch: 6.48 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04689944671565784		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.04689944671565784 | validation: 0.05103308951401697]
	TIME [epoch: 6.48 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04612691457275248		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.04612691457275248 | validation: 0.03367008279132441]
	TIME [epoch: 6.49 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03155950694624987		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.03155950694624987 | validation: 0.03244000649300253]
	TIME [epoch: 6.52 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032636013053315		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.032636013053315 | validation: 0.03410737291644174]
	TIME [epoch: 6.49 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038900605736060266		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.038900605736060266 | validation: 0.02430732522408003]
	TIME [epoch: 6.49 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04163041452089497		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.04163041452089497 | validation: 0.02638180454188032]
	TIME [epoch: 6.48 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037624324324321994		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.037624324324321994 | validation: 0.033448240948259204]
	TIME [epoch: 6.49 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04345840294942635		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.04345840294942635 | validation: 0.04012565148300069]
	TIME [epoch: 6.49 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040981524704997635		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.040981524704997635 | validation: 0.029452170706428773]
	TIME [epoch: 6.49 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038028332573638315		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.038028332573638315 | validation: 0.047847343823066865]
	TIME [epoch: 6.52 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04183882290023256		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.04183882290023256 | validation: 0.04029654605216168]
	TIME [epoch: 6.49 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03750824887493378		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.03750824887493378 | validation: 0.029898308134089224]
	TIME [epoch: 6.48 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03404793467940016		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.03404793467940016 | validation: 0.025891857754677998]
	TIME [epoch: 6.49 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03631974860293236		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.03631974860293236 | validation: 0.030511947899578177]
	TIME [epoch: 6.49 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040609928206544674		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.040609928206544674 | validation: 0.044979088452405995]
	TIME [epoch: 6.48 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04252373218208838		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.04252373218208838 | validation: 0.038102470236162034]
	TIME [epoch: 6.49 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0460519857423266		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.0460519857423266 | validation: 0.035412322966246]
	TIME [epoch: 6.51 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03831532731235998		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.03831532731235998 | validation: 0.0342833286467649]
	TIME [epoch: 6.51 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03632677669600446		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.03632677669600446 | validation: 0.04388087779559527]
	TIME [epoch: 6.49 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041767898987000354		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.041767898987000354 | validation: 0.032595121941507876]
	TIME [epoch: 6.5 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039748009973009285		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.039748009973009285 | validation: 0.024129294394009806]
	TIME [epoch: 6.5 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03638290039565684		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.03638290039565684 | validation: 0.04030375431071284]
	TIME [epoch: 6.52 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039437294052609484		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.039437294052609484 | validation: 0.03475589480885124]
	TIME [epoch: 6.51 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04309175612043118		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.04309175612043118 | validation: 0.03205513189449463]
	TIME [epoch: 6.52 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04621654796987294		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.04621654796987294 | validation: 0.05054337402349001]
	TIME [epoch: 6.58 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0423577269914141		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.0423577269914141 | validation: 0.03373936884627785]
	TIME [epoch: 6.49 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04315418182936297		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.04315418182936297 | validation: 0.03743806832971085]
	TIME [epoch: 6.5 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04523669223615458		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.04523669223615458 | validation: 0.03458672249956024]
	TIME [epoch: 6.49 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04590194603923007		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.04590194603923007 | validation: 0.03570885227570916]
	TIME [epoch: 6.5 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04511987659237109		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.04511987659237109 | validation: 0.02954914544489777]
	TIME [epoch: 6.51 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04513802767022994		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.04513802767022994 | validation: 0.031843693823392256]
	TIME [epoch: 6.52 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04278202657743794		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.04278202657743794 | validation: 0.03841550089679351]
	TIME [epoch: 6.51 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04616028079668173		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.04616028079668173 | validation: 0.029082799655696743]
	TIME [epoch: 6.49 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04147135511359968		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.04147135511359968 | validation: 0.02962196635185551]
	TIME [epoch: 6.48 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04858089778691703		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.04858089778691703 | validation: 0.03736189511592749]
	TIME [epoch: 6.49 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05039791470106654		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.05039791470106654 | validation: 0.029685564083053593]
	TIME [epoch: 6.49 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05143975862110091		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.05143975862110091 | validation: 0.044087697347809734]
	TIME [epoch: 6.5 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0584027745365289		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.0584027745365289 | validation: 0.03299821912556727]
	TIME [epoch: 6.5 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04942072699471385		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.04942072699471385 | validation: 0.034221402699556334]
	TIME [epoch: 6.51 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05189485193652007		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.05189485193652007 | validation: 0.0342280876724049]
	TIME [epoch: 6.48 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048607492722271356		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.048607492722271356 | validation: 0.03547291718329808]
	TIME [epoch: 6.5 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04593565164642454		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.04593565164642454 | validation: 0.033229518299460824]
	TIME [epoch: 6.48 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04060564459353411		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.04060564459353411 | validation: 0.028284096714358997]
	TIME [epoch: 6.48 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04271086684151225		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.04271086684151225 | validation: 0.034529170400153374]
	TIME [epoch: 6.5 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04042038665432267		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.04042038665432267 | validation: 0.02479898488167785]
	TIME [epoch: 6.49 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03675993981731885		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.03675993981731885 | validation: 0.03457864695880873]
	TIME [epoch: 6.54 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04138735284421239		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.04138735284421239 | validation: 0.03650153319311647]
	TIME [epoch: 6.51 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03843603146913573		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.03843603146913573 | validation: 0.03084846009283531]
	TIME [epoch: 6.5 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03799278088738062		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.03799278088738062 | validation: 0.03492428039237007]
	TIME [epoch: 6.5 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039349530634459264		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.039349530634459264 | validation: 0.027555206243359907]
	TIME [epoch: 6.5 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041444367585836694		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.041444367585836694 | validation: 0.02629938331665401]
	TIME [epoch: 6.5 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03967458990833878		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.03967458990833878 | validation: 0.024627059510399507]
	TIME [epoch: 6.5 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0438293141721149		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.0438293141721149 | validation: 0.029000172370802126]
	TIME [epoch: 6.53 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04927980837052903		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.04927980837052903 | validation: 0.03397897022096096]
	TIME [epoch: 6.5 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03948654237504911		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.03948654237504911 | validation: 0.041822658589565805]
	TIME [epoch: 6.5 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04397520500655688		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.04397520500655688 | validation: 0.03195189442448183]
	TIME [epoch: 6.49 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040373717010692645		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.040373717010692645 | validation: 0.03798905095610691]
	TIME [epoch: 6.5 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037582348267988466		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.037582348267988466 | validation: 0.034766377269851094]
	TIME [epoch: 6.5 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04500254513535268		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.04500254513535268 | validation: 0.030028417167142465]
	TIME [epoch: 6.5 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045910000992204644		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.045910000992204644 | validation: 0.03164075505496301]
	TIME [epoch: 6.54 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04169717942299476		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.04169717942299476 | validation: 0.04026455178338267]
	TIME [epoch: 6.51 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04421604302217414		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.04421604302217414 | validation: 0.025881648400970323]
	TIME [epoch: 6.5 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041859463862817387		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.041859463862817387 | validation: 0.037470487520596556]
	TIME [epoch: 6.49 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045637465682797904		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.045637465682797904 | validation: 0.03182880643508253]
	TIME [epoch: 6.5 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04265453058157794		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.04265453058157794 | validation: 0.02767099489303048]
	TIME [epoch: 6.5 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039539304848185665		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.039539304848185665 | validation: 0.03099882804304539]
	TIME [epoch: 6.5 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036743156795796275		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.036743156795796275 | validation: 0.033695538436005805]
	TIME [epoch: 6.53 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0398208208249935		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.0398208208249935 | validation: 0.05009025770821287]
	TIME [epoch: 6.5 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04367488000701841		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.04367488000701841 | validation: 0.03921219077981655]
	TIME [epoch: 6.48 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04351242950175098		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.04351242950175098 | validation: 0.023809481679000842]
	TIME [epoch: 6.5 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040068960546962816		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.040068960546962816 | validation: 0.029977406077661813]
	TIME [epoch: 6.48 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03499006194008272		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.03499006194008272 | validation: 0.03764608969833124]
	TIME [epoch: 6.5 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0332147941523455		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.0332147941523455 | validation: 0.021372566323777088]
	TIME [epoch: 6.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_1341.pth
	Model improved!!!
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032905175758247716		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.032905175758247716 | validation: 0.029958778997755883]
	TIME [epoch: 6.53 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036644352712238995		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.036644352712238995 | validation: 0.02906845288362974]
	TIME [epoch: 6.47 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03783721846313808		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.03783721846313808 | validation: 0.029182692072645355]
	TIME [epoch: 6.46 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03661129310987994		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.03661129310987994 | validation: 0.030613244843358978]
	TIME [epoch: 6.46 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04169721026497637		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.04169721026497637 | validation: 0.031669959619445236]
	TIME [epoch: 6.46 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038555769075927365		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.038555769075927365 | validation: 0.03169397484786721]
	TIME [epoch: 6.46 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035015090604790654		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.035015090604790654 | validation: 0.023031315314697043]
	TIME [epoch: 6.46 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03892354402986059		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.03892354402986059 | validation: 0.028472377779528664]
	TIME [epoch: 6.5 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033442816941978856		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.033442816941978856 | validation: 0.02387712798866043]
	TIME [epoch: 6.47 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03491043796009917		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.03491043796009917 | validation: 0.0193564961469137]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_1351.pth
	Model improved!!!
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03569423733044377		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.03569423733044377 | validation: 0.04060008920362506]
	TIME [epoch: 6.46 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04131806054292397		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.04131806054292397 | validation: 0.039055991089228186]
	TIME [epoch: 6.46 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044377550281497036		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.044377550281497036 | validation: 0.042283765318608175]
	TIME [epoch: 6.46 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04465795245975249		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.04465795245975249 | validation: 0.03830845686507469]
	TIME [epoch: 6.46 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036995557428472485		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.036995557428472485 | validation: 0.03677643132233739]
	TIME [epoch: 6.49 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033112981395596534		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.033112981395596534 | validation: 0.02657376540704683]
	TIME [epoch: 6.46 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036943242129530374		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.036943242129530374 | validation: 0.025161374229744005]
	TIME [epoch: 6.46 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03598323704796601		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.03598323704796601 | validation: 0.03186260192010356]
	TIME [epoch: 6.46 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03773969026354475		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.03773969026354475 | validation: 0.02954162814000671]
	TIME [epoch: 6.46 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03536283115830517		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.03536283115830517 | validation: 0.03663544346415677]
	TIME [epoch: 6.46 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0380734419119161		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.0380734419119161 | validation: 0.04018851182792731]
	TIME [epoch: 6.46 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038242125459277035		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.038242125459277035 | validation: 0.04356800122437262]
	TIME [epoch: 6.48 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042869761921500424		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.042869761921500424 | validation: 0.041365679994496085]
	TIME [epoch: 6.49 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037548664621025615		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.037548664621025615 | validation: 0.02043619619095832]
	TIME [epoch: 6.47 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03848680406072896		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.03848680406072896 | validation: 0.025481738986154398]
	TIME [epoch: 6.47 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036697666991699684		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.036697666991699684 | validation: 0.032143150650903916]
	TIME [epoch: 6.54 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037758980667416495		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.037758980667416495 | validation: 0.03679789742268625]
	TIME [epoch: 6.47 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03842019188013143		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.03842019188013143 | validation: 0.03847961291492464]
	TIME [epoch: 6.47 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04138639420611747		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.04138639420611747 | validation: 0.03787206703810207]
	TIME [epoch: 6.49 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0446735810249371		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.0446735810249371 | validation: 0.029428109462926982]
	TIME [epoch: 6.5 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036925425863580844		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.036925425863580844 | validation: 0.03356118396604805]
	TIME [epoch: 6.48 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03751567593932168		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.03751567593932168 | validation: 0.03276848187042341]
	TIME [epoch: 6.47 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0412010865433243		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.0412010865433243 | validation: 0.04456798436619919]
	TIME [epoch: 6.49 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04618355505733479		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.04618355505733479 | validation: 0.03198178582030435]
	TIME [epoch: 6.48 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03807110352874375		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.03807110352874375 | validation: 0.032908839940630874]
	TIME [epoch: 6.48 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03799459395296472		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.03799459395296472 | validation: 0.025947342833022958]
	TIME [epoch: 6.51 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03352268418124027		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.03352268418124027 | validation: 0.029151216881230502]
	TIME [epoch: 6.51 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03583695436072518		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.03583695436072518 | validation: 0.027689079313014352]
	TIME [epoch: 6.49 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0353768131753683		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.0353768131753683 | validation: 0.03360582547408341]
	TIME [epoch: 6.49 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037096249796717364		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.037096249796717364 | validation: 0.02505459720907429]
	TIME [epoch: 6.49 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04079878354553866		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.04079878354553866 | validation: 0.039191107506592486]
	TIME [epoch: 6.49 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04772605743700415		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.04772605743700415 | validation: 0.03346450817009344]
	TIME [epoch: 6.49 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03749753152375766		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.03749753152375766 | validation: 0.02886533640343374]
	TIME [epoch: 6.49 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037752047922657794		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.037752047922657794 | validation: 0.03375165905726068]
	TIME [epoch: 6.52 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0330370398063923		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.0330370398063923 | validation: 0.025993604773324543]
	TIME [epoch: 6.49 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0302650682120886		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.0302650682120886 | validation: 0.029686759750141126]
	TIME [epoch: 6.49 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03699704499254114		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.03699704499254114 | validation: 0.0362410253489029]
	TIME [epoch: 6.49 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03627132026458015		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.03627132026458015 | validation: 0.03134773457146817]
	TIME [epoch: 6.49 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03971447597404174		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.03971447597404174 | validation: 0.0245590856171535]
	TIME [epoch: 6.49 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035153825300679654		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.035153825300679654 | validation: 0.028304000748024815]
	TIME [epoch: 6.49 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03488621337370099		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.03488621337370099 | validation: 0.030373184216974637]
	TIME [epoch: 6.51 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03841820552657157		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.03841820552657157 | validation: 0.03057910430814828]
	TIME [epoch: 6.48 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03733123889720407		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.03733123889720407 | validation: 0.03552409240995073]
	TIME [epoch: 6.48 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035786848445231154		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.035786848445231154 | validation: 0.028491836796225137]
	TIME [epoch: 6.48 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03888772289650019		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.03888772289650019 | validation: 0.027121239978800765]
	TIME [epoch: 6.49 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034698070018420124		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.034698070018420124 | validation: 0.03014221690755445]
	TIME [epoch: 6.48 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03889388728648874		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.03889388728648874 | validation: 0.03542257374949153]
	TIME [epoch: 6.48 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03623683984946377		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.03623683984946377 | validation: 0.023979741151583467]
	TIME [epoch: 6.52 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03824219381941142		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.03824219381941142 | validation: 0.028729353289006953]
	TIME [epoch: 6.48 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03772094367932486		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.03772094367932486 | validation: 0.02670412266761046]
	TIME [epoch: 6.48 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0461536098513644		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.0461536098513644 | validation: 0.040086249912924525]
	TIME [epoch: 6.48 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040127861994120745		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.040127861994120745 | validation: 0.03348231470128259]
	TIME [epoch: 6.48 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03513995875402294		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.03513995875402294 | validation: 0.031397207746739396]
	TIME [epoch: 6.48 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037300725839866225		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.037300725839866225 | validation: 0.03519143690285547]
	TIME [epoch: 6.48 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03916294286670802		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.03916294286670802 | validation: 0.03727111252935613]
	TIME [epoch: 6.52 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03812072310889343		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.03812072310889343 | validation: 0.027260171478338244]
	TIME [epoch: 6.49 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03597009486810105		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.03597009486810105 | validation: 0.028617510436684684]
	TIME [epoch: 6.49 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03700189247411838		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.03700189247411838 | validation: 0.029035223618911657]
	TIME [epoch: 6.48 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03280410133769433		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.03280410133769433 | validation: 0.03238925694623235]
	TIME [epoch: 6.49 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036427631215884465		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.036427631215884465 | validation: 0.030985371692501106]
	TIME [epoch: 6.49 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0327223002720722		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.0327223002720722 | validation: 0.02512086942332455]
	TIME [epoch: 6.5 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02819009779964169		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.02819009779964169 | validation: 0.024606977791780622]
	TIME [epoch: 6.53 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0315307039187772		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.0315307039187772 | validation: 0.02195985376547168]
	TIME [epoch: 6.49 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033686594863129		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.033686594863129 | validation: 0.025593247382583825]
	TIME [epoch: 6.48 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03119859144401844		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.03119859144401844 | validation: 0.023212635107432825]
	TIME [epoch: 6.49 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03138582259735536		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.03138582259735536 | validation: 0.03254905420138329]
	TIME [epoch: 6.48 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032953051862785		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.032953051862785 | validation: 0.028218561257845973]
	TIME [epoch: 6.48 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03451679878773769		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.03451679878773769 | validation: 0.025332151181507924]
	TIME [epoch: 6.49 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03697364998360016		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.03697364998360016 | validation: 0.02682019310343026]
	TIME [epoch: 6.52 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04292225751704152		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.04292225751704152 | validation: 0.031442199086854916]
	TIME [epoch: 6.5 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03933694332890934		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.03933694332890934 | validation: 0.02300550888429587]
	TIME [epoch: 6.49 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0321447033665222		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.0321447033665222 | validation: 0.024519063392652966]
	TIME [epoch: 6.49 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030605600084979305		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.030605600084979305 | validation: 0.02580600320983485]
	TIME [epoch: 6.48 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03857770818342186		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.03857770818342186 | validation: 0.03330048864629946]
	TIME [epoch: 6.48 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03630857607340719		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.03630857607340719 | validation: 0.028873728115074916]
	TIME [epoch: 6.49 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03566222671334601		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.03566222671334601 | validation: 0.028201763257803946]
	TIME [epoch: 6.51 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030837759120375487		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.030837759120375487 | validation: 0.036158065269829856]
	TIME [epoch: 6.5 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037789524161671244		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.037789524161671244 | validation: 0.026711555228428007]
	TIME [epoch: 6.49 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03972009988128753		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.03972009988128753 | validation: 0.02781564043172854]
	TIME [epoch: 6.49 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03402110740496476		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.03402110740496476 | validation: 0.030640575068497475]
	TIME [epoch: 6.49 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03880496248447616		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.03880496248447616 | validation: 0.026853752274599657]
	TIME [epoch: 6.49 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03667326001934602		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.03667326001934602 | validation: 0.034375162405388286]
	TIME [epoch: 6.49 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037796555457701816		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.037796555457701816 | validation: 0.025319225277535575]
	TIME [epoch: 6.51 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03256204105567213		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.03256204105567213 | validation: 0.02541464912945038]
	TIME [epoch: 6.51 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03565895241693104		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.03565895241693104 | validation: 0.03226335590059955]
	TIME [epoch: 6.48 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040941833642029885		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.040941833642029885 | validation: 0.03273085036982169]
	TIME [epoch: 6.49 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03460452844012494		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.03460452844012494 | validation: 0.02987782477947495]
	TIME [epoch: 6.49 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0339774425088219		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.0339774425088219 | validation: 0.0324034826179392]
	TIME [epoch: 6.48 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03178512081442663		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.03178512081442663 | validation: 0.029344205556148455]
	TIME [epoch: 6.48 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03581006148631997		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.03581006148631997 | validation: 0.04082697348771801]
	TIME [epoch: 6.5 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03776242510648525		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.03776242510648525 | validation: 0.02765847720017067]
	TIME [epoch: 6.51 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03882305095914159		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.03882305095914159 | validation: 0.029492276320778936]
	TIME [epoch: 6.5 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03334885382573298		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.03334885382573298 | validation: 0.027847594688818835]
	TIME [epoch: 6.5 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03576412502547388		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.03576412502547388 | validation: 0.026832029591994506]
	TIME [epoch: 6.48 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03332713483832241		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.03332713483832241 | validation: 0.02609533653658546]
	TIME [epoch: 6.49 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036459147603489256		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.036459147603489256 | validation: 0.02269094710153194]
	TIME [epoch: 6.49 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0379916337299839		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.0379916337299839 | validation: 0.03261270702624591]
	TIME [epoch: 6.5 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031242456120939094		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.031242456120939094 | validation: 0.025936176747955578]
	TIME [epoch: 6.53 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03146828563164804		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.03146828563164804 | validation: 0.030738754953683615]
	TIME [epoch: 6.5 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03592996000294095		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.03592996000294095 | validation: 0.03481933530862598]
	TIME [epoch: 6.49 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03430691392327403		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.03430691392327403 | validation: 0.04443734972437698]
	TIME [epoch: 6.49 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03405560161226243		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.03405560161226243 | validation: 0.02203651415735352]
	TIME [epoch: 6.49 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03341120315523007		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.03341120315523007 | validation: 0.032404746343714236]
	TIME [epoch: 6.5 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036989719870673565		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.036989719870673565 | validation: 0.02074535709489741]
	TIME [epoch: 6.49 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035791839528385286		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.035791839528385286 | validation: 0.03324191301529104]
	TIME [epoch: 6.52 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040253337001486464		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.040253337001486464 | validation: 0.019912927900163083]
	TIME [epoch: 6.49 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0330568330240112		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.0330568330240112 | validation: 0.025496645341872685]
	TIME [epoch: 6.5 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03524550580611266		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.03524550580611266 | validation: 0.022358073101672895]
	TIME [epoch: 6.49 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031570803473270834		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.031570803473270834 | validation: 0.03132180610895586]
	TIME [epoch: 6.5 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033458891395738155		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.033458891395738155 | validation: 0.024386214269476212]
	TIME [epoch: 6.49 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03212891382214112		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.03212891382214112 | validation: 0.03771235905640481]
	TIME [epoch: 6.53 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0359158586462722		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.0359158586462722 | validation: 0.025497854506807832]
	TIME [epoch: 6.52 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03696664622869998		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.03696664622869998 | validation: 0.034019623661773406]
	TIME [epoch: 6.5 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03432876383968146		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.03432876383968146 | validation: 0.027210209387620074]
	TIME [epoch: 6.48 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03159353516280158		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.03159353516280158 | validation: 0.028040910137079333]
	TIME [epoch: 6.49 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033854996966669874		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.033854996966669874 | validation: 0.01863621599813837]
	TIME [epoch: 6.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_1467.pth
	Model improved!!!
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03551964038510366		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.03551964038510366 | validation: 0.02621964594117053]
	TIME [epoch: 6.6 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0350124843707757		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.0350124843707757 | validation: 0.022554214985547393]
	TIME [epoch: 6.5 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03674883178615127		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.03674883178615127 | validation: 0.027151430427146038]
	TIME [epoch: 6.53 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034235809543474466		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.034235809543474466 | validation: 0.01743635384742264]
	TIME [epoch: 6.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_1471.pth
	Model improved!!!
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031210060379765744		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.031210060379765744 | validation: 0.02709610436657937]
	TIME [epoch: 6.57 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03330212397262938		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.03330212397262938 | validation: 0.0259240119640749]
	TIME [epoch: 6.5 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03510027636600396		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.03510027636600396 | validation: 0.023057271352970192]
	TIME [epoch: 6.5 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03665671016987546		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.03665671016987546 | validation: 0.02325027005770127]
	TIME [epoch: 6.51 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030213583613267335		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.030213583613267335 | validation: 0.022619971639195706]
	TIME [epoch: 6.5 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03413287794629029		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.03413287794629029 | validation: 0.026241391590589844]
	TIME [epoch: 6.54 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03158348476764609		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.03158348476764609 | validation: 0.029230993001790467]
	TIME [epoch: 6.51 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03232314797122117		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.03232314797122117 | validation: 0.024402501252149628]
	TIME [epoch: 6.5 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0338780312749348		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.0338780312749348 | validation: 0.020041542235488933]
	TIME [epoch: 6.48 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03477360512563193		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.03477360512563193 | validation: 0.02474377402056963]
	TIME [epoch: 6.5 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03320397609942469		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.03320397609942469 | validation: 0.026470806547743395]
	TIME [epoch: 6.49 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029278895232541142		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.029278895232541142 | validation: 0.03193552550278358]
	TIME [epoch: 6.5 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03130239423301172		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.03130239423301172 | validation: 0.025704984286338047]
	TIME [epoch: 6.55 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03473922943884724		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.03473922943884724 | validation: 0.02754771821471807]
	TIME [epoch: 6.5 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033447723646818237		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.033447723646818237 | validation: 0.02984950779577769]
	TIME [epoch: 6.5 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03254296120482946		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.03254296120482946 | validation: 0.028700371727120647]
	TIME [epoch: 6.5 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03270563289019838		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.03270563289019838 | validation: 0.022661415695574522]
	TIME [epoch: 6.5 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034387394662034054		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.034387394662034054 | validation: 0.036648441419003704]
	TIME [epoch: 6.51 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03262977075749944		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.03262977075749944 | validation: 0.03783299544692879]
	TIME [epoch: 6.5 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03639728779643285		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.03639728779643285 | validation: 0.03739361204919991]
	TIME [epoch: 6.54 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03720991839569124		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.03720991839569124 | validation: 0.03415456809875433]
	TIME [epoch: 6.49 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0409637162724352		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.0409637162724352 | validation: 0.03511401125063428]
	TIME [epoch: 6.5 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03710842203029967		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.03710842203029967 | validation: 0.03351473128047281]
	TIME [epoch: 6.5 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040123914880300406		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.040123914880300406 | validation: 0.03212905837658168]
	TIME [epoch: 6.5 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040896612240082404		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.040896612240082404 | validation: 0.03624325154842116]
	TIME [epoch: 6.5 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036169845202024424		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.036169845202024424 | validation: 0.025404399649661704]
	TIME [epoch: 6.5 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036148086661619304		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.036148086661619304 | validation: 0.031617978368049054]
	TIME [epoch: 6.53 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03430441422918976		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.03430441422918976 | validation: 0.029439316929688236]
	TIME [epoch: 6.5 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03393640311314505		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.03393640311314505 | validation: 0.02501156675742296]
	TIME [epoch: 6.5 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03314875102128595		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.03314875102128595 | validation: 0.032604165754795494]
	TIME [epoch: 6.5 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03536155569187084		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.03536155569187084 | validation: 0.024753384498465838]
	TIME [epoch: 6.5 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0329686484832276		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.0329686484832276 | validation: 0.02749251359018007]
	TIME [epoch: 6.49 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02944772577760332		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.02944772577760332 | validation: 0.03336378499407371]
	TIME [epoch: 6.5 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02932264991871801		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.02932264991871801 | validation: 0.026460962772839002]
	TIME [epoch: 6.52 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035459843553439965		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.035459843553439965 | validation: 0.029758076127344567]
	TIME [epoch: 6.49 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034676901439270554		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.034676901439270554 | validation: 0.030262065092196293]
	TIME [epoch: 6.48 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03266439846853095		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.03266439846853095 | validation: 0.027918378693028666]
	TIME [epoch: 6.48 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031780542292005956		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.031780542292005956 | validation: 0.02788361852101687]
	TIME [epoch: 6.49 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034173518370532244		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.034173518370532244 | validation: 0.04112919320933843]
	TIME [epoch: 6.48 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030700291604215862		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.030700291604215862 | validation: 0.02526332158051508]
	TIME [epoch: 6.49 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032615472726203236		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.032615472726203236 | validation: 0.02339313001860779]
	TIME [epoch: 6.53 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0328130252462629		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.0328130252462629 | validation: 0.029229916748112802]
	TIME [epoch: 6.5 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030421011759948276		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.030421011759948276 | validation: 0.027040786981374097]
	TIME [epoch: 6.48 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031228478334928457		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.031228478334928457 | validation: 0.026303261908059313]
	TIME [epoch: 6.49 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037597880852461206		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.037597880852461206 | validation: 0.024977891179804538]
	TIME [epoch: 6.49 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035790266675408466		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.035790266675408466 | validation: 0.03267177536886091]
	TIME [epoch: 6.49 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035611947357033526		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.035611947357033526 | validation: 0.031101372694518212]
	TIME [epoch: 6.48 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032781693381579484		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.032781693381579484 | validation: 0.027055830949921828]
	TIME [epoch: 6.5 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03673082834245682		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.03673082834245682 | validation: 0.028485416517827322]
	TIME [epoch: 6.51 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03340837052341797		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.03340837052341797 | validation: 0.02621758707068242]
	TIME [epoch: 6.49 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030687717071030934		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.030687717071030934 | validation: 0.02996957792340563]
	TIME [epoch: 6.48 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03032680713937995		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.03032680713937995 | validation: 0.03857444586900826]
	TIME [epoch: 6.49 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037182542578588024		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.037182542578588024 | validation: 0.027901079139775114]
	TIME [epoch: 6.48 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03396394515658352		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.03396394515658352 | validation: 0.03159746300372759]
	TIME [epoch: 6.49 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03353760147920726		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.03353760147920726 | validation: 0.035224941800878797]
	TIME [epoch: 6.5 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034675067596740175		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.034675067596740175 | validation: 0.03446225306536348]
	TIME [epoch: 6.51 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036951099439719165		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.036951099439719165 | validation: 0.02697430851818697]
	TIME [epoch: 6.49 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03368109312430489		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.03368109312430489 | validation: 0.027944872860768688]
	TIME [epoch: 6.52 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03929735493126002		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.03929735493126002 | validation: 0.039801312720131835]
	TIME [epoch: 6.49 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0345743449159624		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.0345743449159624 | validation: 0.026186961887604672]
	TIME [epoch: 6.49 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030943525671946023		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.030943525671946023 | validation: 0.02156911789856294]
	TIME [epoch: 6.49 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03237037073771584		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.03237037073771584 | validation: 0.02783561070211408]
	TIME [epoch: 6.52 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033523032081526204		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.033523032081526204 | validation: 0.02807511828565902]
	TIME [epoch: 6.53 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03303538810990489		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.03303538810990489 | validation: 0.029210329469191075]
	TIME [epoch: 6.5 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03112382578715928		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.03112382578715928 | validation: 0.022360316836260132]
	TIME [epoch: 6.48 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030932275070908268		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.030932275070908268 | validation: 0.03224278210467106]
	TIME [epoch: 6.49 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03162026418196287		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.03162026418196287 | validation: 0.02901508567381739]
	TIME [epoch: 6.5 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034527510360744286		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.034527510360744286 | validation: 0.02710340461567939]
	TIME [epoch: 6.49 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033521935484497375		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.033521935484497375 | validation: 0.023666617764581743]
	TIME [epoch: 6.49 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030155794703541985		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.030155794703541985 | validation: 0.02747748948130922]
	TIME [epoch: 6.51 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03153350699108021		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.03153350699108021 | validation: 0.028571519568281394]
	TIME [epoch: 6.49 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03282925023740513		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.03282925023740513 | validation: 0.03607855976297671]
	TIME [epoch: 6.49 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035282755944003034		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.035282755944003034 | validation: 0.025923005156769496]
	TIME [epoch: 6.5 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03211308780115712		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.03211308780115712 | validation: 0.025721150548966773]
	TIME [epoch: 6.48 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027919546632586594		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.027919546632586594 | validation: 0.023567257742051487]
	TIME [epoch: 6.49 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03426160909319885		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.03426160909319885 | validation: 0.028803829481446865]
	TIME [epoch: 6.5 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032337903941534296		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.032337903941534296 | validation: 0.038614471257550215]
	TIME [epoch: 6.54 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03083182789615489		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.03083182789615489 | validation: 0.030422103242031685]
	TIME [epoch: 6.5 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03327424046848958		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.03327424046848958 | validation: 0.025685166290862448]
	TIME [epoch: 6.5 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03290930588648914		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.03290930588648914 | validation: 0.021813720788314322]
	TIME [epoch: 6.49 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029881940811044963		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.029881940811044963 | validation: 0.021759980411018485]
	TIME [epoch: 6.49 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03785337581380778		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.03785337581380778 | validation: 0.03308708068350077]
	TIME [epoch: 6.5 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03445920358468202		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.03445920358468202 | validation: 0.02218740598566511]
	TIME [epoch: 6.5 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031014481422463113		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.031014481422463113 | validation: 0.026268156070224542]
	TIME [epoch: 6.53 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033282831885761074		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.033282831885761074 | validation: 0.02013465970753006]
	TIME [epoch: 6.49 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028073294660591205		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.028073294660591205 | validation: 0.027115180492615992]
	TIME [epoch: 6.5 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03265105649807125		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.03265105649807125 | validation: 0.03099749387732107]
	TIME [epoch: 6.5 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029229207482474692		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.029229207482474692 | validation: 0.023317354294814567]
	TIME [epoch: 6.5 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03234904797257673		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.03234904797257673 | validation: 0.03209034756666882]
	TIME [epoch: 6.49 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038624646265066856		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.038624646265066856 | validation: 0.025443819981722147]
	TIME [epoch: 6.5 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03157587884737498		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.03157587884737498 | validation: 0.023703931859520903]
	TIME [epoch: 6.54 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031722171021518156		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.031722171021518156 | validation: 0.025546835582025144]
	TIME [epoch: 6.5 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03518936945309947		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.03518936945309947 | validation: 0.029776041477175767]
	TIME [epoch: 6.5 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031121201468905298		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.031121201468905298 | validation: 0.0307412928528208]
	TIME [epoch: 6.5 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029814028566236703		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.029814028566236703 | validation: 0.026247205305101745]
	TIME [epoch: 6.5 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03394985118730473		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.03394985118730473 | validation: 0.025271823127350927]
	TIME [epoch: 6.5 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035009196146019765		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.035009196146019765 | validation: 0.02739085448065727]
	TIME [epoch: 6.5 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03164532202141457		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.03164532202141457 | validation: 0.02570771966139009]
	TIME [epoch: 6.52 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03375138068539247		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.03375138068539247 | validation: 0.026343187949790337]
	TIME [epoch: 6.49 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032556072866672836		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.032556072866672836 | validation: 0.024822002482113237]
	TIME [epoch: 6.49 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03319251562662127		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.03319251562662127 | validation: 0.024723601450505978]
	TIME [epoch: 6.49 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030325977684802347		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.030325977684802347 | validation: 0.02376858706262429]
	TIME [epoch: 6.49 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031031638596953147		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.031031638596953147 | validation: 0.023259330483101866]
	TIME [epoch: 6.49 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03421573048473758		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.03421573048473758 | validation: 0.021108935590000853]
	TIME [epoch: 6.49 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031152746059216863		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.031152746059216863 | validation: 0.02549538151571011]
	TIME [epoch: 6.54 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03208589944350953		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.03208589944350953 | validation: 0.02482784277278121]
	TIME [epoch: 6.5 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033274589274858324		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.033274589274858324 | validation: 0.028970154224454703]
	TIME [epoch: 6.5 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03265198926946294		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.03265198926946294 | validation: 0.02546997466761266]
	TIME [epoch: 6.51 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03054283990025516		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.03054283990025516 | validation: 0.0209440474669606]
	TIME [epoch: 6.49 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03441892308141259		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.03441892308141259 | validation: 0.019826549506423707]
	TIME [epoch: 6.48 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03158136975013108		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.03158136975013108 | validation: 0.029604321190577657]
	TIME [epoch: 6.49 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03393755336506056		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.03393755336506056 | validation: 0.021418435536297346]
	TIME [epoch: 6.53 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037209230365962256		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.037209230365962256 | validation: 0.03260335758812148]
	TIME [epoch: 6.49 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03340104318748387		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.03340104318748387 | validation: 0.025090599668413028]
	TIME [epoch: 6.49 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03420184851191818		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.03420184851191818 | validation: 0.01927688594031122]
	TIME [epoch: 6.48 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03400268729921958		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.03400268729921958 | validation: 0.02575268338020283]
	TIME [epoch: 6.49 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03544068955049147		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.03544068955049147 | validation: 0.02408157618287188]
	TIME [epoch: 6.49 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03550613608552229		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.03550613608552229 | validation: 0.025086585786158837]
	TIME [epoch: 6.49 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03574490012923783		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.03574490012923783 | validation: 0.022551261653020488]
	TIME [epoch: 6.52 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03601214119634458		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.03601214119634458 | validation: 0.028821328469007864]
	TIME [epoch: 6.5 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031973075479260316		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.031973075479260316 | validation: 0.028495220528313655]
	TIME [epoch: 6.49 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03139835107107333		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.03139835107107333 | validation: 0.02556337687803384]
	TIME [epoch: 6.49 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03339962746584494		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.03339962746584494 | validation: 0.026424679956675173]
	TIME [epoch: 6.49 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03198195974934742		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.03198195974934742 | validation: 0.023348524216220693]
	TIME [epoch: 6.48 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03366642475452375		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.03366642475452375 | validation: 0.02576299464057509]
	TIME [epoch: 6.48 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03045618973155509		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.03045618973155509 | validation: 0.020248604517361716]
	TIME [epoch: 6.52 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03267460267782507		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.03267460267782507 | validation: 0.022552577125655976]
	TIME [epoch: 6.51 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03187826449819198		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.03187826449819198 | validation: 0.028723628077764816]
	TIME [epoch: 6.47 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03329034032515256		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.03329034032515256 | validation: 0.025834246237720987]
	TIME [epoch: 6.48 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03220538672354435		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.03220538672354435 | validation: 0.029166781641583154]
	TIME [epoch: 6.5 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030156166174474495		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.030156166174474495 | validation: 0.023155695574645457]
	TIME [epoch: 6.48 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030044739254029625		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.030044739254029625 | validation: 0.01864514291244723]
	TIME [epoch: 6.48 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028483414308855717		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.028483414308855717 | validation: 0.029409838222019893]
	TIME [epoch: 6.51 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03464408017531048		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.03464408017531048 | validation: 0.028978594582545744]
	TIME [epoch: 6.52 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031028786774036414		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.031028786774036414 | validation: 0.03374932097458318]
	TIME [epoch: 6.5 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032766061064128965		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.032766061064128965 | validation: 0.023768238654703247]
	TIME [epoch: 6.49 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03071125158990805		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.03071125158990805 | validation: 0.021624003793121318]
	TIME [epoch: 6.5 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030769377020623035		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.030769377020623035 | validation: 0.027635239257975383]
	TIME [epoch: 6.49 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02924720645904868		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.02924720645904868 | validation: 0.028345956504661787]
	TIME [epoch: 6.5 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034301532450073044		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.034301532450073044 | validation: 0.025025767990460364]
	TIME [epoch: 6.49 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03063401052208751		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.03063401052208751 | validation: 0.024618758195560694]
	TIME [epoch: 6.52 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033459708446451124		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.033459708446451124 | validation: 0.02351993981462972]
	TIME [epoch: 6.48 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034416741169470515		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.034416741169470515 | validation: 0.03050878578365932]
	TIME [epoch: 6.48 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03402392046746906		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.03402392046746906 | validation: 0.028755055024849034]
	TIME [epoch: 6.48 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035249761001630533		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.035249761001630533 | validation: 0.020617892338659113]
	TIME [epoch: 6.48 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032316392171378654		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.032316392171378654 | validation: 0.028370476434288062]
	TIME [epoch: 6.48 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03592502393660711		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.03592502393660711 | validation: 0.02592129397875626]
	TIME [epoch: 6.5 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03520734663225932		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.03520734663225932 | validation: 0.03564725584907204]
	TIME [epoch: 6.52 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032349908648697016		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.032349908648697016 | validation: 0.017963015123119087]
	TIME [epoch: 6.5 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035061995092789656		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.035061995092789656 | validation: 0.03024593670357387]
	TIME [epoch: 6.5 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03639661995634574		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.03639661995634574 | validation: 0.030855341968260612]
	TIME [epoch: 6.49 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03267546320441675		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.03267546320441675 | validation: 0.031522855768887414]
	TIME [epoch: 6.49 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03553196108141228		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.03553196108141228 | validation: 0.01954846696060127]
	TIME [epoch: 6.48 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034000210091572274		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.034000210091572274 | validation: 0.02726602756537078]
	TIME [epoch: 6.5 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03407629438490053		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.03407629438490053 | validation: 0.028748117291914788]
	TIME [epoch: 6.53 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03418768797669783		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.03418768797669783 | validation: 0.03056385629279287]
	TIME [epoch: 6.49 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031804276148164425		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.031804276148164425 | validation: 0.025197471042860586]
	TIME [epoch: 6.49 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035836550267440856		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.035836550267440856 | validation: 0.018710943782868833]
	TIME [epoch: 6.48 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035175699846903836		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.035175699846903836 | validation: 0.019878735415055995]
	TIME [epoch: 6.48 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033018630914139445		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.033018630914139445 | validation: 0.017883590448802337]
	TIME [epoch: 6.48 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031866220793742		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.031866220793742 | validation: 0.02438945258847266]
	TIME [epoch: 6.49 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03396185298919255		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.03396185298919255 | validation: 0.02731451512761336]
	TIME [epoch: 6.52 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031045736286844424		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.031045736286844424 | validation: 0.022629516964733542]
	TIME [epoch: 6.49 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03153351275904824		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.03153351275904824 | validation: 0.021375334330569304]
	TIME [epoch: 6.49 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033524145826609786		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.033524145826609786 | validation: 0.036549542078376435]
	TIME [epoch: 6.5 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03253436027807725		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.03253436027807725 | validation: 0.038739779242461005]
	TIME [epoch: 6.49 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03367475825953543		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.03367475825953543 | validation: 0.024575705519501764]
	TIME [epoch: 6.5 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03114993064553546		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.03114993064553546 | validation: 0.02669477983415304]
	TIME [epoch: 6.49 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03182665118077454		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.03182665118077454 | validation: 0.020582426267704967]
	TIME [epoch: 6.53 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03475688026453285		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.03475688026453285 | validation: 0.02330513265131317]
	TIME [epoch: 6.49 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0311677960309827		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.0311677960309827 | validation: 0.024021000575979425]
	TIME [epoch: 6.49 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03335507182127674		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.03335507182127674 | validation: 0.02643357110044738]
	TIME [epoch: 6.5 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03613239316978088		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.03613239316978088 | validation: 0.025648605661404988]
	TIME [epoch: 6.5 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03259864582557749		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.03259864582557749 | validation: 0.01910806581287372]
	TIME [epoch: 6.49 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032567453652192484		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.032567453652192484 | validation: 0.02783158372588523]
	TIME [epoch: 6.47 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03286759886475593		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.03286759886475593 | validation: 0.030783488372940815]
	TIME [epoch: 6.52 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03136784162425277		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.03136784162425277 | validation: 0.027276611942986053]
	TIME [epoch: 6.46 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03528296525149739		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.03528296525149739 | validation: 0.020904988216306358]
	TIME [epoch: 6.47 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036237106752752		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.036237106752752 | validation: 0.0327613463699676]
	TIME [epoch: 6.45 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03135743924084436		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.03135743924084436 | validation: 0.032151576576355374]
	TIME [epoch: 6.45 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033750777535751016		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.033750777535751016 | validation: 0.027222819543807293]
	TIME [epoch: 6.46 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030339029304348255		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.030339029304348255 | validation: 0.021998843913659565]
	TIME [epoch: 6.46 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029371967454481198		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.029371967454481198 | validation: 0.012636784903815947]
	TIME [epoch: 6.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_1654.pth
	Model improved!!!
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030001909694915417		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.030001909694915417 | validation: 0.024525772977594455]
	TIME [epoch: 6.57 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031962179771168484		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.031962179771168484 | validation: 0.021777142736780927]
	TIME [epoch: 6.45 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02788294406571719		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.02788294406571719 | validation: 0.02720811152388517]
	TIME [epoch: 6.45 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03251762060254796		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.03251762060254796 | validation: 0.03074823466901107]
	TIME [epoch: 6.46 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0345260982375271		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.0345260982375271 | validation: 0.023875576426869518]
	TIME [epoch: 6.47 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030696714059082912		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.030696714059082912 | validation: 0.019489103441166274]
	TIME [epoch: 6.46 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02973434105972434		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.02973434105972434 | validation: 0.02235275709790944]
	TIME [epoch: 6.51 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0304019185854092		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.0304019185854092 | validation: 0.029783242134073937]
	TIME [epoch: 6.46 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03150939346533708		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.03150939346533708 | validation: 0.023839702733414125]
	TIME [epoch: 6.47 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030593668357208885		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.030593668357208885 | validation: 0.022393421774080043]
	TIME [epoch: 6.47 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034174209187410404		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.034174209187410404 | validation: 0.028530013957232016]
	TIME [epoch: 6.47 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03234958742597961		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.03234958742597961 | validation: 0.028857325924166958]
	TIME [epoch: 6.48 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031236922924904237		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.031236922924904237 | validation: 0.02846457532243898]
	TIME [epoch: 6.48 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03119866603819412		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.03119866603819412 | validation: 0.028323876045891833]
	TIME [epoch: 6.5 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031301731612336944		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.031301731612336944 | validation: 0.02266775072834391]
	TIME [epoch: 6.5 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029620766074458585		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.029620766074458585 | validation: 0.02141192475060917]
	TIME [epoch: 6.48 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03363635461409924		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.03363635461409924 | validation: 0.026580298151724104]
	TIME [epoch: 6.47 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031138162559957938		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.031138162559957938 | validation: 0.025664580606150365]
	TIME [epoch: 6.49 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03528612039400439		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.03528612039400439 | validation: 0.026825674020446905]
	TIME [epoch: 6.48 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03304327696754904		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.03304327696754904 | validation: 0.025416641592392035]
	TIME [epoch: 6.49 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031028702439618958		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.031028702439618958 | validation: 0.018751258456777498]
	TIME [epoch: 6.52 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030957505470818575		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.030957505470818575 | validation: 0.030271481299742584]
	TIME [epoch: 6.52 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034530938692319456		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.034530938692319456 | validation: 0.026309559871746463]
	TIME [epoch: 6.5 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031457206392490965		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.031457206392490965 | validation: 0.025176708827325114]
	TIME [epoch: 6.5 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03226477068137106		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.03226477068137106 | validation: 0.028840092190816524]
	TIME [epoch: 6.49 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03383674209908542		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.03383674209908542 | validation: 0.03413273019929618]
	TIME [epoch: 6.5 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03169223557260233		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.03169223557260233 | validation: 0.02426033472779847]
	TIME [epoch: 6.49 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03313778118271449		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.03313778118271449 | validation: 0.01940739155703651]
	TIME [epoch: 6.52 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03125017909089425		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.03125017909089425 | validation: 0.03242255383751309]
	TIME [epoch: 6.52 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03433053132336503		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.03433053132336503 | validation: 0.03134818157864073]
	TIME [epoch: 6.49 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03376309460191848		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.03376309460191848 | validation: 0.021197741795210955]
	TIME [epoch: 6.5 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02993664125131018		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.02993664125131018 | validation: 0.022480789424661616]
	TIME [epoch: 6.49 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030306905421985657		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.030306905421985657 | validation: 0.024593930965527547]
	TIME [epoch: 6.49 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03411032711465756		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.03411032711465756 | validation: 0.023899955567077292]
	TIME [epoch: 6.48 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029847179424340738		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.029847179424340738 | validation: 0.0245084645460679]
	TIME [epoch: 6.49 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03394896028037055		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.03394896028037055 | validation: 0.02262814318817049]
	TIME [epoch: 6.52 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031835608097779626		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.031835608097779626 | validation: 0.027745314475295064]
	TIME [epoch: 6.5 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027247521361095612		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.027247521361095612 | validation: 0.014496512274708856]
	TIME [epoch: 6.5 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03222659139490078		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.03222659139490078 | validation: 0.023400654559379612]
	TIME [epoch: 6.48 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03057640443343115		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.03057640443343115 | validation: 0.02793751308118219]
	TIME [epoch: 6.48 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036441886800899		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.036441886800899 | validation: 0.0312735970136531]
	TIME [epoch: 6.46 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03260919390821134		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.03260919390821134 | validation: 0.034750350588136934]
	TIME [epoch: 6.46 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03374631184227246		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.03374631184227246 | validation: 0.02719741113994329]
	TIME [epoch: 6.48 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03223793031560314		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.03223793031560314 | validation: 0.02361900847390203]
	TIME [epoch: 6.46 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03158516063673046		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.03158516063673046 | validation: 0.033804517935003685]
	TIME [epoch: 6.46 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030606215146840567		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.030606215146840567 | validation: 0.022024409564063988]
	TIME [epoch: 6.46 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030707499004975304		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.030707499004975304 | validation: 0.028706964738675584]
	TIME [epoch: 6.46 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03230060288430678		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.03230060288430678 | validation: 0.02252972713569004]
	TIME [epoch: 6.46 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030210572203522985		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.030210572203522985 | validation: 0.022041200990384504]
	TIME [epoch: 6.46 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030630610859933585		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.030630610859933585 | validation: 0.009554177361915758]
	TIME [epoch: 6.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240309_135700/states/model_tr_study1_1704.pth
	Model improved!!!
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035189708394492245		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.035189708394492245 | validation: 0.024304830737851515]
	TIME [epoch: 6.53 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03150368595815596		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.03150368595815596 | validation: 0.02581326899750831]
	TIME [epoch: 6.46 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031409113231225846		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.031409113231225846 | validation: 0.022571271446648986]
	TIME [epoch: 6.48 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030150837009898887		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.030150837009898887 | validation: 0.02142067164757837]
	TIME [epoch: 6.47 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03325887257356993		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.03325887257356993 | validation: 0.02988440108876337]
	TIME [epoch: 6.46 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03157914493330768		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.03157914493330768 | validation: 0.019062065095363387]
	TIME [epoch: 6.46 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0337341427698751		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.0337341427698751 | validation: 0.0257804750460972]
	TIME [epoch: 6.5 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03721194866060486		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.03721194866060486 | validation: 0.025763860866193183]
	TIME [epoch: 6.47 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030303077449392223		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.030303077449392223 | validation: 0.017439711743914853]
	TIME [epoch: 6.48 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03084368731783398		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.03084368731783398 | validation: 0.02382127570042277]
	TIME [epoch: 6.49 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03180398299472795		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.03180398299472795 | validation: 0.026516036938618495]
	TIME [epoch: 6.48 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03136281994529778		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.03136281994529778 | validation: 0.021665932621143077]
	TIME [epoch: 6.47 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03424928049915202		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.03424928049915202 | validation: 0.024043012510691294]
	TIME [epoch: 6.48 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028147127999489818		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.028147127999489818 | validation: 0.01926984356764492]
	TIME [epoch: 6.51 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03289206237636027		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.03289206237636027 | validation: 0.02885388219206721]
	TIME [epoch: 6.49 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029601057943590844		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.029601057943590844 | validation: 0.029990231448349843]
	TIME [epoch: 6.47 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031643389333358904		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.031643389333358904 | validation: 0.028869345498027048]
	TIME [epoch: 6.49 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030607316785764848		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.030607316785764848 | validation: 0.023399268262225048]
	TIME [epoch: 6.48 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032908294644887634		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.032908294644887634 | validation: 0.02823763412451454]
	TIME [epoch: 6.49 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028635930151082914		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.028635930151082914 | validation: 0.035096703974171244]
	TIME [epoch: 6.47 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031089629343609364		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.031089629343609364 | validation: 0.030110645563866615]
	TIME [epoch: 6.51 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035711327211419265		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.035711327211419265 | validation: 0.028194902101941373]
	TIME [epoch: 6.5 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0344798862552162		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.0344798862552162 | validation: 0.023954998236272812]
	TIME [epoch: 6.48 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03621444081766406		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.03621444081766406 | validation: 0.028172161970073356]
	TIME [epoch: 6.48 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03066072258621063		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.03066072258621063 | validation: 0.02489538825701958]
	TIME [epoch: 6.48 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03456794932457321		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.03456794932457321 | validation: 0.025919674468921416]
	TIME [epoch: 6.48 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0335757834821903		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.0335757834821903 | validation: 0.02481428309047524]
	TIME [epoch: 6.49 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028665826071584317		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.028665826071584317 | validation: 0.027450182687086204]
	TIME [epoch: 6.52 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029836856776935594		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.029836856776935594 | validation: 0.02186640099149368]
	TIME [epoch: 6.49 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03415126313903165		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.03415126313903165 | validation: 0.026994101490762114]
	TIME [epoch: 6.48 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02829215340399544		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.02829215340399544 | validation: 0.02496434169004359]
	TIME [epoch: 6.48 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02985044865643973		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.02985044865643973 | validation: 0.019721345020603364]
	TIME [epoch: 6.49 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03269132536797631		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.03269132536797631 | validation: 0.021450104012988688]
	TIME [epoch: 6.49 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0331748120151727		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.0331748120151727 | validation: 0.026266588146243476]
	TIME [epoch: 6.49 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0344196043709603		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.0344196043709603 | validation: 0.030106877821973244]
	TIME [epoch: 6.5 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030434799971323076		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.030434799971323076 | validation: 0.028710675354683825]
	TIME [epoch: 6.5 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03536226282399525		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.03536226282399525 | validation: 0.02470132055901757]
	TIME [epoch: 6.49 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03293141257321842		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.03293141257321842 | validation: 0.024998533255875643]
	TIME [epoch: 6.49 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03464871817003561		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.03464871817003561 | validation: 0.02287385025646765]
	TIME [epoch: 6.49 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030730874403296936		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.030730874403296936 | validation: 0.01428110307343629]
	TIME [epoch: 6.5 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03688491169638748		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.03688491169638748 | validation: 0.02665396314856293]
	TIME [epoch: 6.49 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03259952235749365		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.03259952235749365 | validation: 0.024714336951663318]
	TIME [epoch: 6.5 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031224010980546224		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.031224010980546224 | validation: 0.017373858615024895]
	TIME [epoch: 6.5 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03511138639160981		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.03511138639160981 | validation: 0.024594966762479756]
	TIME [epoch: 6.49 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0320693576562355		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.0320693576562355 | validation: 0.026052638051589777]
	TIME [epoch: 6.5 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028778654465072256		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.028778654465072256 | validation: 0.026799833094687486]
	TIME [epoch: 6.49 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030237064680942352		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.030237064680942352 | validation: 0.01812626849575735]
	TIME [epoch: 6.49 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032161814516431256		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.032161814516431256 | validation: 0.027676802908590457]
	TIME [epoch: 6.49 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03169857676174619		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.03169857676174619 | validation: 0.012900130656021252]
	TIME [epoch: 6.52 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03402045955689863		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.03402045955689863 | validation: 0.03108163407039141]
	TIME [epoch: 6.51 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029695153241062845		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.029695153241062845 | validation: 0.027052994290502515]
	TIME [epoch: 6.49 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030146065022062775		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.030146065022062775 | validation: 0.02609852419055816]
	TIME [epoch: 6.49 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03079391002924501		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.03079391002924501 | validation: 0.02172378846856686]
	TIME [epoch: 6.48 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030323105366303435		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.030323105366303435 | validation: 0.02602775001371339]
	TIME [epoch: 6.49 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03105240663718851		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.03105240663718851 | validation: 0.018615652439963923]
	TIME [epoch: 6.5 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031532781406190084		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.031532781406190084 | validation: 0.023822629902802168]
	TIME [epoch: 6.49 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0298276790767059		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.0298276790767059 | validation: 0.02016905802027134]
	TIME [epoch: 6.52 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03374738242868884		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.03374738242868884 | validation: 0.02605412036157262]
	TIME [epoch: 6.49 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030977377705890315		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.030977377705890315 | validation: 0.023264888453345414]
	TIME [epoch: 6.49 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033386347509587654		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.033386347509587654 | validation: 0.026762526575695347]
	TIME [epoch: 6.49 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03107607682494623		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.03107607682494623 | validation: 0.03029745876870273]
	TIME [epoch: 6.5 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03362914298032614		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.03362914298032614 | validation: 0.028759388828329176]
	TIME [epoch: 6.49 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032335664372503806		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.032335664372503806 | validation: 0.030467950676324157]
	TIME [epoch: 6.49 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030911121167690854		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.030911121167690854 | validation: 0.02286742207201941]
	TIME [epoch: 6.51 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03074811223512121		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.03074811223512121 | validation: 0.019177342912211005]
	TIME [epoch: 6.48 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03280686609096716		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.03280686609096716 | validation: 0.016143614558358582]
	TIME [epoch: 6.47 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03496612436872788		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.03496612436872788 | validation: 0.026089127120428213]
	TIME [epoch: 6.48 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03359771046282635		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.03359771046282635 | validation: 0.022868987229790055]
	TIME [epoch: 6.49 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031831202910022685		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.031831202910022685 | validation: 0.023835541442224092]
	TIME [epoch: 6.48 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03109650052114341		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.03109650052114341 | validation: 0.025456346046247882]
	TIME [epoch: 6.49 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03230848209416985		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.03230848209416985 | validation: 0.025898460111701854]
	TIME [epoch: 6.53 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02865284068247337		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.02865284068247337 | validation: 0.0314393889378453]
	TIME [epoch: 6.5 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035079571190444706		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.035079571190444706 | validation: 0.026817815248852767]
	TIME [epoch: 6.49 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03272210777680419		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.03272210777680419 | validation: 0.020626345433038266]
	TIME [epoch: 6.5 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029767352706901347		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.029767352706901347 | validation: 0.023787781886563844]
	TIME [epoch: 6.48 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03091853808419663		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.03091853808419663 | validation: 0.025199154162871013]
	TIME [epoch: 6.5 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030485070729562566		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.030485070729562566 | validation: 0.025589938093566432]
	TIME [epoch: 6.5 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03391741236214677		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.03391741236214677 | validation: 0.025915053230470803]
	TIME [epoch: 6.53 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02926947925274909		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.02926947925274909 | validation: 0.024346662941143987]
	TIME [epoch: 6.48 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03296159964454175		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.03296159964454175 | validation: 0.023501732908925377]
	TIME [epoch: 6.48 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03055039032418563		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.03055039032418563 | validation: 0.02280270962684172]
	TIME [epoch: 6.48 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03293486321742628		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.03293486321742628 | validation: 0.030952401182580847]
	TIME [epoch: 6.49 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03217686465383597		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.03217686465383597 | validation: 0.025237495918464987]
	TIME [epoch: 6.49 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030828693142756033		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.030828693142756033 | validation: 0.021437732852513575]
	TIME [epoch: 6.5 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030775229958075547		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.030775229958075547 | validation: 0.02259810628438565]
	TIME [epoch: 6.53 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031728961131669856		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.031728961131669856 | validation: 0.02322017910652944]
	TIME [epoch: 6.49 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03379019554383162		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.03379019554383162 | validation: 0.02646072748982707]
	TIME [epoch: 6.48 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03248064845269502		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.03248064845269502 | validation: 0.024441019495230584]
	TIME [epoch: 6.49 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030363901020038067		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.030363901020038067 | validation: 0.026048693198707895]
	TIME [epoch: 6.5 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03164990863698295		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.03164990863698295 | validation: 0.02666784842059877]
	TIME [epoch: 6.5 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033290024191207405		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.033290024191207405 | validation: 0.02553645544766046]
	TIME [epoch: 6.5 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030931269295764584		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.030931269295764584 | validation: 0.020022239683147633]
	TIME [epoch: 6.53 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03406125654831924		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.03406125654831924 | validation: 0.02737682015058173]
	TIME [epoch: 6.49 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026063806967786436		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.026063806967786436 | validation: 0.02232949883798879]
	TIME [epoch: 6.49 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03315342391485572		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.03315342391485572 | validation: 0.029774646649478004]
	TIME [epoch: 6.49 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03259199032610499		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.03259199032610499 | validation: 0.030506005267371447]
	TIME [epoch: 6.48 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030555264745384142		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.030555264745384142 | validation: 0.026681887238310064]
	TIME [epoch: 6.49 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032243077126104074		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.032243077126104074 | validation: 0.025445352191427004]
	TIME [epoch: 6.5 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030889048174147317		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.030889048174147317 | validation: 0.02483135415581318]
	TIME [epoch: 6.52 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033224847863112326		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.033224847863112326 | validation: 0.020299117324149362]
	TIME [epoch: 6.5 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029302295482281443		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.029302295482281443 | validation: 0.02067608837006015]
	TIME [epoch: 6.48 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032031420770879414		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.032031420770879414 | validation: 0.036953309525224465]
	TIME [epoch: 6.49 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02938228909083497		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.02938228909083497 | validation: 0.029817886787861604]
	TIME [epoch: 6.48 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03258083760471994		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.03258083760471994 | validation: 0.030064812936049897]
	TIME [epoch: 6.48 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031568915021888445		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.031568915021888445 | validation: 0.02570319254956004]
	TIME [epoch: 6.49 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03318467347246		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.03318467347246 | validation: 0.02402000460005529]
	TIME [epoch: 6.52 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03406569224349474		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.03406569224349474 | validation: 0.018998314907253323]
	TIME [epoch: 6.49 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03170140553334521		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.03170140553334521 | validation: 0.02753096626101889]
	TIME [epoch: 6.48 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030508293115028763		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.030508293115028763 | validation: 0.019298986042049795]
	TIME [epoch: 6.48 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0326107165202662		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.0326107165202662 | validation: 0.026758605913468472]
	TIME [epoch: 6.47 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031651492007234175		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.031651492007234175 | validation: 0.019165147066457163]
	TIME [epoch: 6.47 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03267401333559999		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.03267401333559999 | validation: 0.02740372725534763]
	TIME [epoch: 6.48 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03449256340987957		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.03449256340987957 | validation: 0.02935055895568085]
	TIME [epoch: 6.5 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02888699389112137		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.02888699389112137 | validation: 0.026723364610725265]
	TIME [epoch: 6.5 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03064018724883856		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.03064018724883856 | validation: 0.029659720942256516]
	TIME [epoch: 6.48 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03330969173226263		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.03330969173226263 | validation: 0.024530948320068066]
	TIME [epoch: 6.48 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03416233855204401		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.03416233855204401 | validation: 0.02554235839776916]
	TIME [epoch: 6.49 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03430937135635168		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.03430937135635168 | validation: 0.021569318187220583]
	TIME [epoch: 6.48 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030439817938696167		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.030439817938696167 | validation: 0.02199831800745493]
	TIME [epoch: 6.48 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030059254893182286		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.030059254893182286 | validation: 0.022240088409344362]
	TIME [epoch: 6.51 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03298196367228723		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.03298196367228723 | validation: 0.019739797824946795]
	TIME [epoch: 6.51 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032283582083914845		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.032283582083914845 | validation: 0.027635941231140562]
	TIME [epoch: 6.49 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033149236635701115		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.033149236635701115 | validation: 0.022891673075095535]
	TIME [epoch: 6.48 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030388095798577146		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.030388095798577146 | validation: 0.02865325500598856]
	TIME [epoch: 6.48 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03353142745404214		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.03353142745404214 | validation: 0.028202267606448714]
	TIME [epoch: 6.48 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029909625672619254		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.029909625672619254 | validation: 0.03140164186780178]
	TIME [epoch: 6.47 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02995029801481215		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.02995029801481215 | validation: 0.02197997024687773]
	TIME [epoch: 6.49 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03250115400818435		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.03250115400818435 | validation: 0.021059544885171703]
	TIME [epoch: 6.51 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03368125917080547		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.03368125917080547 | validation: 0.013592283595386579]
	TIME [epoch: 6.48 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032405967552137586		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.032405967552137586 | validation: 0.021627988431809193]
	TIME [epoch: 6.48 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033154760785437276		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.033154760785437276 | validation: 0.017364739253585882]
	TIME [epoch: 6.49 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03341583502550108		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.03341583502550108 | validation: 0.023698394869689523]
	TIME [epoch: 6.49 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03197207085667414		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.03197207085667414 | validation: 0.03545508433852101]
	TIME [epoch: 6.48 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032897006802940325		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.032897006802940325 | validation: 0.026022546016628026]
	TIME [epoch: 6.48 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03023566830748293		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.03023566830748293 | validation: 0.015413978813320014]
	TIME [epoch: 6.51 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030543176332501847		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.030543176332501847 | validation: 0.027594409658445947]
	TIME [epoch: 6.47 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03007468086616484		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.03007468086616484 | validation: 0.02395753435252776]
	TIME [epoch: 6.47 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03160012360172748		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.03160012360172748 | validation: 0.02359588584821437]
	TIME [epoch: 6.47 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0312219113146337		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.0312219113146337 | validation: 0.029919430926893587]
	TIME [epoch: 6.48 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03135844945379948		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.03135844945379948 | validation: 0.0281200855198228]
	TIME [epoch: 6.47 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03428151877280337		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.03428151877280337 | validation: 0.020928467450238682]
	TIME [epoch: 6.46 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028303083292217687		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.028303083292217687 | validation: 0.02210445724299495]
	TIME [epoch: 6.49 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02934285374406015		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.02934285374406015 | validation: 0.025018651560333238]
	TIME [epoch: 6.48 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03248649256581769		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.03248649256581769 | validation: 0.02062005460551303]
	TIME [epoch: 6.47 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031794438655023155		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.031794438655023155 | validation: 0.0257014744764638]
	TIME [epoch: 6.47 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03171385210998164		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.03171385210998164 | validation: 0.02242089628637544]
	TIME [epoch: 6.5 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02864019365984825		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.02864019365984825 | validation: 0.03139765457413321]
	TIME [epoch: 6.47 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03141924836057244		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.03141924836057244 | validation: 0.024692934275931697]
	TIME [epoch: 6.49 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03007454550521724		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.03007454550521724 | validation: 0.01860687110904193]
	TIME [epoch: 6.51 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03078455217122418		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.03078455217122418 | validation: 0.02438451622356049]
	TIME [epoch: 6.5 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033736946958501476		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.033736946958501476 | validation: 0.01831619962907912]
	TIME [epoch: 6.49 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032149746276442424		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.032149746276442424 | validation: 0.019058989673188222]
	TIME [epoch: 6.5 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03573669798802592		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.03573669798802592 | validation: 0.026446449802496216]
	TIME [epoch: 6.49 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036623725887495		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.036623725887495 | validation: 0.024740538392893856]
	TIME [epoch: 6.5 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03432321642110667		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.03432321642110667 | validation: 0.023587492901158573]
	TIME [epoch: 6.48 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03444948877474757		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.03444948877474757 | validation: 0.022154670773291158]
	TIME [epoch: 6.54 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03368018297433685		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.03368018297433685 | validation: 0.026817509871524155]
	TIME [epoch: 6.48 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03616583354716835		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.03616583354716835 | validation: 0.026054966774058066]
	TIME [epoch: 6.49 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031444143685462424		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.031444143685462424 | validation: 0.026784699995327132]
	TIME [epoch: 6.48 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034526426875128316		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.034526426875128316 | validation: 0.020311961423100513]
	TIME [epoch: 6.49 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030622400283948158		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.030622400283948158 | validation: 0.02532214897052108]
	TIME [epoch: 6.5 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03466663644072065		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.03466663644072065 | validation: 0.030285905789515837]
	TIME [epoch: 6.5 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029343831479034715		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.029343831479034715 | validation: 0.020841969048997946]
	TIME [epoch: 6.52 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034303649128690446		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.034303649128690446 | validation: 0.027346263911182948]
	TIME [epoch: 6.49 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03351466165922684		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.03351466165922684 | validation: 0.029227200555333087]
	TIME [epoch: 6.48 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031242792042127973		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.031242792042127973 | validation: 0.02187875311179732]
	TIME [epoch: 6.5 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03166387836617174		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.03166387836617174 | validation: 0.03069240866184208]
	TIME [epoch: 6.47 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031185564344468945		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.031185564344468945 | validation: 0.028339577796982447]
	TIME [epoch: 6.48 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03656530207655792		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.03656530207655792 | validation: 0.027305903439114054]
	TIME [epoch: 6.48 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031629887560143455		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.031629887560143455 | validation: 0.024164031874494313]
	TIME [epoch: 6.53 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03479594172308137		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.03479594172308137 | validation: 0.01582766983063026]
	TIME [epoch: 6.5 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031064079674880948		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.031064079674880948 | validation: 0.027831103220619175]
	TIME [epoch: 6.51 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03285378168451285		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.03285378168451285 | validation: 0.028554452395387137]
	TIME [epoch: 6.49 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033361901324648655		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.033361901324648655 | validation: 0.029729052279216905]
	TIME [epoch: 6.5 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03298825878535771		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.03298825878535771 | validation: 0.026671733925807878]
	TIME [epoch: 6.5 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035518041370597574		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.035518041370597574 | validation: 0.03205379427539407]
	TIME [epoch: 6.49 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03415334073149588		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.03415334073149588 | validation: 0.0177791083456128]
	TIME [epoch: 6.52 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031624519106417254		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.031624519106417254 | validation: 0.02736766400567701]
	TIME [epoch: 6.51 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03176601991087338		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.03176601991087338 | validation: 0.027112796098335012]
	TIME [epoch: 6.49 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033405101856555264		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.033405101856555264 | validation: 0.02456250183929033]
	TIME [epoch: 6.49 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03204173432519203		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.03204173432519203 | validation: 0.024766147737703345]
	TIME [epoch: 6.49 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03485281978776249		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.03485281978776249 | validation: 0.027132385546412792]
	TIME [epoch: 6.5 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03151724532660246		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.03151724532660246 | validation: 0.032967501633955225]
	TIME [epoch: 6.5 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03237982627048997		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.03237982627048997 | validation: 0.028230271769006547]
	TIME [epoch: 6.51 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033901357322577735		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.033901357322577735 | validation: 0.026028004921385583]
	TIME [epoch: 6.52 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03176830838436685		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.03176830838436685 | validation: 0.017296868989699773]
	TIME [epoch: 6.5 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03136053227863625		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.03136053227863625 | validation: 0.02570690148482472]
	TIME [epoch: 6.5 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02971962797878899		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.02971962797878899 | validation: 0.01688347432779925]
	TIME [epoch: 6.5 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03138405715954413		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.03138405715954413 | validation: 0.030931485512007948]
	TIME [epoch: 6.5 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03257940295086244		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.03257940295086244 | validation: 0.022873727614207962]
	TIME [epoch: 6.48 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031937850090687864		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.031937850090687864 | validation: 0.02080372910774047]
	TIME [epoch: 6.52 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03053409407070551		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.03053409407070551 | validation: 0.023141112331611226]
	TIME [epoch: 6.51 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027852238246091045		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.027852238246091045 | validation: 0.02402883362211177]
	TIME [epoch: 6.49 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03150711583562309		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.03150711583562309 | validation: 0.016948956536843328]
	TIME [epoch: 6.49 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029124075653935634		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.029124075653935634 | validation: 0.028429317878352723]
	TIME [epoch: 6.5 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028464008353258838		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.028464008353258838 | validation: 0.02075858692808855]
	TIME [epoch: 6.5 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029381465919011855		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.029381465919011855 | validation: 0.0240504899397207]
	TIME [epoch: 6.49 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03373683590364463		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.03373683590364463 | validation: 0.027901272945203708]
	TIME [epoch: 6.5 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02882868578706497		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.02882868578706497 | validation: 0.03263153460719223]
	TIME [epoch: 6.52 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032038131798675935		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.032038131798675935 | validation: 0.03135316288101494]
	TIME [epoch: 6.5 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03150753442974795		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.03150753442974795 | validation: 0.02577919242958333]
	TIME [epoch: 6.49 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03296450037871843		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.03296450037871843 | validation: 0.019894547312852607]
	TIME [epoch: 6.5 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03305920520637486		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.03305920520637486 | validation: 0.020706895782802368]
	TIME [epoch: 6.47 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032693316565187466		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.032693316565187466 | validation: 0.027023103385372355]
	TIME [epoch: 6.49 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03510557379435936		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.03510557379435936 | validation: 0.02194431005617911]
	TIME [epoch: 6.5 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030533558157841718		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.030533558157841718 | validation: 0.028678381068676605]
	TIME [epoch: 6.51 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02675655948220614		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.02675655948220614 | validation: 0.023557085919961532]
	TIME [epoch: 6.48 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029806654331545182		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.029806654331545182 | validation: 0.019493828629798583]
	TIME [epoch: 6.5 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03173468770806891		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.03173468770806891 | validation: 0.026230206902610322]
	TIME [epoch: 6.5 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0330429000268852		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.0330429000268852 | validation: 0.0248890691985432]
	TIME [epoch: 6.47 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03252124675876545		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.03252124675876545 | validation: 0.03433642339017669]
	TIME [epoch: 6.48 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031092898685556036		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.031092898685556036 | validation: 0.02553204233179697]
	TIME [epoch: 6.5 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03256148264180193		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.03256148264180193 | validation: 0.026251172431989666]
	TIME [epoch: 6.52 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029637980324316627		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.029637980324316627 | validation: 0.0235654387044617]
	TIME [epoch: 6.49 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032977038427455335		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.032977038427455335 | validation: 0.020946133011759162]
	TIME [epoch: 6.48 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03404443110128696		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.03404443110128696 | validation: 0.023645050961922563]
	TIME [epoch: 6.48 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030027728053889258		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.030027728053889258 | validation: 0.02538383758716063]
	TIME [epoch: 6.49 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03191228934858457		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.03191228934858457 | validation: 0.021968078901895935]
	TIME [epoch: 6.49 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03150228610034851		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.03150228610034851 | validation: 0.02215452113713093]
	TIME [epoch: 6.49 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030655294336002545		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.030655294336002545 | validation: 0.02098867096996914]
	TIME [epoch: 6.51 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03332818187409933		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.03332818187409933 | validation: 0.023701584674080074]
	TIME [epoch: 6.49 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031695058181930094		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.031695058181930094 | validation: 0.03276838878614797]
	TIME [epoch: 6.49 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029350356667538897		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.029350356667538897 | validation: 0.026572814912183277]
	TIME [epoch: 6.48 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030746264194282624		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.030746264194282624 | validation: 0.02300489115774668]
	TIME [epoch: 6.49 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024274550116242806		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.024274550116242806 | validation: 0.01907972640622456]
	TIME [epoch: 6.48 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029397579773016366		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.029397579773016366 | validation: 0.030516478557589304]
	TIME [epoch: 6.48 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032008810260855475		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.032008810260855475 | validation: 0.02470232085494323]
	TIME [epoch: 6.52 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03277579553499492		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.03277579553499492 | validation: 0.03052563556626815]
	TIME [epoch: 6.5 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03012915169814039		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.03012915169814039 | validation: 0.028463039591924543]
	TIME [epoch: 6.49 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028773506462578466		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.028773506462578466 | validation: 0.01712457011681252]
	TIME [epoch: 6.5 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029380022322180267		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.029380022322180267 | validation: 0.02554576244211134]
	TIME [epoch: 6.52 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03228469865902145		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.03228469865902145 | validation: 0.026296723524413333]
	TIME [epoch: 6.49 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031100578496180843		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.031100578496180843 | validation: 0.023479973213913416]
	TIME [epoch: 6.5 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03212284108922662		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.03212284108922662 | validation: 0.020041491813862434]
	TIME [epoch: 6.54 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02841193760736104		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.02841193760736104 | validation: 0.015109555106356256]
	TIME [epoch: 6.49 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032831730366403696		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.032831730366403696 | validation: 0.027337161002355632]
	TIME [epoch: 6.49 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029003095723709793		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.029003095723709793 | validation: 0.025215815739530033]
	TIME [epoch: 6.48 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03002378798508251		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.03002378798508251 | validation: 0.02661229096193843]
	TIME [epoch: 6.48 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02933886774802951		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.02933886774802951 | validation: 0.023362764685472808]
	TIME [epoch: 6.49 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029802213992498452		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.029802213992498452 | validation: 0.026246335833031483]
	TIME [epoch: 6.49 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02848506738298639		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.02848506738298639 | validation: 0.02575607199551513]
	TIME [epoch: 6.52 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032655095782636485		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.032655095782636485 | validation: 0.023627711561058234]
	TIME [epoch: 6.48 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03034430830349009		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.03034430830349009 | validation: 0.022657011390964314]
	TIME [epoch: 6.48 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028681279715260986		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.028681279715260986 | validation: 0.030050335688789422]
	TIME [epoch: 6.48 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03043427435372121		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.03043427435372121 | validation: 0.02690070183098007]
	TIME [epoch: 6.48 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03365142477664665		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.03365142477664665 | validation: 0.030266512790908643]
	TIME [epoch: 6.48 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028966619395923963		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.028966619395923963 | validation: 0.018411125652615087]
	TIME [epoch: 6.49 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03518892740632443		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.03518892740632443 | validation: 0.022851945579292408]
	TIME [epoch: 6.56 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028755064155033188		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.028755064155033188 | validation: 0.02513529192214949]
	TIME [epoch: 6.48 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027805345828355556		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.027805345828355556 | validation: 0.025091183526126052]
	TIME [epoch: 6.5 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032437859666165844		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.032437859666165844 | validation: 0.032374657739602346]
	TIME [epoch: 6.48 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03098602345051149		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.03098602345051149 | validation: 0.02323990621217569]
	TIME [epoch: 6.48 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029898097958866998		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.029898097958866998 | validation: 0.02590602617802361]
	TIME [epoch: 6.49 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03293850862049428		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.03293850862049428 | validation: 0.021054082058015414]
	TIME [epoch: 6.49 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028857890977960817		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.028857890977960817 | validation: 0.030141718375739066]
	TIME [epoch: 6.51 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02953569465480517		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.02953569465480517 | validation: 0.02573488478280077]
	TIME [epoch: 6.5 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026019485093531997		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.026019485093531997 | validation: 0.024061047250738602]
	TIME [epoch: 6.48 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029679002959881552		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.029679002959881552 | validation: 0.02341182373795273]
	TIME [epoch: 6.48 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03179414386996479		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.03179414386996479 | validation: 0.02630261456673709]
	TIME [epoch: 6.48 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03107281116675955		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.03107281116675955 | validation: 0.020728415689352842]
	TIME [epoch: 6.49 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029910341457320015		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.029910341457320015 | validation: 0.027470331156249417]
	TIME [epoch: 6.48 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032196272018525235		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.032196272018525235 | validation: 0.025895934841924713]
	TIME [epoch: 6.5 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027045258883853153		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.027045258883853153 | validation: 0.02137518997893081]
	TIME [epoch: 6.51 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03188461483423648		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.03188461483423648 | validation: 0.02430310300691399]
	TIME [epoch: 6.5 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02719944958561387		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.02719944958561387 | validation: 0.028515229930832185]
	TIME [epoch: 6.48 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02770576306867859		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.02770576306867859 | validation: 0.028378523416607356]
	TIME [epoch: 6.5 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028216477027786867		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.028216477027786867 | validation: 0.023157426105995013]
	TIME [epoch: 6.49 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029880389299688115		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.029880389299688115 | validation: 0.02662726088983282]
	TIME [epoch: 6.49 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032873851310667515		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.032873851310667515 | validation: 0.027168164604045662]
	TIME [epoch: 6.52 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03113807854854216		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.03113807854854216 | validation: 0.020160937019457016]
	TIME [epoch: 6.52 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027829333245601703		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.027829333245601703 | validation: 0.02528368560698046]
	TIME [epoch: 6.49 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030970684976960688		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.030970684976960688 | validation: 0.018568416997313205]
	TIME [epoch: 6.48 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029847173982338646		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.029847173982338646 | validation: 0.026479647469150765]
	TIME [epoch: 6.49 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03532060903548411		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.03532060903548411 | validation: 0.023276402595366178]
	TIME [epoch: 6.49 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028547144063304268		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.028547144063304268 | validation: 0.020217490376227866]
	TIME [epoch: 6.49 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03201741323206708		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.03201741323206708 | validation: 0.018204246774709904]
	TIME [epoch: 6.51 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026794830234112332		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.026794830234112332 | validation: 0.02335120252416192]
	TIME [epoch: 6.51 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02905906276320184		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.02905906276320184 | validation: 0.026484471685258353]
	TIME [epoch: 6.49 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032780870053560666		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.032780870053560666 | validation: 0.01733824403104178]
	TIME [epoch: 6.49 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032540558840864896		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.032540558840864896 | validation: 0.01822049066584026]
	TIME [epoch: 6.49 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03245260230167146		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.03245260230167146 | validation: 0.0271977298024603]
	TIME [epoch: 6.49 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03059652052499959		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.03059652052499959 | validation: 0.025079816640166685]
	TIME [epoch: 6.5 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03089591397986336		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.03089591397986336 | validation: 0.023469318710493375]
	TIME [epoch: 6.49 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03061643909422829		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.03061643909422829 | validation: 0.024354431252033973]
	TIME [epoch: 6.52 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031357530099680835		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.031357530099680835 | validation: 0.02676887732358628]
	TIME [epoch: 6.49 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030783376459934904		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.030783376459934904 | validation: 0.020811839750345756]
	TIME [epoch: 6.48 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030591700079111776		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.030591700079111776 | validation: 0.01748849922732451]
	TIME [epoch: 6.51 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028857369306441092		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.028857369306441092 | validation: 0.02265727060942107]
	TIME [epoch: 6.5 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028830156068801942		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.028830156068801942 | validation: 0.02412392711157011]
	TIME [epoch: 6.49 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03225469520806022		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.03225469520806022 | validation: 0.028267051291718623]
	TIME [epoch: 6.49 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030662928894934632		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.030662928894934632 | validation: 0.027400162197544452]
	TIME [epoch: 6.53 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03231085481571		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.03231085481571 | validation: 0.022597425343373168]
	TIME [epoch: 6.5 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031329766202958444		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.031329766202958444 | validation: 0.0136907918637702]
	TIME [epoch: 6.47 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030370396351366617		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.030370396351366617 | validation: 0.028290402832238628]
	TIME [epoch: 6.47 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030172787332379478		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.030172787332379478 | validation: 0.02775474943562605]
	TIME [epoch: 6.47 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03028830497595185		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.03028830497595185 | validation: 0.02464065709871848]
	TIME [epoch: 6.48 sec]
Finished training in 13607.983 seconds.
