Args:
Namespace(name='model_tr_study204', outdir='out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r5', training_data='data/transition_rate_studies/tr_study204/tr_study204_training/r5', validation_data='data/transition_rate_studies/tr_study204/tr_study204_validation/r5', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.075, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=100, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 401325133

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r5_20240219_234257/states/model_tr_study204_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 10/10] avg loss: 11.274897541704174		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.274897541704174 | validation: 11.87022451369259]
	TIME [epoch: 71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r5_20240219_234257/states/model_tr_study204_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 10/10] avg loss: 11.200474103554898		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.200474103554898 | validation: 8.677002008835808]
	TIME [epoch: 9.25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r5_20240219_234257/states/model_tr_study204_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 10/10] avg loss: 10.036414560455338		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.036414560455338 | validation: 11.244520620233052]
	TIME [epoch: 9.23 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 10/10] avg loss: 10.525772324946237		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.525772324946237 | validation: 10.890609940796303]
	TIME [epoch: 9.25 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 10/10] avg loss: 10.059753722979814		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.059753722979814 | validation: 11.303556382117662]
	TIME [epoch: 9.22 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 10/10] avg loss: 9.814985286732746		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.814985286732746 | validation: 9.185887384215851]
	TIME [epoch: 9.22 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.011124915103718		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.011124915103718 | validation: 6.5898781405014475]
	TIME [epoch: 9.23 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r5_20240219_234257/states/model_tr_study204_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.860297999039632		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.860297999039632 | validation: 7.357196361980743]
	TIME [epoch: 9.23 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.586504547365381		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.586504547365381 | validation: 7.066360041175301]
	TIME [epoch: 9.25 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.3137979535112665		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.3137979535112665 | validation: 8.925069437712384]
	TIME [epoch: 9.22 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.734498727494595		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.734498727494595 | validation: 6.0834519213047855]
	TIME [epoch: 9.21 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r5_20240219_234257/states/model_tr_study204_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.356920043173522		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.356920043173522 | validation: 5.896907236376711]
	TIME [epoch: 9.24 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r5_20240219_234257/states/model_tr_study204_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.606738628840149		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.606738628840149 | validation: 5.975160117978859]
	TIME [epoch: 9.25 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.14469606948151		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.14469606948151 | validation: 7.241379470141628]
	TIME [epoch: 9.25 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.426454737792819		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.426454737792819 | validation: 5.086010227665476]
	TIME [epoch: 9.23 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r5_20240219_234257/states/model_tr_study204_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.604505167191291		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.604505167191291 | validation: 4.528754978962612]
	TIME [epoch: 9.21 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r5_20240219_234257/states/model_tr_study204_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.608743367856741		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.608743367856741 | validation: 5.930385432384237]
	TIME [epoch: 9.23 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.4576738471790325		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.4576738471790325 | validation: 4.362681759297334]
	TIME [epoch: 9.24 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r5_20240219_234257/states/model_tr_study204_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.590991684723209		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.590991684723209 | validation: 6.250545383870992]
	TIME [epoch: 9.23 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.359437471632685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.359437471632685 | validation: 4.068701201752245]
	TIME [epoch: 9.23 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r5_20240219_234257/states/model_tr_study204_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.623911759548343		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.623911759548343 | validation: 6.826821321444017]
	TIME [epoch: 9.22 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.9811490867171555		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.9811490867171555 | validation: 4.368729642951518]
	TIME [epoch: 9.25 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.068046759546229		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.068046759546229 | validation: 4.845897542747437]
	TIME [epoch: 9.23 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.02192080705018		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.02192080705018 | validation: 3.8102821127783377]
	TIME [epoch: 9.22 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r5_20240219_234257/states/model_tr_study204_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.830457465241537		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.830457465241537 | validation: 5.22347801192292]
	TIME [epoch: 9.23 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.85436212894478		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.85436212894478 | validation: 4.558447680716591]
	TIME [epoch: 9.24 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.079743878637522		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.079743878637522 | validation: 4.811767792391684]
	TIME [epoch: 9.25 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.8706299435575624		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8706299435575624 | validation: 4.856657811253849]
	TIME [epoch: 9.23 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.890613187064782		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.890613187064782 | validation: 7.336476995352305]
	TIME [epoch: 9.22 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.474808619630265		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.474808619630265 | validation: 4.442930245500065]
	TIME [epoch: 9.22 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.6584617274210536		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6584617274210536 | validation: 5.102813492430438]
	TIME [epoch: 9.25 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.7220847422269316		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7220847422269316 | validation: 4.7490914950942145]
	TIME [epoch: 9.23 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.602336088833804		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.602336088833804 | validation: 3.997528078709605]
	TIME [epoch: 9.23 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.6313750557800537		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6313750557800537 | validation: 5.039306057443333]
	TIME [epoch: 9.23 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.6177171913259074		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6177171913259074 | validation: 4.167572109302068]
	TIME [epoch: 9.24 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.32816754859333		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.32816754859333 | validation: 4.70810282298784]
	TIME [epoch: 9.25 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.7547392631889984		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7547392631889984 | validation: 4.472069583310111]
	TIME [epoch: 9.23 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.6268044836920508		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6268044836920508 | validation: 4.138580787306575]
	TIME [epoch: 9.23 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.263662217345199		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.263662217345199 | validation: 4.520004596065769]
	TIME [epoch: 9.23 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.163419903813422		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.163419903813422 | validation: 4.318832923862495]
	TIME [epoch: 9.25 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.877883678852472		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.877883678852472 | validation: 2.697567997198682]
	TIME [epoch: 9.23 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r5_20240219_234257/states/model_tr_study204_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.09048983147973		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.09048983147973 | validation: 2.942289812880441]
	TIME [epoch: 9.23 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.834900573334051		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.834900573334051 | validation: 1.5912204823925586]
	TIME [epoch: 9.23 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r5_20240219_234257/states/model_tr_study204_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9987519246894798		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9987519246894798 | validation: 1.4567263677489457]
	TIME [epoch: 9.23 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r5_20240219_234257/states/model_tr_study204_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7421164922135108		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7421164922135108 | validation: 2.070401012288075]
	TIME [epoch: 9.25 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8654508618823968		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8654508618823968 | validation: 1.0816696403496309]
	TIME [epoch: 9.22 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r5_20240219_234257/states/model_tr_study204_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8362099326687304		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8362099326687304 | validation: 3.114350906895252]
	TIME [epoch: 9.23 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2277297772661115		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2277297772661115 | validation: 1.448427203408607]
	TIME [epoch: 9.22 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8270099630187484		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8270099630187484 | validation: 1.379260832217955]
	TIME [epoch: 9.25 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.021700737055228		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.021700737055228 | validation: 1.5274413967943177]
	TIME [epoch: 9.22 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8499404937164439		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8499404937164439 | validation: 1.6914657320000805]
	TIME [epoch: 9.22 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.647217756124109		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.647217756124109 | validation: 1.473039784828528]
	TIME [epoch: 9.23 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6643440615190954		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6643440615190954 | validation: 1.4665624139413151]
	TIME [epoch: 9.24 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.28388683621197		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.28388683621197 | validation: 2.416101983340563]
	TIME [epoch: 9.25 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7600502332150807		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7600502332150807 | validation: 1.7725435739191129]
	TIME [epoch: 9.23 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.476850077479579		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.476850077479579 | validation: 1.4938165370243468]
	TIME [epoch: 9.22 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.028062431295473		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.028062431295473 | validation: 2.102115550794273]
	TIME [epoch: 9.22 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7464623174161158		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7464623174161158 | validation: 1.296084171939419]
	TIME [epoch: 9.25 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0001029716711747		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0001029716711747 | validation: 1.7355771822164514]
	TIME [epoch: 9.23 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8972304473622692		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8972304473622692 | validation: 1.209159577295981]
	TIME [epoch: 9.22 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9429647921476743		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9429647921476743 | validation: 4.37240880941045]
	TIME [epoch: 9.22 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.8068441478891613		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8068441478891613 | validation: 2.463518484070404]
	TIME [epoch: 9.24 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7418114219833576		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7418114219833576 | validation: 1.1952474420135815]
	TIME [epoch: 9.24 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4254344543575934		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4254344543575934 | validation: 1.4590946640941]
	TIME [epoch: 9.23 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4222310180336586		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4222310180336586 | validation: 1.023821895898508]
	TIME [epoch: 9.23 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r5_20240219_234257/states/model_tr_study204_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.271325743796806		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.271325743796806 | validation: 1.5338217849898879]
	TIME [epoch: 9.23 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6995170613050132		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6995170613050132 | validation: 1.239004222116277]
	TIME [epoch: 9.25 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.65489305436996		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.65489305436996 | validation: 0.872463750832592]
	TIME [epoch: 9.22 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r5_20240219_234257/states/model_tr_study204_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5681052545410676		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5681052545410676 | validation: 1.879540981211464]
	TIME [epoch: 9.22 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7011009628941245		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7011009628941245 | validation: 2.069871338035456]
	TIME [epoch: 9.21 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6598801406288235		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6598801406288235 | validation: 1.4035289151824448]
	TIME [epoch: 9.23 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5576504802565274		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5576504802565274 | validation: 1.0936040260796938]
	TIME [epoch: 9.24 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.781676771850499		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.781676771850499 | validation: 2.4777532549755845]
	TIME [epoch: 9.21 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8291258090334175		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8291258090334175 | validation: 1.3926127537035908]
	TIME [epoch: 9.21 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3874025056023884		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3874025056023884 | validation: 1.8900968400812193]
	TIME [epoch: 9.21 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.492629140680196		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.492629140680196 | validation: 1.1769390281358687]
	TIME [epoch: 9.24 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5483135610010432		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5483135610010432 | validation: 0.8134881104705516]
	TIME [epoch: 9.22 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r5_20240219_234257/states/model_tr_study204_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2973797707718142		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2973797707718142 | validation: 1.4869380587501784]
	TIME [epoch: 9.22 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5173312642116648		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5173312642116648 | validation: 1.492905428786446]
	TIME [epoch: 9.21 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3062136228369485		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3062136228369485 | validation: 1.1080272428330096]
	TIME [epoch: 9.22 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6832857873490306		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6832857873490306 | validation: 1.1194576971163155]
	TIME [epoch: 9.22 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2489689708483782		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2489689708483782 | validation: 1.2322295041591058]
	TIME [epoch: 9.21 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3352205959901666		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3352205959901666 | validation: 2.124441582674352]
	TIME [epoch: 9.21 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4577090687955077		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4577090687955077 | validation: 1.098137854429181]
	TIME [epoch: 9.2 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3893653612652614		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3893653612652614 | validation: 1.0821934496827201]
	TIME [epoch: 9.23 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3010758012994759		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3010758012994759 | validation: 1.219395428701156]
	TIME [epoch: 9.21 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2633272360894414		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2633272360894414 | validation: 0.9849177976726416]
	TIME [epoch: 9.2 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.132377232868033		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.132377232868033 | validation: 1.2697014453337807]
	TIME [epoch: 9.2 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1741864802306103		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1741864802306103 | validation: 2.240294780554307]
	TIME [epoch: 9.22 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3749917010734614		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3749917010734614 | validation: 0.9330012148777715]
	TIME [epoch: 9.23 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4726901026784798		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4726901026784798 | validation: 2.190364310903006]
	TIME [epoch: 9.22 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3302437114650083		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3302437114650083 | validation: 1.544905208376429]
	TIME [epoch: 9.21 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4566552031079099		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4566552031079099 | validation: 0.9719779562211854]
	TIME [epoch: 9.2 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.190502621874551		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.190502621874551 | validation: 0.7186020523844763]
	TIME [epoch: 9.23 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r5_20240219_234257/states/model_tr_study204_94.pth
	Model improved!!!
EPOCH 95/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0810059176334301		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0810059176334301 | validation: 1.1351308854114832]
	TIME [epoch: 9.21 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1609500378009527		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1609500378009527 | validation: 1.4258426436269591]
	TIME [epoch: 9.21 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1459717354393546		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1459717354393546 | validation: 2.2791433884841665]
	TIME [epoch: 9.21 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2138493178714405		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2138493178714405 | validation: 0.9395715260604133]
	TIME [epoch: 9.23 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3161722107511213		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3161722107511213 | validation: 0.8909635631452786]
	TIME [epoch: 9.22 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3579895329563383		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3579895329563383 | validation: 1.7764098179044436]
	TIME [epoch: 9.2 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3185068063297156		[learning rate: 0.0099673]
	Learning Rate: 0.00996733
	LOSS [training: 1.3185068063297156 | validation: 0.7376877841270141]
	TIME [epoch: 9.2 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4878853184034704		[learning rate: 0.0099312]
	Learning Rate: 0.00993116
	LOSS [training: 1.4878853184034704 | validation: 0.9208674063139441]
	TIME [epoch: 9.2 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2994798501833573		[learning rate: 0.0098951]
	Learning Rate: 0.00989512
	LOSS [training: 1.2994798501833573 | validation: 1.7077832217593254]
	TIME [epoch: 9.24 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.213737618303143		[learning rate: 0.0098592]
	Learning Rate: 0.00985921
	LOSS [training: 1.213737618303143 | validation: 1.0007859256676173]
	TIME [epoch: 9.22 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0264303341209478		[learning rate: 0.0098234]
	Learning Rate: 0.00982343
	LOSS [training: 1.0264303341209478 | validation: 0.7268930757443579]
	TIME [epoch: 9.21 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0510930311007474		[learning rate: 0.0097878]
	Learning Rate: 0.00978778
	LOSS [training: 1.0510930311007474 | validation: 1.3340828553200923]
	TIME [epoch: 9.21 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2982444768056385		[learning rate: 0.0097523]
	Learning Rate: 0.00975226
	LOSS [training: 1.2982444768056385 | validation: 1.1742952570781073]
	TIME [epoch: 9.22 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1125871299444916		[learning rate: 0.0097169]
	Learning Rate: 0.00971687
	LOSS [training: 1.1125871299444916 | validation: 1.4719017667475254]
	TIME [epoch: 9.23 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.158634633094086		[learning rate: 0.0096816]
	Learning Rate: 0.0096816
	LOSS [training: 1.158634633094086 | validation: 0.8104602477024738]
	TIME [epoch: 9.21 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.913687758627515		[learning rate: 0.0096465]
	Learning Rate: 0.00964647
	LOSS [training: 0.913687758627515 | validation: 0.7738292801728945]
	TIME [epoch: 9.21 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1193117863166822		[learning rate: 0.0096115]
	Learning Rate: 0.00961146
	LOSS [training: 1.1193117863166822 | validation: 0.7487374459248788]
	TIME [epoch: 9.21 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9809940008895716		[learning rate: 0.0095766]
	Learning Rate: 0.00957658
	LOSS [training: 0.9809940008895716 | validation: 1.706327239134599]
	TIME [epoch: 9.22 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1470182762112648		[learning rate: 0.0095418]
	Learning Rate: 0.00954183
	LOSS [training: 1.1470182762112648 | validation: 0.6183025712800956]
	TIME [epoch: 9.19 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r5_20240219_234257/states/model_tr_study204_113.pth
	Model improved!!!
EPOCH 114/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2437576362814498		[learning rate: 0.0095072]
	Learning Rate: 0.0095072
	LOSS [training: 1.2437576362814498 | validation: 0.5788362575129129]
	TIME [epoch: 9.22 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r5_20240219_234257/states/model_tr_study204_114.pth
	Model improved!!!
EPOCH 115/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1497651464002157		[learning rate: 0.0094727]
	Learning Rate: 0.0094727
	LOSS [training: 1.1497651464002157 | validation: 0.7361341263859571]
	TIME [epoch: 9.22 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8798469837950718		[learning rate: 0.0094383]
	Learning Rate: 0.00943832
	LOSS [training: 0.8798469837950718 | validation: 1.109655262950018]
	TIME [epoch: 9.22 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2094237469929765		[learning rate: 0.0094041]
	Learning Rate: 0.00940407
	LOSS [training: 1.2094237469929765 | validation: 1.1776632116904846]
	TIME [epoch: 9.23 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9207674645009927		[learning rate: 0.0093699]
	Learning Rate: 0.00936994
	LOSS [training: 0.9207674645009927 | validation: 1.023408670140266]
	TIME [epoch: 9.21 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4076590421323663		[learning rate: 0.0093359]
	Learning Rate: 0.00933594
	LOSS [training: 1.4076590421323663 | validation: 1.95376206954663]
	TIME [epoch: 9.21 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0180590427579301		[learning rate: 0.0093021]
	Learning Rate: 0.00930206
	LOSS [training: 1.0180590427579301 | validation: 1.4412130475849272]
	TIME [epoch: 9.2 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0372893460230215		[learning rate: 0.0092683]
	Learning Rate: 0.0092683
	LOSS [training: 1.0372893460230215 | validation: 1.442810782255553]
	TIME [epoch: 9.23 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2201802103776198		[learning rate: 0.0092347]
	Learning Rate: 0.00923466
	LOSS [training: 1.2201802103776198 | validation: 0.8346501434480297]
	TIME [epoch: 9.22 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9721976892420983		[learning rate: 0.0092011]
	Learning Rate: 0.00920115
	LOSS [training: 0.9721976892420983 | validation: 0.8926077730819677]
	TIME [epoch: 9.21 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0074427102165233		[learning rate: 0.0091678]
	Learning Rate: 0.00916776
	LOSS [training: 1.0074427102165233 | validation: 0.806672962961781]
	TIME [epoch: 9.22 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0714948364102554		[learning rate: 0.0091345]
	Learning Rate: 0.00913449
	LOSS [training: 1.0714948364102554 | validation: 0.8166193811873353]
	TIME [epoch: 9.2 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8611656162070151		[learning rate: 0.0091013]
	Learning Rate: 0.00910134
	LOSS [training: 0.8611656162070151 | validation: 0.8863869294671602]
	TIME [epoch: 9.23 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9249197941942366		[learning rate: 0.0090683]
	Learning Rate: 0.00906831
	LOSS [training: 0.9249197941942366 | validation: 1.0310532299689266]
	TIME [epoch: 9.21 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8405679216581634		[learning rate: 0.0090354]
	Learning Rate: 0.0090354
	LOSS [training: 0.8405679216581634 | validation: 1.4573910420628868]
	TIME [epoch: 9.21 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9668628666201375		[learning rate: 0.0090026]
	Learning Rate: 0.00900261
	LOSS [training: 0.9668628666201375 | validation: 0.9267858133140248]
	TIME [epoch: 9.21 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8876608620452716		[learning rate: 0.0089699]
	Learning Rate: 0.00896994
	LOSS [training: 0.8876608620452716 | validation: 0.8624397985416762]
	TIME [epoch: 9.25 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.076024725631394		[learning rate: 0.0089374]
	Learning Rate: 0.00893739
	LOSS [training: 1.076024725631394 | validation: 0.9990447551547214]
	TIME [epoch: 9.22 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3379389986432342		[learning rate: 0.008905]
	Learning Rate: 0.00890495
	LOSS [training: 1.3379389986432342 | validation: 1.802473294361604]
	TIME [epoch: 9.21 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1716132810756161		[learning rate: 0.0088726]
	Learning Rate: 0.00887263
	LOSS [training: 1.1716132810756161 | validation: 0.6740502389737455]
	TIME [epoch: 9.21 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9794369832381378		[learning rate: 0.0088404]
	Learning Rate: 0.00884044
	LOSS [training: 0.9794369832381378 | validation: 1.1368018357634364]
	TIME [epoch: 9.21 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0517062975455755		[learning rate: 0.0088084]
	Learning Rate: 0.00880835
	LOSS [training: 1.0517062975455755 | validation: 1.3857499995881524]
	TIME [epoch: 9.23 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0930712132463536		[learning rate: 0.0087764]
	Learning Rate: 0.00877639
	LOSS [training: 1.0930712132463536 | validation: 0.7644888439809614]
	TIME [epoch: 9.21 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0597264610856807		[learning rate: 0.0087445]
	Learning Rate: 0.00874454
	LOSS [training: 1.0597264610856807 | validation: 0.7682289285489312]
	TIME [epoch: 9.21 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8584108083159554		[learning rate: 0.0087128]
	Learning Rate: 0.0087128
	LOSS [training: 0.8584108083159554 | validation: 1.3895599755982089]
	TIME [epoch: 9.2 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9742467300892319		[learning rate: 0.0086812]
	Learning Rate: 0.00868118
	LOSS [training: 0.9742467300892319 | validation: 0.6011089723044287]
	TIME [epoch: 9.24 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9846332922132515		[learning rate: 0.0086497]
	Learning Rate: 0.00864968
	LOSS [training: 0.9846332922132515 | validation: 1.3156109737615218]
	TIME [epoch: 9.2 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9737283309349036		[learning rate: 0.0086183]
	Learning Rate: 0.00861829
	LOSS [training: 0.9737283309349036 | validation: 1.0935860763444338]
	TIME [epoch: 9.2 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8078247591645811		[learning rate: 0.008587]
	Learning Rate: 0.00858701
	LOSS [training: 0.8078247591645811 | validation: 0.759978878815835]
	TIME [epoch: 9.21 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9421998609320127		[learning rate: 0.0085559]
	Learning Rate: 0.00855585
	LOSS [training: 0.9421998609320127 | validation: 0.7097100714955229]
	TIME [epoch: 9.21 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7246567192901436		[learning rate: 0.0085248]
	Learning Rate: 0.0085248
	LOSS [training: 0.7246567192901436 | validation: 0.6100911662550255]
	TIME [epoch: 9.23 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8513152030549813		[learning rate: 0.0084939]
	Learning Rate: 0.00849386
	LOSS [training: 0.8513152030549813 | validation: 0.6034299519913685]
	TIME [epoch: 9.21 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9637680552774315		[learning rate: 0.008463]
	Learning Rate: 0.00846304
	LOSS [training: 0.9637680552774315 | validation: 0.7497676253017763]
	TIME [epoch: 9.21 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7533903958432121		[learning rate: 0.0084323]
	Learning Rate: 0.00843233
	LOSS [training: 0.7533903958432121 | validation: 0.630345657811583]
	TIME [epoch: 9.21 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9803859949622581		[learning rate: 0.0084017]
	Learning Rate: 0.00840172
	LOSS [training: 0.9803859949622581 | validation: 0.6963283704022303]
	TIME [epoch: 9.22 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9489384751287844		[learning rate: 0.0083712]
	Learning Rate: 0.00837123
	LOSS [training: 0.9489384751287844 | validation: 0.5425912171898681]
	TIME [epoch: 9.21 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r5_20240219_234257/states/model_tr_study204_149.pth
	Model improved!!!
EPOCH 150/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7955675884084304		[learning rate: 0.0083409]
	Learning Rate: 0.00834085
	LOSS [training: 0.7955675884084304 | validation: 0.6398733637351519]
	TIME [epoch: 9.23 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0199953368023191		[learning rate: 0.0083106]
	Learning Rate: 0.00831059
	LOSS [training: 1.0199953368023191 | validation: 1.3940242266720295]
	TIME [epoch: 9.22 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7969831682435016		[learning rate: 0.0082804]
	Learning Rate: 0.00828043
	LOSS [training: 0.7969831682435016 | validation: 0.7217617003267961]
	TIME [epoch: 9.21 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9635910060714789		[learning rate: 0.0082504]
	Learning Rate: 0.00825037
	LOSS [training: 0.9635910060714789 | validation: 1.1923823065638484]
	TIME [epoch: 9.24 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8918511482354688		[learning rate: 0.0082204]
	Learning Rate: 0.00822043
	LOSS [training: 0.8918511482354688 | validation: 1.4002411651172775]
	TIME [epoch: 9.21 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8186816645815632		[learning rate: 0.0081906]
	Learning Rate: 0.0081906
	LOSS [training: 0.8186816645815632 | validation: 0.5535868612679129]
	TIME [epoch: 9.21 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.69760697166098		[learning rate: 0.0081609]
	Learning Rate: 0.00816088
	LOSS [training: 0.69760697166098 | validation: 0.4959433367426465]
	TIME [epoch: 9.22 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r5_20240219_234257/states/model_tr_study204_156.pth
	Model improved!!!
EPOCH 157/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7003882046125363		[learning rate: 0.0081313]
	Learning Rate: 0.00813126
	LOSS [training: 0.7003882046125363 | validation: 0.7510005455688455]
	TIME [epoch: 9.24 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7367953766633237		[learning rate: 0.0081018]
	Learning Rate: 0.00810175
	LOSS [training: 0.7367953766633237 | validation: 0.7751204300304608]
	TIME [epoch: 9.21 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9993462583076658		[learning rate: 0.0080724]
	Learning Rate: 0.00807235
	LOSS [training: 0.9993462583076658 | validation: 1.0001903937122676]
	TIME [epoch: 9.21 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9846558681516407		[learning rate: 0.0080431]
	Learning Rate: 0.00804305
	LOSS [training: 0.9846558681516407 | validation: 0.42312052879327644]
	TIME [epoch: 9.22 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r5_20240219_234257/states/model_tr_study204_160.pth
	Model improved!!!
EPOCH 161/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8054409128136697		[learning rate: 0.0080139]
	Learning Rate: 0.00801387
	LOSS [training: 0.8054409128136697 | validation: 1.2809010551229312]
	TIME [epoch: 9.21 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8284544354450208		[learning rate: 0.0079848]
	Learning Rate: 0.00798478
	LOSS [training: 0.8284544354450208 | validation: 0.424138983156071]
	TIME [epoch: 9.24 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6488764756122632		[learning rate: 0.0079558]
	Learning Rate: 0.00795581
	LOSS [training: 0.6488764756122632 | validation: 0.9086298814937587]
	TIME [epoch: 9.21 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.845499049261298		[learning rate: 0.0079269]
	Learning Rate: 0.00792693
	LOSS [training: 0.845499049261298 | validation: 0.522632680812164]
	TIME [epoch: 9.21 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7048951749368642		[learning rate: 0.0078982]
	Learning Rate: 0.00789817
	LOSS [training: 0.7048951749368642 | validation: 1.2238722617235651]
	TIME [epoch: 9.21 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7928067971581411		[learning rate: 0.0078695]
	Learning Rate: 0.0078695
	LOSS [training: 0.7928067971581411 | validation: 0.4798729633058426]
	TIME [epoch: 9.22 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8036808746632662		[learning rate: 0.0078409]
	Learning Rate: 0.00784094
	LOSS [training: 0.8036808746632662 | validation: 1.4474276703058289]
	TIME [epoch: 9.23 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7888245687337634		[learning rate: 0.0078125]
	Learning Rate: 0.00781249
	LOSS [training: 0.7888245687337634 | validation: 0.5399986320086053]
	TIME [epoch: 9.22 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7205122279974352		[learning rate: 0.0077841]
	Learning Rate: 0.00778414
	LOSS [training: 0.7205122279974352 | validation: 0.722415996103999]
	TIME [epoch: 9.22 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8068272249664303		[learning rate: 0.0077559]
	Learning Rate: 0.00775589
	LOSS [training: 0.8068272249664303 | validation: 0.5206209465987219]
	TIME [epoch: 9.21 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8423873315777058		[learning rate: 0.0077277]
	Learning Rate: 0.00772774
	LOSS [training: 0.8423873315777058 | validation: 0.5862769083764746]
	TIME [epoch: 9.24 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.665360599522195		[learning rate: 0.0076997]
	Learning Rate: 0.0076997
	LOSS [training: 0.665360599522195 | validation: 0.6580373344004462]
	TIME [epoch: 9.22 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7864797636422919		[learning rate: 0.0076718]
	Learning Rate: 0.00767176
	LOSS [training: 0.7864797636422919 | validation: 0.7653159844936313]
	TIME [epoch: 9.21 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7666927304305143		[learning rate: 0.0076439]
	Learning Rate: 0.00764391
	LOSS [training: 0.7666927304305143 | validation: 1.4573698233215067]
	TIME [epoch: 9.21 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7061498856076529		[learning rate: 0.0076162]
	Learning Rate: 0.00761617
	LOSS [training: 0.7061498856076529 | validation: 0.40271860987734587]
	TIME [epoch: 9.23 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r5_20240219_234257/states/model_tr_study204_175.pth
	Model improved!!!
EPOCH 176/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7266885394803367		[learning rate: 0.0075885]
	Learning Rate: 0.00758853
	LOSS [training: 0.7266885394803367 | validation: 0.6410565847172975]
	TIME [epoch: 9.23 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6732582925599873		[learning rate: 0.007561]
	Learning Rate: 0.00756099
	LOSS [training: 0.6732582925599873 | validation: 1.1308172461172896]
	TIME [epoch: 9.21 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6613066400108265		[learning rate: 0.0075336]
	Learning Rate: 0.00753356
	LOSS [training: 0.6613066400108265 | validation: 0.4457685361344082]
	TIME [epoch: 9.22 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6414553118537295		[learning rate: 0.0075062]
	Learning Rate: 0.00750622
	LOSS [training: 0.6414553118537295 | validation: 0.4773717260191601]
	TIME [epoch: 9.21 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6905819766516184		[learning rate: 0.007479]
	Learning Rate: 0.00747897
	LOSS [training: 0.6905819766516184 | validation: 0.5248987417928767]
	TIME [epoch: 9.24 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.702979990176331		[learning rate: 0.0074518]
	Learning Rate: 0.00745183
	LOSS [training: 0.702979990176331 | validation: 0.9037866702042541]
	TIME [epoch: 9.22 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6834724303703957		[learning rate: 0.0074248]
	Learning Rate: 0.00742479
	LOSS [training: 0.6834724303703957 | validation: 0.8113651656656093]
	TIME [epoch: 9.22 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8562904148456303		[learning rate: 0.0073978]
	Learning Rate: 0.00739784
	LOSS [training: 0.8562904148456303 | validation: 0.6417675060076806]
	TIME [epoch: 9.21 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6488597681856915		[learning rate: 0.007371]
	Learning Rate: 0.007371
	LOSS [training: 0.6488597681856915 | validation: 1.0948775656794894]
	TIME [epoch: 9.22 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7276623104861485		[learning rate: 0.0073442]
	Learning Rate: 0.00734425
	LOSS [training: 0.7276623104861485 | validation: 0.6530419133505101]
	TIME [epoch: 9.23 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7675582707412119		[learning rate: 0.0073176]
	Learning Rate: 0.0073176
	LOSS [training: 0.7675582707412119 | validation: 0.9265275485920943]
	TIME [epoch: 9.21 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7038562715133253		[learning rate: 0.007291]
	Learning Rate: 0.00729104
	LOSS [training: 0.7038562715133253 | validation: 0.9910351891925666]
	TIME [epoch: 9.21 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.837681341371589		[learning rate: 0.0072646]
	Learning Rate: 0.00726458
	LOSS [training: 0.837681341371589 | validation: 0.4155824992838209]
	TIME [epoch: 9.21 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.720479930399151		[learning rate: 0.0072382]
	Learning Rate: 0.00723822
	LOSS [training: 0.720479930399151 | validation: 0.6173621542322206]
	TIME [epoch: 9.23 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6347604041222523		[learning rate: 0.0072119]
	Learning Rate: 0.00721195
	LOSS [training: 0.6347604041222523 | validation: 0.615693702720636]
	TIME [epoch: 9.22 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6239486476418358		[learning rate: 0.0071858]
	Learning Rate: 0.00718578
	LOSS [training: 0.6239486476418358 | validation: 0.4468397484753962]
	TIME [epoch: 9.21 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7798026085068412		[learning rate: 0.0071597]
	Learning Rate: 0.0071597
	LOSS [training: 0.7798026085068412 | validation: 0.420721605962207]
	TIME [epoch: 9.22 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.794946208400111		[learning rate: 0.0071337]
	Learning Rate: 0.00713371
	LOSS [training: 0.794946208400111 | validation: 0.469963203509413]
	TIME [epoch: 9.21 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.702384083673748		[learning rate: 0.0071078]
	Learning Rate: 0.00710783
	LOSS [training: 0.702384083673748 | validation: 0.5403674067219377]
	TIME [epoch: 9.24 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6670642974152992		[learning rate: 0.007082]
	Learning Rate: 0.00708203
	LOSS [training: 0.6670642974152992 | validation: 0.8364813588856466]
	TIME [epoch: 9.22 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8591443019509603		[learning rate: 0.0070563]
	Learning Rate: 0.00705633
	LOSS [training: 0.8591443019509603 | validation: 1.0901660690584927]
	TIME [epoch: 9.22 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8016463632088593		[learning rate: 0.0070307]
	Learning Rate: 0.00703072
	LOSS [training: 0.8016463632088593 | validation: 0.4293575687967012]
	TIME [epoch: 9.21 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6122411422201132		[learning rate: 0.0070052]
	Learning Rate: 0.00700521
	LOSS [training: 0.6122411422201132 | validation: 0.3973610895247982]
	TIME [epoch: 9.23 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r5_20240219_234257/states/model_tr_study204_198.pth
	Model improved!!!
EPOCH 199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6643524918301391		[learning rate: 0.0069798]
	Learning Rate: 0.00697979
	LOSS [training: 0.6643524918301391 | validation: 0.8092197685298279]
	TIME [epoch: 9.21 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7042074059041625		[learning rate: 0.0069545]
	Learning Rate: 0.00695446
	LOSS [training: 0.7042074059041625 | validation: 0.5674906984389716]
	TIME [epoch: 9.22 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5676823659093673		[learning rate: 0.0069292]
	Learning Rate: 0.00692922
	LOSS [training: 0.5676823659093673 | validation: 0.4928114487646624]
	TIME [epoch: 9.21 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6242631984295587		[learning rate: 0.0069041]
	Learning Rate: 0.00690407
	LOSS [training: 0.6242631984295587 | validation: 0.7168612914719542]
	TIME [epoch: 9.22 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6769223341645294		[learning rate: 0.006879]
	Learning Rate: 0.00687902
	LOSS [training: 0.6769223341645294 | validation: 1.215332130202876]
	TIME [epoch: 9.24 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.025455729749089		[learning rate: 0.0068541]
	Learning Rate: 0.00685405
	LOSS [training: 1.025455729749089 | validation: 0.564643927064099]
	TIME [epoch: 9.21 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7696382586586729		[learning rate: 0.0068292]
	Learning Rate: 0.00682918
	LOSS [training: 0.7696382586586729 | validation: 0.41022299204608237]
	TIME [epoch: 9.22 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5918872056008252		[learning rate: 0.0068044]
	Learning Rate: 0.00680439
	LOSS [training: 0.5918872056008252 | validation: 0.3745493815050784]
	TIME [epoch: 9.21 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r5_20240219_234257/states/model_tr_study204_206.pth
	Model improved!!!
EPOCH 207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5911369665791991		[learning rate: 0.0067797]
	Learning Rate: 0.0067797
	LOSS [training: 0.5911369665791991 | validation: 0.5003454179826201]
	TIME [epoch: 9.25 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7321403607724921		[learning rate: 0.0067551]
	Learning Rate: 0.0067551
	LOSS [training: 0.7321403607724921 | validation: 0.41816590342691]
	TIME [epoch: 9.23 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6896956736990434		[learning rate: 0.0067306]
	Learning Rate: 0.00673058
	LOSS [training: 0.6896956736990434 | validation: 0.5842046261399291]
	TIME [epoch: 9.22 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6229574408643178		[learning rate: 0.0067062]
	Learning Rate: 0.00670616
	LOSS [training: 0.6229574408643178 | validation: 0.9794198312275186]
	TIME [epoch: 9.23 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6132327311243754		[learning rate: 0.0066818]
	Learning Rate: 0.00668182
	LOSS [training: 0.6132327311243754 | validation: 0.36224434135504074]
	TIME [epoch: 9.23 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r5_20240219_234257/states/model_tr_study204_211.pth
	Model improved!!!
EPOCH 212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6073824205226799		[learning rate: 0.0066576]
	Learning Rate: 0.00665757
	LOSS [training: 0.6073824205226799 | validation: 0.5726882713465221]
	TIME [epoch: 9.24 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7011729601665269		[learning rate: 0.0066334]
	Learning Rate: 0.00663341
	LOSS [training: 0.7011729601665269 | validation: 0.7800259479497671]
	TIME [epoch: 9.23 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6096086779131279		[learning rate: 0.0066093]
	Learning Rate: 0.00660934
	LOSS [training: 0.6096086779131279 | validation: 0.357918002253854]
	TIME [epoch: 9.23 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r5_20240219_234257/states/model_tr_study204_214.pth
	Model improved!!!
EPOCH 215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6440018857761336		[learning rate: 0.0065854]
	Learning Rate: 0.00658535
	LOSS [training: 0.6440018857761336 | validation: 0.8403475125914877]
	TIME [epoch: 9.23 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5448418171359758		[learning rate: 0.0065615]
	Learning Rate: 0.00656145
	LOSS [training: 0.5448418171359758 | validation: 0.7865414863202025]
	TIME [epoch: 9.24 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6152363058947942		[learning rate: 0.0065376]
	Learning Rate: 0.00653764
	LOSS [training: 0.6152363058947942 | validation: 1.0411911091573813]
	TIME [epoch: 9.22 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7027691566885188		[learning rate: 0.0065139]
	Learning Rate: 0.00651392
	LOSS [training: 0.7027691566885188 | validation: 0.7217438652672774]
	TIME [epoch: 9.22 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7547903622686848		[learning rate: 0.0064903]
	Learning Rate: 0.00649028
	LOSS [training: 0.7547903622686848 | validation: 0.47992522858141107]
	TIME [epoch: 9.22 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7535198289020438		[learning rate: 0.0064667]
	Learning Rate: 0.00646672
	LOSS [training: 0.7535198289020438 | validation: 0.4374283761547012]
	TIME [epoch: 9.23 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6215088717900681		[learning rate: 0.0064433]
	Learning Rate: 0.00644325
	LOSS [training: 0.6215088717900681 | validation: 0.6914454872414217]
	TIME [epoch: 9.25 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6559783968423558		[learning rate: 0.0064199]
	Learning Rate: 0.00641987
	LOSS [training: 0.6559783968423558 | validation: 0.36207453763124664]
	TIME [epoch: 9.22 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5999266417790358		[learning rate: 0.0063966]
	Learning Rate: 0.00639657
	LOSS [training: 0.5999266417790358 | validation: 0.7514488464747412]
	TIME [epoch: 9.21 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5810268189414918		[learning rate: 0.0063734]
	Learning Rate: 0.00637336
	LOSS [training: 0.5810268189414918 | validation: 0.3336006984159642]
	TIME [epoch: 9.23 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r5_20240219_234257/states/model_tr_study204_224.pth
	Model improved!!!
EPOCH 225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.636578850868597		[learning rate: 0.0063502]
	Learning Rate: 0.00635023
	LOSS [training: 0.636578850868597 | validation: 0.5808392338152454]
	TIME [epoch: 9.23 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7024363487059466		[learning rate: 0.0063272]
	Learning Rate: 0.00632718
	LOSS [training: 0.7024363487059466 | validation: 0.4414628265133923]
	TIME [epoch: 9.22 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6274735917880874		[learning rate: 0.0063042]
	Learning Rate: 0.00630422
	LOSS [training: 0.6274735917880874 | validation: 0.41131006800175185]
	TIME [epoch: 9.21 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5920118009445527		[learning rate: 0.0062813]
	Learning Rate: 0.00628134
	LOSS [training: 0.5920118009445527 | validation: 0.7518442919763014]
	TIME [epoch: 9.21 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6315006566232004		[learning rate: 0.0062585]
	Learning Rate: 0.00625855
	LOSS [training: 0.6315006566232004 | validation: 1.4765681325748126]
	TIME [epoch: 9.22 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9354208078271702		[learning rate: 0.0062358]
	Learning Rate: 0.00623584
	LOSS [training: 0.9354208078271702 | validation: 0.6410197554726997]
	TIME [epoch: 9.23 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5602850628435179		[learning rate: 0.0062132]
	Learning Rate: 0.00621321
	LOSS [training: 0.5602850628435179 | validation: 0.36844872260360784]
	TIME [epoch: 9.21 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6154658179096593		[learning rate: 0.0061907]
	Learning Rate: 0.00619066
	LOSS [training: 0.6154658179096593 | validation: 0.2919064713758185]
	TIME [epoch: 9.22 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r5_20240219_234257/states/model_tr_study204_232.pth
	Model improved!!!
EPOCH 233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5526371494197861		[learning rate: 0.0061682]
	Learning Rate: 0.00616819
	LOSS [training: 0.5526371494197861 | validation: 0.3713207640116708]
	TIME [epoch: 9.22 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7884314679188694		[learning rate: 0.0061458]
	Learning Rate: 0.00614581
	LOSS [training: 0.7884314679188694 | validation: 0.4846905633767049]
	TIME [epoch: 9.23 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5289543342145874		[learning rate: 0.0061235]
	Learning Rate: 0.0061235
	LOSS [training: 0.5289543342145874 | validation: 0.48339548931533294]
	TIME [epoch: 9.21 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5557824397424409		[learning rate: 0.0061013]
	Learning Rate: 0.00610128
	LOSS [training: 0.5557824397424409 | validation: 0.5719841191875185]
	TIME [epoch: 9.2 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6824165994818981		[learning rate: 0.0060791]
	Learning Rate: 0.00607914
	LOSS [training: 0.6824165994818981 | validation: 0.5988998580311249]
	TIME [epoch: 9.2 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.654953665681688		[learning rate: 0.0060571]
	Learning Rate: 0.00605708
	LOSS [training: 0.654953665681688 | validation: 0.5743755729058153]
	TIME [epoch: 9.22 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6597769173833754		[learning rate: 0.0060351]
	Learning Rate: 0.0060351
	LOSS [training: 0.6597769173833754 | validation: 0.323937538954511]
	TIME [epoch: 9.21 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48193978527293585		[learning rate: 0.0060132]
	Learning Rate: 0.00601319
	LOSS [training: 0.48193978527293585 | validation: 0.44147810520269926]
	TIME [epoch: 9.21 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5389004610310033		[learning rate: 0.0059914]
	Learning Rate: 0.00599137
	LOSS [training: 0.5389004610310033 | validation: 0.38901573721183114]
	TIME [epoch: 9.21 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.54229832434516		[learning rate: 0.0059696]
	Learning Rate: 0.00596963
	LOSS [training: 0.54229832434516 | validation: 0.26626240038219556]
	TIME [epoch: 9.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r5_20240219_234257/states/model_tr_study204_242.pth
	Model improved!!!
EPOCH 243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4733214637882094		[learning rate: 0.005948]
	Learning Rate: 0.00594797
	LOSS [training: 0.4733214637882094 | validation: 0.5456501912382882]
	TIME [epoch: 9.23 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5023267674152889		[learning rate: 0.0059264]
	Learning Rate: 0.00592638
	LOSS [training: 0.5023267674152889 | validation: 0.41253877533508243]
	TIME [epoch: 9.22 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0354157760957414		[learning rate: 0.0059049]
	Learning Rate: 0.00590487
	LOSS [training: 1.0354157760957414 | validation: 2.139179302826332]
	TIME [epoch: 9.21 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8903685815449588		[learning rate: 0.0058834]
	Learning Rate: 0.00588344
	LOSS [training: 0.8903685815449588 | validation: 0.3468009079680785]
	TIME [epoch: 9.21 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6386377420445701		[learning rate: 0.0058621]
	Learning Rate: 0.00586209
	LOSS [training: 0.6386377420445701 | validation: 0.41170356141999775]
	TIME [epoch: 9.23 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5801396095382199		[learning rate: 0.0058408]
	Learning Rate: 0.00584082
	LOSS [training: 0.5801396095382199 | validation: 0.5884849832857942]
	TIME [epoch: 9.23 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6541658624640139		[learning rate: 0.0058196]
	Learning Rate: 0.00581962
	LOSS [training: 0.6541658624640139 | validation: 0.3181320327454234]
	TIME [epoch: 9.2 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4775942240709822		[learning rate: 0.0057985]
	Learning Rate: 0.0057985
	LOSS [training: 0.4775942240709822 | validation: 0.515459065343465]
	TIME [epoch: 9.21 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45724717060934045		[learning rate: 0.0057775]
	Learning Rate: 0.00577746
	LOSS [training: 0.45724717060934045 | validation: 0.24160301584556398]
	TIME [epoch: 9.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r5_20240219_234257/states/model_tr_study204_251.pth
	Model improved!!!
EPOCH 252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5994914934429452		[learning rate: 0.0057565]
	Learning Rate: 0.00575649
	LOSS [training: 0.5994914934429452 | validation: 0.5950080278358885]
	TIME [epoch: 9.23 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.547459475518633		[learning rate: 0.0057356]
	Learning Rate: 0.0057356
	LOSS [training: 0.547459475518633 | validation: 0.3728612339010856]
	TIME [epoch: 9.2 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.557299416300378		[learning rate: 0.0057148]
	Learning Rate: 0.00571479
	LOSS [training: 0.557299416300378 | validation: 0.27553854882328227]
	TIME [epoch: 9.2 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.535556311036796		[learning rate: 0.005694]
	Learning Rate: 0.00569405
	LOSS [training: 0.535556311036796 | validation: 0.2533201576421478]
	TIME [epoch: 9.2 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.459084499785806		[learning rate: 0.0056734]
	Learning Rate: 0.00567338
	LOSS [training: 0.459084499785806 | validation: 0.4230689127384532]
	TIME [epoch: 9.21 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5226568825337694		[learning rate: 0.0056528]
	Learning Rate: 0.00565279
	LOSS [training: 0.5226568825337694 | validation: 0.40354099492739204]
	TIME [epoch: 9.21 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5852505837723124		[learning rate: 0.0056323]
	Learning Rate: 0.00563228
	LOSS [training: 0.5852505837723124 | validation: 0.31334989981090655]
	TIME [epoch: 9.2 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.500880906314161		[learning rate: 0.0056118]
	Learning Rate: 0.00561184
	LOSS [training: 0.500880906314161 | validation: 0.2945607712810693]
	TIME [epoch: 9.21 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4794218289635199		[learning rate: 0.0055915]
	Learning Rate: 0.00559147
	LOSS [training: 0.4794218289635199 | validation: 0.5224415379125082]
	TIME [epoch: 9.21 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4824466729221194		[learning rate: 0.0055712]
	Learning Rate: 0.00557118
	LOSS [training: 0.4824466729221194 | validation: 0.5107165310793039]
	TIME [epoch: 9.22 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48287110830248386		[learning rate: 0.005551]
	Learning Rate: 0.00555096
	LOSS [training: 0.48287110830248386 | validation: 0.32448114042368614]
	TIME [epoch: 9.2 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5329038196453931		[learning rate: 0.0055308]
	Learning Rate: 0.00553082
	LOSS [training: 0.5329038196453931 | validation: 0.4259630027366207]
	TIME [epoch: 9.2 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5157041416588272		[learning rate: 0.0055107]
	Learning Rate: 0.00551075
	LOSS [training: 0.5157041416588272 | validation: 0.6801064922143714]
	TIME [epoch: 9.19 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47742015911925434		[learning rate: 0.0054907]
	Learning Rate: 0.00549075
	LOSS [training: 0.47742015911925434 | validation: 0.2789810917195952]
	TIME [epoch: 9.2 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5465512682309454		[learning rate: 0.0054708]
	Learning Rate: 0.00547082
	LOSS [training: 0.5465512682309454 | validation: 0.3944483576659857]
	TIME [epoch: 9.22 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6666266738145483		[learning rate: 0.005451]
	Learning Rate: 0.00545097
	LOSS [training: 0.6666266738145483 | validation: 0.49197987595803827]
	TIME [epoch: 9.19 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6395828732285862		[learning rate: 0.0054312]
	Learning Rate: 0.00543119
	LOSS [training: 0.6395828732285862 | validation: 0.394979890067368]
	TIME [epoch: 9.19 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4316299518915492		[learning rate: 0.0054115]
	Learning Rate: 0.00541148
	LOSS [training: 0.4316299518915492 | validation: 0.4435261561674879]
	TIME [epoch: 9.19 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4953140293213025		[learning rate: 0.0053918]
	Learning Rate: 0.00539184
	LOSS [training: 0.4953140293213025 | validation: 0.6339585967310775]
	TIME [epoch: 9.22 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5052062478270196		[learning rate: 0.0053723]
	Learning Rate: 0.00537227
	LOSS [training: 0.5052062478270196 | validation: 0.39136861366021947]
	TIME [epoch: 9.21 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47868191344208844		[learning rate: 0.0053528]
	Learning Rate: 0.00535277
	LOSS [training: 0.47868191344208844 | validation: 0.5679890240912614]
	TIME [epoch: 9.2 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4381096657074742		[learning rate: 0.0053333]
	Learning Rate: 0.00533335
	LOSS [training: 0.4381096657074742 | validation: 0.23619728495712305]
	TIME [epoch: 9.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r5_20240219_234257/states/model_tr_study204_273.pth
	Model improved!!!
EPOCH 274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43683394852505125		[learning rate: 0.005314]
	Learning Rate: 0.00531399
	LOSS [training: 0.43683394852505125 | validation: 0.3604360394813254]
	TIME [epoch: 9.23 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6539243633401464		[learning rate: 0.0052947]
	Learning Rate: 0.00529471
	LOSS [training: 0.6539243633401464 | validation: 0.44113834232053933]
	TIME [epoch: 9.24 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4457146287790857		[learning rate: 0.0052755]
	Learning Rate: 0.00527549
	LOSS [training: 0.4457146287790857 | validation: 0.2882056791463323]
	TIME [epoch: 9.23 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48439966921487604		[learning rate: 0.0052563]
	Learning Rate: 0.00525635
	LOSS [training: 0.48439966921487604 | validation: 0.20856529276158506]
	TIME [epoch: 9.22 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r5_20240219_234257/states/model_tr_study204_277.pth
	Model improved!!!
EPOCH 278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.542073698993068		[learning rate: 0.0052373]
	Learning Rate: 0.00523727
	LOSS [training: 0.542073698993068 | validation: 0.4882756921208502]
	TIME [epoch: 9.22 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5042848074440831		[learning rate: 0.0052183]
	Learning Rate: 0.00521827
	LOSS [training: 0.5042848074440831 | validation: 0.2816467956676467]
	TIME [epoch: 9.25 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3564366967458321		[learning rate: 0.0051993]
	Learning Rate: 0.00519933
	LOSS [training: 0.3564366967458321 | validation: 0.37280994899154024]
	TIME [epoch: 9.22 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7058907100397387		[learning rate: 0.0051805]
	Learning Rate: 0.00518046
	LOSS [training: 0.7058907100397387 | validation: 0.8294503384275643]
	TIME [epoch: 9.21 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5233065326423026		[learning rate: 0.0051617]
	Learning Rate: 0.00516166
	LOSS [training: 0.5233065326423026 | validation: 0.2201463116834812]
	TIME [epoch: 9.22 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6547285128567933		[learning rate: 0.0051429]
	Learning Rate: 0.00514293
	LOSS [training: 0.6547285128567933 | validation: 0.24390396748479345]
	TIME [epoch: 9.22 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35250094093106454		[learning rate: 0.0051243]
	Learning Rate: 0.00512426
	LOSS [training: 0.35250094093106454 | validation: 0.268055468459171]
	TIME [epoch: 9.25 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.433646375677539		[learning rate: 0.0051057]
	Learning Rate: 0.00510567
	LOSS [training: 0.433646375677539 | validation: 0.5026156294996201]
	TIME [epoch: 9.23 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6136690935062228		[learning rate: 0.0050871]
	Learning Rate: 0.00508714
	LOSS [training: 0.6136690935062228 | validation: 0.7799006729296917]
	TIME [epoch: 9.23 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38856173047684095		[learning rate: 0.0050687]
	Learning Rate: 0.00506868
	LOSS [training: 0.38856173047684095 | validation: 0.3514969799123888]
	TIME [epoch: 9.22 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6322028349365467		[learning rate: 0.0050503]
	Learning Rate: 0.00505028
	LOSS [training: 0.6322028349365467 | validation: 0.5353162472315689]
	TIME [epoch: 9.22 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45147708028067013		[learning rate: 0.005032]
	Learning Rate: 0.00503196
	LOSS [training: 0.45147708028067013 | validation: 0.6001571450148819]
	TIME [epoch: 9.24 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44384100274100424		[learning rate: 0.0050137]
	Learning Rate: 0.00501369
	LOSS [training: 0.44384100274100424 | validation: 0.33400481203514376]
	TIME [epoch: 9.22 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4458571048450108		[learning rate: 0.0049955]
	Learning Rate: 0.0049955
	LOSS [training: 0.4458571048450108 | validation: 0.2638477504861]
	TIME [epoch: 9.22 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4703784056374767		[learning rate: 0.0049774]
	Learning Rate: 0.00497737
	LOSS [training: 0.4703784056374767 | validation: 0.19958634202025496]
	TIME [epoch: 9.22 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r5_20240219_234257/states/model_tr_study204_292.pth
	Model improved!!!
EPOCH 293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6427725424774144		[learning rate: 0.0049593]
	Learning Rate: 0.00495931
	LOSS [training: 0.6427725424774144 | validation: 1.096973739416091]
	TIME [epoch: 9.25 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4987232598873188		[learning rate: 0.0049413]
	Learning Rate: 0.00494131
	LOSS [training: 0.4987232598873188 | validation: 0.43465072168241703]
	TIME [epoch: 9.22 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4715921344371684		[learning rate: 0.0049234]
	Learning Rate: 0.00492338
	LOSS [training: 0.4715921344371684 | validation: 0.5118326171441564]
	TIME [epoch: 9.22 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37907234216294683		[learning rate: 0.0049055]
	Learning Rate: 0.00490551
	LOSS [training: 0.37907234216294683 | validation: 0.28653413702745745]
	TIME [epoch: 9.22 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38454195305968397		[learning rate: 0.0048877]
	Learning Rate: 0.00488771
	LOSS [training: 0.38454195305968397 | validation: 0.2964976009140028]
	TIME [epoch: 9.23 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5132776136875563		[learning rate: 0.00487]
	Learning Rate: 0.00486997
	LOSS [training: 0.5132776136875563 | validation: 0.36679525310640665]
	TIME [epoch: 9.24 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49355120804234376		[learning rate: 0.0048523]
	Learning Rate: 0.0048523
	LOSS [training: 0.49355120804234376 | validation: 0.29491614281411527]
	TIME [epoch: 9.23 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6207633117908441		[learning rate: 0.0048347]
	Learning Rate: 0.00483469
	LOSS [training: 0.6207633117908441 | validation: 0.45342941612543675]
	TIME [epoch: 9.23 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49167806409290354		[learning rate: 0.0048171]
	Learning Rate: 0.00481714
	LOSS [training: 0.49167806409290354 | validation: 0.33271240193358]
	TIME [epoch: 9.21 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3701323993440155		[learning rate: 0.0047997]
	Learning Rate: 0.00479966
	LOSS [training: 0.3701323993440155 | validation: 0.2618822738154355]
	TIME [epoch: 9.24 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44245210178506955		[learning rate: 0.0047822]
	Learning Rate: 0.00478224
	LOSS [training: 0.44245210178506955 | validation: 0.5951246825068728]
	TIME [epoch: 9.23 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4311630234819589		[learning rate: 0.0047649]
	Learning Rate: 0.00476489
	LOSS [training: 0.4311630234819589 | validation: 0.2859650965836529]
	TIME [epoch: 9.22 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4156463483512972		[learning rate: 0.0047476]
	Learning Rate: 0.00474759
	LOSS [training: 0.4156463483512972 | validation: 0.40873555585818516]
	TIME [epoch: 9.22 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4836614842446626		[learning rate: 0.0047304]
	Learning Rate: 0.00473037
	LOSS [training: 0.4836614842446626 | validation: 0.2914966454761392]
	TIME [epoch: 9.23 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36996733647054564		[learning rate: 0.0047132]
	Learning Rate: 0.0047132
	LOSS [training: 0.36996733647054564 | validation: 0.5202779640367493]
	TIME [epoch: 9.24 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4199857185214967		[learning rate: 0.0046961]
	Learning Rate: 0.00469609
	LOSS [training: 0.4199857185214967 | validation: 0.302456634905736]
	TIME [epoch: 9.22 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43463310496549495		[learning rate: 0.0046791]
	Learning Rate: 0.00467905
	LOSS [training: 0.43463310496549495 | validation: 0.46167836951512775]
	TIME [epoch: 9.22 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4365585410695318		[learning rate: 0.0046621]
	Learning Rate: 0.00466207
	LOSS [training: 0.4365585410695318 | validation: 0.39452842534169036]
	TIME [epoch: 9.22 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33619157200509625		[learning rate: 0.0046452]
	Learning Rate: 0.00464515
	LOSS [training: 0.33619157200509625 | validation: 0.5052663878430044]
	TIME [epoch: 9.26 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4391147555714709		[learning rate: 0.0046283]
	Learning Rate: 0.0046283
	LOSS [training: 0.4391147555714709 | validation: 0.26094053333091416]
	TIME [epoch: 9.22 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45918359022370164		[learning rate: 0.0046115]
	Learning Rate: 0.0046115
	LOSS [training: 0.45918359022370164 | validation: 0.8536358946887119]
	TIME [epoch: 9.21 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5101561169411412		[learning rate: 0.0045948]
	Learning Rate: 0.00459476
	LOSS [training: 0.5101561169411412 | validation: 0.3381803763612058]
	TIME [epoch: 9.22 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34544843454108964		[learning rate: 0.0045781]
	Learning Rate: 0.00457809
	LOSS [training: 0.34544843454108964 | validation: 0.3451110915647683]
	TIME [epoch: 9.23 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38361953906448387		[learning rate: 0.0045615]
	Learning Rate: 0.00456148
	LOSS [training: 0.38361953906448387 | validation: 0.49412079385902263]
	TIME [epoch: 9.23 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.373834125435649		[learning rate: 0.0045449]
	Learning Rate: 0.00454492
	LOSS [training: 0.373834125435649 | validation: 0.4876526759586405]
	TIME [epoch: 9.21 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42553304338895215		[learning rate: 0.0045284]
	Learning Rate: 0.00452843
	LOSS [training: 0.42553304338895215 | validation: 0.2767025528645226]
	TIME [epoch: 9.22 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4688117543034827		[learning rate: 0.004512]
	Learning Rate: 0.00451199
	LOSS [training: 0.4688117543034827 | validation: 0.20430883161035274]
	TIME [epoch: 9.22 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32250508941937095		[learning rate: 0.0044956]
	Learning Rate: 0.00449562
	LOSS [training: 0.32250508941937095 | validation: 0.24984546478353234]
	TIME [epoch: 9.24 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40902390384766996		[learning rate: 0.0044793]
	Learning Rate: 0.0044793
	LOSS [training: 0.40902390384766996 | validation: 0.2290586926666798]
	TIME [epoch: 9.22 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49117825144325716		[learning rate: 0.004463]
	Learning Rate: 0.00446305
	LOSS [training: 0.49117825144325716 | validation: 0.27776154509878365]
	TIME [epoch: 9.22 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3483487123343455		[learning rate: 0.0044469]
	Learning Rate: 0.00444685
	LOSS [training: 0.3483487123343455 | validation: 0.34539396248356324]
	TIME [epoch: 9.23 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5466255522154351		[learning rate: 0.0044307]
	Learning Rate: 0.00443071
	LOSS [training: 0.5466255522154351 | validation: 0.31514813766592265]
	TIME [epoch: 9.24 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3807675488928723		[learning rate: 0.0044146]
	Learning Rate: 0.00441463
	LOSS [training: 0.3807675488928723 | validation: 0.24300245963540468]
	TIME [epoch: 9.24 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35945272413632456		[learning rate: 0.0043986]
	Learning Rate: 0.00439861
	LOSS [training: 0.35945272413632456 | validation: 0.3668422784090571]
	TIME [epoch: 9.23 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38558411740945386		[learning rate: 0.0043827]
	Learning Rate: 0.00438265
	LOSS [training: 0.38558411740945386 | validation: 0.29187645024087105]
	TIME [epoch: 9.21 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40034427787903804		[learning rate: 0.0043667]
	Learning Rate: 0.00436675
	LOSS [training: 0.40034427787903804 | validation: 0.37455654327878407]
	TIME [epoch: 9.21 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8365113620359053		[learning rate: 0.0043509]
	Learning Rate: 0.0043509
	LOSS [training: 0.8365113620359053 | validation: 0.27093955404327164]
	TIME [epoch: 9.24 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42268103524733097		[learning rate: 0.0043351]
	Learning Rate: 0.00433511
	LOSS [training: 0.42268103524733097 | validation: 0.42662523831018784]
	TIME [epoch: 9.22 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4826042149513186		[learning rate: 0.0043194]
	Learning Rate: 0.00431938
	LOSS [training: 0.4826042149513186 | validation: 0.3962026623759264]
	TIME [epoch: 9.22 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4281313860169802		[learning rate: 0.0043037]
	Learning Rate: 0.0043037
	LOSS [training: 0.4281313860169802 | validation: 0.27320890473699155]
	TIME [epoch: 9.21 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48302437979525614		[learning rate: 0.0042881]
	Learning Rate: 0.00428808
	LOSS [training: 0.48302437979525614 | validation: 0.33957139078744886]
	TIME [epoch: 9.23 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34976082306321277		[learning rate: 0.0042725]
	Learning Rate: 0.00427252
	LOSS [training: 0.34976082306321277 | validation: 0.32205347374108434]
	TIME [epoch: 9.23 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6324374369527666		[learning rate: 0.004257]
	Learning Rate: 0.00425702
	LOSS [training: 0.6324374369527666 | validation: 0.6130120907962582]
	TIME [epoch: 9.21 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47977845359216936		[learning rate: 0.0042416]
	Learning Rate: 0.00424157
	LOSS [training: 0.47977845359216936 | validation: 0.43761164475574843]
	TIME [epoch: 9.22 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33205027370154344		[learning rate: 0.0042262]
	Learning Rate: 0.00422617
	LOSS [training: 0.33205027370154344 | validation: 0.2342757558291817]
	TIME [epoch: 9.23 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3956472811460535		[learning rate: 0.0042108]
	Learning Rate: 0.00421084
	LOSS [training: 0.3956472811460535 | validation: 0.3356672444919675]
	TIME [epoch: 9.25 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3077178177619607		[learning rate: 0.0041956]
	Learning Rate: 0.00419556
	LOSS [training: 0.3077178177619607 | validation: 0.49134495004695516]
	TIME [epoch: 9.22 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3819903665629889		[learning rate: 0.0041803]
	Learning Rate: 0.00418033
	LOSS [training: 0.3819903665629889 | validation: 0.15642830265150331]
	TIME [epoch: 9.21 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r5_20240219_234257/states/model_tr_study204_340.pth
	Model improved!!!
EPOCH 341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33945892463726446		[learning rate: 0.0041652]
	Learning Rate: 0.00416516
	LOSS [training: 0.33945892463726446 | validation: 0.2755344436485714]
	TIME [epoch: 9.24 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3771469668467686		[learning rate: 0.00415]
	Learning Rate: 0.00415004
	LOSS [training: 0.3771469668467686 | validation: 0.22215307242708854]
	TIME [epoch: 9.24 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3399690935663922		[learning rate: 0.004135]
	Learning Rate: 0.00413498
	LOSS [training: 0.3399690935663922 | validation: 0.20323063934444874]
	TIME [epoch: 9.23 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4119314623163765		[learning rate: 0.00412]
	Learning Rate: 0.00411998
	LOSS [training: 0.4119314623163765 | validation: 0.4929721924362187]
	TIME [epoch: 9.22 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41085311193851426		[learning rate: 0.004105]
	Learning Rate: 0.00410502
	LOSS [training: 0.41085311193851426 | validation: 0.19670594580771084]
	TIME [epoch: 9.23 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39045433239501864		[learning rate: 0.0040901]
	Learning Rate: 0.00409013
	LOSS [training: 0.39045433239501864 | validation: 0.3886134586604715]
	TIME [epoch: 9.2 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3749221664794602		[learning rate: 0.0040753]
	Learning Rate: 0.00407528
	LOSS [training: 0.3749221664794602 | validation: 0.1446650946057758]
	TIME [epoch: 9.24 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r5_20240219_234257/states/model_tr_study204_347.pth
	Model improved!!!
EPOCH 348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3041998794386903		[learning rate: 0.0040605]
	Learning Rate: 0.00406049
	LOSS [training: 0.3041998794386903 | validation: 0.4109796758533405]
	TIME [epoch: 9.21 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37388195256400436		[learning rate: 0.0040458]
	Learning Rate: 0.00404576
	LOSS [training: 0.37388195256400436 | validation: 0.37624896521986584]
	TIME [epoch: 9.23 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40031957105687377		[learning rate: 0.0040311]
	Learning Rate: 0.00403108
	LOSS [training: 0.40031957105687377 | validation: 0.3162474065035219]
	TIME [epoch: 9.22 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31057793662689454		[learning rate: 0.0040164]
	Learning Rate: 0.00401645
	LOSS [training: 0.31057793662689454 | validation: 0.3021019278594246]
	TIME [epoch: 9.23 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3186729982476359		[learning rate: 0.0040019]
	Learning Rate: 0.00400187
	LOSS [training: 0.3186729982476359 | validation: 0.35411162495095977]
	TIME [epoch: 9.23 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7180384466601873		[learning rate: 0.0039873]
	Learning Rate: 0.00398735
	LOSS [training: 0.7180384466601873 | validation: 0.2519309937043486]
	TIME [epoch: 9.22 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33736946943506096		[learning rate: 0.0039729]
	Learning Rate: 0.00397288
	LOSS [training: 0.33736946943506096 | validation: 0.16726671141544389]
	TIME [epoch: 9.22 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4330446540598161		[learning rate: 0.0039585]
	Learning Rate: 0.00395846
	LOSS [training: 0.4330446540598161 | validation: 0.18232091998852462]
	TIME [epoch: 9.22 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3899811847418897		[learning rate: 0.0039441]
	Learning Rate: 0.00394409
	LOSS [training: 0.3899811847418897 | validation: 0.33885972897177297]
	TIME [epoch: 9.23 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3502037222347916		[learning rate: 0.0039298]
	Learning Rate: 0.00392978
	LOSS [training: 0.3502037222347916 | validation: 0.41384872895994157]
	TIME [epoch: 9.23 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2896121903854941		[learning rate: 0.0039155]
	Learning Rate: 0.00391552
	LOSS [training: 0.2896121903854941 | validation: 0.2936409288016272]
	TIME [epoch: 9.21 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44766482349253484		[learning rate: 0.0039013]
	Learning Rate: 0.00390131
	LOSS [training: 0.44766482349253484 | validation: 0.3833147802195862]
	TIME [epoch: 9.21 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3149618715267952		[learning rate: 0.0038872]
	Learning Rate: 0.00388715
	LOSS [training: 0.3149618715267952 | validation: 0.5798387049253151]
	TIME [epoch: 9.22 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3869208669363307		[learning rate: 0.003873]
	Learning Rate: 0.00387305
	LOSS [training: 0.3869208669363307 | validation: 0.5603276232501847]
	TIME [epoch: 9.23 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3646006534600462		[learning rate: 0.003859]
	Learning Rate: 0.00385899
	LOSS [training: 0.3646006534600462 | validation: 0.21928416671085546]
	TIME [epoch: 9.22 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.332462979120565		[learning rate: 0.003845]
	Learning Rate: 0.00384499
	LOSS [training: 0.332462979120565 | validation: 0.2694017823258719]
	TIME [epoch: 9.22 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33609292364000815		[learning rate: 0.003831]
	Learning Rate: 0.00383103
	LOSS [training: 0.33609292364000815 | validation: 0.15473982166804995]
	TIME [epoch: 9.22 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42867390230736735		[learning rate: 0.0038171]
	Learning Rate: 0.00381713
	LOSS [training: 0.42867390230736735 | validation: 0.24128963500246575]
	TIME [epoch: 9.25 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49254950410230364		[learning rate: 0.0038033]
	Learning Rate: 0.00380328
	LOSS [training: 0.49254950410230364 | validation: 0.5812550400983038]
	TIME [epoch: 9.23 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.476298556221476		[learning rate: 0.0037895]
	Learning Rate: 0.00378947
	LOSS [training: 0.476298556221476 | validation: 0.19742324941288417]
	TIME [epoch: 9.22 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2802879870963116		[learning rate: 0.0037757]
	Learning Rate: 0.00377572
	LOSS [training: 0.2802879870963116 | validation: 0.2986708956211153]
	TIME [epoch: 9.21 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39418023577999184		[learning rate: 0.003762]
	Learning Rate: 0.00376202
	LOSS [training: 0.39418023577999184 | validation: 0.5181206485822368]
	TIME [epoch: 9.23 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3555083404399562		[learning rate: 0.0037484]
	Learning Rate: 0.00374837
	LOSS [training: 0.3555083404399562 | validation: 0.9477951204494817]
	TIME [epoch: 9.25 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43731940610496867		[learning rate: 0.0037348]
	Learning Rate: 0.00373476
	LOSS [training: 0.43731940610496867 | validation: 0.25166090526992047]
	TIME [epoch: 9.22 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34263514552218255		[learning rate: 0.0037212]
	Learning Rate: 0.00372121
	LOSS [training: 0.34263514552218255 | validation: 0.20176781122115728]
	TIME [epoch: 9.22 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3736824783721116		[learning rate: 0.0037077]
	Learning Rate: 0.00370771
	LOSS [training: 0.3736824783721116 | validation: 0.1357256937191933]
	TIME [epoch: 9.21 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r5_20240219_234257/states/model_tr_study204_373.pth
	Model improved!!!
EPOCH 374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35213769490574653		[learning rate: 0.0036943]
	Learning Rate: 0.00369425
	LOSS [training: 0.35213769490574653 | validation: 0.12145812805668846]
	TIME [epoch: 9.25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r5_20240219_234257/states/model_tr_study204_374.pth
	Model improved!!!
EPOCH 375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30069321110356056		[learning rate: 0.0036808]
	Learning Rate: 0.00368084
	LOSS [training: 0.30069321110356056 | validation: 0.3292174198328997]
	TIME [epoch: 9.2 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3863909432831997		[learning rate: 0.0036675]
	Learning Rate: 0.00366749
	LOSS [training: 0.3863909432831997 | validation: 0.184533185513441]
	TIME [epoch: 9.2 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3228658623386924		[learning rate: 0.0036542]
	Learning Rate: 0.00365418
	LOSS [training: 0.3228658623386924 | validation: 0.2578615328209042]
	TIME [epoch: 9.19 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38062060212902493		[learning rate: 0.0036409]
	Learning Rate: 0.00364092
	LOSS [training: 0.38062060212902493 | validation: 0.1663760562056078]
	TIME [epoch: 9.21 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29955249202257517		[learning rate: 0.0036277]
	Learning Rate: 0.0036277
	LOSS [training: 0.29955249202257517 | validation: 0.3798465279576855]
	TIME [epoch: 9.21 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32511338368790194		[learning rate: 0.0036145]
	Learning Rate: 0.00361454
	LOSS [training: 0.32511338368790194 | validation: 0.13321400136461356]
	TIME [epoch: 9.19 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43524448268432814		[learning rate: 0.0036014]
	Learning Rate: 0.00360142
	LOSS [training: 0.43524448268432814 | validation: 0.2531616521298299]
	TIME [epoch: 9.19 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38476083600991917		[learning rate: 0.0035883]
	Learning Rate: 0.00358835
	LOSS [training: 0.38476083600991917 | validation: 0.2127761931022081]
	TIME [epoch: 9.2 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5044722105311557		[learning rate: 0.0035753]
	Learning Rate: 0.00357533
	LOSS [training: 0.5044722105311557 | validation: 0.6582467443260805]
	TIME [epoch: 9.22 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3393081648706713		[learning rate: 0.0035624]
	Learning Rate: 0.00356235
	LOSS [training: 0.3393081648706713 | validation: 0.1802094599378091]
	TIME [epoch: 9.2 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3211973763906336		[learning rate: 0.0035494]
	Learning Rate: 0.00354942
	LOSS [training: 0.3211973763906336 | validation: 0.18506552627488349]
	TIME [epoch: 9.19 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3088946193049655		[learning rate: 0.0035365]
	Learning Rate: 0.00353654
	LOSS [training: 0.3088946193049655 | validation: 0.36480578207113834]
	TIME [epoch: 9.2 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3453646861850663		[learning rate: 0.0035237]
	Learning Rate: 0.00352371
	LOSS [training: 0.3453646861850663 | validation: 0.4131449723896688]
	TIME [epoch: 9.21 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3701412112370223		[learning rate: 0.0035109]
	Learning Rate: 0.00351092
	LOSS [training: 0.3701412112370223 | validation: 0.17801350311579361]
	TIME [epoch: 9.21 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.300140844694728		[learning rate: 0.0034982]
	Learning Rate: 0.00349818
	LOSS [training: 0.300140844694728 | validation: 0.1899320069709833]
	TIME [epoch: 9.21 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9226730615390301		[learning rate: 0.0034855]
	Learning Rate: 0.00348548
	LOSS [training: 0.9226730615390301 | validation: 0.3003130199513897]
	TIME [epoch: 9.2 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2984754611967362		[learning rate: 0.0034728]
	Learning Rate: 0.00347284
	LOSS [training: 0.2984754611967362 | validation: 0.20341547411702315]
	TIME [epoch: 9.2 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2666784905305967		[learning rate: 0.0034602]
	Learning Rate: 0.00346023
	LOSS [training: 0.2666784905305967 | validation: 0.27317552318627625]
	TIME [epoch: 9.22 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27670058824976074		[learning rate: 0.0034477]
	Learning Rate: 0.00344767
	LOSS [training: 0.27670058824976074 | validation: 0.14363825417398435]
	TIME [epoch: 9.19 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.296300000129054		[learning rate: 0.0034352]
	Learning Rate: 0.00343516
	LOSS [training: 0.296300000129054 | validation: 0.40327709173964904]
	TIME [epoch: 9.19 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30681311053086463		[learning rate: 0.0034227]
	Learning Rate: 0.0034227
	LOSS [training: 0.30681311053086463 | validation: 0.13531551176622983]
	TIME [epoch: 9.19 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3217507037063137		[learning rate: 0.0034103]
	Learning Rate: 0.00341028
	LOSS [training: 0.3217507037063137 | validation: 0.2722925377261799]
	TIME [epoch: 9.2 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3326194334299803		[learning rate: 0.0033979]
	Learning Rate: 0.0033979
	LOSS [training: 0.3326194334299803 | validation: 0.4150521236280319]
	TIME [epoch: 9.21 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32470352907020483		[learning rate: 0.0033856]
	Learning Rate: 0.00338557
	LOSS [training: 0.32470352907020483 | validation: 0.2549904485930924]
	TIME [epoch: 9.19 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.994425822412291		[learning rate: 0.0033733]
	Learning Rate: 0.00337328
	LOSS [training: 0.994425822412291 | validation: 0.28537431039453176]
	TIME [epoch: 9.19 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3262467754705872		[learning rate: 0.003361]
	Learning Rate: 0.00336104
	LOSS [training: 0.3262467754705872 | validation: 0.17451654196587352]
	TIME [epoch: 9.19 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3795113128699224		[learning rate: 0.0033488]
	Learning Rate: 0.00334884
	LOSS [training: 0.3795113128699224 | validation: 0.13109266370865671]
	TIME [epoch: 9.22 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2806840501903001		[learning rate: 0.0033367]
	Learning Rate: 0.00333669
	LOSS [training: 0.2806840501903001 | validation: 0.47508034505148244]
	TIME [epoch: 9.2 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29224397600936736		[learning rate: 0.0033246]
	Learning Rate: 0.00332458
	LOSS [training: 0.29224397600936736 | validation: 0.1809512341590893]
	TIME [epoch: 9.19 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3623733360957104		[learning rate: 0.0033125]
	Learning Rate: 0.00331252
	LOSS [training: 0.3623733360957104 | validation: 0.27885593159587946]
	TIME [epoch: 9.19 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3046668817317656		[learning rate: 0.0033005]
	Learning Rate: 0.00330049
	LOSS [training: 0.3046668817317656 | validation: 0.34940134226450303]
	TIME [epoch: 9.21 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34101180313612245		[learning rate: 0.0032885]
	Learning Rate: 0.00328852
	LOSS [training: 0.34101180313612245 | validation: 0.44258153718314025]
	TIME [epoch: 9.21 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32645344577621194		[learning rate: 0.0032766]
	Learning Rate: 0.00327658
	LOSS [training: 0.32645344577621194 | validation: 0.18829530219010443]
	TIME [epoch: 9.19 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36877475157997763		[learning rate: 0.0032647]
	Learning Rate: 0.00326469
	LOSS [training: 0.36877475157997763 | validation: 0.22677872767942647]
	TIME [epoch: 9.19 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35675605501508484		[learning rate: 0.0032528]
	Learning Rate: 0.00325284
	LOSS [training: 0.35675605501508484 | validation: 0.3744399584839166]
	TIME [epoch: 9.19 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3377636271450185		[learning rate: 0.003241]
	Learning Rate: 0.00324104
	LOSS [training: 0.3377636271450185 | validation: 0.1805322895959989]
	TIME [epoch: 9.21 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35921170160939836		[learning rate: 0.0032293]
	Learning Rate: 0.00322928
	LOSS [training: 0.35921170160939836 | validation: 0.2721101901966845]
	TIME [epoch: 9.19 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2771399143380561		[learning rate: 0.0032176]
	Learning Rate: 0.00321756
	LOSS [training: 0.2771399143380561 | validation: 0.22700867049747747]
	TIME [epoch: 9.19 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8593331365835042		[learning rate: 0.0032059]
	Learning Rate: 0.00320588
	LOSS [training: 0.8593331365835042 | validation: 0.7574013002854754]
	TIME [epoch: 9.19 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43738970908502217		[learning rate: 0.0031942]
	Learning Rate: 0.00319425
	LOSS [training: 0.43738970908502217 | validation: 0.22296970632799162]
	TIME [epoch: 9.2 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3121996639877166		[learning rate: 0.0031827]
	Learning Rate: 0.00318265
	LOSS [training: 0.3121996639877166 | validation: 0.2003732529838717]
	TIME [epoch: 9.23 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2874870722887555		[learning rate: 0.0031711]
	Learning Rate: 0.0031711
	LOSS [training: 0.2874870722887555 | validation: 0.3774853554476267]
	TIME [epoch: 9.19 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44569222276435605		[learning rate: 0.0031596]
	Learning Rate: 0.0031596
	LOSS [training: 0.44569222276435605 | validation: 0.22649565818461936]
	TIME [epoch: 9.19 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.275719487486617		[learning rate: 0.0031481]
	Learning Rate: 0.00314813
	LOSS [training: 0.275719487486617 | validation: 0.20698811854026739]
	TIME [epoch: 9.19 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3485526563734604		[learning rate: 0.0031367]
	Learning Rate: 0.00313671
	LOSS [training: 0.3485526563734604 | validation: 0.30206725707705123]
	TIME [epoch: 9.22 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36778012165517826		[learning rate: 0.0031253]
	Learning Rate: 0.00312532
	LOSS [training: 0.36778012165517826 | validation: 0.4684198894036051]
	TIME [epoch: 9.2 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3155577775506215		[learning rate: 0.003114]
	Learning Rate: 0.00311398
	LOSS [training: 0.3155577775506215 | validation: 0.15756332663932587]
	TIME [epoch: 9.19 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43601638606787513		[learning rate: 0.0031027]
	Learning Rate: 0.00310268
	LOSS [training: 0.43601638606787513 | validation: 0.3532142984660496]
	TIME [epoch: 9.19 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3118204995661181		[learning rate: 0.0030914]
	Learning Rate: 0.00309142
	LOSS [training: 0.3118204995661181 | validation: 0.15747920938579535]
	TIME [epoch: 9.19 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6694567714185556		[learning rate: 0.0030802]
	Learning Rate: 0.0030802
	LOSS [training: 0.6694567714185556 | validation: 0.20136568466826527]
	TIME [epoch: 9.22 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42342164197287013		[learning rate: 0.003069]
	Learning Rate: 0.00306902
	LOSS [training: 0.42342164197287013 | validation: 0.2915731028679084]
	TIME [epoch: 9.19 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2778187535057103		[learning rate: 0.0030579]
	Learning Rate: 0.00305788
	LOSS [training: 0.2778187535057103 | validation: 0.25209841956536827]
	TIME [epoch: 9.19 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.409553054521527		[learning rate: 0.0030468]
	Learning Rate: 0.00304679
	LOSS [training: 0.409553054521527 | validation: 0.6152353074251713]
	TIME [epoch: 9.2 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44457634619710024		[learning rate: 0.0030357]
	Learning Rate: 0.00303573
	LOSS [training: 0.44457634619710024 | validation: 0.27297401965102663]
	TIME [epoch: 9.21 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44420742256507434		[learning rate: 0.0030247]
	Learning Rate: 0.00302471
	LOSS [training: 0.44420742256507434 | validation: 0.43247901660576854]
	TIME [epoch: 9.22 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41308777155376264		[learning rate: 0.0030137]
	Learning Rate: 0.00301374
	LOSS [training: 0.41308777155376264 | validation: 0.17359072646482143]
	TIME [epoch: 9.19 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32856174542124206		[learning rate: 0.0030028]
	Learning Rate: 0.0030028
	LOSS [training: 0.32856174542124206 | validation: 0.13927378909699287]
	TIME [epoch: 9.19 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2780054744488612		[learning rate: 0.0029919]
	Learning Rate: 0.0029919
	LOSS [training: 0.2780054744488612 | validation: 0.6807160682155206]
	TIME [epoch: 9.19 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38354638083578185		[learning rate: 0.002981]
	Learning Rate: 0.00298104
	LOSS [training: 0.38354638083578185 | validation: 0.20591839193218425]
	TIME [epoch: 9.22 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31341119851036614		[learning rate: 0.0029702]
	Learning Rate: 0.00297023
	LOSS [training: 0.31341119851036614 | validation: 0.40368144012178336]
	TIME [epoch: 9.2 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28519844947626094		[learning rate: 0.0029594]
	Learning Rate: 0.00295945
	LOSS [training: 0.28519844947626094 | validation: 0.4290511372043173]
	TIME [epoch: 9.19 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3205068640140301		[learning rate: 0.0029487]
	Learning Rate: 0.00294871
	LOSS [training: 0.3205068640140301 | validation: 0.25733704069879687]
	TIME [epoch: 9.19 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3585723516008834		[learning rate: 0.002938]
	Learning Rate: 0.00293801
	LOSS [training: 0.3585723516008834 | validation: 0.2547343268404226]
	TIME [epoch: 9.2 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.320167920663161		[learning rate: 0.0029273]
	Learning Rate: 0.00292734
	LOSS [training: 0.320167920663161 | validation: 0.198843931542387]
	TIME [epoch: 9.2 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3183759895040409		[learning rate: 0.0029167]
	Learning Rate: 0.00291672
	LOSS [training: 0.3183759895040409 | validation: 0.21832665143462687]
	TIME [epoch: 9.2 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4034819777672586		[learning rate: 0.0029061]
	Learning Rate: 0.00290614
	LOSS [training: 0.4034819777672586 | validation: 0.28442416182589875]
	TIME [epoch: 9.19 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2769847378180968		[learning rate: 0.0028956]
	Learning Rate: 0.00289559
	LOSS [training: 0.2769847378180968 | validation: 0.353339258721958]
	TIME [epoch: 9.19 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2831594567792282		[learning rate: 0.0028851]
	Learning Rate: 0.00288508
	LOSS [training: 0.2831594567792282 | validation: 0.4136719553111791]
	TIME [epoch: 9.22 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3996986045048916		[learning rate: 0.0028746]
	Learning Rate: 0.00287461
	LOSS [training: 0.3996986045048916 | validation: 0.45799999331290386]
	TIME [epoch: 9.19 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3108204754794132		[learning rate: 0.0028642]
	Learning Rate: 0.00286418
	LOSS [training: 0.3108204754794132 | validation: 0.12882175317478767]
	TIME [epoch: 9.19 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28408131478915466		[learning rate: 0.0028538]
	Learning Rate: 0.00285378
	LOSS [training: 0.28408131478915466 | validation: 0.3392319271665259]
	TIME [epoch: 9.19 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2801302298719833		[learning rate: 0.0028434]
	Learning Rate: 0.00284343
	LOSS [training: 0.2801302298719833 | validation: 0.29122065137540476]
	TIME [epoch: 9.19 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33756861115326886		[learning rate: 0.0028331]
	Learning Rate: 0.00283311
	LOSS [training: 0.33756861115326886 | validation: 0.3204568436487526]
	TIME [epoch: 9.21 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4994785398591701		[learning rate: 0.0028228]
	Learning Rate: 0.00282283
	LOSS [training: 0.4994785398591701 | validation: 1.5814931957944072]
	TIME [epoch: 9.19 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47344574387965865		[learning rate: 0.0028126]
	Learning Rate: 0.00281258
	LOSS [training: 0.47344574387965865 | validation: 0.14319030650590645]
	TIME [epoch: 9.19 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30151752208573446		[learning rate: 0.0028024]
	Learning Rate: 0.00280238
	LOSS [training: 0.30151752208573446 | validation: 0.16474360490999707]
	TIME [epoch: 9.18 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35318571970561863		[learning rate: 0.0027922]
	Learning Rate: 0.00279221
	LOSS [training: 0.35318571970561863 | validation: 0.23017223342178358]
	TIME [epoch: 9.2 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3505843658854205		[learning rate: 0.0027821]
	Learning Rate: 0.00278207
	LOSS [training: 0.3505843658854205 | validation: 0.2548559738581411]
	TIME [epoch: 9.2 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3600024932407881		[learning rate: 0.002772]
	Learning Rate: 0.00277198
	LOSS [training: 0.3600024932407881 | validation: 0.2597033156176483]
	TIME [epoch: 9.2 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29489643045710345		[learning rate: 0.0027619]
	Learning Rate: 0.00276192
	LOSS [training: 0.29489643045710345 | validation: 0.400746594315307]
	TIME [epoch: 9.2 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3603975667321949		[learning rate: 0.0027519]
	Learning Rate: 0.00275189
	LOSS [training: 0.3603975667321949 | validation: 0.19260362229666428]
	TIME [epoch: 9.21 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3030493666125926		[learning rate: 0.0027419]
	Learning Rate: 0.00274191
	LOSS [training: 0.3030493666125926 | validation: 0.24158941980584797]
	TIME [epoch: 9.21 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2507998023564037		[learning rate: 0.002732]
	Learning Rate: 0.00273196
	LOSS [training: 0.2507998023564037 | validation: 0.3142959857367694]
	TIME [epoch: 9.19 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41544598505733676		[learning rate: 0.002722]
	Learning Rate: 0.00272204
	LOSS [training: 0.41544598505733676 | validation: 0.1836140141436749]
	TIME [epoch: 9.18 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2461937702578739		[learning rate: 0.0027122]
	Learning Rate: 0.00271216
	LOSS [training: 0.2461937702578739 | validation: 0.1462566868427161]
	TIME [epoch: 9.2 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.272492979825876		[learning rate: 0.0027023]
	Learning Rate: 0.00270232
	LOSS [training: 0.272492979825876 | validation: 1.2483158672854195]
	TIME [epoch: 9.22 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4274056151271367		[learning rate: 0.0026925]
	Learning Rate: 0.00269251
	LOSS [training: 0.4274056151271367 | validation: 0.1679137459076353]
	TIME [epoch: 9.19 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2978338257988592		[learning rate: 0.0026827]
	Learning Rate: 0.00268274
	LOSS [training: 0.2978338257988592 | validation: 0.18685372820672574]
	TIME [epoch: 9.18 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3033050029549217		[learning rate: 0.002673]
	Learning Rate: 0.00267301
	LOSS [training: 0.3033050029549217 | validation: 0.5512247449214561]
	TIME [epoch: 9.19 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30349806814887337		[learning rate: 0.0026633]
	Learning Rate: 0.00266331
	LOSS [training: 0.30349806814887337 | validation: 0.19474151264017164]
	TIME [epoch: 9.2 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2709299328025959		[learning rate: 0.0026536]
	Learning Rate: 0.00265364
	LOSS [training: 0.2709299328025959 | validation: 0.24107359136789072]
	TIME [epoch: 9.21 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2758168493741227		[learning rate: 0.002644]
	Learning Rate: 0.00264401
	LOSS [training: 0.2758168493741227 | validation: 0.16564439807904563]
	TIME [epoch: 9.19 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2761798764894811		[learning rate: 0.0026344]
	Learning Rate: 0.00263441
	LOSS [training: 0.2761798764894811 | validation: 0.2784267449097828]
	TIME [epoch: 9.2 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3527275453744002		[learning rate: 0.0026249]
	Learning Rate: 0.00262485
	LOSS [training: 0.3527275453744002 | validation: 0.2581749052520436]
	TIME [epoch: 9.19 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27004042183099075		[learning rate: 0.0026153]
	Learning Rate: 0.00261533
	LOSS [training: 0.27004042183099075 | validation: 0.2144687914362436]
	TIME [epoch: 9.22 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2646270267614715		[learning rate: 0.0026058]
	Learning Rate: 0.00260584
	LOSS [training: 0.2646270267614715 | validation: 0.19167991854389926]
	TIME [epoch: 9.21 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24468806337130614		[learning rate: 0.0025964]
	Learning Rate: 0.00259638
	LOSS [training: 0.24468806337130614 | validation: 0.39062648260206834]
	TIME [epoch: 9.2 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3050751441645777		[learning rate: 0.002587]
	Learning Rate: 0.00258696
	LOSS [training: 0.3050751441645777 | validation: 0.2696254282466242]
	TIME [epoch: 9.2 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2845261931986789		[learning rate: 0.0025776]
	Learning Rate: 0.00257757
	LOSS [training: 0.2845261931986789 | validation: 0.13785290344007645]
	TIME [epoch: 9.2 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.318456970236599		[learning rate: 0.0025682]
	Learning Rate: 0.00256822
	LOSS [training: 0.318456970236599 | validation: 0.15362585182464814]
	TIME [epoch: 9.21 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22450159483520346		[learning rate: 0.0025589]
	Learning Rate: 0.0025589
	LOSS [training: 0.22450159483520346 | validation: 0.19216849517024992]
	TIME [epoch: 9.21 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28957143557298887		[learning rate: 0.0025496]
	Learning Rate: 0.00254961
	LOSS [training: 0.28957143557298887 | validation: 0.15294027159811308]
	TIME [epoch: 9.2 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26828502266134374		[learning rate: 0.0025404]
	Learning Rate: 0.00254036
	LOSS [training: 0.26828502266134374 | validation: 0.14160190297562986]
	TIME [epoch: 9.19 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25726858670606756		[learning rate: 0.0025311]
	Learning Rate: 0.00253114
	LOSS [training: 0.25726858670606756 | validation: 0.13124287467720216]
	TIME [epoch: 9.22 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2910793441709256		[learning rate: 0.002522]
	Learning Rate: 0.00252195
	LOSS [training: 0.2910793441709256 | validation: 0.2714641884323472]
	TIME [epoch: 9.2 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30163122537540155		[learning rate: 0.0025128]
	Learning Rate: 0.0025128
	LOSS [training: 0.30163122537540155 | validation: 0.2359279571938459]
	TIME [epoch: 9.21 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2803589429489181		[learning rate: 0.0025037]
	Learning Rate: 0.00250368
	LOSS [training: 0.2803589429489181 | validation: 0.2734702394102248]
	TIME [epoch: 9.21 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2783001609917704		[learning rate: 0.0024946]
	Learning Rate: 0.00249459
	LOSS [training: 0.2783001609917704 | validation: 0.25814804113507905]
	TIME [epoch: 9.2 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26573739332285856		[learning rate: 0.0024855]
	Learning Rate: 0.00248554
	LOSS [training: 0.26573739332285856 | validation: 0.22125760208331682]
	TIME [epoch: 9.23 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25437287591924823		[learning rate: 0.0024765]
	Learning Rate: 0.00247652
	LOSS [training: 0.25437287591924823 | validation: 0.14825699724203567]
	TIME [epoch: 9.2 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2953757873747094		[learning rate: 0.0024675]
	Learning Rate: 0.00246753
	LOSS [training: 0.2953757873747094 | validation: 0.3320373269453731]
	TIME [epoch: 9.21 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2960882288722677		[learning rate: 0.0024586]
	Learning Rate: 0.00245858
	LOSS [training: 0.2960882288722677 | validation: 0.15762591253605962]
	TIME [epoch: 9.22 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2667635329581558		[learning rate: 0.0024497]
	Learning Rate: 0.00244966
	LOSS [training: 0.2667635329581558 | validation: 0.3095553774337506]
	TIME [epoch: 9.24 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33460819317765267		[learning rate: 0.0024408]
	Learning Rate: 0.00244077
	LOSS [training: 0.33460819317765267 | validation: 0.20537454552513754]
	TIME [epoch: 9.21 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2778933603121736		[learning rate: 0.0024319]
	Learning Rate: 0.00243191
	LOSS [training: 0.2778933603121736 | validation: 0.15428384311684953]
	TIME [epoch: 9.2 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2793369997869145		[learning rate: 0.0024231]
	Learning Rate: 0.00242308
	LOSS [training: 0.2793369997869145 | validation: 0.28014547514866134]
	TIME [epoch: 9.2 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24433073376336822		[learning rate: 0.0024143]
	Learning Rate: 0.00241429
	LOSS [training: 0.24433073376336822 | validation: 0.1404409381502827]
	TIME [epoch: 9.21 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24802598875483933		[learning rate: 0.0024055]
	Learning Rate: 0.00240553
	LOSS [training: 0.24802598875483933 | validation: 0.2635687711781348]
	TIME [epoch: 9.23 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3192443000240763		[learning rate: 0.0023968]
	Learning Rate: 0.0023968
	LOSS [training: 0.3192443000240763 | validation: 0.19787444403549193]
	TIME [epoch: 9.21 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3172759309694499		[learning rate: 0.0023881]
	Learning Rate: 0.0023881
	LOSS [training: 0.3172759309694499 | validation: 0.12948791721031921]
	TIME [epoch: 9.2 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3718201507896612		[learning rate: 0.0023794]
	Learning Rate: 0.00237943
	LOSS [training: 0.3718201507896612 | validation: 0.7020118536450143]
	TIME [epoch: 9.2 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3273017822492255		[learning rate: 0.0023708]
	Learning Rate: 0.0023708
	LOSS [training: 0.3273017822492255 | validation: 0.21450642098506784]
	TIME [epoch: 9.21 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2739257520655785		[learning rate: 0.0023622]
	Learning Rate: 0.0023622
	LOSS [training: 0.2739257520655785 | validation: 0.2674165970364184]
	TIME [epoch: 9.22 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24907390141552627		[learning rate: 0.0023536]
	Learning Rate: 0.00235362
	LOSS [training: 0.24907390141552627 | validation: 0.38826991184162674]
	TIME [epoch: 9.2 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2599483639911404		[learning rate: 0.0023451]
	Learning Rate: 0.00234508
	LOSS [training: 0.2599483639911404 | validation: 0.11772426781147564]
	TIME [epoch: 9.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r5_20240219_234257/states/model_tr_study204_499.pth
	Model improved!!!
EPOCH 500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25143533326838186		[learning rate: 0.0023366]
	Learning Rate: 0.00233657
	LOSS [training: 0.25143533326838186 | validation: 0.22189890576218407]
	TIME [epoch: 9.21 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3375079673838869		[learning rate: 0.0023281]
	Learning Rate: 0.00232809
	LOSS [training: 0.3375079673838869 | validation: 0.1792854377923662]
	TIME [epoch: 9.22 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2861515622733161		[learning rate: 0.0023196]
	Learning Rate: 0.00231964
	LOSS [training: 0.2861515622733161 | validation: 0.18439069436445277]
	TIME [epoch: 9.2 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2480759526073799		[learning rate: 0.0023112]
	Learning Rate: 0.00231122
	LOSS [training: 0.2480759526073799 | validation: 0.20210787756754248]
	TIME [epoch: 9.2 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2979890018100289		[learning rate: 0.0023028]
	Learning Rate: 0.00230284
	LOSS [training: 0.2979890018100289 | validation: 0.13539045444240624]
	TIME [epoch: 9.2 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2500313353942746		[learning rate: 0.0022945]
	Learning Rate: 0.00229448
	LOSS [training: 0.2500313353942746 | validation: 0.1766030725736118]
	TIME [epoch: 9.23 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25523226895291184		[learning rate: 0.0022862]
	Learning Rate: 0.00228615
	LOSS [training: 0.25523226895291184 | validation: 0.414402759696468]
	TIME [epoch: 9.21 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30959435649020345		[learning rate: 0.0022779]
	Learning Rate: 0.00227786
	LOSS [training: 0.30959435649020345 | validation: 0.15861536974624346]
	TIME [epoch: 9.2 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22683077891115017		[learning rate: 0.0022696]
	Learning Rate: 0.00226959
	LOSS [training: 0.22683077891115017 | validation: 0.21813948813220999]
	TIME [epoch: 9.21 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26264652619886003		[learning rate: 0.0022614]
	Learning Rate: 0.00226135
	LOSS [training: 0.26264652619886003 | validation: 0.35811667833903804]
	TIME [epoch: 9.2 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3011027565780001		[learning rate: 0.0022531]
	Learning Rate: 0.00225315
	LOSS [training: 0.3011027565780001 | validation: 0.2422339501220892]
	TIME [epoch: 9.23 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2591593543635036		[learning rate: 0.002245]
	Learning Rate: 0.00224497
	LOSS [training: 0.2591593543635036 | validation: 0.19242755964395472]
	TIME [epoch: 9.2 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26447789323227644		[learning rate: 0.0022368]
	Learning Rate: 0.00223682
	LOSS [training: 0.26447789323227644 | validation: 0.18440324472253192]
	TIME [epoch: 9.2 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23877738544449448		[learning rate: 0.0022287]
	Learning Rate: 0.00222871
	LOSS [training: 0.23877738544449448 | validation: 0.15456362848444338]
	TIME [epoch: 9.2 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2398878394779888		[learning rate: 0.0022206]
	Learning Rate: 0.00222062
	LOSS [training: 0.2398878394779888 | validation: 0.21157260182694274]
	TIME [epoch: 9.23 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2650512653683395		[learning rate: 0.0022126]
	Learning Rate: 0.00221256
	LOSS [training: 0.2650512653683395 | validation: 0.15765463698458115]
	TIME [epoch: 9.2 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22022769938411493		[learning rate: 0.0022045]
	Learning Rate: 0.00220453
	LOSS [training: 0.22022769938411493 | validation: 0.6636005934833651]
	TIME [epoch: 9.2 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43611806380864515		[learning rate: 0.0021965]
	Learning Rate: 0.00219653
	LOSS [training: 0.43611806380864515 | validation: 0.20713833656010408]
	TIME [epoch: 9.19 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2182559898359567		[learning rate: 0.0021886]
	Learning Rate: 0.00218856
	LOSS [training: 0.2182559898359567 | validation: 0.2577821959259571]
	TIME [epoch: 9.2 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24163222167622972		[learning rate: 0.0021806]
	Learning Rate: 0.00218061
	LOSS [training: 0.24163222167622972 | validation: 0.11629398703345001]
	TIME [epoch: 9.24 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r5_20240219_234257/states/model_tr_study204_519.pth
	Model improved!!!
EPOCH 520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37891089313097365		[learning rate: 0.0021727]
	Learning Rate: 0.0021727
	LOSS [training: 0.37891089313097365 | validation: 0.5775919163445233]
	TIME [epoch: 9.21 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38231103715699477		[learning rate: 0.0021648]
	Learning Rate: 0.00216482
	LOSS [training: 0.38231103715699477 | validation: 0.16990055978745372]
	TIME [epoch: 9.2 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22030884506632215		[learning rate: 0.002157]
	Learning Rate: 0.00215696
	LOSS [training: 0.22030884506632215 | validation: 0.16441337247182258]
	TIME [epoch: 9.19 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23045447134988514		[learning rate: 0.0021491]
	Learning Rate: 0.00214913
	LOSS [training: 0.23045447134988514 | validation: 0.13505572222002957]
	TIME [epoch: 9.22 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2626385552463337		[learning rate: 0.0021413]
	Learning Rate: 0.00214133
	LOSS [training: 0.2626385552463337 | validation: 0.20765575406501563]
	TIME [epoch: 9.21 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2379741273861098		[learning rate: 0.0021336]
	Learning Rate: 0.00213356
	LOSS [training: 0.2379741273861098 | validation: 0.19024606541160616]
	TIME [epoch: 9.2 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27614075379245534		[learning rate: 0.0021258]
	Learning Rate: 0.00212582
	LOSS [training: 0.27614075379245534 | validation: 0.18014343840523434]
	TIME [epoch: 9.2 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23948290852445192		[learning rate: 0.0021181]
	Learning Rate: 0.0021181
	LOSS [training: 0.23948290852445192 | validation: 0.13747039824463914]
	TIME [epoch: 9.2 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22021398147546828		[learning rate: 0.0021104]
	Learning Rate: 0.00211042
	LOSS [training: 0.22021398147546828 | validation: 0.20427869153586112]
	TIME [epoch: 9.23 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36040175008671094		[learning rate: 0.0021028]
	Learning Rate: 0.00210276
	LOSS [training: 0.36040175008671094 | validation: 0.17208381246771232]
	TIME [epoch: 9.18 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.227649121777083		[learning rate: 0.0020951]
	Learning Rate: 0.00209513
	LOSS [training: 0.227649121777083 | validation: 0.24624717115398237]
	TIME [epoch: 9.2 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2801045792592055		[learning rate: 0.0020875]
	Learning Rate: 0.00208752
	LOSS [training: 0.2801045792592055 | validation: 0.15502230139508769]
	TIME [epoch: 9.21 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2054383781387051		[learning rate: 0.0020799]
	Learning Rate: 0.00207995
	LOSS [training: 0.2054383781387051 | validation: 0.20993637911998528]
	TIME [epoch: 9.22 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26631497793861986		[learning rate: 0.0020724]
	Learning Rate: 0.0020724
	LOSS [training: 0.26631497793861986 | validation: 0.1346594509228237]
	TIME [epoch: 9.22 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2496649846839794		[learning rate: 0.0020649]
	Learning Rate: 0.00206488
	LOSS [training: 0.2496649846839794 | validation: 0.15503480320602586]
	TIME [epoch: 9.2 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2604223024822576		[learning rate: 0.0020574]
	Learning Rate: 0.00205739
	LOSS [training: 0.2604223024822576 | validation: 0.14205683194201724]
	TIME [epoch: 9.2 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24635058724563721		[learning rate: 0.0020499]
	Learning Rate: 0.00204992
	LOSS [training: 0.24635058724563721 | validation: 0.3441733772031751]
	TIME [epoch: 9.19 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2665131878102037		[learning rate: 0.0020425]
	Learning Rate: 0.00204248
	LOSS [training: 0.2665131878102037 | validation: 0.11600270657498117]
	TIME [epoch: 9.23 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r5_20240219_234257/states/model_tr_study204_537.pth
	Model improved!!!
EPOCH 538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20228440884995527		[learning rate: 0.0020351]
	Learning Rate: 0.00203507
	LOSS [training: 0.20228440884995527 | validation: 0.3308273925789882]
	TIME [epoch: 9.2 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25097497331225493		[learning rate: 0.0020277]
	Learning Rate: 0.00202768
	LOSS [training: 0.25097497331225493 | validation: 0.5248037813718077]
	TIME [epoch: 9.2 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38182168491491436		[learning rate: 0.0020203]
	Learning Rate: 0.00202032
	LOSS [training: 0.38182168491491436 | validation: 0.13361502885002982]
	TIME [epoch: 9.2 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23555215581224917		[learning rate: 0.002013]
	Learning Rate: 0.00201299
	LOSS [training: 0.23555215581224917 | validation: 0.204118959715493]
	TIME [epoch: 9.21 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23275450153835697		[learning rate: 0.0020057]
	Learning Rate: 0.00200569
	LOSS [training: 0.23275450153835697 | validation: 0.18044429501959214]
	TIME [epoch: 9.19 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25139113747515734		[learning rate: 0.0019984]
	Learning Rate: 0.00199841
	LOSS [training: 0.25139113747515734 | validation: 0.23883897372236185]
	TIME [epoch: 9.2 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23230490014677468		[learning rate: 0.0019912]
	Learning Rate: 0.00199116
	LOSS [training: 0.23230490014677468 | validation: 0.21215002688818402]
	TIME [epoch: 9.2 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2086169911049655		[learning rate: 0.0019839]
	Learning Rate: 0.00198393
	LOSS [training: 0.2086169911049655 | validation: 0.16752342315847207]
	TIME [epoch: 9.2 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25556206575419965		[learning rate: 0.0019767]
	Learning Rate: 0.00197673
	LOSS [training: 0.25556206575419965 | validation: 0.28682592552997577]
	TIME [epoch: 9.22 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23277387291119217		[learning rate: 0.0019696]
	Learning Rate: 0.00196956
	LOSS [training: 0.23277387291119217 | validation: 0.1972766706115272]
	TIME [epoch: 9.2 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24269665303806703		[learning rate: 0.0019624]
	Learning Rate: 0.00196241
	LOSS [training: 0.24269665303806703 | validation: 0.14822930340215362]
	TIME [epoch: 9.19 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21800969603709755		[learning rate: 0.0019553]
	Learning Rate: 0.00195529
	LOSS [training: 0.21800969603709755 | validation: 0.1424331549922951]
	TIME [epoch: 9.2 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20863506328668371		[learning rate: 0.0019482]
	Learning Rate: 0.00194819
	LOSS [training: 0.20863506328668371 | validation: 0.1962317626547253]
	TIME [epoch: 9.2 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5130173162768484		[learning rate: 0.0019411]
	Learning Rate: 0.00194112
	LOSS [training: 0.5130173162768484 | validation: 0.1224676914614127]
	TIME [epoch: 9.21 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2406160432198218		[learning rate: 0.0019341]
	Learning Rate: 0.00193408
	LOSS [training: 0.2406160432198218 | validation: 0.22186284308163642]
	TIME [epoch: 9.2 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29702381273441203		[learning rate: 0.0019271]
	Learning Rate: 0.00192706
	LOSS [training: 0.29702381273441203 | validation: 0.21451662957379694]
	TIME [epoch: 9.2 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31548425991313034		[learning rate: 0.0019201]
	Learning Rate: 0.00192006
	LOSS [training: 0.31548425991313034 | validation: 0.17171393620056175]
	TIME [epoch: 9.2 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3515097178611214		[learning rate: 0.0019131]
	Learning Rate: 0.0019131
	LOSS [training: 0.3515097178611214 | validation: 0.1429787881587798]
	TIME [epoch: 9.23 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22916282353654358		[learning rate: 0.0019062]
	Learning Rate: 0.00190615
	LOSS [training: 0.22916282353654358 | validation: 0.12123348058227734]
	TIME [epoch: 9.2 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2378473406907211		[learning rate: 0.0018992]
	Learning Rate: 0.00189924
	LOSS [training: 0.2378473406907211 | validation: 0.1709116097020439]
	TIME [epoch: 9.21 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2926621436941948		[learning rate: 0.0018923]
	Learning Rate: 0.00189234
	LOSS [training: 0.2926621436941948 | validation: 0.12809566765028965]
	TIME [epoch: 9.2 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21269875450172848		[learning rate: 0.0018855]
	Learning Rate: 0.00188548
	LOSS [training: 0.21269875450172848 | validation: 0.2145226724687585]
	TIME [epoch: 9.21 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24895540756926998		[learning rate: 0.0018786]
	Learning Rate: 0.00187863
	LOSS [training: 0.24895540756926998 | validation: 0.18837515743342623]
	TIME [epoch: 9.22 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20531793871236262		[learning rate: 0.0018718]
	Learning Rate: 0.00187182
	LOSS [training: 0.20531793871236262 | validation: 0.17364192835055986]
	TIME [epoch: 9.2 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23884678283971278		[learning rate: 0.001865]
	Learning Rate: 0.00186502
	LOSS [training: 0.23884678283971278 | validation: 0.14721095413662794]
	TIME [epoch: 9.21 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2291165279559196		[learning rate: 0.0018583]
	Learning Rate: 0.00185825
	LOSS [training: 0.2291165279559196 | validation: 0.2645290093815952]
	TIME [epoch: 9.2 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2797455549034505		[learning rate: 0.0018515]
	Learning Rate: 0.00185151
	LOSS [training: 0.2797455549034505 | validation: 0.26277383362126705]
	TIME [epoch: 9.23 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24002322063485831		[learning rate: 0.0018448]
	Learning Rate: 0.00184479
	LOSS [training: 0.24002322063485831 | validation: 0.23700783147198626]
	TIME [epoch: 9.2 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22190068408112312		[learning rate: 0.0018381]
	Learning Rate: 0.0018381
	LOSS [training: 0.22190068408112312 | validation: 0.17497444554479413]
	TIME [epoch: 9.2 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21782830192370586		[learning rate: 0.0018314]
	Learning Rate: 0.00183143
	LOSS [training: 0.21782830192370586 | validation: 0.1461344364609571]
	TIME [epoch: 9.19 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2902368377247643		[learning rate: 0.0018248]
	Learning Rate: 0.00182478
	LOSS [training: 0.2902368377247643 | validation: 0.18975335873245563]
	TIME [epoch: 9.21 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38486109789725936		[learning rate: 0.0018182]
	Learning Rate: 0.00181816
	LOSS [training: 0.38486109789725936 | validation: 1.6818479637322241]
	TIME [epoch: 9.22 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.539809485128996		[learning rate: 0.0018116]
	Learning Rate: 0.00181156
	LOSS [training: 0.539809485128996 | validation: 0.15238809343030718]
	TIME [epoch: 9.2 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3671596409091839		[learning rate: 0.001805]
	Learning Rate: 0.00180499
	LOSS [training: 0.3671596409091839 | validation: 0.3288098945089568]
	TIME [epoch: 9.21 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3759477448189986		[learning rate: 0.0017984]
	Learning Rate: 0.00179844
	LOSS [training: 0.3759477448189986 | validation: 0.19227623730919208]
	TIME [epoch: 9.2 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25661934155277527		[learning rate: 0.0017919]
	Learning Rate: 0.00179191
	LOSS [training: 0.25661934155277527 | validation: 0.200473957603428]
	TIME [epoch: 9.22 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2556140911095929		[learning rate: 0.0017854]
	Learning Rate: 0.00178541
	LOSS [training: 0.2556140911095929 | validation: 0.19570256862613075]
	TIME [epoch: 9.2 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3347244246427975		[learning rate: 0.0017789]
	Learning Rate: 0.00177893
	LOSS [training: 0.3347244246427975 | validation: 0.22542007419744672]
	TIME [epoch: 9.2 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20011558660267642		[learning rate: 0.0017725]
	Learning Rate: 0.00177247
	LOSS [training: 0.20011558660267642 | validation: 0.2910864593296084]
	TIME [epoch: 9.19 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2210071222813496		[learning rate: 0.001766]
	Learning Rate: 0.00176604
	LOSS [training: 0.2210071222813496 | validation: 0.1479265555956462]
	TIME [epoch: 9.21 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40508778341000456		[learning rate: 0.0017596]
	Learning Rate: 0.00175963
	LOSS [training: 0.40508778341000456 | validation: 0.11340311340203635]
	TIME [epoch: 9.22 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r5_20240219_234257/states/model_tr_study204_578.pth
	Model improved!!!
EPOCH 579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2526359161460022		[learning rate: 0.0017532]
	Learning Rate: 0.00175324
	LOSS [training: 0.2526359161460022 | validation: 0.18851689190035764]
	TIME [epoch: 9.22 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23323940452483907		[learning rate: 0.0017469]
	Learning Rate: 0.00174688
	LOSS [training: 0.23323940452483907 | validation: 0.37977687776925617]
	TIME [epoch: 9.2 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36093894804395565		[learning rate: 0.0017405]
	Learning Rate: 0.00174054
	LOSS [training: 0.36093894804395565 | validation: 0.24243759375790785]
	TIME [epoch: 9.2 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23500029068348222		[learning rate: 0.0017342]
	Learning Rate: 0.00173422
	LOSS [training: 0.23500029068348222 | validation: 0.2505090500670815]
	TIME [epoch: 9.23 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2128097437774948		[learning rate: 0.0017279]
	Learning Rate: 0.00172793
	LOSS [training: 0.2128097437774948 | validation: 0.4133026664574616]
	TIME [epoch: 9.21 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23367616979792083		[learning rate: 0.0017217]
	Learning Rate: 0.00172166
	LOSS [training: 0.23367616979792083 | validation: 0.17870595516968962]
	TIME [epoch: 9.21 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2673207575503409		[learning rate: 0.0017154]
	Learning Rate: 0.00171541
	LOSS [training: 0.2673207575503409 | validation: 0.1998673602350307]
	TIME [epoch: 9.2 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2043840103823459		[learning rate: 0.0017092]
	Learning Rate: 0.00170919
	LOSS [training: 0.2043840103823459 | validation: 0.1591117952200919]
	TIME [epoch: 9.21 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19584361808889827		[learning rate: 0.001703]
	Learning Rate: 0.00170298
	LOSS [training: 0.19584361808889827 | validation: 0.15203594344888072]
	TIME [epoch: 9.22 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20090006839451574		[learning rate: 0.0016968]
	Learning Rate: 0.0016968
	LOSS [training: 0.20090006839451574 | validation: 0.506217117223602]
	TIME [epoch: 9.2 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34054035994833		[learning rate: 0.0016906]
	Learning Rate: 0.00169065
	LOSS [training: 0.34054035994833 | validation: 0.1931997870353282]
	TIME [epoch: 9.2 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22773864795341794		[learning rate: 0.0016845]
	Learning Rate: 0.00168451
	LOSS [training: 0.22773864795341794 | validation: 0.24125836389490685]
	TIME [epoch: 9.2 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2723543862153992		[learning rate: 0.0016784]
	Learning Rate: 0.0016784
	LOSS [training: 0.2723543862153992 | validation: 0.17476883341904845]
	TIME [epoch: 9.2 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21397051963110053		[learning rate: 0.0016723]
	Learning Rate: 0.00167231
	LOSS [training: 0.21397051963110053 | validation: 0.13866265079223578]
	TIME [epoch: 9.22 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2896259927159999		[learning rate: 0.0016662]
	Learning Rate: 0.00166624
	LOSS [training: 0.2896259927159999 | validation: 0.1504445088927458]
	TIME [epoch: 9.19 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1976938755948589		[learning rate: 0.0016602]
	Learning Rate: 0.00166019
	LOSS [training: 0.1976938755948589 | validation: 0.3840917370007627]
	TIME [epoch: 9.2 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27477875799255896		[learning rate: 0.0016542]
	Learning Rate: 0.00165417
	LOSS [training: 0.27477875799255896 | validation: 0.1402943347220209]
	TIME [epoch: 9.18 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2012023001345642		[learning rate: 0.0016482]
	Learning Rate: 0.00164816
	LOSS [training: 0.2012023001345642 | validation: 0.15798108310157763]
	TIME [epoch: 9.22 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2553145540555304		[learning rate: 0.0016422]
	Learning Rate: 0.00164218
	LOSS [training: 0.2553145540555304 | validation: 0.2204814285472703]
	TIME [epoch: 9.21 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2268890621813008		[learning rate: 0.0016362]
	Learning Rate: 0.00163622
	LOSS [training: 0.2268890621813008 | validation: 0.22637985456186918]
	TIME [epoch: 9.19 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2436986254336392		[learning rate: 0.0016303]
	Learning Rate: 0.00163028
	LOSS [training: 0.2436986254336392 | validation: 0.18786893646640135]
	TIME [epoch: 9.19 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19186293016208017		[learning rate: 0.0016244]
	Learning Rate: 0.00162437
	LOSS [training: 0.19186293016208017 | validation: 0.11726611942301668]
	TIME [epoch: 9.2 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2463401394948858		[learning rate: 0.0016185]
	Learning Rate: 0.00161847
	LOSS [training: 0.2463401394948858 | validation: 0.4032031850172394]
	TIME [epoch: 9.22 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45714363886109455		[learning rate: 0.0016126]
	Learning Rate: 0.0016126
	LOSS [training: 0.45714363886109455 | validation: 0.12484334851601328]
	TIME [epoch: 9.2 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2084789167783156		[learning rate: 0.0016067]
	Learning Rate: 0.00160675
	LOSS [training: 0.2084789167783156 | validation: 0.22174735514367971]
	TIME [epoch: 9.19 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20016165301145347		[learning rate: 0.0016009]
	Learning Rate: 0.00160092
	LOSS [training: 0.20016165301145347 | validation: 0.29065906206361986]
	TIME [epoch: 9.19 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26540096802973445		[learning rate: 0.0015951]
	Learning Rate: 0.00159511
	LOSS [training: 0.26540096802973445 | validation: 0.2270423825653141]
	TIME [epoch: 9.21 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25854198659892624		[learning rate: 0.0015893]
	Learning Rate: 0.00158932
	LOSS [training: 0.25854198659892624 | validation: 0.19019486425240859]
	TIME [epoch: 9.19 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20248542449402485		[learning rate: 0.0015835]
	Learning Rate: 0.00158355
	LOSS [training: 0.20248542449402485 | validation: 0.15515020763884543]
	TIME [epoch: 9.2 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20060713885854278		[learning rate: 0.0015778]
	Learning Rate: 0.0015778
	LOSS [training: 0.20060713885854278 | validation: 0.17411783947525716]
	TIME [epoch: 9.18 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21069858645537787		[learning rate: 0.0015721]
	Learning Rate: 0.00157208
	LOSS [training: 0.21069858645537787 | validation: 0.14845516280567272]
	TIME [epoch: 9.22 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22787286184492053		[learning rate: 0.0015664]
	Learning Rate: 0.00156637
	LOSS [training: 0.22787286184492053 | validation: 0.10223568739700042]
	TIME [epoch: 9.21 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r5_20240219_234257/states/model_tr_study204_610.pth
	Model improved!!!
EPOCH 611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27572916584783413		[learning rate: 0.0015607]
	Learning Rate: 0.00156069
	LOSS [training: 0.27572916584783413 | validation: 0.2080373917033834]
	TIME [epoch: 9.22 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5962154551952987		[learning rate: 0.001555]
	Learning Rate: 0.00155502
	LOSS [training: 0.5962154551952987 | validation: 0.17743899954977188]
	TIME [epoch: 9.22 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25637208429051084		[learning rate: 0.0015494]
	Learning Rate: 0.00154938
	LOSS [training: 0.25637208429051084 | validation: 0.17290239474076133]
	TIME [epoch: 9.21 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20679550738615515		[learning rate: 0.0015438]
	Learning Rate: 0.00154376
	LOSS [training: 0.20679550738615515 | validation: 0.22385131552515555]
	TIME [epoch: 9.26 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21778454093240313		[learning rate: 0.0015382]
	Learning Rate: 0.00153815
	LOSS [training: 0.21778454093240313 | validation: 0.2957801808700381]
	TIME [epoch: 9.22 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26795868500532866		[learning rate: 0.0015326]
	Learning Rate: 0.00153257
	LOSS [training: 0.26795868500532866 | validation: 0.11968754279842105]
	TIME [epoch: 9.21 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20007369192983077		[learning rate: 0.001527]
	Learning Rate: 0.00152701
	LOSS [training: 0.20007369192983077 | validation: 0.1317018455727411]
	TIME [epoch: 9.21 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22732692101411184		[learning rate: 0.0015215]
	Learning Rate: 0.00152147
	LOSS [training: 0.22732692101411184 | validation: 0.23791307353138513]
	TIME [epoch: 9.22 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29589879879782516		[learning rate: 0.0015159]
	Learning Rate: 0.00151595
	LOSS [training: 0.29589879879782516 | validation: 0.14214911295680077]
	TIME [epoch: 9.23 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20135538962366267		[learning rate: 0.0015104]
	Learning Rate: 0.00151045
	LOSS [training: 0.20135538962366267 | validation: 0.28798017493625727]
	TIME [epoch: 9.21 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21446518607066292		[learning rate: 0.001505]
	Learning Rate: 0.00150496
	LOSS [training: 0.21446518607066292 | validation: 0.18704304084571025]
	TIME [epoch: 9.22 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23584140746080498		[learning rate: 0.0014995]
	Learning Rate: 0.0014995
	LOSS [training: 0.23584140746080498 | validation: 0.17100267951100218]
	TIME [epoch: 9.22 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21084603937456253		[learning rate: 0.0014941]
	Learning Rate: 0.00149406
	LOSS [training: 0.21084603937456253 | validation: 0.3917616754593739]
	TIME [epoch: 9.23 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22523990556950507		[learning rate: 0.0014886]
	Learning Rate: 0.00148864
	LOSS [training: 0.22523990556950507 | validation: 0.1294696992581144]
	TIME [epoch: 9.23 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19851792066300908		[learning rate: 0.0014832]
	Learning Rate: 0.00148324
	LOSS [training: 0.19851792066300908 | validation: 0.20172118353296145]
	TIME [epoch: 9.21 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2381210779391744		[learning rate: 0.0014779]
	Learning Rate: 0.00147785
	LOSS [training: 0.2381210779391744 | validation: 0.18968976902897292]
	TIME [epoch: 9.21 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24382842398714222		[learning rate: 0.0014725]
	Learning Rate: 0.00147249
	LOSS [training: 0.24382842398714222 | validation: 0.3262988915268751]
	TIME [epoch: 9.21 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2287215987318171		[learning rate: 0.0014671]
	Learning Rate: 0.00146715
	LOSS [training: 0.2287215987318171 | validation: 0.25146057438523417]
	TIME [epoch: 9.26 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34064367681854424		[learning rate: 0.0014618]
	Learning Rate: 0.00146182
	LOSS [training: 0.34064367681854424 | validation: 0.10697269090728147]
	TIME [epoch: 9.21 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21310334096033473		[learning rate: 0.0014565]
	Learning Rate: 0.00145652
	LOSS [training: 0.21310334096033473 | validation: 0.09097521012242318]
	TIME [epoch: 9.21 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r5_20240219_234257/states/model_tr_study204_630.pth
	Model improved!!!
EPOCH 631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22303762398828358		[learning rate: 0.0014512]
	Learning Rate: 0.00145123
	LOSS [training: 0.22303762398828358 | validation: 0.14198086328611892]
	TIME [epoch: 9.21 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20078493136917022		[learning rate: 0.001446]
	Learning Rate: 0.00144597
	LOSS [training: 0.20078493136917022 | validation: 0.13778373166282673]
	TIME [epoch: 9.21 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2724370931093416		[learning rate: 0.0014407]
	Learning Rate: 0.00144072
	LOSS [training: 0.2724370931093416 | validation: 0.18215049954942564]
	TIME [epoch: 9.22 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21248789869013804		[learning rate: 0.0014355]
	Learning Rate: 0.00143549
	LOSS [training: 0.21248789869013804 | validation: 0.14637786323999818]
	TIME [epoch: 9.21 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19014161427344006		[learning rate: 0.0014303]
	Learning Rate: 0.00143028
	LOSS [training: 0.19014161427344006 | validation: 0.14700688079734986]
	TIME [epoch: 9.23 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2566383839561445		[learning rate: 0.0014251]
	Learning Rate: 0.00142509
	LOSS [training: 0.2566383839561445 | validation: 0.19059781882963694]
	TIME [epoch: 9.21 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21019049635540582		[learning rate: 0.0014199]
	Learning Rate: 0.00141992
	LOSS [training: 0.21019049635540582 | validation: 0.1357561891181905]
	TIME [epoch: 9.24 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24727857312185225		[learning rate: 0.0014148]
	Learning Rate: 0.00141476
	LOSS [training: 0.24727857312185225 | validation: 0.15071012861207345]
	TIME [epoch: 9.22 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20043377453285402		[learning rate: 0.0014096]
	Learning Rate: 0.00140963
	LOSS [training: 0.20043377453285402 | validation: 0.13811922695289564]
	TIME [epoch: 9.21 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24842850600208716		[learning rate: 0.0014045]
	Learning Rate: 0.00140451
	LOSS [training: 0.24842850600208716 | validation: 0.28863146407696083]
	TIME [epoch: 9.21 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21093853190848785		[learning rate: 0.0013994]
	Learning Rate: 0.00139942
	LOSS [training: 0.21093853190848785 | validation: 0.11102463617894165]
	TIME [epoch: 9.21 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24859054841764366		[learning rate: 0.0013943]
	Learning Rate: 0.00139434
	LOSS [training: 0.24859054841764366 | validation: 0.21641256757756377]
	TIME [epoch: 9.26 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20522545752478805		[learning rate: 0.0013893]
	Learning Rate: 0.00138928
	LOSS [training: 0.20522545752478805 | validation: 0.1912752418231508]
	TIME [epoch: 9.21 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1719149811983344		[learning rate: 0.0013842]
	Learning Rate: 0.00138424
	LOSS [training: 0.1719149811983344 | validation: 0.13844136524686196]
	TIME [epoch: 9.21 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2302346353032818		[learning rate: 0.0013792]
	Learning Rate: 0.00137921
	LOSS [training: 0.2302346353032818 | validation: 0.1641310746165166]
	TIME [epoch: 9.21 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21772064650184036		[learning rate: 0.0013742]
	Learning Rate: 0.00137421
	LOSS [training: 0.21772064650184036 | validation: 0.1216725467007445]
	TIME [epoch: 9.23 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21703428237938568		[learning rate: 0.0013692]
	Learning Rate: 0.00136922
	LOSS [training: 0.21703428237938568 | validation: 0.2286583378254145]
	TIME [epoch: 9.23 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2754147311660937		[learning rate: 0.0013643]
	Learning Rate: 0.00136425
	LOSS [training: 0.2754147311660937 | validation: 0.17576840572624275]
	TIME [epoch: 9.22 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23076691515786613		[learning rate: 0.0013593]
	Learning Rate: 0.0013593
	LOSS [training: 0.23076691515786613 | validation: 0.15590483225021184]
	TIME [epoch: 9.23 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23732742171172702		[learning rate: 0.0013544]
	Learning Rate: 0.00135437
	LOSS [training: 0.23732742171172702 | validation: 0.1288838388694919]
	TIME [epoch: 9.21 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19110424714592056		[learning rate: 0.0013495]
	Learning Rate: 0.00134945
	LOSS [training: 0.19110424714592056 | validation: 0.16576481382809374]
	TIME [epoch: 9.24 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22731792695889222		[learning rate: 0.0013446]
	Learning Rate: 0.00134456
	LOSS [training: 0.22731792695889222 | validation: 0.15007353186812145]
	TIME [epoch: 9.21 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2132426275618977		[learning rate: 0.0013397]
	Learning Rate: 0.00133968
	LOSS [training: 0.2132426275618977 | validation: 0.16340843056022347]
	TIME [epoch: 9.2 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19647532736791534		[learning rate: 0.0013348]
	Learning Rate: 0.00133481
	LOSS [training: 0.19647532736791534 | validation: 0.09961302550287354]
	TIME [epoch: 9.2 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20154339554698697		[learning rate: 0.00133]
	Learning Rate: 0.00132997
	LOSS [training: 0.20154339554698697 | validation: 0.10764764468201538]
	TIME [epoch: 9.22 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22677692168010605		[learning rate: 0.0013251]
	Learning Rate: 0.00132514
	LOSS [training: 0.22677692168010605 | validation: 0.2365038822502956]
	TIME [epoch: 9.24 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2284765437450813		[learning rate: 0.0013203]
	Learning Rate: 0.00132034
	LOSS [training: 0.2284765437450813 | validation: 0.1281790212248603]
	TIME [epoch: 9.21 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17690920978551622		[learning rate: 0.0013155]
	Learning Rate: 0.00131554
	LOSS [training: 0.17690920978551622 | validation: 0.12392896109813804]
	TIME [epoch: 9.21 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22657889460562824		[learning rate: 0.0013108]
	Learning Rate: 0.00131077
	LOSS [training: 0.22657889460562824 | validation: 0.12276260198704236]
	TIME [epoch: 9.2 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20273343287310466		[learning rate: 0.001306]
	Learning Rate: 0.00130601
	LOSS [training: 0.20273343287310466 | validation: 0.14562885105983958]
	TIME [epoch: 9.23 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21849962016483318		[learning rate: 0.0013013]
	Learning Rate: 0.00130127
	LOSS [training: 0.21849962016483318 | validation: 0.13046315997172497]
	TIME [epoch: 9.21 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18259625409381902		[learning rate: 0.0012966]
	Learning Rate: 0.00129655
	LOSS [training: 0.18259625409381902 | validation: 0.26206059341406185]
	TIME [epoch: 9.21 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2761541500197334		[learning rate: 0.0012918]
	Learning Rate: 0.00129185
	LOSS [training: 0.2761541500197334 | validation: 0.15818926738867545]
	TIME [epoch: 9.22 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22454611553162515		[learning rate: 0.0012872]
	Learning Rate: 0.00128716
	LOSS [training: 0.22454611553162515 | validation: 0.16816691440044523]
	TIME [epoch: 9.23 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1748164000120661		[learning rate: 0.0012825]
	Learning Rate: 0.00128249
	LOSS [training: 0.1748164000120661 | validation: 0.12008501364414645]
	TIME [epoch: 9.24 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20844692897508804		[learning rate: 0.0012778]
	Learning Rate: 0.00127783
	LOSS [training: 0.20844692897508804 | validation: 0.15762492118080484]
	TIME [epoch: 9.2 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23182045616219202		[learning rate: 0.0012732]
	Learning Rate: 0.00127319
	LOSS [training: 0.23182045616219202 | validation: 0.12637904723078378]
	TIME [epoch: 9.2 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18788220375029702		[learning rate: 0.0012686]
	Learning Rate: 0.00126857
	LOSS [training: 0.18788220375029702 | validation: 0.13269376931443494]
	TIME [epoch: 9.2 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24479483622307202		[learning rate: 0.001264]
	Learning Rate: 0.00126397
	LOSS [training: 0.24479483622307202 | validation: 0.15431885676934906]
	TIME [epoch: 9.22 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19776038115470249		[learning rate: 0.0012594]
	Learning Rate: 0.00125938
	LOSS [training: 0.19776038115470249 | validation: 0.20032301672995617]
	TIME [epoch: 9.2 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2101513837480557		[learning rate: 0.0012548]
	Learning Rate: 0.00125481
	LOSS [training: 0.2101513837480557 | validation: 0.20190853053110663]
	TIME [epoch: 9.21 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22229648338074207		[learning rate: 0.0012503]
	Learning Rate: 0.00125026
	LOSS [training: 0.22229648338074207 | validation: 0.22813652898653916]
	TIME [epoch: 9.2 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.206753737064944		[learning rate: 0.0012457]
	Learning Rate: 0.00124572
	LOSS [training: 0.206753737064944 | validation: 0.22744060932170618]
	TIME [epoch: 9.21 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20306377627850036		[learning rate: 0.0012412]
	Learning Rate: 0.0012412
	LOSS [training: 0.20306377627850036 | validation: 0.17864203942732343]
	TIME [epoch: 9.21 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22709220512258024		[learning rate: 0.0012367]
	Learning Rate: 0.0012367
	LOSS [training: 0.22709220512258024 | validation: 0.1495969606409115]
	TIME [epoch: 9.2 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20038582713280567		[learning rate: 0.0012322]
	Learning Rate: 0.00123221
	LOSS [training: 0.20038582713280567 | validation: 0.22210676393402784]
	TIME [epoch: 9.2 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18878451271880517		[learning rate: 0.0012277]
	Learning Rate: 0.00122774
	LOSS [training: 0.18878451271880517 | validation: 0.15435007722170646]
	TIME [epoch: 9.2 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23555611780524816		[learning rate: 0.0012233]
	Learning Rate: 0.00122328
	LOSS [training: 0.23555611780524816 | validation: 0.1716505787887329]
	TIME [epoch: 9.23 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23699450809120962		[learning rate: 0.0012188]
	Learning Rate: 0.00121884
	LOSS [training: 0.23699450809120962 | validation: 0.3477445747062423]
	TIME [epoch: 9.21 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23011718251986452		[learning rate: 0.0012144]
	Learning Rate: 0.00121442
	LOSS [training: 0.23011718251986452 | validation: 0.27512276138087943]
	TIME [epoch: 9.2 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2130786166360883		[learning rate: 0.00121]
	Learning Rate: 0.00121001
	LOSS [training: 0.2130786166360883 | validation: 0.16700382659621696]
	TIME [epoch: 9.2 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20074332262207406		[learning rate: 0.0012056]
	Learning Rate: 0.00120562
	LOSS [training: 0.20074332262207406 | validation: 0.11698007232094222]
	TIME [epoch: 9.21 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1845092393449617		[learning rate: 0.0012012]
	Learning Rate: 0.00120125
	LOSS [training: 0.1845092393449617 | validation: 0.16956910562929656]
	TIME [epoch: 9.22 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18648067084664025		[learning rate: 0.0011969]
	Learning Rate: 0.00119689
	LOSS [training: 0.18648067084664025 | validation: 0.14903946644724245]
	TIME [epoch: 9.2 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2051482988767222		[learning rate: 0.0011925]
	Learning Rate: 0.00119254
	LOSS [training: 0.2051482988767222 | validation: 0.1365991639268598]
	TIME [epoch: 9.2 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28998743424773027		[learning rate: 0.0011882]
	Learning Rate: 0.00118821
	LOSS [training: 0.28998743424773027 | validation: 0.15403107915535674]
	TIME [epoch: 9.21 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20600380652992464		[learning rate: 0.0011839]
	Learning Rate: 0.0011839
	LOSS [training: 0.20600380652992464 | validation: 0.1572482746548287]
	TIME [epoch: 9.22 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19821683727958112		[learning rate: 0.0011796]
	Learning Rate: 0.00117961
	LOSS [training: 0.19821683727958112 | validation: 0.18508461340086685]
	TIME [epoch: 9.2 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1982702551082453		[learning rate: 0.0011753]
	Learning Rate: 0.00117532
	LOSS [training: 0.1982702551082453 | validation: 0.11102522715411198]
	TIME [epoch: 9.19 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2200087859507578		[learning rate: 0.0011711]
	Learning Rate: 0.00117106
	LOSS [training: 0.2200087859507578 | validation: 0.17331056050021673]
	TIME [epoch: 9.2 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20607974814200847		[learning rate: 0.0011668]
	Learning Rate: 0.00116681
	LOSS [training: 0.20607974814200847 | validation: 0.18244050136744688]
	TIME [epoch: 9.2 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1824902588746997		[learning rate: 0.0011626]
	Learning Rate: 0.00116258
	LOSS [training: 0.1824902588746997 | validation: 0.11528066341725937]
	TIME [epoch: 9.21 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21918311385671135		[learning rate: 0.0011584]
	Learning Rate: 0.00115836
	LOSS [training: 0.21918311385671135 | validation: 0.16814826838402003]
	TIME [epoch: 9.21 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19625196753386448		[learning rate: 0.0011542]
	Learning Rate: 0.00115415
	LOSS [training: 0.19625196753386448 | validation: 0.13030552019935082]
	TIME [epoch: 9.2 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17079485725704607		[learning rate: 0.00115]
	Learning Rate: 0.00114996
	LOSS [training: 0.17079485725704607 | validation: 0.12177015643630275]
	TIME [epoch: 9.19 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21112725807798977		[learning rate: 0.0011458]
	Learning Rate: 0.00114579
	LOSS [training: 0.21112725807798977 | validation: 0.1271601456966006]
	TIME [epoch: 9.22 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19078626816451288		[learning rate: 0.0011416]
	Learning Rate: 0.00114163
	LOSS [training: 0.19078626816451288 | validation: 0.25716921686497646]
	TIME [epoch: 9.2 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2694615210114623		[learning rate: 0.0011375]
	Learning Rate: 0.00113749
	LOSS [training: 0.2694615210114623 | validation: 0.21186009176273077]
	TIME [epoch: 9.19 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19453805925074183		[learning rate: 0.0011334]
	Learning Rate: 0.00113336
	LOSS [training: 0.19453805925074183 | validation: 0.2193731984353455]
	TIME [epoch: 9.2 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19297136582695595		[learning rate: 0.0011292]
	Learning Rate: 0.00112925
	LOSS [training: 0.19297136582695595 | validation: 0.1097133141745777]
	TIME [epoch: 9.22 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37883484288311137		[learning rate: 0.0011252]
	Learning Rate: 0.00112515
	LOSS [training: 0.37883484288311137 | validation: 0.2674692235550963]
	TIME [epoch: 9.24 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2157595140121539		[learning rate: 0.0011211]
	Learning Rate: 0.00112107
	LOSS [training: 0.2157595140121539 | validation: 0.20379586589083182]
	TIME [epoch: 9.2 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18225847127192407		[learning rate: 0.001117]
	Learning Rate: 0.001117
	LOSS [training: 0.18225847127192407 | validation: 0.13080280403687206]
	TIME [epoch: 9.2 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18864755478673048		[learning rate: 0.0011129]
	Learning Rate: 0.00111295
	LOSS [training: 0.18864755478673048 | validation: 0.1146254028672283]
	TIME [epoch: 9.2 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18552440436670176		[learning rate: 0.0011089]
	Learning Rate: 0.00110891
	LOSS [training: 0.18552440436670176 | validation: 0.19537825294575553]
	TIME [epoch: 9.23 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2315599161028831		[learning rate: 0.0011049]
	Learning Rate: 0.00110488
	LOSS [training: 0.2315599161028831 | validation: 0.15146427143614732]
	TIME [epoch: 9.21 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17269074744692633		[learning rate: 0.0011009]
	Learning Rate: 0.00110087
	LOSS [training: 0.17269074744692633 | validation: 0.14089325128300434]
	TIME [epoch: 9.2 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2257107645507006		[learning rate: 0.0010969]
	Learning Rate: 0.00109688
	LOSS [training: 0.2257107645507006 | validation: 0.1407925932488372]
	TIME [epoch: 9.2 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2898689422720069		[learning rate: 0.0010929]
	Learning Rate: 0.0010929
	LOSS [training: 0.2898689422720069 | validation: 0.13118649364418639]
	TIME [epoch: 9.22 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1792709638885271		[learning rate: 0.0010889]
	Learning Rate: 0.00108893
	LOSS [training: 0.1792709638885271 | validation: 0.11850245013657554]
	TIME [epoch: 9.23 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1792426149141664		[learning rate: 0.001085]
	Learning Rate: 0.00108498
	LOSS [training: 0.1792426149141664 | validation: 0.1422982232632256]
	TIME [epoch: 9.21 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19499589357830377		[learning rate: 0.001081]
	Learning Rate: 0.00108104
	LOSS [training: 0.19499589357830377 | validation: 0.129585286719083]
	TIME [epoch: 9.21 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17587749125799107		[learning rate: 0.0010771]
	Learning Rate: 0.00107712
	LOSS [training: 0.17587749125799107 | validation: 0.11263100169984139]
	TIME [epoch: 9.22 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2665646690383327		[learning rate: 0.0010732]
	Learning Rate: 0.00107321
	LOSS [training: 0.2665646690383327 | validation: 0.12446662732340272]
	TIME [epoch: 9.24 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.206985911123963		[learning rate: 0.0010693]
	Learning Rate: 0.00106931
	LOSS [training: 0.206985911123963 | validation: 0.11991526980779273]
	TIME [epoch: 9.21 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17273650577277716		[learning rate: 0.0010654]
	Learning Rate: 0.00106543
	LOSS [training: 0.17273650577277716 | validation: 0.15431406958906974]
	TIME [epoch: 9.21 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19893785713258966		[learning rate: 0.0010616]
	Learning Rate: 0.00106157
	LOSS [training: 0.19893785713258966 | validation: 0.222177022671402]
	TIME [epoch: 9.22 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19630644206184963		[learning rate: 0.0010577]
	Learning Rate: 0.00105771
	LOSS [training: 0.19630644206184963 | validation: 0.13110643701577213]
	TIME [epoch: 9.21 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17850835657731562		[learning rate: 0.0010539]
	Learning Rate: 0.00105388
	LOSS [training: 0.17850835657731562 | validation: 0.160850154777992]
	TIME [epoch: 9.24 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25690494228419586		[learning rate: 0.0010501]
	Learning Rate: 0.00105005
	LOSS [training: 0.25690494228419586 | validation: 0.15119133233591903]
	TIME [epoch: 9.21 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18633332903050798		[learning rate: 0.0010462]
	Learning Rate: 0.00104624
	LOSS [training: 0.18633332903050798 | validation: 0.19381544529998518]
	TIME [epoch: 9.21 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19716337256589317		[learning rate: 0.0010424]
	Learning Rate: 0.00104244
	LOSS [training: 0.19716337256589317 | validation: 0.15264786692410487]
	TIME [epoch: 9.21 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24108252536104385		[learning rate: 0.0010387]
	Learning Rate: 0.00103866
	LOSS [training: 0.24108252536104385 | validation: 0.35188977465452875]
	TIME [epoch: 9.23 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26995169855244705		[learning rate: 0.0010349]
	Learning Rate: 0.00103489
	LOSS [training: 0.26995169855244705 | validation: 0.3360347168885086]
	TIME [epoch: 9.22 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2506380596440923		[learning rate: 0.0010311]
	Learning Rate: 0.00103114
	LOSS [training: 0.2506380596440923 | validation: 0.16110299669291783]
	TIME [epoch: 9.23 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17416086899433597		[learning rate: 0.0010274]
	Learning Rate: 0.00102739
	LOSS [training: 0.17416086899433597 | validation: 0.1290237814212811]
	TIME [epoch: 9.21 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18005444717619995		[learning rate: 0.0010237]
	Learning Rate: 0.00102367
	LOSS [training: 0.18005444717619995 | validation: 0.16794129767972732]
	TIME [epoch: 9.22 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18386719524902456		[learning rate: 0.00102]
	Learning Rate: 0.00101995
	LOSS [training: 0.18386719524902456 | validation: 0.20709393813532795]
	TIME [epoch: 9.24 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18770165071534387		[learning rate: 0.0010162]
	Learning Rate: 0.00101625
	LOSS [training: 0.18770165071534387 | validation: 0.15772734056988968]
	TIME [epoch: 9.21 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24484645948814307		[learning rate: 0.0010126]
	Learning Rate: 0.00101256
	LOSS [training: 0.24484645948814307 | validation: 0.11896549913009519]
	TIME [epoch: 9.21 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2524228194075314		[learning rate: 0.0010089]
	Learning Rate: 0.00100889
	LOSS [training: 0.2524228194075314 | validation: 0.1059753690967965]
	TIME [epoch: 9.2 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20601736180532954		[learning rate: 0.0010052]
	Learning Rate: 0.00100522
	LOSS [training: 0.20601736180532954 | validation: 0.12766573895012667]
	TIME [epoch: 9.23 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18120303473691848		[learning rate: 0.0010016]
	Learning Rate: 0.00100158
	LOSS [training: 0.18120303473691848 | validation: 0.13522588791685675]
	TIME [epoch: 9.23 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15606857781383496		[learning rate: 0.00099794]
	Learning Rate: 0.000997942
	LOSS [training: 0.15606857781383496 | validation: 0.17040253028664015]
	TIME [epoch: 9.21 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22487195189134743		[learning rate: 0.00099432]
	Learning Rate: 0.00099432
	LOSS [training: 0.22487195189134743 | validation: 0.15898234615641524]
	TIME [epoch: 9.21 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19815266497122333		[learning rate: 0.00099071]
	Learning Rate: 0.000990712
	LOSS [training: 0.19815266497122333 | validation: 0.12351752037533173]
	TIME [epoch: 9.21 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2207774888581592		[learning rate: 0.00098712]
	Learning Rate: 0.000987116
	LOSS [training: 0.2207774888581592 | validation: 0.17502043870549328]
	TIME [epoch: 9.23 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20942565172500424		[learning rate: 0.00098353]
	Learning Rate: 0.000983534
	LOSS [training: 0.20942565172500424 | validation: 0.19141817281334628]
	TIME [epoch: 9.21 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1765937123723806		[learning rate: 0.00097996]
	Learning Rate: 0.000979965
	LOSS [training: 0.1765937123723806 | validation: 0.39557124613875516]
	TIME [epoch: 9.21 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1962434073082688		[learning rate: 0.00097641]
	Learning Rate: 0.000976409
	LOSS [training: 0.1962434073082688 | validation: 0.1262513098180818]
	TIME [epoch: 9.21 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19384784936287472		[learning rate: 0.00097287]
	Learning Rate: 0.000972865
	LOSS [training: 0.19384784936287472 | validation: 0.15089564843321596]
	TIME [epoch: 9.24 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18680489816464854		[learning rate: 0.00096933]
	Learning Rate: 0.000969335
	LOSS [training: 0.18680489816464854 | validation: 0.1691664230132957]
	TIME [epoch: 9.21 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19641624110089653		[learning rate: 0.00096582]
	Learning Rate: 0.000965817
	LOSS [training: 0.19641624110089653 | validation: 0.13698000341323202]
	TIME [epoch: 9.2 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1849752952026657		[learning rate: 0.00096231]
	Learning Rate: 0.000962312
	LOSS [training: 0.1849752952026657 | validation: 0.15501243490337407]
	TIME [epoch: 9.19 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19450551883123715		[learning rate: 0.00095882]
	Learning Rate: 0.00095882
	LOSS [training: 0.19450551883123715 | validation: 0.1356697154496937]
	TIME [epoch: 9.2 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22114363860657327		[learning rate: 0.00095534]
	Learning Rate: 0.00095534
	LOSS [training: 0.22114363860657327 | validation: 0.19216342375215817]
	TIME [epoch: 9.22 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20455117820752874		[learning rate: 0.00095187]
	Learning Rate: 0.000951873
	LOSS [training: 0.20455117820752874 | validation: 0.15625218551339373]
	TIME [epoch: 9.2 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18854239692276242		[learning rate: 0.00094842]
	Learning Rate: 0.000948419
	LOSS [training: 0.18854239692276242 | validation: 0.16265442328493407]
	TIME [epoch: 9.19 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1567910788434687		[learning rate: 0.00094498]
	Learning Rate: 0.000944977
	LOSS [training: 0.1567910788434687 | validation: 0.17758384352784923]
	TIME [epoch: 9.2 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28935189894309793		[learning rate: 0.00094155]
	Learning Rate: 0.000941547
	LOSS [training: 0.28935189894309793 | validation: 0.24584172257039938]
	TIME [epoch: 9.21 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1995329819920905		[learning rate: 0.00093813]
	Learning Rate: 0.00093813
	LOSS [training: 0.1995329819920905 | validation: 0.24597811284266916]
	TIME [epoch: 9.2 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3383700850294382		[learning rate: 0.00093473]
	Learning Rate: 0.000934726
	LOSS [training: 0.3383700850294382 | validation: 0.1239217922198524]
	TIME [epoch: 9.2 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17886630526954622		[learning rate: 0.00093133]
	Learning Rate: 0.000931334
	LOSS [training: 0.17886630526954622 | validation: 0.20167277695747185]
	TIME [epoch: 9.2 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21043181390717489		[learning rate: 0.00092795]
	Learning Rate: 0.000927954
	LOSS [training: 0.21043181390717489 | validation: 0.22442148440453863]
	TIME [epoch: 9.2 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17030173084057873		[learning rate: 0.00092459]
	Learning Rate: 0.000924586
	LOSS [training: 0.17030173084057873 | validation: 0.10717311482252628]
	TIME [epoch: 9.22 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24284243385081541		[learning rate: 0.00092123]
	Learning Rate: 0.000921231
	LOSS [training: 0.24284243385081541 | validation: 0.1358861731277574]
	TIME [epoch: 9.19 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15871468645389825		[learning rate: 0.00091789]
	Learning Rate: 0.000917888
	LOSS [training: 0.15871468645389825 | validation: 0.11146120096667828]
	TIME [epoch: 9.2 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18626983920985857		[learning rate: 0.00091456]
	Learning Rate: 0.000914556
	LOSS [training: 0.18626983920985857 | validation: 0.15382629047532198]
	TIME [epoch: 9.19 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18760035114844992		[learning rate: 0.00091124]
	Learning Rate: 0.000911237
	LOSS [training: 0.18760035114844992 | validation: 0.16561265946655865]
	TIME [epoch: 9.2 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22345020030636703		[learning rate: 0.00090793]
	Learning Rate: 0.000907931
	LOSS [training: 0.22345020030636703 | validation: 0.1308509468082963]
	TIME [epoch: 9.21 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20355089857792463		[learning rate: 0.00090464]
	Learning Rate: 0.000904636
	LOSS [training: 0.20355089857792463 | validation: 0.2167203314216565]
	TIME [epoch: 9.2 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19948974253072316		[learning rate: 0.00090135]
	Learning Rate: 0.000901353
	LOSS [training: 0.19948974253072316 | validation: 0.11308487781221553]
	TIME [epoch: 9.19 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19183586746054246		[learning rate: 0.00089808]
	Learning Rate: 0.000898082
	LOSS [training: 0.19183586746054246 | validation: 0.11654810487851841]
	TIME [epoch: 9.19 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16153349280815948		[learning rate: 0.00089482]
	Learning Rate: 0.000894822
	LOSS [training: 0.16153349280815948 | validation: 0.23986997045727163]
	TIME [epoch: 9.22 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19472605025986672		[learning rate: 0.00089157]
	Learning Rate: 0.000891575
	LOSS [training: 0.19472605025986672 | validation: 0.1696765870149322]
	TIME [epoch: 9.21 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18851643568670795		[learning rate: 0.00088834]
	Learning Rate: 0.000888339
	LOSS [training: 0.18851643568670795 | validation: 0.11678900068572695]
	TIME [epoch: 9.2 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16032611923166665		[learning rate: 0.00088512]
	Learning Rate: 0.000885116
	LOSS [training: 0.16032611923166665 | validation: 0.140517238399272]
	TIME [epoch: 9.2 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18476685967248332		[learning rate: 0.0008819]
	Learning Rate: 0.000881903
	LOSS [training: 0.18476685967248332 | validation: 0.19323204268256378]
	TIME [epoch: 9.2 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20225001331632217		[learning rate: 0.0008787]
	Learning Rate: 0.000878703
	LOSS [training: 0.20225001331632217 | validation: 0.16113180358048543]
	TIME [epoch: 9.21 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2143124390185755		[learning rate: 0.00087551]
	Learning Rate: 0.000875514
	LOSS [training: 0.2143124390185755 | validation: 0.2096493093414201]
	TIME [epoch: 9.19 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21214941020682443		[learning rate: 0.00087234]
	Learning Rate: 0.000872337
	LOSS [training: 0.21214941020682443 | validation: 0.14747181563020226]
	TIME [epoch: 9.19 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1693159440121896		[learning rate: 0.00086917]
	Learning Rate: 0.000869171
	LOSS [training: 0.1693159440121896 | validation: 0.21103376687078862]
	TIME [epoch: 9.19 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1854241715547576		[learning rate: 0.00086602]
	Learning Rate: 0.000866017
	LOSS [training: 0.1854241715547576 | validation: 0.1665144117972976]
	TIME [epoch: 9.21 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1808947023018764		[learning rate: 0.00086287]
	Learning Rate: 0.000862874
	LOSS [training: 0.1808947023018764 | validation: 0.14104983433552915]
	TIME [epoch: 9.21 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17847604173442574		[learning rate: 0.00085974]
	Learning Rate: 0.000859743
	LOSS [training: 0.17847604173442574 | validation: 0.13749359851788095]
	TIME [epoch: 9.19 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1655717712619603		[learning rate: 0.00085662]
	Learning Rate: 0.000856623
	LOSS [training: 0.1655717712619603 | validation: 0.14842568499962297]
	TIME [epoch: 9.19 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20164471250194493		[learning rate: 0.00085351]
	Learning Rate: 0.000853514
	LOSS [training: 0.20164471250194493 | validation: 0.11025115742368186]
	TIME [epoch: 9.2 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18782615036846126		[learning rate: 0.00085042]
	Learning Rate: 0.000850416
	LOSS [training: 0.18782615036846126 | validation: 0.13671052833831063]
	TIME [epoch: 9.22 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18052046402540156		[learning rate: 0.00084733]
	Learning Rate: 0.00084733
	LOSS [training: 0.18052046402540156 | validation: 0.1536759229375993]
	TIME [epoch: 9.2 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17307561438642335		[learning rate: 0.00084426]
	Learning Rate: 0.000844255
	LOSS [training: 0.17307561438642335 | validation: 0.11261607006498298]
	TIME [epoch: 9.2 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16847941055914897		[learning rate: 0.00084119]
	Learning Rate: 0.000841191
	LOSS [training: 0.16847941055914897 | validation: 0.11913646438817757]
	TIME [epoch: 9.19 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1802525134418967		[learning rate: 0.00083814]
	Learning Rate: 0.000838139
	LOSS [training: 0.1802525134418967 | validation: 0.10937505718091237]
	TIME [epoch: 9.22 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.182996788256678		[learning rate: 0.0008351]
	Learning Rate: 0.000835097
	LOSS [training: 0.182996788256678 | validation: 0.1831703379463853]
	TIME [epoch: 9.2 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18579939921574531		[learning rate: 0.00083207]
	Learning Rate: 0.000832066
	LOSS [training: 0.18579939921574531 | validation: 0.12154276820981103]
	TIME [epoch: 9.2 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17197638742453802		[learning rate: 0.00082905]
	Learning Rate: 0.000829046
	LOSS [training: 0.17197638742453802 | validation: 0.1334557289001033]
	TIME [epoch: 9.2 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1481043620508778		[learning rate: 0.00082604]
	Learning Rate: 0.000826038
	LOSS [training: 0.1481043620508778 | validation: 0.11943785096026434]
	TIME [epoch: 9.21 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1950933979806509		[learning rate: 0.00082304]
	Learning Rate: 0.00082304
	LOSS [training: 0.1950933979806509 | validation: 0.122486477006409]
	TIME [epoch: 9.22 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15738036312087506		[learning rate: 0.00082005]
	Learning Rate: 0.000820053
	LOSS [training: 0.15738036312087506 | validation: 0.12397459096972177]
	TIME [epoch: 9.2 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1797867812114207		[learning rate: 0.00081708]
	Learning Rate: 0.000817077
	LOSS [training: 0.1797867812114207 | validation: 0.14588121950761523]
	TIME [epoch: 9.2 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1627425091478523		[learning rate: 0.00081411]
	Learning Rate: 0.000814112
	LOSS [training: 0.1627425091478523 | validation: 0.17557894175925998]
	TIME [epoch: 9.2 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22944569549425423		[learning rate: 0.00081116]
	Learning Rate: 0.000811158
	LOSS [training: 0.22944569549425423 | validation: 0.11629138328546418]
	TIME [epoch: 9.24 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16325610460695453		[learning rate: 0.00080821]
	Learning Rate: 0.000808214
	LOSS [training: 0.16325610460695453 | validation: 0.1802480081045221]
	TIME [epoch: 9.22 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19019416129756814		[learning rate: 0.00080528]
	Learning Rate: 0.000805281
	LOSS [training: 0.19019416129756814 | validation: 0.12082129794677443]
	TIME [epoch: 9.21 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1926022435937132		[learning rate: 0.00080236]
	Learning Rate: 0.000802358
	LOSS [training: 0.1926022435937132 | validation: 0.10834701400575507]
	TIME [epoch: 9.21 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17220420148606266		[learning rate: 0.00079945]
	Learning Rate: 0.000799447
	LOSS [training: 0.17220420148606266 | validation: 0.12843604160025654]
	TIME [epoch: 9.22 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17001574754107204		[learning rate: 0.00079655]
	Learning Rate: 0.000796545
	LOSS [training: 0.17001574754107204 | validation: 0.20259577351260283]
	TIME [epoch: 9.22 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1889195278810268		[learning rate: 0.00079365]
	Learning Rate: 0.000793655
	LOSS [training: 0.1889195278810268 | validation: 0.2422768720377072]
	TIME [epoch: 9.21 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21064176270742604		[learning rate: 0.00079077]
	Learning Rate: 0.000790775
	LOSS [training: 0.21064176270742604 | validation: 0.11147194469795799]
	TIME [epoch: 9.21 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1686263140584782		[learning rate: 0.0007879]
	Learning Rate: 0.000787905
	LOSS [training: 0.1686263140584782 | validation: 0.1630467125122349]
	TIME [epoch: 9.21 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19678833319876537		[learning rate: 0.00078505]
	Learning Rate: 0.000785045
	LOSS [training: 0.19678833319876537 | validation: 0.11257798322944546]
	TIME [epoch: 9.24 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1705840793140815		[learning rate: 0.0007822]
	Learning Rate: 0.000782196
	LOSS [training: 0.1705840793140815 | validation: 0.1898642928659092]
	TIME [epoch: 9.21 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16924732312570948		[learning rate: 0.00077936]
	Learning Rate: 0.000779358
	LOSS [training: 0.16924732312570948 | validation: 0.11117827396431582]
	TIME [epoch: 9.2 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.173694542644235		[learning rate: 0.00077653]
	Learning Rate: 0.000776529
	LOSS [training: 0.173694542644235 | validation: 0.1943221463891645]
	TIME [epoch: 9.21 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16736783433752603		[learning rate: 0.00077371]
	Learning Rate: 0.000773711
	LOSS [training: 0.16736783433752603 | validation: 0.13202325417738942]
	TIME [epoch: 9.22 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1947979417135806		[learning rate: 0.0007709]
	Learning Rate: 0.000770903
	LOSS [training: 0.1947979417135806 | validation: 0.1203324886800742]
	TIME [epoch: 9.22 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17547441881245315		[learning rate: 0.00076811]
	Learning Rate: 0.000768106
	LOSS [training: 0.17547441881245315 | validation: 0.13723465169761567]
	TIME [epoch: 9.21 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1640698713732377		[learning rate: 0.00076532]
	Learning Rate: 0.000765318
	LOSS [training: 0.1640698713732377 | validation: 0.15710417421533224]
	TIME [epoch: 9.21 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20994027438127877		[learning rate: 0.00076254]
	Learning Rate: 0.000762541
	LOSS [training: 0.20994027438127877 | validation: 0.11843778315860719]
	TIME [epoch: 9.21 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20388376442572512		[learning rate: 0.00075977]
	Learning Rate: 0.000759774
	LOSS [training: 0.20388376442572512 | validation: 0.17492390212207337]
	TIME [epoch: 9.23 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30246886881612634		[learning rate: 0.00075702]
	Learning Rate: 0.000757016
	LOSS [training: 0.30246886881612634 | validation: 0.14167574220614074]
	TIME [epoch: 9.21 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17874354710483015		[learning rate: 0.00075427]
	Learning Rate: 0.000754269
	LOSS [training: 0.17874354710483015 | validation: 0.11525478617504784]
	TIME [epoch: 9.21 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1577621854015076		[learning rate: 0.00075153]
	Learning Rate: 0.000751532
	LOSS [training: 0.1577621854015076 | validation: 0.18231601817251064]
	TIME [epoch: 9.2 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17102299222811274		[learning rate: 0.0007488]
	Learning Rate: 0.000748804
	LOSS [training: 0.17102299222811274 | validation: 0.1412069649976786]
	TIME [epoch: 9.21 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16206991842901125		[learning rate: 0.00074609]
	Learning Rate: 0.000746087
	LOSS [training: 0.16206991842901125 | validation: 0.12902998300946883]
	TIME [epoch: 9.22 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1661808934050693		[learning rate: 0.00074338]
	Learning Rate: 0.000743379
	LOSS [training: 0.1661808934050693 | validation: 0.24450065977028454]
	TIME [epoch: 9.2 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18162645676395806		[learning rate: 0.00074068]
	Learning Rate: 0.000740682
	LOSS [training: 0.18162645676395806 | validation: 0.20850588389203575]
	TIME [epoch: 9.2 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2684027980012795		[learning rate: 0.00073799]
	Learning Rate: 0.000737994
	LOSS [training: 0.2684027980012795 | validation: 0.1264407216917589]
	TIME [epoch: 9.22 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15656914141925699		[learning rate: 0.00073532]
	Learning Rate: 0.000735315
	LOSS [training: 0.15656914141925699 | validation: 0.09968825502615636]
	TIME [epoch: 9.23 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19291075417319342		[learning rate: 0.00073265]
	Learning Rate: 0.000732647
	LOSS [training: 0.19291075417319342 | validation: 0.12677905569081574]
	TIME [epoch: 9.2 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17358556101091002		[learning rate: 0.00072999]
	Learning Rate: 0.000729988
	LOSS [training: 0.17358556101091002 | validation: 0.12618526695362292]
	TIME [epoch: 9.19 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18199904696469243		[learning rate: 0.00072734]
	Learning Rate: 0.000727339
	LOSS [training: 0.18199904696469243 | validation: 0.11583717989427822]
	TIME [epoch: 9.2 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16207555154102815		[learning rate: 0.0007247]
	Learning Rate: 0.000724699
	LOSS [training: 0.16207555154102815 | validation: 0.11220755570555455]
	TIME [epoch: 9.2 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1672565144291839		[learning rate: 0.00072207]
	Learning Rate: 0.000722069
	LOSS [training: 0.1672565144291839 | validation: 0.1261770063882127]
	TIME [epoch: 9.22 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15599317483085642		[learning rate: 0.00071945]
	Learning Rate: 0.000719449
	LOSS [training: 0.15599317483085642 | validation: 0.14946934176930854]
	TIME [epoch: 9.2 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19464896584124622		[learning rate: 0.00071684]
	Learning Rate: 0.000716838
	LOSS [training: 0.19464896584124622 | validation: 0.18150940512666136]
	TIME [epoch: 9.2 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16554450018545158		[learning rate: 0.00071424]
	Learning Rate: 0.000714237
	LOSS [training: 0.16554450018545158 | validation: 0.20145127515062872]
	TIME [epoch: 9.2 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2105770744723531		[learning rate: 0.00071164]
	Learning Rate: 0.000711645
	LOSS [training: 0.2105770744723531 | validation: 0.11282730514053799]
	TIME [epoch: 9.22 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16505906729588105		[learning rate: 0.00070906]
	Learning Rate: 0.000709062
	LOSS [training: 0.16505906729588105 | validation: 0.11426185827144958]
	TIME [epoch: 9.2 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17607602495268532		[learning rate: 0.00070649]
	Learning Rate: 0.000706489
	LOSS [training: 0.17607602495268532 | validation: 0.12557682066551956]
	TIME [epoch: 9.2 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17830894750175066		[learning rate: 0.00070392]
	Learning Rate: 0.000703925
	LOSS [training: 0.17830894750175066 | validation: 0.25773585475600513]
	TIME [epoch: 9.2 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16805191724520857		[learning rate: 0.00070137]
	Learning Rate: 0.00070137
	LOSS [training: 0.16805191724520857 | validation: 0.13417227466779147]
	TIME [epoch: 9.2 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16803183997265536		[learning rate: 0.00069883]
	Learning Rate: 0.000698825
	LOSS [training: 0.16803183997265536 | validation: 0.18017401348144807]
	TIME [epoch: 9.22 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17707676808037826		[learning rate: 0.00069629]
	Learning Rate: 0.000696289
	LOSS [training: 0.17707676808037826 | validation: 0.15815490126273202]
	TIME [epoch: 9.19 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13780286084203502		[learning rate: 0.00069376]
	Learning Rate: 0.000693762
	LOSS [training: 0.13780286084203502 | validation: 0.12002418925705467]
	TIME [epoch: 9.19 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14396237316117177		[learning rate: 0.00069124]
	Learning Rate: 0.000691244
	LOSS [training: 0.14396237316117177 | validation: 0.11847930351785838]
	TIME [epoch: 9.19 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3092722189555713		[learning rate: 0.00068874]
	Learning Rate: 0.000688736
	LOSS [training: 0.3092722189555713 | validation: 0.6169390250445103]
	TIME [epoch: 9.23 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32364623020442046		[learning rate: 0.00068624]
	Learning Rate: 0.000686236
	LOSS [training: 0.32364623020442046 | validation: 0.1610416085826164]
	TIME [epoch: 9.2 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15819992572680308		[learning rate: 0.00068375]
	Learning Rate: 0.000683746
	LOSS [training: 0.15819992572680308 | validation: 0.12706675345862065]
	TIME [epoch: 9.2 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19196077007804724		[learning rate: 0.00068126]
	Learning Rate: 0.000681265
	LOSS [training: 0.19196077007804724 | validation: 0.12003414350513725]
	TIME [epoch: 9.2 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18558048925246137		[learning rate: 0.00067879]
	Learning Rate: 0.000678792
	LOSS [training: 0.18558048925246137 | validation: 0.1885259729239236]
	TIME [epoch: 9.19 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19902963294163828		[learning rate: 0.00067633]
	Learning Rate: 0.000676329
	LOSS [training: 0.19902963294163828 | validation: 0.19601414060533284]
	TIME [epoch: 9.23 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3216879920931086		[learning rate: 0.00067387]
	Learning Rate: 0.000673874
	LOSS [training: 0.3216879920931086 | validation: 0.09706041581256486]
	TIME [epoch: 9.2 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20507700869744325		[learning rate: 0.00067143]
	Learning Rate: 0.000671429
	LOSS [training: 0.20507700869744325 | validation: 0.11766456408941754]
	TIME [epoch: 9.21 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14292447641753844		[learning rate: 0.00066899]
	Learning Rate: 0.000668992
	LOSS [training: 0.14292447641753844 | validation: 0.10529535576779817]
	TIME [epoch: 9.21 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18030116902179802		[learning rate: 0.00066656]
	Learning Rate: 0.000666564
	LOSS [training: 0.18030116902179802 | validation: 0.12117612489545385]
	TIME [epoch: 9.24 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.163442490174797		[learning rate: 0.00066415]
	Learning Rate: 0.000664145
	LOSS [training: 0.163442490174797 | validation: 0.1364886974204363]
	TIME [epoch: 9.21 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2118477103979699		[learning rate: 0.00066174]
	Learning Rate: 0.000661735
	LOSS [training: 0.2118477103979699 | validation: 0.11295316433533106]
	TIME [epoch: 9.21 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1497330224171868		[learning rate: 0.00065933]
	Learning Rate: 0.000659334
	LOSS [training: 0.1497330224171868 | validation: 0.1372278807082271]
	TIME [epoch: 9.2 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17247651645194023		[learning rate: 0.00065694]
	Learning Rate: 0.000656941
	LOSS [training: 0.17247651645194023 | validation: 0.21940351921758477]
	TIME [epoch: 9.21 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18474439968916948		[learning rate: 0.00065456]
	Learning Rate: 0.000654557
	LOSS [training: 0.18474439968916948 | validation: 0.1473674494883972]
	TIME [epoch: 9.23 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17696972814428627		[learning rate: 0.00065218]
	Learning Rate: 0.000652182
	LOSS [training: 0.17696972814428627 | validation: 0.13694829501891384]
	TIME [epoch: 9.2 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21650838719601123		[learning rate: 0.00064981]
	Learning Rate: 0.000649815
	LOSS [training: 0.21650838719601123 | validation: 0.1666592005526804]
	TIME [epoch: 9.21 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1744705282498788		[learning rate: 0.00064746]
	Learning Rate: 0.000647456
	LOSS [training: 0.1744705282498788 | validation: 0.18053392626703824]
	TIME [epoch: 9.2 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17880660444398375		[learning rate: 0.00064511]
	Learning Rate: 0.000645107
	LOSS [training: 0.17880660444398375 | validation: 0.13949445302979907]
	TIME [epoch: 9.23 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18501018557455817		[learning rate: 0.00064277]
	Learning Rate: 0.000642766
	LOSS [training: 0.18501018557455817 | validation: 0.1362285121543702]
	TIME [epoch: 9.21 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17070357708102377		[learning rate: 0.00064043]
	Learning Rate: 0.000640433
	LOSS [training: 0.17070357708102377 | validation: 0.1255601898265921]
	TIME [epoch: 9.2 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15865957665986866		[learning rate: 0.00063811]
	Learning Rate: 0.000638109
	LOSS [training: 0.15865957665986866 | validation: 0.18488879188841487]
	TIME [epoch: 9.21 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18125301754440837		[learning rate: 0.00063579]
	Learning Rate: 0.000635793
	LOSS [training: 0.18125301754440837 | validation: 0.137058013941304]
	TIME [epoch: 9.21 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1709002957124905		[learning rate: 0.00063349]
	Learning Rate: 0.000633486
	LOSS [training: 0.1709002957124905 | validation: 0.13286540841772504]
	TIME [epoch: 9.23 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1973485486790343		[learning rate: 0.00063119]
	Learning Rate: 0.000631187
	LOSS [training: 0.1973485486790343 | validation: 0.22656439334554423]
	TIME [epoch: 9.2 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1486903318004154		[learning rate: 0.0006289]
	Learning Rate: 0.000628896
	LOSS [training: 0.1486903318004154 | validation: 0.13839992985070385]
	TIME [epoch: 9.2 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14359234753789066		[learning rate: 0.00062661]
	Learning Rate: 0.000626614
	LOSS [training: 0.14359234753789066 | validation: 0.14080028311442994]
	TIME [epoch: 9.2 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22915511420658086		[learning rate: 0.00062434]
	Learning Rate: 0.00062434
	LOSS [training: 0.22915511420658086 | validation: 0.1318061483508376]
	TIME [epoch: 9.22 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1647974233805855		[learning rate: 0.00062207]
	Learning Rate: 0.000622074
	LOSS [training: 0.1647974233805855 | validation: 0.10914708001688928]
	TIME [epoch: 9.22 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15661110395585265		[learning rate: 0.00061982]
	Learning Rate: 0.000619816
	LOSS [training: 0.15661110395585265 | validation: 0.11434906264787417]
	TIME [epoch: 9.2 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16433975691508146		[learning rate: 0.00061757]
	Learning Rate: 0.000617567
	LOSS [training: 0.16433975691508146 | validation: 0.1311127435120279]
	TIME [epoch: 9.2 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17615725821673606		[learning rate: 0.00061533]
	Learning Rate: 0.000615326
	LOSS [training: 0.17615725821673606 | validation: 0.08983261334804471]
	TIME [epoch: 9.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r5_20240219_234257/states/model_tr_study204_867.pth
	Model improved!!!
EPOCH 868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17422696768270912		[learning rate: 0.00061309]
	Learning Rate: 0.000613093
	LOSS [training: 0.17422696768270912 | validation: 0.16918286350884884]
	TIME [epoch: 9.23 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14682554077754614		[learning rate: 0.00061087]
	Learning Rate: 0.000610868
	LOSS [training: 0.14682554077754614 | validation: 0.11628103431566733]
	TIME [epoch: 9.2 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16097840599639096		[learning rate: 0.00060865]
	Learning Rate: 0.000608651
	LOSS [training: 0.16097840599639096 | validation: 0.19016411346266043]
	TIME [epoch: 9.21 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15729345672760953		[learning rate: 0.00060644]
	Learning Rate: 0.000606442
	LOSS [training: 0.15729345672760953 | validation: 0.10786839291898001]
	TIME [epoch: 9.2 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21675067997516123		[learning rate: 0.00060424]
	Learning Rate: 0.000604242
	LOSS [training: 0.21675067997516123 | validation: 0.12995861252788624]
	TIME [epoch: 9.22 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17407958839778348		[learning rate: 0.00060205]
	Learning Rate: 0.000602049
	LOSS [training: 0.17407958839778348 | validation: 0.16785015725017383]
	TIME [epoch: 9.23 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1647544211450471		[learning rate: 0.00059986]
	Learning Rate: 0.000599864
	LOSS [training: 0.1647544211450471 | validation: 0.12551206467049786]
	TIME [epoch: 9.2 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14811060216203614		[learning rate: 0.00059769]
	Learning Rate: 0.000597687
	LOSS [training: 0.14811060216203614 | validation: 0.18641527070774672]
	TIME [epoch: 9.2 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16741958094059423		[learning rate: 0.00059552]
	Learning Rate: 0.000595518
	LOSS [training: 0.16741958094059423 | validation: 0.1134697753405012]
	TIME [epoch: 9.2 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21939717784958815		[learning rate: 0.00059336]
	Learning Rate: 0.000593357
	LOSS [training: 0.21939717784958815 | validation: 0.37232380714307833]
	TIME [epoch: 9.22 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19582602560292822		[learning rate: 0.0005912]
	Learning Rate: 0.000591203
	LOSS [training: 0.19582602560292822 | validation: 0.14147066943965841]
	TIME [epoch: 9.2 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16749014611236024		[learning rate: 0.00058906]
	Learning Rate: 0.000589058
	LOSS [training: 0.16749014611236024 | validation: 0.1810608929885807]
	TIME [epoch: 9.2 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16728940092623604		[learning rate: 0.00058692]
	Learning Rate: 0.00058692
	LOSS [training: 0.16728940092623604 | validation: 0.14806489763779845]
	TIME [epoch: 9.2 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18874957577969015		[learning rate: 0.00058479]
	Learning Rate: 0.00058479
	LOSS [training: 0.18874957577969015 | validation: 0.14915319314529507]
	TIME [epoch: 9.2 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1669771827387472		[learning rate: 0.00058267]
	Learning Rate: 0.000582668
	LOSS [training: 0.1669771827387472 | validation: 0.11211143595694992]
	TIME [epoch: 9.25 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18741096992075204		[learning rate: 0.00058055]
	Learning Rate: 0.000580553
	LOSS [training: 0.18741096992075204 | validation: 0.14056005740898248]
	TIME [epoch: 9.21 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16276486787617753		[learning rate: 0.00057845]
	Learning Rate: 0.000578446
	LOSS [training: 0.16276486787617753 | validation: 0.16883152653193817]
	TIME [epoch: 9.21 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17865141328009068		[learning rate: 0.00057635]
	Learning Rate: 0.000576347
	LOSS [training: 0.17865141328009068 | validation: 0.13335535887379552]
	TIME [epoch: 9.2 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18615262714715314		[learning rate: 0.00057426]
	Learning Rate: 0.000574256
	LOSS [training: 0.18615262714715314 | validation: 0.144491190764507]
	TIME [epoch: 9.22 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16592436362616073		[learning rate: 0.00057217]
	Learning Rate: 0.000572172
	LOSS [training: 0.16592436362616073 | validation: 0.14041443466249018]
	TIME [epoch: 9.21 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18252906362405613		[learning rate: 0.0005701]
	Learning Rate: 0.000570095
	LOSS [training: 0.18252906362405613 | validation: 0.28597242962528613]
	TIME [epoch: 9.2 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19601905720405974		[learning rate: 0.00056803]
	Learning Rate: 0.000568026
	LOSS [training: 0.19601905720405974 | validation: 0.12456421013196561]
	TIME [epoch: 9.2 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17870048378927153		[learning rate: 0.00056596]
	Learning Rate: 0.000565965
	LOSS [training: 0.17870048378927153 | validation: 0.15305875952694137]
	TIME [epoch: 9.2 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20249006451668877		[learning rate: 0.00056391]
	Learning Rate: 0.000563911
	LOSS [training: 0.20249006451668877 | validation: 0.13563027869158029]
	TIME [epoch: 9.22 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18323692296428423		[learning rate: 0.00056186]
	Learning Rate: 0.000561864
	LOSS [training: 0.18323692296428423 | validation: 0.13969245052816492]
	TIME [epoch: 9.21 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16698420985492216		[learning rate: 0.00055983]
	Learning Rate: 0.000559825
	LOSS [training: 0.16698420985492216 | validation: 0.13685639444356382]
	TIME [epoch: 9.2 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15905722928677052		[learning rate: 0.00055779]
	Learning Rate: 0.000557794
	LOSS [training: 0.15905722928677052 | validation: 0.17813557199106453]
	TIME [epoch: 9.2 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15531309763516649		[learning rate: 0.00055577]
	Learning Rate: 0.00055577
	LOSS [training: 0.15531309763516649 | validation: 0.1428262675653592]
	TIME [epoch: 9.21 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19023655959776517		[learning rate: 0.00055375]
	Learning Rate: 0.000553753
	LOSS [training: 0.19023655959776517 | validation: 0.2362239464140571]
	TIME [epoch: 9.22 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23654129886186492		[learning rate: 0.00055174]
	Learning Rate: 0.000551743
	LOSS [training: 0.23654129886186492 | validation: 0.1587165946391502]
	TIME [epoch: 9.2 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19284897446868268		[learning rate: 0.00054974]
	Learning Rate: 0.000549741
	LOSS [training: 0.19284897446868268 | validation: 0.10487762073833595]
	TIME [epoch: 9.19 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15125408288682568		[learning rate: 0.00054775]
	Learning Rate: 0.000547746
	LOSS [training: 0.15125408288682568 | validation: 0.09536709638567817]
	TIME [epoch: 9.2 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1482832039778393		[learning rate: 0.00054576]
	Learning Rate: 0.000545758
	LOSS [training: 0.1482832039778393 | validation: 0.12945385619841437]
	TIME [epoch: 9.23 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14643170741924263		[learning rate: 0.00054378]
	Learning Rate: 0.000543777
	LOSS [training: 0.14643170741924263 | validation: 0.1496903514490584]
	TIME [epoch: 9.2 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20261076941511552		[learning rate: 0.0005418]
	Learning Rate: 0.000541804
	LOSS [training: 0.20261076941511552 | validation: 0.15167419550654127]
	TIME [epoch: 9.22 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1733291309651563		[learning rate: 0.00053984]
	Learning Rate: 0.000539838
	LOSS [training: 0.1733291309651563 | validation: 0.15421397150643396]
	TIME [epoch: 9.2 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.176380300807048		[learning rate: 0.00053788]
	Learning Rate: 0.000537879
	LOSS [training: 0.176380300807048 | validation: 0.09275349555219888]
	TIME [epoch: 9.2 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1783737391751635		[learning rate: 0.00053593]
	Learning Rate: 0.000535926
	LOSS [training: 0.1783737391751635 | validation: 0.1530151321159589]
	TIME [epoch: 9.21 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1590398619471506		[learning rate: 0.00053398]
	Learning Rate: 0.000533982
	LOSS [training: 0.1590398619471506 | validation: 0.15619891195438648]
	TIME [epoch: 9.19 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1667791350534113		[learning rate: 0.00053204]
	Learning Rate: 0.000532044
	LOSS [training: 0.1667791350534113 | validation: 0.1516010942334784]
	TIME [epoch: 9.21 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.170281475375198		[learning rate: 0.00053011]
	Learning Rate: 0.000530113
	LOSS [training: 0.170281475375198 | validation: 0.19339943812799926]
	TIME [epoch: 9.21 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15607231634677185		[learning rate: 0.00052819]
	Learning Rate: 0.000528189
	LOSS [training: 0.15607231634677185 | validation: 0.12215719959589177]
	TIME [epoch: 9.24 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14438652257741563		[learning rate: 0.00052627]
	Learning Rate: 0.000526272
	LOSS [training: 0.14438652257741563 | validation: 0.11621183694247889]
	TIME [epoch: 9.21 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14832946303149983		[learning rate: 0.00052436]
	Learning Rate: 0.000524362
	LOSS [training: 0.14832946303149983 | validation: 0.11892642181313763]
	TIME [epoch: 9.22 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2078309967191665		[learning rate: 0.00052246]
	Learning Rate: 0.00052246
	LOSS [training: 0.2078309967191665 | validation: 0.16892023760169617]
	TIME [epoch: 9.21 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1765148404767046		[learning rate: 0.00052056]
	Learning Rate: 0.000520563
	LOSS [training: 0.1765148404767046 | validation: 0.14223029414492688]
	TIME [epoch: 9.21 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15820446441826458		[learning rate: 0.00051867]
	Learning Rate: 0.000518674
	LOSS [training: 0.15820446441826458 | validation: 0.14762776013921092]
	TIME [epoch: 9.22 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13981504712188034		[learning rate: 0.00051679]
	Learning Rate: 0.000516792
	LOSS [training: 0.13981504712188034 | validation: 0.10792740288714853]
	TIME [epoch: 9.2 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15892582843566466		[learning rate: 0.00051492]
	Learning Rate: 0.000514917
	LOSS [training: 0.15892582843566466 | validation: 0.11925649803184463]
	TIME [epoch: 9.21 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1825026667851005		[learning rate: 0.00051305]
	Learning Rate: 0.000513048
	LOSS [training: 0.1825026667851005 | validation: 0.1461442130935432]
	TIME [epoch: 9.19 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.178461491997912		[learning rate: 0.00051119]
	Learning Rate: 0.000511186
	LOSS [training: 0.178461491997912 | validation: 0.10009175531221648]
	TIME [epoch: 9.22 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14663434500949063		[learning rate: 0.00050933]
	Learning Rate: 0.000509331
	LOSS [training: 0.14663434500949063 | validation: 0.14715978749594258]
	TIME [epoch: 9.2 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15365201969608083		[learning rate: 0.00050748]
	Learning Rate: 0.000507483
	LOSS [training: 0.15365201969608083 | validation: 0.12745373017273434]
	TIME [epoch: 9.19 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1738801254720002		[learning rate: 0.00050564]
	Learning Rate: 0.000505641
	LOSS [training: 0.1738801254720002 | validation: 0.12863321081150983]
	TIME [epoch: 9.22 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17470580284214693		[learning rate: 0.00050381]
	Learning Rate: 0.000503806
	LOSS [training: 0.17470580284214693 | validation: 0.09336354822881221]
	TIME [epoch: 9.21 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19019743665243713		[learning rate: 0.00050198]
	Learning Rate: 0.000501977
	LOSS [training: 0.19019743665243713 | validation: 0.11621072836987727]
	TIME [epoch: 9.22 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13972301355544944		[learning rate: 0.00050016]
	Learning Rate: 0.000500156
	LOSS [training: 0.13972301355544944 | validation: 0.12004426436424523]
	TIME [epoch: 9.2 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14496038401437183		[learning rate: 0.00049834]
	Learning Rate: 0.000498341
	LOSS [training: 0.14496038401437183 | validation: 0.11231418947587254]
	TIME [epoch: 9.19 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1528594256798272		[learning rate: 0.00049653]
	Learning Rate: 0.000496532
	LOSS [training: 0.1528594256798272 | validation: 0.1616044106883067]
	TIME [epoch: 9.19 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17986943144211567		[learning rate: 0.00049473]
	Learning Rate: 0.00049473
	LOSS [training: 0.17986943144211567 | validation: 0.2188258197418585]
	TIME [epoch: 9.22 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1554820283027508		[learning rate: 0.00049293]
	Learning Rate: 0.000492935
	LOSS [training: 0.1554820283027508 | validation: 0.14423383844272808]
	TIME [epoch: 9.2 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17466920250920387		[learning rate: 0.00049115]
	Learning Rate: 0.000491146
	LOSS [training: 0.17466920250920387 | validation: 0.17969701311774866]
	TIME [epoch: 9.19 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16098827324296278		[learning rate: 0.00048936]
	Learning Rate: 0.000489364
	LOSS [training: 0.16098827324296278 | validation: 0.10044352823552435]
	TIME [epoch: 9.2 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20984709633611504		[learning rate: 0.00048759]
	Learning Rate: 0.000487588
	LOSS [training: 0.20984709633611504 | validation: 0.1053009067356786]
	TIME [epoch: 9.22 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15175939982663886		[learning rate: 0.00048582]
	Learning Rate: 0.000485818
	LOSS [training: 0.15175939982663886 | validation: 0.11893240732375787]
	TIME [epoch: 9.21 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15243462927694598		[learning rate: 0.00048406]
	Learning Rate: 0.000484055
	LOSS [training: 0.15243462927694598 | validation: 0.11720052756860738]
	TIME [epoch: 9.2 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14415183841432394		[learning rate: 0.0004823]
	Learning Rate: 0.000482298
	LOSS [training: 0.14415183841432394 | validation: 0.1661216097773452]
	TIME [epoch: 9.2 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1561554496293998		[learning rate: 0.00048055]
	Learning Rate: 0.000480548
	LOSS [training: 0.1561554496293998 | validation: 0.11830090078273411]
	TIME [epoch: 9.2 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1407465446969938		[learning rate: 0.0004788]
	Learning Rate: 0.000478804
	LOSS [training: 0.1407465446969938 | validation: 0.1275248383887202]
	TIME [epoch: 9.22 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18991065839225538		[learning rate: 0.00047707]
	Learning Rate: 0.000477067
	LOSS [training: 0.18991065839225538 | validation: 0.15359604295071277]
	TIME [epoch: 9.2 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21517981282838558		[learning rate: 0.00047534]
	Learning Rate: 0.000475335
	LOSS [training: 0.21517981282838558 | validation: 0.14281437651027754]
	TIME [epoch: 9.2 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15249089335775728		[learning rate: 0.00047361]
	Learning Rate: 0.00047361
	LOSS [training: 0.15249089335775728 | validation: 0.10571436006163984]
	TIME [epoch: 9.19 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14812185451444412		[learning rate: 0.00047189]
	Learning Rate: 0.000471891
	LOSS [training: 0.14812185451444412 | validation: 0.09458409391538941]
	TIME [epoch: 9.2 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16114248817830729		[learning rate: 0.00047018]
	Learning Rate: 0.000470179
	LOSS [training: 0.16114248817830729 | validation: 0.12029439039719633]
	TIME [epoch: 9.21 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15999867708511123		[learning rate: 0.00046847]
	Learning Rate: 0.000468473
	LOSS [training: 0.15999867708511123 | validation: 0.3493891448759086]
	TIME [epoch: 9.21 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20580708612295112		[learning rate: 0.00046677]
	Learning Rate: 0.000466773
	LOSS [training: 0.20580708612295112 | validation: 0.10261033065338544]
	TIME [epoch: 9.19 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13539287076637374		[learning rate: 0.00046508]
	Learning Rate: 0.000465079
	LOSS [training: 0.13539287076637374 | validation: 0.10837402017264375]
	TIME [epoch: 9.2 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1926358203524481		[learning rate: 0.00046339]
	Learning Rate: 0.000463391
	LOSS [training: 0.1926358203524481 | validation: 0.13471997211074965]
	TIME [epoch: 9.22 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15018553120830008		[learning rate: 0.00046171]
	Learning Rate: 0.000461709
	LOSS [training: 0.15018553120830008 | validation: 0.10705823668080416]
	TIME [epoch: 9.2 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1368494651500815		[learning rate: 0.00046003]
	Learning Rate: 0.000460034
	LOSS [training: 0.1368494651500815 | validation: 0.10804105492784091]
	TIME [epoch: 9.21 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13655886214239904		[learning rate: 0.00045836]
	Learning Rate: 0.000458364
	LOSS [training: 0.13655886214239904 | validation: 0.09513827551042019]
	TIME [epoch: 9.2 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15672968527514575		[learning rate: 0.0004567]
	Learning Rate: 0.000456701
	LOSS [training: 0.15672968527514575 | validation: 0.14904596367336248]
	TIME [epoch: 9.21 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19576180607930543		[learning rate: 0.00045504]
	Learning Rate: 0.000455043
	LOSS [training: 0.19576180607930543 | validation: 0.11235288299763604]
	TIME [epoch: 9.21 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13766961559379315		[learning rate: 0.00045339]
	Learning Rate: 0.000453392
	LOSS [training: 0.13766961559379315 | validation: 0.11787721833417988]
	TIME [epoch: 9.19 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15909705685291908		[learning rate: 0.00045175]
	Learning Rate: 0.000451746
	LOSS [training: 0.15909705685291908 | validation: 0.10328454845111695]
	TIME [epoch: 9.21 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14955886488002448		[learning rate: 0.00045011]
	Learning Rate: 0.000450107
	LOSS [training: 0.14955886488002448 | validation: 0.10130394350572264]
	TIME [epoch: 9.2 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17276232075921624		[learning rate: 0.00044847]
	Learning Rate: 0.000448474
	LOSS [training: 0.17276232075921624 | validation: 0.12858651855939085]
	TIME [epoch: 9.23 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16171983475921212		[learning rate: 0.00044685]
	Learning Rate: 0.000446846
	LOSS [training: 0.16171983475921212 | validation: 0.12133273844530304]
	TIME [epoch: 9.2 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1610503319689393		[learning rate: 0.00044522]
	Learning Rate: 0.000445224
	LOSS [training: 0.1610503319689393 | validation: 0.13331279372578408]
	TIME [epoch: 9.2 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1623468488055579		[learning rate: 0.00044361]
	Learning Rate: 0.000443609
	LOSS [training: 0.1623468488055579 | validation: 0.11212724446252284]
	TIME [epoch: 9.19 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15240190686647845		[learning rate: 0.000442]
	Learning Rate: 0.000441999
	LOSS [training: 0.15240190686647845 | validation: 0.12125779352494696]
	TIME [epoch: 9.2 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15287782876923883		[learning rate: 0.00044039]
	Learning Rate: 0.000440395
	LOSS [training: 0.15287782876923883 | validation: 0.12075751108329673]
	TIME [epoch: 9.22 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15754639216708718		[learning rate: 0.0004388]
	Learning Rate: 0.000438797
	LOSS [training: 0.15754639216708718 | validation: 0.08805284691176724]
	TIME [epoch: 9.21 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r5_20240219_234257/states/model_tr_study204_960.pth
	Model improved!!!
EPOCH 961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14951407177243864		[learning rate: 0.0004372]
	Learning Rate: 0.000437204
	LOSS [training: 0.14951407177243864 | validation: 0.12151263075218899]
	TIME [epoch: 9.22 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16158681795260693		[learning rate: 0.00043562]
	Learning Rate: 0.000435617
	LOSS [training: 0.16158681795260693 | validation: 0.13204322461079412]
	TIME [epoch: 9.21 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1670500289828689		[learning rate: 0.00043404]
	Learning Rate: 0.000434037
	LOSS [training: 0.1670500289828689 | validation: 0.11345366201012387]
	TIME [epoch: 9.21 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15491333886975925		[learning rate: 0.00043246]
	Learning Rate: 0.000432461
	LOSS [training: 0.15491333886975925 | validation: 0.1500644187236455]
	TIME [epoch: 9.2 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16278968212332495		[learning rate: 0.00043089]
	Learning Rate: 0.000430892
	LOSS [training: 0.16278968212332495 | validation: 0.13011913933900415]
	TIME [epoch: 9.2 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15135924578168353		[learning rate: 0.00042933]
	Learning Rate: 0.000429328
	LOSS [training: 0.15135924578168353 | validation: 0.1481395581401287]
	TIME [epoch: 9.2 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1506093919206439		[learning rate: 0.00042777]
	Learning Rate: 0.00042777
	LOSS [training: 0.1506093919206439 | validation: 0.12225141578054635]
	TIME [epoch: 9.2 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1588186236559515		[learning rate: 0.00042622]
	Learning Rate: 0.000426218
	LOSS [training: 0.1588186236559515 | validation: 0.11647146524414184]
	TIME [epoch: 9.21 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16087103658808874		[learning rate: 0.00042467]
	Learning Rate: 0.000424671
	LOSS [training: 0.16087103658808874 | validation: 0.11820209250499168]
	TIME [epoch: 9.2 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13076045808145417		[learning rate: 0.00042313]
	Learning Rate: 0.00042313
	LOSS [training: 0.13076045808145417 | validation: 0.194557364966287]
	TIME [epoch: 9.19 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16283263026623462		[learning rate: 0.00042159]
	Learning Rate: 0.000421594
	LOSS [training: 0.16283263026623462 | validation: 0.10531199946905918]
	TIME [epoch: 9.2 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15241790536488534		[learning rate: 0.00042006]
	Learning Rate: 0.000420064
	LOSS [training: 0.15241790536488534 | validation: 0.1498436830777093]
	TIME [epoch: 9.22 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17016036255152484		[learning rate: 0.00041854]
	Learning Rate: 0.00041854
	LOSS [training: 0.17016036255152484 | validation: 0.16933993128635577]
	TIME [epoch: 9.23 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14974500092005918		[learning rate: 0.00041702]
	Learning Rate: 0.000417021
	LOSS [training: 0.14974500092005918 | validation: 0.2675044905632471]
	TIME [epoch: 9.2 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16937856011185443		[learning rate: 0.00041551]
	Learning Rate: 0.000415508
	LOSS [training: 0.16937856011185443 | validation: 0.1284314149826929]
	TIME [epoch: 9.21 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15536867387562442		[learning rate: 0.000414]
	Learning Rate: 0.000414
	LOSS [training: 0.15536867387562442 | validation: 0.10396497181283178]
	TIME [epoch: 9.19 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15309797512369896		[learning rate: 0.0004125]
	Learning Rate: 0.000412497
	LOSS [training: 0.15309797512369896 | validation: 0.11538355308816603]
	TIME [epoch: 9.21 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14837661612864209		[learning rate: 0.000411]
	Learning Rate: 0.000411
	LOSS [training: 0.14837661612864209 | validation: 0.1050119461243742]
	TIME [epoch: 9.2 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15672979195490364		[learning rate: 0.00040951]
	Learning Rate: 0.000409509
	LOSS [training: 0.15672979195490364 | validation: 0.10465596306227799]
	TIME [epoch: 9.2 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15039978798474757		[learning rate: 0.00040802]
	Learning Rate: 0.000408023
	LOSS [training: 0.15039978798474757 | validation: 0.13029644974710491]
	TIME [epoch: 9.19 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13417812938731144		[learning rate: 0.00040654]
	Learning Rate: 0.000406542
	LOSS [training: 0.13417812938731144 | validation: 0.09135086750837774]
	TIME [epoch: 9.2 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15065388412069575		[learning rate: 0.00040507]
	Learning Rate: 0.000405067
	LOSS [training: 0.15065388412069575 | validation: 0.12017718843522751]
	TIME [epoch: 9.22 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1475148470134457		[learning rate: 0.0004036]
	Learning Rate: 0.000403597
	LOSS [training: 0.1475148470134457 | validation: 0.11429171648648558]
	TIME [epoch: 9.2 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15596934432762014		[learning rate: 0.00040213]
	Learning Rate: 0.000402132
	LOSS [training: 0.15596934432762014 | validation: 0.13530165646638048]
	TIME [epoch: 9.2 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16663756296682797		[learning rate: 0.00040067]
	Learning Rate: 0.000400672
	LOSS [training: 0.16663756296682797 | validation: 0.11947580319462009]
	TIME [epoch: 9.19 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1604156285837024		[learning rate: 0.00039922]
	Learning Rate: 0.000399218
	LOSS [training: 0.1604156285837024 | validation: 0.1185865010162153]
	TIME [epoch: 9.23 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15615727165217405		[learning rate: 0.00039777]
	Learning Rate: 0.00039777
	LOSS [training: 0.15615727165217405 | validation: 0.11955623906746624]
	TIME [epoch: 9.2 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16404976092215381		[learning rate: 0.00039633]
	Learning Rate: 0.000396326
	LOSS [training: 0.16404976092215381 | validation: 0.13064722890267813]
	TIME [epoch: 9.2 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.158472597607711		[learning rate: 0.00039489]
	Learning Rate: 0.000394888
	LOSS [training: 0.158472597607711 | validation: 0.1283898967330956]
	TIME [epoch: 9.2 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15502680378016592		[learning rate: 0.00039345]
	Learning Rate: 0.000393455
	LOSS [training: 0.15502680378016592 | validation: 0.11706227273985922]
	TIME [epoch: 9.2 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15546034514853166		[learning rate: 0.00039203]
	Learning Rate: 0.000392027
	LOSS [training: 0.15546034514853166 | validation: 0.12373973832729825]
	TIME [epoch: 9.22 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1455051303859887		[learning rate: 0.0003906]
	Learning Rate: 0.000390604
	LOSS [training: 0.1455051303859887 | validation: 0.10822169286553074]
	TIME [epoch: 9.2 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15015108038724512		[learning rate: 0.00038919]
	Learning Rate: 0.000389187
	LOSS [training: 0.15015108038724512 | validation: 0.11761905455774266]
	TIME [epoch: 9.2 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15236522566276914		[learning rate: 0.00038777]
	Learning Rate: 0.000387774
	LOSS [training: 0.15236522566276914 | validation: 0.2180974660040439]
	TIME [epoch: 9.21 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20325949598917942		[learning rate: 0.00038637]
	Learning Rate: 0.000386367
	LOSS [training: 0.20325949598917942 | validation: 0.1559293456739683]
	TIME [epoch: 9.22 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14718038787591547		[learning rate: 0.00038496]
	Learning Rate: 0.000384965
	LOSS [training: 0.14718038787591547 | validation: 0.13434795787617132]
	TIME [epoch: 9.2 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16701642561673907		[learning rate: 0.00038357]
	Learning Rate: 0.000383568
	LOSS [training: 0.16701642561673907 | validation: 0.26204314425090747]
	TIME [epoch: 9.2 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17758489805517294		[learning rate: 0.00038218]
	Learning Rate: 0.000382176
	LOSS [training: 0.17758489805517294 | validation: 0.14631707402782387]
	TIME [epoch: 9.21 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14151390719029872		[learning rate: 0.00038079]
	Learning Rate: 0.000380789
	LOSS [training: 0.14151390719029872 | validation: 0.10212179473063213]
	TIME [epoch: 9.2 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1458114513459235		[learning rate: 0.00037941]
	Learning Rate: 0.000379407
	LOSS [training: 0.1458114513459235 | validation: 0.13703511671099486]
	TIME [epoch: 9.23 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15057258063817489		[learning rate: 0.00037803]
	Learning Rate: 0.00037803
	LOSS [training: 0.15057258063817489 | validation: 0.10336412550382104]
	TIME [epoch: 9.2 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14042220848586415		[learning rate: 0.00037666]
	Learning Rate: 0.000376658
	LOSS [training: 0.14042220848586415 | validation: 0.11248806188851113]
	TIME [epoch: 9.2 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15156027923481344		[learning rate: 0.00037529]
	Learning Rate: 0.000375291
	LOSS [training: 0.15156027923481344 | validation: 0.1177505359739255]
	TIME [epoch: 9.2 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1790829778044532		[learning rate: 0.00037393]
	Learning Rate: 0.000373929
	LOSS [training: 0.1790829778044532 | validation: 0.37658883690990974]
	TIME [epoch: 9.22 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2296267920682359		[learning rate: 0.00037257]
	Learning Rate: 0.000372572
	LOSS [training: 0.2296267920682359 | validation: 0.0988702831485842]
	TIME [epoch: 9.19 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1516168905920457		[learning rate: 0.00037122]
	Learning Rate: 0.00037122
	LOSS [training: 0.1516168905920457 | validation: 0.1445372880139425]
	TIME [epoch: 9.2 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1408891003155439		[learning rate: 0.00036987]
	Learning Rate: 0.000369873
	LOSS [training: 0.1408891003155439 | validation: 0.10898442834070698]
	TIME [epoch: 9.2 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13395303204508363		[learning rate: 0.00036853]
	Learning Rate: 0.000368531
	LOSS [training: 0.13395303204508363 | validation: 0.1164048899120215]
	TIME [epoch: 9.2 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14608710961983945		[learning rate: 0.00036719]
	Learning Rate: 0.000367193
	LOSS [training: 0.14608710961983945 | validation: 0.12936277222334458]
	TIME [epoch: 9.22 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15746482257746605		[learning rate: 0.00036586]
	Learning Rate: 0.000365861
	LOSS [training: 0.15746482257746605 | validation: 0.11671794328216267]
	TIME [epoch: 9.2 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13796838402981212		[learning rate: 0.00036453]
	Learning Rate: 0.000364533
	LOSS [training: 0.13796838402981212 | validation: 0.11424678694658462]
	TIME [epoch: 9.18 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14587814133146587		[learning rate: 0.00036321]
	Learning Rate: 0.00036321
	LOSS [training: 0.14587814133146587 | validation: 0.14491079868181733]
	TIME [epoch: 9.2 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1433742531688606		[learning rate: 0.00036189]
	Learning Rate: 0.000361892
	LOSS [training: 0.1433742531688606 | validation: 0.1331477973595509]
	TIME [epoch: 9.21 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1684271815888299		[learning rate: 0.00036058]
	Learning Rate: 0.000360579
	LOSS [training: 0.1684271815888299 | validation: 0.18246968351188375]
	TIME [epoch: 9.2 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15430770138298358		[learning rate: 0.00035927]
	Learning Rate: 0.00035927
	LOSS [training: 0.15430770138298358 | validation: 0.09941951040725586]
	TIME [epoch: 9.19 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12812867664173883		[learning rate: 0.00035797]
	Learning Rate: 0.000357966
	LOSS [training: 0.12812867664173883 | validation: 0.11846331375365428]
	TIME [epoch: 9.2 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14522614365785924		[learning rate: 0.00035667]
	Learning Rate: 0.000356667
	LOSS [training: 0.14522614365785924 | validation: 0.15788565952634562]
	TIME [epoch: 9.2 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16537361584721266		[learning rate: 0.00035537]
	Learning Rate: 0.000355373
	LOSS [training: 0.16537361584721266 | validation: 0.11082269724638513]
	TIME [epoch: 9.23 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13137497095825518		[learning rate: 0.00035408]
	Learning Rate: 0.000354083
	LOSS [training: 0.13137497095825518 | validation: 0.11757347119432723]
	TIME [epoch: 9.19 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1363462824158596		[learning rate: 0.0003528]
	Learning Rate: 0.000352798
	LOSS [training: 0.1363462824158596 | validation: 0.10451594135496978]
	TIME [epoch: 9.19 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15702509101662493		[learning rate: 0.00035152]
	Learning Rate: 0.000351518
	LOSS [training: 0.15702509101662493 | validation: 0.1784537171700066]
	TIME [epoch: 9.19 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18591238176699745		[learning rate: 0.00035024]
	Learning Rate: 0.000350242
	LOSS [training: 0.18591238176699745 | validation: 0.10632856681833996]
	TIME [epoch: 9.21 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14761085736450202		[learning rate: 0.00034897]
	Learning Rate: 0.000348971
	LOSS [training: 0.14761085736450202 | validation: 0.115816674468803]
	TIME [epoch: 9.21 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1338756345595959		[learning rate: 0.0003477]
	Learning Rate: 0.000347705
	LOSS [training: 0.1338756345595959 | validation: 0.13762253768984647]
	TIME [epoch: 9.2 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13022749789114035		[learning rate: 0.00034644]
	Learning Rate: 0.000346443
	LOSS [training: 0.13022749789114035 | validation: 0.11231394661873573]
	TIME [epoch: 9.22 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13836127668702639		[learning rate: 0.00034519]
	Learning Rate: 0.000345186
	LOSS [training: 0.13836127668702639 | validation: 0.11147820852054721]
	TIME [epoch: 9.22 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12707335868930386		[learning rate: 0.00034393]
	Learning Rate: 0.000343933
	LOSS [training: 0.12707335868930386 | validation: 0.1002438973348026]
	TIME [epoch: 9.24 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1367007790074934		[learning rate: 0.00034268]
	Learning Rate: 0.000342685
	LOSS [training: 0.1367007790074934 | validation: 0.11810714580000732]
	TIME [epoch: 9.21 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14891344225012323		[learning rate: 0.00034144]
	Learning Rate: 0.000341441
	LOSS [training: 0.14891344225012323 | validation: 0.12527831603247663]
	TIME [epoch: 9.22 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1442683337707364		[learning rate: 0.0003402]
	Learning Rate: 0.000340202
	LOSS [training: 0.1442683337707364 | validation: 0.14156146580594428]
	TIME [epoch: 9.2 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13207830813253596		[learning rate: 0.00033897]
	Learning Rate: 0.000338967
	LOSS [training: 0.13207830813253596 | validation: 0.09926187748323959]
	TIME [epoch: 9.21 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14399016441043128		[learning rate: 0.00033774]
	Learning Rate: 0.000337737
	LOSS [training: 0.14399016441043128 | validation: 0.13878560529972345]
	TIME [epoch: 9.2 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1392862166918905		[learning rate: 0.00033651]
	Learning Rate: 0.000336512
	LOSS [training: 0.1392862166918905 | validation: 0.11145848929437951]
	TIME [epoch: 9.2 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16841390604249498		[learning rate: 0.00033529]
	Learning Rate: 0.00033529
	LOSS [training: 0.16841390604249498 | validation: 0.13622906055367692]
	TIME [epoch: 9.21 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14936951131649773		[learning rate: 0.00033407]
	Learning Rate: 0.000334074
	LOSS [training: 0.14936951131649773 | validation: 0.1042805091470396]
	TIME [epoch: 9.2 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16442212113648735		[learning rate: 0.00033286]
	Learning Rate: 0.000332861
	LOSS [training: 0.16442212113648735 | validation: 0.13168291561850987]
	TIME [epoch: 9.23 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15356479245212074		[learning rate: 0.00033165]
	Learning Rate: 0.000331653
	LOSS [training: 0.15356479245212074 | validation: 0.1443779706702068]
	TIME [epoch: 9.19 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13713068246053833		[learning rate: 0.00033045]
	Learning Rate: 0.00033045
	LOSS [training: 0.13713068246053833 | validation: 0.10536378732004287]
	TIME [epoch: 9.2 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12689071201160132		[learning rate: 0.00032925]
	Learning Rate: 0.00032925
	LOSS [training: 0.12689071201160132 | validation: 0.09433955906241417]
	TIME [epoch: 9.21 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15669290605094804		[learning rate: 0.00032806]
	Learning Rate: 0.000328056
	LOSS [training: 0.15669290605094804 | validation: 0.09898670696912328]
	TIME [epoch: 9.21 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13334599729983226		[learning rate: 0.00032686]
	Learning Rate: 0.000326865
	LOSS [training: 0.13334599729983226 | validation: 0.09690998439882384]
	TIME [epoch: 9.21 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16711004313462147		[learning rate: 0.00032568]
	Learning Rate: 0.000325679
	LOSS [training: 0.16711004313462147 | validation: 0.11101586107833228]
	TIME [epoch: 9.2 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16239131450770816		[learning rate: 0.0003245]
	Learning Rate: 0.000324497
	LOSS [training: 0.16239131450770816 | validation: 0.11965380389306673]
	TIME [epoch: 9.19 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1472753690272045		[learning rate: 0.00032332]
	Learning Rate: 0.000323319
	LOSS [training: 0.1472753690272045 | validation: 0.0988378376841499]
	TIME [epoch: 9.2 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13576068407910827		[learning rate: 0.00032215]
	Learning Rate: 0.000322146
	LOSS [training: 0.13576068407910827 | validation: 0.11140037559174568]
	TIME [epoch: 9.23 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13836098104716496		[learning rate: 0.00032098]
	Learning Rate: 0.000320977
	LOSS [training: 0.13836098104716496 | validation: 0.140960441942568]
	TIME [epoch: 9.2 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13772180907365522		[learning rate: 0.00031981]
	Learning Rate: 0.000319812
	LOSS [training: 0.13772180907365522 | validation: 0.09601926646563617]
	TIME [epoch: 9.2 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13516364322148006		[learning rate: 0.00031865]
	Learning Rate: 0.000318651
	LOSS [training: 0.13516364322148006 | validation: 0.0766443225525872]
	TIME [epoch: 9.19 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r5_20240219_234257/states/model_tr_study204_1048.pth
	Model improved!!!
EPOCH 1049/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13752365016584212		[learning rate: 0.0003175]
	Learning Rate: 0.000317495
	LOSS [training: 0.13752365016584212 | validation: 0.1274328706598027]
	TIME [epoch: 9.21 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13405850127414937		[learning rate: 0.00031634]
	Learning Rate: 0.000316343
	LOSS [training: 0.13405850127414937 | validation: 0.10475626101341813]
	TIME [epoch: 9.22 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17081828379412373		[learning rate: 0.00031519]
	Learning Rate: 0.000315195
	LOSS [training: 0.17081828379412373 | validation: 0.12869206587403537]
	TIME [epoch: 9.2 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14104019680571717		[learning rate: 0.00031405]
	Learning Rate: 0.000314051
	LOSS [training: 0.14104019680571717 | validation: 0.1024235981730792]
	TIME [epoch: 9.2 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14564706976435246		[learning rate: 0.00031291]
	Learning Rate: 0.000312911
	LOSS [training: 0.14564706976435246 | validation: 0.11216220612889445]
	TIME [epoch: 9.2 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1488619065546433		[learning rate: 0.00031178]
	Learning Rate: 0.000311776
	LOSS [training: 0.1488619065546433 | validation: 0.10997666710187926]
	TIME [epoch: 9.22 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1465009240995857		[learning rate: 0.00031064]
	Learning Rate: 0.000310644
	LOSS [training: 0.1465009240995857 | validation: 0.12413796303503408]
	TIME [epoch: 9.2 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1450940690312828		[learning rate: 0.00030952]
	Learning Rate: 0.000309517
	LOSS [training: 0.1450940690312828 | validation: 0.12811915866614595]
	TIME [epoch: 9.2 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1320688903267931		[learning rate: 0.00030839]
	Learning Rate: 0.000308394
	LOSS [training: 0.1320688903267931 | validation: 0.09703128309886914]
	TIME [epoch: 9.21 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13266106217109525		[learning rate: 0.00030727]
	Learning Rate: 0.000307274
	LOSS [training: 0.13266106217109525 | validation: 0.11353596260904789]
	TIME [epoch: 9.21 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14480041082755526		[learning rate: 0.00030616]
	Learning Rate: 0.000306159
	LOSS [training: 0.14480041082755526 | validation: 0.11178650151575947]
	TIME [epoch: 9.23 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14341200206690669		[learning rate: 0.00030505]
	Learning Rate: 0.000305048
	LOSS [training: 0.14341200206690669 | validation: 0.11450910304849876]
	TIME [epoch: 9.2 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13983795562754045		[learning rate: 0.00030394]
	Learning Rate: 0.000303941
	LOSS [training: 0.13983795562754045 | validation: 0.12741502756836395]
	TIME [epoch: 9.21 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1416768633663932		[learning rate: 0.00030284]
	Learning Rate: 0.000302838
	LOSS [training: 0.1416768633663932 | validation: 0.12105926816409829]
	TIME [epoch: 9.21 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14315199944317417		[learning rate: 0.00030174]
	Learning Rate: 0.000301739
	LOSS [training: 0.14315199944317417 | validation: 0.1380746489922603]
	TIME [epoch: 9.22 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14026125046969518		[learning rate: 0.00030064]
	Learning Rate: 0.000300644
	LOSS [training: 0.14026125046969518 | validation: 0.12297468481981062]
	TIME [epoch: 9.21 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1327765052361224		[learning rate: 0.00029955]
	Learning Rate: 0.000299553
	LOSS [training: 0.1327765052361224 | validation: 0.10456110614143582]
	TIME [epoch: 9.21 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13986550935919834		[learning rate: 0.00029847]
	Learning Rate: 0.000298466
	LOSS [training: 0.13986550935919834 | validation: 0.09671929564173018]
	TIME [epoch: 9.21 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14126873672739854		[learning rate: 0.00029738]
	Learning Rate: 0.000297383
	LOSS [training: 0.14126873672739854 | validation: 0.08586720086804564]
	TIME [epoch: 9.2 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14707687565029162		[learning rate: 0.0002963]
	Learning Rate: 0.000296304
	LOSS [training: 0.14707687565029162 | validation: 0.13807069927270252]
	TIME [epoch: 9.22 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14941830640183912		[learning rate: 0.00029523]
	Learning Rate: 0.000295228
	LOSS [training: 0.14941830640183912 | validation: 0.12751762793908458]
	TIME [epoch: 9.2 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15254719140981812		[learning rate: 0.00029416]
	Learning Rate: 0.000294157
	LOSS [training: 0.15254719140981812 | validation: 0.1422628666965782]
	TIME [epoch: 9.2 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14445601639650174		[learning rate: 0.00029309]
	Learning Rate: 0.000293089
	LOSS [training: 0.14445601639650174 | validation: 0.08941546749644357]
	TIME [epoch: 9.2 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14187855689862924		[learning rate: 0.00029203]
	Learning Rate: 0.000292026
	LOSS [training: 0.14187855689862924 | validation: 0.09721412041574407]
	TIME [epoch: 9.21 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1295734747779819		[learning rate: 0.00029097]
	Learning Rate: 0.000290966
	LOSS [training: 0.1295734747779819 | validation: 0.12725878015978528]
	TIME [epoch: 9.22 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13319523127771318		[learning rate: 0.00028991]
	Learning Rate: 0.00028991
	LOSS [training: 0.13319523127771318 | validation: 0.09482910435409944]
	TIME [epoch: 9.2 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12937126234437882		[learning rate: 0.00028886]
	Learning Rate: 0.000288858
	LOSS [training: 0.12937126234437882 | validation: 0.11691109572475619]
	TIME [epoch: 9.2 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1383267722890712		[learning rate: 0.00028781]
	Learning Rate: 0.00028781
	LOSS [training: 0.1383267722890712 | validation: 0.11672000542501956]
	TIME [epoch: 9.2 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1496995101044814		[learning rate: 0.00028677]
	Learning Rate: 0.000286765
	LOSS [training: 0.1496995101044814 | validation: 0.12157808515080212]
	TIME [epoch: 9.23 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13970391951952812		[learning rate: 0.00028572]
	Learning Rate: 0.000285724
	LOSS [training: 0.13970391951952812 | validation: 0.1137749755643464]
	TIME [epoch: 9.2 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14172024073877337		[learning rate: 0.00028469]
	Learning Rate: 0.000284688
	LOSS [training: 0.14172024073877337 | validation: 0.09827257953292501]
	TIME [epoch: 9.2 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14055688652517878		[learning rate: 0.00028365]
	Learning Rate: 0.000283654
	LOSS [training: 0.14055688652517878 | validation: 0.12040593499474703]
	TIME [epoch: 9.19 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1319912265769818		[learning rate: 0.00028263]
	Learning Rate: 0.000282625
	LOSS [training: 0.1319912265769818 | validation: 0.10373750091220468]
	TIME [epoch: 9.2 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1468585229940371		[learning rate: 0.0002816]
	Learning Rate: 0.000281599
	LOSS [training: 0.1468585229940371 | validation: 0.10343044658306619]
	TIME [epoch: 9.21 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14333802092045883		[learning rate: 0.00028058]
	Learning Rate: 0.000280577
	LOSS [training: 0.14333802092045883 | validation: 0.1491571414818527]
	TIME [epoch: 9.2 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12297582620682698		[learning rate: 0.00027956]
	Learning Rate: 0.000279559
	LOSS [training: 0.12297582620682698 | validation: 0.10064197305808462]
	TIME [epoch: 9.19 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14152709705253338		[learning rate: 0.00027854]
	Learning Rate: 0.000278545
	LOSS [training: 0.14152709705253338 | validation: 0.1362401207147581]
	TIME [epoch: 9.21 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13468352808951697		[learning rate: 0.00027753]
	Learning Rate: 0.000277534
	LOSS [training: 0.13468352808951697 | validation: 0.10154776712522642]
	TIME [epoch: 9.22 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12626998959759872		[learning rate: 0.00027653]
	Learning Rate: 0.000276527
	LOSS [training: 0.12626998959759872 | validation: 0.09887389915381595]
	TIME [epoch: 9.19 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13734340942322737		[learning rate: 0.00027552]
	Learning Rate: 0.000275523
	LOSS [training: 0.13734340942322737 | validation: 0.11454917623612274]
	TIME [epoch: 9.19 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14389109612837597		[learning rate: 0.00027452]
	Learning Rate: 0.000274523
	LOSS [training: 0.14389109612837597 | validation: 0.10518899627527832]
	TIME [epoch: 9.19 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12421985637098232		[learning rate: 0.00027353]
	Learning Rate: 0.000273527
	LOSS [training: 0.12421985637098232 | validation: 0.10568064894885529]
	TIME [epoch: 9.21 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1520752649278751		[learning rate: 0.00027253]
	Learning Rate: 0.000272534
	LOSS [training: 0.1520752649278751 | validation: 0.11772782996277494]
	TIME [epoch: 9.22 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1475726186221175		[learning rate: 0.00027155]
	Learning Rate: 0.000271545
	LOSS [training: 0.1475726186221175 | validation: 0.1074930419280902]
	TIME [epoch: 9.2 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13739109150204248		[learning rate: 0.00027056]
	Learning Rate: 0.00027056
	LOSS [training: 0.13739109150204248 | validation: 0.12117300882035531]
	TIME [epoch: 9.2 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14570116475588227		[learning rate: 0.00026958]
	Learning Rate: 0.000269578
	LOSS [training: 0.14570116475588227 | validation: 0.10130447032552756]
	TIME [epoch: 9.2 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13260813625349924		[learning rate: 0.0002686]
	Learning Rate: 0.0002686
	LOSS [training: 0.13260813625349924 | validation: 0.11015081320520723]
	TIME [epoch: 9.22 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13894394738279933		[learning rate: 0.00026762]
	Learning Rate: 0.000267625
	LOSS [training: 0.13894394738279933 | validation: 0.10440789526811678]
	TIME [epoch: 9.2 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12551803335460002		[learning rate: 0.00026665]
	Learning Rate: 0.000266654
	LOSS [training: 0.12551803335460002 | validation: 0.12001081836909741]
	TIME [epoch: 9.2 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12524026622522827		[learning rate: 0.00026569]
	Learning Rate: 0.000265686
	LOSS [training: 0.12524026622522827 | validation: 0.11474094138111776]
	TIME [epoch: 9.2 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14183921900322471		[learning rate: 0.00026472]
	Learning Rate: 0.000264722
	LOSS [training: 0.14183921900322471 | validation: 0.10965057922642055]
	TIME [epoch: 9.21 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1269298483905969		[learning rate: 0.00026376]
	Learning Rate: 0.000263761
	LOSS [training: 0.1269298483905969 | validation: 0.09131092776103752]
	TIME [epoch: 9.22 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14589299965844918		[learning rate: 0.0002628]
	Learning Rate: 0.000262804
	LOSS [training: 0.14589299965844918 | validation: 0.10401288886031035]
	TIME [epoch: 9.2 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1394551088208518		[learning rate: 0.00026185]
	Learning Rate: 0.00026185
	LOSS [training: 0.1394551088208518 | validation: 0.1260254286573832]
	TIME [epoch: 9.19 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1357847631827409		[learning rate: 0.0002609]
	Learning Rate: 0.0002609
	LOSS [training: 0.1357847631827409 | validation: 0.11396434284797799]
	TIME [epoch: 9.2 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12878861134833283		[learning rate: 0.00025995]
	Learning Rate: 0.000259953
	LOSS [training: 0.12878861134833283 | validation: 0.08978815636987963]
	TIME [epoch: 9.23 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15134188403694868		[learning rate: 0.00025901]
	Learning Rate: 0.00025901
	LOSS [training: 0.15134188403694868 | validation: 0.0995499761297038]
	TIME [epoch: 9.21 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12657976018649236		[learning rate: 0.00025807]
	Learning Rate: 0.00025807
	LOSS [training: 0.12657976018649236 | validation: 0.11973179792061145]
	TIME [epoch: 9.19 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13833476249733273		[learning rate: 0.00025713]
	Learning Rate: 0.000257133
	LOSS [training: 0.13833476249733273 | validation: 0.11106977575476669]
	TIME [epoch: 9.19 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14187992243644368		[learning rate: 0.0002562]
	Learning Rate: 0.0002562
	LOSS [training: 0.14187992243644368 | validation: 0.1233156360041595]
	TIME [epoch: 9.21 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15612799553308143		[learning rate: 0.00025527]
	Learning Rate: 0.00025527
	LOSS [training: 0.15612799553308143 | validation: 0.11712974464852405]
	TIME [epoch: 9.22 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15153011512116774		[learning rate: 0.00025434]
	Learning Rate: 0.000254344
	LOSS [training: 0.15153011512116774 | validation: 0.11171349198898814]
	TIME [epoch: 9.2 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13634194598487043		[learning rate: 0.00025342]
	Learning Rate: 0.000253421
	LOSS [training: 0.13634194598487043 | validation: 0.1149704404314775]
	TIME [epoch: 9.2 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13204824494718898		[learning rate: 0.0002525]
	Learning Rate: 0.000252501
	LOSS [training: 0.13204824494718898 | validation: 0.10787629896792586]
	TIME [epoch: 9.2 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13313616990123006		[learning rate: 0.00025158]
	Learning Rate: 0.000251585
	LOSS [training: 0.13313616990123006 | validation: 0.10684376303413082]
	TIME [epoch: 9.22 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13551838471131394		[learning rate: 0.00025067]
	Learning Rate: 0.000250672
	LOSS [training: 0.13551838471131394 | validation: 0.1321445062348739]
	TIME [epoch: 9.19 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15255658857702942		[learning rate: 0.00024976]
	Learning Rate: 0.000249762
	LOSS [training: 0.15255658857702942 | validation: 0.12554137653933012]
	TIME [epoch: 9.19 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1343660921979949		[learning rate: 0.00024886]
	Learning Rate: 0.000248856
	LOSS [training: 0.1343660921979949 | validation: 0.09591826510717116]
	TIME [epoch: 9.19 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12928546359451626		[learning rate: 0.00024795]
	Learning Rate: 0.000247952
	LOSS [training: 0.12928546359451626 | validation: 0.10227080284352406]
	TIME [epoch: 9.2 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1428842754304419		[learning rate: 0.00024705]
	Learning Rate: 0.000247053
	LOSS [training: 0.1428842754304419 | validation: 0.10152807948336724]
	TIME [epoch: 9.21 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13291276520056128		[learning rate: 0.00024616]
	Learning Rate: 0.000246156
	LOSS [training: 0.13291276520056128 | validation: 0.09469086856457436]
	TIME [epoch: 9.2 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14399767692680826		[learning rate: 0.00024526]
	Learning Rate: 0.000245263
	LOSS [training: 0.14399767692680826 | validation: 0.1043957343128494]
	TIME [epoch: 9.2 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1430246787481807		[learning rate: 0.00024437]
	Learning Rate: 0.000244373
	LOSS [training: 0.1430246787481807 | validation: 0.10450979237259948]
	TIME [epoch: 9.2 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13284233966648246		[learning rate: 0.00024349]
	Learning Rate: 0.000243486
	LOSS [training: 0.13284233966648246 | validation: 0.10104127555663425]
	TIME [epoch: 9.21 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1338286000438768		[learning rate: 0.0002426]
	Learning Rate: 0.000242602
	LOSS [training: 0.1338286000438768 | validation: 0.09234681358228952]
	TIME [epoch: 9.19 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12574278790004842		[learning rate: 0.00024172]
	Learning Rate: 0.000241722
	LOSS [training: 0.12574278790004842 | validation: 0.1173455104540192]
	TIME [epoch: 9.19 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13361415982403052		[learning rate: 0.00024084]
	Learning Rate: 0.000240845
	LOSS [training: 0.13361415982403052 | validation: 0.11068702974448713]
	TIME [epoch: 9.19 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15987200139016988		[learning rate: 0.00023997]
	Learning Rate: 0.000239971
	LOSS [training: 0.15987200139016988 | validation: 0.11838203077326467]
	TIME [epoch: 9.19 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13956518404332657		[learning rate: 0.0002391]
	Learning Rate: 0.0002391
	LOSS [training: 0.13956518404332657 | validation: 0.10367306460592238]
	TIME [epoch: 9.21 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12778153317981375		[learning rate: 0.00023823]
	Learning Rate: 0.000238232
	LOSS [training: 0.12778153317981375 | validation: 0.1199128305507849]
	TIME [epoch: 9.2 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15602655008950927		[learning rate: 0.00023737]
	Learning Rate: 0.000237367
	LOSS [training: 0.15602655008950927 | validation: 0.11194580110315391]
	TIME [epoch: 9.18 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13811078706520508		[learning rate: 0.00023651]
	Learning Rate: 0.000236506
	LOSS [training: 0.13811078706520508 | validation: 0.13119345126613016]
	TIME [epoch: 9.19 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1422669363443014		[learning rate: 0.00023565]
	Learning Rate: 0.000235648
	LOSS [training: 0.1422669363443014 | validation: 0.11882697030838998]
	TIME [epoch: 9.21 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14535762881444328		[learning rate: 0.00023479]
	Learning Rate: 0.000234793
	LOSS [training: 0.14535762881444328 | validation: 0.12953556855862397]
	TIME [epoch: 9.19 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1364621361028027		[learning rate: 0.00023394]
	Learning Rate: 0.00023394
	LOSS [training: 0.1364621361028027 | validation: 0.12222430827652336]
	TIME [epoch: 9.2 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.133948593848996		[learning rate: 0.00023309]
	Learning Rate: 0.000233091
	LOSS [training: 0.133948593848996 | validation: 0.1201382600271846]
	TIME [epoch: 9.19 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13651191534671264		[learning rate: 0.00023225]
	Learning Rate: 0.000232246
	LOSS [training: 0.13651191534671264 | validation: 0.13986084988512057]
	TIME [epoch: 9.2 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13584189872510996		[learning rate: 0.0002314]
	Learning Rate: 0.000231403
	LOSS [training: 0.13584189872510996 | validation: 0.1173473254833175]
	TIME [epoch: 9.21 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1334206335634875		[learning rate: 0.00023056]
	Learning Rate: 0.000230563
	LOSS [training: 0.1334206335634875 | validation: 0.11529400711876633]
	TIME [epoch: 9.2 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13073789410761422		[learning rate: 0.00022973]
	Learning Rate: 0.000229726
	LOSS [training: 0.13073789410761422 | validation: 0.14863482044648632]
	TIME [epoch: 9.19 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19327356508365867		[learning rate: 0.00022889]
	Learning Rate: 0.000228893
	LOSS [training: 0.19327356508365867 | validation: 0.13725790198041515]
	TIME [epoch: 9.18 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1372660149186692		[learning rate: 0.00022806]
	Learning Rate: 0.000228062
	LOSS [training: 0.1372660149186692 | validation: 0.12135174628172014]
	TIME [epoch: 9.21 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1297879752429		[learning rate: 0.00022723]
	Learning Rate: 0.000227234
	LOSS [training: 0.1297879752429 | validation: 0.09246144493823089]
	TIME [epoch: 9.19 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1558008108985111		[learning rate: 0.00022641]
	Learning Rate: 0.00022641
	LOSS [training: 0.1558008108985111 | validation: 0.11327108797576609]
	TIME [epoch: 9.2 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13143795904801117		[learning rate: 0.00022559]
	Learning Rate: 0.000225588
	LOSS [training: 0.13143795904801117 | validation: 0.10762116019416511]
	TIME [epoch: 9.2 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14366497948911322		[learning rate: 0.00022477]
	Learning Rate: 0.000224769
	LOSS [training: 0.14366497948911322 | validation: 0.09299813714910454]
	TIME [epoch: 9.19 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12486307029387127		[learning rate: 0.00022395]
	Learning Rate: 0.000223954
	LOSS [training: 0.12486307029387127 | validation: 0.09825848786705621]
	TIME [epoch: 9.22 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11992219912626056		[learning rate: 0.00022314]
	Learning Rate: 0.000223141
	LOSS [training: 0.11992219912626056 | validation: 0.10916370575495349]
	TIME [epoch: 9.19 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12471133259776099		[learning rate: 0.00022233]
	Learning Rate: 0.000222331
	LOSS [training: 0.12471133259776099 | validation: 0.10392944925374652]
	TIME [epoch: 9.2 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11728126122539591		[learning rate: 0.00022152]
	Learning Rate: 0.000221524
	LOSS [training: 0.11728126122539591 | validation: 0.08936727248348855]
	TIME [epoch: 9.2 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14232285832891312		[learning rate: 0.00022072]
	Learning Rate: 0.00022072
	LOSS [training: 0.14232285832891312 | validation: 0.08256881475722191]
	TIME [epoch: 9.21 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13815519381583774		[learning rate: 0.00021992]
	Learning Rate: 0.000219919
	LOSS [training: 0.13815519381583774 | validation: 0.10880406894292038]
	TIME [epoch: 9.2 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14103105755826034		[learning rate: 0.00021912]
	Learning Rate: 0.000219121
	LOSS [training: 0.14103105755826034 | validation: 0.11878321185714986]
	TIME [epoch: 9.19 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13550150494320928		[learning rate: 0.00021833]
	Learning Rate: 0.000218326
	LOSS [training: 0.13550150494320928 | validation: 0.09842937203808799]
	TIME [epoch: 9.18 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1313615735909338		[learning rate: 0.00021753]
	Learning Rate: 0.000217534
	LOSS [training: 0.1313615735909338 | validation: 0.12350935444396799]
	TIME [epoch: 9.19 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13868095232116998		[learning rate: 0.00021674]
	Learning Rate: 0.000216744
	LOSS [training: 0.13868095232116998 | validation: 0.11609400880572121]
	TIME [epoch: 9.21 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1263030044949794		[learning rate: 0.00021596]
	Learning Rate: 0.000215958
	LOSS [training: 0.1263030044949794 | validation: 0.12225187719261865]
	TIME [epoch: 9.2 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13068072706465914		[learning rate: 0.00021517]
	Learning Rate: 0.000215174
	LOSS [training: 0.13068072706465914 | validation: 0.09504328194000138]
	TIME [epoch: 9.2 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15647499102950732		[learning rate: 0.00021439]
	Learning Rate: 0.000214393
	LOSS [training: 0.15647499102950732 | validation: 0.10911386414677432]
	TIME [epoch: 9.21 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12852882560492912		[learning rate: 0.00021361]
	Learning Rate: 0.000213615
	LOSS [training: 0.12852882560492912 | validation: 0.10425291508077696]
	TIME [epoch: 9.22 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12750006734205738		[learning rate: 0.00021284]
	Learning Rate: 0.00021284
	LOSS [training: 0.12750006734205738 | validation: 0.10516057270124879]
	TIME [epoch: 9.2 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13631909751352417		[learning rate: 0.00021207]
	Learning Rate: 0.000212067
	LOSS [training: 0.13631909751352417 | validation: 0.11066816515030371]
	TIME [epoch: 9.19 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12985722797683097		[learning rate: 0.0002113]
	Learning Rate: 0.000211298
	LOSS [training: 0.12985722797683097 | validation: 0.11323144005593952]
	TIME [epoch: 9.19 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13949694366228255		[learning rate: 0.00021053]
	Learning Rate: 0.000210531
	LOSS [training: 0.13949694366228255 | validation: 0.09448283213633427]
	TIME [epoch: 9.19 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12214940872700278		[learning rate: 0.00020977]
	Learning Rate: 0.000209767
	LOSS [training: 0.12214940872700278 | validation: 0.11520453476148912]
	TIME [epoch: 9.23 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13516081457227305		[learning rate: 0.00020901]
	Learning Rate: 0.000209006
	LOSS [training: 0.13516081457227305 | validation: 0.11196277943257864]
	TIME [epoch: 9.19 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13182870190083776		[learning rate: 0.00020825]
	Learning Rate: 0.000208247
	LOSS [training: 0.13182870190083776 | validation: 0.10183159475394232]
	TIME [epoch: 9.19 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1339942114399862		[learning rate: 0.00020749]
	Learning Rate: 0.000207491
	LOSS [training: 0.1339942114399862 | validation: 0.0911121041131959]
	TIME [epoch: 9.19 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11568140785090272		[learning rate: 0.00020674]
	Learning Rate: 0.000206738
	LOSS [training: 0.11568140785090272 | validation: 0.10309715014902979]
	TIME [epoch: 9.21 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13471033186633208		[learning rate: 0.00020599]
	Learning Rate: 0.000205988
	LOSS [training: 0.13471033186633208 | validation: 0.11621813216713703]
	TIME [epoch: 9.21 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13456735053050997		[learning rate: 0.00020524]
	Learning Rate: 0.000205241
	LOSS [training: 0.13456735053050997 | validation: 0.09249525777472753]
	TIME [epoch: 9.21 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13701208878856908		[learning rate: 0.0002045]
	Learning Rate: 0.000204496
	LOSS [training: 0.13701208878856908 | validation: 0.09348660786675311]
	TIME [epoch: 9.21 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1297487620989322		[learning rate: 0.00020375]
	Learning Rate: 0.000203754
	LOSS [training: 0.1297487620989322 | validation: 0.09110387227424385]
	TIME [epoch: 9.2 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12981130009316771		[learning rate: 0.00020301]
	Learning Rate: 0.000203014
	LOSS [training: 0.12981130009316771 | validation: 0.10007785220987]
	TIME [epoch: 9.21 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12972122091297286		[learning rate: 0.00020228]
	Learning Rate: 0.000202277
	LOSS [training: 0.12972122091297286 | validation: 0.1027462835477331]
	TIME [epoch: 9.2 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12728911523569383		[learning rate: 0.00020154]
	Learning Rate: 0.000201543
	LOSS [training: 0.12728911523569383 | validation: 0.08855424655049997]
	TIME [epoch: 9.21 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13245541094185373		[learning rate: 0.00020081]
	Learning Rate: 0.000200812
	LOSS [training: 0.13245541094185373 | validation: 0.09819983306582741]
	TIME [epoch: 9.19 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1304657282866198		[learning rate: 0.00020008]
	Learning Rate: 0.000200083
	LOSS [training: 0.1304657282866198 | validation: 0.0873972160415868]
	TIME [epoch: 9.2 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1277034314755588		[learning rate: 0.00019936]
	Learning Rate: 0.000199357
	LOSS [training: 0.1277034314755588 | validation: 0.10803444973846921]
	TIME [epoch: 9.2 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14019692227910655		[learning rate: 0.00019863]
	Learning Rate: 0.000198634
	LOSS [training: 0.14019692227910655 | validation: 0.10769621521476866]
	TIME [epoch: 9.18 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14652065892573327		[learning rate: 0.00019791]
	Learning Rate: 0.000197913
	LOSS [training: 0.14652065892573327 | validation: 0.09956511341500222]
	TIME [epoch: 9.19 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15564787006794517		[learning rate: 0.00019719]
	Learning Rate: 0.000197194
	LOSS [training: 0.15564787006794517 | validation: 0.11273851379738828]
	TIME [epoch: 9.19 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12000601717811712		[learning rate: 0.00019648]
	Learning Rate: 0.000196479
	LOSS [training: 0.12000601717811712 | validation: 0.11215283193643943]
	TIME [epoch: 9.23 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12480972802802033		[learning rate: 0.00019577]
	Learning Rate: 0.000195766
	LOSS [training: 0.12480972802802033 | validation: 0.0988128116201917]
	TIME [epoch: 9.2 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1257177161926935		[learning rate: 0.00019506]
	Learning Rate: 0.000195055
	LOSS [training: 0.1257177161926935 | validation: 0.10528864048515939]
	TIME [epoch: 9.21 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14635362070387833		[learning rate: 0.00019435]
	Learning Rate: 0.000194347
	LOSS [training: 0.14635362070387833 | validation: 0.09198277205344363]
	TIME [epoch: 9.19 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12715033910275392		[learning rate: 0.00019364]
	Learning Rate: 0.000193642
	LOSS [training: 0.12715033910275392 | validation: 0.09410819338985946]
	TIME [epoch: 9.21 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13406260759904046		[learning rate: 0.00019294]
	Learning Rate: 0.000192939
	LOSS [training: 0.13406260759904046 | validation: 0.0952355816447948]
	TIME [epoch: 9.21 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11909962275628576		[learning rate: 0.00019224]
	Learning Rate: 0.000192239
	LOSS [training: 0.11909962275628576 | validation: 0.08762161502827852]
	TIME [epoch: 9.2 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14743118646460743		[learning rate: 0.00019154]
	Learning Rate: 0.000191542
	LOSS [training: 0.14743118646460743 | validation: 0.08748515235715469]
	TIME [epoch: 9.2 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13218165975282697		[learning rate: 0.00019085]
	Learning Rate: 0.000190846
	LOSS [training: 0.13218165975282697 | validation: 0.10867436249261661]
	TIME [epoch: 9.2 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1313140569124793		[learning rate: 0.00019015]
	Learning Rate: 0.000190154
	LOSS [training: 0.1313140569124793 | validation: 0.11297402942254756]
	TIME [epoch: 9.21 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11767041805276086		[learning rate: 0.00018946]
	Learning Rate: 0.000189464
	LOSS [training: 0.11767041805276086 | validation: 0.09197944230854799]
	TIME [epoch: 9.19 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1357767831791135		[learning rate: 0.00018878]
	Learning Rate: 0.000188776
	LOSS [training: 0.1357767831791135 | validation: 0.1051568501298348]
	TIME [epoch: 9.19 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1356803500610603		[learning rate: 0.00018809]
	Learning Rate: 0.000188091
	LOSS [training: 0.1356803500610603 | validation: 0.126121643326883]
	TIME [epoch: 9.19 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12999982438359148		[learning rate: 0.00018741]
	Learning Rate: 0.000187409
	LOSS [training: 0.12999982438359148 | validation: 0.11810465346856822]
	TIME [epoch: 9.21 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12509003847255146		[learning rate: 0.00018673]
	Learning Rate: 0.000186729
	LOSS [training: 0.12509003847255146 | validation: 0.10702685837345566]
	TIME [epoch: 9.21 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1286784021678377		[learning rate: 0.00018605]
	Learning Rate: 0.000186051
	LOSS [training: 0.1286784021678377 | validation: 0.09628070309689436]
	TIME [epoch: 9.2 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12383237060356063		[learning rate: 0.00018538]
	Learning Rate: 0.000185376
	LOSS [training: 0.12383237060356063 | validation: 0.11113823455380939]
	TIME [epoch: 9.19 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13916107061421898		[learning rate: 0.0001847]
	Learning Rate: 0.000184703
	LOSS [training: 0.13916107061421898 | validation: 0.10814988977659871]
	TIME [epoch: 9.19 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13328783773589015		[learning rate: 0.00018403]
	Learning Rate: 0.000184033
	LOSS [training: 0.13328783773589015 | validation: 0.11099714230266766]
	TIME [epoch: 9.21 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13027275467511973		[learning rate: 0.00018336]
	Learning Rate: 0.000183365
	LOSS [training: 0.13027275467511973 | validation: 0.10617695406169447]
	TIME [epoch: 9.19 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12839121520925004		[learning rate: 0.0001827]
	Learning Rate: 0.000182699
	LOSS [training: 0.12839121520925004 | validation: 0.1035425421820389]
	TIME [epoch: 9.19 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14029244391417608		[learning rate: 0.00018204]
	Learning Rate: 0.000182036
	LOSS [training: 0.14029244391417608 | validation: 0.09416954054508458]
	TIME [epoch: 9.19 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.125325861737775		[learning rate: 0.00018138]
	Learning Rate: 0.000181376
	LOSS [training: 0.125325861737775 | validation: 0.09854470418249728]
	TIME [epoch: 9.19 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1314433747989548		[learning rate: 0.00018072]
	Learning Rate: 0.000180717
	LOSS [training: 0.1314433747989548 | validation: 0.09922593026909925]
	TIME [epoch: 9.2 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1264980670475952		[learning rate: 0.00018006]
	Learning Rate: 0.000180062
	LOSS [training: 0.1264980670475952 | validation: 0.11431807266136976]
	TIME [epoch: 9.18 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14229943828775946		[learning rate: 0.00017941]
	Learning Rate: 0.000179408
	LOSS [training: 0.14229943828775946 | validation: 0.11363988198260508]
	TIME [epoch: 9.19 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12261734484269562		[learning rate: 0.00017876]
	Learning Rate: 0.000178757
	LOSS [training: 0.12261734484269562 | validation: 0.09728908187044635]
	TIME [epoch: 9.19 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12923944176798088		[learning rate: 0.00017811]
	Learning Rate: 0.000178108
	LOSS [training: 0.12923944176798088 | validation: 0.10199200514968873]
	TIME [epoch: 9.23 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13768751482062844		[learning rate: 0.00017746]
	Learning Rate: 0.000177462
	LOSS [training: 0.13768751482062844 | validation: 0.10220974444747695]
	TIME [epoch: 9.21 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1251664128785472		[learning rate: 0.00017682]
	Learning Rate: 0.000176818
	LOSS [training: 0.1251664128785472 | validation: 0.1026747695701451]
	TIME [epoch: 9.19 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13323919869886483		[learning rate: 0.00017618]
	Learning Rate: 0.000176176
	LOSS [training: 0.13323919869886483 | validation: 0.11466711131957152]
	TIME [epoch: 9.19 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13179129903380588		[learning rate: 0.00017554]
	Learning Rate: 0.000175537
	LOSS [training: 0.13179129903380588 | validation: 0.10987238019979828]
	TIME [epoch: 9.2 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13908667336035685		[learning rate: 0.0001749]
	Learning Rate: 0.0001749
	LOSS [training: 0.13908667336035685 | validation: 0.10562628092966253]
	TIME [epoch: 9.21 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12242686143000411		[learning rate: 0.00017427]
	Learning Rate: 0.000174265
	LOSS [training: 0.12242686143000411 | validation: 0.08784586697164026]
	TIME [epoch: 9.19 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11340759103633706		[learning rate: 0.00017363]
	Learning Rate: 0.000173633
	LOSS [training: 0.11340759103633706 | validation: 0.10522289127081627]
	TIME [epoch: 9.2 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11889971543383102		[learning rate: 0.000173]
	Learning Rate: 0.000173003
	LOSS [training: 0.11889971543383102 | validation: 0.09322298534551432]
	TIME [epoch: 9.19 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12856175500630979		[learning rate: 0.00017237]
	Learning Rate: 0.000172375
	LOSS [training: 0.12856175500630979 | validation: 0.0896931549205252]
	TIME [epoch: 9.21 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12162841284773115		[learning rate: 0.00017175]
	Learning Rate: 0.000171749
	LOSS [training: 0.12162841284773115 | validation: 0.10706773848880016]
	TIME [epoch: 9.19 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1223606941110463		[learning rate: 0.00017113]
	Learning Rate: 0.000171126
	LOSS [training: 0.1223606941110463 | validation: 0.12002134564487892]
	TIME [epoch: 9.19 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13929969567261807		[learning rate: 0.0001705]
	Learning Rate: 0.000170505
	LOSS [training: 0.13929969567261807 | validation: 0.09738032607968167]
	TIME [epoch: 9.19 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12944108194564316		[learning rate: 0.00016989]
	Learning Rate: 0.000169886
	LOSS [training: 0.12944108194564316 | validation: 0.10256534177434293]
	TIME [epoch: 9.21 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11682951202165123		[learning rate: 0.00016927]
	Learning Rate: 0.00016927
	LOSS [training: 0.11682951202165123 | validation: 0.09904110959119401]
	TIME [epoch: 9.26 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13751078354478177		[learning rate: 0.00016866]
	Learning Rate: 0.000168655
	LOSS [training: 0.13751078354478177 | validation: 0.09635247309229758]
	TIME [epoch: 9.19 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12006530099285459		[learning rate: 0.00016804]
	Learning Rate: 0.000168043
	LOSS [training: 0.12006530099285459 | validation: 0.10251453114323265]
	TIME [epoch: 9.19 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14122356437022102		[learning rate: 0.00016743]
	Learning Rate: 0.000167433
	LOSS [training: 0.14122356437022102 | validation: 0.10148875553111827]
	TIME [epoch: 9.2 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13610823635787053		[learning rate: 0.00016683]
	Learning Rate: 0.000166826
	LOSS [training: 0.13610823635787053 | validation: 0.08471777118179276]
	TIME [epoch: 9.23 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13790023190850126		[learning rate: 0.00016622]
	Learning Rate: 0.00016622
	LOSS [training: 0.13790023190850126 | validation: 0.15652999261579126]
	TIME [epoch: 9.21 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13947228414673474		[learning rate: 0.00016562]
	Learning Rate: 0.000165617
	LOSS [training: 0.13947228414673474 | validation: 0.10137785123950788]
	TIME [epoch: 9.2 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12341634391157871		[learning rate: 0.00016502]
	Learning Rate: 0.000165016
	LOSS [training: 0.12341634391157871 | validation: 0.08463963573795993]
	TIME [epoch: 9.2 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12193814397288669		[learning rate: 0.00016442]
	Learning Rate: 0.000164417
	LOSS [training: 0.12193814397288669 | validation: 0.0985539670880544]
	TIME [epoch: 9.2 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12087546088584482		[learning rate: 0.00016382]
	Learning Rate: 0.000163821
	LOSS [training: 0.12087546088584482 | validation: 0.08770698867247062]
	TIME [epoch: 9.21 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12148196828412212		[learning rate: 0.00016323]
	Learning Rate: 0.000163226
	LOSS [training: 0.12148196828412212 | validation: 0.10318127616334923]
	TIME [epoch: 9.19 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.125675342860159		[learning rate: 0.00016263]
	Learning Rate: 0.000162634
	LOSS [training: 0.125675342860159 | validation: 0.14685352812348443]
	TIME [epoch: 9.19 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.144558629291196		[learning rate: 0.00016204]
	Learning Rate: 0.000162043
	LOSS [training: 0.144558629291196 | validation: 0.09698119749901199]
	TIME [epoch: 9.2 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1336064184579265		[learning rate: 0.00016146]
	Learning Rate: 0.000161455
	LOSS [training: 0.1336064184579265 | validation: 0.09785118547403884]
	TIME [epoch: 9.22 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12600509801608822		[learning rate: 0.00016087]
	Learning Rate: 0.000160869
	LOSS [training: 0.12600509801608822 | validation: 0.10290700674289166]
	TIME [epoch: 9.2 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12547812005090478		[learning rate: 0.00016029]
	Learning Rate: 0.000160286
	LOSS [training: 0.12547812005090478 | validation: 0.09555092251151227]
	TIME [epoch: 9.19 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1272845808087955		[learning rate: 0.0001597]
	Learning Rate: 0.000159704
	LOSS [training: 0.1272845808087955 | validation: 0.11672154292420286]
	TIME [epoch: 9.19 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1253741547552195		[learning rate: 0.00015912]
	Learning Rate: 0.000159124
	LOSS [training: 0.1253741547552195 | validation: 0.10981924335566512]
	TIME [epoch: 9.2 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12438275313247764		[learning rate: 0.00015855]
	Learning Rate: 0.000158547
	LOSS [training: 0.12438275313247764 | validation: 0.09614865966320385]
	TIME [epoch: 9.21 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12245143091469537		[learning rate: 0.00015797]
	Learning Rate: 0.000157972
	LOSS [training: 0.12245143091469537 | validation: 0.12317603735561469]
	TIME [epoch: 9.19 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1344288003300943		[learning rate: 0.0001574]
	Learning Rate: 0.000157398
	LOSS [training: 0.1344288003300943 | validation: 0.102230622168578]
	TIME [epoch: 9.19 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13507347939874917		[learning rate: 0.00015683]
	Learning Rate: 0.000156827
	LOSS [training: 0.13507347939874917 | validation: 0.09260105240835477]
	TIME [epoch: 9.2 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1335145125112656		[learning rate: 0.00015626]
	Learning Rate: 0.000156258
	LOSS [training: 0.1335145125112656 | validation: 0.08752600882577308]
	TIME [epoch: 9.21 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1438445549684519		[learning rate: 0.00015569]
	Learning Rate: 0.000155691
	LOSS [training: 0.1438445549684519 | validation: 0.11385543129272119]
	TIME [epoch: 9.19 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1600484731546346		[learning rate: 0.00015513]
	Learning Rate: 0.000155126
	LOSS [training: 0.1600484731546346 | validation: 0.10206115458503556]
	TIME [epoch: 9.2 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11908130629642899		[learning rate: 0.00015456]
	Learning Rate: 0.000154563
	LOSS [training: 0.11908130629642899 | validation: 0.0875259527228577]
	TIME [epoch: 9.2 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12628376417515852		[learning rate: 0.000154]
	Learning Rate: 0.000154002
	LOSS [training: 0.12628376417515852 | validation: 0.09232247263505255]
	TIME [epoch: 9.19 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12532451715607518		[learning rate: 0.00015344]
	Learning Rate: 0.000153443
	LOSS [training: 0.12532451715607518 | validation: 0.09737345272147158]
	TIME [epoch: 9.22 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13202747202959814		[learning rate: 0.00015289]
	Learning Rate: 0.000152886
	LOSS [training: 0.13202747202959814 | validation: 0.091554306816444]
	TIME [epoch: 9.2 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12738978751074687		[learning rate: 0.00015233]
	Learning Rate: 0.000152331
	LOSS [training: 0.12738978751074687 | validation: 0.09836114401773852]
	TIME [epoch: 9.2 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1499285722202304		[learning rate: 0.00015178]
	Learning Rate: 0.000151779
	LOSS [training: 0.1499285722202304 | validation: 0.12590895292215393]
	TIME [epoch: 9.19 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14628544534850935		[learning rate: 0.00015123]
	Learning Rate: 0.000151228
	LOSS [training: 0.14628544534850935 | validation: 0.12345265703782872]
	TIME [epoch: 9.21 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1360620496722226		[learning rate: 0.00015068]
	Learning Rate: 0.000150679
	LOSS [training: 0.1360620496722226 | validation: 0.09341271959618005]
	TIME [epoch: 9.2 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1441659312107108		[learning rate: 0.00015013]
	Learning Rate: 0.000150132
	LOSS [training: 0.1441659312107108 | validation: 0.10569652104114602]
	TIME [epoch: 9.19 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13654551341015425		[learning rate: 0.00014959]
	Learning Rate: 0.000149587
	LOSS [training: 0.13654551341015425 | validation: 0.09504161465420227]
	TIME [epoch: 9.19 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12569166013366223		[learning rate: 0.00014904]
	Learning Rate: 0.000149044
	LOSS [training: 0.12569166013366223 | validation: 0.12975747733383566]
	TIME [epoch: 9.19 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12931113184082735		[learning rate: 0.0001485]
	Learning Rate: 0.000148504
	LOSS [training: 0.12931113184082735 | validation: 0.11362209091328758]
	TIME [epoch: 9.22 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11564199596861136		[learning rate: 0.00014796]
	Learning Rate: 0.000147965
	LOSS [training: 0.11564199596861136 | validation: 0.10466353167786552]
	TIME [epoch: 9.2 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11658905645786591		[learning rate: 0.00014743]
	Learning Rate: 0.000147428
	LOSS [training: 0.11658905645786591 | validation: 0.10259836238754572]
	TIME [epoch: 9.19 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12201045902127985		[learning rate: 0.00014689]
	Learning Rate: 0.000146893
	LOSS [training: 0.12201045902127985 | validation: 0.1027582166013254]
	TIME [epoch: 9.19 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1356472895817355		[learning rate: 0.00014636]
	Learning Rate: 0.00014636
	LOSS [training: 0.1356472895817355 | validation: 0.09021794744480331]
	TIME [epoch: 9.21 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13373967005464532		[learning rate: 0.00014583]
	Learning Rate: 0.000145828
	LOSS [training: 0.13373967005464532 | validation: 0.09455931931536946]
	TIME [epoch: 9.2 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13197881559329244		[learning rate: 0.0001453]
	Learning Rate: 0.000145299
	LOSS [training: 0.13197881559329244 | validation: 0.10015310343470035]
	TIME [epoch: 9.19 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13723573026372576		[learning rate: 0.00014477]
	Learning Rate: 0.000144772
	LOSS [training: 0.13723573026372576 | validation: 0.10555178143433736]
	TIME [epoch: 9.18 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12258538449259393		[learning rate: 0.00014425]
	Learning Rate: 0.000144247
	LOSS [training: 0.12258538449259393 | validation: 0.10150762770453231]
	TIME [epoch: 9.19 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13870042680014466		[learning rate: 0.00014372]
	Learning Rate: 0.000143723
	LOSS [training: 0.13870042680014466 | validation: 0.16195435246708753]
	TIME [epoch: 9.2 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15722609128161996		[learning rate: 0.0001432]
	Learning Rate: 0.000143201
	LOSS [training: 0.15722609128161996 | validation: 0.10810645261362262]
	TIME [epoch: 9.19 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13439377929816226		[learning rate: 0.00014268]
	Learning Rate: 0.000142682
	LOSS [training: 0.13439377929816226 | validation: 0.09319828447940288]
	TIME [epoch: 9.18 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13105869180207652		[learning rate: 0.00014216]
	Learning Rate: 0.000142164
	LOSS [training: 0.13105869180207652 | validation: 0.09829026127914434]
	TIME [epoch: 9.19 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11807694926689376		[learning rate: 0.00014165]
	Learning Rate: 0.000141648
	LOSS [training: 0.11807694926689376 | validation: 0.0968968477742634]
	TIME [epoch: 9.2 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12720884704372454		[learning rate: 0.00014113]
	Learning Rate: 0.000141134
	LOSS [training: 0.12720884704372454 | validation: 0.08881424948620686]
	TIME [epoch: 9.2 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12682276856557		[learning rate: 0.00014062]
	Learning Rate: 0.000140622
	LOSS [training: 0.12682276856557 | validation: 0.10700686224673048]
	TIME [epoch: 9.19 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1291932800455276		[learning rate: 0.00014011]
	Learning Rate: 0.000140112
	LOSS [training: 0.1291932800455276 | validation: 0.10501983990382632]
	TIME [epoch: 9.18 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11863171248196738		[learning rate: 0.0001396]
	Learning Rate: 0.000139603
	LOSS [training: 0.11863171248196738 | validation: 0.10550585691069285]
	TIME [epoch: 9.17 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14584268792394528		[learning rate: 0.0001391]
	Learning Rate: 0.000139096
	LOSS [training: 0.14584268792394528 | validation: 0.0997064718045084]
	TIME [epoch: 9.21 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1256743590248513		[learning rate: 0.00013859]
	Learning Rate: 0.000138592
	LOSS [training: 0.1256743590248513 | validation: 0.08618829194296063]
	TIME [epoch: 9.19 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13146507438986527		[learning rate: 0.00013809]
	Learning Rate: 0.000138089
	LOSS [training: 0.13146507438986527 | validation: 0.10836057794707044]
	TIME [epoch: 9.19 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1365513254104998		[learning rate: 0.00013759]
	Learning Rate: 0.000137587
	LOSS [training: 0.1365513254104998 | validation: 0.09686155302922694]
	TIME [epoch: 9.18 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11988807119949388		[learning rate: 0.00013709]
	Learning Rate: 0.000137088
	LOSS [training: 0.11988807119949388 | validation: 0.10204153439199978]
	TIME [epoch: 9.2 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12535177986651763		[learning rate: 0.00013659]
	Learning Rate: 0.000136591
	LOSS [training: 0.12535177986651763 | validation: 0.10712239186882108]
	TIME [epoch: 9.2 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12378554431394037		[learning rate: 0.00013609]
	Learning Rate: 0.000136095
	LOSS [training: 0.12378554431394037 | validation: 0.09857257596000674]
	TIME [epoch: 9.19 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12957523782586847		[learning rate: 0.0001356]
	Learning Rate: 0.000135601
	LOSS [training: 0.12957523782586847 | validation: 0.101371463579633]
	TIME [epoch: 9.19 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1280630808624403		[learning rate: 0.00013511]
	Learning Rate: 0.000135109
	LOSS [training: 0.1280630808624403 | validation: 0.09203042525291111]
	TIME [epoch: 9.2 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11585473205185559		[learning rate: 0.00013462]
	Learning Rate: 0.000134619
	LOSS [training: 0.11585473205185559 | validation: 0.10393957377738394]
	TIME [epoch: 9.22 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11072041167197366		[learning rate: 0.00013413]
	Learning Rate: 0.00013413
	LOSS [training: 0.11072041167197366 | validation: 0.095814449077679]
	TIME [epoch: 9.19 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16639531303208793		[learning rate: 0.00013364]
	Learning Rate: 0.000133643
	LOSS [training: 0.16639531303208793 | validation: 0.1371093910190752]
	TIME [epoch: 9.19 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14784975668097441		[learning rate: 0.00013316]
	Learning Rate: 0.000133158
	LOSS [training: 0.14784975668097441 | validation: 0.0956733347045221]
	TIME [epoch: 9.18 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13534619021615324		[learning rate: 0.00013268]
	Learning Rate: 0.000132675
	LOSS [training: 0.13534619021615324 | validation: 0.13542955217825853]
	TIME [epoch: 9.2 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18433739321742693		[learning rate: 0.00013219]
	Learning Rate: 0.000132194
	LOSS [training: 0.18433739321742693 | validation: 0.11168712114380894]
	TIME [epoch: 9.2 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15532812188056924		[learning rate: 0.00013171]
	Learning Rate: 0.000131714
	LOSS [training: 0.15532812188056924 | validation: 0.09850380480798956]
	TIME [epoch: 9.19 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13960997879209108		[learning rate: 0.00013124]
	Learning Rate: 0.000131236
	LOSS [training: 0.13960997879209108 | validation: 0.09945023664510672]
	TIME [epoch: 9.19 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1305349723644587		[learning rate: 0.00013076]
	Learning Rate: 0.00013076
	LOSS [training: 0.1305349723644587 | validation: 0.08820224595595218]
	TIME [epoch: 9.2 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1286819509654056		[learning rate: 0.00013029]
	Learning Rate: 0.000130285
	LOSS [training: 0.1286819509654056 | validation: 0.09747449375586444]
	TIME [epoch: 9.22 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12746760252298245		[learning rate: 0.00012981]
	Learning Rate: 0.000129812
	LOSS [training: 0.12746760252298245 | validation: 0.10772334077678511]
	TIME [epoch: 9.19 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13423581235027532		[learning rate: 0.00012934]
	Learning Rate: 0.000129341
	LOSS [training: 0.13423581235027532 | validation: 0.09552790539391956]
	TIME [epoch: 9.2 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13715408799906353		[learning rate: 0.00012887]
	Learning Rate: 0.000128872
	LOSS [training: 0.13715408799906353 | validation: 0.16112699636049999]
	TIME [epoch: 9.2 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1735140641870261		[learning rate: 0.0001284]
	Learning Rate: 0.000128404
	LOSS [training: 0.1735140641870261 | validation: 0.10173088415751114]
	TIME [epoch: 9.21 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12839927226691422		[learning rate: 0.00012794]
	Learning Rate: 0.000127938
	LOSS [training: 0.12839927226691422 | validation: 0.09993033544607083]
	TIME [epoch: 9.21 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1491338971623583		[learning rate: 0.00012747]
	Learning Rate: 0.000127474
	LOSS [training: 0.1491338971623583 | validation: 0.10272035807394654]
	TIME [epoch: 9.2 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12178472491955487		[learning rate: 0.00012701]
	Learning Rate: 0.000127011
	LOSS [training: 0.12178472491955487 | validation: 0.10317827111330252]
	TIME [epoch: 9.19 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14059071909553617		[learning rate: 0.00012655]
	Learning Rate: 0.00012655
	LOSS [training: 0.14059071909553617 | validation: 0.11477279006106596]
	TIME [epoch: 9.19 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14607482571053865		[learning rate: 0.00012609]
	Learning Rate: 0.000126091
	LOSS [training: 0.14607482571053865 | validation: 0.12773403841191563]
	TIME [epoch: 9.22 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13323635415292645		[learning rate: 0.00012563]
	Learning Rate: 0.000125633
	LOSS [training: 0.13323635415292645 | validation: 0.10944621806709381]
	TIME [epoch: 9.2 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12374609366565317		[learning rate: 0.00012518]
	Learning Rate: 0.000125178
	LOSS [training: 0.12374609366565317 | validation: 0.11390727189246883]
	TIME [epoch: 9.21 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12664637347174282		[learning rate: 0.00012472]
	Learning Rate: 0.000124723
	LOSS [training: 0.12664637347174282 | validation: 0.10170021656151915]
	TIME [epoch: 9.2 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11943016763354566		[learning rate: 0.00012427]
	Learning Rate: 0.000124271
	LOSS [training: 0.11943016763354566 | validation: 0.09809466515778523]
	TIME [epoch: 9.2 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13201275336178922		[learning rate: 0.00012382]
	Learning Rate: 0.00012382
	LOSS [training: 0.13201275336178922 | validation: 0.10194248745511306]
	TIME [epoch: 9.21 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1286528032177087		[learning rate: 0.00012337]
	Learning Rate: 0.00012337
	LOSS [training: 0.1286528032177087 | validation: 0.11252611718585037]
	TIME [epoch: 9.19 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13820289818266868		[learning rate: 0.00012292]
	Learning Rate: 0.000122923
	LOSS [training: 0.13820289818266868 | validation: 0.13928925094732134]
	TIME [epoch: 9.2 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.128925233056109		[learning rate: 0.00012248]
	Learning Rate: 0.000122476
	LOSS [training: 0.128925233056109 | validation: 0.11303449819460384]
	TIME [epoch: 9.2 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13770996798002116		[learning rate: 0.00012203]
	Learning Rate: 0.000122032
	LOSS [training: 0.13770996798002116 | validation: 0.09188017421009967]
	TIME [epoch: 9.24 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.118526318782833		[learning rate: 0.00012159]
	Learning Rate: 0.000121589
	LOSS [training: 0.118526318782833 | validation: 0.09322113526590725]
	TIME [epoch: 9.2 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13859987408857907		[learning rate: 0.00012115]
	Learning Rate: 0.000121148
	LOSS [training: 0.13859987408857907 | validation: 0.08927879216995402]
	TIME [epoch: 9.2 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11709663195577538		[learning rate: 0.00012071]
	Learning Rate: 0.000120708
	LOSS [training: 0.11709663195577538 | validation: 0.09790998195656067]
	TIME [epoch: 9.19 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12763930043294944		[learning rate: 0.00012027]
	Learning Rate: 0.00012027
	LOSS [training: 0.12763930043294944 | validation: 0.10065988558161387]
	TIME [epoch: 9.21 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12141328568394964		[learning rate: 0.00011983]
	Learning Rate: 0.000119834
	LOSS [training: 0.12141328568394964 | validation: 0.0951354335293729]
	TIME [epoch: 9.21 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12709343722044675		[learning rate: 0.0001194]
	Learning Rate: 0.000119399
	LOSS [training: 0.12709343722044675 | validation: 0.08711359527607637]
	TIME [epoch: 9.19 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12464576537958154		[learning rate: 0.00011897]
	Learning Rate: 0.000118966
	LOSS [training: 0.12464576537958154 | validation: 0.11204464356731136]
	TIME [epoch: 9.2 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1255310818446666		[learning rate: 0.00011853]
	Learning Rate: 0.000118534
	LOSS [training: 0.1255310818446666 | validation: 0.09206049651541748]
	TIME [epoch: 9.2 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13141954957643684		[learning rate: 0.0001181]
	Learning Rate: 0.000118104
	LOSS [training: 0.13141954957643684 | validation: 0.1128513364258742]
	TIME [epoch: 9.21 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11526445732970499		[learning rate: 0.00011767]
	Learning Rate: 0.000117675
	LOSS [training: 0.11526445732970499 | validation: 0.09356221194132802]
	TIME [epoch: 9.2 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11337743244975254		[learning rate: 0.00011725]
	Learning Rate: 0.000117248
	LOSS [training: 0.11337743244975254 | validation: 0.09284589829648102]
	TIME [epoch: 9.19 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12016161495489382		[learning rate: 0.00011682]
	Learning Rate: 0.000116822
	LOSS [training: 0.12016161495489382 | validation: 0.10061339681418603]
	TIME [epoch: 9.2 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11578975171501896		[learning rate: 0.0001164]
	Learning Rate: 0.000116398
	LOSS [training: 0.11578975171501896 | validation: 0.09619434082766272]
	TIME [epoch: 9.2 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12075532958009491		[learning rate: 0.00011598]
	Learning Rate: 0.000115976
	LOSS [training: 0.12075532958009491 | validation: 0.10114852173211639]
	TIME [epoch: 9.21 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13663616946145105		[learning rate: 0.00011556]
	Learning Rate: 0.000115555
	LOSS [training: 0.13663616946145105 | validation: 0.10300287121057589]
	TIME [epoch: 9.19 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12781290624067912		[learning rate: 0.00011514]
	Learning Rate: 0.000115136
	LOSS [training: 0.12781290624067912 | validation: 0.10981484649136289]
	TIME [epoch: 9.19 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13971743186551722		[learning rate: 0.00011472]
	Learning Rate: 0.000114718
	LOSS [training: 0.13971743186551722 | validation: 0.09461309582605965]
	TIME [epoch: 9.19 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1291071607475122		[learning rate: 0.0001143]
	Learning Rate: 0.000114302
	LOSS [training: 0.1291071607475122 | validation: 0.10195080166964339]
	TIME [epoch: 9.21 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11905684038629609		[learning rate: 0.00011389]
	Learning Rate: 0.000113887
	LOSS [training: 0.11905684038629609 | validation: 0.09697594372754767]
	TIME [epoch: 9.19 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12747494663018422		[learning rate: 0.00011347]
	Learning Rate: 0.000113474
	LOSS [training: 0.12747494663018422 | validation: 0.08602125474920755]
	TIME [epoch: 9.19 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11960891664936879		[learning rate: 0.00011306]
	Learning Rate: 0.000113062
	LOSS [training: 0.11960891664936879 | validation: 0.11623960822350995]
	TIME [epoch: 9.19 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13494033318297285		[learning rate: 0.00011265]
	Learning Rate: 0.000112651
	LOSS [training: 0.13494033318297285 | validation: 0.10429224873284952]
	TIME [epoch: 9.21 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1263798540497159		[learning rate: 0.00011224]
	Learning Rate: 0.000112243
	LOSS [training: 0.1263798540497159 | validation: 0.10013391852253992]
	TIME [epoch: 9.21 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12856221327334877		[learning rate: 0.00011184]
	Learning Rate: 0.000111835
	LOSS [training: 0.12856221327334877 | validation: 0.1004909062830025]
	TIME [epoch: 9.2 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14708347886375736		[learning rate: 0.00011143]
	Learning Rate: 0.000111429
	LOSS [training: 0.14708347886375736 | validation: 0.11056899569322035]
	TIME [epoch: 9.19 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13863277739042534		[learning rate: 0.00011103]
	Learning Rate: 0.000111025
	LOSS [training: 0.13863277739042534 | validation: 0.08746648062580988]
	TIME [epoch: 9.2 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11645516930845326		[learning rate: 0.00011062]
	Learning Rate: 0.000110622
	LOSS [training: 0.11645516930845326 | validation: 0.09792386852430131]
	TIME [epoch: 9.21 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12083850744044244		[learning rate: 0.00011022]
	Learning Rate: 0.000110221
	LOSS [training: 0.12083850744044244 | validation: 0.11293506132387032]
	TIME [epoch: 9.18 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13634806477169698		[learning rate: 0.00010982]
	Learning Rate: 0.000109821
	LOSS [training: 0.13634806477169698 | validation: 0.08800449650808925]
	TIME [epoch: 9.19 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12294391320018958		[learning rate: 0.00010942]
	Learning Rate: 0.000109422
	LOSS [training: 0.12294391320018958 | validation: 0.08948123047464238]
	TIME [epoch: 9.19 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12998543402146584		[learning rate: 0.00010903]
	Learning Rate: 0.000109025
	LOSS [training: 0.12998543402146584 | validation: 0.0954567110048247]
	TIME [epoch: 9.2 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1216413841531355		[learning rate: 0.00010863]
	Learning Rate: 0.000108629
	LOSS [training: 0.1216413841531355 | validation: 0.10944825802624657]
	TIME [epoch: 9.21 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12567824283309242		[learning rate: 0.00010824]
	Learning Rate: 0.000108235
	LOSS [training: 0.12567824283309242 | validation: 0.09892588129001828]
	TIME [epoch: 9.19 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11738714651585416		[learning rate: 0.00010784]
	Learning Rate: 0.000107842
	LOSS [training: 0.11738714651585416 | validation: 0.10938091369166117]
	TIME [epoch: 9.19 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12466334277900312		[learning rate: 0.00010745]
	Learning Rate: 0.000107451
	LOSS [training: 0.12466334277900312 | validation: 0.08586216089567966]
	TIME [epoch: 9.19 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12364018241332075		[learning rate: 0.00010706]
	Learning Rate: 0.000107061
	LOSS [training: 0.12364018241332075 | validation: 0.09360600835480248]
	TIME [epoch: 9.21 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11694224143020175		[learning rate: 0.00010667]
	Learning Rate: 0.000106673
	LOSS [training: 0.11694224143020175 | validation: 0.08967891295110411]
	TIME [epoch: 9.19 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12796212107747473		[learning rate: 0.00010629]
	Learning Rate: 0.000106285
	LOSS [training: 0.12796212107747473 | validation: 0.09829906871685401]
	TIME [epoch: 9.19 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1138737847403141		[learning rate: 0.0001059]
	Learning Rate: 0.0001059
	LOSS [training: 0.1138737847403141 | validation: 0.09444739561479643]
	TIME [epoch: 9.19 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1215304947241137		[learning rate: 0.00010552]
	Learning Rate: 0.000105515
	LOSS [training: 0.1215304947241137 | validation: 0.09882478830796834]
	TIME [epoch: 9.2 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13711611322017545		[learning rate: 0.00010513]
	Learning Rate: 0.000105132
	LOSS [training: 0.13711611322017545 | validation: 0.11456194947269593]
	TIME [epoch: 9.2 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13958299204919994		[learning rate: 0.00010475]
	Learning Rate: 0.000104751
	LOSS [training: 0.13958299204919994 | validation: 0.090709994810848]
	TIME [epoch: 9.19 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11832672414844363		[learning rate: 0.00010437]
	Learning Rate: 0.000104371
	LOSS [training: 0.11832672414844363 | validation: 0.09305498524611626]
	TIME [epoch: 9.19 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11604257302885135		[learning rate: 0.00010399]
	Learning Rate: 0.000103992
	LOSS [training: 0.11604257302885135 | validation: 0.09412377122536181]
	TIME [epoch: 9.2 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11711750280155042		[learning rate: 0.00010361]
	Learning Rate: 0.000103615
	LOSS [training: 0.11711750280155042 | validation: 0.09185015929571123]
	TIME [epoch: 9.21 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12965161340696646		[learning rate: 0.00010324]
	Learning Rate: 0.000103239
	LOSS [training: 0.12965161340696646 | validation: 0.08896287308159025]
	TIME [epoch: 9.2 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12410179354148365		[learning rate: 0.00010286]
	Learning Rate: 0.000102864
	LOSS [training: 0.12410179354148365 | validation: 0.09939140390547901]
	TIME [epoch: 9.19 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11971247875815508		[learning rate: 0.00010249]
	Learning Rate: 0.000102491
	LOSS [training: 0.11971247875815508 | validation: 0.07804042874712469]
	TIME [epoch: 9.19 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12061450696389708		[learning rate: 0.00010212]
	Learning Rate: 0.000102119
	LOSS [training: 0.12061450696389708 | validation: 0.10173984825100249]
	TIME [epoch: 9.19 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11956913721593469		[learning rate: 0.00010175]
	Learning Rate: 0.000101748
	LOSS [training: 0.11956913721593469 | validation: 0.09280308340279715]
	TIME [epoch: 9.22 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11295567815093221		[learning rate: 0.00010138]
	Learning Rate: 0.000101379
	LOSS [training: 0.11295567815093221 | validation: 0.09461771425614734]
	TIME [epoch: 9.21 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11145113105218966		[learning rate: 0.00010101]
	Learning Rate: 0.000101011
	LOSS [training: 0.11145113105218966 | validation: 0.09636104822411601]
	TIME [epoch: 9.21 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12108157892902179		[learning rate: 0.00010064]
	Learning Rate: 0.000100644
	LOSS [training: 0.12108157892902179 | validation: 0.08892538942042172]
	TIME [epoch: 9.19 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1142633190104165		[learning rate: 0.00010028]
	Learning Rate: 0.000100279
	LOSS [training: 0.1142633190104165 | validation: 0.09168460728879702]
	TIME [epoch: 9.21 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11533244585932093		[learning rate: 9.9915e-05]
	Learning Rate: 9.99152e-05
	LOSS [training: 0.11533244585932093 | validation: 0.08894252938442568]
	TIME [epoch: 9.2 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1250693107344168		[learning rate: 9.9553e-05]
	Learning Rate: 9.95526e-05
	LOSS [training: 0.1250693107344168 | validation: 0.0982079324217994]
	TIME [epoch: 9.19 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12674898424274367		[learning rate: 9.9191e-05]
	Learning Rate: 9.91913e-05
	LOSS [training: 0.12674898424274367 | validation: 0.10970019724058232]
	TIME [epoch: 9.19 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1248799043942778		[learning rate: 9.8831e-05]
	Learning Rate: 9.88314e-05
	LOSS [training: 0.1248799043942778 | validation: 0.09614894525367754]
	TIME [epoch: 9.19 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12308454021474677		[learning rate: 9.8473e-05]
	Learning Rate: 9.84727e-05
	LOSS [training: 0.12308454021474677 | validation: 0.08903117612858626]
	TIME [epoch: 9.22 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1162845233463213		[learning rate: 9.8115e-05]
	Learning Rate: 9.81153e-05
	LOSS [training: 0.1162845233463213 | validation: 0.09012667643805532]
	TIME [epoch: 9.18 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12567703571426547		[learning rate: 9.7759e-05]
	Learning Rate: 9.77592e-05
	LOSS [training: 0.12567703571426547 | validation: 0.09315221709254498]
	TIME [epoch: 9.18 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12335645312979113		[learning rate: 9.7404e-05]
	Learning Rate: 9.74045e-05
	LOSS [training: 0.12335645312979113 | validation: 0.10202433735925734]
	TIME [epoch: 9.18 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1298376458150274		[learning rate: 9.7051e-05]
	Learning Rate: 9.7051e-05
	LOSS [training: 0.1298376458150274 | validation: 0.09514699672165378]
	TIME [epoch: 9.22 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12267121929172312		[learning rate: 9.6699e-05]
	Learning Rate: 9.66988e-05
	LOSS [training: 0.12267121929172312 | validation: 0.09717919964964772]
	TIME [epoch: 9.21 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.127079920456271		[learning rate: 9.6348e-05]
	Learning Rate: 9.63479e-05
	LOSS [training: 0.127079920456271 | validation: 0.09637542537426183]
	TIME [epoch: 9.2 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12955423254577056		[learning rate: 9.5998e-05]
	Learning Rate: 9.59982e-05
	LOSS [training: 0.12955423254577056 | validation: 0.09822082047285062]
	TIME [epoch: 9.2 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11669734344143415		[learning rate: 9.565e-05]
	Learning Rate: 9.56499e-05
	LOSS [training: 0.11669734344143415 | validation: 0.0907375776991416]
	TIME [epoch: 9.2 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11602853239899832		[learning rate: 9.5303e-05]
	Learning Rate: 9.53027e-05
	LOSS [training: 0.11602853239899832 | validation: 0.08976176382415021]
	TIME [epoch: 9.22 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12248855467300408		[learning rate: 9.4957e-05]
	Learning Rate: 9.49569e-05
	LOSS [training: 0.12248855467300408 | validation: 0.11133049184567304]
	TIME [epoch: 9.19 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12689260297188465		[learning rate: 9.4612e-05]
	Learning Rate: 9.46122e-05
	LOSS [training: 0.12689260297188465 | validation: 0.09731957090727275]
	TIME [epoch: 9.18 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13707013903896376		[learning rate: 9.4269e-05]
	Learning Rate: 9.42689e-05
	LOSS [training: 0.13707013903896376 | validation: 0.12567757663786872]
	TIME [epoch: 9.19 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14369373281402945		[learning rate: 9.3927e-05]
	Learning Rate: 9.39268e-05
	LOSS [training: 0.14369373281402945 | validation: 0.1101301748845044]
	TIME [epoch: 9.21 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13138419466147594		[learning rate: 9.3586e-05]
	Learning Rate: 9.35859e-05
	LOSS [training: 0.13138419466147594 | validation: 0.09187304164144355]
	TIME [epoch: 9.2 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12984508238866355		[learning rate: 9.3246e-05]
	Learning Rate: 9.32463e-05
	LOSS [training: 0.12984508238866355 | validation: 0.09590872382019838]
	TIME [epoch: 9.19 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1252595485232268		[learning rate: 9.2908e-05]
	Learning Rate: 9.29079e-05
	LOSS [training: 0.1252595485232268 | validation: 0.07091219134228541]
	TIME [epoch: 9.19 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r5_20240219_234257/states/model_tr_study204_1387.pth
	Model improved!!!
EPOCH 1388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11823880482186369		[learning rate: 9.2571e-05]
	Learning Rate: 9.25707e-05
	LOSS [training: 0.11823880482186369 | validation: 0.09731652095132459]
	TIME [epoch: 9.19 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12405264017597595		[learning rate: 9.2235e-05]
	Learning Rate: 9.22348e-05
	LOSS [training: 0.12405264017597595 | validation: 0.09176689323465897]
	TIME [epoch: 9.23 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11553935834404494		[learning rate: 9.19e-05]
	Learning Rate: 9.19001e-05
	LOSS [training: 0.11553935834404494 | validation: 0.08751009583588744]
	TIME [epoch: 9.19 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11394287169035763		[learning rate: 9.1567e-05]
	Learning Rate: 9.15665e-05
	LOSS [training: 0.11394287169035763 | validation: 0.09490288935925922]
	TIME [epoch: 9.19 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12256436386130228		[learning rate: 9.1234e-05]
	Learning Rate: 9.12343e-05
	LOSS [training: 0.12256436386130228 | validation: 0.09922956341021243]
	TIME [epoch: 9.19 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12271367543675415		[learning rate: 9.0903e-05]
	Learning Rate: 9.09031e-05
	LOSS [training: 0.12271367543675415 | validation: 0.10097093834738921]
	TIME [epoch: 9.22 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11990209588347696		[learning rate: 9.0573e-05]
	Learning Rate: 9.05733e-05
	LOSS [training: 0.11990209588347696 | validation: 0.0908275156333946]
	TIME [epoch: 9.2 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11739743634553801		[learning rate: 9.0245e-05]
	Learning Rate: 9.02446e-05
	LOSS [training: 0.11739743634553801 | validation: 0.09412841104344549]
	TIME [epoch: 9.19 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11865116028705161		[learning rate: 8.9917e-05]
	Learning Rate: 8.99171e-05
	LOSS [training: 0.11865116028705161 | validation: 0.09477582286248351]
	TIME [epoch: 9.19 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13389384057428333		[learning rate: 8.9591e-05]
	Learning Rate: 8.95908e-05
	LOSS [training: 0.13389384057428333 | validation: 0.11058844291406755]
	TIME [epoch: 9.19 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13018393647422757		[learning rate: 8.9266e-05]
	Learning Rate: 8.92656e-05
	LOSS [training: 0.13018393647422757 | validation: 0.1004974309006297]
	TIME [epoch: 9.21 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12337066042076308		[learning rate: 8.8942e-05]
	Learning Rate: 8.89417e-05
	LOSS [training: 0.12337066042076308 | validation: 0.09294157081673945]
	TIME [epoch: 9.2 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12630065299410992		[learning rate: 8.8619e-05]
	Learning Rate: 8.86189e-05
	LOSS [training: 0.12630065299410992 | validation: 0.09665918799971716]
	TIME [epoch: 9.18 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1271176771074209		[learning rate: 8.8297e-05]
	Learning Rate: 8.82973e-05
	LOSS [training: 0.1271176771074209 | validation: 0.11843126490180961]
	TIME [epoch: 9.19 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1115230377575096		[learning rate: 8.7977e-05]
	Learning Rate: 8.79769e-05
	LOSS [training: 0.1115230377575096 | validation: 0.09044212921653232]
	TIME [epoch: 9.19 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1155844501476504		[learning rate: 8.7658e-05]
	Learning Rate: 8.76576e-05
	LOSS [training: 0.1155844501476504 | validation: 0.08045172257804752]
	TIME [epoch: 9.22 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11864773250818494		[learning rate: 8.7339e-05]
	Learning Rate: 8.73395e-05
	LOSS [training: 0.11864773250818494 | validation: 0.09186290191940505]
	TIME [epoch: 9.18 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11372129826809352		[learning rate: 8.7023e-05]
	Learning Rate: 8.70225e-05
	LOSS [training: 0.11372129826809352 | validation: 0.09299672932879746]
	TIME [epoch: 9.18 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12697920014860528		[learning rate: 8.6707e-05]
	Learning Rate: 8.67067e-05
	LOSS [training: 0.12697920014860528 | validation: 0.10186386472401707]
	TIME [epoch: 9.18 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11589078540534245		[learning rate: 8.6392e-05]
	Learning Rate: 8.63921e-05
	LOSS [training: 0.11589078540534245 | validation: 0.09369497417480334]
	TIME [epoch: 9.2 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12211943405863628		[learning rate: 8.6079e-05]
	Learning Rate: 8.60785e-05
	LOSS [training: 0.12211943405863628 | validation: 0.11426960187340399]
	TIME [epoch: 9.19 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12499966356076493		[learning rate: 8.5766e-05]
	Learning Rate: 8.57661e-05
	LOSS [training: 0.12499966356076493 | validation: 0.0895057131792192]
	TIME [epoch: 9.19 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12425982009849004		[learning rate: 8.5455e-05]
	Learning Rate: 8.54549e-05
	LOSS [training: 0.12425982009849004 | validation: 0.09612331499823737]
	TIME [epoch: 9.18 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11419155357531885		[learning rate: 8.5145e-05]
	Learning Rate: 8.51448e-05
	LOSS [training: 0.11419155357531885 | validation: 0.10101114983429113]
	TIME [epoch: 9.19 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13391731441022026		[learning rate: 8.4836e-05]
	Learning Rate: 8.48358e-05
	LOSS [training: 0.13391731441022026 | validation: 0.09104266964297399]
	TIME [epoch: 9.22 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13280675812067366		[learning rate: 8.4528e-05]
	Learning Rate: 8.45279e-05
	LOSS [training: 0.13280675812067366 | validation: 0.11741015219966974]
	TIME [epoch: 9.19 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1211301355022627		[learning rate: 8.4221e-05]
	Learning Rate: 8.42211e-05
	LOSS [training: 0.1211301355022627 | validation: 0.08790940932234813]
	TIME [epoch: 9.19 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13265888654067245		[learning rate: 8.3916e-05]
	Learning Rate: 8.39155e-05
	LOSS [training: 0.13265888654067245 | validation: 0.11658766479238357]
	TIME [epoch: 9.19 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12515243643832863		[learning rate: 8.3611e-05]
	Learning Rate: 8.3611e-05
	LOSS [training: 0.12515243643832863 | validation: 0.1085675231688435]
	TIME [epoch: 9.2 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14271274231855813		[learning rate: 8.3308e-05]
	Learning Rate: 8.33075e-05
	LOSS [training: 0.14271274231855813 | validation: 0.11331453413307205]
	TIME [epoch: 9.21 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13047313048574236		[learning rate: 8.3005e-05]
	Learning Rate: 8.30052e-05
	LOSS [training: 0.13047313048574236 | validation: 0.08558710402740652]
	TIME [epoch: 9.19 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12526201401220122		[learning rate: 8.2704e-05]
	Learning Rate: 8.2704e-05
	LOSS [training: 0.12526201401220122 | validation: 0.09051667417811052]
	TIME [epoch: 9.19 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12006027553337525		[learning rate: 8.2404e-05]
	Learning Rate: 8.24038e-05
	LOSS [training: 0.12006027553337525 | validation: 0.10075789986234185]
	TIME [epoch: 9.19 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11539543296989418		[learning rate: 8.2105e-05]
	Learning Rate: 8.21048e-05
	LOSS [training: 0.11539543296989418 | validation: 0.07604365623022243]
	TIME [epoch: 9.21 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12643241040123646		[learning rate: 8.1807e-05]
	Learning Rate: 8.18068e-05
	LOSS [training: 0.12643241040123646 | validation: 0.08980431476919572]
	TIME [epoch: 9.19 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11899667441340267		[learning rate: 8.151e-05]
	Learning Rate: 8.15099e-05
	LOSS [training: 0.11899667441340267 | validation: 0.09191153000292425]
	TIME [epoch: 9.19 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11915247309654045		[learning rate: 8.1214e-05]
	Learning Rate: 8.12142e-05
	LOSS [training: 0.11915247309654045 | validation: 0.08662733209341739]
	TIME [epoch: 9.2 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12205039334262116		[learning rate: 8.0919e-05]
	Learning Rate: 8.09194e-05
	LOSS [training: 0.12205039334262116 | validation: 0.09316102367361595]
	TIME [epoch: 9.21 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12437621266554588		[learning rate: 8.0626e-05]
	Learning Rate: 8.06257e-05
	LOSS [training: 0.12437621266554588 | validation: 0.08651646363831245]
	TIME [epoch: 9.2 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1238305507121735		[learning rate: 8.0333e-05]
	Learning Rate: 8.03331e-05
	LOSS [training: 0.1238305507121735 | validation: 0.09108176081585186]
	TIME [epoch: 9.19 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11472897536733884		[learning rate: 8.0042e-05]
	Learning Rate: 8.00416e-05
	LOSS [training: 0.11472897536733884 | validation: 0.07901215262791733]
	TIME [epoch: 9.2 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11737547880945862		[learning rate: 7.9751e-05]
	Learning Rate: 7.97511e-05
	LOSS [training: 0.11737547880945862 | validation: 0.0953912853752448]
	TIME [epoch: 9.19 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11666404704616831		[learning rate: 7.9462e-05]
	Learning Rate: 7.94617e-05
	LOSS [training: 0.11666404704616831 | validation: 0.08981003681230454]
	TIME [epoch: 9.23 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12819646975673216		[learning rate: 7.9173e-05]
	Learning Rate: 7.91733e-05
	LOSS [training: 0.12819646975673216 | validation: 0.09051562841444905]
	TIME [epoch: 9.19 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11979988560976622		[learning rate: 7.8886e-05]
	Learning Rate: 7.8886e-05
	LOSS [training: 0.11979988560976622 | validation: 0.09353092177881216]
	TIME [epoch: 9.19 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12223784421439676		[learning rate: 7.86e-05]
	Learning Rate: 7.85997e-05
	LOSS [training: 0.12223784421439676 | validation: 0.08940627223700662]
	TIME [epoch: 9.19 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12882850769803011		[learning rate: 7.8315e-05]
	Learning Rate: 7.83145e-05
	LOSS [training: 0.12882850769803011 | validation: 0.0941449861183336]
	TIME [epoch: 9.2 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1168811066073497		[learning rate: 7.803e-05]
	Learning Rate: 7.80303e-05
	LOSS [training: 0.1168811066073497 | validation: 0.09981570580929217]
	TIME [epoch: 9.2 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11585663014640238		[learning rate: 7.7747e-05]
	Learning Rate: 7.77471e-05
	LOSS [training: 0.11585663014640238 | validation: 0.09157963409249528]
	TIME [epoch: 9.19 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11789379046353779		[learning rate: 7.7465e-05]
	Learning Rate: 7.7465e-05
	LOSS [training: 0.11789379046353779 | validation: 0.09775848298263701]
	TIME [epoch: 9.2 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11992513344282807		[learning rate: 7.7184e-05]
	Learning Rate: 7.71838e-05
	LOSS [training: 0.11992513344282807 | validation: 0.09623328662212147]
	TIME [epoch: 9.19 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10790363081908538		[learning rate: 7.6904e-05]
	Learning Rate: 7.69037e-05
	LOSS [training: 0.10790363081908538 | validation: 0.09977686739284364]
	TIME [epoch: 9.21 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11853104884185466		[learning rate: 7.6625e-05]
	Learning Rate: 7.66246e-05
	LOSS [training: 0.11853104884185466 | validation: 0.09362372379970368]
	TIME [epoch: 9.19 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1146738468698885		[learning rate: 7.6347e-05]
	Learning Rate: 7.63466e-05
	LOSS [training: 0.1146738468698885 | validation: 0.08831147501960754]
	TIME [epoch: 9.19 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1215114797318737		[learning rate: 7.607e-05]
	Learning Rate: 7.60695e-05
	LOSS [training: 0.1215114797318737 | validation: 0.09596699632939498]
	TIME [epoch: 9.19 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11980677884378406		[learning rate: 7.5793e-05]
	Learning Rate: 7.57935e-05
	LOSS [training: 0.11980677884378406 | validation: 0.1061103925440946]
	TIME [epoch: 9.2 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12038043964563802		[learning rate: 7.5518e-05]
	Learning Rate: 7.55184e-05
	LOSS [training: 0.12038043964563802 | validation: 0.10951690357467161]
	TIME [epoch: 9.2 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12058194462439269		[learning rate: 7.5244e-05]
	Learning Rate: 7.52443e-05
	LOSS [training: 0.12058194462439269 | validation: 0.09149156677956556]
	TIME [epoch: 9.19 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11812002119088269		[learning rate: 7.4971e-05]
	Learning Rate: 7.49712e-05
	LOSS [training: 0.11812002119088269 | validation: 0.08807628379771333]
	TIME [epoch: 9.18 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10748052396644225		[learning rate: 7.4699e-05]
	Learning Rate: 7.46992e-05
	LOSS [training: 0.10748052396644225 | validation: 0.10239686882801141]
	TIME [epoch: 9.18 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1191481502966063		[learning rate: 7.4428e-05]
	Learning Rate: 7.44281e-05
	LOSS [training: 0.1191481502966063 | validation: 0.08886341265114173]
	TIME [epoch: 9.21 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11852938227660828		[learning rate: 7.4158e-05]
	Learning Rate: 7.4158e-05
	LOSS [training: 0.11852938227660828 | validation: 0.09572028475813471]
	TIME [epoch: 9.19 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12488609998666589		[learning rate: 7.3889e-05]
	Learning Rate: 7.38889e-05
	LOSS [training: 0.12488609998666589 | validation: 0.09247979410725723]
	TIME [epoch: 9.17 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1183068083948865		[learning rate: 7.3621e-05]
	Learning Rate: 7.36207e-05
	LOSS [training: 0.1183068083948865 | validation: 0.07935251258481932]
	TIME [epoch: 9.18 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11010332621500847		[learning rate: 7.3354e-05]
	Learning Rate: 7.33536e-05
	LOSS [training: 0.11010332621500847 | validation: 0.0868218749488471]
	TIME [epoch: 9.19 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12260402658234323		[learning rate: 7.3087e-05]
	Learning Rate: 7.30873e-05
	LOSS [training: 0.12260402658234323 | validation: 0.10045898678835478]
	TIME [epoch: 9.2 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11892673639070037		[learning rate: 7.2822e-05]
	Learning Rate: 7.28221e-05
	LOSS [training: 0.11892673639070037 | validation: 0.09964708476567077]
	TIME [epoch: 9.19 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12237135824333252		[learning rate: 7.2558e-05]
	Learning Rate: 7.25578e-05
	LOSS [training: 0.12237135824333252 | validation: 0.10167398949810141]
	TIME [epoch: 9.2 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12232094277648513		[learning rate: 7.2295e-05]
	Learning Rate: 7.22945e-05
	LOSS [training: 0.12232094277648513 | validation: 0.10262543680863198]
	TIME [epoch: 9.19 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11898775745756415		[learning rate: 7.2032e-05]
	Learning Rate: 7.20321e-05
	LOSS [training: 0.11898775745756415 | validation: 0.10176511016399621]
	TIME [epoch: 9.21 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.113600247927002		[learning rate: 7.1771e-05]
	Learning Rate: 7.17707e-05
	LOSS [training: 0.113600247927002 | validation: 0.09317644094163588]
	TIME [epoch: 9.19 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10695002944391292		[learning rate: 7.151e-05]
	Learning Rate: 7.15103e-05
	LOSS [training: 0.10695002944391292 | validation: 0.08954817560180112]
	TIME [epoch: 9.19 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11387278352882786		[learning rate: 7.1251e-05]
	Learning Rate: 7.12508e-05
	LOSS [training: 0.11387278352882786 | validation: 0.09319493032586318]
	TIME [epoch: 9.19 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10890708154166791		[learning rate: 7.0992e-05]
	Learning Rate: 7.09922e-05
	LOSS [training: 0.10890708154166791 | validation: 0.09200990235255488]
	TIME [epoch: 9.2 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11661402004724611		[learning rate: 7.0735e-05]
	Learning Rate: 7.07345e-05
	LOSS [training: 0.11661402004724611 | validation: 0.09015188747931516]
	TIME [epoch: 9.2 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11731741314487179		[learning rate: 7.0478e-05]
	Learning Rate: 7.04778e-05
	LOSS [training: 0.11731741314487179 | validation: 0.09155080623647927]
	TIME [epoch: 9.19 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12349335136401278		[learning rate: 7.0222e-05]
	Learning Rate: 7.02221e-05
	LOSS [training: 0.12349335136401278 | validation: 0.09056361435493707]
	TIME [epoch: 9.19 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12257053883845279		[learning rate: 6.9967e-05]
	Learning Rate: 6.99672e-05
	LOSS [training: 0.12257053883845279 | validation: 0.09995623541821608]
	TIME [epoch: 9.19 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1168162182411386		[learning rate: 6.9713e-05]
	Learning Rate: 6.97133e-05
	LOSS [training: 0.1168162182411386 | validation: 0.09646987905524557]
	TIME [epoch: 9.22 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12497377005139035		[learning rate: 6.946e-05]
	Learning Rate: 6.94603e-05
	LOSS [training: 0.12497377005139035 | validation: 0.08644612271165766]
	TIME [epoch: 9.2 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12053996742216302		[learning rate: 6.9208e-05]
	Learning Rate: 6.92083e-05
	LOSS [training: 0.12053996742216302 | validation: 0.09619203913472041]
	TIME [epoch: 9.18 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11987702433766474		[learning rate: 6.8957e-05]
	Learning Rate: 6.89571e-05
	LOSS [training: 0.11987702433766474 | validation: 0.09284881276893064]
	TIME [epoch: 9.19 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13068241966231328		[learning rate: 6.8707e-05]
	Learning Rate: 6.87068e-05
	LOSS [training: 0.13068241966231328 | validation: 0.10939962836576819]
	TIME [epoch: 9.2 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12522800343806778		[learning rate: 6.8457e-05]
	Learning Rate: 6.84575e-05
	LOSS [training: 0.12522800343806778 | validation: 0.09775143568116382]
	TIME [epoch: 9.21 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13052765049993764		[learning rate: 6.8209e-05]
	Learning Rate: 6.82091e-05
	LOSS [training: 0.13052765049993764 | validation: 0.1044918111383166]
	TIME [epoch: 9.19 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1466610099121099		[learning rate: 6.7962e-05]
	Learning Rate: 6.79615e-05
	LOSS [training: 0.1466610099121099 | validation: 0.10757726453772895]
	TIME [epoch: 9.18 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1463962709958861		[learning rate: 6.7715e-05]
	Learning Rate: 6.77149e-05
	LOSS [training: 0.1463962709958861 | validation: 0.10128366500358349]
	TIME [epoch: 9.18 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13060284490387902		[learning rate: 6.7469e-05]
	Learning Rate: 6.74692e-05
	LOSS [training: 0.13060284490387902 | validation: 0.09457848057018642]
	TIME [epoch: 9.21 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13806964326217333		[learning rate: 6.7224e-05]
	Learning Rate: 6.72243e-05
	LOSS [training: 0.13806964326217333 | validation: 0.1067417511994588]
	TIME [epoch: 9.19 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13265776362521486		[learning rate: 6.698e-05]
	Learning Rate: 6.69804e-05
	LOSS [training: 0.13265776362521486 | validation: 0.09081522664627639]
	TIME [epoch: 9.18 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11671114098291895		[learning rate: 6.6737e-05]
	Learning Rate: 6.67373e-05
	LOSS [training: 0.11671114098291895 | validation: 0.09216295163942045]
	TIME [epoch: 9.19 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11596905462326428		[learning rate: 6.6495e-05]
	Learning Rate: 6.64951e-05
	LOSS [training: 0.11596905462326428 | validation: 0.07621376705826527]
	TIME [epoch: 9.19 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11882324906337202		[learning rate: 6.6254e-05]
	Learning Rate: 6.62538e-05
	LOSS [training: 0.11882324906337202 | validation: 0.08662312968657951]
	TIME [epoch: 9.21 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11871878350002829		[learning rate: 6.6013e-05]
	Learning Rate: 6.60133e-05
	LOSS [training: 0.11871878350002829 | validation: 0.08811512170302671]
	TIME [epoch: 9.19 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1175710740345283		[learning rate: 6.5774e-05]
	Learning Rate: 6.57738e-05
	LOSS [training: 0.1175710740345283 | validation: 0.10383438795708574]
	TIME [epoch: 9.18 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12661826241436117		[learning rate: 6.5535e-05]
	Learning Rate: 6.55351e-05
	LOSS [training: 0.12661826241436117 | validation: 0.09086767510702466]
	TIME [epoch: 9.18 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12420317437232879		[learning rate: 6.5297e-05]
	Learning Rate: 6.52972e-05
	LOSS [training: 0.12420317437232879 | validation: 0.09438230588198213]
	TIME [epoch: 9.2 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11416213265342345		[learning rate: 6.506e-05]
	Learning Rate: 6.50603e-05
	LOSS [training: 0.11416213265342345 | validation: 0.09839576562515256]
	TIME [epoch: 9.18 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12322041763498766		[learning rate: 6.4824e-05]
	Learning Rate: 6.48242e-05
	LOSS [training: 0.12322041763498766 | validation: 0.09292009536740989]
	TIME [epoch: 9.19 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1164571518400275		[learning rate: 6.4589e-05]
	Learning Rate: 6.45889e-05
	LOSS [training: 0.1164571518400275 | validation: 0.10094646042703329]
	TIME [epoch: 9.19 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.126542954733335		[learning rate: 6.4354e-05]
	Learning Rate: 6.43545e-05
	LOSS [training: 0.126542954733335 | validation: 0.10040475538930843]
	TIME [epoch: 9.2 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11739485999893803		[learning rate: 6.4121e-05]
	Learning Rate: 6.4121e-05
	LOSS [training: 0.11739485999893803 | validation: 0.08058304526450398]
	TIME [epoch: 9.21 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12317137493672874		[learning rate: 6.3888e-05]
	Learning Rate: 6.38883e-05
	LOSS [training: 0.12317137493672874 | validation: 0.09395058715773358]
	TIME [epoch: 9.19 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1324585624815934		[learning rate: 6.3656e-05]
	Learning Rate: 6.36564e-05
	LOSS [training: 0.1324585624815934 | validation: 0.09533072462284559]
	TIME [epoch: 9.18 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12597873043555427		[learning rate: 6.3425e-05]
	Learning Rate: 6.34254e-05
	LOSS [training: 0.12597873043555427 | validation: 0.08942715246274838]
	TIME [epoch: 9.18 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13024790823397128		[learning rate: 6.3195e-05]
	Learning Rate: 6.31952e-05
	LOSS [training: 0.13024790823397128 | validation: 0.09055969878629255]
	TIME [epoch: 9.21 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11511871612781728		[learning rate: 6.2966e-05]
	Learning Rate: 6.29659e-05
	LOSS [training: 0.11511871612781728 | validation: 0.0846933949349361]
	TIME [epoch: 9.2 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11957174012653718		[learning rate: 6.2737e-05]
	Learning Rate: 6.27374e-05
	LOSS [training: 0.11957174012653718 | validation: 0.08611419631001685]
	TIME [epoch: 9.19 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11909009152438577		[learning rate: 6.251e-05]
	Learning Rate: 6.25097e-05
	LOSS [training: 0.11909009152438577 | validation: 0.07958532284112536]
	TIME [epoch: 9.18 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11347806993312681		[learning rate: 6.2283e-05]
	Learning Rate: 6.22828e-05
	LOSS [training: 0.11347806993312681 | validation: 0.09643392132118656]
	TIME [epoch: 9.19 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11173126750312139		[learning rate: 6.2057e-05]
	Learning Rate: 6.20568e-05
	LOSS [training: 0.11173126750312139 | validation: 0.0944940117905963]
	TIME [epoch: 9.2 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11689200723134015		[learning rate: 6.1832e-05]
	Learning Rate: 6.18316e-05
	LOSS [training: 0.11689200723134015 | validation: 0.09002689223325054]
	TIME [epoch: 9.19 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12146034250699136		[learning rate: 6.1607e-05]
	Learning Rate: 6.16072e-05
	LOSS [training: 0.12146034250699136 | validation: 0.07972163722928258]
	TIME [epoch: 9.18 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11385765430519638		[learning rate: 6.1384e-05]
	Learning Rate: 6.13836e-05
	LOSS [training: 0.11385765430519638 | validation: 0.0810711786041744]
	TIME [epoch: 9.18 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11349901422707076		[learning rate: 6.1161e-05]
	Learning Rate: 6.11609e-05
	LOSS [training: 0.11349901422707076 | validation: 0.086464762038373]
	TIME [epoch: 9.2 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11502136687154907		[learning rate: 6.0939e-05]
	Learning Rate: 6.09389e-05
	LOSS [training: 0.11502136687154907 | validation: 0.09131370194420103]
	TIME [epoch: 9.2 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1104566263403324		[learning rate: 6.0718e-05]
	Learning Rate: 6.07178e-05
	LOSS [training: 0.1104566263403324 | validation: 0.08515868405794676]
	TIME [epoch: 9.2 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11632696849127892		[learning rate: 6.0497e-05]
	Learning Rate: 6.04974e-05
	LOSS [training: 0.11632696849127892 | validation: 0.08571317393468673]
	TIME [epoch: 9.2 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11762822408706135		[learning rate: 6.0278e-05]
	Learning Rate: 6.02779e-05
	LOSS [training: 0.11762822408706135 | validation: 0.08899400160357056]
	TIME [epoch: 9.19 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11326290823140943		[learning rate: 6.0059e-05]
	Learning Rate: 6.00591e-05
	LOSS [training: 0.11326290823140943 | validation: 0.09118441151789679]
	TIME [epoch: 9.22 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11249489369797974		[learning rate: 5.9841e-05]
	Learning Rate: 5.98412e-05
	LOSS [training: 0.11249489369797974 | validation: 0.10057238252420947]
	TIME [epoch: 9.19 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10605190915726544		[learning rate: 5.9624e-05]
	Learning Rate: 5.9624e-05
	LOSS [training: 0.10605190915726544 | validation: 0.07962348855353821]
	TIME [epoch: 9.2 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1258957139090195		[learning rate: 5.9408e-05]
	Learning Rate: 5.94076e-05
	LOSS [training: 0.1258957139090195 | validation: 0.09409421954855174]
	TIME [epoch: 9.19 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11951653739364868		[learning rate: 5.9192e-05]
	Learning Rate: 5.9192e-05
	LOSS [training: 0.11951653739364868 | validation: 0.09218365945418286]
	TIME [epoch: 9.21 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12276172765120738		[learning rate: 5.8977e-05]
	Learning Rate: 5.89772e-05
	LOSS [training: 0.12276172765120738 | validation: 0.08775711775466835]
	TIME [epoch: 9.2 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1152879962312842		[learning rate: 5.8763e-05]
	Learning Rate: 5.87632e-05
	LOSS [training: 0.1152879962312842 | validation: 0.08181480337735159]
	TIME [epoch: 9.19 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11231396018821826		[learning rate: 5.855e-05]
	Learning Rate: 5.85499e-05
	LOSS [training: 0.11231396018821826 | validation: 0.08902758367636042]
	TIME [epoch: 9.19 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11845298900253995		[learning rate: 5.8337e-05]
	Learning Rate: 5.83374e-05
	LOSS [training: 0.11845298900253995 | validation: 0.09396501813967434]
	TIME [epoch: 9.19 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11493032459056043		[learning rate: 5.8126e-05]
	Learning Rate: 5.81257e-05
	LOSS [training: 0.11493032459056043 | validation: 0.08255452939256619]
	TIME [epoch: 9.22 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11248681318809654		[learning rate: 5.7915e-05]
	Learning Rate: 5.79148e-05
	LOSS [training: 0.11248681318809654 | validation: 0.08687668343529661]
	TIME [epoch: 9.19 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10937217484261605		[learning rate: 5.7705e-05]
	Learning Rate: 5.77046e-05
	LOSS [training: 0.10937217484261605 | validation: 0.0830650390518499]
	TIME [epoch: 9.21 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11516954191813114		[learning rate: 5.7495e-05]
	Learning Rate: 5.74952e-05
	LOSS [training: 0.11516954191813114 | validation: 0.08261988444110767]
	TIME [epoch: 9.21 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11851688052515467		[learning rate: 5.7287e-05]
	Learning Rate: 5.72866e-05
	LOSS [training: 0.11851688052515467 | validation: 0.08171506143536503]
	TIME [epoch: 9.21 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10695559450694606		[learning rate: 5.7079e-05]
	Learning Rate: 5.70787e-05
	LOSS [training: 0.10695559450694606 | validation: 0.09253051547864666]
	TIME [epoch: 9.22 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12435102961432087		[learning rate: 5.6872e-05]
	Learning Rate: 5.68715e-05
	LOSS [training: 0.12435102961432087 | validation: 0.09659580817763246]
	TIME [epoch: 9.19 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1237070306954328		[learning rate: 5.6665e-05]
	Learning Rate: 5.66651e-05
	LOSS [training: 0.1237070306954328 | validation: 0.08960062365913746]
	TIME [epoch: 9.19 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12759283604044927		[learning rate: 5.6459e-05]
	Learning Rate: 5.64595e-05
	LOSS [training: 0.12759283604044927 | validation: 0.08991801636870078]
	TIME [epoch: 9.19 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11703134025695812		[learning rate: 5.6255e-05]
	Learning Rate: 5.62546e-05
	LOSS [training: 0.11703134025695812 | validation: 0.09391746671493101]
	TIME [epoch: 9.22 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11984767573279467		[learning rate: 5.605e-05]
	Learning Rate: 5.60504e-05
	LOSS [training: 0.11984767573279467 | validation: 0.09811710226123725]
	TIME [epoch: 9.19 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1274139919724074		[learning rate: 5.5847e-05]
	Learning Rate: 5.5847e-05
	LOSS [training: 0.1274139919724074 | validation: 0.08843059155522828]
	TIME [epoch: 9.19 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11133734705201145		[learning rate: 5.5644e-05]
	Learning Rate: 5.56444e-05
	LOSS [training: 0.11133734705201145 | validation: 0.10087871101046625]
	TIME [epoch: 9.19 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11704883494103242		[learning rate: 5.5442e-05]
	Learning Rate: 5.54424e-05
	LOSS [training: 0.11704883494103242 | validation: 0.09271062590090606]
	TIME [epoch: 9.2 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11697619694596528		[learning rate: 5.5241e-05]
	Learning Rate: 5.52412e-05
	LOSS [training: 0.11697619694596528 | validation: 0.091760085705059]
	TIME [epoch: 9.2 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11817530190829766		[learning rate: 5.5041e-05]
	Learning Rate: 5.50407e-05
	LOSS [training: 0.11817530190829766 | validation: 0.08826273576315517]
	TIME [epoch: 9.19 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1215511895087235		[learning rate: 5.4841e-05]
	Learning Rate: 5.4841e-05
	LOSS [training: 0.1215511895087235 | validation: 0.08818641879229161]
	TIME [epoch: 9.2 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11814046294878737		[learning rate: 5.4642e-05]
	Learning Rate: 5.4642e-05
	LOSS [training: 0.11814046294878737 | validation: 0.0936452374399176]
	TIME [epoch: 9.2 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11849871109838668		[learning rate: 5.4444e-05]
	Learning Rate: 5.44437e-05
	LOSS [training: 0.11849871109838668 | validation: 0.0846771082610217]
	TIME [epoch: 9.21 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11435883810786347		[learning rate: 5.4246e-05]
	Learning Rate: 5.42461e-05
	LOSS [training: 0.11435883810786347 | validation: 0.10197407202220904]
	TIME [epoch: 9.2 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12601347734539214		[learning rate: 5.4049e-05]
	Learning Rate: 5.40492e-05
	LOSS [training: 0.12601347734539214 | validation: 0.09064924239990081]
	TIME [epoch: 9.19 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11583183112863667		[learning rate: 5.3853e-05]
	Learning Rate: 5.38531e-05
	LOSS [training: 0.11583183112863667 | validation: 0.08700968518146096]
	TIME [epoch: 9.19 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10982313370253374		[learning rate: 5.3658e-05]
	Learning Rate: 5.36577e-05
	LOSS [training: 0.10982313370253374 | validation: 0.09237034541127295]
	TIME [epoch: 9.2 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12461537412982415		[learning rate: 5.3463e-05]
	Learning Rate: 5.34629e-05
	LOSS [training: 0.12461537412982415 | validation: 0.09249322360814682]
	TIME [epoch: 9.21 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10383214819615538		[learning rate: 5.3269e-05]
	Learning Rate: 5.32689e-05
	LOSS [training: 0.10383214819615538 | validation: 0.08484098931857995]
	TIME [epoch: 9.19 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11685605238110555		[learning rate: 5.3076e-05]
	Learning Rate: 5.30756e-05
	LOSS [training: 0.11685605238110555 | validation: 0.09119428011286637]
	TIME [epoch: 9.19 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11184421979811025		[learning rate: 5.2883e-05]
	Learning Rate: 5.2883e-05
	LOSS [training: 0.11184421979811025 | validation: 0.09037900726075704]
	TIME [epoch: 9.19 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1179270951308323		[learning rate: 5.2691e-05]
	Learning Rate: 5.26911e-05
	LOSS [training: 0.1179270951308323 | validation: 0.09184211573334702]
	TIME [epoch: 9.21 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12077057201452934		[learning rate: 5.25e-05]
	Learning Rate: 5.24998e-05
	LOSS [training: 0.12077057201452934 | validation: 0.0952899664809088]
	TIME [epoch: 9.19 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12171958421246654		[learning rate: 5.2309e-05]
	Learning Rate: 5.23093e-05
	LOSS [training: 0.12171958421246654 | validation: 0.08540256592868885]
	TIME [epoch: 9.19 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11493716202277164		[learning rate: 5.2119e-05]
	Learning Rate: 5.21195e-05
	LOSS [training: 0.11493716202277164 | validation: 0.09227186653129589]
	TIME [epoch: 9.19 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10804200157128971		[learning rate: 5.193e-05]
	Learning Rate: 5.19303e-05
	LOSS [training: 0.10804200157128971 | validation: 0.09192239921265394]
	TIME [epoch: 9.21 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12000368909308498		[learning rate: 5.1742e-05]
	Learning Rate: 5.17419e-05
	LOSS [training: 0.12000368909308498 | validation: 0.0787805097243465]
	TIME [epoch: 9.22 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.111382953333039		[learning rate: 5.1554e-05]
	Learning Rate: 5.15541e-05
	LOSS [training: 0.111382953333039 | validation: 0.08515650614153858]
	TIME [epoch: 9.2 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12038910923317747		[learning rate: 5.1367e-05]
	Learning Rate: 5.1367e-05
	LOSS [training: 0.12038910923317747 | validation: 0.08573136445382751]
	TIME [epoch: 9.18 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11569317596324054		[learning rate: 5.1181e-05]
	Learning Rate: 5.11806e-05
	LOSS [training: 0.11569317596324054 | validation: 0.10413450348279023]
	TIME [epoch: 9.19 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12488516955219235		[learning rate: 5.0995e-05]
	Learning Rate: 5.09949e-05
	LOSS [training: 0.12488516955219235 | validation: 0.09948238038710074]
	TIME [epoch: 9.23 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11666047970168525		[learning rate: 5.081e-05]
	Learning Rate: 5.08098e-05
	LOSS [training: 0.11666047970168525 | validation: 0.08573076874819686]
	TIME [epoch: 9.21 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12883733247103193		[learning rate: 5.0625e-05]
	Learning Rate: 5.06254e-05
	LOSS [training: 0.12883733247103193 | validation: 0.08739945377149397]
	TIME [epoch: 9.18 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11684316619760471		[learning rate: 5.0442e-05]
	Learning Rate: 5.04417e-05
	LOSS [training: 0.11684316619760471 | validation: 0.08885807034904968]
	TIME [epoch: 9.19 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1135459075073971		[learning rate: 5.0259e-05]
	Learning Rate: 5.02586e-05
	LOSS [training: 0.1135459075073971 | validation: 0.10265795274790353]
	TIME [epoch: 9.2 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11455486627708397		[learning rate: 5.0076e-05]
	Learning Rate: 5.00762e-05
	LOSS [training: 0.11455486627708397 | validation: 0.09163125299297009]
	TIME [epoch: 9.21 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11892035973436155		[learning rate: 4.9894e-05]
	Learning Rate: 4.98945e-05
	LOSS [training: 0.11892035973436155 | validation: 0.10750548171849855]
	TIME [epoch: 9.19 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1075225297705857		[learning rate: 4.9713e-05]
	Learning Rate: 4.97134e-05
	LOSS [training: 0.1075225297705857 | validation: 0.10031340594533165]
	TIME [epoch: 9.2 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11439991170505041		[learning rate: 4.9533e-05]
	Learning Rate: 4.9533e-05
	LOSS [training: 0.11439991170505041 | validation: 0.09345502059845075]
	TIME [epoch: 9.2 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11813098151416897		[learning rate: 4.9353e-05]
	Learning Rate: 4.93533e-05
	LOSS [training: 0.11813098151416897 | validation: 0.09424958334553224]
	TIME [epoch: 9.21 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10480862527415791		[learning rate: 4.9174e-05]
	Learning Rate: 4.91742e-05
	LOSS [training: 0.10480862527415791 | validation: 0.08208134646024715]
	TIME [epoch: 9.19 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12543441506810576		[learning rate: 4.8996e-05]
	Learning Rate: 4.89957e-05
	LOSS [training: 0.12543441506810576 | validation: 0.08208143259572626]
	TIME [epoch: 9.19 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11817884137388726		[learning rate: 4.8818e-05]
	Learning Rate: 4.88179e-05
	LOSS [training: 0.11817884137388726 | validation: 0.08095013744878508]
	TIME [epoch: 9.19 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11843990745934736		[learning rate: 4.8641e-05]
	Learning Rate: 4.86407e-05
	LOSS [training: 0.11843990745934736 | validation: 0.09646707404741309]
	TIME [epoch: 9.2 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11794117814460267		[learning rate: 4.8464e-05]
	Learning Rate: 4.84642e-05
	LOSS [training: 0.11794117814460267 | validation: 0.10092040768444982]
	TIME [epoch: 9.2 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1234115700146741		[learning rate: 4.8288e-05]
	Learning Rate: 4.82883e-05
	LOSS [training: 0.1234115700146741 | validation: 0.09036636584231594]
	TIME [epoch: 9.19 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11831594410404382		[learning rate: 4.8113e-05]
	Learning Rate: 4.81131e-05
	LOSS [training: 0.11831594410404382 | validation: 0.08732730717561414]
	TIME [epoch: 9.19 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11399696911057193		[learning rate: 4.7938e-05]
	Learning Rate: 4.79385e-05
	LOSS [training: 0.11399696911057193 | validation: 0.09956081408988648]
	TIME [epoch: 9.2 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11286004627963198		[learning rate: 4.7765e-05]
	Learning Rate: 4.77645e-05
	LOSS [training: 0.11286004627963198 | validation: 0.08722752817584274]
	TIME [epoch: 9.21 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11849292679995815		[learning rate: 4.7591e-05]
	Learning Rate: 4.75912e-05
	LOSS [training: 0.11849292679995815 | validation: 0.08945913884557516]
	TIME [epoch: 9.2 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11805168271757574		[learning rate: 4.7418e-05]
	Learning Rate: 4.74185e-05
	LOSS [training: 0.11805168271757574 | validation: 0.09167537899464057]
	TIME [epoch: 9.19 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11317713182481279		[learning rate: 4.7246e-05]
	Learning Rate: 4.72464e-05
	LOSS [training: 0.11317713182481279 | validation: 0.08747460240117744]
	TIME [epoch: 9.2 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12102246838797522		[learning rate: 4.7075e-05]
	Learning Rate: 4.70749e-05
	LOSS [training: 0.12102246838797522 | validation: 0.08069946830869458]
	TIME [epoch: 9.2 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11809614851162335		[learning rate: 4.6904e-05]
	Learning Rate: 4.69041e-05
	LOSS [training: 0.11809614851162335 | validation: 0.08936270082319925]
	TIME [epoch: 9.2 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11997194087836176		[learning rate: 4.6734e-05]
	Learning Rate: 4.67339e-05
	LOSS [training: 0.11997194087836176 | validation: 0.09410378407896669]
	TIME [epoch: 9.19 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1162497241690672		[learning rate: 4.6564e-05]
	Learning Rate: 4.65643e-05
	LOSS [training: 0.1162497241690672 | validation: 0.0913911583251279]
	TIME [epoch: 9.18 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12339835738675124		[learning rate: 4.6395e-05]
	Learning Rate: 4.63953e-05
	LOSS [training: 0.12339835738675124 | validation: 0.10241602764518526]
	TIME [epoch: 9.18 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11535695269587858		[learning rate: 4.6227e-05]
	Learning Rate: 4.62269e-05
	LOSS [training: 0.11535695269587858 | validation: 0.10141455978141056]
	TIME [epoch: 9.2 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12015681427139424		[learning rate: 4.6059e-05]
	Learning Rate: 4.60591e-05
	LOSS [training: 0.12015681427139424 | validation: 0.08717901821754404]
	TIME [epoch: 9.19 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10726404595722021		[learning rate: 4.5892e-05]
	Learning Rate: 4.5892e-05
	LOSS [training: 0.10726404595722021 | validation: 0.09021786033097781]
	TIME [epoch: 9.18 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11704297289688		[learning rate: 4.5725e-05]
	Learning Rate: 4.57254e-05
	LOSS [training: 0.11704297289688 | validation: 0.09746345960187137]
	TIME [epoch: 9.18 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12111648005331346		[learning rate: 4.556e-05]
	Learning Rate: 4.55595e-05
	LOSS [training: 0.12111648005331346 | validation: 0.09671536610337499]
	TIME [epoch: 9.19 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11858903158385577		[learning rate: 4.5394e-05]
	Learning Rate: 4.53942e-05
	LOSS [training: 0.11858903158385577 | validation: 0.10258609091447474]
	TIME [epoch: 9.2 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1112465745693415		[learning rate: 4.5229e-05]
	Learning Rate: 4.52294e-05
	LOSS [training: 0.1112465745693415 | validation: 0.11951008358590123]
	TIME [epoch: 9.19 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12015180805023443		[learning rate: 4.5065e-05]
	Learning Rate: 4.50653e-05
	LOSS [training: 0.12015180805023443 | validation: 0.09538908843706896]
	TIME [epoch: 9.21 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11632498598973737		[learning rate: 4.4902e-05]
	Learning Rate: 4.49017e-05
	LOSS [training: 0.11632498598973737 | validation: 0.0807370215225855]
	TIME [epoch: 9.18 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11521812540782612		[learning rate: 4.4739e-05]
	Learning Rate: 4.47388e-05
	LOSS [training: 0.11521812540782612 | validation: 0.09200038432035647]
	TIME [epoch: 9.21 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11292332382184926		[learning rate: 4.4576e-05]
	Learning Rate: 4.45764e-05
	LOSS [training: 0.11292332382184926 | validation: 0.09565645617646656]
	TIME [epoch: 9.19 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11869653487426705		[learning rate: 4.4415e-05]
	Learning Rate: 4.44147e-05
	LOSS [training: 0.11869653487426705 | validation: 0.09396522225121566]
	TIME [epoch: 9.19 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11731491158710883		[learning rate: 4.4253e-05]
	Learning Rate: 4.42535e-05
	LOSS [training: 0.11731491158710883 | validation: 0.09040694754884844]
	TIME [epoch: 9.18 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12020011319369692		[learning rate: 4.4093e-05]
	Learning Rate: 4.40929e-05
	LOSS [training: 0.12020011319369692 | validation: 0.09251648942002523]
	TIME [epoch: 9.19 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11876682233066864		[learning rate: 4.3933e-05]
	Learning Rate: 4.39329e-05
	LOSS [training: 0.11876682233066864 | validation: 0.09446782196028303]
	TIME [epoch: 9.22 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1300667497105462		[learning rate: 4.3773e-05]
	Learning Rate: 4.37734e-05
	LOSS [training: 0.1300667497105462 | validation: 0.08376335329890693]
	TIME [epoch: 9.19 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.117562287012559		[learning rate: 4.3615e-05]
	Learning Rate: 4.36146e-05
	LOSS [training: 0.117562287012559 | validation: 0.09137683205521722]
	TIME [epoch: 9.19 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12354160231230164		[learning rate: 4.3456e-05]
	Learning Rate: 4.34563e-05
	LOSS [training: 0.12354160231230164 | validation: 0.09815826057283449]
	TIME [epoch: 9.18 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11610421774302812		[learning rate: 4.3299e-05]
	Learning Rate: 4.32986e-05
	LOSS [training: 0.11610421774302812 | validation: 0.0953981956427246]
	TIME [epoch: 9.21 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11947654022715817		[learning rate: 4.3141e-05]
	Learning Rate: 4.31415e-05
	LOSS [training: 0.11947654022715817 | validation: 0.0859378162575057]
	TIME [epoch: 9.19 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11519923640644583		[learning rate: 4.2985e-05]
	Learning Rate: 4.29849e-05
	LOSS [training: 0.11519923640644583 | validation: 0.08334601333958383]
	TIME [epoch: 9.18 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11350442973081214		[learning rate: 4.2829e-05]
	Learning Rate: 4.28289e-05
	LOSS [training: 0.11350442973081214 | validation: 0.09205152361322273]
	TIME [epoch: 9.19 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1283491648252758		[learning rate: 4.2673e-05]
	Learning Rate: 4.26735e-05
	LOSS [training: 0.1283491648252758 | validation: 0.09549100328579717]
	TIME [epoch: 9.19 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11829959753624238		[learning rate: 4.2519e-05]
	Learning Rate: 4.25186e-05
	LOSS [training: 0.11829959753624238 | validation: 0.08755305912942285]
	TIME [epoch: 9.2 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11533468683765355		[learning rate: 4.2364e-05]
	Learning Rate: 4.23643e-05
	LOSS [training: 0.11533468683765355 | validation: 0.10100615361477533]
	TIME [epoch: 9.19 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12332415678490335		[learning rate: 4.2211e-05]
	Learning Rate: 4.22106e-05
	LOSS [training: 0.12332415678490335 | validation: 0.10297975039261445]
	TIME [epoch: 9.19 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11783398042103399		[learning rate: 4.2057e-05]
	Learning Rate: 4.20574e-05
	LOSS [training: 0.11783398042103399 | validation: 0.0880754731880335]
	TIME [epoch: 9.19 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11569767619805993		[learning rate: 4.1905e-05]
	Learning Rate: 4.19047e-05
	LOSS [training: 0.11569767619805993 | validation: 0.0805021391639875]
	TIME [epoch: 9.21 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11707891726085609		[learning rate: 4.1753e-05]
	Learning Rate: 4.17527e-05
	LOSS [training: 0.11707891726085609 | validation: 0.08676071007640337]
	TIME [epoch: 9.19 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12560144550660174		[learning rate: 4.1601e-05]
	Learning Rate: 4.16012e-05
	LOSS [training: 0.12560144550660174 | validation: 0.09346836908611159]
	TIME [epoch: 9.18 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12473065036803041		[learning rate: 4.145e-05]
	Learning Rate: 4.14502e-05
	LOSS [training: 0.12473065036803041 | validation: 0.09618149170891435]
	TIME [epoch: 9.19 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1265056648815853		[learning rate: 4.13e-05]
	Learning Rate: 4.12998e-05
	LOSS [training: 0.1265056648815853 | validation: 0.08266205188908846]
	TIME [epoch: 9.19 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11857412828769684		[learning rate: 4.115e-05]
	Learning Rate: 4.11499e-05
	LOSS [training: 0.11857412828769684 | validation: 0.09590561391266594]
	TIME [epoch: 9.22 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11666368838056389		[learning rate: 4.1001e-05]
	Learning Rate: 4.10005e-05
	LOSS [training: 0.11666368838056389 | validation: 0.09517695700952042]
	TIME [epoch: 9.19 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12463817728020629		[learning rate: 4.0852e-05]
	Learning Rate: 4.08517e-05
	LOSS [training: 0.12463817728020629 | validation: 0.10811178725778285]
	TIME [epoch: 9.18 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11491863823226367		[learning rate: 4.0703e-05]
	Learning Rate: 4.07035e-05
	LOSS [training: 0.11491863823226367 | validation: 0.09752109541564347]
	TIME [epoch: 9.19 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1140187053088074		[learning rate: 4.0556e-05]
	Learning Rate: 4.05558e-05
	LOSS [training: 0.1140187053088074 | validation: 0.09357276750297802]
	TIME [epoch: 9.21 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13079013584821805		[learning rate: 4.0409e-05]
	Learning Rate: 4.04086e-05
	LOSS [training: 0.13079013584821805 | validation: 0.092039066349486]
	TIME [epoch: 9.19 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12137356801383703		[learning rate: 4.0262e-05]
	Learning Rate: 4.0262e-05
	LOSS [training: 0.12137356801383703 | validation: 0.08966930232610124]
	TIME [epoch: 9.2 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12548244762016858		[learning rate: 4.0116e-05]
	Learning Rate: 4.01158e-05
	LOSS [training: 0.12548244762016858 | validation: 0.09204507133744898]
	TIME [epoch: 9.18 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11494687526298675		[learning rate: 3.997e-05]
	Learning Rate: 3.99703e-05
	LOSS [training: 0.11494687526298675 | validation: 0.08170484496130584]
	TIME [epoch: 9.18 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1198807482940322		[learning rate: 3.9825e-05]
	Learning Rate: 3.98252e-05
	LOSS [training: 0.1198807482940322 | validation: 0.08117602314040873]
	TIME [epoch: 9.21 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11463907845754617		[learning rate: 3.9681e-05]
	Learning Rate: 3.96807e-05
	LOSS [training: 0.11463907845754617 | validation: 0.0844071723368709]
	TIME [epoch: 9.2 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11931263788031654		[learning rate: 3.9537e-05]
	Learning Rate: 3.95367e-05
	LOSS [training: 0.11931263788031654 | validation: 0.08121106832099784]
	TIME [epoch: 9.19 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11504373093877569		[learning rate: 3.9393e-05]
	Learning Rate: 3.93932e-05
	LOSS [training: 0.11504373093877569 | validation: 0.09059981795262746]
	TIME [epoch: 9.19 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12097419989978622		[learning rate: 3.925e-05]
	Learning Rate: 3.92502e-05
	LOSS [training: 0.12097419989978622 | validation: 0.08792301750186504]
	TIME [epoch: 9.21 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11621470587606356		[learning rate: 3.9108e-05]
	Learning Rate: 3.91078e-05
	LOSS [training: 0.11621470587606356 | validation: 0.08604902038861059]
	TIME [epoch: 9.2 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12252157576318819		[learning rate: 3.8966e-05]
	Learning Rate: 3.89659e-05
	LOSS [training: 0.12252157576318819 | validation: 0.09745363711934127]
	TIME [epoch: 9.19 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12117760825690342		[learning rate: 3.8824e-05]
	Learning Rate: 3.88245e-05
	LOSS [training: 0.12117760825690342 | validation: 0.09480439182694733]
	TIME [epoch: 9.19 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1145531442422282		[learning rate: 3.8684e-05]
	Learning Rate: 3.86836e-05
	LOSS [training: 0.1145531442422282 | validation: 0.08930490188702901]
	TIME [epoch: 9.18 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11433180707312136		[learning rate: 3.8543e-05]
	Learning Rate: 3.85432e-05
	LOSS [training: 0.11433180707312136 | validation: 0.09219875478775816]
	TIME [epoch: 9.21 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11185002021020156		[learning rate: 3.8403e-05]
	Learning Rate: 3.84033e-05
	LOSS [training: 0.11185002021020156 | validation: 0.097582239745885]
	TIME [epoch: 9.19 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10581023866288426		[learning rate: 3.8264e-05]
	Learning Rate: 3.82639e-05
	LOSS [training: 0.10581023866288426 | validation: 0.08607866880097488]
	TIME [epoch: 9.19 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11936818618489087		[learning rate: 3.8125e-05]
	Learning Rate: 3.81251e-05
	LOSS [training: 0.11936818618489087 | validation: 0.08774246140773662]
	TIME [epoch: 9.19 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11467456969307657		[learning rate: 3.7987e-05]
	Learning Rate: 3.79867e-05
	LOSS [training: 0.11467456969307657 | validation: 0.09298768478900714]
	TIME [epoch: 9.2 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11151240887179614		[learning rate: 3.7849e-05]
	Learning Rate: 3.78489e-05
	LOSS [training: 0.11151240887179614 | validation: 0.09861410484494668]
	TIME [epoch: 9.2 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.119969583948678		[learning rate: 3.7711e-05]
	Learning Rate: 3.77115e-05
	LOSS [training: 0.119969583948678 | validation: 0.1062938047243876]
	TIME [epoch: 9.18 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1303991406727903		[learning rate: 3.7575e-05]
	Learning Rate: 3.75746e-05
	LOSS [training: 0.1303991406727903 | validation: 0.10099054214072689]
	TIME [epoch: 9.2 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11934937989081167		[learning rate: 3.7438e-05]
	Learning Rate: 3.74383e-05
	LOSS [training: 0.11934937989081167 | validation: 0.09280509147047641]
	TIME [epoch: 9.19 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12040294667890354		[learning rate: 3.7302e-05]
	Learning Rate: 3.73024e-05
	LOSS [training: 0.12040294667890354 | validation: 0.09954427638293568]
	TIME [epoch: 9.23 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10872367561482563		[learning rate: 3.7167e-05]
	Learning Rate: 3.7167e-05
	LOSS [training: 0.10872367561482563 | validation: 0.09803053061264948]
	TIME [epoch: 9.2 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11347292137511242		[learning rate: 3.7032e-05]
	Learning Rate: 3.70322e-05
	LOSS [training: 0.11347292137511242 | validation: 0.09775600440963078]
	TIME [epoch: 9.2 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11061654948317423		[learning rate: 3.6898e-05]
	Learning Rate: 3.68978e-05
	LOSS [training: 0.11061654948317423 | validation: 0.0824473190956617]
	TIME [epoch: 9.19 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11234147062558249		[learning rate: 3.6764e-05]
	Learning Rate: 3.67639e-05
	LOSS [training: 0.11234147062558249 | validation: 0.08554621753465994]
	TIME [epoch: 9.2 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12371790444515121		[learning rate: 3.663e-05]
	Learning Rate: 3.66304e-05
	LOSS [training: 0.12371790444515121 | validation: 0.0866292794638086]
	TIME [epoch: 9.21 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11080273573158742		[learning rate: 3.6498e-05]
	Learning Rate: 3.64975e-05
	LOSS [training: 0.11080273573158742 | validation: 0.09235867517188479]
	TIME [epoch: 9.19 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1261867412668435		[learning rate: 3.6365e-05]
	Learning Rate: 3.63651e-05
	LOSS [training: 0.1261867412668435 | validation: 0.0906446535948851]
	TIME [epoch: 9.19 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12108602860555387		[learning rate: 3.6233e-05]
	Learning Rate: 3.62331e-05
	LOSS [training: 0.12108602860555387 | validation: 0.08724265043331918]
	TIME [epoch: 9.18 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12684630580335915		[learning rate: 3.6102e-05]
	Learning Rate: 3.61016e-05
	LOSS [training: 0.12684630580335915 | validation: 0.08683002014917923]
	TIME [epoch: 9.22 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12207767794173645		[learning rate: 3.5971e-05]
	Learning Rate: 3.59706e-05
	LOSS [training: 0.12207767794173645 | validation: 0.08848407165585037]
	TIME [epoch: 9.19 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10609339215800609		[learning rate: 3.584e-05]
	Learning Rate: 3.584e-05
	LOSS [training: 0.10609339215800609 | validation: 0.10756108150378427]
	TIME [epoch: 9.19 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11371396079375769		[learning rate: 3.571e-05]
	Learning Rate: 3.571e-05
	LOSS [training: 0.11371396079375769 | validation: 0.09230448275226608]
	TIME [epoch: 9.19 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10496195121126246		[learning rate: 3.558e-05]
	Learning Rate: 3.55804e-05
	LOSS [training: 0.10496195121126246 | validation: 0.09378852867754099]
	TIME [epoch: 9.2 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11104074563764407		[learning rate: 3.5451e-05]
	Learning Rate: 3.54513e-05
	LOSS [training: 0.11104074563764407 | validation: 0.08778924526231022]
	TIME [epoch: 9.21 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11645534422940376		[learning rate: 3.5323e-05]
	Learning Rate: 3.53226e-05
	LOSS [training: 0.11645534422940376 | validation: 0.08262167487411799]
	TIME [epoch: 9.18 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1087599602892984		[learning rate: 3.5194e-05]
	Learning Rate: 3.51944e-05
	LOSS [training: 0.1087599602892984 | validation: 0.09393371551943647]
	TIME [epoch: 9.19 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10612857118323553		[learning rate: 3.5067e-05]
	Learning Rate: 3.50667e-05
	LOSS [training: 0.10612857118323553 | validation: 0.0810409299301281]
	TIME [epoch: 9.19 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11196684358262862		[learning rate: 3.4939e-05]
	Learning Rate: 3.49394e-05
	LOSS [training: 0.11196684358262862 | validation: 0.09365820367904686]
	TIME [epoch: 9.22 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11260186583457776		[learning rate: 3.4813e-05]
	Learning Rate: 3.48126e-05
	LOSS [training: 0.11260186583457776 | validation: 0.0932596744086506]
	TIME [epoch: 9.19 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10858153529953259		[learning rate: 3.4686e-05]
	Learning Rate: 3.46863e-05
	LOSS [training: 0.10858153529953259 | validation: 0.08507251859348056]
	TIME [epoch: 9.19 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11047686095570493		[learning rate: 3.456e-05]
	Learning Rate: 3.45604e-05
	LOSS [training: 0.11047686095570493 | validation: 0.08665118841408066]
	TIME [epoch: 9.19 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12268449698857849		[learning rate: 3.4435e-05]
	Learning Rate: 3.4435e-05
	LOSS [training: 0.12268449698857849 | validation: 0.08795655006894842]
	TIME [epoch: 9.2 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11849451173921674		[learning rate: 3.431e-05]
	Learning Rate: 3.431e-05
	LOSS [training: 0.11849451173921674 | validation: 0.09549374282311215]
	TIME [epoch: 9.2 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11503310195632328		[learning rate: 3.4186e-05]
	Learning Rate: 3.41855e-05
	LOSS [training: 0.11503310195632328 | validation: 0.09089097688033843]
	TIME [epoch: 9.2 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11237333232646099		[learning rate: 3.4061e-05]
	Learning Rate: 3.40615e-05
	LOSS [training: 0.11237333232646099 | validation: 0.073373166575406]
	TIME [epoch: 9.2 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11369024228863944		[learning rate: 3.3938e-05]
	Learning Rate: 3.39378e-05
	LOSS [training: 0.11369024228863944 | validation: 0.08285757405787922]
	TIME [epoch: 9.2 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12203886293643998		[learning rate: 3.3815e-05]
	Learning Rate: 3.38147e-05
	LOSS [training: 0.12203886293643998 | validation: 0.09936573405382923]
	TIME [epoch: 9.21 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10989395813101273		[learning rate: 3.3692e-05]
	Learning Rate: 3.3692e-05
	LOSS [training: 0.10989395813101273 | validation: 0.09159275973590986]
	TIME [epoch: 9.19 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11836336291144393		[learning rate: 3.357e-05]
	Learning Rate: 3.35697e-05
	LOSS [training: 0.11836336291144393 | validation: 0.08182622753597388]
	TIME [epoch: 9.19 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11830745221749821		[learning rate: 3.3448e-05]
	Learning Rate: 3.34479e-05
	LOSS [training: 0.11830745221749821 | validation: 0.10423773995949401]
	TIME [epoch: 9.19 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11705299042411024		[learning rate: 3.3326e-05]
	Learning Rate: 3.33265e-05
	LOSS [training: 0.11705299042411024 | validation: 0.08845456240550617]
	TIME [epoch: 9.2 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10879553057441678		[learning rate: 3.3206e-05]
	Learning Rate: 3.32055e-05
	LOSS [training: 0.10879553057441678 | validation: 0.09509365210993094]
	TIME [epoch: 9.21 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1134390913087776		[learning rate: 3.3085e-05]
	Learning Rate: 3.3085e-05
	LOSS [training: 0.1134390913087776 | validation: 0.08512024215864328]
	TIME [epoch: 9.19 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11897587912571876		[learning rate: 3.2965e-05]
	Learning Rate: 3.2965e-05
	LOSS [training: 0.11897587912571876 | validation: 0.08080340339737005]
	TIME [epoch: 9.19 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12022573338240083		[learning rate: 3.2845e-05]
	Learning Rate: 3.28453e-05
	LOSS [training: 0.12022573338240083 | validation: 0.08216073912544322]
	TIME [epoch: 9.18 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11088361073878739		[learning rate: 3.2726e-05]
	Learning Rate: 3.27261e-05
	LOSS [training: 0.11088361073878739 | validation: 0.08521017200626868]
	TIME [epoch: 9.23 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11514394979046258		[learning rate: 3.2607e-05]
	Learning Rate: 3.26074e-05
	LOSS [training: 0.11514394979046258 | validation: 0.08416594514289286]
	TIME [epoch: 9.2 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11993570809511031		[learning rate: 3.2489e-05]
	Learning Rate: 3.2489e-05
	LOSS [training: 0.11993570809511031 | validation: 0.08058475649551836]
	TIME [epoch: 9.19 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11915681698147436		[learning rate: 3.2371e-05]
	Learning Rate: 3.23711e-05
	LOSS [training: 0.11915681698147436 | validation: 0.0804839368076144]
	TIME [epoch: 9.19 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10867370859106673		[learning rate: 3.2254e-05]
	Learning Rate: 3.22537e-05
	LOSS [training: 0.10867370859106673 | validation: 0.0856183600585013]
	TIME [epoch: 9.2 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11179998744598965		[learning rate: 3.2137e-05]
	Learning Rate: 3.21366e-05
	LOSS [training: 0.11179998744598965 | validation: 0.08005261592016405]
	TIME [epoch: 9.21 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10883035017123022		[learning rate: 3.202e-05]
	Learning Rate: 3.202e-05
	LOSS [training: 0.10883035017123022 | validation: 0.08863537339281773]
	TIME [epoch: 9.19 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11150721878366059		[learning rate: 3.1904e-05]
	Learning Rate: 3.19038e-05
	LOSS [training: 0.11150721878366059 | validation: 0.08273016009709719]
	TIME [epoch: 9.19 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11601679883705525		[learning rate: 3.1788e-05]
	Learning Rate: 3.1788e-05
	LOSS [training: 0.11601679883705525 | validation: 0.08299602130691333]
	TIME [epoch: 9.19 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12485628153445831		[learning rate: 3.1673e-05]
	Learning Rate: 3.16726e-05
	LOSS [training: 0.12485628153445831 | validation: 0.0928163047137667]
	TIME [epoch: 9.22 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12581047379904123		[learning rate: 3.1558e-05]
	Learning Rate: 3.15577e-05
	LOSS [training: 0.12581047379904123 | validation: 0.08022881284777167]
	TIME [epoch: 9.19 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12118850848785337		[learning rate: 3.1443e-05]
	Learning Rate: 3.14432e-05
	LOSS [training: 0.12118850848785337 | validation: 0.10316087104239294]
	TIME [epoch: 9.19 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1205757948442977		[learning rate: 3.1329e-05]
	Learning Rate: 3.13291e-05
	LOSS [training: 0.1205757948442977 | validation: 0.09463668808944672]
	TIME [epoch: 9.19 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11778917319401053		[learning rate: 3.1215e-05]
	Learning Rate: 3.12154e-05
	LOSS [training: 0.11778917319401053 | validation: 0.0935000634611466]
	TIME [epoch: 9.2 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1186057279884735		[learning rate: 3.1102e-05]
	Learning Rate: 3.11021e-05
	LOSS [training: 0.1186057279884735 | validation: 0.08747016287459128]
	TIME [epoch: 9.22 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12276510880309943		[learning rate: 3.0989e-05]
	Learning Rate: 3.09892e-05
	LOSS [training: 0.12276510880309943 | validation: 0.08693484476993266]
	TIME [epoch: 9.2 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11680523705700677		[learning rate: 3.0877e-05]
	Learning Rate: 3.08768e-05
	LOSS [training: 0.11680523705700677 | validation: 0.09629386528030531]
	TIME [epoch: 9.19 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11605092339139955		[learning rate: 3.0765e-05]
	Learning Rate: 3.07647e-05
	LOSS [training: 0.11605092339139955 | validation: 0.08779602779589199]
	TIME [epoch: 9.19 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11866649032134031		[learning rate: 3.0653e-05]
	Learning Rate: 3.0653e-05
	LOSS [training: 0.11866649032134031 | validation: 0.10024549777758861]
	TIME [epoch: 9.21 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11289778378679191		[learning rate: 3.0542e-05]
	Learning Rate: 3.05418e-05
	LOSS [training: 0.11289778378679191 | validation: 0.09672781356507984]
	TIME [epoch: 9.19 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11071151271438415		[learning rate: 3.0431e-05]
	Learning Rate: 3.0431e-05
	LOSS [training: 0.11071151271438415 | validation: 0.08840755062754815]
	TIME [epoch: 9.18 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11468957563185882		[learning rate: 3.0321e-05]
	Learning Rate: 3.03205e-05
	LOSS [training: 0.11468957563185882 | validation: 0.0852718520751451]
	TIME [epoch: 9.19 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1222654281295222		[learning rate: 3.0211e-05]
	Learning Rate: 3.02105e-05
	LOSS [training: 0.1222654281295222 | validation: 0.09487268910171462]
	TIME [epoch: 9.19 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10593294735124217		[learning rate: 3.0101e-05]
	Learning Rate: 3.01009e-05
	LOSS [training: 0.10593294735124217 | validation: 0.08762714301760957]
	TIME [epoch: 9.21 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12282055169141695		[learning rate: 2.9992e-05]
	Learning Rate: 2.99916e-05
	LOSS [training: 0.12282055169141695 | validation: 0.09192740966231211]
	TIME [epoch: 9.19 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11982850180652393		[learning rate: 2.9883e-05]
	Learning Rate: 2.98828e-05
	LOSS [training: 0.11982850180652393 | validation: 0.08132133660064346]
	TIME [epoch: 9.19 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11983155061525705		[learning rate: 2.9774e-05]
	Learning Rate: 2.97743e-05
	LOSS [training: 0.11983155061525705 | validation: 0.08877375747215979]
	TIME [epoch: 9.18 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11873381079316206		[learning rate: 2.9666e-05]
	Learning Rate: 2.96663e-05
	LOSS [training: 0.11873381079316206 | validation: 0.09173588619127174]
	TIME [epoch: 9.2 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11680148785102032		[learning rate: 2.9559e-05]
	Learning Rate: 2.95586e-05
	LOSS [training: 0.11680148785102032 | validation: 0.09159587366462371]
	TIME [epoch: 9.2 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11252109902659232		[learning rate: 2.9451e-05]
	Learning Rate: 2.94514e-05
	LOSS [training: 0.11252109902659232 | validation: 0.09997218785946874]
	TIME [epoch: 9.19 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1143239686149143		[learning rate: 2.9344e-05]
	Learning Rate: 2.93445e-05
	LOSS [training: 0.1143239686149143 | validation: 0.09458227254474437]
	TIME [epoch: 9.18 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1092337904453529		[learning rate: 2.9238e-05]
	Learning Rate: 2.9238e-05
	LOSS [training: 0.1092337904453529 | validation: 0.09711729796406768]
	TIME [epoch: 9.19 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1237385293316355		[learning rate: 2.9132e-05]
	Learning Rate: 2.91319e-05
	LOSS [training: 0.1237385293316355 | validation: 0.09198392917380026]
	TIME [epoch: 9.21 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11729428739541017		[learning rate: 2.9026e-05]
	Learning Rate: 2.90262e-05
	LOSS [training: 0.11729428739541017 | validation: 0.10610672054756426]
	TIME [epoch: 9.19 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.121123826273385		[learning rate: 2.8921e-05]
	Learning Rate: 2.89208e-05
	LOSS [training: 0.121123826273385 | validation: 0.10250292790267167]
	TIME [epoch: 9.19 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13254512943638813		[learning rate: 2.8816e-05]
	Learning Rate: 2.88159e-05
	LOSS [training: 0.13254512943638813 | validation: 0.1037217207065076]
	TIME [epoch: 9.19 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13285269025215946		[learning rate: 2.8711e-05]
	Learning Rate: 2.87113e-05
	LOSS [training: 0.13285269025215946 | validation: 0.0988167204560812]
	TIME [epoch: 9.22 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11697242825862138		[learning rate: 2.8607e-05]
	Learning Rate: 2.86071e-05
	LOSS [training: 0.11697242825862138 | validation: 0.11187982054149917]
	TIME [epoch: 9.2 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11756653900061635		[learning rate: 2.8503e-05]
	Learning Rate: 2.85033e-05
	LOSS [training: 0.11756653900061635 | validation: 0.09665434828185034]
	TIME [epoch: 9.19 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12497056069363954		[learning rate: 2.84e-05]
	Learning Rate: 2.83998e-05
	LOSS [training: 0.12497056069363954 | validation: 0.09612517082974259]
	TIME [epoch: 9.19 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12859564296966908		[learning rate: 2.8297e-05]
	Learning Rate: 2.82968e-05
	LOSS [training: 0.12859564296966908 | validation: 0.09914392682371533]
	TIME [epoch: 9.19 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11309497701501878		[learning rate: 2.8194e-05]
	Learning Rate: 2.81941e-05
	LOSS [training: 0.11309497701501878 | validation: 0.09128429939462518]
	TIME [epoch: 9.22 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11913494796783086		[learning rate: 2.8092e-05]
	Learning Rate: 2.80918e-05
	LOSS [training: 0.11913494796783086 | validation: 0.08819171273983249]
	TIME [epoch: 9.19 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1220113445263133		[learning rate: 2.799e-05]
	Learning Rate: 2.79898e-05
	LOSS [training: 0.1220113445263133 | validation: 0.09013164614650855]
	TIME [epoch: 9.19 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11442984941463615		[learning rate: 2.7888e-05]
	Learning Rate: 2.78882e-05
	LOSS [training: 0.11442984941463615 | validation: 0.08630110534593248]
	TIME [epoch: 9.18 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11077932948290356		[learning rate: 2.7787e-05]
	Learning Rate: 2.7787e-05
	LOSS [training: 0.11077932948290356 | validation: 0.08929670226892596]
	TIME [epoch: 9.21 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12058795940261642		[learning rate: 2.7686e-05]
	Learning Rate: 2.76862e-05
	LOSS [training: 0.12058795940261642 | validation: 0.08483316864846373]
	TIME [epoch: 9.19 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11648011777367798		[learning rate: 2.7586e-05]
	Learning Rate: 2.75857e-05
	LOSS [training: 0.11648011777367798 | validation: 0.0901440594266025]
	TIME [epoch: 9.18 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11759174485234898		[learning rate: 2.7486e-05]
	Learning Rate: 2.74856e-05
	LOSS [training: 0.11759174485234898 | validation: 0.08683556116435273]
	TIME [epoch: 9.19 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12297013436612078		[learning rate: 2.7386e-05]
	Learning Rate: 2.73859e-05
	LOSS [training: 0.12297013436612078 | validation: 0.09246968619250609]
	TIME [epoch: 9.19 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11375933535648568		[learning rate: 2.7286e-05]
	Learning Rate: 2.72865e-05
	LOSS [training: 0.11375933535648568 | validation: 0.08608748021443637]
	TIME [epoch: 9.21 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1134518627256634		[learning rate: 2.7187e-05]
	Learning Rate: 2.71875e-05
	LOSS [training: 0.1134518627256634 | validation: 0.08703590526865992]
	TIME [epoch: 9.19 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12703953904086146		[learning rate: 2.7089e-05]
	Learning Rate: 2.70888e-05
	LOSS [training: 0.12703953904086146 | validation: 0.09458457547331445]
	TIME [epoch: 9.2 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12445818787085894		[learning rate: 2.699e-05]
	Learning Rate: 2.69905e-05
	LOSS [training: 0.12445818787085894 | validation: 0.08494618318234562]
	TIME [epoch: 9.19 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11466151861825695		[learning rate: 2.6893e-05]
	Learning Rate: 2.68925e-05
	LOSS [training: 0.11466151861825695 | validation: 0.07385883670481087]
	TIME [epoch: 9.2 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11834603859730033		[learning rate: 2.6795e-05]
	Learning Rate: 2.67949e-05
	LOSS [training: 0.11834603859730033 | validation: 0.08676360520143955]
	TIME [epoch: 9.21 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11929201786198337		[learning rate: 2.6698e-05]
	Learning Rate: 2.66977e-05
	LOSS [training: 0.11929201786198337 | validation: 0.08688918572411035]
	TIME [epoch: 9.19 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10845351808423734		[learning rate: 2.6601e-05]
	Learning Rate: 2.66008e-05
	LOSS [training: 0.10845351808423734 | validation: 0.08314888880461777]
	TIME [epoch: 9.19 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11518764212331083		[learning rate: 2.6504e-05]
	Learning Rate: 2.65043e-05
	LOSS [training: 0.11518764212331083 | validation: 0.09184807992783538]
	TIME [epoch: 9.19 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11691605287827478		[learning rate: 2.6408e-05]
	Learning Rate: 2.64081e-05
	LOSS [training: 0.11691605287827478 | validation: 0.08718690053995208]
	TIME [epoch: 9.22 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11428098583704922		[learning rate: 2.6312e-05]
	Learning Rate: 2.63123e-05
	LOSS [training: 0.11428098583704922 | validation: 0.09021227226078313]
	TIME [epoch: 9.2 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12116007161161299		[learning rate: 2.6217e-05]
	Learning Rate: 2.62168e-05
	LOSS [training: 0.12116007161161299 | validation: 0.08901519063136265]
	TIME [epoch: 9.19 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11833536766172648		[learning rate: 2.6122e-05]
	Learning Rate: 2.61216e-05
	LOSS [training: 0.11833536766172648 | validation: 0.08855582553771758]
	TIME [epoch: 9.19 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11893887379369703		[learning rate: 2.6027e-05]
	Learning Rate: 2.60268e-05
	LOSS [training: 0.11893887379369703 | validation: 0.0875867536908119]
	TIME [epoch: 9.22 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12114039001641919		[learning rate: 2.5932e-05]
	Learning Rate: 2.59324e-05
	LOSS [training: 0.12114039001641919 | validation: 0.08872243531241775]
	TIME [epoch: 9.2 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10853865813243538		[learning rate: 2.5838e-05]
	Learning Rate: 2.58383e-05
	LOSS [training: 0.10853865813243538 | validation: 0.07664310432360034]
	TIME [epoch: 9.19 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11208593680561829		[learning rate: 2.5744e-05]
	Learning Rate: 2.57445e-05
	LOSS [training: 0.11208593680561829 | validation: 0.08224123887939785]
	TIME [epoch: 9.19 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11453560617232525		[learning rate: 2.5651e-05]
	Learning Rate: 2.56511e-05
	LOSS [training: 0.11453560617232525 | validation: 0.08689847858908734]
	TIME [epoch: 9.18 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11278921547322192		[learning rate: 2.5558e-05]
	Learning Rate: 2.5558e-05
	LOSS [training: 0.11278921547322192 | validation: 0.08636746448388624]
	TIME [epoch: 9.22 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12242738894783414		[learning rate: 2.5465e-05]
	Learning Rate: 2.54652e-05
	LOSS [training: 0.12242738894783414 | validation: 0.0794709300836576]
	TIME [epoch: 9.18 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11490741905939361		[learning rate: 2.5373e-05]
	Learning Rate: 2.53728e-05
	LOSS [training: 0.11490741905939361 | validation: 0.09134345995680346]
	TIME [epoch: 9.18 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12114172416417712		[learning rate: 2.5281e-05]
	Learning Rate: 2.52807e-05
	LOSS [training: 0.12114172416417712 | validation: 0.0846243327241617]
	TIME [epoch: 9.19 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11019414917901918		[learning rate: 2.5189e-05]
	Learning Rate: 2.5189e-05
	LOSS [training: 0.11019414917901918 | validation: 0.08346953169818634]
	TIME [epoch: 9.22 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11077336504770086		[learning rate: 2.5098e-05]
	Learning Rate: 2.50976e-05
	LOSS [training: 0.11077336504770086 | validation: 0.08279032104117398]
	TIME [epoch: 9.19 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11019884898208457		[learning rate: 2.5006e-05]
	Learning Rate: 2.50065e-05
	LOSS [training: 0.11019884898208457 | validation: 0.07860001261163509]
	TIME [epoch: 9.19 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11267712380419329		[learning rate: 2.4916e-05]
	Learning Rate: 2.49157e-05
	LOSS [training: 0.11267712380419329 | validation: 0.07109480190624856]
	TIME [epoch: 9.18 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11288654106626636		[learning rate: 2.4825e-05]
	Learning Rate: 2.48253e-05
	LOSS [training: 0.11288654106626636 | validation: 0.09135511316219608]
	TIME [epoch: 9.18 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12271847835797552		[learning rate: 2.4735e-05]
	Learning Rate: 2.47352e-05
	LOSS [training: 0.12271847835797552 | validation: 0.08114799394422954]
	TIME [epoch: 9.21 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11003508575522736		[learning rate: 2.4645e-05]
	Learning Rate: 2.46455e-05
	LOSS [training: 0.11003508575522736 | validation: 0.07949338177133936]
	TIME [epoch: 9.19 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11407541214792558		[learning rate: 2.4556e-05]
	Learning Rate: 2.4556e-05
	LOSS [training: 0.11407541214792558 | validation: 0.08053617831952933]
	TIME [epoch: 9.19 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12003911717444346		[learning rate: 2.4467e-05]
	Learning Rate: 2.44669e-05
	LOSS [training: 0.12003911717444346 | validation: 0.08226110371517303]
	TIME [epoch: 9.2 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11835211354380412		[learning rate: 2.4378e-05]
	Learning Rate: 2.43781e-05
	LOSS [training: 0.11835211354380412 | validation: 0.08057839927517131]
	TIME [epoch: 9.21 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12401443523119218		[learning rate: 2.429e-05]
	Learning Rate: 2.42896e-05
	LOSS [training: 0.12401443523119218 | validation: 0.07463431831948483]
	TIME [epoch: 9.21 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.118271866049901		[learning rate: 2.4201e-05]
	Learning Rate: 2.42015e-05
	LOSS [training: 0.118271866049901 | validation: 0.07872476546165821]
	TIME [epoch: 9.18 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11783840631780192		[learning rate: 2.4114e-05]
	Learning Rate: 2.41137e-05
	LOSS [training: 0.11783840631780192 | validation: 0.07822525300300291]
	TIME [epoch: 9.18 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10868677877816883		[learning rate: 2.4026e-05]
	Learning Rate: 2.40262e-05
	LOSS [training: 0.10868677877816883 | validation: 0.08410885140304643]
	TIME [epoch: 9.18 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1184164710439493		[learning rate: 2.3939e-05]
	Learning Rate: 2.3939e-05
	LOSS [training: 0.1184164710439493 | validation: 0.08551635938092791]
	TIME [epoch: 9.21 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11515949271166066		[learning rate: 2.3852e-05]
	Learning Rate: 2.38521e-05
	LOSS [training: 0.11515949271166066 | validation: 0.08617146777906788]
	TIME [epoch: 9.19 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12025873959231999		[learning rate: 2.3766e-05]
	Learning Rate: 2.37655e-05
	LOSS [training: 0.12025873959231999 | validation: 0.08194548321393529]
	TIME [epoch: 9.18 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12338858072700161		[learning rate: 2.3679e-05]
	Learning Rate: 2.36793e-05
	LOSS [training: 0.12338858072700161 | validation: 0.08909899820731716]
	TIME [epoch: 9.18 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11598408461299414		[learning rate: 2.3593e-05]
	Learning Rate: 2.35933e-05
	LOSS [training: 0.11598408461299414 | validation: 0.09615546872822484]
	TIME [epoch: 9.2 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11133961452960854		[learning rate: 2.3508e-05]
	Learning Rate: 2.35077e-05
	LOSS [training: 0.11133961452960854 | validation: 0.09432330332490439]
	TIME [epoch: 9.2 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11713348031251183		[learning rate: 2.3422e-05]
	Learning Rate: 2.34224e-05
	LOSS [training: 0.11713348031251183 | validation: 0.07500816923190051]
	TIME [epoch: 9.2 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11977420997549038		[learning rate: 2.3337e-05]
	Learning Rate: 2.33374e-05
	LOSS [training: 0.11977420997549038 | validation: 0.07433136679970455]
	TIME [epoch: 9.2 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12413777001376476		[learning rate: 2.3253e-05]
	Learning Rate: 2.32527e-05
	LOSS [training: 0.12413777001376476 | validation: 0.08936237320851692]
	TIME [epoch: 9.2 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12086419646967288		[learning rate: 2.3168e-05]
	Learning Rate: 2.31683e-05
	LOSS [training: 0.12086419646967288 | validation: 0.08859698502279993]
	TIME [epoch: 9.21 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10807641181941745		[learning rate: 2.3084e-05]
	Learning Rate: 2.30843e-05
	LOSS [training: 0.10807641181941745 | validation: 0.0867035663716393]
	TIME [epoch: 9.19 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11401579729415035		[learning rate: 2.3e-05]
	Learning Rate: 2.30005e-05
	LOSS [training: 0.11401579729415035 | validation: 0.08456491938649886]
	TIME [epoch: 9.19 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11265335857993279		[learning rate: 2.2917e-05]
	Learning Rate: 2.2917e-05
	LOSS [training: 0.11265335857993279 | validation: 0.09509685905697868]
	TIME [epoch: 9.2 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12287902838049318		[learning rate: 2.2834e-05]
	Learning Rate: 2.28338e-05
	LOSS [training: 0.12287902838049318 | validation: 0.0861319053151097]
	TIME [epoch: 9.2 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12330124458251754		[learning rate: 2.2751e-05]
	Learning Rate: 2.2751e-05
	LOSS [training: 0.12330124458251754 | validation: 0.08592993225068382]
	TIME [epoch: 9.21 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10963254279403137		[learning rate: 2.2668e-05]
	Learning Rate: 2.26684e-05
	LOSS [training: 0.10963254279403137 | validation: 0.08240693141803826]
	TIME [epoch: 9.19 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11140161443887853		[learning rate: 2.2586e-05]
	Learning Rate: 2.25862e-05
	LOSS [training: 0.11140161443887853 | validation: 0.08228487919338903]
	TIME [epoch: 9.19 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10671543600368807		[learning rate: 2.2504e-05]
	Learning Rate: 2.25042e-05
	LOSS [training: 0.10671543600368807 | validation: 0.07915770417167874]
	TIME [epoch: 9.19 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11624482409968495		[learning rate: 2.2423e-05]
	Learning Rate: 2.24225e-05
	LOSS [training: 0.11624482409968495 | validation: 0.07493450041521979]
	TIME [epoch: 9.21 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11225875766187421		[learning rate: 2.2341e-05]
	Learning Rate: 2.23411e-05
	LOSS [training: 0.11225875766187421 | validation: 0.08270908353269826]
	TIME [epoch: 9.2 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11201386092522628		[learning rate: 2.226e-05]
	Learning Rate: 2.22601e-05
	LOSS [training: 0.11201386092522628 | validation: 0.09405227574186695]
	TIME [epoch: 9.19 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11982710674412009		[learning rate: 2.2179e-05]
	Learning Rate: 2.21793e-05
	LOSS [training: 0.11982710674412009 | validation: 0.08472185339633355]
	TIME [epoch: 9.18 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11366857932371444		[learning rate: 2.2099e-05]
	Learning Rate: 2.20988e-05
	LOSS [training: 0.11366857932371444 | validation: 0.09559092986671937]
	TIME [epoch: 9.19 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11072276612707543		[learning rate: 2.2019e-05]
	Learning Rate: 2.20186e-05
	LOSS [training: 0.11072276612707543 | validation: 0.0829513307286242]
	TIME [epoch: 9.2 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11403601957059457		[learning rate: 2.1939e-05]
	Learning Rate: 2.19387e-05
	LOSS [training: 0.11403601957059457 | validation: 0.08427414167673868]
	TIME [epoch: 9.18 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10638327541807162		[learning rate: 2.1859e-05]
	Learning Rate: 2.18591e-05
	LOSS [training: 0.10638327541807162 | validation: 0.0902159068447707]
	TIME [epoch: 9.18 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11916274825952493		[learning rate: 2.178e-05]
	Learning Rate: 2.17797e-05
	LOSS [training: 0.11916274825952493 | validation: 0.08319984342980435]
	TIME [epoch: 9.2 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11786193336395763		[learning rate: 2.1701e-05]
	Learning Rate: 2.17007e-05
	LOSS [training: 0.11786193336395763 | validation: 0.08768653422354793]
	TIME [epoch: 9.22 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10932472102125099		[learning rate: 2.1622e-05]
	Learning Rate: 2.16219e-05
	LOSS [training: 0.10932472102125099 | validation: 0.08152587083261367]
	TIME [epoch: 9.19 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1095575766599393		[learning rate: 2.1543e-05]
	Learning Rate: 2.15435e-05
	LOSS [training: 0.1095575766599393 | validation: 0.07861673609661123]
	TIME [epoch: 9.18 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10855843963171656		[learning rate: 2.1465e-05]
	Learning Rate: 2.14653e-05
	LOSS [training: 0.10855843963171656 | validation: 0.08768738775646243]
	TIME [epoch: 9.19 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12157251219708116		[learning rate: 2.1387e-05]
	Learning Rate: 2.13874e-05
	LOSS [training: 0.12157251219708116 | validation: 0.08731864309776294]
	TIME [epoch: 9.2 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10379518546092856		[learning rate: 2.131e-05]
	Learning Rate: 2.13098e-05
	LOSS [training: 0.10379518546092856 | validation: 0.09028674892820848]
	TIME [epoch: 9.21 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11985725564665073		[learning rate: 2.1232e-05]
	Learning Rate: 2.12325e-05
	LOSS [training: 0.11985725564665073 | validation: 0.07733566219557625]
	TIME [epoch: 9.19 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10471631927966182		[learning rate: 2.1155e-05]
	Learning Rate: 2.11554e-05
	LOSS [training: 0.10471631927966182 | validation: 0.0909231608663981]
	TIME [epoch: 9.18 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11258814465622573		[learning rate: 2.1079e-05]
	Learning Rate: 2.10786e-05
	LOSS [training: 0.11258814465622573 | validation: 0.07795555078497685]
	TIME [epoch: 9.19 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12059591426488228		[learning rate: 2.1002e-05]
	Learning Rate: 2.10021e-05
	LOSS [training: 0.12059591426488228 | validation: 0.08630861746970925]
	TIME [epoch: 9.21 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12039643964785904		[learning rate: 2.0926e-05]
	Learning Rate: 2.09259e-05
	LOSS [training: 0.12039643964785904 | validation: 0.09001972736059788]
	TIME [epoch: 9.19 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10941528815857046		[learning rate: 2.085e-05]
	Learning Rate: 2.085e-05
	LOSS [training: 0.10941528815857046 | validation: 0.08465595859912092]
	TIME [epoch: 9.19 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11418465856762017		[learning rate: 2.0774e-05]
	Learning Rate: 2.07743e-05
	LOSS [training: 0.11418465856762017 | validation: 0.08291772681346614]
	TIME [epoch: 9.19 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1170702484385077		[learning rate: 2.0699e-05]
	Learning Rate: 2.06989e-05
	LOSS [training: 0.1170702484385077 | validation: 0.08096837128954162]
	TIME [epoch: 9.19 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11252292646831805		[learning rate: 2.0624e-05]
	Learning Rate: 2.06238e-05
	LOSS [training: 0.11252292646831805 | validation: 0.08523622202447931]
	TIME [epoch: 9.21 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11114630929705535		[learning rate: 2.0549e-05]
	Learning Rate: 2.05489e-05
	LOSS [training: 0.11114630929705535 | validation: 0.09395577589682046]
	TIME [epoch: 9.19 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1176355382701066		[learning rate: 2.0474e-05]
	Learning Rate: 2.04744e-05
	LOSS [training: 0.1176355382701066 | validation: 0.08320260356786861]
	TIME [epoch: 9.18 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10861868100550029		[learning rate: 2.04e-05]
	Learning Rate: 2.04001e-05
	LOSS [training: 0.10861868100550029 | validation: 0.07921374795077099]
	TIME [epoch: 9.19 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11805709706680075		[learning rate: 2.0326e-05]
	Learning Rate: 2.0326e-05
	LOSS [training: 0.11805709706680075 | validation: 0.0687874145166833]
	TIME [epoch: 9.22 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r5_20240219_234257/states/model_tr_study204_1805.pth
	Model improved!!!
EPOCH 1806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1140144019988846		[learning rate: 2.0252e-05]
	Learning Rate: 2.02523e-05
	LOSS [training: 0.1140144019988846 | validation: 0.10287120527267371]
	TIME [epoch: 9.21 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11188022605399939		[learning rate: 2.0179e-05]
	Learning Rate: 2.01788e-05
	LOSS [training: 0.11188022605399939 | validation: 0.09271850701313866]
	TIME [epoch: 9.2 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.116609061457834		[learning rate: 2.0106e-05]
	Learning Rate: 2.01055e-05
	LOSS [training: 0.116609061457834 | validation: 0.08060878826212699]
	TIME [epoch: 9.18 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11240157741197701		[learning rate: 2.0033e-05]
	Learning Rate: 2.00326e-05
	LOSS [training: 0.11240157741197701 | validation: 0.0849210185122504]
	TIME [epoch: 9.2 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12076688733647958		[learning rate: 1.996e-05]
	Learning Rate: 1.99599e-05
	LOSS [training: 0.12076688733647958 | validation: 0.08757141077093088]
	TIME [epoch: 9.2 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10494492604621634		[learning rate: 1.9887e-05]
	Learning Rate: 1.98874e-05
	LOSS [training: 0.10494492604621634 | validation: 0.09166788466782792]
	TIME [epoch: 9.2 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1098165192000063		[learning rate: 1.9815e-05]
	Learning Rate: 1.98153e-05
	LOSS [training: 0.1098165192000063 | validation: 0.09325986505303908]
	TIME [epoch: 9.2 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1061266053422141		[learning rate: 1.9743e-05]
	Learning Rate: 1.97434e-05
	LOSS [training: 0.1061266053422141 | validation: 0.09122638235054366]
	TIME [epoch: 9.19 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12148215622854182		[learning rate: 1.9672e-05]
	Learning Rate: 1.96717e-05
	LOSS [training: 0.12148215622854182 | validation: 0.08965033151945309]
	TIME [epoch: 9.2 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11868392266926861		[learning rate: 1.96e-05]
	Learning Rate: 1.96003e-05
	LOSS [training: 0.11868392266926861 | validation: 0.08762469445335269]
	TIME [epoch: 9.21 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11092981988754427		[learning rate: 1.9529e-05]
	Learning Rate: 1.95292e-05
	LOSS [training: 0.11092981988754427 | validation: 0.08168376053695105]
	TIME [epoch: 9.19 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11607431619124801		[learning rate: 1.9458e-05]
	Learning Rate: 1.94583e-05
	LOSS [training: 0.11607431619124801 | validation: 0.0886924196417479]
	TIME [epoch: 9.2 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11010043055810961		[learning rate: 1.9388e-05]
	Learning Rate: 1.93877e-05
	LOSS [training: 0.11010043055810961 | validation: 0.08309115788442452]
	TIME [epoch: 9.19 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10824789879110094		[learning rate: 1.9317e-05]
	Learning Rate: 1.93173e-05
	LOSS [training: 0.10824789879110094 | validation: 0.08763526035739469]
	TIME [epoch: 9.23 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11681090360038533		[learning rate: 1.9247e-05]
	Learning Rate: 1.92472e-05
	LOSS [training: 0.11681090360038533 | validation: 0.08683173917462811]
	TIME [epoch: 9.2 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10888755528342438		[learning rate: 1.9177e-05]
	Learning Rate: 1.91774e-05
	LOSS [training: 0.10888755528342438 | validation: 0.09845021837370702]
	TIME [epoch: 9.19 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10951001799584792		[learning rate: 1.9108e-05]
	Learning Rate: 1.91078e-05
	LOSS [training: 0.10951001799584792 | validation: 0.09323359627971586]
	TIME [epoch: 9.19 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11012960795469302		[learning rate: 1.9038e-05]
	Learning Rate: 1.90384e-05
	LOSS [training: 0.11012960795469302 | validation: 0.08390397469298652]
	TIME [epoch: 9.2 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11422678254857681		[learning rate: 1.8969e-05]
	Learning Rate: 1.89694e-05
	LOSS [training: 0.11422678254857681 | validation: 0.09461007804803107]
	TIME [epoch: 9.21 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11151457817117616		[learning rate: 1.8901e-05]
	Learning Rate: 1.89005e-05
	LOSS [training: 0.11151457817117616 | validation: 0.08503999802607032]
	TIME [epoch: 9.2 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11512263335219526		[learning rate: 1.8832e-05]
	Learning Rate: 1.88319e-05
	LOSS [training: 0.11512263335219526 | validation: 0.08538049050619367]
	TIME [epoch: 9.21 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11706186523917554		[learning rate: 1.8764e-05]
	Learning Rate: 1.87636e-05
	LOSS [training: 0.11706186523917554 | validation: 0.08937150346799302]
	TIME [epoch: 9.2 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11984878077954035		[learning rate: 1.8695e-05]
	Learning Rate: 1.86955e-05
	LOSS [training: 0.11984878077954035 | validation: 0.08429496403773268]
	TIME [epoch: 9.21 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11199355607471		[learning rate: 1.8628e-05]
	Learning Rate: 1.86276e-05
	LOSS [training: 0.11199355607471 | validation: 0.0823704463431916]
	TIME [epoch: 9.2 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11089225719857287		[learning rate: 1.856e-05]
	Learning Rate: 1.856e-05
	LOSS [training: 0.11089225719857287 | validation: 0.09182137577752869]
	TIME [epoch: 9.19 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11468305949409767		[learning rate: 1.8493e-05]
	Learning Rate: 1.84927e-05
	LOSS [training: 0.11468305949409767 | validation: 0.0898641797679706]
	TIME [epoch: 9.2 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10653476948691501		[learning rate: 1.8426e-05]
	Learning Rate: 1.84256e-05
	LOSS [training: 0.10653476948691501 | validation: 0.08392054339200644]
	TIME [epoch: 9.2 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11361508483430136		[learning rate: 1.8359e-05]
	Learning Rate: 1.83587e-05
	LOSS [training: 0.11361508483430136 | validation: 0.08396751005820356]
	TIME [epoch: 9.21 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10696346297722012		[learning rate: 1.8292e-05]
	Learning Rate: 1.82921e-05
	LOSS [training: 0.10696346297722012 | validation: 0.084959065709638]
	TIME [epoch: 9.19 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12164216370706005		[learning rate: 1.8226e-05]
	Learning Rate: 1.82257e-05
	LOSS [training: 0.12164216370706005 | validation: 0.08979800441868696]
	TIME [epoch: 9.19 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10540277309120134		[learning rate: 1.816e-05]
	Learning Rate: 1.81596e-05
	LOSS [training: 0.10540277309120134 | validation: 0.0746012040850891]
	TIME [epoch: 9.18 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11368552571030008		[learning rate: 1.8094e-05]
	Learning Rate: 1.80937e-05
	LOSS [training: 0.11368552571030008 | validation: 0.08188043524897781]
	TIME [epoch: 9.21 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11279690183141648		[learning rate: 1.8028e-05]
	Learning Rate: 1.8028e-05
	LOSS [training: 0.11279690183141648 | validation: 0.08448596114178883]
	TIME [epoch: 9.2 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11280151227674182		[learning rate: 1.7963e-05]
	Learning Rate: 1.79626e-05
	LOSS [training: 0.11280151227674182 | validation: 0.10092805004729902]
	TIME [epoch: 9.19 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11245894353526993		[learning rate: 1.7897e-05]
	Learning Rate: 1.78974e-05
	LOSS [training: 0.11245894353526993 | validation: 0.09165301592673833]
	TIME [epoch: 9.18 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11120402191801967		[learning rate: 1.7832e-05]
	Learning Rate: 1.78324e-05
	LOSS [training: 0.11120402191801967 | validation: 0.08626180312701857]
	TIME [epoch: 9.19 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11754414400301134		[learning rate: 1.7768e-05]
	Learning Rate: 1.77677e-05
	LOSS [training: 0.11754414400301134 | validation: 0.09096708753377337]
	TIME [epoch: 9.2 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10916302166686502		[learning rate: 1.7703e-05]
	Learning Rate: 1.77032e-05
	LOSS [training: 0.10916302166686502 | validation: 0.08680613914941271]
	TIME [epoch: 9.18 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11101011854688914		[learning rate: 1.7639e-05]
	Learning Rate: 1.7639e-05
	LOSS [training: 0.11101011854688914 | validation: 0.09066910383569515]
	TIME [epoch: 9.2 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10892735348328722		[learning rate: 1.7575e-05]
	Learning Rate: 1.7575e-05
	LOSS [training: 0.10892735348328722 | validation: 0.0883735058027662]
	TIME [epoch: 9.2 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10927534053170933		[learning rate: 1.7511e-05]
	Learning Rate: 1.75112e-05
	LOSS [training: 0.10927534053170933 | validation: 0.08629771883577098]
	TIME [epoch: 9.22 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10548189187435726		[learning rate: 1.7448e-05]
	Learning Rate: 1.74476e-05
	LOSS [training: 0.10548189187435726 | validation: 0.08985074556876822]
	TIME [epoch: 9.19 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1126738061654241		[learning rate: 1.7384e-05]
	Learning Rate: 1.73843e-05
	LOSS [training: 0.1126738061654241 | validation: 0.079273302842032]
	TIME [epoch: 9.19 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11198361425342425		[learning rate: 1.7321e-05]
	Learning Rate: 1.73212e-05
	LOSS [training: 0.11198361425342425 | validation: 0.08477549904616453]
	TIME [epoch: 9.19 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11340820937902293		[learning rate: 1.7258e-05]
	Learning Rate: 1.72584e-05
	LOSS [training: 0.11340820937902293 | validation: 0.073856317664982]
	TIME [epoch: 9.19 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10730784432683867		[learning rate: 1.7196e-05]
	Learning Rate: 1.71957e-05
	LOSS [training: 0.10730784432683867 | validation: 0.07824428909958564]
	TIME [epoch: 9.21 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12123483905596075		[learning rate: 1.7133e-05]
	Learning Rate: 1.71333e-05
	LOSS [training: 0.12123483905596075 | validation: 0.08595723196498431]
	TIME [epoch: 9.18 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11866454350500413		[learning rate: 1.7071e-05]
	Learning Rate: 1.70712e-05
	LOSS [training: 0.11866454350500413 | validation: 0.09283909296345544]
	TIME [epoch: 9.18 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11962761921910021		[learning rate: 1.7009e-05]
	Learning Rate: 1.70092e-05
	LOSS [training: 0.11962761921910021 | validation: 0.09465020561570667]
	TIME [epoch: 9.18 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11062160769960791		[learning rate: 1.6947e-05]
	Learning Rate: 1.69475e-05
	LOSS [training: 0.11062160769960791 | validation: 0.07815315652382257]
	TIME [epoch: 9.21 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11125632681387945		[learning rate: 1.6886e-05]
	Learning Rate: 1.6886e-05
	LOSS [training: 0.11125632681387945 | validation: 0.09128728291717153]
	TIME [epoch: 9.19 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1188155897649813		[learning rate: 1.6825e-05]
	Learning Rate: 1.68247e-05
	LOSS [training: 0.1188155897649813 | validation: 0.0842783539538695]
	TIME [epoch: 9.2 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11723098773920611		[learning rate: 1.6764e-05]
	Learning Rate: 1.67636e-05
	LOSS [training: 0.11723098773920611 | validation: 0.0864322457732435]
	TIME [epoch: 9.19 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11346811126864172		[learning rate: 1.6703e-05]
	Learning Rate: 1.67028e-05
	LOSS [training: 0.11346811126864172 | validation: 0.08899826885005332]
	TIME [epoch: 9.2 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1043842685114088		[learning rate: 1.6642e-05]
	Learning Rate: 1.66422e-05
	LOSS [training: 0.1043842685114088 | validation: 0.08134492888993936]
	TIME [epoch: 9.21 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11225114947997798		[learning rate: 1.6582e-05]
	Learning Rate: 1.65818e-05
	LOSS [training: 0.11225114947997798 | validation: 0.08848989498373801]
	TIME [epoch: 9.19 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11288756712382378		[learning rate: 1.6522e-05]
	Learning Rate: 1.65216e-05
	LOSS [training: 0.11288756712382378 | validation: 0.08372808762810112]
	TIME [epoch: 9.18 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11180935891185932		[learning rate: 1.6462e-05]
	Learning Rate: 1.64617e-05
	LOSS [training: 0.11180935891185932 | validation: 0.09219087113708953]
	TIME [epoch: 9.19 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11240859697973771		[learning rate: 1.6402e-05]
	Learning Rate: 1.64019e-05
	LOSS [training: 0.11240859697973771 | validation: 0.08314161810735561]
	TIME [epoch: 9.21 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10761623525101979		[learning rate: 1.6342e-05]
	Learning Rate: 1.63424e-05
	LOSS [training: 0.10761623525101979 | validation: 0.08903751189346097]
	TIME [epoch: 9.19 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11188790593619521		[learning rate: 1.6283e-05]
	Learning Rate: 1.62831e-05
	LOSS [training: 0.11188790593619521 | validation: 0.08228155532031406]
	TIME [epoch: 9.19 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11980219627988316		[learning rate: 1.6224e-05]
	Learning Rate: 1.6224e-05
	LOSS [training: 0.11980219627988316 | validation: 0.08166510461006363]
	TIME [epoch: 9.18 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11255219914191605		[learning rate: 1.6165e-05]
	Learning Rate: 1.61651e-05
	LOSS [training: 0.11255219914191605 | validation: 0.08777735243734767]
	TIME [epoch: 9.19 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11374577141033622		[learning rate: 1.6106e-05]
	Learning Rate: 1.61065e-05
	LOSS [training: 0.11374577141033622 | validation: 0.08695600689522634]
	TIME [epoch: 9.21 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11255551918335387		[learning rate: 1.6048e-05]
	Learning Rate: 1.6048e-05
	LOSS [training: 0.11255551918335387 | validation: 0.08105142355655348]
	TIME [epoch: 9.19 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1179084336289872		[learning rate: 1.599e-05]
	Learning Rate: 1.59898e-05
	LOSS [training: 0.1179084336289872 | validation: 0.0958761368196181]
	TIME [epoch: 9.19 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11220290026576574		[learning rate: 1.5932e-05]
	Learning Rate: 1.59317e-05
	LOSS [training: 0.11220290026576574 | validation: 0.0919051368156229]
	TIME [epoch: 9.19 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12378021445282202		[learning rate: 1.5874e-05]
	Learning Rate: 1.58739e-05
	LOSS [training: 0.12378021445282202 | validation: 0.0888745574997555]
	TIME [epoch: 9.2 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11468873022334287		[learning rate: 1.5816e-05]
	Learning Rate: 1.58163e-05
	LOSS [training: 0.11468873022334287 | validation: 0.0909993224513373]
	TIME [epoch: 9.19 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11275691344577851		[learning rate: 1.5759e-05]
	Learning Rate: 1.57589e-05
	LOSS [training: 0.11275691344577851 | validation: 0.08131907807601466]
	TIME [epoch: 9.19 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11489225377375589		[learning rate: 1.5702e-05]
	Learning Rate: 1.57017e-05
	LOSS [training: 0.11489225377375589 | validation: 0.09602860294215074]
	TIME [epoch: 9.18 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11354937682225204		[learning rate: 1.5645e-05]
	Learning Rate: 1.56447e-05
	LOSS [training: 0.11354937682225204 | validation: 0.09029777284776966]
	TIME [epoch: 9.19 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11236917580005082		[learning rate: 1.5588e-05]
	Learning Rate: 1.5588e-05
	LOSS [training: 0.11236917580005082 | validation: 0.08599198284457477]
	TIME [epoch: 9.21 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11197575537733928		[learning rate: 1.5531e-05]
	Learning Rate: 1.55314e-05
	LOSS [training: 0.11197575537733928 | validation: 0.09732573155791494]
	TIME [epoch: 9.19 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10840586524677369		[learning rate: 1.5475e-05]
	Learning Rate: 1.5475e-05
	LOSS [training: 0.10840586524677369 | validation: 0.08973065090716126]
	TIME [epoch: 9.19 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11655732531087928		[learning rate: 1.5419e-05]
	Learning Rate: 1.54189e-05
	LOSS [training: 0.11655732531087928 | validation: 0.09267333508449146]
	TIME [epoch: 9.19 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11287426294980249		[learning rate: 1.5363e-05]
	Learning Rate: 1.53629e-05
	LOSS [training: 0.11287426294980249 | validation: 0.08452156022237413]
	TIME [epoch: 9.21 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12251270416982682		[learning rate: 1.5307e-05]
	Learning Rate: 1.53072e-05
	LOSS [training: 0.12251270416982682 | validation: 0.09185883228253121]
	TIME [epoch: 9.2 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11346842539487537		[learning rate: 1.5252e-05]
	Learning Rate: 1.52516e-05
	LOSS [training: 0.11346842539487537 | validation: 0.08051294231865064]
	TIME [epoch: 9.2 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11528778362237493		[learning rate: 1.5196e-05]
	Learning Rate: 1.51963e-05
	LOSS [training: 0.11528778362237493 | validation: 0.07953868536690649]
	TIME [epoch: 9.19 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12156337963155661		[learning rate: 1.5141e-05]
	Learning Rate: 1.51411e-05
	LOSS [training: 0.12156337963155661 | validation: 0.08315702176636627]
	TIME [epoch: 9.19 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11889985223929263		[learning rate: 1.5086e-05]
	Learning Rate: 1.50862e-05
	LOSS [training: 0.11889985223929263 | validation: 0.09344659040019357]
	TIME [epoch: 9.23 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10924860501607107		[learning rate: 1.5031e-05]
	Learning Rate: 1.50314e-05
	LOSS [training: 0.10924860501607107 | validation: 0.09617504870849505]
	TIME [epoch: 9.2 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1104832515937233		[learning rate: 1.4977e-05]
	Learning Rate: 1.49769e-05
	LOSS [training: 0.1104832515937233 | validation: 0.08981525804544895]
	TIME [epoch: 9.2 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1120592026994788		[learning rate: 1.4923e-05]
	Learning Rate: 1.49225e-05
	LOSS [training: 0.1120592026994788 | validation: 0.08726740369702454]
	TIME [epoch: 9.19 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10703204849500896		[learning rate: 1.4868e-05]
	Learning Rate: 1.48684e-05
	LOSS [training: 0.10703204849500896 | validation: 0.08724819249796471]
	TIME [epoch: 9.21 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10925589058236244		[learning rate: 1.4814e-05]
	Learning Rate: 1.48144e-05
	LOSS [training: 0.10925589058236244 | validation: 0.08220775762147275]
	TIME [epoch: 9.21 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10639592751823465		[learning rate: 1.4761e-05]
	Learning Rate: 1.47606e-05
	LOSS [training: 0.10639592751823465 | validation: 0.09153824823535733]
	TIME [epoch: 9.19 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11567312596455297		[learning rate: 1.4707e-05]
	Learning Rate: 1.47071e-05
	LOSS [training: 0.11567312596455297 | validation: 0.08709716306086054]
	TIME [epoch: 9.19 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12164467445917486		[learning rate: 1.4654e-05]
	Learning Rate: 1.46537e-05
	LOSS [training: 0.12164467445917486 | validation: 0.08415299495081244]
	TIME [epoch: 9.19 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11037470069201802		[learning rate: 1.4601e-05]
	Learning Rate: 1.46005e-05
	LOSS [training: 0.11037470069201802 | validation: 0.07592942831552167]
	TIME [epoch: 9.22 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1070435666984576		[learning rate: 1.4548e-05]
	Learning Rate: 1.45475e-05
	LOSS [training: 0.1070435666984576 | validation: 0.08065633865127539]
	TIME [epoch: 9.2 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10964386887210853		[learning rate: 1.4495e-05]
	Learning Rate: 1.44947e-05
	LOSS [training: 0.10964386887210853 | validation: 0.0856277636702194]
	TIME [epoch: 9.19 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10836994506083637		[learning rate: 1.4442e-05]
	Learning Rate: 1.44421e-05
	LOSS [training: 0.10836994506083637 | validation: 0.08592826829066712]
	TIME [epoch: 9.19 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1067761195500665		[learning rate: 1.439e-05]
	Learning Rate: 1.43897e-05
	LOSS [training: 0.1067761195500665 | validation: 0.09602511534640085]
	TIME [epoch: 9.2 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1141689189934841		[learning rate: 1.4338e-05]
	Learning Rate: 1.43375e-05
	LOSS [training: 0.1141689189934841 | validation: 0.0933322324923646]
	TIME [epoch: 9.2 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1111755747511656		[learning rate: 1.4285e-05]
	Learning Rate: 1.42855e-05
	LOSS [training: 0.1111755747511656 | validation: 0.09563838215459189]
	TIME [epoch: 9.19 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11114244658213641		[learning rate: 1.4234e-05]
	Learning Rate: 1.42336e-05
	LOSS [training: 0.11114244658213641 | validation: 0.08372829361701996]
	TIME [epoch: 9.19 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11618520385249871		[learning rate: 1.4182e-05]
	Learning Rate: 1.4182e-05
	LOSS [training: 0.11618520385249871 | validation: 0.07738825321526707]
	TIME [epoch: 9.18 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11834567513894459		[learning rate: 1.4131e-05]
	Learning Rate: 1.41305e-05
	LOSS [training: 0.11834567513894459 | validation: 0.09180303665905748]
	TIME [epoch: 9.21 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11199417772853167		[learning rate: 1.4079e-05]
	Learning Rate: 1.40792e-05
	LOSS [training: 0.11199417772853167 | validation: 0.08817216769568759]
	TIME [epoch: 9.18 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11693799835749012		[learning rate: 1.4028e-05]
	Learning Rate: 1.40281e-05
	LOSS [training: 0.11693799835749012 | validation: 0.08743666423973126]
	TIME [epoch: 9.19 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10601195919407977		[learning rate: 1.3977e-05]
	Learning Rate: 1.39772e-05
	LOSS [training: 0.10601195919407977 | validation: 0.07918793812345565]
	TIME [epoch: 9.2 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11150376881742123		[learning rate: 1.3927e-05]
	Learning Rate: 1.39265e-05
	LOSS [training: 0.11150376881742123 | validation: 0.08909572006188303]
	TIME [epoch: 9.21 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11700370699302928		[learning rate: 1.3876e-05]
	Learning Rate: 1.3876e-05
	LOSS [training: 0.11700370699302928 | validation: 0.09104160903081601]
	TIME [epoch: 9.21 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1272930429450579		[learning rate: 1.3826e-05]
	Learning Rate: 1.38256e-05
	LOSS [training: 0.1272930429450579 | validation: 0.07994608989584698]
	TIME [epoch: 9.19 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11518627340167165		[learning rate: 1.3775e-05]
	Learning Rate: 1.37754e-05
	LOSS [training: 0.11518627340167165 | validation: 0.08550560194258491]
	TIME [epoch: 9.19 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10771273584420964		[learning rate: 1.3725e-05]
	Learning Rate: 1.37254e-05
	LOSS [training: 0.10771273584420964 | validation: 0.08654227559766202]
	TIME [epoch: 9.19 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10853174960669539		[learning rate: 1.3676e-05]
	Learning Rate: 1.36756e-05
	LOSS [training: 0.10853174960669539 | validation: 0.08416539032774553]
	TIME [epoch: 9.21 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1113612363997192		[learning rate: 1.3626e-05]
	Learning Rate: 1.3626e-05
	LOSS [training: 0.1113612363997192 | validation: 0.09157331366753732]
	TIME [epoch: 9.18 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10928910882140079		[learning rate: 1.3577e-05]
	Learning Rate: 1.35766e-05
	LOSS [training: 0.10928910882140079 | validation: 0.08477221533850264]
	TIME [epoch: 9.17 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11272787697377191		[learning rate: 1.3527e-05]
	Learning Rate: 1.35273e-05
	LOSS [training: 0.11272787697377191 | validation: 0.09007223349311644]
	TIME [epoch: 9.19 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12040949681727371		[learning rate: 1.3478e-05]
	Learning Rate: 1.34782e-05
	LOSS [training: 0.12040949681727371 | validation: 0.08243911624855989]
	TIME [epoch: 9.19 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12069649410797638		[learning rate: 1.3429e-05]
	Learning Rate: 1.34293e-05
	LOSS [training: 0.12069649410797638 | validation: 0.09115807971337003]
	TIME [epoch: 9.2 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10899108904730034		[learning rate: 1.3381e-05]
	Learning Rate: 1.33805e-05
	LOSS [training: 0.10899108904730034 | validation: 0.0792065233253792]
	TIME [epoch: 9.18 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11140421952744353		[learning rate: 1.3332e-05]
	Learning Rate: 1.3332e-05
	LOSS [training: 0.11140421952744353 | validation: 0.07924519212436448]
	TIME [epoch: 9.19 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11674382461426247		[learning rate: 1.3284e-05]
	Learning Rate: 1.32836e-05
	LOSS [training: 0.11674382461426247 | validation: 0.08427288677041268]
	TIME [epoch: 9.19 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10988857924989988		[learning rate: 1.3235e-05]
	Learning Rate: 1.32354e-05
	LOSS [training: 0.10988857924989988 | validation: 0.10434786671585089]
	TIME [epoch: 9.22 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11759829265516179		[learning rate: 1.3187e-05]
	Learning Rate: 1.31874e-05
	LOSS [training: 0.11759829265516179 | validation: 0.0945400440674583]
	TIME [epoch: 9.19 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12154851186938313		[learning rate: 1.314e-05]
	Learning Rate: 1.31395e-05
	LOSS [training: 0.12154851186938313 | validation: 0.07783073283822387]
	TIME [epoch: 9.19 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11365701819253175		[learning rate: 1.3092e-05]
	Learning Rate: 1.30918e-05
	LOSS [training: 0.11365701819253175 | validation: 0.0807369388837411]
	TIME [epoch: 9.19 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1141249626600939		[learning rate: 1.3044e-05]
	Learning Rate: 1.30443e-05
	LOSS [training: 0.1141249626600939 | validation: 0.09107920190578783]
	TIME [epoch: 9.2 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10443187714509347		[learning rate: 1.2997e-05]
	Learning Rate: 1.2997e-05
	LOSS [training: 0.10443187714509347 | validation: 0.08242420293481548]
	TIME [epoch: 9.2 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11493727809111269		[learning rate: 1.295e-05]
	Learning Rate: 1.29498e-05
	LOSS [training: 0.11493727809111269 | validation: 0.07668933178247103]
	TIME [epoch: 9.19 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10723159736521712		[learning rate: 1.2903e-05]
	Learning Rate: 1.29028e-05
	LOSS [training: 0.10723159736521712 | validation: 0.08659745793553285]
	TIME [epoch: 9.19 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1080879865872294		[learning rate: 1.2856e-05]
	Learning Rate: 1.2856e-05
	LOSS [training: 0.1080879865872294 | validation: 0.09382357892614548]
	TIME [epoch: 9.19 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.112786800711168		[learning rate: 1.2809e-05]
	Learning Rate: 1.28093e-05
	LOSS [training: 0.112786800711168 | validation: 0.08389797744416987]
	TIME [epoch: 9.22 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1173019445379887		[learning rate: 1.2763e-05]
	Learning Rate: 1.27628e-05
	LOSS [training: 0.1173019445379887 | validation: 0.09284393376612658]
	TIME [epoch: 9.19 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12120436145552507		[learning rate: 1.2717e-05]
	Learning Rate: 1.27165e-05
	LOSS [training: 0.12120436145552507 | validation: 0.08909556172797156]
	TIME [epoch: 9.2 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11637949668020023		[learning rate: 1.267e-05]
	Learning Rate: 1.26704e-05
	LOSS [training: 0.11637949668020023 | validation: 0.07987470638488138]
	TIME [epoch: 9.2 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11539536252930578		[learning rate: 1.2624e-05]
	Learning Rate: 1.26244e-05
	LOSS [training: 0.11539536252930578 | validation: 0.08879991849671688]
	TIME [epoch: 9.21 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11468941804393969		[learning rate: 1.2579e-05]
	Learning Rate: 1.25786e-05
	LOSS [training: 0.11468941804393969 | validation: 0.09348243714799992]
	TIME [epoch: 9.21 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11114164377582032		[learning rate: 1.2533e-05]
	Learning Rate: 1.25329e-05
	LOSS [training: 0.11114164377582032 | validation: 0.07795484999393378]
	TIME [epoch: 9.2 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11440778480181302		[learning rate: 1.2487e-05]
	Learning Rate: 1.24874e-05
	LOSS [training: 0.11440778480181302 | validation: 0.08474735206044288]
	TIME [epoch: 9.2 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11444823641160447		[learning rate: 1.2442e-05]
	Learning Rate: 1.24421e-05
	LOSS [training: 0.11444823641160447 | validation: 0.0888481268104914]
	TIME [epoch: 9.19 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11502757828404712		[learning rate: 1.2397e-05]
	Learning Rate: 1.2397e-05
	LOSS [training: 0.11502757828404712 | validation: 0.08484159643037759]
	TIME [epoch: 9.22 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.110827604815619		[learning rate: 1.2352e-05]
	Learning Rate: 1.2352e-05
	LOSS [training: 0.110827604815619 | validation: 0.08383512977478375]
	TIME [epoch: 9.2 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10993166379312776		[learning rate: 1.2307e-05]
	Learning Rate: 1.23072e-05
	LOSS [training: 0.10993166379312776 | validation: 0.09036420044321204]
	TIME [epoch: 9.2 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1154753086346004		[learning rate: 1.2263e-05]
	Learning Rate: 1.22625e-05
	LOSS [training: 0.1154753086346004 | validation: 0.08691194327462731]
	TIME [epoch: 9.2 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11306732840886154		[learning rate: 1.2218e-05]
	Learning Rate: 1.2218e-05
	LOSS [training: 0.11306732840886154 | validation: 0.0906538203699094]
	TIME [epoch: 9.21 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12003893146256192		[learning rate: 1.2174e-05]
	Learning Rate: 1.21737e-05
	LOSS [training: 0.12003893146256192 | validation: 0.08823181424319868]
	TIME [epoch: 9.22 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1068064672982925		[learning rate: 1.2129e-05]
	Learning Rate: 1.21295e-05
	LOSS [training: 0.1068064672982925 | validation: 0.07977807763384533]
	TIME [epoch: 9.21 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11027223644458675		[learning rate: 1.2085e-05]
	Learning Rate: 1.20855e-05
	LOSS [training: 0.11027223644458675 | validation: 0.08464443798630591]
	TIME [epoch: 9.22 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12302683062371567		[learning rate: 1.2042e-05]
	Learning Rate: 1.20416e-05
	LOSS [training: 0.12302683062371567 | validation: 0.07799887596010638]
	TIME [epoch: 9.22 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.113903955215455		[learning rate: 1.1998e-05]
	Learning Rate: 1.19979e-05
	LOSS [training: 0.113903955215455 | validation: 0.0914074250563032]
	TIME [epoch: 9.25 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10986020652011545		[learning rate: 1.1954e-05]
	Learning Rate: 1.19544e-05
	LOSS [training: 0.10986020652011545 | validation: 0.09715143681528972]
	TIME [epoch: 9.21 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11305510341717573		[learning rate: 1.1911e-05]
	Learning Rate: 1.1911e-05
	LOSS [training: 0.11305510341717573 | validation: 0.08762960809247705]
	TIME [epoch: 9.2 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12127818188285615		[learning rate: 1.1868e-05]
	Learning Rate: 1.18678e-05
	LOSS [training: 0.12127818188285615 | validation: 0.08509972155768805]
	TIME [epoch: 9.2 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11358244616481557		[learning rate: 1.1825e-05]
	Learning Rate: 1.18247e-05
	LOSS [training: 0.11358244616481557 | validation: 0.08230610618265262]
	TIME [epoch: 9.22 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11746165512902909		[learning rate: 1.1782e-05]
	Learning Rate: 1.17818e-05
	LOSS [training: 0.11746165512902909 | validation: 0.08989473032550908]
	TIME [epoch: 9.22 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10352487312543686		[learning rate: 1.1739e-05]
	Learning Rate: 1.1739e-05
	LOSS [training: 0.10352487312543686 | validation: 0.08837712475754153]
	TIME [epoch: 9.21 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12312236220016173		[learning rate: 1.1696e-05]
	Learning Rate: 1.16964e-05
	LOSS [training: 0.12312236220016173 | validation: 0.0839998742594208]
	TIME [epoch: 9.2 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11470796798586735		[learning rate: 1.1654e-05]
	Learning Rate: 1.1654e-05
	LOSS [training: 0.11470796798586735 | validation: 0.08484506004250729]
	TIME [epoch: 9.2 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10359634481104396		[learning rate: 1.1612e-05]
	Learning Rate: 1.16117e-05
	LOSS [training: 0.10359634481104396 | validation: 0.0902590766238929]
	TIME [epoch: 9.23 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12362377514569109		[learning rate: 1.157e-05]
	Learning Rate: 1.15695e-05
	LOSS [training: 0.12362377514569109 | validation: 0.07793447343184697]
	TIME [epoch: 9.21 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11305313066787423		[learning rate: 1.1528e-05]
	Learning Rate: 1.15275e-05
	LOSS [training: 0.11305313066787423 | validation: 0.09100457832349508]
	TIME [epoch: 9.2 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11064842815963767		[learning rate: 1.1486e-05]
	Learning Rate: 1.14857e-05
	LOSS [training: 0.11064842815963767 | validation: 0.0855676162341049]
	TIME [epoch: 9.2 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11152774706364803		[learning rate: 1.1444e-05]
	Learning Rate: 1.1444e-05
	LOSS [training: 0.11152774706364803 | validation: 0.08846063164768174]
	TIME [epoch: 9.2 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11268009956696379		[learning rate: 1.1402e-05]
	Learning Rate: 1.14025e-05
	LOSS [training: 0.11268009956696379 | validation: 0.0875903074220524]
	TIME [epoch: 9.22 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10978113330785555		[learning rate: 1.1361e-05]
	Learning Rate: 1.13611e-05
	LOSS [training: 0.10978113330785555 | validation: 0.07300844898475073]
	TIME [epoch: 9.21 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11201416144876604		[learning rate: 1.132e-05]
	Learning Rate: 1.13199e-05
	LOSS [training: 0.11201416144876604 | validation: 0.0807659466371252]
	TIME [epoch: 9.2 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11257229317993758		[learning rate: 1.1279e-05]
	Learning Rate: 1.12788e-05
	LOSS [training: 0.11257229317993758 | validation: 0.07580591379967523]
	TIME [epoch: 9.2 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10770033493934525		[learning rate: 1.1238e-05]
	Learning Rate: 1.12379e-05
	LOSS [training: 0.10770033493934525 | validation: 0.08500984006200334]
	TIME [epoch: 9.22 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10912510621205433		[learning rate: 1.1197e-05]
	Learning Rate: 1.11971e-05
	LOSS [training: 0.10912510621205433 | validation: 0.08484994045697064]
	TIME [epoch: 9.21 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12132636268587207		[learning rate: 1.1156e-05]
	Learning Rate: 1.11565e-05
	LOSS [training: 0.12132636268587207 | validation: 0.07256659257022352]
	TIME [epoch: 9.21 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11906397846066803		[learning rate: 1.1116e-05]
	Learning Rate: 1.1116e-05
	LOSS [training: 0.11906397846066803 | validation: 0.07934967371126012]
	TIME [epoch: 9.21 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11322457775743526		[learning rate: 1.1076e-05]
	Learning Rate: 1.10756e-05
	LOSS [training: 0.11322457775743526 | validation: 0.08932369452698871]
	TIME [epoch: 9.22 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1178700513402076		[learning rate: 1.1035e-05]
	Learning Rate: 1.10354e-05
	LOSS [training: 0.1178700513402076 | validation: 0.09766209603485909]
	TIME [epoch: 9.23 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1116592326883763		[learning rate: 1.0995e-05]
	Learning Rate: 1.09954e-05
	LOSS [training: 0.1116592326883763 | validation: 0.07941750073675363]
	TIME [epoch: 9.2 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11070875164821833		[learning rate: 1.0955e-05]
	Learning Rate: 1.09555e-05
	LOSS [training: 0.11070875164821833 | validation: 0.08515177749931074]
	TIME [epoch: 9.21 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1138874537617933		[learning rate: 1.0916e-05]
	Learning Rate: 1.09157e-05
	LOSS [training: 0.1138874537617933 | validation: 0.08916722368496469]
	TIME [epoch: 9.2 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10773306429571243		[learning rate: 1.0876e-05]
	Learning Rate: 1.08761e-05
	LOSS [training: 0.10773306429571243 | validation: 0.09097639986547928]
	TIME [epoch: 9.22 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10989550483096275		[learning rate: 1.0837e-05]
	Learning Rate: 1.08366e-05
	LOSS [training: 0.10989550483096275 | validation: 0.08087605458597684]
	TIME [epoch: 9.2 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1136259779806014		[learning rate: 1.0797e-05]
	Learning Rate: 1.07973e-05
	LOSS [training: 0.1136259779806014 | validation: 0.09633554695835954]
	TIME [epoch: 9.19 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11209333271961675		[learning rate: 1.0758e-05]
	Learning Rate: 1.07581e-05
	LOSS [training: 0.11209333271961675 | validation: 0.07460540607546459]
	TIME [epoch: 9.2 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11639652209957237		[learning rate: 1.0719e-05]
	Learning Rate: 1.07191e-05
	LOSS [training: 0.11639652209957237 | validation: 0.08337979249272726]
	TIME [epoch: 9.2 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10596328018765244		[learning rate: 1.068e-05]
	Learning Rate: 1.06802e-05
	LOSS [training: 0.10596328018765244 | validation: 0.08520831774829644]
	TIME [epoch: 9.21 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10973800029854057		[learning rate: 1.0641e-05]
	Learning Rate: 1.06414e-05
	LOSS [training: 0.10973800029854057 | validation: 0.08577125404379732]
	TIME [epoch: 9.19 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1205302162208651		[learning rate: 1.0603e-05]
	Learning Rate: 1.06028e-05
	LOSS [training: 0.1205302162208651 | validation: 0.09661218863824939]
	TIME [epoch: 9.19 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11788949869972372		[learning rate: 1.0564e-05]
	Learning Rate: 1.05643e-05
	LOSS [training: 0.11788949869972372 | validation: 0.09066881066326704]
	TIME [epoch: 9.2 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1182018376306638		[learning rate: 1.0526e-05]
	Learning Rate: 1.0526e-05
	LOSS [training: 0.1182018376306638 | validation: 0.09808076035061863]
	TIME [epoch: 9.22 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11099832057826389		[learning rate: 1.0488e-05]
	Learning Rate: 1.04878e-05
	LOSS [training: 0.11099832057826389 | validation: 0.08232452507160422]
	TIME [epoch: 9.2 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10950086258345446		[learning rate: 1.045e-05]
	Learning Rate: 1.04497e-05
	LOSS [training: 0.10950086258345446 | validation: 0.0935743118106338]
	TIME [epoch: 9.19 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10766904652145226		[learning rate: 1.0412e-05]
	Learning Rate: 1.04118e-05
	LOSS [training: 0.10766904652145226 | validation: 0.09451251709551997]
	TIME [epoch: 9.19 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11886422211402876		[learning rate: 1.0374e-05]
	Learning Rate: 1.0374e-05
	LOSS [training: 0.11886422211402876 | validation: 0.0823792186017352]
	TIME [epoch: 9.19 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11324202589053008		[learning rate: 1.0336e-05]
	Learning Rate: 1.03364e-05
	LOSS [training: 0.11324202589053008 | validation: 0.10485299556780367]
	TIME [epoch: 9.21 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11435117744151366		[learning rate: 1.0299e-05]
	Learning Rate: 1.02989e-05
	LOSS [training: 0.11435117744151366 | validation: 0.0910167445038786]
	TIME [epoch: 9.19 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11761736588456148		[learning rate: 1.0261e-05]
	Learning Rate: 1.02615e-05
	LOSS [training: 0.11761736588456148 | validation: 0.09073827853223396]
	TIME [epoch: 9.19 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11042671856378705		[learning rate: 1.0224e-05]
	Learning Rate: 1.02243e-05
	LOSS [training: 0.11042671856378705 | validation: 0.09044834892041928]
	TIME [epoch: 9.18 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1135205832576625		[learning rate: 1.0187e-05]
	Learning Rate: 1.01872e-05
	LOSS [training: 0.1135205832576625 | validation: 0.08220498686380483]
	TIME [epoch: 9.21 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11535787249175593		[learning rate: 1.015e-05]
	Learning Rate: 1.01502e-05
	LOSS [training: 0.11535787249175593 | validation: 0.08479652594505042]
	TIME [epoch: 9.18 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11365696430883292		[learning rate: 1.0113e-05]
	Learning Rate: 1.01133e-05
	LOSS [training: 0.11365696430883292 | validation: 0.08856429382561815]
	TIME [epoch: 9.18 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1152114375371623		[learning rate: 1.0077e-05]
	Learning Rate: 1.00766e-05
	LOSS [training: 0.1152114375371623 | validation: 0.08545667177718277]
	TIME [epoch: 9.18 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11271617224917274		[learning rate: 1.004e-05]
	Learning Rate: 1.00401e-05
	LOSS [training: 0.11271617224917274 | validation: 0.08350015956019485]
	TIME [epoch: 9.19 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11772327724522888		[learning rate: 1.0004e-05]
	Learning Rate: 1.00036e-05
	LOSS [training: 0.11772327724522888 | validation: 0.07873146788248517]
	TIME [epoch: 9.21 sec]
Finished training in 18547.325 seconds.
