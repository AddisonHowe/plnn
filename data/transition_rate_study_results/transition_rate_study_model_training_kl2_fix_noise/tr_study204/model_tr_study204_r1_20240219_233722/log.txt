Args:
Namespace(name='model_tr_study204', outdir='out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1', training_data='data/transition_rate_studies/tr_study204/tr_study204_training/r1', validation_data='data/transition_rate_studies/tr_study204/tr_study204_validation/r1', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.075, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=100, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 4219740954

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 10/10] avg loss: 10.820715752569106		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.820715752569106 | validation: 11.50227718553295]
	TIME [epoch: 78.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 10/10] avg loss: 9.927557212725251		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.927557212725251 | validation: 9.55606296761076]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.903822039196127		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.903822039196127 | validation: 8.663333808733524]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.767918463820742		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.767918463820742 | validation: 10.901205449596894]
	TIME [epoch: 8.53 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 10/10] avg loss: 9.067040408756187		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.067040408756187 | validation: 10.412708120335825]
	TIME [epoch: 8.53 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.264083965851135		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.264083965851135 | validation: 10.215271936587197]
	TIME [epoch: 8.53 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.622082530019384		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.622082530019384 | validation: 8.017293741015488]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.074715616935511		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.074715616935511 | validation: 9.594415754292342]
	TIME [epoch: 8.54 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.139159529517459		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.139159529517459 | validation: 8.483989909369333]
	TIME [epoch: 8.53 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.725516086816803		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.725516086816803 | validation: 6.852419598868931]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.664025147164965		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.664025147164965 | validation: 9.04300829448798]
	TIME [epoch: 8.54 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.927704286253058		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.927704286253058 | validation: 5.970317917417773]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.353810942761622		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.353810942761622 | validation: 5.64081146048696]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.438766668475336		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.438766668475336 | validation: 6.3052796044692965]
	TIME [epoch: 8.53 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.359640593950202		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.359640593950202 | validation: 6.41743963234489]
	TIME [epoch: 8.53 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.202957291112897		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.202957291112897 | validation: 6.7969219592557035]
	TIME [epoch: 8.54 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.051626473962722		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.051626473962722 | validation: 5.769403457551369]
	TIME [epoch: 8.53 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.416506373343015		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.416506373343015 | validation: 7.608239742949008]
	TIME [epoch: 8.53 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.446472344077888		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.446472344077888 | validation: 8.04053603450732]
	TIME [epoch: 8.53 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.315366242456308		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.315366242456308 | validation: 6.549182380399223]
	TIME [epoch: 8.55 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.049939069246809		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.049939069246809 | validation: 6.116632009241632]
	TIME [epoch: 8.53 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.979571122828867		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.979571122828867 | validation: 6.238273925435307]
	TIME [epoch: 8.53 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.880692431048588		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.880692431048588 | validation: 5.99478298454582]
	TIME [epoch: 8.53 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.876197959049844		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.876197959049844 | validation: 6.145632967736473]
	TIME [epoch: 8.56 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.9019725283346265		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.9019725283346265 | validation: 5.962339768142685]
	TIME [epoch: 8.53 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.821772970220985		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.821772970220985 | validation: 5.950869458791185]
	TIME [epoch: 8.53 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.789232086642915		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.789232086642915 | validation: 6.25423798069885]
	TIME [epoch: 8.54 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.794131225723916		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.794131225723916 | validation: 5.767615947874431]
	TIME [epoch: 8.55 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.7431221803927395		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.7431221803927395 | validation: 5.947354587656222]
	TIME [epoch: 8.53 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.719753717663194		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.719753717663194 | validation: 5.6417074438747665]
	TIME [epoch: 8.53 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.656603620071672		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.656603620071672 | validation: 6.296653105940319]
	TIME [epoch: 8.52 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.673777324949609		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.673777324949609 | validation: 6.250033711709069]
	TIME [epoch: 8.53 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.67943920197482		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.67943920197482 | validation: 5.745353202757746]
	TIME [epoch: 8.55 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.620914727373225		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.620914727373225 | validation: 5.621381012183139]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.471706741157914		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.471706741157914 | validation: 6.285599498372951]
	TIME [epoch: 8.51 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.649086046278056		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.649086046278056 | validation: 5.848010455880236]
	TIME [epoch: 8.52 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.434792252875964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.434792252875964 | validation: 5.67198997285133]
	TIME [epoch: 8.54 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.4417820283625185		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.4417820283625185 | validation: 5.3791820992980615]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.510398368588907		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.510398368588907 | validation: 5.378114441582115]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.432097883056349		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.432097883056349 | validation: 5.392372025147248]
	TIME [epoch: 8.54 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.392451769818449		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.392451769818449 | validation: 5.311638944990738]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.446357643212151		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.446357643212151 | validation: 5.473695506631763]
	TIME [epoch: 8.52 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.349256438869988		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.349256438869988 | validation: 5.501802724875852]
	TIME [epoch: 8.52 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.272885090589063		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.272885090589063 | validation: 5.6667002201426335]
	TIME [epoch: 8.52 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.33658283231963		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.33658283231963 | validation: 5.28964076371764]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.295926110567604		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.295926110567604 | validation: 5.560480612861866]
	TIME [epoch: 8.53 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.220614860906999		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.220614860906999 | validation: 5.214551855902486]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.193915468562927		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.193915468562927 | validation: 5.383234773603775]
	TIME [epoch: 8.52 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.229531595354633		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.229531595354633 | validation: 5.444405673011834]
	TIME [epoch: 8.54 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.156933969924976		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.156933969924976 | validation: 5.462976612250886]
	TIME [epoch: 8.51 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.175232354406058		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.175232354406058 | validation: 5.425229808653315]
	TIME [epoch: 8.51 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.152391677044708		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.152391677044708 | validation: 5.403389140639684]
	TIME [epoch: 8.51 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.170436403597651		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.170436403597651 | validation: 5.232601803504188]
	TIME [epoch: 8.53 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.063409803943477		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.063409803943477 | validation: 5.3528270236873645]
	TIME [epoch: 8.52 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.188677801235768		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.188677801235768 | validation: 5.324197822407698]
	TIME [epoch: 8.51 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.079474388340697		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.079474388340697 | validation: 5.2522788838514565]
	TIME [epoch: 8.51 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.065966479953486		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.065966479953486 | validation: 5.67703873216054]
	TIME [epoch: 8.52 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.236562329700484		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.236562329700484 | validation: 5.307378614399401]
	TIME [epoch: 8.54 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.106689124203751		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.106689124203751 | validation: 5.030471780588208]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.9827409209037823		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9827409209037823 | validation: 5.187324037054214]
	TIME [epoch: 8.51 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.980767487978693		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.980767487978693 | validation: 5.001006443051236]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.9747214525102614		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9747214525102614 | validation: 5.217451923534426]
	TIME [epoch: 8.54 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.0055884825510635		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.0055884825510635 | validation: 5.150879226148794]
	TIME [epoch: 8.51 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.8840862201447743		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8840862201447743 | validation: 5.259332389783539]
	TIME [epoch: 8.51 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.951890280277336		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.951890280277336 | validation: 5.161871681693741]
	TIME [epoch: 8.51 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.9013674260912254		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9013674260912254 | validation: 5.2100650705405736]
	TIME [epoch: 8.54 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.9084934435934438		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9084934435934438 | validation: 5.1201125050407335]
	TIME [epoch: 8.51 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.883743307941843		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.883743307941843 | validation: 5.054400668149549]
	TIME [epoch: 8.52 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.8851525719742		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8851525719742 | validation: 4.9745378553935735]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.875222815817685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.875222815817685 | validation: 4.861582170264058]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_70.pth
	Model improved!!!
EPOCH 71/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.045311006685805		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.045311006685805 | validation: 4.985681179318908]
	TIME [epoch: 8.52 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.875265304960523		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.875265304960523 | validation: 5.275322783377325]
	TIME [epoch: 8.51 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.049786196899332		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.049786196899332 | validation: 4.846167050228867]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.9184008221521607		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9184008221521607 | validation: 5.046173109276975]
	TIME [epoch: 8.57 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.8478021815049646		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8478021815049646 | validation: 5.246547204208559]
	TIME [epoch: 8.52 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.839791330298975		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.839791330298975 | validation: 5.062003852809683]
	TIME [epoch: 8.51 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.7822966087111007		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7822966087111007 | validation: 5.444560260555109]
	TIME [epoch: 8.51 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.9092671021363543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9092671021363543 | validation: 5.042427100948922]
	TIME [epoch: 8.51 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.777545462695021		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.777545462695021 | validation: 4.874753081560172]
	TIME [epoch: 8.53 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.835702938364457		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.835702938364457 | validation: 5.1066236510301195]
	TIME [epoch: 8.51 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.791580530607623		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.791580530607623 | validation: 5.040845450317798]
	TIME [epoch: 8.51 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.748500809991087		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.748500809991087 | validation: 5.08992010008258]
	TIME [epoch: 8.51 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.932003130732375		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.932003130732375 | validation: 4.884471482440312]
	TIME [epoch: 8.53 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.816533386683614		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.816533386683614 | validation: 5.10763946459977]
	TIME [epoch: 8.52 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.232738396438485		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.232738396438485 | validation: 5.619779684096926]
	TIME [epoch: 8.51 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.867220155600319		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.867220155600319 | validation: 5.004710870253604]
	TIME [epoch: 8.51 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.9066616078861403		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9066616078861403 | validation: 5.038598513987151]
	TIME [epoch: 8.55 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.8335583453472557		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8335583453472557 | validation: 5.293738107009391]
	TIME [epoch: 8.51 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.795995007244244		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.795995007244244 | validation: 5.20383092530412]
	TIME [epoch: 8.5 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.7664483383921827		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7664483383921827 | validation: 5.437854824768959]
	TIME [epoch: 8.52 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.8261786682840784		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8261786682840784 | validation: 4.884455641131439]
	TIME [epoch: 8.54 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.777307614127775		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.777307614127775 | validation: 4.743258165793079]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_92.pth
	Model improved!!!
EPOCH 93/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.135233635179165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.135233635179165 | validation: 5.998862801321306]
	TIME [epoch: 8.52 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.392628874660376		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.392628874660376 | validation: 5.8958778059949495]
	TIME [epoch: 8.51 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.062630038629357		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.062630038629357 | validation: 4.8951193665339945]
	TIME [epoch: 8.52 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.770957182360655		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.770957182360655 | validation: 4.70231178111235]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_96.pth
	Model improved!!!
EPOCH 97/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.8235395060347		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8235395060347 | validation: 4.944269199972866]
	TIME [epoch: 8.52 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.711980407198395		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.711980407198395 | validation: 5.259627032194551]
	TIME [epoch: 8.52 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.7648440791989883		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7648440791989883 | validation: 4.70735814835143]
	TIME [epoch: 8.51 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.7376442195451		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7376442195451 | validation: 4.70942771102259]
	TIME [epoch: 8.54 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.8431300119990413		[learning rate: 0.0099673]
	Learning Rate: 0.00996733
	LOSS [training: 3.8431300119990413 | validation: 4.645669607192333]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_101.pth
	Model improved!!!
EPOCH 102/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.7141682118378014		[learning rate: 0.0099312]
	Learning Rate: 0.00993116
	LOSS [training: 3.7141682118378014 | validation: 4.719285922878546]
	TIME [epoch: 8.52 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.7058515059915442		[learning rate: 0.0098951]
	Learning Rate: 0.00989512
	LOSS [training: 3.7058515059915442 | validation: 4.844779331475072]
	TIME [epoch: 8.52 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.6635309170478685		[learning rate: 0.0098592]
	Learning Rate: 0.00985921
	LOSS [training: 3.6635309170478685 | validation: 4.943666485656424]
	TIME [epoch: 8.54 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.6376221593815563		[learning rate: 0.0098234]
	Learning Rate: 0.00982343
	LOSS [training: 3.6376221593815563 | validation: 4.612838073194319]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_105.pth
	Model improved!!!
EPOCH 106/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.6778724350603698		[learning rate: 0.0097878]
	Learning Rate: 0.00978778
	LOSS [training: 3.6778724350603698 | validation: 4.347028808504715]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_106.pth
	Model improved!!!
EPOCH 107/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.7512154092074623		[learning rate: 0.0097523]
	Learning Rate: 0.00975226
	LOSS [training: 3.7512154092074623 | validation: 4.303306198352619]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_107.pth
	Model improved!!!
EPOCH 108/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.251310266154017		[learning rate: 0.0097169]
	Learning Rate: 0.00971687
	LOSS [training: 3.251310266154017 | validation: 4.0798958255169735]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_108.pth
	Model improved!!!
EPOCH 109/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.177547215980934		[learning rate: 0.0096816]
	Learning Rate: 0.0096816
	LOSS [training: 3.177547215980934 | validation: 4.249708852343689]
	TIME [epoch: 8.53 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1924958810015127		[learning rate: 0.0096465]
	Learning Rate: 0.00964647
	LOSS [training: 3.1924958810015127 | validation: 4.0837747410987815]
	TIME [epoch: 8.52 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.099042020839264		[learning rate: 0.0096115]
	Learning Rate: 0.00961146
	LOSS [training: 3.099042020839264 | validation: 4.608116207834673]
	TIME [epoch: 8.52 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.0371109263286358		[learning rate: 0.0095766]
	Learning Rate: 0.00957658
	LOSS [training: 3.0371109263286358 | validation: 3.8507372921955563]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_112.pth
	Model improved!!!
EPOCH 113/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.465371042578339		[learning rate: 0.0095418]
	Learning Rate: 0.00954183
	LOSS [training: 2.465371042578339 | validation: 3.616824966279009]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_113.pth
	Model improved!!!
EPOCH 114/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2627553945256644		[learning rate: 0.0095072]
	Learning Rate: 0.0095072
	LOSS [training: 2.2627553945256644 | validation: 3.820791582092367]
	TIME [epoch: 8.52 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2807780058690486		[learning rate: 0.0094727]
	Learning Rate: 0.0094727
	LOSS [training: 2.2807780058690486 | validation: 3.6521103206542476]
	TIME [epoch: 8.52 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.9399588650956288		[learning rate: 0.0094383]
	Learning Rate: 0.00943832
	LOSS [training: 2.9399588650956288 | validation: 4.723345396917534]
	TIME [epoch: 8.53 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5654276013847506		[learning rate: 0.0094041]
	Learning Rate: 0.00940407
	LOSS [training: 2.5654276013847506 | validation: 3.3613425140245656]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_117.pth
	Model improved!!!
EPOCH 118/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1004493868030183		[learning rate: 0.0093699]
	Learning Rate: 0.00936994
	LOSS [training: 2.1004493868030183 | validation: 3.740973008026998]
	TIME [epoch: 8.52 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.054728675853169		[learning rate: 0.0093359]
	Learning Rate: 0.00933594
	LOSS [training: 2.054728675853169 | validation: 3.6115448795622944]
	TIME [epoch: 8.52 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.302565090210844		[learning rate: 0.0093021]
	Learning Rate: 0.00930206
	LOSS [training: 2.302565090210844 | validation: 4.001731642489829]
	TIME [epoch: 8.52 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1284136205319357		[learning rate: 0.0092683]
	Learning Rate: 0.0092683
	LOSS [training: 2.1284136205319357 | validation: 3.3835014653629867]
	TIME [epoch: 8.54 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.028854458743467		[learning rate: 0.0092347]
	Learning Rate: 0.00923466
	LOSS [training: 2.028854458743467 | validation: 3.4291965338692014]
	TIME [epoch: 8.51 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9021737389620632		[learning rate: 0.0092011]
	Learning Rate: 0.00920115
	LOSS [training: 1.9021737389620632 | validation: 3.572076022001622]
	TIME [epoch: 8.51 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.042406239733257		[learning rate: 0.0091678]
	Learning Rate: 0.00916776
	LOSS [training: 2.042406239733257 | validation: 3.3557207376623923]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_124.pth
	Model improved!!!
EPOCH 125/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.900879119446109		[learning rate: 0.0091345]
	Learning Rate: 0.00913449
	LOSS [training: 1.900879119446109 | validation: 2.7483618451464773]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_125.pth
	Model improved!!!
EPOCH 126/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9696253159058934		[learning rate: 0.0091013]
	Learning Rate: 0.00910134
	LOSS [training: 1.9696253159058934 | validation: 2.844154892301846]
	TIME [epoch: 8.52 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0357306331061564		[learning rate: 0.0090683]
	Learning Rate: 0.00906831
	LOSS [training: 2.0357306331061564 | validation: 3.202066020291036]
	TIME [epoch: 8.51 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7854814569152044		[learning rate: 0.0090354]
	Learning Rate: 0.0090354
	LOSS [training: 1.7854814569152044 | validation: 2.3841693242708804]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_128.pth
	Model improved!!!
EPOCH 129/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.482351571039761		[learning rate: 0.0090026]
	Learning Rate: 0.00900261
	LOSS [training: 1.482351571039761 | validation: 1.8171648032313783]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_129.pth
	Model improved!!!
EPOCH 130/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.172820919232444		[learning rate: 0.0089699]
	Learning Rate: 0.00896994
	LOSS [training: 1.172820919232444 | validation: 1.0660684158870404]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_130.pth
	Model improved!!!
EPOCH 131/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1626269176417345		[learning rate: 0.0089374]
	Learning Rate: 0.00893739
	LOSS [training: 1.1626269176417345 | validation: 1.1042798505420728]
	TIME [epoch: 8.52 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0057431070865808		[learning rate: 0.008905]
	Learning Rate: 0.00890495
	LOSS [training: 1.0057431070865808 | validation: 0.875055842168907]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_132.pth
	Model improved!!!
EPOCH 133/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9188289689766529		[learning rate: 0.0088726]
	Learning Rate: 0.00887263
	LOSS [training: 0.9188289689766529 | validation: 1.0319366078788739]
	TIME [epoch: 8.55 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8992942140253897		[learning rate: 0.0088404]
	Learning Rate: 0.00884044
	LOSS [training: 0.8992942140253897 | validation: 0.7206102960335969]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_134.pth
	Model improved!!!
EPOCH 135/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9224117730276926		[learning rate: 0.0088084]
	Learning Rate: 0.00880835
	LOSS [training: 0.9224117730276926 | validation: 0.9909660801010742]
	TIME [epoch: 8.52 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.319263837996003		[learning rate: 0.0087764]
	Learning Rate: 0.00877639
	LOSS [training: 1.319263837996003 | validation: 1.3495699192836828]
	TIME [epoch: 8.52 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9579494372013952		[learning rate: 0.0087445]
	Learning Rate: 0.00874454
	LOSS [training: 0.9579494372013952 | validation: 0.8064797930134242]
	TIME [epoch: 8.55 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9148453797357096		[learning rate: 0.0087128]
	Learning Rate: 0.0087128
	LOSS [training: 0.9148453797357096 | validation: 1.2207832495448776]
	TIME [epoch: 8.53 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9161356248206767		[learning rate: 0.0086812]
	Learning Rate: 0.00868118
	LOSS [training: 0.9161356248206767 | validation: 1.2692741783617878]
	TIME [epoch: 8.53 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8328093202649466		[learning rate: 0.0086497]
	Learning Rate: 0.00864968
	LOSS [training: 0.8328093202649466 | validation: 1.1954750747770078]
	TIME [epoch: 8.52 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9408940632250768		[learning rate: 0.0086183]
	Learning Rate: 0.00861829
	LOSS [training: 0.9408940632250768 | validation: 1.2088484009176774]
	TIME [epoch: 8.54 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8021879661662338		[learning rate: 0.008587]
	Learning Rate: 0.00858701
	LOSS [training: 0.8021879661662338 | validation: 0.5741697432465033]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_142.pth
	Model improved!!!
EPOCH 143/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7907773733990053		[learning rate: 0.0085559]
	Learning Rate: 0.00855585
	LOSS [training: 0.7907773733990053 | validation: 0.6018777410874532]
	TIME [epoch: 8.52 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7976453032432199		[learning rate: 0.0085248]
	Learning Rate: 0.0085248
	LOSS [training: 0.7976453032432199 | validation: 0.7575945598538911]
	TIME [epoch: 8.52 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9969633376838806		[learning rate: 0.0084939]
	Learning Rate: 0.00849386
	LOSS [training: 0.9969633376838806 | validation: 0.5698949317386788]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_145.pth
	Model improved!!!
EPOCH 146/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8707323006808065		[learning rate: 0.008463]
	Learning Rate: 0.00846304
	LOSS [training: 0.8707323006808065 | validation: 0.8526293021614579]
	TIME [epoch: 8.54 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8355652262019712		[learning rate: 0.0084323]
	Learning Rate: 0.00843233
	LOSS [training: 0.8355652262019712 | validation: 0.7996413535108292]
	TIME [epoch: 8.52 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7347103450223037		[learning rate: 0.0084017]
	Learning Rate: 0.00840172
	LOSS [training: 0.7347103450223037 | validation: 0.9506184075752504]
	TIME [epoch: 8.52 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.992581253975046		[learning rate: 0.0083712]
	Learning Rate: 0.00837123
	LOSS [training: 0.992581253975046 | validation: 0.5989827267276859]
	TIME [epoch: 8.52 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8233172649622947		[learning rate: 0.0083409]
	Learning Rate: 0.00834085
	LOSS [training: 0.8233172649622947 | validation: 0.7029337150965307]
	TIME [epoch: 8.55 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7103386556571472		[learning rate: 0.0083106]
	Learning Rate: 0.00831059
	LOSS [training: 0.7103386556571472 | validation: 1.0627153134643337]
	TIME [epoch: 8.52 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.704399026317995		[learning rate: 0.0082804]
	Learning Rate: 0.00828043
	LOSS [training: 0.704399026317995 | validation: 1.1342626432390959]
	TIME [epoch: 8.52 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7505533305603496		[learning rate: 0.0082504]
	Learning Rate: 0.00825037
	LOSS [training: 0.7505533305603496 | validation: 0.5380505316074944]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_153.pth
	Model improved!!!
EPOCH 154/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7682149144078239		[learning rate: 0.0082204]
	Learning Rate: 0.00822043
	LOSS [training: 0.7682149144078239 | validation: 0.5390582812376263]
	TIME [epoch: 8.55 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7313811934208369		[learning rate: 0.0081906]
	Learning Rate: 0.0081906
	LOSS [training: 0.7313811934208369 | validation: 0.6261947815222315]
	TIME [epoch: 8.52 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7328900600994915		[learning rate: 0.0081609]
	Learning Rate: 0.00816088
	LOSS [training: 0.7328900600994915 | validation: 0.8252137934600188]
	TIME [epoch: 8.52 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.845734537597037		[learning rate: 0.0081313]
	Learning Rate: 0.00813126
	LOSS [training: 0.845734537597037 | validation: 1.033623878421487]
	TIME [epoch: 8.52 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0382689074112594		[learning rate: 0.0081018]
	Learning Rate: 0.00810175
	LOSS [training: 1.0382689074112594 | validation: 0.6224259939917798]
	TIME [epoch: 8.55 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7982202126406449		[learning rate: 0.0080724]
	Learning Rate: 0.00807235
	LOSS [training: 0.7982202126406449 | validation: 0.7545970931767069]
	TIME [epoch: 8.53 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7272005744874129		[learning rate: 0.0080431]
	Learning Rate: 0.00804305
	LOSS [training: 0.7272005744874129 | validation: 0.8683851755045642]
	TIME [epoch: 8.52 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7176642763053553		[learning rate: 0.0080139]
	Learning Rate: 0.00801387
	LOSS [training: 0.7176642763053553 | validation: 0.6176059163509988]
	TIME [epoch: 8.52 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6625966370901478		[learning rate: 0.0079848]
	Learning Rate: 0.00798478
	LOSS [training: 0.6625966370901478 | validation: 0.8302759196687699]
	TIME [epoch: 8.54 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8152975779346617		[learning rate: 0.0079558]
	Learning Rate: 0.00795581
	LOSS [training: 0.8152975779346617 | validation: 0.6551733708732004]
	TIME [epoch: 8.53 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.820258299930036		[learning rate: 0.0079269]
	Learning Rate: 0.00792693
	LOSS [training: 0.820258299930036 | validation: 1.2736916544817845]
	TIME [epoch: 8.53 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8566769075497085		[learning rate: 0.0078982]
	Learning Rate: 0.00789817
	LOSS [training: 0.8566769075497085 | validation: 0.4409720066332646]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_165.pth
	Model improved!!!
EPOCH 166/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.772024992904607		[learning rate: 0.0078695]
	Learning Rate: 0.0078695
	LOSS [training: 0.772024992904607 | validation: 1.6004733955565587]
	TIME [epoch: 8.52 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8145782247187338		[learning rate: 0.0078409]
	Learning Rate: 0.00784094
	LOSS [training: 0.8145782247187338 | validation: 0.8173824897364648]
	TIME [epoch: 8.55 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6076060327707845		[learning rate: 0.0078125]
	Learning Rate: 0.00781249
	LOSS [training: 0.6076060327707845 | validation: 0.5993985649175315]
	TIME [epoch: 8.53 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6470635277419529		[learning rate: 0.0077841]
	Learning Rate: 0.00778414
	LOSS [training: 0.6470635277419529 | validation: 0.6410948372541625]
	TIME [epoch: 8.52 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.919343812617643		[learning rate: 0.0077559]
	Learning Rate: 0.00775589
	LOSS [training: 0.919343812617643 | validation: 0.6061386662268285]
	TIME [epoch: 8.52 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6462785612013741		[learning rate: 0.0077277]
	Learning Rate: 0.00772774
	LOSS [training: 0.6462785612013741 | validation: 0.4849291813101865]
	TIME [epoch: 8.55 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6893461218583131		[learning rate: 0.0076997]
	Learning Rate: 0.0076997
	LOSS [training: 0.6893461218583131 | validation: 0.9133100138994931]
	TIME [epoch: 8.52 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6319632813002187		[learning rate: 0.0076718]
	Learning Rate: 0.00767176
	LOSS [training: 0.6319632813002187 | validation: 0.8719917148430567]
	TIME [epoch: 8.52 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.726334735701545		[learning rate: 0.0076439]
	Learning Rate: 0.00764391
	LOSS [training: 0.726334735701545 | validation: 0.6564891224334615]
	TIME [epoch: 8.51 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8169040453850938		[learning rate: 0.0076162]
	Learning Rate: 0.00761617
	LOSS [training: 0.8169040453850938 | validation: 0.9377192059379607]
	TIME [epoch: 8.54 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8846739821948993		[learning rate: 0.0075885]
	Learning Rate: 0.00758853
	LOSS [training: 0.8846739821948993 | validation: 0.49180964300410585]
	TIME [epoch: 8.51 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8648813416298677		[learning rate: 0.007561]
	Learning Rate: 0.00756099
	LOSS [training: 0.8648813416298677 | validation: 0.8758922365817458]
	TIME [epoch: 8.51 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.590040245519172		[learning rate: 0.0075336]
	Learning Rate: 0.00753356
	LOSS [training: 0.590040245519172 | validation: 0.6773448055203031]
	TIME [epoch: 8.52 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6128169081264538		[learning rate: 0.0075062]
	Learning Rate: 0.00750622
	LOSS [training: 0.6128169081264538 | validation: 0.4846346049437389]
	TIME [epoch: 8.53 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.612239079175673		[learning rate: 0.007479]
	Learning Rate: 0.00747897
	LOSS [training: 0.612239079175673 | validation: 0.5888061857694974]
	TIME [epoch: 8.52 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6788937701295528		[learning rate: 0.0074518]
	Learning Rate: 0.00745183
	LOSS [training: 0.6788937701295528 | validation: 0.7482546244099921]
	TIME [epoch: 8.51 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5576827084666597		[learning rate: 0.0074248]
	Learning Rate: 0.00742479
	LOSS [training: 0.5576827084666597 | validation: 0.5300272468276592]
	TIME [epoch: 8.52 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7070600219234102		[learning rate: 0.0073978]
	Learning Rate: 0.00739784
	LOSS [training: 0.7070600219234102 | validation: 1.105116609154623]
	TIME [epoch: 8.52 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7663614940187168		[learning rate: 0.007371]
	Learning Rate: 0.007371
	LOSS [training: 0.7663614940187168 | validation: 0.506327675057989]
	TIME [epoch: 8.53 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6014623445201911		[learning rate: 0.0073442]
	Learning Rate: 0.00734425
	LOSS [training: 0.6014623445201911 | validation: 1.2210403233402256]
	TIME [epoch: 8.51 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6060909306085767		[learning rate: 0.0073176]
	Learning Rate: 0.0073176
	LOSS [training: 0.6060909306085767 | validation: 0.5394010327945483]
	TIME [epoch: 8.51 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5437190758837156		[learning rate: 0.007291]
	Learning Rate: 0.00729104
	LOSS [training: 0.5437190758837156 | validation: 0.5737051945493976]
	TIME [epoch: 8.51 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6189371909522418		[learning rate: 0.0072646]
	Learning Rate: 0.00726458
	LOSS [training: 0.6189371909522418 | validation: 0.40976848714185365]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_188.pth
	Model improved!!!
EPOCH 189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.607753733989714		[learning rate: 0.0072382]
	Learning Rate: 0.00723822
	LOSS [training: 0.607753733989714 | validation: 1.7588219547027184]
	TIME [epoch: 8.51 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7623045081743757		[learning rate: 0.0072119]
	Learning Rate: 0.00721195
	LOSS [training: 0.7623045081743757 | validation: 0.8071245533017134]
	TIME [epoch: 8.51 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5296223266928385		[learning rate: 0.0071858]
	Learning Rate: 0.00718578
	LOSS [training: 0.5296223266928385 | validation: 0.608318686371301]
	TIME [epoch: 8.51 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.630143807141124		[learning rate: 0.0071597]
	Learning Rate: 0.0071597
	LOSS [training: 0.630143807141124 | validation: 0.7281044873862406]
	TIME [epoch: 8.53 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.541886521249536		[learning rate: 0.0071337]
	Learning Rate: 0.00713371
	LOSS [training: 0.541886521249536 | validation: 0.6115281668624505]
	TIME [epoch: 8.51 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8506993355015402		[learning rate: 0.0071078]
	Learning Rate: 0.00710783
	LOSS [training: 0.8506993355015402 | validation: 1.29327533358921]
	TIME [epoch: 8.5 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6396900143647473		[learning rate: 0.007082]
	Learning Rate: 0.00708203
	LOSS [training: 0.6396900143647473 | validation: 0.5453293310622476]
	TIME [epoch: 8.51 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.513057930916254		[learning rate: 0.0070563]
	Learning Rate: 0.00705633
	LOSS [training: 0.513057930916254 | validation: 0.40302804669307307]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_196.pth
	Model improved!!!
EPOCH 197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.699262978138018		[learning rate: 0.0070307]
	Learning Rate: 0.00703072
	LOSS [training: 0.699262978138018 | validation: 0.8476767385705336]
	TIME [epoch: 8.52 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7426670631984117		[learning rate: 0.0070052]
	Learning Rate: 0.00700521
	LOSS [training: 0.7426670631984117 | validation: 0.653444861412]
	TIME [epoch: 8.51 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5463214948565469		[learning rate: 0.0069798]
	Learning Rate: 0.00697979
	LOSS [training: 0.5463214948565469 | validation: 0.3909807832899871]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_199.pth
	Model improved!!!
EPOCH 200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44904218932327195		[learning rate: 0.0069545]
	Learning Rate: 0.00695446
	LOSS [training: 0.44904218932327195 | validation: 0.3955332498546035]
	TIME [epoch: 8.52 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4770983242560048		[learning rate: 0.0069292]
	Learning Rate: 0.00692922
	LOSS [training: 0.4770983242560048 | validation: 0.6388054025653337]
	TIME [epoch: 8.52 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6031484431715487		[learning rate: 0.0069041]
	Learning Rate: 0.00690407
	LOSS [training: 0.6031484431715487 | validation: 0.5572976688617277]
	TIME [epoch: 8.51 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5589432445846596		[learning rate: 0.006879]
	Learning Rate: 0.00687902
	LOSS [training: 0.5589432445846596 | validation: 0.5597691785848278]
	TIME [epoch: 8.51 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5419661371965612		[learning rate: 0.0068541]
	Learning Rate: 0.00685405
	LOSS [training: 0.5419661371965612 | validation: 0.9595162993519433]
	TIME [epoch: 8.51 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5511824445272949		[learning rate: 0.0068292]
	Learning Rate: 0.00682918
	LOSS [training: 0.5511824445272949 | validation: 0.5372177745892194]
	TIME [epoch: 8.53 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5242732780646834		[learning rate: 0.0068044]
	Learning Rate: 0.00680439
	LOSS [training: 0.5242732780646834 | validation: 0.541944086888239]
	TIME [epoch: 8.51 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5070027748743235		[learning rate: 0.0067797]
	Learning Rate: 0.0067797
	LOSS [training: 0.5070027748743235 | validation: 0.45937548731322697]
	TIME [epoch: 8.51 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46588014697959296		[learning rate: 0.0067551]
	Learning Rate: 0.0067551
	LOSS [training: 0.46588014697959296 | validation: 1.1350185654261837]
	TIME [epoch: 8.51 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5210000172990412		[learning rate: 0.0067306]
	Learning Rate: 0.00673058
	LOSS [training: 0.5210000172990412 | validation: 2.190377032335153]
	TIME [epoch: 8.53 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7799619444729518		[learning rate: 0.0067062]
	Learning Rate: 0.00670616
	LOSS [training: 0.7799619444729518 | validation: 0.3759068169571016]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_210.pth
	Model improved!!!
EPOCH 211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5029273863864424		[learning rate: 0.0066818]
	Learning Rate: 0.00668182
	LOSS [training: 0.5029273863864424 | validation: 0.4345575151988439]
	TIME [epoch: 8.52 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4782666105675103		[learning rate: 0.0066576]
	Learning Rate: 0.00665757
	LOSS [training: 0.4782666105675103 | validation: 0.4783729715125739]
	TIME [epoch: 8.51 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.003238279111869		[learning rate: 0.0066334]
	Learning Rate: 0.00663341
	LOSS [training: 1.003238279111869 | validation: 1.1924270459024953]
	TIME [epoch: 8.54 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5743981634452536		[learning rate: 0.0066093]
	Learning Rate: 0.00660934
	LOSS [training: 0.5743981634452536 | validation: 0.30316145622976765]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_214.pth
	Model improved!!!
EPOCH 215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5162381810369783		[learning rate: 0.0065854]
	Learning Rate: 0.00658535
	LOSS [training: 0.5162381810369783 | validation: 0.34334029692970425]
	TIME [epoch: 8.51 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5100607128135185		[learning rate: 0.0065615]
	Learning Rate: 0.00656145
	LOSS [training: 0.5100607128135185 | validation: 0.3238657466495778]
	TIME [epoch: 8.51 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4331990726476323		[learning rate: 0.0065376]
	Learning Rate: 0.00653764
	LOSS [training: 0.4331990726476323 | validation: 0.8574917595852691]
	TIME [epoch: 8.53 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5286751796926455		[learning rate: 0.0065139]
	Learning Rate: 0.00651392
	LOSS [training: 0.5286751796926455 | validation: 0.42133900000850794]
	TIME [epoch: 8.52 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4444990695630556		[learning rate: 0.0064903]
	Learning Rate: 0.00649028
	LOSS [training: 0.4444990695630556 | validation: 0.47472936831945917]
	TIME [epoch: 8.51 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4241283648537271		[learning rate: 0.0064667]
	Learning Rate: 0.00646672
	LOSS [training: 0.4241283648537271 | validation: 0.5023320172757044]
	TIME [epoch: 8.51 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5424752507276026		[learning rate: 0.0064433]
	Learning Rate: 0.00644325
	LOSS [training: 0.5424752507276026 | validation: 0.5188931922993696]
	TIME [epoch: 8.51 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.507376830830854		[learning rate: 0.0064199]
	Learning Rate: 0.00641987
	LOSS [training: 0.507376830830854 | validation: 0.6359841664285519]
	TIME [epoch: 8.53 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5563942677490153		[learning rate: 0.0063966]
	Learning Rate: 0.00639657
	LOSS [training: 0.5563942677490153 | validation: 0.4267181726597308]
	TIME [epoch: 8.52 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6208971251741978		[learning rate: 0.0063734]
	Learning Rate: 0.00637336
	LOSS [training: 0.6208971251741978 | validation: 0.42130287999440985]
	TIME [epoch: 8.51 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6205473395585763		[learning rate: 0.0063502]
	Learning Rate: 0.00635023
	LOSS [training: 0.6205473395585763 | validation: 0.3846833157782883]
	TIME [epoch: 8.51 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49412745182057594		[learning rate: 0.0063272]
	Learning Rate: 0.00632718
	LOSS [training: 0.49412745182057594 | validation: 0.399494852440259]
	TIME [epoch: 8.54 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6087022727154006		[learning rate: 0.0063042]
	Learning Rate: 0.00630422
	LOSS [training: 0.6087022727154006 | validation: 0.41108941029922275]
	TIME [epoch: 8.51 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46875571865761145		[learning rate: 0.0062813]
	Learning Rate: 0.00628134
	LOSS [training: 0.46875571865761145 | validation: 0.6566738637858354]
	TIME [epoch: 8.51 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4885486793060981		[learning rate: 0.0062585]
	Learning Rate: 0.00625855
	LOSS [training: 0.4885486793060981 | validation: 0.4115204296796068]
	TIME [epoch: 8.51 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41476361603821504		[learning rate: 0.0062358]
	Learning Rate: 0.00623584
	LOSS [training: 0.41476361603821504 | validation: 0.5365188411082662]
	TIME [epoch: 8.54 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.520009793844893		[learning rate: 0.0062132]
	Learning Rate: 0.00621321
	LOSS [training: 0.520009793844893 | validation: 0.8978749966707623]
	TIME [epoch: 8.52 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7240639830942794		[learning rate: 0.0061907]
	Learning Rate: 0.00619066
	LOSS [training: 0.7240639830942794 | validation: 0.6262459065761081]
	TIME [epoch: 8.52 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5213495165612322		[learning rate: 0.0061682]
	Learning Rate: 0.00616819
	LOSS [training: 0.5213495165612322 | validation: 0.47814515767951693]
	TIME [epoch: 8.5 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3835613558102463		[learning rate: 0.0061458]
	Learning Rate: 0.00614581
	LOSS [training: 0.3835613558102463 | validation: 0.5175895378756398]
	TIME [epoch: 8.52 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7822446905036784		[learning rate: 0.0061235]
	Learning Rate: 0.0061235
	LOSS [training: 0.7822446905036784 | validation: 1.4368823972194331]
	TIME [epoch: 8.52 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5410343349161543		[learning rate: 0.0061013]
	Learning Rate: 0.00610128
	LOSS [training: 0.5410343349161543 | validation: 1.0453351039045071]
	TIME [epoch: 8.5 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5694818356719564		[learning rate: 0.0060791]
	Learning Rate: 0.00607914
	LOSS [training: 0.5694818356719564 | validation: 0.6726759894549208]
	TIME [epoch: 8.5 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5314344237706845		[learning rate: 0.0060571]
	Learning Rate: 0.00605708
	LOSS [training: 0.5314344237706845 | validation: 0.5425810324002686]
	TIME [epoch: 8.52 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44914589902961655		[learning rate: 0.0060351]
	Learning Rate: 0.0060351
	LOSS [training: 0.44914589902961655 | validation: 0.4899410231330015]
	TIME [epoch: 8.53 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.414238611275313		[learning rate: 0.0060132]
	Learning Rate: 0.00601319
	LOSS [training: 0.414238611275313 | validation: 0.4167918473130524]
	TIME [epoch: 8.5 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4712622264664149		[learning rate: 0.0059914]
	Learning Rate: 0.00599137
	LOSS [training: 0.4712622264664149 | validation: 1.6680969434701194]
	TIME [epoch: 8.51 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6156952512899215		[learning rate: 0.0059696]
	Learning Rate: 0.00596963
	LOSS [training: 0.6156952512899215 | validation: 0.32193803449752356]
	TIME [epoch: 8.51 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3954160901817989		[learning rate: 0.005948]
	Learning Rate: 0.00594797
	LOSS [training: 0.3954160901817989 | validation: 0.5347047774089775]
	TIME [epoch: 8.53 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45515918796803917		[learning rate: 0.0059264]
	Learning Rate: 0.00592638
	LOSS [training: 0.45515918796803917 | validation: 0.34576625465545263]
	TIME [epoch: 8.5 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4109411697099469		[learning rate: 0.0059049]
	Learning Rate: 0.00590487
	LOSS [training: 0.4109411697099469 | validation: 0.6465325666773575]
	TIME [epoch: 8.5 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48175579828160836		[learning rate: 0.0058834]
	Learning Rate: 0.00588344
	LOSS [training: 0.48175579828160836 | validation: 0.5686942990569327]
	TIME [epoch: 8.5 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4228418966777718		[learning rate: 0.0058621]
	Learning Rate: 0.00586209
	LOSS [training: 0.4228418966777718 | validation: 0.45678143733818055]
	TIME [epoch: 8.53 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4334629498421809		[learning rate: 0.0058408]
	Learning Rate: 0.00584082
	LOSS [training: 0.4334629498421809 | validation: 0.36291503738625197]
	TIME [epoch: 8.5 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4503038929989283		[learning rate: 0.0058196]
	Learning Rate: 0.00581962
	LOSS [training: 0.4503038929989283 | validation: 0.5551918060838477]
	TIME [epoch: 8.5 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4073800466388242		[learning rate: 0.0057985]
	Learning Rate: 0.0057985
	LOSS [training: 0.4073800466388242 | validation: 0.6969893488411218]
	TIME [epoch: 8.51 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4755380313649523		[learning rate: 0.0057775]
	Learning Rate: 0.00577746
	LOSS [training: 0.4755380313649523 | validation: 0.6694090825612226]
	TIME [epoch: 8.52 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5472185233820707		[learning rate: 0.0057565]
	Learning Rate: 0.00575649
	LOSS [training: 0.5472185233820707 | validation: 0.5352986599013281]
	TIME [epoch: 8.52 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.397581472005889		[learning rate: 0.0057356]
	Learning Rate: 0.0057356
	LOSS [training: 0.397581472005889 | validation: 0.6102637608368444]
	TIME [epoch: 8.5 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5404567887134235		[learning rate: 0.0057148]
	Learning Rate: 0.00571479
	LOSS [training: 0.5404567887134235 | validation: 0.45263634467028724]
	TIME [epoch: 8.5 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4453075474307758		[learning rate: 0.005694]
	Learning Rate: 0.00569405
	LOSS [training: 0.4453075474307758 | validation: 0.3020644335095122]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_255.pth
	Model improved!!!
EPOCH 256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4905526247965043		[learning rate: 0.0056734]
	Learning Rate: 0.00567338
	LOSS [training: 0.4905526247965043 | validation: 0.3599225371368434]
	TIME [epoch: 8.54 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48668475530934135		[learning rate: 0.0056528]
	Learning Rate: 0.00565279
	LOSS [training: 0.48668475530934135 | validation: 0.3325729257793232]
	TIME [epoch: 8.51 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4233521192964661		[learning rate: 0.0056323]
	Learning Rate: 0.00563228
	LOSS [training: 0.4233521192964661 | validation: 0.3602657158014208]
	TIME [epoch: 8.51 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4346052714965505		[learning rate: 0.0056118]
	Learning Rate: 0.00561184
	LOSS [training: 0.4346052714965505 | validation: 0.4232572919910518]
	TIME [epoch: 8.51 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4423557400574639		[learning rate: 0.0055915]
	Learning Rate: 0.00559147
	LOSS [training: 0.4423557400574639 | validation: 0.7399004763318844]
	TIME [epoch: 8.54 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47138423638839805		[learning rate: 0.0055712]
	Learning Rate: 0.00557118
	LOSS [training: 0.47138423638839805 | validation: 0.4607237494417352]
	TIME [epoch: 8.51 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3832951141029577		[learning rate: 0.005551]
	Learning Rate: 0.00555096
	LOSS [training: 0.3832951141029577 | validation: 0.446203206429043]
	TIME [epoch: 8.51 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36469114008490955		[learning rate: 0.0055308]
	Learning Rate: 0.00553082
	LOSS [training: 0.36469114008490955 | validation: 0.35923291986934436]
	TIME [epoch: 8.51 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5071683089914601		[learning rate: 0.0055107]
	Learning Rate: 0.00551075
	LOSS [training: 0.5071683089914601 | validation: 0.43758344626766094]
	TIME [epoch: 8.54 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4320584185536392		[learning rate: 0.0054907]
	Learning Rate: 0.00549075
	LOSS [training: 0.4320584185536392 | validation: 0.40791431797158473]
	TIME [epoch: 8.51 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3821845378896073		[learning rate: 0.0054708]
	Learning Rate: 0.00547082
	LOSS [training: 0.3821845378896073 | validation: 0.28889823824175953]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_266.pth
	Model improved!!!
EPOCH 267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6075899488970364		[learning rate: 0.005451]
	Learning Rate: 0.00545097
	LOSS [training: 0.6075899488970364 | validation: 0.5845142536173227]
	TIME [epoch: 8.51 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3619045989661507		[learning rate: 0.0054312]
	Learning Rate: 0.00543119
	LOSS [training: 0.3619045989661507 | validation: 0.7239291136851853]
	TIME [epoch: 8.55 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4500731704527798		[learning rate: 0.0054115]
	Learning Rate: 0.00541148
	LOSS [training: 0.4500731704527798 | validation: 0.35951591548840794]
	TIME [epoch: 8.53 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38874362153408626		[learning rate: 0.0053918]
	Learning Rate: 0.00539184
	LOSS [training: 0.38874362153408626 | validation: 0.425053907977769]
	TIME [epoch: 8.53 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3894595504351893		[learning rate: 0.0053723]
	Learning Rate: 0.00537227
	LOSS [training: 0.3894595504351893 | validation: 0.29654959346629717]
	TIME [epoch: 8.52 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34260585713181546		[learning rate: 0.0053528]
	Learning Rate: 0.00535277
	LOSS [training: 0.34260585713181546 | validation: 0.38840033680465313]
	TIME [epoch: 8.54 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3923508769947938		[learning rate: 0.0053333]
	Learning Rate: 0.00533335
	LOSS [training: 0.3923508769947938 | validation: 0.2493683282298694]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_273.pth
	Model improved!!!
EPOCH 274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43757159070950846		[learning rate: 0.005314]
	Learning Rate: 0.00531399
	LOSS [training: 0.43757159070950846 | validation: 0.8058998797652535]
	TIME [epoch: 8.53 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4256278884867407		[learning rate: 0.0052947]
	Learning Rate: 0.00529471
	LOSS [training: 0.4256278884867407 | validation: 0.3179319673036244]
	TIME [epoch: 8.53 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43745528365485437		[learning rate: 0.0052755]
	Learning Rate: 0.00527549
	LOSS [training: 0.43745528365485437 | validation: 0.7672255269531902]
	TIME [epoch: 8.53 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5420358852486034		[learning rate: 0.0052563]
	Learning Rate: 0.00525635
	LOSS [training: 0.5420358852486034 | validation: 0.3583996486193357]
	TIME [epoch: 8.55 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.404456615178614		[learning rate: 0.0052373]
	Learning Rate: 0.00523727
	LOSS [training: 0.404456615178614 | validation: 0.2971769591767721]
	TIME [epoch: 8.53 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5550084807391266		[learning rate: 0.0052183]
	Learning Rate: 0.00521827
	LOSS [training: 0.5550084807391266 | validation: 0.5298356684697024]
	TIME [epoch: 8.52 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41325548467025197		[learning rate: 0.0051993]
	Learning Rate: 0.00519933
	LOSS [training: 0.41325548467025197 | validation: 0.41974261098802446]
	TIME [epoch: 8.53 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33776067212752336		[learning rate: 0.0051805]
	Learning Rate: 0.00518046
	LOSS [training: 0.33776067212752336 | validation: 0.40259027451634255]
	TIME [epoch: 8.55 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3572785352181841		[learning rate: 0.0051617]
	Learning Rate: 0.00516166
	LOSS [training: 0.3572785352181841 | validation: 1.0660839868986014]
	TIME [epoch: 8.53 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5410997955402157		[learning rate: 0.0051429]
	Learning Rate: 0.00514293
	LOSS [training: 0.5410997955402157 | validation: 0.30667704178044086]
	TIME [epoch: 8.53 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34028249318569526		[learning rate: 0.0051243]
	Learning Rate: 0.00512426
	LOSS [training: 0.34028249318569526 | validation: 0.46233416791081966]
	TIME [epoch: 8.53 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4733972347022224		[learning rate: 0.0051057]
	Learning Rate: 0.00510567
	LOSS [training: 0.4733972347022224 | validation: 0.2541789440636728]
	TIME [epoch: 8.55 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36380114587254964		[learning rate: 0.0050871]
	Learning Rate: 0.00508714
	LOSS [training: 0.36380114587254964 | validation: 0.5487952592457642]
	TIME [epoch: 8.53 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.364044030209935		[learning rate: 0.0050687]
	Learning Rate: 0.00506868
	LOSS [training: 0.364044030209935 | validation: 0.8462121632777042]
	TIME [epoch: 8.53 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4643578591089855		[learning rate: 0.0050503]
	Learning Rate: 0.00505028
	LOSS [training: 0.4643578591089855 | validation: 0.7492702580249491]
	TIME [epoch: 8.52 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3685577357613783		[learning rate: 0.005032]
	Learning Rate: 0.00503196
	LOSS [training: 0.3685577357613783 | validation: 0.385544779522066]
	TIME [epoch: 8.54 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3296151648225275		[learning rate: 0.0050137]
	Learning Rate: 0.00501369
	LOSS [training: 0.3296151648225275 | validation: 0.31738488518290225]
	TIME [epoch: 8.54 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36021301100658926		[learning rate: 0.0049955]
	Learning Rate: 0.0049955
	LOSS [training: 0.36021301100658926 | validation: 0.42429477967980955]
	TIME [epoch: 8.53 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38797307280265764		[learning rate: 0.0049774]
	Learning Rate: 0.00497737
	LOSS [training: 0.38797307280265764 | validation: 0.32506602214482777]
	TIME [epoch: 8.53 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36107953811526655		[learning rate: 0.0049593]
	Learning Rate: 0.00495931
	LOSS [training: 0.36107953811526655 | validation: 0.5946476071039701]
	TIME [epoch: 8.54 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5408995285592403		[learning rate: 0.0049413]
	Learning Rate: 0.00494131
	LOSS [training: 0.5408995285592403 | validation: 0.25151603323708954]
	TIME [epoch: 8.55 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3265615504096548		[learning rate: 0.0049234]
	Learning Rate: 0.00492338
	LOSS [training: 0.3265615504096548 | validation: 0.3334308202307739]
	TIME [epoch: 8.53 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33780274237441604		[learning rate: 0.0049055]
	Learning Rate: 0.00490551
	LOSS [training: 0.33780274237441604 | validation: 0.5786975358662215]
	TIME [epoch: 8.52 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36023301570538		[learning rate: 0.0048877]
	Learning Rate: 0.00488771
	LOSS [training: 0.36023301570538 | validation: 0.33767076018938424]
	TIME [epoch: 8.53 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4389098351993875		[learning rate: 0.00487]
	Learning Rate: 0.00486997
	LOSS [training: 0.4389098351993875 | validation: 0.4699193384499941]
	TIME [epoch: 8.55 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44794620872635454		[learning rate: 0.0048523]
	Learning Rate: 0.0048523
	LOSS [training: 0.44794620872635454 | validation: 0.4331449432992245]
	TIME [epoch: 8.53 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39382578936707013		[learning rate: 0.0048347]
	Learning Rate: 0.00483469
	LOSS [training: 0.39382578936707013 | validation: 0.5161200875833503]
	TIME [epoch: 8.53 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40689433381333745		[learning rate: 0.0048171]
	Learning Rate: 0.00481714
	LOSS [training: 0.40689433381333745 | validation: 0.2165721311942167]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_301.pth
	Model improved!!!
EPOCH 302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34741919823830764		[learning rate: 0.0047997]
	Learning Rate: 0.00479966
	LOSS [training: 0.34741919823830764 | validation: 0.2796800897606423]
	TIME [epoch: 8.55 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3931063201071577		[learning rate: 0.0047822]
	Learning Rate: 0.00478224
	LOSS [training: 0.3931063201071577 | validation: 0.25219280109885883]
	TIME [epoch: 8.53 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3492042143462331		[learning rate: 0.0047649]
	Learning Rate: 0.00476489
	LOSS [training: 0.3492042143462331 | validation: 0.34873099801157825]
	TIME [epoch: 8.53 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34811900592601525		[learning rate: 0.0047476]
	Learning Rate: 0.00474759
	LOSS [training: 0.34811900592601525 | validation: 0.3072535562575962]
	TIME [epoch: 8.53 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43004744484086566		[learning rate: 0.0047304]
	Learning Rate: 0.00473037
	LOSS [training: 0.43004744484086566 | validation: 0.23832252124167713]
	TIME [epoch: 8.55 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28523187646979464		[learning rate: 0.0047132]
	Learning Rate: 0.0047132
	LOSS [training: 0.28523187646979464 | validation: 0.44334145206695086]
	TIME [epoch: 8.53 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3853114588396421		[learning rate: 0.0046961]
	Learning Rate: 0.00469609
	LOSS [training: 0.3853114588396421 | validation: 0.2913034202880486]
	TIME [epoch: 8.53 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4701970076248574		[learning rate: 0.0046791]
	Learning Rate: 0.00467905
	LOSS [training: 0.4701970076248574 | validation: 0.6837311381035416]
	TIME [epoch: 8.52 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30347986885291517		[learning rate: 0.0046621]
	Learning Rate: 0.00466207
	LOSS [training: 0.30347986885291517 | validation: 0.6801868638109001]
	TIME [epoch: 8.54 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43572378468420636		[learning rate: 0.0046452]
	Learning Rate: 0.00464515
	LOSS [training: 0.43572378468420636 | validation: 0.3555756732035088]
	TIME [epoch: 8.53 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2546948755493094		[learning rate: 0.0046283]
	Learning Rate: 0.0046283
	LOSS [training: 0.2546948755493094 | validation: 0.41138810864137665]
	TIME [epoch: 8.52 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3331514064903612		[learning rate: 0.0046115]
	Learning Rate: 0.0046115
	LOSS [training: 0.3331514064903612 | validation: 0.25665967986930377]
	TIME [epoch: 8.52 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5021638736826806		[learning rate: 0.0045948]
	Learning Rate: 0.00459476
	LOSS [training: 0.5021638736826806 | validation: 0.4533878276710378]
	TIME [epoch: 8.53 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48637922460472555		[learning rate: 0.0045781]
	Learning Rate: 0.00457809
	LOSS [training: 0.48637922460472555 | validation: 0.3675823953497976]
	TIME [epoch: 8.55 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3616202851154883		[learning rate: 0.0045615]
	Learning Rate: 0.00456148
	LOSS [training: 0.3616202851154883 | validation: 0.2898109373436839]
	TIME [epoch: 8.52 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.308418343755703		[learning rate: 0.0045449]
	Learning Rate: 0.00454492
	LOSS [training: 0.308418343755703 | validation: 0.3379660087973734]
	TIME [epoch: 8.52 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28014662500490256		[learning rate: 0.0045284]
	Learning Rate: 0.00452843
	LOSS [training: 0.28014662500490256 | validation: 0.4263999596663233]
	TIME [epoch: 8.52 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3342945111589242		[learning rate: 0.004512]
	Learning Rate: 0.00451199
	LOSS [training: 0.3342945111589242 | validation: 0.4810394238191875]
	TIME [epoch: 8.54 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4922530407408755		[learning rate: 0.0044956]
	Learning Rate: 0.00449562
	LOSS [training: 0.4922530407408755 | validation: 0.7000828145321483]
	TIME [epoch: 8.52 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3521232621948175		[learning rate: 0.0044793]
	Learning Rate: 0.0044793
	LOSS [training: 0.3521232621948175 | validation: 0.29457529335711174]
	TIME [epoch: 8.52 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38833160832328995		[learning rate: 0.004463]
	Learning Rate: 0.00446305
	LOSS [training: 0.38833160832328995 | validation: 0.20710184898836292]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_322.pth
	Model improved!!!
EPOCH 323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34829173601216395		[learning rate: 0.0044469]
	Learning Rate: 0.00444685
	LOSS [training: 0.34829173601216395 | validation: 0.2717411505440712]
	TIME [epoch: 8.54 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3079641796757603		[learning rate: 0.0044307]
	Learning Rate: 0.00443071
	LOSS [training: 0.3079641796757603 | validation: 0.31421917314610925]
	TIME [epoch: 8.52 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32175864736182325		[learning rate: 0.0044146]
	Learning Rate: 0.00441463
	LOSS [training: 0.32175864736182325 | validation: 0.15229089343474603]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_325.pth
	Model improved!!!
EPOCH 326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28398095607202994		[learning rate: 0.0043986]
	Learning Rate: 0.00439861
	LOSS [training: 0.28398095607202994 | validation: 0.46871180726103134]
	TIME [epoch: 8.52 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2864107017983866		[learning rate: 0.0043827]
	Learning Rate: 0.00438265
	LOSS [training: 0.2864107017983866 | validation: 0.18373326444351706]
	TIME [epoch: 8.54 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2933444225365112		[learning rate: 0.0043667]
	Learning Rate: 0.00436675
	LOSS [training: 0.2933444225365112 | validation: 0.3652614392533626]
	TIME [epoch: 8.54 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3396831724311105		[learning rate: 0.0043509]
	Learning Rate: 0.0043509
	LOSS [training: 0.3396831724311105 | validation: 0.23923136431250935]
	TIME [epoch: 8.53 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32603394286224086		[learning rate: 0.0043351]
	Learning Rate: 0.00433511
	LOSS [training: 0.32603394286224086 | validation: 0.40690185195923717]
	TIME [epoch: 8.53 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36495891732594526		[learning rate: 0.0043194]
	Learning Rate: 0.00431938
	LOSS [training: 0.36495891732594526 | validation: 0.19090039233103734]
	TIME [epoch: 8.53 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34129533779929694		[learning rate: 0.0043037]
	Learning Rate: 0.0043037
	LOSS [training: 0.34129533779929694 | validation: 0.3660042487967012]
	TIME [epoch: 8.54 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29893991259540165		[learning rate: 0.0042881]
	Learning Rate: 0.00428808
	LOSS [training: 0.29893991259540165 | validation: 1.2950007506764487]
	TIME [epoch: 8.52 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5127253093320441		[learning rate: 0.0042725]
	Learning Rate: 0.00427252
	LOSS [training: 0.5127253093320441 | validation: 0.5956326759913371]
	TIME [epoch: 8.53 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29165043278358493		[learning rate: 0.004257]
	Learning Rate: 0.00425702
	LOSS [training: 0.29165043278358493 | validation: 0.4351951106509654]
	TIME [epoch: 8.52 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3584178125691522		[learning rate: 0.0042416]
	Learning Rate: 0.00424157
	LOSS [training: 0.3584178125691522 | validation: 0.21393382151688053]
	TIME [epoch: 8.55 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2862702996718541		[learning rate: 0.0042262]
	Learning Rate: 0.00422617
	LOSS [training: 0.2862702996718541 | validation: 0.2910483518651222]
	TIME [epoch: 8.52 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2843888748593834		[learning rate: 0.0042108]
	Learning Rate: 0.00421084
	LOSS [training: 0.2843888748593834 | validation: 0.271567515013426]
	TIME [epoch: 8.52 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42118132845289935		[learning rate: 0.0041956]
	Learning Rate: 0.00419556
	LOSS [training: 0.42118132845289935 | validation: 0.7522774986341129]
	TIME [epoch: 8.52 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36235785407466314		[learning rate: 0.0041803]
	Learning Rate: 0.00418033
	LOSS [training: 0.36235785407466314 | validation: 0.3091399057491627]
	TIME [epoch: 8.54 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31296328332096635		[learning rate: 0.0041652]
	Learning Rate: 0.00416516
	LOSS [training: 0.31296328332096635 | validation: 0.3688493018021902]
	TIME [epoch: 8.52 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28003466550577716		[learning rate: 0.00415]
	Learning Rate: 0.00415004
	LOSS [training: 0.28003466550577716 | validation: 0.29154160695713105]
	TIME [epoch: 8.51 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28582564907712643		[learning rate: 0.004135]
	Learning Rate: 0.00413498
	LOSS [training: 0.28582564907712643 | validation: 0.3920394255512839]
	TIME [epoch: 8.52 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26595986996198395		[learning rate: 0.00412]
	Learning Rate: 0.00411998
	LOSS [training: 0.26595986996198395 | validation: 0.3036782003807656]
	TIME [epoch: 8.53 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3189341107308501		[learning rate: 0.004105]
	Learning Rate: 0.00410502
	LOSS [training: 0.3189341107308501 | validation: 0.2510918642297803]
	TIME [epoch: 8.53 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3254073505039181		[learning rate: 0.0040901]
	Learning Rate: 0.00409013
	LOSS [training: 0.3254073505039181 | validation: 0.8133610016972934]
	TIME [epoch: 8.52 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3727816545516656		[learning rate: 0.0040753]
	Learning Rate: 0.00407528
	LOSS [training: 0.3727816545516656 | validation: 0.36047572425983665]
	TIME [epoch: 8.52 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2622894822904771		[learning rate: 0.0040605]
	Learning Rate: 0.00406049
	LOSS [training: 0.2622894822904771 | validation: 0.6511825482261409]
	TIME [epoch: 8.52 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3087714059904486		[learning rate: 0.0040458]
	Learning Rate: 0.00404576
	LOSS [training: 0.3087714059904486 | validation: 0.17395830271887247]
	TIME [epoch: 8.54 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37124499883823614		[learning rate: 0.0040311]
	Learning Rate: 0.00403108
	LOSS [training: 0.37124499883823614 | validation: 0.31119578293569683]
	TIME [epoch: 8.52 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2776851267466506		[learning rate: 0.0040164]
	Learning Rate: 0.00401645
	LOSS [training: 0.2776851267466506 | validation: 0.21779933063153126]
	TIME [epoch: 8.52 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3431873219848832		[learning rate: 0.0040019]
	Learning Rate: 0.00400187
	LOSS [training: 0.3431873219848832 | validation: 0.3631259918064519]
	TIME [epoch: 8.51 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4578018353832971		[learning rate: 0.0039873]
	Learning Rate: 0.00398735
	LOSS [training: 0.4578018353832971 | validation: 0.19538760548897938]
	TIME [epoch: 8.55 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2892714985779326		[learning rate: 0.0039729]
	Learning Rate: 0.00397288
	LOSS [training: 0.2892714985779326 | validation: 0.21106876755614246]
	TIME [epoch: 8.52 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.271550087174868		[learning rate: 0.0039585]
	Learning Rate: 0.00395846
	LOSS [training: 0.271550087174868 | validation: 0.284780739722166]
	TIME [epoch: 8.52 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2747275081216881		[learning rate: 0.0039441]
	Learning Rate: 0.00394409
	LOSS [training: 0.2747275081216881 | validation: 0.3184764799393888]
	TIME [epoch: 8.52 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26128916990572654		[learning rate: 0.0039298]
	Learning Rate: 0.00392978
	LOSS [training: 0.26128916990572654 | validation: 0.2657453619125756]
	TIME [epoch: 8.55 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26297026653210664		[learning rate: 0.0039155]
	Learning Rate: 0.00391552
	LOSS [training: 0.26297026653210664 | validation: 0.4339570333525124]
	TIME [epoch: 8.52 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3627805935792251		[learning rate: 0.0039013]
	Learning Rate: 0.00390131
	LOSS [training: 0.3627805935792251 | validation: 0.4272968490639671]
	TIME [epoch: 8.52 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2872983019357537		[learning rate: 0.0038872]
	Learning Rate: 0.00388715
	LOSS [training: 0.2872983019357537 | validation: 0.2993836029017948]
	TIME [epoch: 8.52 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35026656318793525		[learning rate: 0.003873]
	Learning Rate: 0.00387305
	LOSS [training: 0.35026656318793525 | validation: 0.2916553537182473]
	TIME [epoch: 8.54 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2608833593191836		[learning rate: 0.003859]
	Learning Rate: 0.00385899
	LOSS [training: 0.2608833593191836 | validation: 0.6477316323117389]
	TIME [epoch: 8.53 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30306843346285933		[learning rate: 0.003845]
	Learning Rate: 0.00384499
	LOSS [training: 0.30306843346285933 | validation: 0.3929979756356683]
	TIME [epoch: 8.51 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2850569099443166		[learning rate: 0.003831]
	Learning Rate: 0.00383103
	LOSS [training: 0.2850569099443166 | validation: 0.19036934710835585]
	TIME [epoch: 8.52 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2511707656086543		[learning rate: 0.0038171]
	Learning Rate: 0.00381713
	LOSS [training: 0.2511707656086543 | validation: 0.2639231174670638]
	TIME [epoch: 8.53 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3811013213144134		[learning rate: 0.0038033]
	Learning Rate: 0.00380328
	LOSS [training: 0.3811013213144134 | validation: 0.707514425366828]
	TIME [epoch: 8.54 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40747714676021607		[learning rate: 0.0037895]
	Learning Rate: 0.00378947
	LOSS [training: 0.40747714676021607 | validation: 0.3539017922780534]
	TIME [epoch: 8.52 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2820054607635275		[learning rate: 0.0037757]
	Learning Rate: 0.00377572
	LOSS [training: 0.2820054607635275 | validation: 0.317844178888395]
	TIME [epoch: 8.52 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32248562746938103		[learning rate: 0.003762]
	Learning Rate: 0.00376202
	LOSS [training: 0.32248562746938103 | validation: 0.29004578856641905]
	TIME [epoch: 8.52 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32112477983571097		[learning rate: 0.0037484]
	Learning Rate: 0.00374837
	LOSS [training: 0.32112477983571097 | validation: 0.3319847750103003]
	TIME [epoch: 8.55 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3077215026709267		[learning rate: 0.0037348]
	Learning Rate: 0.00373476
	LOSS [training: 0.3077215026709267 | validation: 0.31131210812720356]
	TIME [epoch: 8.52 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3630349849913812		[learning rate: 0.0037212]
	Learning Rate: 0.00372121
	LOSS [training: 0.3630349849913812 | validation: 0.3399412313109094]
	TIME [epoch: 8.51 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2642924693657932		[learning rate: 0.0037077]
	Learning Rate: 0.00370771
	LOSS [training: 0.2642924693657932 | validation: 0.27413956834422215]
	TIME [epoch: 8.52 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3270482550415207		[learning rate: 0.0036943]
	Learning Rate: 0.00369425
	LOSS [training: 0.3270482550415207 | validation: 0.48351015074574094]
	TIME [epoch: 8.54 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4024179803339534		[learning rate: 0.0036808]
	Learning Rate: 0.00368084
	LOSS [training: 0.4024179803339534 | validation: 0.38760995860864966]
	TIME [epoch: 8.52 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28432043590478573		[learning rate: 0.0036675]
	Learning Rate: 0.00366749
	LOSS [training: 0.28432043590478573 | validation: 0.22250963433255422]
	TIME [epoch: 8.52 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3911918159910501		[learning rate: 0.0036542]
	Learning Rate: 0.00365418
	LOSS [training: 0.3911918159910501 | validation: 0.2151969804101594]
	TIME [epoch: 8.52 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3256877705722028		[learning rate: 0.0036409]
	Learning Rate: 0.00364092
	LOSS [training: 0.3256877705722028 | validation: 0.49477482174122417]
	TIME [epoch: 8.54 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2849657660076536		[learning rate: 0.0036277]
	Learning Rate: 0.0036277
	LOSS [training: 0.2849657660076536 | validation: 0.32424364007508666]
	TIME [epoch: 8.52 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4003936763137664		[learning rate: 0.0036145]
	Learning Rate: 0.00361454
	LOSS [training: 0.4003936763137664 | validation: 0.2871998860196384]
	TIME [epoch: 8.52 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2605547823612623		[learning rate: 0.0036014]
	Learning Rate: 0.00360142
	LOSS [training: 0.2605547823612623 | validation: 0.44704121753823234]
	TIME [epoch: 8.52 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26063013767791465		[learning rate: 0.0035883]
	Learning Rate: 0.00358835
	LOSS [training: 0.26063013767791465 | validation: 0.3609939680357277]
	TIME [epoch: 8.53 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4955708401902562		[learning rate: 0.0035753]
	Learning Rate: 0.00357533
	LOSS [training: 0.4955708401902562 | validation: 0.6218831275684504]
	TIME [epoch: 8.54 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2399557917017034		[learning rate: 0.0035624]
	Learning Rate: 0.00356235
	LOSS [training: 0.2399557917017034 | validation: 0.26206397739087534]
	TIME [epoch: 8.52 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2587880306919		[learning rate: 0.0035494]
	Learning Rate: 0.00354942
	LOSS [training: 0.2587880306919 | validation: 0.24878430187302586]
	TIME [epoch: 8.52 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2976083180699335		[learning rate: 0.0035365]
	Learning Rate: 0.00353654
	LOSS [training: 0.2976083180699335 | validation: 0.33237511103577644]
	TIME [epoch: 8.52 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22819246031930523		[learning rate: 0.0035237]
	Learning Rate: 0.00352371
	LOSS [training: 0.22819246031930523 | validation: 0.2991692769211788]
	TIME [epoch: 8.54 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3350384200879501		[learning rate: 0.0035109]
	Learning Rate: 0.00351092
	LOSS [training: 0.3350384200879501 | validation: 0.27859792387272697]
	TIME [epoch: 8.51 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3355868130001394		[learning rate: 0.0034982]
	Learning Rate: 0.00349818
	LOSS [training: 0.3355868130001394 | validation: 0.2024100214876286]
	TIME [epoch: 8.52 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4029834738523041		[learning rate: 0.0034855]
	Learning Rate: 0.00348548
	LOSS [training: 0.4029834738523041 | validation: 0.18194039338316104]
	TIME [epoch: 8.51 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24848215198378626		[learning rate: 0.0034728]
	Learning Rate: 0.00347284
	LOSS [training: 0.24848215198378626 | validation: 0.5132056998551116]
	TIME [epoch: 8.54 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3010551572231301		[learning rate: 0.0034602]
	Learning Rate: 0.00346023
	LOSS [training: 0.3010551572231301 | validation: 0.1391942886433622]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_392.pth
	Model improved!!!
EPOCH 393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2513985890878311		[learning rate: 0.0034477]
	Learning Rate: 0.00344767
	LOSS [training: 0.2513985890878311 | validation: 0.23737089934432676]
	TIME [epoch: 8.52 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3102991509588187		[learning rate: 0.0034352]
	Learning Rate: 0.00343516
	LOSS [training: 0.3102991509588187 | validation: 0.30129750313920556]
	TIME [epoch: 8.51 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2725256163604417		[learning rate: 0.0034227]
	Learning Rate: 0.0034227
	LOSS [training: 0.2725256163604417 | validation: 0.19551828556024908]
	TIME [epoch: 8.53 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24150822414020795		[learning rate: 0.0034103]
	Learning Rate: 0.00341028
	LOSS [training: 0.24150822414020795 | validation: 0.32313564722211785]
	TIME [epoch: 8.52 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3579183822977797		[learning rate: 0.0033979]
	Learning Rate: 0.0033979
	LOSS [training: 0.3579183822977797 | validation: 0.436681478098195]
	TIME [epoch: 8.52 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32976370151488715		[learning rate: 0.0033856]
	Learning Rate: 0.00338557
	LOSS [training: 0.32976370151488715 | validation: 0.2552701208746386]
	TIME [epoch: 8.51 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2904770035779444		[learning rate: 0.0033733]
	Learning Rate: 0.00337328
	LOSS [training: 0.2904770035779444 | validation: 0.20639250744790166]
	TIME [epoch: 8.53 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29670769169830913		[learning rate: 0.003361]
	Learning Rate: 0.00336104
	LOSS [training: 0.29670769169830913 | validation: 0.3167297928958738]
	TIME [epoch: 8.53 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2768527333815307		[learning rate: 0.0033488]
	Learning Rate: 0.00334884
	LOSS [training: 0.2768527333815307 | validation: 0.2656398314334712]
	TIME [epoch: 8.51 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30425623442414684		[learning rate: 0.0033367]
	Learning Rate: 0.00333669
	LOSS [training: 0.30425623442414684 | validation: 0.5564101348088303]
	TIME [epoch: 8.51 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23995173711612988		[learning rate: 0.0033246]
	Learning Rate: 0.00332458
	LOSS [training: 0.23995173711612988 | validation: 0.16418430325735328]
	TIME [epoch: 8.51 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4191330321667091		[learning rate: 0.0033125]
	Learning Rate: 0.00331252
	LOSS [training: 0.4191330321667091 | validation: 0.18520276211725742]
	TIME [epoch: 8.54 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2658144436248272		[learning rate: 0.0033005]
	Learning Rate: 0.00330049
	LOSS [training: 0.2658144436248272 | validation: 0.18083312772015583]
	TIME [epoch: 8.51 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.292601459446413		[learning rate: 0.0032885]
	Learning Rate: 0.00328852
	LOSS [training: 0.292601459446413 | validation: 0.2712870700265304]
	TIME [epoch: 8.51 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22295840771253234		[learning rate: 0.0032766]
	Learning Rate: 0.00327658
	LOSS [training: 0.22295840771253234 | validation: 0.16874824125750665]
	TIME [epoch: 8.51 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23071520718653785		[learning rate: 0.0032647]
	Learning Rate: 0.00326469
	LOSS [training: 0.23071520718653785 | validation: 0.23472808462656275]
	TIME [epoch: 8.54 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2884350373800771		[learning rate: 0.0032528]
	Learning Rate: 0.00325284
	LOSS [training: 0.2884350373800771 | validation: 0.16473940849147584]
	TIME [epoch: 8.52 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26213089548109025		[learning rate: 0.003241]
	Learning Rate: 0.00324104
	LOSS [training: 0.26213089548109025 | validation: 0.44018492381029994]
	TIME [epoch: 8.52 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2684230858618412		[learning rate: 0.0032293]
	Learning Rate: 0.00322928
	LOSS [training: 0.2684230858618412 | validation: 0.33554800600220547]
	TIME [epoch: 8.51 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25616383086831906		[learning rate: 0.0032176]
	Learning Rate: 0.00321756
	LOSS [training: 0.25616383086831906 | validation: 0.27460088103619884]
	TIME [epoch: 8.53 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2530916879289715		[learning rate: 0.0032059]
	Learning Rate: 0.00320588
	LOSS [training: 0.2530916879289715 | validation: 0.5185173071657093]
	TIME [epoch: 8.51 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2910670982063808		[learning rate: 0.0031942]
	Learning Rate: 0.00319425
	LOSS [training: 0.2910670982063808 | validation: 0.37666292942554114]
	TIME [epoch: 8.51 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2841067760739649		[learning rate: 0.0031827]
	Learning Rate: 0.00318265
	LOSS [training: 0.2841067760739649 | validation: 0.24877743675241332]
	TIME [epoch: 8.51 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3208869321221026		[learning rate: 0.0031711]
	Learning Rate: 0.0031711
	LOSS [training: 0.3208869321221026 | validation: 0.3067583620067196]
	TIME [epoch: 8.53 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24966713866328555		[learning rate: 0.0031596]
	Learning Rate: 0.0031596
	LOSS [training: 0.24966713866328555 | validation: 0.2131953253663687]
	TIME [epoch: 8.53 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3009699213068247		[learning rate: 0.0031481]
	Learning Rate: 0.00314813
	LOSS [training: 0.3009699213068247 | validation: 0.3479474970217996]
	TIME [epoch: 8.52 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3028266571506497		[learning rate: 0.0031367]
	Learning Rate: 0.00313671
	LOSS [training: 0.3028266571506497 | validation: 0.19874104108471333]
	TIME [epoch: 8.51 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33006379514222445		[learning rate: 0.0031253]
	Learning Rate: 0.00312532
	LOSS [training: 0.33006379514222445 | validation: 0.168232483741944]
	TIME [epoch: 8.51 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2941238110375579		[learning rate: 0.003114]
	Learning Rate: 0.00311398
	LOSS [training: 0.2941238110375579 | validation: 0.21694385098109892]
	TIME [epoch: 8.54 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26675550296630907		[learning rate: 0.0031027]
	Learning Rate: 0.00310268
	LOSS [training: 0.26675550296630907 | validation: 0.17551067681696095]
	TIME [epoch: 8.51 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.250632723462123		[learning rate: 0.0030914]
	Learning Rate: 0.00309142
	LOSS [training: 0.250632723462123 | validation: 0.3585839157232915]
	TIME [epoch: 8.51 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1867561492256676		[learning rate: 0.0030802]
	Learning Rate: 0.0030802
	LOSS [training: 0.1867561492256676 | validation: 0.1782820488571326]
	TIME [epoch: 8.51 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28277693601536247		[learning rate: 0.003069]
	Learning Rate: 0.00306902
	LOSS [training: 0.28277693601536247 | validation: 0.19240218563040412]
	TIME [epoch: 8.54 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27326398101359983		[learning rate: 0.0030579]
	Learning Rate: 0.00305788
	LOSS [training: 0.27326398101359983 | validation: 0.22580705157635977]
	TIME [epoch: 8.51 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2778842247235739		[learning rate: 0.0030468]
	Learning Rate: 0.00304679
	LOSS [training: 0.2778842247235739 | validation: 0.3792349878169784]
	TIME [epoch: 8.52 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24482585991063927		[learning rate: 0.0030357]
	Learning Rate: 0.00303573
	LOSS [training: 0.24482585991063927 | validation: 0.4254064233642729]
	TIME [epoch: 8.51 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26145865077427877		[learning rate: 0.0030247]
	Learning Rate: 0.00302471
	LOSS [training: 0.26145865077427877 | validation: 0.27346070827547825]
	TIME [epoch: 8.54 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24074682106761675		[learning rate: 0.0030137]
	Learning Rate: 0.00301374
	LOSS [training: 0.24074682106761675 | validation: 0.5568969568314935]
	TIME [epoch: 8.52 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2777032146344064		[learning rate: 0.0030028]
	Learning Rate: 0.0030028
	LOSS [training: 0.2777032146344064 | validation: 0.22110435087040892]
	TIME [epoch: 8.52 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3138543189443105		[learning rate: 0.0029919]
	Learning Rate: 0.0029919
	LOSS [training: 0.3138543189443105 | validation: 0.1544186194184119]
	TIME [epoch: 8.51 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24779067431471233		[learning rate: 0.002981]
	Learning Rate: 0.00298104
	LOSS [training: 0.24779067431471233 | validation: 0.27869407172852134]
	TIME [epoch: 8.53 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23388710616327807		[learning rate: 0.0029702]
	Learning Rate: 0.00297023
	LOSS [training: 0.23388710616327807 | validation: 0.18851490694379308]
	TIME [epoch: 8.52 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2120061396769805		[learning rate: 0.0029594]
	Learning Rate: 0.00295945
	LOSS [training: 0.2120061396769805 | validation: 0.21991418763873344]
	TIME [epoch: 8.51 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2139259981379335		[learning rate: 0.0029487]
	Learning Rate: 0.00294871
	LOSS [training: 0.2139259981379335 | validation: 0.1575536828002275]
	TIME [epoch: 8.51 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3410626063999017		[learning rate: 0.002938]
	Learning Rate: 0.00293801
	LOSS [training: 0.3410626063999017 | validation: 0.20778296065222573]
	TIME [epoch: 8.52 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27776438805943066		[learning rate: 0.0029273]
	Learning Rate: 0.00292734
	LOSS [training: 0.27776438805943066 | validation: 0.11326321651672942]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_438.pth
	Model improved!!!
EPOCH 439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3175223054527717		[learning rate: 0.0029167]
	Learning Rate: 0.00291672
	LOSS [training: 0.3175223054527717 | validation: 0.22762757336793465]
	TIME [epoch: 8.52 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25574632288032306		[learning rate: 0.0029061]
	Learning Rate: 0.00290614
	LOSS [training: 0.25574632288032306 | validation: 0.3083835588294208]
	TIME [epoch: 8.51 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31055133166760024		[learning rate: 0.0028956]
	Learning Rate: 0.00289559
	LOSS [training: 0.31055133166760024 | validation: 0.16649435793081732]
	TIME [epoch: 8.51 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19986384159530707		[learning rate: 0.0028851]
	Learning Rate: 0.00288508
	LOSS [training: 0.19986384159530707 | validation: 0.19504227192224594]
	TIME [epoch: 8.53 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2141477925878467		[learning rate: 0.0028746]
	Learning Rate: 0.00287461
	LOSS [training: 0.2141477925878467 | validation: 0.19137043106404045]
	TIME [epoch: 8.51 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34842281768586886		[learning rate: 0.0028642]
	Learning Rate: 0.00286418
	LOSS [training: 0.34842281768586886 | validation: 0.22684853385624187]
	TIME [epoch: 8.51 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2280186431625983		[learning rate: 0.0028538]
	Learning Rate: 0.00285378
	LOSS [training: 0.2280186431625983 | validation: 0.40404422889137975]
	TIME [epoch: 8.5 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23416770579769075		[learning rate: 0.0028434]
	Learning Rate: 0.00284343
	LOSS [training: 0.23416770579769075 | validation: 0.2634466608429885]
	TIME [epoch: 8.53 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26941142946563057		[learning rate: 0.0028331]
	Learning Rate: 0.00283311
	LOSS [training: 0.26941142946563057 | validation: 0.26141846846129113]
	TIME [epoch: 8.51 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21437678498433382		[learning rate: 0.0028228]
	Learning Rate: 0.00282283
	LOSS [training: 0.21437678498433382 | validation: 0.26975114000148537]
	TIME [epoch: 8.51 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22070959783554173		[learning rate: 0.0028126]
	Learning Rate: 0.00281258
	LOSS [training: 0.22070959783554173 | validation: 0.5284994917260236]
	TIME [epoch: 8.51 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2798144806894033		[learning rate: 0.0028024]
	Learning Rate: 0.00280238
	LOSS [training: 0.2798144806894033 | validation: 0.1921583732374455]
	TIME [epoch: 8.53 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2018900427051868		[learning rate: 0.0027922]
	Learning Rate: 0.00279221
	LOSS [training: 0.2018900427051868 | validation: 0.27934196952904994]
	TIME [epoch: 8.53 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21809602561851044		[learning rate: 0.0027821]
	Learning Rate: 0.00278207
	LOSS [training: 0.21809602561851044 | validation: 0.3038530041836224]
	TIME [epoch: 8.51 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23423957933866774		[learning rate: 0.002772]
	Learning Rate: 0.00277198
	LOSS [training: 0.23423957933866774 | validation: 0.1803003510449807]
	TIME [epoch: 8.52 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23857964907684798		[learning rate: 0.0027619]
	Learning Rate: 0.00276192
	LOSS [training: 0.23857964907684798 | validation: 0.15479203569538236]
	TIME [epoch: 8.52 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20852837665909996		[learning rate: 0.0027519]
	Learning Rate: 0.00275189
	LOSS [training: 0.20852837665909996 | validation: 0.10637395427578689]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_455.pth
	Model improved!!!
EPOCH 456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1979682914014617		[learning rate: 0.0027419]
	Learning Rate: 0.00274191
	LOSS [training: 0.1979682914014617 | validation: 0.1887387366739002]
	TIME [epoch: 8.52 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22946426142520818		[learning rate: 0.002732]
	Learning Rate: 0.00273196
	LOSS [training: 0.22946426142520818 | validation: 0.26902650893237323]
	TIME [epoch: 8.51 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26515752546627647		[learning rate: 0.002722]
	Learning Rate: 0.00272204
	LOSS [training: 0.26515752546627647 | validation: 0.634174637386102]
	TIME [epoch: 8.51 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2661818839659433		[learning rate: 0.0027122]
	Learning Rate: 0.00271216
	LOSS [training: 0.2661818839659433 | validation: 0.21536876769324248]
	TIME [epoch: 8.53 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48942261827350003		[learning rate: 0.0027023]
	Learning Rate: 0.00270232
	LOSS [training: 0.48942261827350003 | validation: 0.13306809063478844]
	TIME [epoch: 8.51 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16615512271218175		[learning rate: 0.0026925]
	Learning Rate: 0.00269251
	LOSS [training: 0.16615512271218175 | validation: 0.12671867526879138]
	TIME [epoch: 8.51 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2116947672322219		[learning rate: 0.0026827]
	Learning Rate: 0.00268274
	LOSS [training: 0.2116947672322219 | validation: 0.13236762382666434]
	TIME [epoch: 8.51 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20889646242168686		[learning rate: 0.002673]
	Learning Rate: 0.00267301
	LOSS [training: 0.20889646242168686 | validation: 0.15154815373734537]
	TIME [epoch: 8.53 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18832166646610016		[learning rate: 0.0026633]
	Learning Rate: 0.00266331
	LOSS [training: 0.18832166646610016 | validation: 0.1927266440728964]
	TIME [epoch: 8.51 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2203832680722353		[learning rate: 0.0026536]
	Learning Rate: 0.00265364
	LOSS [training: 0.2203832680722353 | validation: 0.13893483702967824]
	TIME [epoch: 8.51 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.192449291248277		[learning rate: 0.002644]
	Learning Rate: 0.00264401
	LOSS [training: 0.192449291248277 | validation: 0.2555104862415539]
	TIME [epoch: 8.51 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20186934978400534		[learning rate: 0.0026344]
	Learning Rate: 0.00263441
	LOSS [training: 0.20186934978400534 | validation: 0.16871423806273989]
	TIME [epoch: 8.53 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3100967246434333		[learning rate: 0.0026249]
	Learning Rate: 0.00262485
	LOSS [training: 0.3100967246434333 | validation: 0.15064776918205305]
	TIME [epoch: 8.51 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19755917797626465		[learning rate: 0.0026153]
	Learning Rate: 0.00261533
	LOSS [training: 0.19755917797626465 | validation: 0.11310472532179822]
	TIME [epoch: 8.51 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18788928849481631		[learning rate: 0.0026058]
	Learning Rate: 0.00260584
	LOSS [training: 0.18788928849481631 | validation: 0.32436925887632884]
	TIME [epoch: 8.51 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24946232038575378		[learning rate: 0.0025964]
	Learning Rate: 0.00259638
	LOSS [training: 0.24946232038575378 | validation: 0.3664516530802092]
	TIME [epoch: 8.53 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24203911234388875		[learning rate: 0.002587]
	Learning Rate: 0.00258696
	LOSS [training: 0.24203911234388875 | validation: 0.15092394718047467]
	TIME [epoch: 8.53 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2441827676705559		[learning rate: 0.0025776]
	Learning Rate: 0.00257757
	LOSS [training: 0.2441827676705559 | validation: 0.1282921974347765]
	TIME [epoch: 8.52 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1806559623947465		[learning rate: 0.0025682]
	Learning Rate: 0.00256822
	LOSS [training: 0.1806559623947465 | validation: 0.17645877815303285]
	TIME [epoch: 8.51 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22431312564684142		[learning rate: 0.0025589]
	Learning Rate: 0.0025589
	LOSS [training: 0.22431312564684142 | validation: 0.2302476835347288]
	TIME [epoch: 8.5 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2576441112025548		[learning rate: 0.0025496]
	Learning Rate: 0.00254961
	LOSS [training: 0.2576441112025548 | validation: 0.237330320883739]
	TIME [epoch: 8.54 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23620086722268172		[learning rate: 0.0025404]
	Learning Rate: 0.00254036
	LOSS [training: 0.23620086722268172 | validation: 0.20081365182494382]
	TIME [epoch: 8.51 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2148833524163835		[learning rate: 0.0025311]
	Learning Rate: 0.00253114
	LOSS [training: 0.2148833524163835 | validation: 0.11596172446468178]
	TIME [epoch: 8.51 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1788813151662396		[learning rate: 0.002522]
	Learning Rate: 0.00252195
	LOSS [training: 0.1788813151662396 | validation: 0.18778766244529077]
	TIME [epoch: 8.5 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2078795988286568		[learning rate: 0.0025128]
	Learning Rate: 0.0025128
	LOSS [training: 0.2078795988286568 | validation: 0.2647238451837624]
	TIME [epoch: 8.54 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20424715847992675		[learning rate: 0.0025037]
	Learning Rate: 0.00250368
	LOSS [training: 0.20424715847992675 | validation: 0.16317181905710193]
	TIME [epoch: 8.51 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24301387218976847		[learning rate: 0.0024946]
	Learning Rate: 0.00249459
	LOSS [training: 0.24301387218976847 | validation: 0.1403564073561281]
	TIME [epoch: 8.51 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19984123905941703		[learning rate: 0.0024855]
	Learning Rate: 0.00248554
	LOSS [training: 0.19984123905941703 | validation: 0.25729890119783766]
	TIME [epoch: 8.51 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20364094361260304		[learning rate: 0.0024765]
	Learning Rate: 0.00247652
	LOSS [training: 0.20364094361260304 | validation: 0.1874390468274051]
	TIME [epoch: 8.52 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.217124290134115		[learning rate: 0.0024675]
	Learning Rate: 0.00246753
	LOSS [training: 0.217124290134115 | validation: 0.43108342906386343]
	TIME [epoch: 8.51 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22457121820206255		[learning rate: 0.0024586]
	Learning Rate: 0.00245858
	LOSS [training: 0.22457121820206255 | validation: 0.10420364117646105]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_486.pth
	Model improved!!!
EPOCH 487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3074775637163622		[learning rate: 0.0024497]
	Learning Rate: 0.00244966
	LOSS [training: 0.3074775637163622 | validation: 0.252885892067157]
	TIME [epoch: 8.51 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22888110738616546		[learning rate: 0.0024408]
	Learning Rate: 0.00244077
	LOSS [training: 0.22888110738616546 | validation: 0.13342919020363495]
	TIME [epoch: 8.53 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18949428124348897		[learning rate: 0.0024319]
	Learning Rate: 0.00243191
	LOSS [training: 0.18949428124348897 | validation: 0.19708194868880005]
	TIME [epoch: 8.53 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22875011722231556		[learning rate: 0.0024231]
	Learning Rate: 0.00242308
	LOSS [training: 0.22875011722231556 | validation: 0.17573718320046713]
	TIME [epoch: 8.51 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2036529770198252		[learning rate: 0.0024143]
	Learning Rate: 0.00241429
	LOSS [training: 0.2036529770198252 | validation: 0.2537077194024121]
	TIME [epoch: 8.51 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2584491425518704		[learning rate: 0.0024055]
	Learning Rate: 0.00240553
	LOSS [training: 0.2584491425518704 | validation: 0.24066505599660343]
	TIME [epoch: 8.51 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21424056110113154		[learning rate: 0.0023968]
	Learning Rate: 0.0023968
	LOSS [training: 0.21424056110113154 | validation: 0.6263748233245054]
	TIME [epoch: 8.53 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22836942603160973		[learning rate: 0.0023881]
	Learning Rate: 0.0023881
	LOSS [training: 0.22836942603160973 | validation: 0.13387106771997243]
	TIME [epoch: 8.52 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.202754722348911		[learning rate: 0.0023794]
	Learning Rate: 0.00237943
	LOSS [training: 0.202754722348911 | validation: 0.13327681961123566]
	TIME [epoch: 8.51 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24447223878981794		[learning rate: 0.0023708]
	Learning Rate: 0.0023708
	LOSS [training: 0.24447223878981794 | validation: 0.15240952866976454]
	TIME [epoch: 8.51 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20534841624547834		[learning rate: 0.0023622]
	Learning Rate: 0.0023622
	LOSS [training: 0.20534841624547834 | validation: 0.8343338416163366]
	TIME [epoch: 8.52 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30401558408959434		[learning rate: 0.0023536]
	Learning Rate: 0.00235362
	LOSS [training: 0.30401558408959434 | validation: 0.14920962459254905]
	TIME [epoch: 8.51 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19054457235078806		[learning rate: 0.0023451]
	Learning Rate: 0.00234508
	LOSS [training: 0.19054457235078806 | validation: 0.28294262785991364]
	TIME [epoch: 8.51 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16082653693833404		[learning rate: 0.0023366]
	Learning Rate: 0.00233657
	LOSS [training: 0.16082653693833404 | validation: 0.39678799573210527]
	TIME [epoch: 8.5 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20837565936764474		[learning rate: 0.0023281]
	Learning Rate: 0.00232809
	LOSS [training: 0.20837565936764474 | validation: 0.1962917540426002]
	TIME [epoch: 8.54 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23712599528706227		[learning rate: 0.0023196]
	Learning Rate: 0.00231964
	LOSS [training: 0.23712599528706227 | validation: 0.16062982678191254]
	TIME [epoch: 8.52 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1978131671865162		[learning rate: 0.0023112]
	Learning Rate: 0.00231122
	LOSS [training: 0.1978131671865162 | validation: 0.12736767789795828]
	TIME [epoch: 8.51 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.161831842644809		[learning rate: 0.0023028]
	Learning Rate: 0.00230284
	LOSS [training: 0.161831842644809 | validation: 0.21569421724512572]
	TIME [epoch: 8.51 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18348697301671907		[learning rate: 0.0022945]
	Learning Rate: 0.00229448
	LOSS [training: 0.18348697301671907 | validation: 0.3836507545588023]
	TIME [epoch: 8.53 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1787324812601246		[learning rate: 0.0022862]
	Learning Rate: 0.00228615
	LOSS [training: 0.1787324812601246 | validation: 0.31694580179132326]
	TIME [epoch: 8.52 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22410814712696295		[learning rate: 0.0022779]
	Learning Rate: 0.00227786
	LOSS [training: 0.22410814712696295 | validation: 0.18962438962040656]
	TIME [epoch: 8.51 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2158094427201928		[learning rate: 0.0022696]
	Learning Rate: 0.00226959
	LOSS [training: 0.2158094427201928 | validation: 0.17328664934939797]
	TIME [epoch: 8.51 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16270409870095753		[learning rate: 0.0022614]
	Learning Rate: 0.00226135
	LOSS [training: 0.16270409870095753 | validation: 0.1590725006893285]
	TIME [epoch: 8.52 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22401074819513625		[learning rate: 0.0022531]
	Learning Rate: 0.00225315
	LOSS [training: 0.22401074819513625 | validation: 0.24539533381663692]
	TIME [epoch: 8.54 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16962586398577906		[learning rate: 0.002245]
	Learning Rate: 0.00224497
	LOSS [training: 0.16962586398577906 | validation: 0.17942735142355953]
	TIME [epoch: 8.51 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17249511345081353		[learning rate: 0.0022368]
	Learning Rate: 0.00223682
	LOSS [training: 0.17249511345081353 | validation: 0.31060024583439066]
	TIME [epoch: 8.51 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19139182629032991		[learning rate: 0.0022287]
	Learning Rate: 0.00222871
	LOSS [training: 0.19139182629032991 | validation: 0.2345685728858996]
	TIME [epoch: 8.51 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18460484011966025		[learning rate: 0.0022206]
	Learning Rate: 0.00222062
	LOSS [training: 0.18460484011966025 | validation: 0.17429494573720178]
	TIME [epoch: 8.54 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1831817711116542		[learning rate: 0.0022126]
	Learning Rate: 0.00221256
	LOSS [training: 0.1831817711116542 | validation: 0.16846418959328244]
	TIME [epoch: 8.52 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20454411335016634		[learning rate: 0.0022045]
	Learning Rate: 0.00220453
	LOSS [training: 0.20454411335016634 | validation: 0.22662747571558312]
	TIME [epoch: 8.52 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2304587104226746		[learning rate: 0.0021965]
	Learning Rate: 0.00219653
	LOSS [training: 0.2304587104226746 | validation: 0.24567352433077444]
	TIME [epoch: 8.51 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18174411337980004		[learning rate: 0.0021886]
	Learning Rate: 0.00218856
	LOSS [training: 0.18174411337980004 | validation: 0.1846180978173827]
	TIME [epoch: 8.54 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16892169468339327		[learning rate: 0.0021806]
	Learning Rate: 0.00218061
	LOSS [training: 0.16892169468339327 | validation: 0.1675666156706713]
	TIME [epoch: 8.51 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1946322059162665		[learning rate: 0.0021727]
	Learning Rate: 0.0021727
	LOSS [training: 0.1946322059162665 | validation: 0.13912287435927506]
	TIME [epoch: 8.51 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17770427616227785		[learning rate: 0.0021648]
	Learning Rate: 0.00216482
	LOSS [training: 0.17770427616227785 | validation: 0.38582320472004183]
	TIME [epoch: 8.51 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29495069885961495		[learning rate: 0.002157]
	Learning Rate: 0.00215696
	LOSS [training: 0.29495069885961495 | validation: 0.3552676789489106]
	TIME [epoch: 8.53 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19912368906386327		[learning rate: 0.0021491]
	Learning Rate: 0.00214913
	LOSS [training: 0.19912368906386327 | validation: 0.1767883070414512]
	TIME [epoch: 8.52 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2032464177074637		[learning rate: 0.0021413]
	Learning Rate: 0.00214133
	LOSS [training: 0.2032464177074637 | validation: 0.22697462052613027]
	TIME [epoch: 8.51 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17039508830697717		[learning rate: 0.0021336]
	Learning Rate: 0.00213356
	LOSS [training: 0.17039508830697717 | validation: 0.21792908843961]
	TIME [epoch: 8.5 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2040041364783803		[learning rate: 0.0021258]
	Learning Rate: 0.00212582
	LOSS [training: 0.2040041364783803 | validation: 0.14807755759893604]
	TIME [epoch: 8.5 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1906070730637889		[learning rate: 0.0021181]
	Learning Rate: 0.0021181
	LOSS [training: 0.1906070730637889 | validation: 0.15289562600042317]
	TIME [epoch: 8.53 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15939383860213102		[learning rate: 0.0021104]
	Learning Rate: 0.00211042
	LOSS [training: 0.15939383860213102 | validation: 0.20502366827920526]
	TIME [epoch: 8.5 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1776030192414994		[learning rate: 0.0021028]
	Learning Rate: 0.00210276
	LOSS [training: 0.1776030192414994 | validation: 0.11335809811125741]
	TIME [epoch: 8.5 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1871877119425328		[learning rate: 0.0020951]
	Learning Rate: 0.00209513
	LOSS [training: 0.1871877119425328 | validation: 0.17605231921580713]
	TIME [epoch: 8.5 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14899255319033947		[learning rate: 0.0020875]
	Learning Rate: 0.00208752
	LOSS [training: 0.14899255319033947 | validation: 0.18621878127547248]
	TIME [epoch: 8.54 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20793534788130086		[learning rate: 0.0020799]
	Learning Rate: 0.00207995
	LOSS [training: 0.20793534788130086 | validation: 0.2816241039824958]
	TIME [epoch: 8.5 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17915523927683397		[learning rate: 0.0020724]
	Learning Rate: 0.0020724
	LOSS [training: 0.17915523927683397 | validation: 0.20336213605413855]
	TIME [epoch: 8.51 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1980822302647643		[learning rate: 0.0020649]
	Learning Rate: 0.00206488
	LOSS [training: 0.1980822302647643 | validation: 0.4650154930721977]
	TIME [epoch: 8.51 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22733935104784594		[learning rate: 0.0020574]
	Learning Rate: 0.00205739
	LOSS [training: 0.22733935104784594 | validation: 0.2560813263472169]
	TIME [epoch: 8.53 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18351111675202897		[learning rate: 0.0020499]
	Learning Rate: 0.00204992
	LOSS [training: 0.18351111675202897 | validation: 0.19977369492200964]
	TIME [epoch: 8.52 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23380176706591121		[learning rate: 0.0020425]
	Learning Rate: 0.00204248
	LOSS [training: 0.23380176706591121 | validation: 0.24650842626456804]
	TIME [epoch: 8.51 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21409221481228746		[learning rate: 0.0020351]
	Learning Rate: 0.00203507
	LOSS [training: 0.21409221481228746 | validation: 0.13323328035246906]
	TIME [epoch: 8.5 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20993096146630857		[learning rate: 0.0020277]
	Learning Rate: 0.00202768
	LOSS [training: 0.20993096146630857 | validation: 0.1803565679184802]
	TIME [epoch: 8.52 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1588032487349536		[learning rate: 0.0020203]
	Learning Rate: 0.00202032
	LOSS [training: 0.1588032487349536 | validation: 0.15779083196158922]
	TIME [epoch: 8.52 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15357862103312395		[learning rate: 0.002013]
	Learning Rate: 0.00201299
	LOSS [training: 0.15357862103312395 | validation: 0.20640137899516375]
	TIME [epoch: 8.5 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16960427311051401		[learning rate: 0.0020057]
	Learning Rate: 0.00200569
	LOSS [training: 0.16960427311051401 | validation: 0.11408611176231347]
	TIME [epoch: 8.5 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.142640659635548		[learning rate: 0.0019984]
	Learning Rate: 0.00199841
	LOSS [training: 0.142640659635548 | validation: 0.09778743185984197]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_543.pth
	Model improved!!!
EPOCH 544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15439655180693873		[learning rate: 0.0019912]
	Learning Rate: 0.00199116
	LOSS [training: 0.15439655180693873 | validation: 0.2691812863204578]
	TIME [epoch: 8.54 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19887678916217594		[learning rate: 0.0019839]
	Learning Rate: 0.00198393
	LOSS [training: 0.19887678916217594 | validation: 0.34856975654661393]
	TIME [epoch: 8.51 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2694197056395434		[learning rate: 0.0019767]
	Learning Rate: 0.00197673
	LOSS [training: 0.2694197056395434 | validation: 0.1459498426207257]
	TIME [epoch: 8.52 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14981616503575898		[learning rate: 0.0019696]
	Learning Rate: 0.00196956
	LOSS [training: 0.14981616503575898 | validation: 0.23926837428674028]
	TIME [epoch: 8.51 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23667842665495056		[learning rate: 0.0019624]
	Learning Rate: 0.00196241
	LOSS [training: 0.23667842665495056 | validation: 0.37018350682853085]
	TIME [epoch: 8.54 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1967614399461979		[learning rate: 0.0019553]
	Learning Rate: 0.00195529
	LOSS [training: 0.1967614399461979 | validation: 0.18120545914624336]
	TIME [epoch: 8.5 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1417498701443959		[learning rate: 0.0019482]
	Learning Rate: 0.00194819
	LOSS [training: 0.1417498701443959 | validation: 0.18922475832733165]
	TIME [epoch: 8.51 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2084744244896449		[learning rate: 0.0019411]
	Learning Rate: 0.00194112
	LOSS [training: 0.2084744244896449 | validation: 0.1731443613201136]
	TIME [epoch: 8.51 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15640808901184108		[learning rate: 0.0019341]
	Learning Rate: 0.00193408
	LOSS [training: 0.15640808901184108 | validation: 0.14510440516823742]
	TIME [epoch: 8.53 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1624155628679769		[learning rate: 0.0019271]
	Learning Rate: 0.00192706
	LOSS [training: 0.1624155628679769 | validation: 0.16644378691217665]
	TIME [epoch: 8.51 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.195772567890275		[learning rate: 0.0019201]
	Learning Rate: 0.00192006
	LOSS [training: 0.195772567890275 | validation: 0.0870437258911439]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_554.pth
	Model improved!!!
EPOCH 555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17077969829114711		[learning rate: 0.0019131]
	Learning Rate: 0.0019131
	LOSS [training: 0.17077969829114711 | validation: 0.11903604582557029]
	TIME [epoch: 8.5 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16822058650630697		[learning rate: 0.0019062]
	Learning Rate: 0.00190615
	LOSS [training: 0.16822058650630697 | validation: 0.15386704068422483]
	TIME [epoch: 8.52 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16458851358674703		[learning rate: 0.0018992]
	Learning Rate: 0.00189924
	LOSS [training: 0.16458851358674703 | validation: 0.18263347442970856]
	TIME [epoch: 8.51 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16683613688492946		[learning rate: 0.0018923]
	Learning Rate: 0.00189234
	LOSS [training: 0.16683613688492946 | validation: 0.17698525821105335]
	TIME [epoch: 8.5 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17447768984480563		[learning rate: 0.0018855]
	Learning Rate: 0.00188548
	LOSS [training: 0.17447768984480563 | validation: 0.2549086995469545]
	TIME [epoch: 8.5 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1561627864497338		[learning rate: 0.0018786]
	Learning Rate: 0.00187863
	LOSS [training: 0.1561627864497338 | validation: 0.14774630946536627]
	TIME [epoch: 8.52 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23824634087153881		[learning rate: 0.0018718]
	Learning Rate: 0.00187182
	LOSS [training: 0.23824634087153881 | validation: 0.25527754466451485]
	TIME [epoch: 8.52 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20385016108521942		[learning rate: 0.001865]
	Learning Rate: 0.00186502
	LOSS [training: 0.20385016108521942 | validation: 0.12173205109805921]
	TIME [epoch: 8.51 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12912323059838254		[learning rate: 0.0018583]
	Learning Rate: 0.00185825
	LOSS [training: 0.12912323059838254 | validation: 0.1318428849005914]
	TIME [epoch: 8.51 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17388936026353075		[learning rate: 0.0018515]
	Learning Rate: 0.00185151
	LOSS [training: 0.17388936026353075 | validation: 0.20669927144658698]
	TIME [epoch: 8.51 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1986565327116679		[learning rate: 0.0018448]
	Learning Rate: 0.00184479
	LOSS [training: 0.1986565327116679 | validation: 0.25634201679931057]
	TIME [epoch: 8.53 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1325455879090651		[learning rate: 0.0018381]
	Learning Rate: 0.0018381
	LOSS [training: 0.1325455879090651 | validation: 0.2547945861048169]
	TIME [epoch: 8.5 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1770835574359642		[learning rate: 0.0018314]
	Learning Rate: 0.00183143
	LOSS [training: 0.1770835574359642 | validation: 0.10892638586226996]
	TIME [epoch: 8.51 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17444072483537976		[learning rate: 0.0018248]
	Learning Rate: 0.00182478
	LOSS [training: 0.17444072483537976 | validation: 0.1365940228885376]
	TIME [epoch: 8.5 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1307199821455229		[learning rate: 0.0018182]
	Learning Rate: 0.00181816
	LOSS [training: 0.1307199821455229 | validation: 0.12237939065706563]
	TIME [epoch: 8.53 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2352141035314148		[learning rate: 0.0018116]
	Learning Rate: 0.00181156
	LOSS [training: 0.2352141035314148 | validation: 0.28148436026699475]
	TIME [epoch: 8.51 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14087851738833235		[learning rate: 0.001805]
	Learning Rate: 0.00180499
	LOSS [training: 0.14087851738833235 | validation: 0.11678524033898872]
	TIME [epoch: 8.51 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13567094247875347		[learning rate: 0.0017984]
	Learning Rate: 0.00179844
	LOSS [training: 0.13567094247875347 | validation: 0.15027142498725443]
	TIME [epoch: 8.5 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1720991712247331		[learning rate: 0.0017919]
	Learning Rate: 0.00179191
	LOSS [training: 0.1720991712247331 | validation: 0.14760299365800972]
	TIME [epoch: 8.53 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20803233240959956		[learning rate: 0.0017854]
	Learning Rate: 0.00178541
	LOSS [training: 0.20803233240959956 | validation: 0.2823653381702799]
	TIME [epoch: 8.51 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17786115286547494		[learning rate: 0.0017789]
	Learning Rate: 0.00177893
	LOSS [training: 0.17786115286547494 | validation: 0.09724563302234476]
	TIME [epoch: 8.52 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14455936563857733		[learning rate: 0.0017725]
	Learning Rate: 0.00177247
	LOSS [training: 0.14455936563857733 | validation: 0.13768114658968875]
	TIME [epoch: 8.5 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15409312064464706		[learning rate: 0.001766]
	Learning Rate: 0.00176604
	LOSS [training: 0.15409312064464706 | validation: 0.1047754369224436]
	TIME [epoch: 8.51 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15392075776939257		[learning rate: 0.0017596]
	Learning Rate: 0.00175963
	LOSS [training: 0.15392075776939257 | validation: 0.15677844838468585]
	TIME [epoch: 8.52 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17248858482574178		[learning rate: 0.0017532]
	Learning Rate: 0.00175324
	LOSS [training: 0.17248858482574178 | validation: 0.09104000728127007]
	TIME [epoch: 8.5 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16604982895673584		[learning rate: 0.0017469]
	Learning Rate: 0.00174688
	LOSS [training: 0.16604982895673584 | validation: 0.11939592615988345]
	TIME [epoch: 8.51 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1613939046822755		[learning rate: 0.0017405]
	Learning Rate: 0.00174054
	LOSS [training: 0.1613939046822755 | validation: 0.14325629190308198]
	TIME [epoch: 8.51 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18534893624306512		[learning rate: 0.0017342]
	Learning Rate: 0.00173422
	LOSS [training: 0.18534893624306512 | validation: 0.13432847724381075]
	TIME [epoch: 8.53 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18551091943718306		[learning rate: 0.0017279]
	Learning Rate: 0.00172793
	LOSS [training: 0.18551091943718306 | validation: 0.10821832130803058]
	TIME [epoch: 8.5 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13369479868276576		[learning rate: 0.0017217]
	Learning Rate: 0.00172166
	LOSS [training: 0.13369479868276576 | validation: 0.10412167590896343]
	TIME [epoch: 8.5 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13664117804123893		[learning rate: 0.0017154]
	Learning Rate: 0.00171541
	LOSS [training: 0.13664117804123893 | validation: 0.09360053061617593]
	TIME [epoch: 8.5 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20954039785398587		[learning rate: 0.0017092]
	Learning Rate: 0.00170919
	LOSS [training: 0.20954039785398587 | validation: 0.16438789513049362]
	TIME [epoch: 8.52 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14633505183670012		[learning rate: 0.001703]
	Learning Rate: 0.00170298
	LOSS [training: 0.14633505183670012 | validation: 0.09779019642236395]
	TIME [epoch: 8.51 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15382153322969233		[learning rate: 0.0016968]
	Learning Rate: 0.0016968
	LOSS [training: 0.15382153322969233 | validation: 0.13892229672036627]
	TIME [epoch: 8.5 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2002970827744151		[learning rate: 0.0016906]
	Learning Rate: 0.00169065
	LOSS [training: 0.2002970827744151 | validation: 0.1920909061285797]
	TIME [epoch: 8.5 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12660872061665476		[learning rate: 0.0016845]
	Learning Rate: 0.00168451
	LOSS [training: 0.12660872061665476 | validation: 0.15859209149934395]
	TIME [epoch: 8.52 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22346726433513203		[learning rate: 0.0016784]
	Learning Rate: 0.0016784
	LOSS [training: 0.22346726433513203 | validation: 0.12885768779905704]
	TIME [epoch: 8.5 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1360421508506881		[learning rate: 0.0016723]
	Learning Rate: 0.00167231
	LOSS [training: 0.1360421508506881 | validation: 0.13093125360589158]
	TIME [epoch: 8.5 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1922722610765846		[learning rate: 0.0016662]
	Learning Rate: 0.00166624
	LOSS [training: 0.1922722610765846 | validation: 0.08287927013154461]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_593.pth
	Model improved!!!
EPOCH 594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15669054349695685		[learning rate: 0.0016602]
	Learning Rate: 0.00166019
	LOSS [training: 0.15669054349695685 | validation: 0.22350704652573417]
	TIME [epoch: 8.52 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17236349753908314		[learning rate: 0.0016542]
	Learning Rate: 0.00165417
	LOSS [training: 0.17236349753908314 | validation: 0.13352982915646658]
	TIME [epoch: 8.52 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13058362437381674		[learning rate: 0.0016482]
	Learning Rate: 0.00164816
	LOSS [training: 0.13058362437381674 | validation: 0.1421429356906161]
	TIME [epoch: 8.51 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15925190624992086		[learning rate: 0.0016422]
	Learning Rate: 0.00164218
	LOSS [training: 0.15925190624992086 | validation: 0.13906463986988474]
	TIME [epoch: 8.51 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16145325806824173		[learning rate: 0.0016362]
	Learning Rate: 0.00163622
	LOSS [training: 0.16145325806824173 | validation: 0.22573340368851683]
	TIME [epoch: 8.51 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1599651592659846		[learning rate: 0.0016303]
	Learning Rate: 0.00163028
	LOSS [training: 0.1599651592659846 | validation: 0.13872188163024968]
	TIME [epoch: 8.54 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1841783579606327		[learning rate: 0.0016244]
	Learning Rate: 0.00162437
	LOSS [training: 0.1841783579606327 | validation: 0.14412227037316902]
	TIME [epoch: 8.51 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14961410664223757		[learning rate: 0.0016185]
	Learning Rate: 0.00161847
	LOSS [training: 0.14961410664223757 | validation: 0.22411805609641988]
	TIME [epoch: 8.5 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.169574788781332		[learning rate: 0.0016126]
	Learning Rate: 0.0016126
	LOSS [training: 0.169574788781332 | validation: 0.2720661118946289]
	TIME [epoch: 8.5 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17035962638697633		[learning rate: 0.0016067]
	Learning Rate: 0.00160675
	LOSS [training: 0.17035962638697633 | validation: 0.09177019972238357]
	TIME [epoch: 8.54 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1407627694328098		[learning rate: 0.0016009]
	Learning Rate: 0.00160092
	LOSS [training: 0.1407627694328098 | validation: 0.12958606660022315]
	TIME [epoch: 8.51 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15361330221180322		[learning rate: 0.0015951]
	Learning Rate: 0.00159511
	LOSS [training: 0.15361330221180322 | validation: 0.33051621352525273]
	TIME [epoch: 8.51 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18767995610915467		[learning rate: 0.0015893]
	Learning Rate: 0.00158932
	LOSS [training: 0.18767995610915467 | validation: 0.06489016959194069]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_606.pth
	Model improved!!!
EPOCH 607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16195020041518415		[learning rate: 0.0015835]
	Learning Rate: 0.00158355
	LOSS [training: 0.16195020041518415 | validation: 0.14807601724286526]
	TIME [epoch: 8.54 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12315611510089708		[learning rate: 0.0015778]
	Learning Rate: 0.0015778
	LOSS [training: 0.12315611510089708 | validation: 0.14511344130724863]
	TIME [epoch: 8.51 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15349502558822925		[learning rate: 0.0015721]
	Learning Rate: 0.00157208
	LOSS [training: 0.15349502558822925 | validation: 0.16172726071688304]
	TIME [epoch: 8.51 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1519776889763828		[learning rate: 0.0015664]
	Learning Rate: 0.00156637
	LOSS [training: 0.1519776889763828 | validation: 0.2087845754503041]
	TIME [epoch: 8.51 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.219546485899212		[learning rate: 0.0015607]
	Learning Rate: 0.00156069
	LOSS [training: 0.219546485899212 | validation: 0.09498271795763]
	TIME [epoch: 8.53 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12831720869969693		[learning rate: 0.001555]
	Learning Rate: 0.00155502
	LOSS [training: 0.12831720869969693 | validation: 0.2323164154942148]
	TIME [epoch: 8.52 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1582038592997374		[learning rate: 0.0015494]
	Learning Rate: 0.00154938
	LOSS [training: 0.1582038592997374 | validation: 0.08099269217382818]
	TIME [epoch: 8.51 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13500885752583586		[learning rate: 0.0015438]
	Learning Rate: 0.00154376
	LOSS [training: 0.13500885752583586 | validation: 0.21139318553205222]
	TIME [epoch: 8.51 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1640460830316493		[learning rate: 0.0015382]
	Learning Rate: 0.00153815
	LOSS [training: 0.1640460830316493 | validation: 0.100239611735668]
	TIME [epoch: 8.51 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1388750007635749		[learning rate: 0.0015326]
	Learning Rate: 0.00153257
	LOSS [training: 0.1388750007635749 | validation: 0.1633370437069404]
	TIME [epoch: 8.53 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1311340602693461		[learning rate: 0.001527]
	Learning Rate: 0.00152701
	LOSS [training: 0.1311340602693461 | validation: 0.09863342847780475]
	TIME [epoch: 8.51 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18087063889135757		[learning rate: 0.0015215]
	Learning Rate: 0.00152147
	LOSS [training: 0.18087063889135757 | validation: 0.19298705700658053]
	TIME [epoch: 8.51 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16627286716964915		[learning rate: 0.0015159]
	Learning Rate: 0.00151595
	LOSS [training: 0.16627286716964915 | validation: 0.12260833493199061]
	TIME [epoch: 8.51 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11510115809195758		[learning rate: 0.0015104]
	Learning Rate: 0.00151045
	LOSS [training: 0.11510115809195758 | validation: 0.11516997233902021]
	TIME [epoch: 8.54 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1467971988570384		[learning rate: 0.001505]
	Learning Rate: 0.00150496
	LOSS [training: 0.1467971988570384 | validation: 0.12082989468576287]
	TIME [epoch: 8.51 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11629654875016777		[learning rate: 0.0014995]
	Learning Rate: 0.0014995
	LOSS [training: 0.11629654875016777 | validation: 0.10589439626033269]
	TIME [epoch: 8.51 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16807654959045093		[learning rate: 0.0014941]
	Learning Rate: 0.00149406
	LOSS [training: 0.16807654959045093 | validation: 0.25788658096867556]
	TIME [epoch: 8.51 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19704794719365945		[learning rate: 0.0014886]
	Learning Rate: 0.00148864
	LOSS [training: 0.19704794719365945 | validation: 0.17881103287580719]
	TIME [epoch: 8.54 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1795974434768903		[learning rate: 0.0014832]
	Learning Rate: 0.00148324
	LOSS [training: 0.1795974434768903 | validation: 0.14294313763350758]
	TIME [epoch: 8.51 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1367993695441795		[learning rate: 0.0014779]
	Learning Rate: 0.00147785
	LOSS [training: 0.1367993695441795 | validation: 0.1407414387967848]
	TIME [epoch: 8.51 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15978049246433473		[learning rate: 0.0014725]
	Learning Rate: 0.00147249
	LOSS [training: 0.15978049246433473 | validation: 0.25932355017470515]
	TIME [epoch: 8.51 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18045194091766997		[learning rate: 0.0014671]
	Learning Rate: 0.00146715
	LOSS [training: 0.18045194091766997 | validation: 0.10823088462161744]
	TIME [epoch: 8.53 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18070902278014567		[learning rate: 0.0014618]
	Learning Rate: 0.00146182
	LOSS [training: 0.18070902278014567 | validation: 0.13272754112430704]
	TIME [epoch: 8.52 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15411179604879452		[learning rate: 0.0014565]
	Learning Rate: 0.00145652
	LOSS [training: 0.15411179604879452 | validation: 0.2498416348486773]
	TIME [epoch: 8.51 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14483756320434027		[learning rate: 0.0014512]
	Learning Rate: 0.00145123
	LOSS [training: 0.14483756320434027 | validation: 0.17919976965818143]
	TIME [epoch: 8.51 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13384571108126503		[learning rate: 0.001446]
	Learning Rate: 0.00144597
	LOSS [training: 0.13384571108126503 | validation: 0.17845111649683976]
	TIME [epoch: 8.51 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13435158362157334		[learning rate: 0.0014407]
	Learning Rate: 0.00144072
	LOSS [training: 0.13435158362157334 | validation: 0.16548632253170012]
	TIME [epoch: 8.53 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14932278863965068		[learning rate: 0.0014355]
	Learning Rate: 0.00143549
	LOSS [training: 0.14932278863965068 | validation: 0.1999372149881392]
	TIME [epoch: 8.51 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1405353448537871		[learning rate: 0.0014303]
	Learning Rate: 0.00143028
	LOSS [training: 0.1405353448537871 | validation: 0.07974440147125442]
	TIME [epoch: 8.51 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21390414494749424		[learning rate: 0.0014251]
	Learning Rate: 0.00142509
	LOSS [training: 0.21390414494749424 | validation: 0.178400851390572]
	TIME [epoch: 8.5 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13661553146238714		[learning rate: 0.0014199]
	Learning Rate: 0.00141992
	LOSS [training: 0.13661553146238714 | validation: 0.09999362621239331]
	TIME [epoch: 8.53 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13010622733161775		[learning rate: 0.0014148]
	Learning Rate: 0.00141476
	LOSS [training: 0.13010622733161775 | validation: 0.16591640445974226]
	TIME [epoch: 8.5 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15149648614521177		[learning rate: 0.0014096]
	Learning Rate: 0.00140963
	LOSS [training: 0.15149648614521177 | validation: 0.24059250138434782]
	TIME [epoch: 8.51 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15501842896254456		[learning rate: 0.0014045]
	Learning Rate: 0.00140451
	LOSS [training: 0.15501842896254456 | validation: 0.09213162385226048]
	TIME [epoch: 8.51 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11995525332772923		[learning rate: 0.0013994]
	Learning Rate: 0.00139942
	LOSS [training: 0.11995525332772923 | validation: 0.18842664120744268]
	TIME [epoch: 8.53 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1441635644437782		[learning rate: 0.0013943]
	Learning Rate: 0.00139434
	LOSS [training: 0.1441635644437782 | validation: 0.16645044910061474]
	TIME [epoch: 8.51 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1646602790655431		[learning rate: 0.0013893]
	Learning Rate: 0.00138928
	LOSS [training: 0.1646602790655431 | validation: 0.1675658894631643]
	TIME [epoch: 8.51 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1252351911613642		[learning rate: 0.0013842]
	Learning Rate: 0.00138424
	LOSS [training: 0.1252351911613642 | validation: 0.1891934972460846]
	TIME [epoch: 8.51 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1285017808072673		[learning rate: 0.0013792]
	Learning Rate: 0.00137921
	LOSS [training: 0.1285017808072673 | validation: 0.08724360339944201]
	TIME [epoch: 8.52 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16166817808700493		[learning rate: 0.0013742]
	Learning Rate: 0.00137421
	LOSS [training: 0.16166817808700493 | validation: 0.10984692326501995]
	TIME [epoch: 8.51 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1797481406353933		[learning rate: 0.0013692]
	Learning Rate: 0.00136922
	LOSS [training: 0.1797481406353933 | validation: 0.21431513933683724]
	TIME [epoch: 8.51 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15797360154662426		[learning rate: 0.0013643]
	Learning Rate: 0.00136425
	LOSS [training: 0.15797360154662426 | validation: 0.10057176423180308]
	TIME [epoch: 8.5 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13331747688795623		[learning rate: 0.0013593]
	Learning Rate: 0.0013593
	LOSS [training: 0.13331747688795623 | validation: 0.1627952986674971]
	TIME [epoch: 8.51 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1481540165270146		[learning rate: 0.0013544]
	Learning Rate: 0.00135437
	LOSS [training: 0.1481540165270146 | validation: 0.0933765383260177]
	TIME [epoch: 8.53 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16816065244608686		[learning rate: 0.0013495]
	Learning Rate: 0.00134945
	LOSS [training: 0.16816065244608686 | validation: 0.20387711807095354]
	TIME [epoch: 8.51 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14224125836852658		[learning rate: 0.0013446]
	Learning Rate: 0.00134456
	LOSS [training: 0.14224125836852658 | validation: 0.19780605460540368]
	TIME [epoch: 8.5 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1375936398381859		[learning rate: 0.0013397]
	Learning Rate: 0.00133968
	LOSS [training: 0.1375936398381859 | validation: 0.2026730588803335]
	TIME [epoch: 8.51 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18721625239889667		[learning rate: 0.0013348]
	Learning Rate: 0.00133481
	LOSS [training: 0.18721625239889667 | validation: 0.11086823695259147]
	TIME [epoch: 8.53 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14306647247198698		[learning rate: 0.00133]
	Learning Rate: 0.00132997
	LOSS [training: 0.14306647247198698 | validation: 0.10426514215763888]
	TIME [epoch: 8.51 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1174006273868351		[learning rate: 0.0013251]
	Learning Rate: 0.00132514
	LOSS [training: 0.1174006273868351 | validation: 0.14614757881217766]
	TIME [epoch: 8.5 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11223798173761332		[learning rate: 0.0013203]
	Learning Rate: 0.00132034
	LOSS [training: 0.11223798173761332 | validation: 0.17261038394773104]
	TIME [epoch: 8.51 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15110888660753913		[learning rate: 0.0013155]
	Learning Rate: 0.00131554
	LOSS [training: 0.15110888660753913 | validation: 0.20046025104675647]
	TIME [epoch: 8.53 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1187533121967563		[learning rate: 0.0013108]
	Learning Rate: 0.00131077
	LOSS [training: 0.1187533121967563 | validation: 0.20130398018084636]
	TIME [epoch: 8.51 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14180030891929035		[learning rate: 0.001306]
	Learning Rate: 0.00130601
	LOSS [training: 0.14180030891929035 | validation: 0.12102483924163664]
	TIME [epoch: 8.51 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12028169961662458		[learning rate: 0.0013013]
	Learning Rate: 0.00130127
	LOSS [training: 0.12028169961662458 | validation: 0.12214555314007648]
	TIME [epoch: 8.5 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12619565779345987		[learning rate: 0.0012966]
	Learning Rate: 0.00129655
	LOSS [training: 0.12619565779345987 | validation: 0.12758711338414397]
	TIME [epoch: 8.52 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12332401020571464		[learning rate: 0.0012918]
	Learning Rate: 0.00129185
	LOSS [training: 0.12332401020571464 | validation: 0.22660100201794048]
	TIME [epoch: 8.52 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11683355311300889		[learning rate: 0.0012872]
	Learning Rate: 0.00128716
	LOSS [training: 0.11683355311300889 | validation: 0.09167549120046364]
	TIME [epoch: 8.51 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10563039123561424		[learning rate: 0.0012825]
	Learning Rate: 0.00128249
	LOSS [training: 0.10563039123561424 | validation: 0.12185556397742589]
	TIME [epoch: 8.51 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11844150318423532		[learning rate: 0.0012778]
	Learning Rate: 0.00127783
	LOSS [training: 0.11844150318423532 | validation: 0.15239765739443978]
	TIME [epoch: 8.52 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12526309646056336		[learning rate: 0.0012732]
	Learning Rate: 0.00127319
	LOSS [training: 0.12526309646056336 | validation: 0.1570472655877495]
	TIME [epoch: 8.53 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15713932597173375		[learning rate: 0.0012686]
	Learning Rate: 0.00126857
	LOSS [training: 0.15713932597173375 | validation: 0.2195216545898112]
	TIME [epoch: 8.51 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14225486978985155		[learning rate: 0.001264]
	Learning Rate: 0.00126397
	LOSS [training: 0.14225486978985155 | validation: 0.13515348361995616]
	TIME [epoch: 8.51 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20503514204944606		[learning rate: 0.0012594]
	Learning Rate: 0.00125938
	LOSS [training: 0.20503514204944606 | validation: 0.11450815949857726]
	TIME [epoch: 8.51 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15657169543797558		[learning rate: 0.0012548]
	Learning Rate: 0.00125481
	LOSS [training: 0.15657169543797558 | validation: 0.0901357051115137]
	TIME [epoch: 8.54 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10920011320491049		[learning rate: 0.0012503]
	Learning Rate: 0.00125026
	LOSS [training: 0.10920011320491049 | validation: 0.1147919325929615]
	TIME [epoch: 8.51 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11586506193287663		[learning rate: 0.0012457]
	Learning Rate: 0.00124572
	LOSS [training: 0.11586506193287663 | validation: 0.0935701436314697]
	TIME [epoch: 8.51 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12949899028746015		[learning rate: 0.0012412]
	Learning Rate: 0.0012412
	LOSS [training: 0.12949899028746015 | validation: 0.2483576070713912]
	TIME [epoch: 8.51 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12674097465407738		[learning rate: 0.0012367]
	Learning Rate: 0.0012367
	LOSS [training: 0.12674097465407738 | validation: 0.09880252232771647]
	TIME [epoch: 8.53 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13687359770207191		[learning rate: 0.0012322]
	Learning Rate: 0.00123221
	LOSS [training: 0.13687359770207191 | validation: 0.09596139632426118]
	TIME [epoch: 8.51 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1084205281391718		[learning rate: 0.0012277]
	Learning Rate: 0.00122774
	LOSS [training: 0.1084205281391718 | validation: 0.19851912251414575]
	TIME [epoch: 8.5 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14989672323625414		[learning rate: 0.0012233]
	Learning Rate: 0.00122328
	LOSS [training: 0.14989672323625414 | validation: 0.11617556972189341]
	TIME [epoch: 8.51 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1317683808780174		[learning rate: 0.0012188]
	Learning Rate: 0.00121884
	LOSS [training: 0.1317683808780174 | validation: 0.11418776889170767]
	TIME [epoch: 8.52 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11889499498883302		[learning rate: 0.0012144]
	Learning Rate: 0.00121442
	LOSS [training: 0.11889499498883302 | validation: 0.07869135451257658]
	TIME [epoch: 8.52 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1226529911981226		[learning rate: 0.00121]
	Learning Rate: 0.00121001
	LOSS [training: 0.1226529911981226 | validation: 0.08684351068140249]
	TIME [epoch: 8.51 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14224717329677486		[learning rate: 0.0012056]
	Learning Rate: 0.00120562
	LOSS [training: 0.14224717329677486 | validation: 0.1353664497602638]
	TIME [epoch: 8.51 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10893986254813473		[learning rate: 0.0012012]
	Learning Rate: 0.00120125
	LOSS [training: 0.10893986254813473 | validation: 0.21996297608088466]
	TIME [epoch: 8.51 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12710087914742535		[learning rate: 0.0011969]
	Learning Rate: 0.00119689
	LOSS [training: 0.12710087914742535 | validation: 0.07454948823609892]
	TIME [epoch: 8.53 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11553854198798988		[learning rate: 0.0011925]
	Learning Rate: 0.00119254
	LOSS [training: 0.11553854198798988 | validation: 0.10247397788111673]
	TIME [epoch: 8.51 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10384573238804269		[learning rate: 0.0011882]
	Learning Rate: 0.00118821
	LOSS [training: 0.10384573238804269 | validation: 0.21613857494189948]
	TIME [epoch: 8.51 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14074614552124992		[learning rate: 0.0011839]
	Learning Rate: 0.0011839
	LOSS [training: 0.14074614552124992 | validation: 0.07110806831105758]
	TIME [epoch: 8.51 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10630199133658466		[learning rate: 0.0011796]
	Learning Rate: 0.00117961
	LOSS [training: 0.10630199133658466 | validation: 0.10252863232775909]
	TIME [epoch: 8.54 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1070497014910555		[learning rate: 0.0011753]
	Learning Rate: 0.00117532
	LOSS [training: 0.1070497014910555 | validation: 0.1046376239197738]
	TIME [epoch: 8.51 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11431256269036978		[learning rate: 0.0011711]
	Learning Rate: 0.00117106
	LOSS [training: 0.11431256269036978 | validation: 0.11615952267166328]
	TIME [epoch: 8.51 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1100895704402782		[learning rate: 0.0011668]
	Learning Rate: 0.00116681
	LOSS [training: 0.1100895704402782 | validation: 0.13922604499605395]
	TIME [epoch: 8.5 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12616880154320467		[learning rate: 0.0011626]
	Learning Rate: 0.00116258
	LOSS [training: 0.12616880154320467 | validation: 0.0854313318815084]
	TIME [epoch: 8.53 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14905421853664413		[learning rate: 0.0011584]
	Learning Rate: 0.00115836
	LOSS [training: 0.14905421853664413 | validation: 0.13683646002880015]
	TIME [epoch: 8.51 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1218566653253113		[learning rate: 0.0011542]
	Learning Rate: 0.00115415
	LOSS [training: 0.1218566653253113 | validation: 0.11882715781361228]
	TIME [epoch: 8.5 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12481049644881334		[learning rate: 0.00115]
	Learning Rate: 0.00114996
	LOSS [training: 0.12481049644881334 | validation: 0.07513424372360272]
	TIME [epoch: 8.51 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11369440884467771		[learning rate: 0.0011458]
	Learning Rate: 0.00114579
	LOSS [training: 0.11369440884467771 | validation: 0.14052411163619272]
	TIME [epoch: 8.52 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1171254193854159		[learning rate: 0.0011416]
	Learning Rate: 0.00114163
	LOSS [training: 0.1171254193854159 | validation: 0.12169260165179333]
	TIME [epoch: 8.52 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11845022611546238		[learning rate: 0.0011375]
	Learning Rate: 0.00113749
	LOSS [training: 0.11845022611546238 | validation: 0.09853524941810857]
	TIME [epoch: 8.51 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1467684796170875		[learning rate: 0.0011334]
	Learning Rate: 0.00113336
	LOSS [training: 0.1467684796170875 | validation: 0.15491138972414167]
	TIME [epoch: 8.51 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09659437503630516		[learning rate: 0.0011292]
	Learning Rate: 0.00112925
	LOSS [training: 0.09659437503630516 | validation: 0.14628612759508366]
	TIME [epoch: 8.51 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14660257571505292		[learning rate: 0.0011252]
	Learning Rate: 0.00112515
	LOSS [training: 0.14660257571505292 | validation: 0.13053215203047952]
	TIME [epoch: 8.53 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1337960122982719		[learning rate: 0.0011211]
	Learning Rate: 0.00112107
	LOSS [training: 0.1337960122982719 | validation: 0.09240942682765547]
	TIME [epoch: 8.51 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10691571129469399		[learning rate: 0.001117]
	Learning Rate: 0.001117
	LOSS [training: 0.10691571129469399 | validation: 0.08982690484769518]
	TIME [epoch: 8.51 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13073014451152776		[learning rate: 0.0011129]
	Learning Rate: 0.00111295
	LOSS [training: 0.13073014451152776 | validation: 0.071984127216144]
	TIME [epoch: 8.51 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11494235516036592		[learning rate: 0.0011089]
	Learning Rate: 0.00110891
	LOSS [training: 0.11494235516036592 | validation: 0.26471673065180434]
	TIME [epoch: 8.53 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11108922622922082		[learning rate: 0.0011049]
	Learning Rate: 0.00110488
	LOSS [training: 0.11108922622922082 | validation: 0.12437872119304841]
	TIME [epoch: 8.51 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1256450148871867		[learning rate: 0.0011009]
	Learning Rate: 0.00110087
	LOSS [training: 0.1256450148871867 | validation: 0.18502682241132476]
	TIME [epoch: 8.5 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1334181374750039		[learning rate: 0.0010969]
	Learning Rate: 0.00109688
	LOSS [training: 0.1334181374750039 | validation: 0.14515496187358648]
	TIME [epoch: 8.5 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1340320780000615		[learning rate: 0.0010929]
	Learning Rate: 0.0010929
	LOSS [training: 0.1340320780000615 | validation: 0.09752544170537755]
	TIME [epoch: 8.53 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10531480600785077		[learning rate: 0.0010889]
	Learning Rate: 0.00108893
	LOSS [training: 0.10531480600785077 | validation: 0.07769729294915362]
	TIME [epoch: 8.51 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2009111079059293		[learning rate: 0.001085]
	Learning Rate: 0.00108498
	LOSS [training: 0.2009111079059293 | validation: 0.1009126972689233]
	TIME [epoch: 8.51 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11189520453089777		[learning rate: 0.001081]
	Learning Rate: 0.00108104
	LOSS [training: 0.11189520453089777 | validation: 0.11269713637455347]
	TIME [epoch: 8.51 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13780376364763255		[learning rate: 0.0010771]
	Learning Rate: 0.00107712
	LOSS [training: 0.13780376364763255 | validation: 0.08801793306616473]
	TIME [epoch: 8.52 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09509725794037266		[learning rate: 0.0010732]
	Learning Rate: 0.00107321
	LOSS [training: 0.09509725794037266 | validation: 0.09133843515652391]
	TIME [epoch: 8.52 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15975776152362112		[learning rate: 0.0010693]
	Learning Rate: 0.00106931
	LOSS [training: 0.15975776152362112 | validation: 0.2902563366940758]
	TIME [epoch: 8.51 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14680098389496143		[learning rate: 0.0010654]
	Learning Rate: 0.00106543
	LOSS [training: 0.14680098389496143 | validation: 0.09823735933431005]
	TIME [epoch: 8.51 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09218334399537838		[learning rate: 0.0010616]
	Learning Rate: 0.00106157
	LOSS [training: 0.09218334399537838 | validation: 0.10451002708537258]
	TIME [epoch: 8.51 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10730103037128343		[learning rate: 0.0010577]
	Learning Rate: 0.00105771
	LOSS [training: 0.10730103037128343 | validation: 0.12061388987319077]
	TIME [epoch: 8.53 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11543276310099224		[learning rate: 0.0010539]
	Learning Rate: 0.00105388
	LOSS [training: 0.11543276310099224 | validation: 0.17198826792317065]
	TIME [epoch: 8.5 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10860651938887933		[learning rate: 0.0010501]
	Learning Rate: 0.00105005
	LOSS [training: 0.10860651938887933 | validation: 0.14103918978556013]
	TIME [epoch: 8.5 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11457067557687631		[learning rate: 0.0010462]
	Learning Rate: 0.00104624
	LOSS [training: 0.11457067557687631 | validation: 0.13133952368142446]
	TIME [epoch: 8.5 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11291268138369474		[learning rate: 0.0010424]
	Learning Rate: 0.00104244
	LOSS [training: 0.11291268138369474 | validation: 0.14868252228546713]
	TIME [epoch: 8.53 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13435935975420576		[learning rate: 0.0010387]
	Learning Rate: 0.00103866
	LOSS [training: 0.13435935975420576 | validation: 0.1835247749556459]
	TIME [epoch: 8.5 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14066129953108525		[learning rate: 0.0010349]
	Learning Rate: 0.00103489
	LOSS [training: 0.14066129953108525 | validation: 0.12550921780965502]
	TIME [epoch: 8.5 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10885938035986771		[learning rate: 0.0010311]
	Learning Rate: 0.00103114
	LOSS [training: 0.10885938035986771 | validation: 0.0988545682999151]
	TIME [epoch: 8.51 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0869248529394239		[learning rate: 0.0010274]
	Learning Rate: 0.00102739
	LOSS [training: 0.0869248529394239 | validation: 0.11757487460595106]
	TIME [epoch: 8.53 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12043461675794478		[learning rate: 0.0010237]
	Learning Rate: 0.00102367
	LOSS [training: 0.12043461675794478 | validation: 0.09711315678380461]
	TIME [epoch: 8.5 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09331950123642804		[learning rate: 0.00102]
	Learning Rate: 0.00101995
	LOSS [training: 0.09331950123642804 | validation: 0.11967239154650097]
	TIME [epoch: 8.5 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11318699281803575		[learning rate: 0.0010162]
	Learning Rate: 0.00101625
	LOSS [training: 0.11318699281803575 | validation: 0.17488082576031783]
	TIME [epoch: 8.5 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.139088542635281		[learning rate: 0.0010126]
	Learning Rate: 0.00101256
	LOSS [training: 0.139088542635281 | validation: 0.23721020707136953]
	TIME [epoch: 8.52 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15213809746881915		[learning rate: 0.0010089]
	Learning Rate: 0.00100889
	LOSS [training: 0.15213809746881915 | validation: 0.11105272612286111]
	TIME [epoch: 8.51 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11334561229655471		[learning rate: 0.0010052]
	Learning Rate: 0.00100522
	LOSS [training: 0.11334561229655471 | validation: 0.10608754341047244]
	TIME [epoch: 8.5 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11314640512261005		[learning rate: 0.0010016]
	Learning Rate: 0.00100158
	LOSS [training: 0.11314640512261005 | validation: 0.08498325594742007]
	TIME [epoch: 8.51 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12844366584554717		[learning rate: 0.00099794]
	Learning Rate: 0.000997942
	LOSS [training: 0.12844366584554717 | validation: 0.1468791123559655]
	TIME [epoch: 8.51 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11840241426744827		[learning rate: 0.00099432]
	Learning Rate: 0.00099432
	LOSS [training: 0.11840241426744827 | validation: 0.17184311831606708]
	TIME [epoch: 8.52 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15054670261992578		[learning rate: 0.00099071]
	Learning Rate: 0.000990712
	LOSS [training: 0.15054670261992578 | validation: 0.12313787378978093]
	TIME [epoch: 8.51 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11034132124097165		[learning rate: 0.00098712]
	Learning Rate: 0.000987116
	LOSS [training: 0.11034132124097165 | validation: 0.08808520811059865]
	TIME [epoch: 8.51 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09762442596856095		[learning rate: 0.00098353]
	Learning Rate: 0.000983534
	LOSS [training: 0.09762442596856095 | validation: 0.062202501736604965]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_738.pth
	Model improved!!!
EPOCH 739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11411351129354068		[learning rate: 0.00097996]
	Learning Rate: 0.000979965
	LOSS [training: 0.11411351129354068 | validation: 0.16516206715352172]
	TIME [epoch: 8.53 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13566130999532422		[learning rate: 0.00097641]
	Learning Rate: 0.000976409
	LOSS [training: 0.13566130999532422 | validation: 0.16368503076350616]
	TIME [epoch: 8.5 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1018172493536313		[learning rate: 0.00097287]
	Learning Rate: 0.000972865
	LOSS [training: 0.1018172493536313 | validation: 0.10447238939424705]
	TIME [epoch: 8.5 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11400173171980324		[learning rate: 0.00096933]
	Learning Rate: 0.000969335
	LOSS [training: 0.11400173171980324 | validation: 0.08750932808238507]
	TIME [epoch: 8.51 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1492601395306099		[learning rate: 0.00096582]
	Learning Rate: 0.000965817
	LOSS [training: 0.1492601395306099 | validation: 0.09646988039327481]
	TIME [epoch: 8.53 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10905151516512798		[learning rate: 0.00096231]
	Learning Rate: 0.000962312
	LOSS [training: 0.10905151516512798 | validation: 0.09058405342446017]
	TIME [epoch: 8.5 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09860970950952505		[learning rate: 0.00095882]
	Learning Rate: 0.00095882
	LOSS [training: 0.09860970950952505 | validation: 0.11715179700590976]
	TIME [epoch: 8.5 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0940544296984838		[learning rate: 0.00095534]
	Learning Rate: 0.00095534
	LOSS [training: 0.0940544296984838 | validation: 0.11195243884006294]
	TIME [epoch: 8.5 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11762975919271323		[learning rate: 0.00095187]
	Learning Rate: 0.000951873
	LOSS [training: 0.11762975919271323 | validation: 0.07189758262603482]
	TIME [epoch: 8.52 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12849383921032326		[learning rate: 0.00094842]
	Learning Rate: 0.000948419
	LOSS [training: 0.12849383921032326 | validation: 0.06578074315289414]
	TIME [epoch: 8.51 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14076804921939126		[learning rate: 0.00094498]
	Learning Rate: 0.000944977
	LOSS [training: 0.14076804921939126 | validation: 0.09609494352136863]
	TIME [epoch: 8.5 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11324903466160693		[learning rate: 0.00094155]
	Learning Rate: 0.000941547
	LOSS [training: 0.11324903466160693 | validation: 0.13652159347473836]
	TIME [epoch: 8.5 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10419784656990247		[learning rate: 0.00093813]
	Learning Rate: 0.00093813
	LOSS [training: 0.10419784656990247 | validation: 0.12316875311340429]
	TIME [epoch: 8.52 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08751883269045006		[learning rate: 0.00093473]
	Learning Rate: 0.000934726
	LOSS [training: 0.08751883269045006 | validation: 0.17211039932239752]
	TIME [epoch: 8.52 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12724060004979293		[learning rate: 0.00093133]
	Learning Rate: 0.000931334
	LOSS [training: 0.12724060004979293 | validation: 0.13793380717840242]
	TIME [epoch: 8.5 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13637610759552998		[learning rate: 0.00092795]
	Learning Rate: 0.000927954
	LOSS [training: 0.13637610759552998 | validation: 0.1108289189283507]
	TIME [epoch: 8.5 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10452388070014855		[learning rate: 0.00092459]
	Learning Rate: 0.000924586
	LOSS [training: 0.10452388070014855 | validation: 0.06704868482140942]
	TIME [epoch: 8.5 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10160867866369419		[learning rate: 0.00092123]
	Learning Rate: 0.000921231
	LOSS [training: 0.10160867866369419 | validation: 0.08802656562855485]
	TIME [epoch: 8.53 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09414138167581289		[learning rate: 0.00091789]
	Learning Rate: 0.000917888
	LOSS [training: 0.09414138167581289 | validation: 0.09693396515204683]
	TIME [epoch: 8.5 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11063984844810697		[learning rate: 0.00091456]
	Learning Rate: 0.000914556
	LOSS [training: 0.11063984844810697 | validation: 0.2085845799625703]
	TIME [epoch: 8.5 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10579967467117621		[learning rate: 0.00091124]
	Learning Rate: 0.000911237
	LOSS [training: 0.10579967467117621 | validation: 0.15856414008358538]
	TIME [epoch: 8.5 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1121575066187882		[learning rate: 0.00090793]
	Learning Rate: 0.000907931
	LOSS [training: 0.1121575066187882 | validation: 0.08663056497207283]
	TIME [epoch: 8.53 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1159929261642556		[learning rate: 0.00090464]
	Learning Rate: 0.000904636
	LOSS [training: 0.1159929261642556 | validation: 0.14114996881639075]
	TIME [epoch: 8.5 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09095656209876508		[learning rate: 0.00090135]
	Learning Rate: 0.000901353
	LOSS [training: 0.09095656209876508 | validation: 0.17529351990456749]
	TIME [epoch: 8.5 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10507787617375038		[learning rate: 0.00089808]
	Learning Rate: 0.000898082
	LOSS [training: 0.10507787617375038 | validation: 0.11010208834447613]
	TIME [epoch: 8.5 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1299894388277864		[learning rate: 0.00089482]
	Learning Rate: 0.000894822
	LOSS [training: 0.1299894388277864 | validation: 0.10179145187659555]
	TIME [epoch: 8.53 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14717844938113092		[learning rate: 0.00089157]
	Learning Rate: 0.000891575
	LOSS [training: 0.14717844938113092 | validation: 0.1386104956127478]
	TIME [epoch: 8.5 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11366758858149355		[learning rate: 0.00088834]
	Learning Rate: 0.000888339
	LOSS [training: 0.11366758858149355 | validation: 0.06401726498975763]
	TIME [epoch: 8.5 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09234726663278142		[learning rate: 0.00088512]
	Learning Rate: 0.000885116
	LOSS [training: 0.09234726663278142 | validation: 0.15448076163362226]
	TIME [epoch: 8.5 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10517349982408697		[learning rate: 0.0008819]
	Learning Rate: 0.000881903
	LOSS [training: 0.10517349982408697 | validation: 0.13539191428671843]
	TIME [epoch: 8.52 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11188929161176919		[learning rate: 0.0008787]
	Learning Rate: 0.000878703
	LOSS [training: 0.11188929161176919 | validation: 0.073331190054625]
	TIME [epoch: 8.51 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08639778475817082		[learning rate: 0.00087551]
	Learning Rate: 0.000875514
	LOSS [training: 0.08639778475817082 | validation: 0.09636268332184848]
	TIME [epoch: 8.5 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12705525717055016		[learning rate: 0.00087234]
	Learning Rate: 0.000872337
	LOSS [training: 0.12705525717055016 | validation: 0.1235772721668841]
	TIME [epoch: 8.5 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1363406919743476		[learning rate: 0.00086917]
	Learning Rate: 0.000869171
	LOSS [training: 0.1363406919743476 | validation: 0.09312739948332768]
	TIME [epoch: 8.5 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11714641895010955		[learning rate: 0.00086602]
	Learning Rate: 0.000866017
	LOSS [training: 0.11714641895010955 | validation: 0.08533286730429067]
	TIME [epoch: 8.53 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1118938837471171		[learning rate: 0.00086287]
	Learning Rate: 0.000862874
	LOSS [training: 0.1118938837471171 | validation: 0.10685241945821303]
	TIME [epoch: 8.5 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09227068550786653		[learning rate: 0.00085974]
	Learning Rate: 0.000859743
	LOSS [training: 0.09227068550786653 | validation: 0.10069629642023847]
	TIME [epoch: 8.5 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11866295225021384		[learning rate: 0.00085662]
	Learning Rate: 0.000856623
	LOSS [training: 0.11866295225021384 | validation: 0.11558727506354034]
	TIME [epoch: 8.5 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09873879493177182		[learning rate: 0.00085351]
	Learning Rate: 0.000853514
	LOSS [training: 0.09873879493177182 | validation: 0.07133033961144972]
	TIME [epoch: 8.52 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10644508861430764		[learning rate: 0.00085042]
	Learning Rate: 0.000850416
	LOSS [training: 0.10644508861430764 | validation: 0.07464727997799567]
	TIME [epoch: 8.5 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08871599683454645		[learning rate: 0.00084733]
	Learning Rate: 0.00084733
	LOSS [training: 0.08871599683454645 | validation: 0.1256824494023908]
	TIME [epoch: 8.5 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13706283922794854		[learning rate: 0.00084426]
	Learning Rate: 0.000844255
	LOSS [training: 0.13706283922794854 | validation: 0.09312052588523381]
	TIME [epoch: 8.5 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09622178854749298		[learning rate: 0.00084119]
	Learning Rate: 0.000841191
	LOSS [training: 0.09622178854749298 | validation: 0.11517740300266144]
	TIME [epoch: 8.52 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10985299133231244		[learning rate: 0.00083814]
	Learning Rate: 0.000838139
	LOSS [training: 0.10985299133231244 | validation: 0.10347777264565107]
	TIME [epoch: 8.5 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10636561242115943		[learning rate: 0.0008351]
	Learning Rate: 0.000835097
	LOSS [training: 0.10636561242115943 | validation: 0.08065554783643152]
	TIME [epoch: 8.5 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08437963572181206		[learning rate: 0.00083207]
	Learning Rate: 0.000832066
	LOSS [training: 0.08437963572181206 | validation: 0.09983412152447779]
	TIME [epoch: 8.5 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0797018165238368		[learning rate: 0.00082905]
	Learning Rate: 0.000829046
	LOSS [training: 0.0797018165238368 | validation: 0.085130374845177]
	TIME [epoch: 8.52 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12507110951756678		[learning rate: 0.00082604]
	Learning Rate: 0.000826038
	LOSS [training: 0.12507110951756678 | validation: 0.18745513852435916]
	TIME [epoch: 8.51 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09958413600606054		[learning rate: 0.00082304]
	Learning Rate: 0.00082304
	LOSS [training: 0.09958413600606054 | validation: 0.0751005051999392]
	TIME [epoch: 8.5 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10031487617138317		[learning rate: 0.00082005]
	Learning Rate: 0.000820053
	LOSS [training: 0.10031487617138317 | validation: 0.08306175451931297]
	TIME [epoch: 8.5 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09071410417886655		[learning rate: 0.00081708]
	Learning Rate: 0.000817077
	LOSS [training: 0.09071410417886655 | validation: 0.12366468151282435]
	TIME [epoch: 8.5 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10629553982510309		[learning rate: 0.00081411]
	Learning Rate: 0.000814112
	LOSS [training: 0.10629553982510309 | validation: 0.08505409124091606]
	TIME [epoch: 8.53 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0948223851724705		[learning rate: 0.00081116]
	Learning Rate: 0.000811158
	LOSS [training: 0.0948223851724705 | validation: 0.12204353899234893]
	TIME [epoch: 8.5 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11630325676874123		[learning rate: 0.00080821]
	Learning Rate: 0.000808214
	LOSS [training: 0.11630325676874123 | validation: 0.09917826154846479]
	TIME [epoch: 8.5 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11584893704023		[learning rate: 0.00080528]
	Learning Rate: 0.000805281
	LOSS [training: 0.11584893704023 | validation: 0.07070354228093687]
	TIME [epoch: 8.5 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11840844824622751		[learning rate: 0.00080236]
	Learning Rate: 0.000802358
	LOSS [training: 0.11840844824622751 | validation: 0.1256185605569099]
	TIME [epoch: 8.53 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1391607853811768		[learning rate: 0.00079945]
	Learning Rate: 0.000799447
	LOSS [training: 0.1391607853811768 | validation: 0.09842672344129715]
	TIME [epoch: 8.51 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08838627986880118		[learning rate: 0.00079655]
	Learning Rate: 0.000796545
	LOSS [training: 0.08838627986880118 | validation: 0.07411865535479056]
	TIME [epoch: 8.5 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09553948119856874		[learning rate: 0.00079365]
	Learning Rate: 0.000793655
	LOSS [training: 0.09553948119856874 | validation: 0.1171095747734962]
	TIME [epoch: 8.5 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11104032671140843		[learning rate: 0.00079077]
	Learning Rate: 0.000790775
	LOSS [training: 0.11104032671140843 | validation: 0.08257225364881225]
	TIME [epoch: 8.52 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10432652431904614		[learning rate: 0.0007879]
	Learning Rate: 0.000787905
	LOSS [training: 0.10432652431904614 | validation: 0.14035998161686267]
	TIME [epoch: 8.5 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12017804113404951		[learning rate: 0.00078505]
	Learning Rate: 0.000785045
	LOSS [training: 0.12017804113404951 | validation: 0.11213703497319125]
	TIME [epoch: 8.5 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10159861584027077		[learning rate: 0.0007822]
	Learning Rate: 0.000782196
	LOSS [training: 0.10159861584027077 | validation: 0.09833659565305372]
	TIME [epoch: 8.5 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08395259096007526		[learning rate: 0.00077936]
	Learning Rate: 0.000779358
	LOSS [training: 0.08395259096007526 | validation: 0.09236519508365588]
	TIME [epoch: 8.52 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10732891611078066		[learning rate: 0.00077653]
	Learning Rate: 0.000776529
	LOSS [training: 0.10732891611078066 | validation: 0.13317302446053358]
	TIME [epoch: 8.52 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10428969744339038		[learning rate: 0.00077371]
	Learning Rate: 0.000773711
	LOSS [training: 0.10428969744339038 | validation: 0.06942262267050792]
	TIME [epoch: 8.5 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0977946510582201		[learning rate: 0.0007709]
	Learning Rate: 0.000770903
	LOSS [training: 0.0977946510582201 | validation: 0.1231860154341628]
	TIME [epoch: 8.5 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08483988376213927		[learning rate: 0.00076811]
	Learning Rate: 0.000768106
	LOSS [training: 0.08483988376213927 | validation: 0.10907436145431479]
	TIME [epoch: 8.51 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10066251410058191		[learning rate: 0.00076532]
	Learning Rate: 0.000765318
	LOSS [training: 0.10066251410058191 | validation: 0.11801218300929825]
	TIME [epoch: 8.53 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11201285928213016		[learning rate: 0.00076254]
	Learning Rate: 0.000762541
	LOSS [training: 0.11201285928213016 | validation: 0.0788860352302949]
	TIME [epoch: 8.5 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08785401065819778		[learning rate: 0.00075977]
	Learning Rate: 0.000759774
	LOSS [training: 0.08785401065819778 | validation: 0.10895728121178799]
	TIME [epoch: 8.5 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08394171167016731		[learning rate: 0.00075702]
	Learning Rate: 0.000757016
	LOSS [training: 0.08394171167016731 | validation: 0.11530140026390978]
	TIME [epoch: 8.5 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08891583813296672		[learning rate: 0.00075427]
	Learning Rate: 0.000754269
	LOSS [training: 0.08891583813296672 | validation: 0.0773660873139654]
	TIME [epoch: 8.53 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14817628515474343		[learning rate: 0.00075153]
	Learning Rate: 0.000751532
	LOSS [training: 0.14817628515474343 | validation: 0.10575448756179459]
	TIME [epoch: 8.5 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10949972230547649		[learning rate: 0.0007488]
	Learning Rate: 0.000748804
	LOSS [training: 0.10949972230547649 | validation: 0.10196773003962889]
	TIME [epoch: 8.5 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11496194006164688		[learning rate: 0.00074609]
	Learning Rate: 0.000746087
	LOSS [training: 0.11496194006164688 | validation: 0.10907047248623213]
	TIME [epoch: 8.5 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1061360503113276		[learning rate: 0.00074338]
	Learning Rate: 0.000743379
	LOSS [training: 0.1061360503113276 | validation: 0.11245984551247326]
	TIME [epoch: 8.52 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08981863790339047		[learning rate: 0.00074068]
	Learning Rate: 0.000740682
	LOSS [training: 0.08981863790339047 | validation: 0.12523390998532835]
	TIME [epoch: 8.51 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1092712763149494		[learning rate: 0.00073799]
	Learning Rate: 0.000737994
	LOSS [training: 0.1092712763149494 | validation: 0.0712266979823602]
	TIME [epoch: 8.5 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08978016946881477		[learning rate: 0.00073532]
	Learning Rate: 0.000735315
	LOSS [training: 0.08978016946881477 | validation: 0.1337676132750122]
	TIME [epoch: 8.5 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1089311390441364		[learning rate: 0.00073265]
	Learning Rate: 0.000732647
	LOSS [training: 0.1089311390441364 | validation: 0.07164502179760285]
	TIME [epoch: 8.51 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10163122311048053		[learning rate: 0.00072999]
	Learning Rate: 0.000729988
	LOSS [training: 0.10163122311048053 | validation: 0.11737277982066849]
	TIME [epoch: 8.52 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10870175687281627		[learning rate: 0.00072734]
	Learning Rate: 0.000727339
	LOSS [training: 0.10870175687281627 | validation: 0.14586482162208533]
	TIME [epoch: 8.5 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10746303954592835		[learning rate: 0.0007247]
	Learning Rate: 0.000724699
	LOSS [training: 0.10746303954592835 | validation: 0.09130003129164996]
	TIME [epoch: 8.5 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11031738215929363		[learning rate: 0.00072207]
	Learning Rate: 0.000722069
	LOSS [training: 0.11031738215929363 | validation: 0.10654951553183345]
	TIME [epoch: 8.5 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11326988095890271		[learning rate: 0.00071945]
	Learning Rate: 0.000719449
	LOSS [training: 0.11326988095890271 | validation: 0.07802399914005007]
	TIME [epoch: 8.52 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08035950934022733		[learning rate: 0.00071684]
	Learning Rate: 0.000716838
	LOSS [training: 0.08035950934022733 | validation: 0.1398206335520311]
	TIME [epoch: 8.51 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1426230480489311		[learning rate: 0.00071424]
	Learning Rate: 0.000714237
	LOSS [training: 0.1426230480489311 | validation: 0.15307525143057943]
	TIME [epoch: 8.5 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1302998492682825		[learning rate: 0.00071164]
	Learning Rate: 0.000711645
	LOSS [training: 0.1302998492682825 | validation: 0.07155178851558555]
	TIME [epoch: 8.5 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08581197173968495		[learning rate: 0.00070906]
	Learning Rate: 0.000709062
	LOSS [training: 0.08581197173968495 | validation: 0.0901706211927515]
	TIME [epoch: 8.52 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12923985561012113		[learning rate: 0.00070649]
	Learning Rate: 0.000706489
	LOSS [training: 0.12923985561012113 | validation: 0.13329404246369303]
	TIME [epoch: 8.5 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09790497897881448		[learning rate: 0.00070392]
	Learning Rate: 0.000703925
	LOSS [training: 0.09790497897881448 | validation: 0.07981790772240309]
	TIME [epoch: 8.51 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09268075531075476		[learning rate: 0.00070137]
	Learning Rate: 0.00070137
	LOSS [training: 0.09268075531075476 | validation: 0.08675636923437047]
	TIME [epoch: 8.5 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10882151242040575		[learning rate: 0.00069883]
	Learning Rate: 0.000698825
	LOSS [training: 0.10882151242040575 | validation: 0.13165482100719042]
	TIME [epoch: 8.53 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12333997053879435		[learning rate: 0.00069629]
	Learning Rate: 0.000696289
	LOSS [training: 0.12333997053879435 | validation: 0.12083458386286519]
	TIME [epoch: 8.51 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09777860424978749		[learning rate: 0.00069376]
	Learning Rate: 0.000693762
	LOSS [training: 0.09777860424978749 | validation: 0.08748736391649672]
	TIME [epoch: 8.5 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08398730105301459		[learning rate: 0.00069124]
	Learning Rate: 0.000691244
	LOSS [training: 0.08398730105301459 | validation: 0.08386973868120659]
	TIME [epoch: 8.5 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11382061520053699		[learning rate: 0.00068874]
	Learning Rate: 0.000688736
	LOSS [training: 0.11382061520053699 | validation: 0.14815393029221227]
	TIME [epoch: 8.52 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11409379035374131		[learning rate: 0.00068624]
	Learning Rate: 0.000686236
	LOSS [training: 0.11409379035374131 | validation: 0.07459133558666067]
	TIME [epoch: 8.52 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09186614838934197		[learning rate: 0.00068375]
	Learning Rate: 0.000683746
	LOSS [training: 0.09186614838934197 | validation: 0.07275126052604555]
	TIME [epoch: 8.5 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.088043425945635		[learning rate: 0.00068126]
	Learning Rate: 0.000681265
	LOSS [training: 0.088043425945635 | validation: 0.18662665322506125]
	TIME [epoch: 8.5 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11443926390304074		[learning rate: 0.00067879]
	Learning Rate: 0.000678792
	LOSS [training: 0.11443926390304074 | validation: 0.11981997933614172]
	TIME [epoch: 8.5 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09006617870198841		[learning rate: 0.00067633]
	Learning Rate: 0.000676329
	LOSS [training: 0.09006617870198841 | validation: 0.0847528248183014]
	TIME [epoch: 8.52 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10364286116408519		[learning rate: 0.00067387]
	Learning Rate: 0.000673874
	LOSS [training: 0.10364286116408519 | validation: 0.07095820556206014]
	TIME [epoch: 8.5 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0802836482174746		[learning rate: 0.00067143]
	Learning Rate: 0.000671429
	LOSS [training: 0.0802836482174746 | validation: 0.22213648090826105]
	TIME [epoch: 8.5 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0862965040408066		[learning rate: 0.00066899]
	Learning Rate: 0.000668992
	LOSS [training: 0.0862965040408066 | validation: 0.07990187771223731]
	TIME [epoch: 8.5 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07922288559313637		[learning rate: 0.00066656]
	Learning Rate: 0.000666564
	LOSS [training: 0.07922288559313637 | validation: 0.08724172725532045]
	TIME [epoch: 8.53 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09435786723542204		[learning rate: 0.00066415]
	Learning Rate: 0.000664145
	LOSS [training: 0.09435786723542204 | validation: 0.15562243550276922]
	TIME [epoch: 8.5 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12486268463998232		[learning rate: 0.00066174]
	Learning Rate: 0.000661735
	LOSS [training: 0.12486268463998232 | validation: 0.09310955640268714]
	TIME [epoch: 8.5 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09815142871074362		[learning rate: 0.00065933]
	Learning Rate: 0.000659334
	LOSS [training: 0.09815142871074362 | validation: 0.10499960111783979]
	TIME [epoch: 8.5 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1183087995942352		[learning rate: 0.00065694]
	Learning Rate: 0.000656941
	LOSS [training: 0.1183087995942352 | validation: 0.14277663089504705]
	TIME [epoch: 8.52 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11725625205741955		[learning rate: 0.00065456]
	Learning Rate: 0.000654557
	LOSS [training: 0.11725625205741955 | validation: 0.09998861824110927]
	TIME [epoch: 8.51 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09614848679891655		[learning rate: 0.00065218]
	Learning Rate: 0.000652182
	LOSS [training: 0.09614848679891655 | validation: 0.07725286428288555]
	TIME [epoch: 8.51 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0764098911399949		[learning rate: 0.00064981]
	Learning Rate: 0.000649815
	LOSS [training: 0.0764098911399949 | validation: 0.16015456761891922]
	TIME [epoch: 8.51 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10470602042548278		[learning rate: 0.00064746]
	Learning Rate: 0.000647456
	LOSS [training: 0.10470602042548278 | validation: 0.11514968098049856]
	TIME [epoch: 8.53 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10845100164433345		[learning rate: 0.00064511]
	Learning Rate: 0.000645107
	LOSS [training: 0.10845100164433345 | validation: 0.09109140834862617]
	TIME [epoch: 8.52 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09845431528810414		[learning rate: 0.00064277]
	Learning Rate: 0.000642766
	LOSS [training: 0.09845431528810414 | validation: 0.13231413302028056]
	TIME [epoch: 8.51 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09303668659694994		[learning rate: 0.00064043]
	Learning Rate: 0.000640433
	LOSS [training: 0.09303668659694994 | validation: 0.06905291012851097]
	TIME [epoch: 8.5 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09631259991416845		[learning rate: 0.00063811]
	Learning Rate: 0.000638109
	LOSS [training: 0.09631259991416845 | validation: 0.12559607347108012]
	TIME [epoch: 8.51 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10890952640571913		[learning rate: 0.00063579]
	Learning Rate: 0.000635793
	LOSS [training: 0.10890952640571913 | validation: 0.06463439401745599]
	TIME [epoch: 8.53 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09526837472011458		[learning rate: 0.00063349]
	Learning Rate: 0.000633486
	LOSS [training: 0.09526837472011458 | validation: 0.12626975229231033]
	TIME [epoch: 8.51 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10886419297311097		[learning rate: 0.00063119]
	Learning Rate: 0.000631187
	LOSS [training: 0.10886419297311097 | validation: 0.09211247943472006]
	TIME [epoch: 8.5 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0931094397302524		[learning rate: 0.0006289]
	Learning Rate: 0.000628896
	LOSS [training: 0.0931094397302524 | validation: 0.15473343597802008]
	TIME [epoch: 8.51 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08365507753339571		[learning rate: 0.00062661]
	Learning Rate: 0.000626614
	LOSS [training: 0.08365507753339571 | validation: 0.09852069321440751]
	TIME [epoch: 8.53 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08492181398748208		[learning rate: 0.00062434]
	Learning Rate: 0.00062434
	LOSS [training: 0.08492181398748208 | validation: 0.06596604244424402]
	TIME [epoch: 8.5 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10461742581776101		[learning rate: 0.00062207]
	Learning Rate: 0.000622074
	LOSS [training: 0.10461742581776101 | validation: 0.08703598172514379]
	TIME [epoch: 8.5 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09110555123909146		[learning rate: 0.00061982]
	Learning Rate: 0.000619816
	LOSS [training: 0.09110555123909146 | validation: 0.07559547472548772]
	TIME [epoch: 8.5 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0882218314869066		[learning rate: 0.00061757]
	Learning Rate: 0.000617567
	LOSS [training: 0.0882218314869066 | validation: 0.13655520067897448]
	TIME [epoch: 8.53 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1020570189477585		[learning rate: 0.00061533]
	Learning Rate: 0.000615326
	LOSS [training: 0.1020570189477585 | validation: 0.08130691529106338]
	TIME [epoch: 8.51 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08190438631216942		[learning rate: 0.00061309]
	Learning Rate: 0.000613093
	LOSS [training: 0.08190438631216942 | validation: 0.07386894359321175]
	TIME [epoch: 8.5 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10046286114315946		[learning rate: 0.00061087]
	Learning Rate: 0.000610868
	LOSS [training: 0.10046286114315946 | validation: 0.08727102085335114]
	TIME [epoch: 8.5 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0905325270610203		[learning rate: 0.00060865]
	Learning Rate: 0.000608651
	LOSS [training: 0.0905325270610203 | validation: 0.1072916439467724]
	TIME [epoch: 8.51 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10362449109846521		[learning rate: 0.00060644]
	Learning Rate: 0.000606442
	LOSS [training: 0.10362449109846521 | validation: 0.13796001570451877]
	TIME [epoch: 8.51 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0827992465223795		[learning rate: 0.00060424]
	Learning Rate: 0.000604242
	LOSS [training: 0.0827992465223795 | validation: 0.061821950613025756]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_872.pth
	Model improved!!!
EPOCH 873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09626090925930567		[learning rate: 0.00060205]
	Learning Rate: 0.000602049
	LOSS [training: 0.09626090925930567 | validation: 0.07073158683008789]
	TIME [epoch: 8.5 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1237665441274737		[learning rate: 0.00059986]
	Learning Rate: 0.000599864
	LOSS [training: 0.1237665441274737 | validation: 0.33875461963108755]
	TIME [epoch: 8.5 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13582290668066463		[learning rate: 0.00059769]
	Learning Rate: 0.000597687
	LOSS [training: 0.13582290668066463 | validation: 0.12510219179739587]
	TIME [epoch: 8.51 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10047122463228582		[learning rate: 0.00059552]
	Learning Rate: 0.000595518
	LOSS [training: 0.10047122463228582 | validation: 0.11326682566065928]
	TIME [epoch: 8.5 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08581867108897721		[learning rate: 0.00059336]
	Learning Rate: 0.000593357
	LOSS [training: 0.08581867108897721 | validation: 0.07895205503989038]
	TIME [epoch: 8.51 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08421300772565951		[learning rate: 0.0005912]
	Learning Rate: 0.000591203
	LOSS [training: 0.08421300772565951 | validation: 0.09410854786114134]
	TIME [epoch: 8.51 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07750186086614581		[learning rate: 0.00058906]
	Learning Rate: 0.000589058
	LOSS [training: 0.07750186086614581 | validation: 0.0593944474916458]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_879.pth
	Model improved!!!
EPOCH 880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10408014886762487		[learning rate: 0.00058692]
	Learning Rate: 0.00058692
	LOSS [training: 0.10408014886762487 | validation: 0.18595619131947477]
	TIME [epoch: 8.51 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11016725428350656		[learning rate: 0.00058479]
	Learning Rate: 0.00058479
	LOSS [training: 0.11016725428350656 | validation: 0.07046857105410476]
	TIME [epoch: 8.5 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08287971168521395		[learning rate: 0.00058267]
	Learning Rate: 0.000582668
	LOSS [training: 0.08287971168521395 | validation: 0.09733758165973672]
	TIME [epoch: 8.49 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0832967021477744		[learning rate: 0.00058055]
	Learning Rate: 0.000580553
	LOSS [training: 0.0832967021477744 | validation: 0.0759335151305714]
	TIME [epoch: 8.52 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08537856840444		[learning rate: 0.00057845]
	Learning Rate: 0.000578446
	LOSS [training: 0.08537856840444 | validation: 0.0850789937630787]
	TIME [epoch: 8.5 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10133106249211972		[learning rate: 0.00057635]
	Learning Rate: 0.000576347
	LOSS [training: 0.10133106249211972 | validation: 0.07760019532683066]
	TIME [epoch: 8.49 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08361064280432394		[learning rate: 0.00057426]
	Learning Rate: 0.000574256
	LOSS [training: 0.08361064280432394 | validation: 0.09696704115857184]
	TIME [epoch: 8.49 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0909356019040629		[learning rate: 0.00057217]
	Learning Rate: 0.000572172
	LOSS [training: 0.0909356019040629 | validation: 0.08681115382491914]
	TIME [epoch: 8.51 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08224352583999449		[learning rate: 0.0005701]
	Learning Rate: 0.000570095
	LOSS [training: 0.08224352583999449 | validation: 0.07261207699589335]
	TIME [epoch: 8.5 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11070072475341493		[learning rate: 0.00056803]
	Learning Rate: 0.000568026
	LOSS [training: 0.11070072475341493 | validation: 0.17957643048998492]
	TIME [epoch: 8.49 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09309128696725898		[learning rate: 0.00056596]
	Learning Rate: 0.000565965
	LOSS [training: 0.09309128696725898 | validation: 0.0693968582538538]
	TIME [epoch: 8.49 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09386049734083733		[learning rate: 0.00056391]
	Learning Rate: 0.000563911
	LOSS [training: 0.09386049734083733 | validation: 0.11039010840463417]
	TIME [epoch: 8.5 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08293853594811763		[learning rate: 0.00056186]
	Learning Rate: 0.000561864
	LOSS [training: 0.08293853594811763 | validation: 0.06688439638708538]
	TIME [epoch: 8.52 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08805991808234234		[learning rate: 0.00055983]
	Learning Rate: 0.000559825
	LOSS [training: 0.08805991808234234 | validation: 0.12025089244704067]
	TIME [epoch: 8.49 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14932232770435366		[learning rate: 0.00055779]
	Learning Rate: 0.000557794
	LOSS [training: 0.14932232770435366 | validation: 0.11100174368823387]
	TIME [epoch: 8.5 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09613196416804384		[learning rate: 0.00055577]
	Learning Rate: 0.00055577
	LOSS [training: 0.09613196416804384 | validation: 0.09926945892949324]
	TIME [epoch: 8.5 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0879345543683968		[learning rate: 0.00055375]
	Learning Rate: 0.000553753
	LOSS [training: 0.0879345543683968 | validation: 0.07540144835332627]
	TIME [epoch: 8.52 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12013264611217464		[learning rate: 0.00055174]
	Learning Rate: 0.000551743
	LOSS [training: 0.12013264611217464 | validation: 0.08001773183008537]
	TIME [epoch: 8.49 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06982703978890513		[learning rate: 0.00054974]
	Learning Rate: 0.000549741
	LOSS [training: 0.06982703978890513 | validation: 0.13013978672253448]
	TIME [epoch: 8.5 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0829359137432952		[learning rate: 0.00054775]
	Learning Rate: 0.000547746
	LOSS [training: 0.0829359137432952 | validation: 0.10424670146274502]
	TIME [epoch: 8.49 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08442153771476671		[learning rate: 0.00054576]
	Learning Rate: 0.000545758
	LOSS [training: 0.08442153771476671 | validation: 0.06751859991204517]
	TIME [epoch: 8.52 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07630046543467045		[learning rate: 0.00054378]
	Learning Rate: 0.000543777
	LOSS [training: 0.07630046543467045 | validation: 0.08183502928464043]
	TIME [epoch: 8.5 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09821227445086529		[learning rate: 0.0005418]
	Learning Rate: 0.000541804
	LOSS [training: 0.09821227445086529 | validation: 0.0882465548502214]
	TIME [epoch: 8.49 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08247099408331432		[learning rate: 0.00053984]
	Learning Rate: 0.000539838
	LOSS [training: 0.08247099408331432 | validation: 0.08223060995571846]
	TIME [epoch: 8.49 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08171332727413781		[learning rate: 0.00053788]
	Learning Rate: 0.000537879
	LOSS [training: 0.08171332727413781 | validation: 0.08369586789167374]
	TIME [epoch: 8.51 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0837154301310328		[learning rate: 0.00053593]
	Learning Rate: 0.000535926
	LOSS [training: 0.0837154301310328 | validation: 0.07393484866926633]
	TIME [epoch: 8.5 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07429775088234422		[learning rate: 0.00053398]
	Learning Rate: 0.000533982
	LOSS [training: 0.07429775088234422 | validation: 0.08857268389976243]
	TIME [epoch: 8.5 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0816427905229056		[learning rate: 0.00053204]
	Learning Rate: 0.000532044
	LOSS [training: 0.0816427905229056 | validation: 0.08133390880108031]
	TIME [epoch: 8.5 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07992593780016147		[learning rate: 0.00053011]
	Learning Rate: 0.000530113
	LOSS [training: 0.07992593780016147 | validation: 0.10838892821521594]
	TIME [epoch: 8.5 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10989236182520394		[learning rate: 0.00052819]
	Learning Rate: 0.000528189
	LOSS [training: 0.10989236182520394 | validation: 0.0903677900443439]
	TIME [epoch: 8.52 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08547820917935832		[learning rate: 0.00052627]
	Learning Rate: 0.000526272
	LOSS [training: 0.08547820917935832 | validation: 0.07392216810861287]
	TIME [epoch: 8.49 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08111506469993139		[learning rate: 0.00052436]
	Learning Rate: 0.000524362
	LOSS [training: 0.08111506469993139 | validation: 0.07267839507774912]
	TIME [epoch: 8.49 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0932410232367544		[learning rate: 0.00052246]
	Learning Rate: 0.00052246
	LOSS [training: 0.0932410232367544 | validation: 0.0890716565964714]
	TIME [epoch: 8.5 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08340381685887638		[learning rate: 0.00052056]
	Learning Rate: 0.000520563
	LOSS [training: 0.08340381685887638 | validation: 0.077645671644563]
	TIME [epoch: 8.52 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09376246545498679		[learning rate: 0.00051867]
	Learning Rate: 0.000518674
	LOSS [training: 0.09376246545498679 | validation: 0.07837755262560472]
	TIME [epoch: 8.49 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08312355590621848		[learning rate: 0.00051679]
	Learning Rate: 0.000516792
	LOSS [training: 0.08312355590621848 | validation: 0.08271514325078132]
	TIME [epoch: 8.5 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08179296585575994		[learning rate: 0.00051492]
	Learning Rate: 0.000514917
	LOSS [training: 0.08179296585575994 | validation: 0.07681017478521829]
	TIME [epoch: 8.49 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0850802153805532		[learning rate: 0.00051305]
	Learning Rate: 0.000513048
	LOSS [training: 0.0850802153805532 | validation: 0.0657661048343958]
	TIME [epoch: 8.52 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08301043934534053		[learning rate: 0.00051119]
	Learning Rate: 0.000511186
	LOSS [training: 0.08301043934534053 | validation: 0.10995242506466289]
	TIME [epoch: 8.49 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09659211693292004		[learning rate: 0.00050933]
	Learning Rate: 0.000509331
	LOSS [training: 0.09659211693292004 | validation: 0.06973001306839485]
	TIME [epoch: 8.49 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0869408803091377		[learning rate: 0.00050748]
	Learning Rate: 0.000507483
	LOSS [training: 0.0869408803091377 | validation: 0.12523927711597171]
	TIME [epoch: 8.5 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09562656684179341		[learning rate: 0.00050564]
	Learning Rate: 0.000505641
	LOSS [training: 0.09562656684179341 | validation: 0.09679077182941269]
	TIME [epoch: 8.51 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08333036750243808		[learning rate: 0.00050381]
	Learning Rate: 0.000503806
	LOSS [training: 0.08333036750243808 | validation: 0.08587552548935024]
	TIME [epoch: 8.51 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07356538296922999		[learning rate: 0.00050198]
	Learning Rate: 0.000501977
	LOSS [training: 0.07356538296922999 | validation: 0.10415244096019158]
	TIME [epoch: 8.49 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07713508184099745		[learning rate: 0.00050016]
	Learning Rate: 0.000500156
	LOSS [training: 0.07713508184099745 | validation: 0.07973666352237056]
	TIME [epoch: 8.49 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09214412530327108		[learning rate: 0.00049834]
	Learning Rate: 0.000498341
	LOSS [training: 0.09214412530327108 | validation: 0.08688901794200402]
	TIME [epoch: 8.5 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07604734788018523		[learning rate: 0.00049653]
	Learning Rate: 0.000496532
	LOSS [training: 0.07604734788018523 | validation: 0.1514445763062906]
	TIME [epoch: 8.52 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0946026568577152		[learning rate: 0.00049473]
	Learning Rate: 0.00049473
	LOSS [training: 0.0946026568577152 | validation: 0.07350285228302528]
	TIME [epoch: 8.5 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07745775476708497		[learning rate: 0.00049293]
	Learning Rate: 0.000492935
	LOSS [training: 0.07745775476708497 | validation: 0.07190185860993503]
	TIME [epoch: 8.5 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07449086058191998		[learning rate: 0.00049115]
	Learning Rate: 0.000491146
	LOSS [training: 0.07449086058191998 | validation: 0.08111766441331852]
	TIME [epoch: 8.5 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0770813090357903		[learning rate: 0.00048936]
	Learning Rate: 0.000489364
	LOSS [training: 0.0770813090357903 | validation: 0.08003973352516779]
	TIME [epoch: 8.54 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08131703376758188		[learning rate: 0.00048759]
	Learning Rate: 0.000487588
	LOSS [training: 0.08131703376758188 | validation: 0.09149193615797929]
	TIME [epoch: 8.5 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08378235899963923		[learning rate: 0.00048582]
	Learning Rate: 0.000485818
	LOSS [training: 0.08378235899963923 | validation: 0.05992563854382514]
	TIME [epoch: 8.51 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08496503691527799		[learning rate: 0.00048406]
	Learning Rate: 0.000484055
	LOSS [training: 0.08496503691527799 | validation: 0.07989679028262123]
	TIME [epoch: 8.51 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07960978884229031		[learning rate: 0.0004823]
	Learning Rate: 0.000482298
	LOSS [training: 0.07960978884229031 | validation: 0.09437439239599135]
	TIME [epoch: 8.53 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08075985614588758		[learning rate: 0.00048055]
	Learning Rate: 0.000480548
	LOSS [training: 0.08075985614588758 | validation: 0.07798372918771937]
	TIME [epoch: 8.5 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08869210187391728		[learning rate: 0.0004788]
	Learning Rate: 0.000478804
	LOSS [training: 0.08869210187391728 | validation: 0.06325550544946011]
	TIME [epoch: 8.5 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08900405575718917		[learning rate: 0.00047707]
	Learning Rate: 0.000477067
	LOSS [training: 0.08900405575718917 | validation: 0.07787298811984245]
	TIME [epoch: 8.5 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08463305997740281		[learning rate: 0.00047534]
	Learning Rate: 0.000475335
	LOSS [training: 0.08463305997740281 | validation: 0.11279717132906537]
	TIME [epoch: 8.52 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12994954519322632		[learning rate: 0.00047361]
	Learning Rate: 0.00047361
	LOSS [training: 0.12994954519322632 | validation: 0.07831033095938879]
	TIME [epoch: 8.53 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07316499934069107		[learning rate: 0.00047189]
	Learning Rate: 0.000471891
	LOSS [training: 0.07316499934069107 | validation: 0.07209533432636098]
	TIME [epoch: 8.5 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06854113762316617		[learning rate: 0.00047018]
	Learning Rate: 0.000470179
	LOSS [training: 0.06854113762316617 | validation: 0.08003900089453683]
	TIME [epoch: 8.5 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08227711136713342		[learning rate: 0.00046847]
	Learning Rate: 0.000468473
	LOSS [training: 0.08227711136713342 | validation: 0.06762309215260803]
	TIME [epoch: 8.51 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0776805401781436		[learning rate: 0.00046677]
	Learning Rate: 0.000466773
	LOSS [training: 0.0776805401781436 | validation: 0.05610202164836718]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_943.pth
	Model improved!!!
EPOCH 944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11487800549976057		[learning rate: 0.00046508]
	Learning Rate: 0.000465079
	LOSS [training: 0.11487800549976057 | validation: 0.09621119040817391]
	TIME [epoch: 8.51 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07476684276336634		[learning rate: 0.00046339]
	Learning Rate: 0.000463391
	LOSS [training: 0.07476684276336634 | validation: 0.09860778726843983]
	TIME [epoch: 8.51 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07434736646204769		[learning rate: 0.00046171]
	Learning Rate: 0.000461709
	LOSS [training: 0.07434736646204769 | validation: 0.07337872003820609]
	TIME [epoch: 8.5 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07294182094799437		[learning rate: 0.00046003]
	Learning Rate: 0.000460034
	LOSS [training: 0.07294182094799437 | validation: 0.12093737241554996]
	TIME [epoch: 8.53 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07662476044607729		[learning rate: 0.00045836]
	Learning Rate: 0.000458364
	LOSS [training: 0.07662476044607729 | validation: 0.06712152898628182]
	TIME [epoch: 8.51 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0721481126825602		[learning rate: 0.0004567]
	Learning Rate: 0.000456701
	LOSS [training: 0.0721481126825602 | validation: 0.0946091028094452]
	TIME [epoch: 8.51 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07779077328258599		[learning rate: 0.00045504]
	Learning Rate: 0.000455043
	LOSS [training: 0.07779077328258599 | validation: 0.06416913126276333]
	TIME [epoch: 8.51 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08329968321386663		[learning rate: 0.00045339]
	Learning Rate: 0.000453392
	LOSS [training: 0.08329968321386663 | validation: 0.09577588613904772]
	TIME [epoch: 8.53 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08446092796135377		[learning rate: 0.00045175]
	Learning Rate: 0.000451746
	LOSS [training: 0.08446092796135377 | validation: 0.0582378526772931]
	TIME [epoch: 8.51 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08332196673436856		[learning rate: 0.00045011]
	Learning Rate: 0.000450107
	LOSS [training: 0.08332196673436856 | validation: 0.07286280536774233]
	TIME [epoch: 8.5 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08410464061857965		[learning rate: 0.00044847]
	Learning Rate: 0.000448474
	LOSS [training: 0.08410464061857965 | validation: 0.06349977809152092]
	TIME [epoch: 8.5 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07426284054903999		[learning rate: 0.00044685]
	Learning Rate: 0.000446846
	LOSS [training: 0.07426284054903999 | validation: 0.11943235903416086]
	TIME [epoch: 8.52 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07228139491382199		[learning rate: 0.00044522]
	Learning Rate: 0.000445224
	LOSS [training: 0.07228139491382199 | validation: 0.055846989477575465]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_956.pth
	Model improved!!!
EPOCH 957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11961181968083352		[learning rate: 0.00044361]
	Learning Rate: 0.000443609
	LOSS [training: 0.11961181968083352 | validation: 0.09704395784621603]
	TIME [epoch: 8.51 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08370316899381822		[learning rate: 0.000442]
	Learning Rate: 0.000441999
	LOSS [training: 0.08370316899381822 | validation: 0.18463409764102273]
	TIME [epoch: 8.5 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0966538704909288		[learning rate: 0.00044039]
	Learning Rate: 0.000440395
	LOSS [training: 0.0966538704909288 | validation: 0.09000569610002057]
	TIME [epoch: 8.52 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09937257074197807		[learning rate: 0.0004388]
	Learning Rate: 0.000438797
	LOSS [training: 0.09937257074197807 | validation: 0.05923399168025825]
	TIME [epoch: 8.52 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07656840110826593		[learning rate: 0.0004372]
	Learning Rate: 0.000437204
	LOSS [training: 0.07656840110826593 | validation: 0.08888036576402938]
	TIME [epoch: 8.5 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07051073332387883		[learning rate: 0.00043562]
	Learning Rate: 0.000435617
	LOSS [training: 0.07051073332387883 | validation: 0.0686900791169277]
	TIME [epoch: 8.51 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09349925387675288		[learning rate: 0.00043404]
	Learning Rate: 0.000434037
	LOSS [training: 0.09349925387675288 | validation: 0.06706115100848836]
	TIME [epoch: 8.51 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07179477764967701		[learning rate: 0.00043246]
	Learning Rate: 0.000432461
	LOSS [training: 0.07179477764967701 | validation: 0.059933117857000506]
	TIME [epoch: 8.53 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07022403164432174		[learning rate: 0.00043089]
	Learning Rate: 0.000430892
	LOSS [training: 0.07022403164432174 | validation: 0.07089314074824643]
	TIME [epoch: 8.5 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08087760064250951		[learning rate: 0.00042933]
	Learning Rate: 0.000429328
	LOSS [training: 0.08087760064250951 | validation: 0.05947189639908457]
	TIME [epoch: 8.5 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07404290315809073		[learning rate: 0.00042777]
	Learning Rate: 0.00042777
	LOSS [training: 0.07404290315809073 | validation: 0.0632124253827617]
	TIME [epoch: 8.5 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07043628330830012		[learning rate: 0.00042622]
	Learning Rate: 0.000426218
	LOSS [training: 0.07043628330830012 | validation: 0.07209261809175148]
	TIME [epoch: 8.53 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06773042579230691		[learning rate: 0.00042467]
	Learning Rate: 0.000424671
	LOSS [training: 0.06773042579230691 | validation: 0.060080883990365416]
	TIME [epoch: 8.5 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07164405671072424		[learning rate: 0.00042313]
	Learning Rate: 0.00042313
	LOSS [training: 0.07164405671072424 | validation: 0.056977870537284286]
	TIME [epoch: 8.5 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0795272283517613		[learning rate: 0.00042159]
	Learning Rate: 0.000421594
	LOSS [training: 0.0795272283517613 | validation: 0.060821671914643854]
	TIME [epoch: 8.5 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.069472414084978		[learning rate: 0.00042006]
	Learning Rate: 0.000420064
	LOSS [training: 0.069472414084978 | validation: 0.06201703941708819]
	TIME [epoch: 8.53 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0776688580570557		[learning rate: 0.00041854]
	Learning Rate: 0.00041854
	LOSS [training: 0.0776688580570557 | validation: 0.0854735760372248]
	TIME [epoch: 8.5 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07392110392839046		[learning rate: 0.00041702]
	Learning Rate: 0.000417021
	LOSS [training: 0.07392110392839046 | validation: 0.060973590550427045]
	TIME [epoch: 8.5 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07790189594696142		[learning rate: 0.00041551]
	Learning Rate: 0.000415508
	LOSS [training: 0.07790189594696142 | validation: 0.10227116265343641]
	TIME [epoch: 8.5 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07890665827274156		[learning rate: 0.000414]
	Learning Rate: 0.000414
	LOSS [training: 0.07890665827274156 | validation: 0.07265466631665679]
	TIME [epoch: 8.52 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08827777366837117		[learning rate: 0.0004125]
	Learning Rate: 0.000412497
	LOSS [training: 0.08827777366837117 | validation: 0.07488347629490907]
	TIME [epoch: 8.51 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07990001573512337		[learning rate: 0.000411]
	Learning Rate: 0.000411
	LOSS [training: 0.07990001573512337 | validation: 0.09058394694234692]
	TIME [epoch: 8.5 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08307028056310214		[learning rate: 0.00040951]
	Learning Rate: 0.000409509
	LOSS [training: 0.08307028056310214 | validation: 0.07910092113687806]
	TIME [epoch: 8.5 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0705783106844314		[learning rate: 0.00040802]
	Learning Rate: 0.000408023
	LOSS [training: 0.0705783106844314 | validation: 0.05067997038060184]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_980.pth
	Model improved!!!
EPOCH 981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06454108292448779		[learning rate: 0.00040654]
	Learning Rate: 0.000406542
	LOSS [training: 0.06454108292448779 | validation: 0.08407371707208827]
	TIME [epoch: 8.53 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07893991669981557		[learning rate: 0.00040507]
	Learning Rate: 0.000405067
	LOSS [training: 0.07893991669981557 | validation: 0.07597649739015182]
	TIME [epoch: 8.51 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08019061606959901		[learning rate: 0.0004036]
	Learning Rate: 0.000403597
	LOSS [training: 0.08019061606959901 | validation: 0.06302071267454754]
	TIME [epoch: 8.5 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08316517101382173		[learning rate: 0.00040213]
	Learning Rate: 0.000402132
	LOSS [training: 0.08316517101382173 | validation: 0.07249214301285423]
	TIME [epoch: 8.5 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06778549576224088		[learning rate: 0.00040067]
	Learning Rate: 0.000400672
	LOSS [training: 0.06778549576224088 | validation: 0.07776889323819412]
	TIME [epoch: 8.53 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06876199070856104		[learning rate: 0.00039922]
	Learning Rate: 0.000399218
	LOSS [training: 0.06876199070856104 | validation: 0.07278092586219698]
	TIME [epoch: 8.5 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07339156318611886		[learning rate: 0.00039777]
	Learning Rate: 0.00039777
	LOSS [training: 0.07339156318611886 | validation: 0.06833883158245867]
	TIME [epoch: 8.5 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10069123359818744		[learning rate: 0.00039633]
	Learning Rate: 0.000396326
	LOSS [training: 0.10069123359818744 | validation: 0.1655986408951225]
	TIME [epoch: 8.5 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07501895488751067		[learning rate: 0.00039489]
	Learning Rate: 0.000394888
	LOSS [training: 0.07501895488751067 | validation: 0.06901920757745392]
	TIME [epoch: 8.53 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08510984610180201		[learning rate: 0.00039345]
	Learning Rate: 0.000393455
	LOSS [training: 0.08510984610180201 | validation: 0.09545862201290267]
	TIME [epoch: 8.51 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08446647114242375		[learning rate: 0.00039203]
	Learning Rate: 0.000392027
	LOSS [training: 0.08446647114242375 | validation: 0.07530193459006791]
	TIME [epoch: 8.5 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06640123160184899		[learning rate: 0.0003906]
	Learning Rate: 0.000390604
	LOSS [training: 0.06640123160184899 | validation: 0.0766788154999753]
	TIME [epoch: 8.5 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10340550840525342		[learning rate: 0.00038919]
	Learning Rate: 0.000389187
	LOSS [training: 0.10340550840525342 | validation: 0.07290284800359655]
	TIME [epoch: 8.52 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06965399970460462		[learning rate: 0.00038777]
	Learning Rate: 0.000387774
	LOSS [training: 0.06965399970460462 | validation: 0.06952834284644904]
	TIME [epoch: 8.52 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08834893598310083		[learning rate: 0.00038637]
	Learning Rate: 0.000386367
	LOSS [training: 0.08834893598310083 | validation: 0.08885054350529034]
	TIME [epoch: 8.49 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.072961504811317		[learning rate: 0.00038496]
	Learning Rate: 0.000384965
	LOSS [training: 0.072961504811317 | validation: 0.05840987528073004]
	TIME [epoch: 8.5 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08617464707079317		[learning rate: 0.00038357]
	Learning Rate: 0.000383568
	LOSS [training: 0.08617464707079317 | validation: 0.07877715706434404]
	TIME [epoch: 8.51 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09414683158577894		[learning rate: 0.00038218]
	Learning Rate: 0.000382176
	LOSS [training: 0.09414683158577894 | validation: 0.06178374290387976]
	TIME [epoch: 8.52 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06761314747167946		[learning rate: 0.00038079]
	Learning Rate: 0.000380789
	LOSS [training: 0.06761314747167946 | validation: 0.09921912367272183]
	TIME [epoch: 8.5 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08737367362828023		[learning rate: 0.00037941]
	Learning Rate: 0.000379407
	LOSS [training: 0.08737367362828023 | validation: 0.06503358251710933]
	TIME [epoch: 8.51 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07015135251275752		[learning rate: 0.00037803]
	Learning Rate: 0.00037803
	LOSS [training: 0.07015135251275752 | validation: 0.05425896626907339]
	TIME [epoch: 8.51 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06629204561020069		[learning rate: 0.00037666]
	Learning Rate: 0.000376658
	LOSS [training: 0.06629204561020069 | validation: 0.07099697424401599]
	TIME [epoch: 8.53 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0736729321532736		[learning rate: 0.00037529]
	Learning Rate: 0.000375291
	LOSS [training: 0.0736729321532736 | validation: 0.09218056471488467]
	TIME [epoch: 8.5 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07598125015626067		[learning rate: 0.00037393]
	Learning Rate: 0.000373929
	LOSS [training: 0.07598125015626067 | validation: 0.06433014708158705]
	TIME [epoch: 8.51 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07729408056909572		[learning rate: 0.00037257]
	Learning Rate: 0.000372572
	LOSS [training: 0.07729408056909572 | validation: 0.09511776556928926]
	TIME [epoch: 8.51 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08123541142421947		[learning rate: 0.00037122]
	Learning Rate: 0.00037122
	LOSS [training: 0.08123541142421947 | validation: 0.14622312788122652]
	TIME [epoch: 8.53 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08913567292557482		[learning rate: 0.00036987]
	Learning Rate: 0.000369873
	LOSS [training: 0.08913567292557482 | validation: 0.07054677241136503]
	TIME [epoch: 8.51 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06671721755715321		[learning rate: 0.00036853]
	Learning Rate: 0.000368531
	LOSS [training: 0.06671721755715321 | validation: 0.0835003177003392]
	TIME [epoch: 8.51 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07946440184717182		[learning rate: 0.00036719]
	Learning Rate: 0.000367193
	LOSS [training: 0.07946440184717182 | validation: 0.06298150516958474]
	TIME [epoch: 8.5 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06221993172583682		[learning rate: 0.00036586]
	Learning Rate: 0.000365861
	LOSS [training: 0.06221993172583682 | validation: 0.07098822933992449]
	TIME [epoch: 8.51 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08393147323863255		[learning rate: 0.00036453]
	Learning Rate: 0.000364533
	LOSS [training: 0.08393147323863255 | validation: 0.0699202102707454]
	TIME [epoch: 8.51 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07504291208595223		[learning rate: 0.00036321]
	Learning Rate: 0.00036321
	LOSS [training: 0.07504291208595223 | validation: 0.06893533528933779]
	TIME [epoch: 8.5 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07418619392957491		[learning rate: 0.00036189]
	Learning Rate: 0.000361892
	LOSS [training: 0.07418619392957491 | validation: 0.07186674057538275]
	TIME [epoch: 8.5 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06759822512080854		[learning rate: 0.00036058]
	Learning Rate: 0.000360579
	LOSS [training: 0.06759822512080854 | validation: 0.06934535082098497]
	TIME [epoch: 8.51 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0749475765301435		[learning rate: 0.00035927]
	Learning Rate: 0.00035927
	LOSS [training: 0.0749475765301435 | validation: 0.06684675390693431]
	TIME [epoch: 8.52 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06469980160289876		[learning rate: 0.00035797]
	Learning Rate: 0.000357966
	LOSS [training: 0.06469980160289876 | validation: 0.07166330623580552]
	TIME [epoch: 8.5 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07130664899142473		[learning rate: 0.00035667]
	Learning Rate: 0.000356667
	LOSS [training: 0.07130664899142473 | validation: 0.06144784037337481]
	TIME [epoch: 8.5 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06823546844217634		[learning rate: 0.00035537]
	Learning Rate: 0.000355373
	LOSS [training: 0.06823546844217634 | validation: 0.07646354710950354]
	TIME [epoch: 8.5 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07418187976487073		[learning rate: 0.00035408]
	Learning Rate: 0.000354083
	LOSS [training: 0.07418187976487073 | validation: 0.0680520899063019]
	TIME [epoch: 8.53 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06765242422681517		[learning rate: 0.0003528]
	Learning Rate: 0.000352798
	LOSS [training: 0.06765242422681517 | validation: 0.07106635844706263]
	TIME [epoch: 8.5 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07613165807677862		[learning rate: 0.00035152]
	Learning Rate: 0.000351518
	LOSS [training: 0.07613165807677862 | validation: 0.0917550260193718]
	TIME [epoch: 8.5 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07661286568127443		[learning rate: 0.00035024]
	Learning Rate: 0.000350242
	LOSS [training: 0.07661286568127443 | validation: 0.07504627899770294]
	TIME [epoch: 8.5 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07357727042761546		[learning rate: 0.00034897]
	Learning Rate: 0.000348971
	LOSS [training: 0.07357727042761546 | validation: 0.05121265805093098]
	TIME [epoch: 8.53 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06693208397640753		[learning rate: 0.0003477]
	Learning Rate: 0.000347705
	LOSS [training: 0.06693208397640753 | validation: 0.05822027546054429]
	TIME [epoch: 8.5 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07634652074778443		[learning rate: 0.00034644]
	Learning Rate: 0.000346443
	LOSS [training: 0.07634652074778443 | validation: 0.08992722965217764]
	TIME [epoch: 8.51 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07471063698505237		[learning rate: 0.00034519]
	Learning Rate: 0.000345186
	LOSS [training: 0.07471063698505237 | validation: 0.06789459413421592]
	TIME [epoch: 8.51 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061786480737803615		[learning rate: 0.00034393]
	Learning Rate: 0.000343933
	LOSS [training: 0.061786480737803615 | validation: 0.08929100831722851]
	TIME [epoch: 8.52 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08479714397511473		[learning rate: 0.00034268]
	Learning Rate: 0.000342685
	LOSS [training: 0.08479714397511473 | validation: 0.07224273873679962]
	TIME [epoch: 8.51 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07680355221906628		[learning rate: 0.00034144]
	Learning Rate: 0.000341441
	LOSS [training: 0.07680355221906628 | validation: 0.08305376498569775]
	TIME [epoch: 8.5 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09655252027897847		[learning rate: 0.0003402]
	Learning Rate: 0.000340202
	LOSS [training: 0.09655252027897847 | validation: 0.06107986795212919]
	TIME [epoch: 8.5 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07109563053722968		[learning rate: 0.00033897]
	Learning Rate: 0.000338967
	LOSS [training: 0.07109563053722968 | validation: 0.08151751325138064]
	TIME [epoch: 8.51 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07615545005496407		[learning rate: 0.00033774]
	Learning Rate: 0.000337737
	LOSS [training: 0.07615545005496407 | validation: 0.06635763535187386]
	TIME [epoch: 8.51 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07235308875030588		[learning rate: 0.00033651]
	Learning Rate: 0.000336512
	LOSS [training: 0.07235308875030588 | validation: 0.058427117939085685]
	TIME [epoch: 8.49 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06640644996110089		[learning rate: 0.00033529]
	Learning Rate: 0.00033529
	LOSS [training: 0.06640644996110089 | validation: 0.1075873684840678]
	TIME [epoch: 8.5 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09254154361631288		[learning rate: 0.00033407]
	Learning Rate: 0.000334074
	LOSS [training: 0.09254154361631288 | validation: 0.07305241163810816]
	TIME [epoch: 8.5 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06776833092779552		[learning rate: 0.00033286]
	Learning Rate: 0.000332861
	LOSS [training: 0.06776833092779552 | validation: 0.07225241204049479]
	TIME [epoch: 8.52 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06423536393880717		[learning rate: 0.00033165]
	Learning Rate: 0.000331653
	LOSS [training: 0.06423536393880717 | validation: 0.06064851350040587]
	TIME [epoch: 8.5 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07811088172228357		[learning rate: 0.00033045]
	Learning Rate: 0.00033045
	LOSS [training: 0.07811088172228357 | validation: 0.07608601389777615]
	TIME [epoch: 8.49 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06801256577581236		[learning rate: 0.00032925]
	Learning Rate: 0.00032925
	LOSS [training: 0.06801256577581236 | validation: 0.07414704454248076]
	TIME [epoch: 8.5 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06362302141405873		[learning rate: 0.00032806]
	Learning Rate: 0.000328056
	LOSS [training: 0.06362302141405873 | validation: 0.06390472383278005]
	TIME [epoch: 8.52 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08581223301965264		[learning rate: 0.00032686]
	Learning Rate: 0.000326865
	LOSS [training: 0.08581223301965264 | validation: 0.05225877776506088]
	TIME [epoch: 8.5 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06326135875653185		[learning rate: 0.00032568]
	Learning Rate: 0.000325679
	LOSS [training: 0.06326135875653185 | validation: 0.0618880678133413]
	TIME [epoch: 8.49 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07346380820825464		[learning rate: 0.0003245]
	Learning Rate: 0.000324497
	LOSS [training: 0.07346380820825464 | validation: 0.08000350893756666]
	TIME [epoch: 8.49 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0799491517424192		[learning rate: 0.00032332]
	Learning Rate: 0.000323319
	LOSS [training: 0.0799491517424192 | validation: 0.08707430418670067]
	TIME [epoch: 8.52 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07979796943473702		[learning rate: 0.00032215]
	Learning Rate: 0.000322146
	LOSS [training: 0.07979796943473702 | validation: 0.08225936656205983]
	TIME [epoch: 8.5 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0973754759536857		[learning rate: 0.00032098]
	Learning Rate: 0.000320977
	LOSS [training: 0.0973754759536857 | validation: 0.06538977391976503]
	TIME [epoch: 8.49 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0788270672750696		[learning rate: 0.00031981]
	Learning Rate: 0.000319812
	LOSS [training: 0.0788270672750696 | validation: 0.05675466825604682]
	TIME [epoch: 8.5 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07410952358006025		[learning rate: 0.00031865]
	Learning Rate: 0.000318651
	LOSS [training: 0.07410952358006025 | validation: 0.09343051820421276]
	TIME [epoch: 8.5 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09361165966249227		[learning rate: 0.0003175]
	Learning Rate: 0.000317495
	LOSS [training: 0.09361165966249227 | validation: 0.06994662397566424]
	TIME [epoch: 8.52 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06709205487567392		[learning rate: 0.00031634]
	Learning Rate: 0.000316343
	LOSS [training: 0.06709205487567392 | validation: 0.06473384744058293]
	TIME [epoch: 8.49 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07808949596190806		[learning rate: 0.00031519]
	Learning Rate: 0.000315195
	LOSS [training: 0.07808949596190806 | validation: 0.10335130152485825]
	TIME [epoch: 8.5 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07217930558529148		[learning rate: 0.00031405]
	Learning Rate: 0.000314051
	LOSS [training: 0.07217930558529148 | validation: 0.068461710333302]
	TIME [epoch: 8.5 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06284487370564312		[learning rate: 0.00031291]
	Learning Rate: 0.000312911
	LOSS [training: 0.06284487370564312 | validation: 0.06896188394091649]
	TIME [epoch: 8.52 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061606347521811364		[learning rate: 0.00031178]
	Learning Rate: 0.000311776
	LOSS [training: 0.061606347521811364 | validation: 0.07413523796965113]
	TIME [epoch: 8.5 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07197906451578676		[learning rate: 0.00031064]
	Learning Rate: 0.000310644
	LOSS [training: 0.07197906451578676 | validation: 0.0599295042199996]
	TIME [epoch: 8.5 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0712042241822892		[learning rate: 0.00030952]
	Learning Rate: 0.000309517
	LOSS [training: 0.0712042241822892 | validation: 0.06458075742800193]
	TIME [epoch: 8.5 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06608552992530743		[learning rate: 0.00030839]
	Learning Rate: 0.000308394
	LOSS [training: 0.06608552992530743 | validation: 0.08731565881699188]
	TIME [epoch: 8.53 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07326176267981141		[learning rate: 0.00030727]
	Learning Rate: 0.000307274
	LOSS [training: 0.07326176267981141 | validation: 0.10860860960347943]
	TIME [epoch: 8.5 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06926204381054019		[learning rate: 0.00030616]
	Learning Rate: 0.000306159
	LOSS [training: 0.06926204381054019 | validation: 0.050717022652888466]
	TIME [epoch: 8.49 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06689828741023492		[learning rate: 0.00030505]
	Learning Rate: 0.000305048
	LOSS [training: 0.06689828741023492 | validation: 0.10796796255063784]
	TIME [epoch: 8.49 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08842435762549009		[learning rate: 0.00030394]
	Learning Rate: 0.000303941
	LOSS [training: 0.08842435762549009 | validation: 0.0639220786913115]
	TIME [epoch: 8.51 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06199215036098517		[learning rate: 0.00030284]
	Learning Rate: 0.000302838
	LOSS [training: 0.06199215036098517 | validation: 0.07024070459617837]
	TIME [epoch: 8.51 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06963568313272729		[learning rate: 0.00030174]
	Learning Rate: 0.000301739
	LOSS [training: 0.06963568313272729 | validation: 0.0661314342994255]
	TIME [epoch: 8.51 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06873014596424312		[learning rate: 0.00030064]
	Learning Rate: 0.000300644
	LOSS [training: 0.06873014596424312 | validation: 0.06270034600541018]
	TIME [epoch: 8.5 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07415524950649832		[learning rate: 0.00029955]
	Learning Rate: 0.000299553
	LOSS [training: 0.07415524950649832 | validation: 0.05535267354209261]
	TIME [epoch: 8.5 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06053340750963517		[learning rate: 0.00029847]
	Learning Rate: 0.000298466
	LOSS [training: 0.06053340750963517 | validation: 0.06275156576072226]
	TIME [epoch: 8.52 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06551807158242538		[learning rate: 0.00029738]
	Learning Rate: 0.000297383
	LOSS [training: 0.06551807158242538 | validation: 0.06768072644182727]
	TIME [epoch: 8.5 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06344509098483497		[learning rate: 0.0002963]
	Learning Rate: 0.000296304
	LOSS [training: 0.06344509098483497 | validation: 0.09791547531055955]
	TIME [epoch: 8.5 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0793272302373567		[learning rate: 0.00029523]
	Learning Rate: 0.000295228
	LOSS [training: 0.0793272302373567 | validation: 0.08411194649514242]
	TIME [epoch: 8.5 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07557379664117395		[learning rate: 0.00029416]
	Learning Rate: 0.000294157
	LOSS [training: 0.07557379664117395 | validation: 0.06715894518701604]
	TIME [epoch: 8.52 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09734549217614111		[learning rate: 0.00029309]
	Learning Rate: 0.000293089
	LOSS [training: 0.09734549217614111 | validation: 0.07403560008341406]
	TIME [epoch: 8.49 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08428851531964754		[learning rate: 0.00029203]
	Learning Rate: 0.000292026
	LOSS [training: 0.08428851531964754 | validation: 0.061682556495067604]
	TIME [epoch: 8.5 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07331190873242652		[learning rate: 0.00029097]
	Learning Rate: 0.000290966
	LOSS [training: 0.07331190873242652 | validation: 0.06713532157422775]
	TIME [epoch: 8.49 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0726796440226034		[learning rate: 0.00028991]
	Learning Rate: 0.00028991
	LOSS [training: 0.0726796440226034 | validation: 0.09486631760649518]
	TIME [epoch: 8.52 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07410426376955687		[learning rate: 0.00028886]
	Learning Rate: 0.000288858
	LOSS [training: 0.07410426376955687 | validation: 0.06734295416363767]
	TIME [epoch: 8.5 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08700321861478841		[learning rate: 0.00028781]
	Learning Rate: 0.00028781
	LOSS [training: 0.08700321861478841 | validation: 0.059268316665568456]
	TIME [epoch: 8.49 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06699884053457347		[learning rate: 0.00028677]
	Learning Rate: 0.000286765
	LOSS [training: 0.06699884053457347 | validation: 0.050568424270489604]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_1077.pth
	Model improved!!!
EPOCH 1078/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06944404753841871		[learning rate: 0.00028572]
	Learning Rate: 0.000285724
	LOSS [training: 0.06944404753841871 | validation: 0.09225431311058008]
	TIME [epoch: 8.52 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07943084528107222		[learning rate: 0.00028469]
	Learning Rate: 0.000284688
	LOSS [training: 0.07943084528107222 | validation: 0.07651052553571423]
	TIME [epoch: 8.5 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06481949173284991		[learning rate: 0.00028365]
	Learning Rate: 0.000283654
	LOSS [training: 0.06481949173284991 | validation: 0.05495977067117643]
	TIME [epoch: 8.5 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06609200609590134		[learning rate: 0.00028263]
	Learning Rate: 0.000282625
	LOSS [training: 0.06609200609590134 | validation: 0.06375951651434031]
	TIME [epoch: 8.5 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06419166830100911		[learning rate: 0.0002816]
	Learning Rate: 0.000281599
	LOSS [training: 0.06419166830100911 | validation: 0.07117182154841235]
	TIME [epoch: 8.51 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05989648636077417		[learning rate: 0.00028058]
	Learning Rate: 0.000280577
	LOSS [training: 0.05989648636077417 | validation: 0.07274807055987537]
	TIME [epoch: 8.51 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07321133111768183		[learning rate: 0.00027956]
	Learning Rate: 0.000279559
	LOSS [training: 0.07321133111768183 | validation: 0.06273914445751516]
	TIME [epoch: 8.5 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10870208658977462		[learning rate: 0.00027854]
	Learning Rate: 0.000278545
	LOSS [training: 0.10870208658977462 | validation: 0.0651275143104712]
	TIME [epoch: 8.5 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06492041461614485		[learning rate: 0.00027753]
	Learning Rate: 0.000277534
	LOSS [training: 0.06492041461614485 | validation: 0.06013743902099652]
	TIME [epoch: 8.5 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0633947720009004		[learning rate: 0.00027653]
	Learning Rate: 0.000276527
	LOSS [training: 0.0633947720009004 | validation: 0.06071313025814787]
	TIME [epoch: 8.53 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06575010820946484		[learning rate: 0.00027552]
	Learning Rate: 0.000275523
	LOSS [training: 0.06575010820946484 | validation: 0.07902941760821906]
	TIME [epoch: 8.5 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07701112487800668		[learning rate: 0.00027452]
	Learning Rate: 0.000274523
	LOSS [training: 0.07701112487800668 | validation: 0.05483322765442673]
	TIME [epoch: 8.5 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06270943620999986		[learning rate: 0.00027353]
	Learning Rate: 0.000273527
	LOSS [training: 0.06270943620999986 | validation: 0.0657769618307975]
	TIME [epoch: 8.5 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06880131653543753		[learning rate: 0.00027253]
	Learning Rate: 0.000272534
	LOSS [training: 0.06880131653543753 | validation: 0.07867916267051717]
	TIME [epoch: 8.53 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06055831019737521		[learning rate: 0.00027155]
	Learning Rate: 0.000271545
	LOSS [training: 0.06055831019737521 | validation: 0.06109881204684821]
	TIME [epoch: 8.5 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07857605902597885		[learning rate: 0.00027056]
	Learning Rate: 0.00027056
	LOSS [training: 0.07857605902597885 | validation: 0.0688094266819472]
	TIME [epoch: 8.5 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07045411749715969		[learning rate: 0.00026958]
	Learning Rate: 0.000269578
	LOSS [training: 0.07045411749715969 | validation: 0.0755631764646115]
	TIME [epoch: 8.5 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062989046673561		[learning rate: 0.0002686]
	Learning Rate: 0.0002686
	LOSS [training: 0.062989046673561 | validation: 0.08166075198577535]
	TIME [epoch: 8.51 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0771839383228734		[learning rate: 0.00026762]
	Learning Rate: 0.000267625
	LOSS [training: 0.0771839383228734 | validation: 0.06285492133222843]
	TIME [epoch: 8.5 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06683053372829541		[learning rate: 0.00026665]
	Learning Rate: 0.000266654
	LOSS [training: 0.06683053372829541 | validation: 0.08165609077601427]
	TIME [epoch: 8.5 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07426091631510137		[learning rate: 0.00026569]
	Learning Rate: 0.000265686
	LOSS [training: 0.07426091631510137 | validation: 0.06967225127730031]
	TIME [epoch: 8.5 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07585171456522558		[learning rate: 0.00026472]
	Learning Rate: 0.000264722
	LOSS [training: 0.07585171456522558 | validation: 0.0675414061098375]
	TIME [epoch: 8.51 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06551314975897854		[learning rate: 0.00026376]
	Learning Rate: 0.000263761
	LOSS [training: 0.06551314975897854 | validation: 0.05310725620393905]
	TIME [epoch: 8.51 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06209102823607474		[learning rate: 0.0002628]
	Learning Rate: 0.000262804
	LOSS [training: 0.06209102823607474 | validation: 0.05551069135653612]
	TIME [epoch: 8.5 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08683862857626687		[learning rate: 0.00026185]
	Learning Rate: 0.00026185
	LOSS [training: 0.08683862857626687 | validation: 0.07335397694647494]
	TIME [epoch: 8.5 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0682567580287679		[learning rate: 0.0002609]
	Learning Rate: 0.0002609
	LOSS [training: 0.0682567580287679 | validation: 0.09296659523325419]
	TIME [epoch: 8.5 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.066434031831274		[learning rate: 0.00025995]
	Learning Rate: 0.000259953
	LOSS [training: 0.066434031831274 | validation: 0.06464113056230397]
	TIME [epoch: 8.52 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07211342720851374		[learning rate: 0.00025901]
	Learning Rate: 0.00025901
	LOSS [training: 0.07211342720851374 | validation: 0.07663596081404984]
	TIME [epoch: 8.5 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06057322426932308		[learning rate: 0.00025807]
	Learning Rate: 0.00025807
	LOSS [training: 0.06057322426932308 | validation: 0.0870085176994572]
	TIME [epoch: 8.49 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06737089411876243		[learning rate: 0.00025713]
	Learning Rate: 0.000257133
	LOSS [training: 0.06737089411876243 | validation: 0.07314601232585359]
	TIME [epoch: 8.49 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06573054567216179		[learning rate: 0.0002562]
	Learning Rate: 0.0002562
	LOSS [training: 0.06573054567216179 | validation: 0.0690773835455156]
	TIME [epoch: 8.53 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06848626376233366		[learning rate: 0.00025527]
	Learning Rate: 0.00025527
	LOSS [training: 0.06848626376233366 | validation: 0.12247377966883152]
	TIME [epoch: 8.49 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07372526847025157		[learning rate: 0.00025434]
	Learning Rate: 0.000254344
	LOSS [training: 0.07372526847025157 | validation: 0.05996971500693728]
	TIME [epoch: 8.49 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07302614089635678		[learning rate: 0.00025342]
	Learning Rate: 0.000253421
	LOSS [training: 0.07302614089635678 | validation: 0.0743011362942439]
	TIME [epoch: 8.49 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0766575249312173		[learning rate: 0.0002525]
	Learning Rate: 0.000252501
	LOSS [training: 0.0766575249312173 | validation: 0.08265840204811159]
	TIME [epoch: 8.51 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06244915487739343		[learning rate: 0.00025158]
	Learning Rate: 0.000251585
	LOSS [training: 0.06244915487739343 | validation: 0.07050465275612773]
	TIME [epoch: 8.5 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07769910986129566		[learning rate: 0.00025067]
	Learning Rate: 0.000250672
	LOSS [training: 0.07769910986129566 | validation: 0.07573778454457175]
	TIME [epoch: 8.49 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06559257953457114		[learning rate: 0.00024976]
	Learning Rate: 0.000249762
	LOSS [training: 0.06559257953457114 | validation: 0.07800628296464455]
	TIME [epoch: 8.49 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07058901868638826		[learning rate: 0.00024886]
	Learning Rate: 0.000248856
	LOSS [training: 0.07058901868638826 | validation: 0.05568856140647331]
	TIME [epoch: 8.51 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0628912083102255		[learning rate: 0.00024795]
	Learning Rate: 0.000247952
	LOSS [training: 0.0628912083102255 | validation: 0.06929958053557628]
	TIME [epoch: 8.5 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0678910088248614		[learning rate: 0.00024705]
	Learning Rate: 0.000247053
	LOSS [training: 0.0678910088248614 | validation: 0.07038155408241495]
	TIME [epoch: 8.51 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06886098731186993		[learning rate: 0.00024616]
	Learning Rate: 0.000246156
	LOSS [training: 0.06886098731186993 | validation: 0.052245027356674544]
	TIME [epoch: 8.5 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06476646180008025		[learning rate: 0.00024526]
	Learning Rate: 0.000245263
	LOSS [training: 0.06476646180008025 | validation: 0.06048494570307019]
	TIME [epoch: 8.5 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05912117607173217		[learning rate: 0.00024437]
	Learning Rate: 0.000244373
	LOSS [training: 0.05912117607173217 | validation: 0.06497177851001057]
	TIME [epoch: 8.52 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06864646878182264		[learning rate: 0.00024349]
	Learning Rate: 0.000243486
	LOSS [training: 0.06864646878182264 | validation: 0.07390746109762747]
	TIME [epoch: 8.5 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06589034538333786		[learning rate: 0.0002426]
	Learning Rate: 0.000242602
	LOSS [training: 0.06589034538333786 | validation: 0.05585698291968849]
	TIME [epoch: 8.49 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06272746717343206		[learning rate: 0.00024172]
	Learning Rate: 0.000241722
	LOSS [training: 0.06272746717343206 | validation: 0.06912270676896587]
	TIME [epoch: 8.5 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06885733806419167		[learning rate: 0.00024084]
	Learning Rate: 0.000240845
	LOSS [training: 0.06885733806419167 | validation: 0.09057166734297385]
	TIME [epoch: 8.52 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06470981617815072		[learning rate: 0.00023997]
	Learning Rate: 0.000239971
	LOSS [training: 0.06470981617815072 | validation: 0.06343721339607125]
	TIME [epoch: 8.5 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0704790549409091		[learning rate: 0.0002391]
	Learning Rate: 0.0002391
	LOSS [training: 0.0704790549409091 | validation: 0.058212124230082166]
	TIME [epoch: 8.49 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07896444494355066		[learning rate: 0.00023823]
	Learning Rate: 0.000238232
	LOSS [training: 0.07896444494355066 | validation: 0.062334856830016536]
	TIME [epoch: 8.49 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08566130454279614		[learning rate: 0.00023737]
	Learning Rate: 0.000237367
	LOSS [training: 0.08566130454279614 | validation: 0.07194670308796311]
	TIME [epoch: 8.51 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07299690457368935		[learning rate: 0.00023651]
	Learning Rate: 0.000236506
	LOSS [training: 0.07299690457368935 | validation: 0.05781456754493279]
	TIME [epoch: 8.49 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06351163805314783		[learning rate: 0.00023565]
	Learning Rate: 0.000235648
	LOSS [training: 0.06351163805314783 | validation: 0.06445075130866691]
	TIME [epoch: 8.49 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05638308473704616		[learning rate: 0.00023479]
	Learning Rate: 0.000234793
	LOSS [training: 0.05638308473704616 | validation: 0.06136173736403526]
	TIME [epoch: 8.49 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07205483113158043		[learning rate: 0.00023394]
	Learning Rate: 0.00023394
	LOSS [training: 0.07205483113158043 | validation: 0.07298781333613066]
	TIME [epoch: 8.51 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06748984999601228		[learning rate: 0.00023309]
	Learning Rate: 0.000233091
	LOSS [training: 0.06748984999601228 | validation: 0.08897379871506039]
	TIME [epoch: 8.51 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06451381226336389		[learning rate: 0.00023225]
	Learning Rate: 0.000232246
	LOSS [training: 0.06451381226336389 | validation: 0.06075353088414481]
	TIME [epoch: 8.5 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06924062040172181		[learning rate: 0.0002314]
	Learning Rate: 0.000231403
	LOSS [training: 0.06924062040172181 | validation: 0.08858154329940578]
	TIME [epoch: 8.49 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06675296423947573		[learning rate: 0.00023056]
	Learning Rate: 0.000230563
	LOSS [training: 0.06675296423947573 | validation: 0.06214973440447859]
	TIME [epoch: 8.49 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0639163340058381		[learning rate: 0.00022973]
	Learning Rate: 0.000229726
	LOSS [training: 0.0639163340058381 | validation: 0.08601241708767349]
	TIME [epoch: 8.52 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09721983388614015		[learning rate: 0.00022889]
	Learning Rate: 0.000228893
	LOSS [training: 0.09721983388614015 | validation: 0.06635218515213884]
	TIME [epoch: 8.5 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06359114183316397		[learning rate: 0.00022806]
	Learning Rate: 0.000228062
	LOSS [training: 0.06359114183316397 | validation: 0.05821365281518377]
	TIME [epoch: 8.5 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0739046667827176		[learning rate: 0.00022723]
	Learning Rate: 0.000227234
	LOSS [training: 0.0739046667827176 | validation: 0.05919621767635215]
	TIME [epoch: 8.49 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06116256867139016		[learning rate: 0.00022641]
	Learning Rate: 0.00022641
	LOSS [training: 0.06116256867139016 | validation: 0.0643023057761406]
	TIME [epoch: 8.53 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06545504107027353		[learning rate: 0.00022559]
	Learning Rate: 0.000225588
	LOSS [training: 0.06545504107027353 | validation: 0.061281387425079624]
	TIME [epoch: 8.49 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07684301020824649		[learning rate: 0.00022477]
	Learning Rate: 0.000224769
	LOSS [training: 0.07684301020824649 | validation: 0.098427029085341]
	TIME [epoch: 8.49 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07053568589096519		[learning rate: 0.00022395]
	Learning Rate: 0.000223954
	LOSS [training: 0.07053568589096519 | validation: 0.08283536950693796]
	TIME [epoch: 8.49 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06280753961148892		[learning rate: 0.00022314]
	Learning Rate: 0.000223141
	LOSS [training: 0.06280753961148892 | validation: 0.09232970227207307]
	TIME [epoch: 8.51 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0687447108600989		[learning rate: 0.00022233]
	Learning Rate: 0.000222331
	LOSS [training: 0.0687447108600989 | validation: 0.05153313316435637]
	TIME [epoch: 8.5 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0748829494940115		[learning rate: 0.00022152]
	Learning Rate: 0.000221524
	LOSS [training: 0.0748829494940115 | validation: 0.06802813542664965]
	TIME [epoch: 8.49 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06274176509881574		[learning rate: 0.00022072]
	Learning Rate: 0.00022072
	LOSS [training: 0.06274176509881574 | validation: 0.05485670836260607]
	TIME [epoch: 8.49 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05589711654641514		[learning rate: 0.00021992]
	Learning Rate: 0.000219919
	LOSS [training: 0.05589711654641514 | validation: 0.06022594050501713]
	TIME [epoch: 8.51 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07207588834742143		[learning rate: 0.00021912]
	Learning Rate: 0.000219121
	LOSS [training: 0.07207588834742143 | validation: 0.06510341398914522]
	TIME [epoch: 8.5 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06484701881909358		[learning rate: 0.00021833]
	Learning Rate: 0.000218326
	LOSS [training: 0.06484701881909358 | validation: 0.055558910464613365]
	TIME [epoch: 8.5 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059890508258325106		[learning rate: 0.00021753]
	Learning Rate: 0.000217534
	LOSS [training: 0.059890508258325106 | validation: 0.039598619448537174]
	TIME [epoch: 8.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_1153.pth
	Model improved!!!
EPOCH 1154/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07253578675834058		[learning rate: 0.00021674]
	Learning Rate: 0.000216744
	LOSS [training: 0.07253578675834058 | validation: 0.08264244717526405]
	TIME [epoch: 8.5 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0717220205560059		[learning rate: 0.00021596]
	Learning Rate: 0.000215958
	LOSS [training: 0.0717220205560059 | validation: 0.07241234429631835]
	TIME [epoch: 8.52 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05792127517697891		[learning rate: 0.00021517]
	Learning Rate: 0.000215174
	LOSS [training: 0.05792127517697891 | validation: 0.051655092349392265]
	TIME [epoch: 8.49 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06057689119875853		[learning rate: 0.00021439]
	Learning Rate: 0.000214393
	LOSS [training: 0.06057689119875853 | validation: 0.05425132529541217]
	TIME [epoch: 8.5 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057512907946867364		[learning rate: 0.00021361]
	Learning Rate: 0.000213615
	LOSS [training: 0.057512907946867364 | validation: 0.09171366215021935]
	TIME [epoch: 8.5 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06724019395212975		[learning rate: 0.00021284]
	Learning Rate: 0.00021284
	LOSS [training: 0.06724019395212975 | validation: 0.0704812080271011]
	TIME [epoch: 8.52 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06173396198436541		[learning rate: 0.00021207]
	Learning Rate: 0.000212067
	LOSS [training: 0.06173396198436541 | validation: 0.06580731490749378]
	TIME [epoch: 8.5 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05377727096843582		[learning rate: 0.0002113]
	Learning Rate: 0.000211298
	LOSS [training: 0.05377727096843582 | validation: 0.05745692889231628]
	TIME [epoch: 8.5 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05598390684874438		[learning rate: 0.00021053]
	Learning Rate: 0.000210531
	LOSS [training: 0.05598390684874438 | validation: 0.06909785445777461]
	TIME [epoch: 8.5 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06060791525295648		[learning rate: 0.00020977]
	Learning Rate: 0.000209767
	LOSS [training: 0.06060791525295648 | validation: 0.07429498796283779]
	TIME [epoch: 8.52 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07139333995035066		[learning rate: 0.00020901]
	Learning Rate: 0.000209006
	LOSS [training: 0.07139333995035066 | validation: 0.06947143973652761]
	TIME [epoch: 8.5 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07017031496666545		[learning rate: 0.00020825]
	Learning Rate: 0.000208247
	LOSS [training: 0.07017031496666545 | validation: 0.06304284897923138]
	TIME [epoch: 8.5 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058191871866232		[learning rate: 0.00020749]
	Learning Rate: 0.000207491
	LOSS [training: 0.058191871866232 | validation: 0.062069632229608866]
	TIME [epoch: 8.5 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06047176802871851		[learning rate: 0.00020674]
	Learning Rate: 0.000206738
	LOSS [training: 0.06047176802871851 | validation: 0.057557356351203036]
	TIME [epoch: 8.51 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06677318546916526		[learning rate: 0.00020599]
	Learning Rate: 0.000205988
	LOSS [training: 0.06677318546916526 | validation: 0.0830511264017802]
	TIME [epoch: 8.5 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07848781055846836		[learning rate: 0.00020524]
	Learning Rate: 0.000205241
	LOSS [training: 0.07848781055846836 | validation: 0.14179115801455155]
	TIME [epoch: 8.49 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07907090014366527		[learning rate: 0.0002045]
	Learning Rate: 0.000204496
	LOSS [training: 0.07907090014366527 | validation: 0.06847045329888227]
	TIME [epoch: 8.5 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0689935263352365		[learning rate: 0.00020375]
	Learning Rate: 0.000203754
	LOSS [training: 0.0689935263352365 | validation: 0.054787491931244936]
	TIME [epoch: 8.51 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07162797974025852		[learning rate: 0.00020301]
	Learning Rate: 0.000203014
	LOSS [training: 0.07162797974025852 | validation: 0.05800959858850376]
	TIME [epoch: 8.53 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05899133402476041		[learning rate: 0.00020228]
	Learning Rate: 0.000202277
	LOSS [training: 0.05899133402476041 | validation: 0.058781776018908716]
	TIME [epoch: 8.49 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07857061866770995		[learning rate: 0.00020154]
	Learning Rate: 0.000201543
	LOSS [training: 0.07857061866770995 | validation: 0.058222986477841264]
	TIME [epoch: 8.49 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06427621775705142		[learning rate: 0.00020081]
	Learning Rate: 0.000200812
	LOSS [training: 0.06427621775705142 | validation: 0.05937456539774316]
	TIME [epoch: 8.5 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07006963764395574		[learning rate: 0.00020008]
	Learning Rate: 0.000200083
	LOSS [training: 0.07006963764395574 | validation: 0.055930087017583466]
	TIME [epoch: 8.52 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06587497611140046		[learning rate: 0.00019936]
	Learning Rate: 0.000199357
	LOSS [training: 0.06587497611140046 | validation: 0.06450841618020077]
	TIME [epoch: 8.49 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06501603837406315		[learning rate: 0.00019863]
	Learning Rate: 0.000198634
	LOSS [training: 0.06501603837406315 | validation: 0.07008535414102653]
	TIME [epoch: 8.49 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061022855914843376		[learning rate: 0.00019791]
	Learning Rate: 0.000197913
	LOSS [training: 0.061022855914843376 | validation: 0.07439438536318094]
	TIME [epoch: 8.49 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06835880495775715		[learning rate: 0.00019719]
	Learning Rate: 0.000197194
	LOSS [training: 0.06835880495775715 | validation: 0.057841773128218345]
	TIME [epoch: 8.52 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06856962493234493		[learning rate: 0.00019648]
	Learning Rate: 0.000196479
	LOSS [training: 0.06856962493234493 | validation: 0.0704724149643762]
	TIME [epoch: 8.5 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07669633639361664		[learning rate: 0.00019577]
	Learning Rate: 0.000195766
	LOSS [training: 0.07669633639361664 | validation: 0.06165888313095198]
	TIME [epoch: 8.5 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06693524831909903		[learning rate: 0.00019506]
	Learning Rate: 0.000195055
	LOSS [training: 0.06693524831909903 | validation: 0.07425204015238647]
	TIME [epoch: 8.5 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062437719429476124		[learning rate: 0.00019435]
	Learning Rate: 0.000194347
	LOSS [training: 0.062437719429476124 | validation: 0.06548004555767523]
	TIME [epoch: 8.52 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06743340109261639		[learning rate: 0.00019364]
	Learning Rate: 0.000193642
	LOSS [training: 0.06743340109261639 | validation: 0.05487763141016161]
	TIME [epoch: 8.51 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06477023780491595		[learning rate: 0.00019294]
	Learning Rate: 0.000192939
	LOSS [training: 0.06477023780491595 | validation: 0.07234965063741391]
	TIME [epoch: 8.49 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06947184584173897		[learning rate: 0.00019224]
	Learning Rate: 0.000192239
	LOSS [training: 0.06947184584173897 | validation: 0.06047436034792775]
	TIME [epoch: 8.5 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06411163589263222		[learning rate: 0.00019154]
	Learning Rate: 0.000191542
	LOSS [training: 0.06411163589263222 | validation: 0.0500567359986559]
	TIME [epoch: 8.5 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05391797408923289		[learning rate: 0.00019085]
	Learning Rate: 0.000190846
	LOSS [training: 0.05391797408923289 | validation: 0.060220609508106177]
	TIME [epoch: 8.51 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07188936273182393		[learning rate: 0.00019015]
	Learning Rate: 0.000190154
	LOSS [training: 0.07188936273182393 | validation: 0.062067204810941044]
	TIME [epoch: 8.5 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06257360527593667		[learning rate: 0.00018946]
	Learning Rate: 0.000189464
	LOSS [training: 0.06257360527593667 | validation: 0.06696752579424703]
	TIME [epoch: 8.49 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06022001799415255		[learning rate: 0.00018878]
	Learning Rate: 0.000188776
	LOSS [training: 0.06022001799415255 | validation: 0.0515505854379691]
	TIME [epoch: 8.51 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0646159229297283		[learning rate: 0.00018809]
	Learning Rate: 0.000188091
	LOSS [training: 0.0646159229297283 | validation: 0.06986000268805453]
	TIME [epoch: 8.52 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07169227739072395		[learning rate: 0.00018741]
	Learning Rate: 0.000187409
	LOSS [training: 0.07169227739072395 | validation: 0.07172443367712536]
	TIME [epoch: 8.5 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05919931130722943		[learning rate: 0.00018673]
	Learning Rate: 0.000186729
	LOSS [training: 0.05919931130722943 | validation: 0.06851471037380533]
	TIME [epoch: 8.49 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05965382493968817		[learning rate: 0.00018605]
	Learning Rate: 0.000186051
	LOSS [training: 0.05965382493968817 | validation: 0.06763423877395922]
	TIME [epoch: 8.49 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06581745778670564		[learning rate: 0.00018538]
	Learning Rate: 0.000185376
	LOSS [training: 0.06581745778670564 | validation: 0.06552569618721543]
	TIME [epoch: 8.52 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05930650729526142		[learning rate: 0.0001847]
	Learning Rate: 0.000184703
	LOSS [training: 0.05930650729526142 | validation: 0.060620615371307605]
	TIME [epoch: 8.5 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05802622844749779		[learning rate: 0.00018403]
	Learning Rate: 0.000184033
	LOSS [training: 0.05802622844749779 | validation: 0.06706599003859286]
	TIME [epoch: 8.49 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06936277855768849		[learning rate: 0.00018336]
	Learning Rate: 0.000183365
	LOSS [training: 0.06936277855768849 | validation: 0.05985767706082214]
	TIME [epoch: 8.5 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05968215601128261		[learning rate: 0.0001827]
	Learning Rate: 0.000182699
	LOSS [training: 0.05968215601128261 | validation: 0.07612100983537548]
	TIME [epoch: 8.51 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06516135116730701		[learning rate: 0.00018204]
	Learning Rate: 0.000182036
	LOSS [training: 0.06516135116730701 | validation: 0.05647671714639794]
	TIME [epoch: 8.5 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058513945962845135		[learning rate: 0.00018138]
	Learning Rate: 0.000181376
	LOSS [training: 0.058513945962845135 | validation: 0.05399459763518256]
	TIME [epoch: 8.5 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06922047056060303		[learning rate: 0.00018072]
	Learning Rate: 0.000180717
	LOSS [training: 0.06922047056060303 | validation: 0.05809470444918207]
	TIME [epoch: 8.5 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07053215398025167		[learning rate: 0.00018006]
	Learning Rate: 0.000180062
	LOSS [training: 0.07053215398025167 | validation: 0.05786123013748374]
	TIME [epoch: 8.51 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061536211727515375		[learning rate: 0.00017941]
	Learning Rate: 0.000179408
	LOSS [training: 0.061536211727515375 | validation: 0.07519965650676905]
	TIME [epoch: 8.52 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06373823444872766		[learning rate: 0.00017876]
	Learning Rate: 0.000178757
	LOSS [training: 0.06373823444872766 | validation: 0.06543938277676611]
	TIME [epoch: 8.5 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07009215411671223		[learning rate: 0.00017811]
	Learning Rate: 0.000178108
	LOSS [training: 0.07009215411671223 | validation: 0.06638519432451087]
	TIME [epoch: 8.5 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06433529348069787		[learning rate: 0.00017746]
	Learning Rate: 0.000177462
	LOSS [training: 0.06433529348069787 | validation: 0.05840220202945373]
	TIME [epoch: 8.5 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058175861083459735		[learning rate: 0.00017682]
	Learning Rate: 0.000176818
	LOSS [training: 0.058175861083459735 | validation: 0.05585252648219789]
	TIME [epoch: 8.52 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051844327266214726		[learning rate: 0.00017618]
	Learning Rate: 0.000176176
	LOSS [training: 0.051844327266214726 | validation: 0.04955209617882925]
	TIME [epoch: 8.49 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060800951391971045		[learning rate: 0.00017554]
	Learning Rate: 0.000175537
	LOSS [training: 0.060800951391971045 | validation: 0.05656087992132206]
	TIME [epoch: 8.49 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06266352288638896		[learning rate: 0.0001749]
	Learning Rate: 0.0001749
	LOSS [training: 0.06266352288638896 | validation: 0.05063440381135622]
	TIME [epoch: 8.49 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055738744256633686		[learning rate: 0.00017427]
	Learning Rate: 0.000174265
	LOSS [training: 0.055738744256633686 | validation: 0.05513266894432173]
	TIME [epoch: 8.52 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05694547169771723		[learning rate: 0.00017363]
	Learning Rate: 0.000173633
	LOSS [training: 0.05694547169771723 | validation: 0.07064657480438352]
	TIME [epoch: 8.49 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06982087976932369		[learning rate: 0.000173]
	Learning Rate: 0.000173003
	LOSS [training: 0.06982087976932369 | validation: 0.05520995879778277]
	TIME [epoch: 8.5 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05901007529372519		[learning rate: 0.00017237]
	Learning Rate: 0.000172375
	LOSS [training: 0.05901007529372519 | validation: 0.05938153618203118]
	TIME [epoch: 8.5 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06615896772650925		[learning rate: 0.00017175]
	Learning Rate: 0.000171749
	LOSS [training: 0.06615896772650925 | validation: 0.05781690275855088]
	TIME [epoch: 8.51 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05876291930185157		[learning rate: 0.00017113]
	Learning Rate: 0.000171126
	LOSS [training: 0.05876291930185157 | validation: 0.05559582633788303]
	TIME [epoch: 8.5 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056907021599078636		[learning rate: 0.0001705]
	Learning Rate: 0.000170505
	LOSS [training: 0.056907021599078636 | validation: 0.05552392538505893]
	TIME [epoch: 8.5 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061045032221599835		[learning rate: 0.00016989]
	Learning Rate: 0.000169886
	LOSS [training: 0.061045032221599835 | validation: 0.0560737387113797]
	TIME [epoch: 8.5 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06535525978733374		[learning rate: 0.00016927]
	Learning Rate: 0.00016927
	LOSS [training: 0.06535525978733374 | validation: 0.0636180250290216]
	TIME [epoch: 8.51 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06381278401734733		[learning rate: 0.00016866]
	Learning Rate: 0.000168655
	LOSS [training: 0.06381278401734733 | validation: 0.06405890763388938]
	TIME [epoch: 8.51 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056712476799004555		[learning rate: 0.00016804]
	Learning Rate: 0.000168043
	LOSS [training: 0.056712476799004555 | validation: 0.06443518655012764]
	TIME [epoch: 8.49 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058663711385598095		[learning rate: 0.00016743]
	Learning Rate: 0.000167433
	LOSS [training: 0.058663711385598095 | validation: 0.05555284285702371]
	TIME [epoch: 8.49 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05634257840631342		[learning rate: 0.00016683]
	Learning Rate: 0.000166826
	LOSS [training: 0.05634257840631342 | validation: 0.050389621940003106]
	TIME [epoch: 8.49 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062134182828061046		[learning rate: 0.00016622]
	Learning Rate: 0.00016622
	LOSS [training: 0.062134182828061046 | validation: 0.06321018914936524]
	TIME [epoch: 8.52 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06002470763907734		[learning rate: 0.00016562]
	Learning Rate: 0.000165617
	LOSS [training: 0.06002470763907734 | validation: 0.06253560258212326]
	TIME [epoch: 8.49 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05738527795242958		[learning rate: 0.00016502]
	Learning Rate: 0.000165016
	LOSS [training: 0.05738527795242958 | validation: 0.06397429910356253]
	TIME [epoch: 8.49 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05256729539679304		[learning rate: 0.00016442]
	Learning Rate: 0.000164417
	LOSS [training: 0.05256729539679304 | validation: 0.06110461095826665]
	TIME [epoch: 8.5 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057017617705370546		[learning rate: 0.00016382]
	Learning Rate: 0.000163821
	LOSS [training: 0.057017617705370546 | validation: 0.07139759924149512]
	TIME [epoch: 8.52 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06467916806158594		[learning rate: 0.00016323]
	Learning Rate: 0.000163226
	LOSS [training: 0.06467916806158594 | validation: 0.04906168368169942]
	TIME [epoch: 8.5 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05511146670587508		[learning rate: 0.00016263]
	Learning Rate: 0.000162634
	LOSS [training: 0.05511146670587508 | validation: 0.09144396539247546]
	TIME [epoch: 8.49 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07693768374290658		[learning rate: 0.00016204]
	Learning Rate: 0.000162043
	LOSS [training: 0.07693768374290658 | validation: 0.05860913736485571]
	TIME [epoch: 8.49 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05706151875485125		[learning rate: 0.00016146]
	Learning Rate: 0.000161455
	LOSS [training: 0.05706151875485125 | validation: 0.053305165494691914]
	TIME [epoch: 8.51 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056692290412265686		[learning rate: 0.00016087]
	Learning Rate: 0.000160869
	LOSS [training: 0.056692290412265686 | validation: 0.05498634132416086]
	TIME [epoch: 8.51 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059004618735380224		[learning rate: 0.00016029]
	Learning Rate: 0.000160286
	LOSS [training: 0.059004618735380224 | validation: 0.0660715265331866]
	TIME [epoch: 8.5 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06600559740671955		[learning rate: 0.0001597]
	Learning Rate: 0.000159704
	LOSS [training: 0.06600559740671955 | validation: 0.0530683231689422]
	TIME [epoch: 8.49 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06106586932456989		[learning rate: 0.00015912]
	Learning Rate: 0.000159124
	LOSS [training: 0.06106586932456989 | validation: 0.056108481241941954]
	TIME [epoch: 8.49 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05513711423317056		[learning rate: 0.00015855]
	Learning Rate: 0.000158547
	LOSS [training: 0.05513711423317056 | validation: 0.061306083327653846]
	TIME [epoch: 8.51 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06205750724724587		[learning rate: 0.00015797]
	Learning Rate: 0.000157972
	LOSS [training: 0.06205750724724587 | validation: 0.05784628760799512]
	TIME [epoch: 8.49 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06529090073272555		[learning rate: 0.0001574]
	Learning Rate: 0.000157398
	LOSS [training: 0.06529090073272555 | validation: 0.08636863737290533]
	TIME [epoch: 8.49 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061017131667552224		[learning rate: 0.00015683]
	Learning Rate: 0.000156827
	LOSS [training: 0.061017131667552224 | validation: 0.09044177040528986]
	TIME [epoch: 8.49 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0724416069048881		[learning rate: 0.00015626]
	Learning Rate: 0.000156258
	LOSS [training: 0.0724416069048881 | validation: 0.06569735126478385]
	TIME [epoch: 8.52 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06428371843190771		[learning rate: 0.00015569]
	Learning Rate: 0.000155691
	LOSS [training: 0.06428371843190771 | validation: 0.051065469766839094]
	TIME [epoch: 8.49 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05588558453929322		[learning rate: 0.00015513]
	Learning Rate: 0.000155126
	LOSS [training: 0.05588558453929322 | validation: 0.058053577264844454]
	TIME [epoch: 8.5 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061222732687882274		[learning rate: 0.00015456]
	Learning Rate: 0.000154563
	LOSS [training: 0.061222732687882274 | validation: 0.06161930350000994]
	TIME [epoch: 8.5 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06412601853769619		[learning rate: 0.000154]
	Learning Rate: 0.000154002
	LOSS [training: 0.06412601853769619 | validation: 0.070612567132725]
	TIME [epoch: 8.52 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05882784277530177		[learning rate: 0.00015344]
	Learning Rate: 0.000153443
	LOSS [training: 0.05882784277530177 | validation: 0.05721315046021995]
	TIME [epoch: 8.5 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05294469983949287		[learning rate: 0.00015289]
	Learning Rate: 0.000152886
	LOSS [training: 0.05294469983949287 | validation: 0.054027158164152246]
	TIME [epoch: 8.5 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06419924203620617		[learning rate: 0.00015233]
	Learning Rate: 0.000152331
	LOSS [training: 0.06419924203620617 | validation: 0.060456341503919465]
	TIME [epoch: 8.5 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06144785994426503		[learning rate: 0.00015178]
	Learning Rate: 0.000151779
	LOSS [training: 0.06144785994426503 | validation: 0.04911460703879811]
	TIME [epoch: 8.51 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06466232559887455		[learning rate: 0.00015123]
	Learning Rate: 0.000151228
	LOSS [training: 0.06466232559887455 | validation: 0.04480485374299466]
	TIME [epoch: 8.51 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06143828809078065		[learning rate: 0.00015068]
	Learning Rate: 0.000150679
	LOSS [training: 0.06143828809078065 | validation: 0.06883627890081456]
	TIME [epoch: 8.5 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06152588410291476		[learning rate: 0.00015013]
	Learning Rate: 0.000150132
	LOSS [training: 0.06152588410291476 | validation: 0.05605108874671541]
	TIME [epoch: 8.5 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059612092578122014		[learning rate: 0.00014959]
	Learning Rate: 0.000149587
	LOSS [training: 0.059612092578122014 | validation: 0.05398231813434988]
	TIME [epoch: 8.5 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05997990912184685		[learning rate: 0.00014904]
	Learning Rate: 0.000149044
	LOSS [training: 0.05997990912184685 | validation: 0.06238455604338588]
	TIME [epoch: 8.52 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06329134495948431		[learning rate: 0.0001485]
	Learning Rate: 0.000148504
	LOSS [training: 0.06329134495948431 | validation: 0.06820145412890448]
	TIME [epoch: 8.5 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06398126501196771		[learning rate: 0.00014796]
	Learning Rate: 0.000147965
	LOSS [training: 0.06398126501196771 | validation: 0.06747201326981743]
	TIME [epoch: 8.49 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05797080404061039		[learning rate: 0.00014743]
	Learning Rate: 0.000147428
	LOSS [training: 0.05797080404061039 | validation: 0.05570474990402849]
	TIME [epoch: 8.5 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059639041680727235		[learning rate: 0.00014689]
	Learning Rate: 0.000146893
	LOSS [training: 0.059639041680727235 | validation: 0.056860511198384686]
	TIME [epoch: 8.52 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06538973112727262		[learning rate: 0.00014636]
	Learning Rate: 0.00014636
	LOSS [training: 0.06538973112727262 | validation: 0.0633430200546465]
	TIME [epoch: 8.49 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06223646609228915		[learning rate: 0.00014583]
	Learning Rate: 0.000145828
	LOSS [training: 0.06223646609228915 | validation: 0.05626980062282554]
	TIME [epoch: 8.5 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059457293343304664		[learning rate: 0.0001453]
	Learning Rate: 0.000145299
	LOSS [training: 0.059457293343304664 | validation: 0.05703464759279698]
	TIME [epoch: 8.49 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06208952640600281		[learning rate: 0.00014477]
	Learning Rate: 0.000144772
	LOSS [training: 0.06208952640600281 | validation: 0.05992674940852706]
	TIME [epoch: 8.52 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052990258637086604		[learning rate: 0.00014425]
	Learning Rate: 0.000144247
	LOSS [training: 0.052990258637086604 | validation: 0.056656106482264365]
	TIME [epoch: 8.5 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059965868745572214		[learning rate: 0.00014372]
	Learning Rate: 0.000143723
	LOSS [training: 0.059965868745572214 | validation: 0.06915268425454127]
	TIME [epoch: 8.5 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0565556708113533		[learning rate: 0.0001432]
	Learning Rate: 0.000143201
	LOSS [training: 0.0565556708113533 | validation: 0.06179340517628981]
	TIME [epoch: 8.5 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060390242016223575		[learning rate: 0.00014268]
	Learning Rate: 0.000142682
	LOSS [training: 0.060390242016223575 | validation: 0.059503561618812664]
	TIME [epoch: 8.51 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05718482213731344		[learning rate: 0.00014216]
	Learning Rate: 0.000142164
	LOSS [training: 0.05718482213731344 | validation: 0.0441285411037302]
	TIME [epoch: 8.51 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058932083755668795		[learning rate: 0.00014165]
	Learning Rate: 0.000141648
	LOSS [training: 0.058932083755668795 | validation: 0.06505320849210601]
	TIME [epoch: 8.5 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06048903203058378		[learning rate: 0.00014113]
	Learning Rate: 0.000141134
	LOSS [training: 0.06048903203058378 | validation: 0.06816154998012962]
	TIME [epoch: 8.5 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07023061841894314		[learning rate: 0.00014062]
	Learning Rate: 0.000140622
	LOSS [training: 0.07023061841894314 | validation: 0.06887038859868148]
	TIME [epoch: 8.5 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06241210018891251		[learning rate: 0.00014011]
	Learning Rate: 0.000140112
	LOSS [training: 0.06241210018891251 | validation: 0.060621011869841326]
	TIME [epoch: 8.51 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06334487659219712		[learning rate: 0.0001396]
	Learning Rate: 0.000139603
	LOSS [training: 0.06334487659219712 | validation: 0.06212022263504068]
	TIME [epoch: 8.5 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060029523895226554		[learning rate: 0.0001391]
	Learning Rate: 0.000139096
	LOSS [training: 0.060029523895226554 | validation: 0.06537858425021983]
	TIME [epoch: 8.5 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06044457417268836		[learning rate: 0.00013859]
	Learning Rate: 0.000138592
	LOSS [training: 0.06044457417268836 | validation: 0.04872882564818111]
	TIME [epoch: 8.5 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06533415246053412		[learning rate: 0.00013809]
	Learning Rate: 0.000138089
	LOSS [training: 0.06533415246053412 | validation: 0.05878695535116348]
	TIME [epoch: 8.53 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05864361694167699		[learning rate: 0.00013759]
	Learning Rate: 0.000137587
	LOSS [training: 0.05864361694167699 | validation: 0.05937870418061446]
	TIME [epoch: 8.5 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0679558095504309		[learning rate: 0.00013709]
	Learning Rate: 0.000137088
	LOSS [training: 0.0679558095504309 | validation: 0.06705325298449719]
	TIME [epoch: 8.5 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05783146526908034		[learning rate: 0.00013659]
	Learning Rate: 0.000136591
	LOSS [training: 0.05783146526908034 | validation: 0.06185679843538745]
	TIME [epoch: 8.5 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058830371899700265		[learning rate: 0.00013609]
	Learning Rate: 0.000136095
	LOSS [training: 0.058830371899700265 | validation: 0.04054840102096049]
	TIME [epoch: 8.52 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053985894274914924		[learning rate: 0.0001356]
	Learning Rate: 0.000135601
	LOSS [training: 0.053985894274914924 | validation: 0.05232316382547176]
	TIME [epoch: 8.5 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06225941679585782		[learning rate: 0.00013511]
	Learning Rate: 0.000135109
	LOSS [training: 0.06225941679585782 | validation: 0.05336301622367215]
	TIME [epoch: 8.5 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058772442704571895		[learning rate: 0.00013462]
	Learning Rate: 0.000134619
	LOSS [training: 0.058772442704571895 | validation: 0.056252102840772054]
	TIME [epoch: 8.49 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05388659798330855		[learning rate: 0.00013413]
	Learning Rate: 0.00013413
	LOSS [training: 0.05388659798330855 | validation: 0.06065139314549432]
	TIME [epoch: 8.52 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057776996197780206		[learning rate: 0.00013364]
	Learning Rate: 0.000133643
	LOSS [training: 0.057776996197780206 | validation: 0.06761566656404816]
	TIME [epoch: 8.51 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0550932357568674		[learning rate: 0.00013316]
	Learning Rate: 0.000133158
	LOSS [training: 0.0550932357568674 | validation: 0.048228764198417526]
	TIME [epoch: 8.49 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054665691902404		[learning rate: 0.00013268]
	Learning Rate: 0.000132675
	LOSS [training: 0.054665691902404 | validation: 0.05987636988344257]
	TIME [epoch: 8.5 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05775780117314213		[learning rate: 0.00013219]
	Learning Rate: 0.000132194
	LOSS [training: 0.05775780117314213 | validation: 0.04965595291791805]
	TIME [epoch: 8.5 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0574909643608135		[learning rate: 0.00013171]
	Learning Rate: 0.000131714
	LOSS [training: 0.0574909643608135 | validation: 0.06649957856218851]
	TIME [epoch: 8.51 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06584264065958609		[learning rate: 0.00013124]
	Learning Rate: 0.000131236
	LOSS [training: 0.06584264065958609 | validation: 0.06109238747855261]
	TIME [epoch: 8.49 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058699002397472		[learning rate: 0.00013076]
	Learning Rate: 0.00013076
	LOSS [training: 0.058699002397472 | validation: 0.06434912953860783]
	TIME [epoch: 8.5 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06851130079602968		[learning rate: 0.00013029]
	Learning Rate: 0.000130285
	LOSS [training: 0.06851130079602968 | validation: 0.053010909011630344]
	TIME [epoch: 8.5 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06442936008258353		[learning rate: 0.00012981]
	Learning Rate: 0.000129812
	LOSS [training: 0.06442936008258353 | validation: 0.05782296539487818]
	TIME [epoch: 8.52 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060197034407088436		[learning rate: 0.00012934]
	Learning Rate: 0.000129341
	LOSS [training: 0.060197034407088436 | validation: 0.04917798723471592]
	TIME [epoch: 8.5 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05677522066535493		[learning rate: 0.00012887]
	Learning Rate: 0.000128872
	LOSS [training: 0.05677522066535493 | validation: 0.05977141954205219]
	TIME [epoch: 8.49 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05531722982989763		[learning rate: 0.0001284]
	Learning Rate: 0.000128404
	LOSS [training: 0.05531722982989763 | validation: 0.05378830040427305]
	TIME [epoch: 8.49 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0558462345903866		[learning rate: 0.00012794]
	Learning Rate: 0.000127938
	LOSS [training: 0.0558462345903866 | validation: 0.05864613252142367]
	TIME [epoch: 8.52 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05612431157526526		[learning rate: 0.00012747]
	Learning Rate: 0.000127474
	LOSS [training: 0.05612431157526526 | validation: 0.05556865597000674]
	TIME [epoch: 8.49 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05989151162445052		[learning rate: 0.00012701]
	Learning Rate: 0.000127011
	LOSS [training: 0.05989151162445052 | validation: 0.06033386734442209]
	TIME [epoch: 8.49 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058805255568516256		[learning rate: 0.00012655]
	Learning Rate: 0.00012655
	LOSS [training: 0.058805255568516256 | validation: 0.05218919588867329]
	TIME [epoch: 8.5 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055004378393828456		[learning rate: 0.00012609]
	Learning Rate: 0.000126091
	LOSS [training: 0.055004378393828456 | validation: 0.07555396952020887]
	TIME [epoch: 8.51 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06084969893789112		[learning rate: 0.00012563]
	Learning Rate: 0.000125633
	LOSS [training: 0.06084969893789112 | validation: 0.06402937808727113]
	TIME [epoch: 8.51 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053213792546023285		[learning rate: 0.00012518]
	Learning Rate: 0.000125178
	LOSS [training: 0.053213792546023285 | validation: 0.06117729341567907]
	TIME [epoch: 8.5 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06430388375501357		[learning rate: 0.00012472]
	Learning Rate: 0.000124723
	LOSS [training: 0.06430388375501357 | validation: 0.0482482110958357]
	TIME [epoch: 8.5 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05884623813948795		[learning rate: 0.00012427]
	Learning Rate: 0.000124271
	LOSS [training: 0.05884623813948795 | validation: 0.07031500903384702]
	TIME [epoch: 8.5 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06070144860814469		[learning rate: 0.00012382]
	Learning Rate: 0.00012382
	LOSS [training: 0.06070144860814469 | validation: 0.06501501017315578]
	TIME [epoch: 8.52 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06566122874688353		[learning rate: 0.00012337]
	Learning Rate: 0.00012337
	LOSS [training: 0.06566122874688353 | validation: 0.07198812796450799]
	TIME [epoch: 8.49 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06085613361889421		[learning rate: 0.00012292]
	Learning Rate: 0.000122923
	LOSS [training: 0.06085613361889421 | validation: 0.056825030479042804]
	TIME [epoch: 8.49 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05871974655760194		[learning rate: 0.00012248]
	Learning Rate: 0.000122476
	LOSS [training: 0.05871974655760194 | validation: 0.06710363384181336]
	TIME [epoch: 8.5 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06173884684776396		[learning rate: 0.00012203]
	Learning Rate: 0.000122032
	LOSS [training: 0.06173884684776396 | validation: 0.05450290892232583]
	TIME [epoch: 8.52 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0583754089917505		[learning rate: 0.00012159]
	Learning Rate: 0.000121589
	LOSS [training: 0.0583754089917505 | validation: 0.07003197896616661]
	TIME [epoch: 8.5 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061781733023032206		[learning rate: 0.00012115]
	Learning Rate: 0.000121148
	LOSS [training: 0.061781733023032206 | validation: 0.0710309464383497]
	TIME [epoch: 8.51 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06575485914636263		[learning rate: 0.00012071]
	Learning Rate: 0.000120708
	LOSS [training: 0.06575485914636263 | validation: 0.0709674985255592]
	TIME [epoch: 8.49 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06758951279600894		[learning rate: 0.00012027]
	Learning Rate: 0.00012027
	LOSS [training: 0.06758951279600894 | validation: 0.04782316717360461]
	TIME [epoch: 8.52 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059401143589667325		[learning rate: 0.00011983]
	Learning Rate: 0.000119834
	LOSS [training: 0.059401143589667325 | validation: 0.0473424746203725]
	TIME [epoch: 8.49 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054942483121609306		[learning rate: 0.0001194]
	Learning Rate: 0.000119399
	LOSS [training: 0.054942483121609306 | validation: 0.058291904139131726]
	TIME [epoch: 8.49 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056193625417361406		[learning rate: 0.00011897]
	Learning Rate: 0.000118966
	LOSS [training: 0.056193625417361406 | validation: 0.0536856547194855]
	TIME [epoch: 8.48 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06217895147239298		[learning rate: 0.00011853]
	Learning Rate: 0.000118534
	LOSS [training: 0.06217895147239298 | validation: 0.06433330271811052]
	TIME [epoch: 8.51 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0670871195836442		[learning rate: 0.0001181]
	Learning Rate: 0.000118104
	LOSS [training: 0.0670871195836442 | validation: 0.048857887609389125]
	TIME [epoch: 8.5 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05741951860878188		[learning rate: 0.00011767]
	Learning Rate: 0.000117675
	LOSS [training: 0.05741951860878188 | validation: 0.06604655293500243]
	TIME [epoch: 8.49 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06420771413082393		[learning rate: 0.00011725]
	Learning Rate: 0.000117248
	LOSS [training: 0.06420771413082393 | validation: 0.053756912217221335]
	TIME [epoch: 8.49 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049790359439442114		[learning rate: 0.00011682]
	Learning Rate: 0.000116822
	LOSS [training: 0.049790359439442114 | validation: 0.05743970970940017]
	TIME [epoch: 8.5 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05562154725061408		[learning rate: 0.0001164]
	Learning Rate: 0.000116398
	LOSS [training: 0.05562154725061408 | validation: 0.059114237142650745]
	TIME [epoch: 8.51 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05616578442627117		[learning rate: 0.00011598]
	Learning Rate: 0.000115976
	LOSS [training: 0.05616578442627117 | validation: 0.06229233558783592]
	TIME [epoch: 8.49 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06107552266947043		[learning rate: 0.00011556]
	Learning Rate: 0.000115555
	LOSS [training: 0.06107552266947043 | validation: 0.06483303648755248]
	TIME [epoch: 8.49 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06012351394938555		[learning rate: 0.00011514]
	Learning Rate: 0.000115136
	LOSS [training: 0.06012351394938555 | validation: 0.07116872099370684]
	TIME [epoch: 8.49 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058615931336039886		[learning rate: 0.00011472]
	Learning Rate: 0.000114718
	LOSS [training: 0.058615931336039886 | validation: 0.06415610934942373]
	TIME [epoch: 8.52 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062054565743067516		[learning rate: 0.0001143]
	Learning Rate: 0.000114302
	LOSS [training: 0.062054565743067516 | validation: 0.05679970571125144]
	TIME [epoch: 8.49 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057790380223709116		[learning rate: 0.00011389]
	Learning Rate: 0.000113887
	LOSS [training: 0.057790380223709116 | validation: 0.05407593064011428]
	TIME [epoch: 8.5 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06138277545004078		[learning rate: 0.00011347]
	Learning Rate: 0.000113474
	LOSS [training: 0.06138277545004078 | validation: 0.054200640182376386]
	TIME [epoch: 8.5 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05859888747573079		[learning rate: 0.00011306]
	Learning Rate: 0.000113062
	LOSS [training: 0.05859888747573079 | validation: 0.06247571254790375]
	TIME [epoch: 8.52 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05874316432267003		[learning rate: 0.00011265]
	Learning Rate: 0.000112651
	LOSS [training: 0.05874316432267003 | validation: 0.05855633963010231]
	TIME [epoch: 8.5 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0541508794542795		[learning rate: 0.00011224]
	Learning Rate: 0.000112243
	LOSS [training: 0.0541508794542795 | validation: 0.05536955718437736]
	TIME [epoch: 8.49 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05353224670119152		[learning rate: 0.00011184]
	Learning Rate: 0.000111835
	LOSS [training: 0.05353224670119152 | validation: 0.05155058147623711]
	TIME [epoch: 8.49 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05097005024444934		[learning rate: 0.00011143]
	Learning Rate: 0.000111429
	LOSS [training: 0.05097005024444934 | validation: 0.05547998493877732]
	TIME [epoch: 8.51 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057975983435262016		[learning rate: 0.00011103]
	Learning Rate: 0.000111025
	LOSS [training: 0.057975983435262016 | validation: 0.07041807195479124]
	TIME [epoch: 8.5 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05742310048161353		[learning rate: 0.00011062]
	Learning Rate: 0.000110622
	LOSS [training: 0.05742310048161353 | validation: 0.05274740526106246]
	TIME [epoch: 8.49 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05346441451508255		[learning rate: 0.00011022]
	Learning Rate: 0.000110221
	LOSS [training: 0.05346441451508255 | validation: 0.04720192400947916]
	TIME [epoch: 8.5 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05620731532618974		[learning rate: 0.00010982]
	Learning Rate: 0.000109821
	LOSS [training: 0.05620731532618974 | validation: 0.06306063923422423]
	TIME [epoch: 8.51 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0613101106537674		[learning rate: 0.00010942]
	Learning Rate: 0.000109422
	LOSS [training: 0.0613101106537674 | validation: 0.06534276161052233]
	TIME [epoch: 8.51 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05571013412752851		[learning rate: 0.00010903]
	Learning Rate: 0.000109025
	LOSS [training: 0.05571013412752851 | validation: 0.05739262518119877]
	TIME [epoch: 8.49 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06178257332075778		[learning rate: 0.00010863]
	Learning Rate: 0.000108629
	LOSS [training: 0.06178257332075778 | validation: 0.0521410379798879]
	TIME [epoch: 8.5 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058832186047067636		[learning rate: 0.00010824]
	Learning Rate: 0.000108235
	LOSS [training: 0.058832186047067636 | validation: 0.053881245724625826]
	TIME [epoch: 8.49 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05166755590585005		[learning rate: 0.00010784]
	Learning Rate: 0.000107842
	LOSS [training: 0.05166755590585005 | validation: 0.0621560548443718]
	TIME [epoch: 8.52 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060000618659262005		[learning rate: 0.00010745]
	Learning Rate: 0.000107451
	LOSS [training: 0.060000618659262005 | validation: 0.05443416549511508]
	TIME [epoch: 8.49 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05359496566684041		[learning rate: 0.00010706]
	Learning Rate: 0.000107061
	LOSS [training: 0.05359496566684041 | validation: 0.05733851550896782]
	TIME [epoch: 8.5 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05636788956651819		[learning rate: 0.00010667]
	Learning Rate: 0.000106673
	LOSS [training: 0.05636788956651819 | validation: 0.05890201428650766]
	TIME [epoch: 8.49 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05106142589033239		[learning rate: 0.00010629]
	Learning Rate: 0.000106285
	LOSS [training: 0.05106142589033239 | validation: 0.06856529088700747]
	TIME [epoch: 8.51 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05885442739423395		[learning rate: 0.0001059]
	Learning Rate: 0.0001059
	LOSS [training: 0.05885442739423395 | validation: 0.055324066942700964]
	TIME [epoch: 8.49 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05562756300525503		[learning rate: 0.00010552]
	Learning Rate: 0.000105515
	LOSS [training: 0.05562756300525503 | validation: 0.06010257982498579]
	TIME [epoch: 8.5 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05121210589578321		[learning rate: 0.00010513]
	Learning Rate: 0.000105132
	LOSS [training: 0.05121210589578321 | validation: 0.05324184137394432]
	TIME [epoch: 8.49 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05522070892015846		[learning rate: 0.00010475]
	Learning Rate: 0.000104751
	LOSS [training: 0.05522070892015846 | validation: 0.05356860933493833]
	TIME [epoch: 8.52 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05163633385259114		[learning rate: 0.00010437]
	Learning Rate: 0.000104371
	LOSS [training: 0.05163633385259114 | validation: 0.06534533563605346]
	TIME [epoch: 8.51 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06481615023661944		[learning rate: 0.00010399]
	Learning Rate: 0.000103992
	LOSS [training: 0.06481615023661944 | validation: 0.06418123736463759]
	TIME [epoch: 8.5 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05907308732371171		[learning rate: 0.00010361]
	Learning Rate: 0.000103615
	LOSS [training: 0.05907308732371171 | validation: 0.057538139857045166]
	TIME [epoch: 8.49 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05304545420168131		[learning rate: 0.00010324]
	Learning Rate: 0.000103239
	LOSS [training: 0.05304545420168131 | validation: 0.042348629190006426]
	TIME [epoch: 8.5 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05458058540162321		[learning rate: 0.00010286]
	Learning Rate: 0.000102864
	LOSS [training: 0.05458058540162321 | validation: 0.055491309959547624]
	TIME [epoch: 8.51 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06831628729234737		[learning rate: 0.00010249]
	Learning Rate: 0.000102491
	LOSS [training: 0.06831628729234737 | validation: 0.05442609893375047]
	TIME [epoch: 8.49 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05518852224209915		[learning rate: 0.00010212]
	Learning Rate: 0.000102119
	LOSS [training: 0.05518852224209915 | validation: 0.05620001618867172]
	TIME [epoch: 8.49 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06036566632728729		[learning rate: 0.00010175]
	Learning Rate: 0.000101748
	LOSS [training: 0.06036566632728729 | validation: 0.04673477505708933]
	TIME [epoch: 8.5 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05236227846397953		[learning rate: 0.00010138]
	Learning Rate: 0.000101379
	LOSS [training: 0.05236227846397953 | validation: 0.04869675452464471]
	TIME [epoch: 8.52 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054622478517516046		[learning rate: 0.00010101]
	Learning Rate: 0.000101011
	LOSS [training: 0.054622478517516046 | validation: 0.059082590958446785]
	TIME [epoch: 8.49 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053630636857629366		[learning rate: 0.00010064]
	Learning Rate: 0.000100644
	LOSS [training: 0.053630636857629366 | validation: 0.045532550774710634]
	TIME [epoch: 8.49 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05436221846536639		[learning rate: 0.00010028]
	Learning Rate: 0.000100279
	LOSS [training: 0.05436221846536639 | validation: 0.041645629180811106]
	TIME [epoch: 8.49 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06068224272176862		[learning rate: 9.9915e-05]
	Learning Rate: 9.99152e-05
	LOSS [training: 0.06068224272176862 | validation: 0.05684394045768736]
	TIME [epoch: 8.52 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053434147215044914		[learning rate: 9.9553e-05]
	Learning Rate: 9.95526e-05
	LOSS [training: 0.053434147215044914 | validation: 0.06500665394123793]
	TIME [epoch: 8.5 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05270640441330861		[learning rate: 9.9191e-05]
	Learning Rate: 9.91913e-05
	LOSS [training: 0.05270640441330861 | validation: 0.04758628323043684]
	TIME [epoch: 8.49 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05381880902871146		[learning rate: 9.8831e-05]
	Learning Rate: 9.88314e-05
	LOSS [training: 0.05381880902871146 | validation: 0.05148994442335398]
	TIME [epoch: 8.49 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05181590354328676		[learning rate: 9.8473e-05]
	Learning Rate: 9.84727e-05
	LOSS [training: 0.05181590354328676 | validation: 0.05315652178271103]
	TIME [epoch: 8.51 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054650314090900806		[learning rate: 9.8115e-05]
	Learning Rate: 9.81153e-05
	LOSS [training: 0.054650314090900806 | validation: 0.057251365822823]
	TIME [epoch: 8.5 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04712167685782069		[learning rate: 9.7759e-05]
	Learning Rate: 9.77592e-05
	LOSS [training: 0.04712167685782069 | validation: 0.04658139614800634]
	TIME [epoch: 8.5 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060268950006281595		[learning rate: 9.7404e-05]
	Learning Rate: 9.74045e-05
	LOSS [training: 0.060268950006281595 | validation: 0.05901814905234477]
	TIME [epoch: 8.5 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061450269578826176		[learning rate: 9.7051e-05]
	Learning Rate: 9.7051e-05
	LOSS [training: 0.061450269578826176 | validation: 0.06213472487002999]
	TIME [epoch: 8.51 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05572110939418121		[learning rate: 9.6699e-05]
	Learning Rate: 9.66988e-05
	LOSS [training: 0.05572110939418121 | validation: 0.05699845580408561]
	TIME [epoch: 8.51 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05599089789047988		[learning rate: 9.6348e-05]
	Learning Rate: 9.63479e-05
	LOSS [training: 0.05599089789047988 | validation: 0.04949789121334572]
	TIME [epoch: 8.49 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05882720697874607		[learning rate: 9.5998e-05]
	Learning Rate: 9.59982e-05
	LOSS [training: 0.05882720697874607 | validation: 0.06704229501189496]
	TIME [epoch: 8.5 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057082488335939076		[learning rate: 9.565e-05]
	Learning Rate: 9.56499e-05
	LOSS [training: 0.057082488335939076 | validation: 0.0652056107179471]
	TIME [epoch: 8.5 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05021888335363982		[learning rate: 9.5303e-05]
	Learning Rate: 9.53027e-05
	LOSS [training: 0.05021888335363982 | validation: 0.05232179515701153]
	TIME [epoch: 8.52 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059968563046833054		[learning rate: 9.4957e-05]
	Learning Rate: 9.49569e-05
	LOSS [training: 0.059968563046833054 | validation: 0.05410933124768777]
	TIME [epoch: 8.49 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05621728087028401		[learning rate: 9.4612e-05]
	Learning Rate: 9.46122e-05
	LOSS [training: 0.05621728087028401 | validation: 0.05710719663120682]
	TIME [epoch: 8.5 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06289939252246098		[learning rate: 9.4269e-05]
	Learning Rate: 9.42689e-05
	LOSS [training: 0.06289939252246098 | validation: 0.055061283068851594]
	TIME [epoch: 8.5 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057772701723160916		[learning rate: 9.3927e-05]
	Learning Rate: 9.39268e-05
	LOSS [training: 0.057772701723160916 | validation: 0.04996766785297806]
	TIME [epoch: 8.51 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05855392308081375		[learning rate: 9.3586e-05]
	Learning Rate: 9.35859e-05
	LOSS [training: 0.05855392308081375 | validation: 0.044710861636234285]
	TIME [epoch: 8.5 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055442934950834945		[learning rate: 9.3246e-05]
	Learning Rate: 9.32463e-05
	LOSS [training: 0.055442934950834945 | validation: 0.05634083741590061]
	TIME [epoch: 8.5 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05301918611736602		[learning rate: 9.2908e-05]
	Learning Rate: 9.29079e-05
	LOSS [training: 0.05301918611736602 | validation: 0.05712864553209096]
	TIME [epoch: 8.49 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0569608442393882		[learning rate: 9.2571e-05]
	Learning Rate: 9.25707e-05
	LOSS [training: 0.0569608442393882 | validation: 0.046643671910660975]
	TIME [epoch: 8.51 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05642605568996083		[learning rate: 9.2235e-05]
	Learning Rate: 9.22348e-05
	LOSS [training: 0.05642605568996083 | validation: 0.061962372194074404]
	TIME [epoch: 8.49 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061866714855834636		[learning rate: 9.19e-05]
	Learning Rate: 9.19001e-05
	LOSS [training: 0.061866714855834636 | validation: 0.04477237152681093]
	TIME [epoch: 8.49 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05835711457188728		[learning rate: 9.1567e-05]
	Learning Rate: 9.15665e-05
	LOSS [training: 0.05835711457188728 | validation: 0.059830433790026435]
	TIME [epoch: 8.49 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05812339529639511		[learning rate: 9.1234e-05]
	Learning Rate: 9.12343e-05
	LOSS [training: 0.05812339529639511 | validation: 0.05348871229829319]
	TIME [epoch: 8.5 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0608328791391344		[learning rate: 9.0903e-05]
	Learning Rate: 9.09031e-05
	LOSS [training: 0.0608328791391344 | validation: 0.05497964666564331]
	TIME [epoch: 8.52 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060603355239697655		[learning rate: 9.0573e-05]
	Learning Rate: 9.05733e-05
	LOSS [training: 0.060603355239697655 | validation: 0.054721850196426516]
	TIME [epoch: 8.48 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055388051903283955		[learning rate: 9.0245e-05]
	Learning Rate: 9.02446e-05
	LOSS [training: 0.055388051903283955 | validation: 0.057039599962567425]
	TIME [epoch: 8.5 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06489959197460018		[learning rate: 8.9917e-05]
	Learning Rate: 8.99171e-05
	LOSS [training: 0.06489959197460018 | validation: 0.05967504034843407]
	TIME [epoch: 8.49 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05211264411214778		[learning rate: 8.9591e-05]
	Learning Rate: 8.95908e-05
	LOSS [training: 0.05211264411214778 | validation: 0.04423085931264959]
	TIME [epoch: 8.51 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05352807246544801		[learning rate: 8.9266e-05]
	Learning Rate: 8.92656e-05
	LOSS [training: 0.05352807246544801 | validation: 0.054015076344331656]
	TIME [epoch: 8.49 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05665858767240269		[learning rate: 8.8942e-05]
	Learning Rate: 8.89417e-05
	LOSS [training: 0.05665858767240269 | validation: 0.06059923889639152]
	TIME [epoch: 8.5 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054921026668783304		[learning rate: 8.8619e-05]
	Learning Rate: 8.86189e-05
	LOSS [training: 0.054921026668783304 | validation: 0.05819855066988007]
	TIME [epoch: 8.49 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051426721271381315		[learning rate: 8.8297e-05]
	Learning Rate: 8.82973e-05
	LOSS [training: 0.051426721271381315 | validation: 0.05212353594122889]
	TIME [epoch: 8.52 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06090980077509674		[learning rate: 8.7977e-05]
	Learning Rate: 8.79769e-05
	LOSS [training: 0.06090980077509674 | validation: 0.05181864282668182]
	TIME [epoch: 8.49 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05298636659144731		[learning rate: 8.7658e-05]
	Learning Rate: 8.76576e-05
	LOSS [training: 0.05298636659144731 | validation: 0.04830002945967175]
	TIME [epoch: 8.5 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05350708661695734		[learning rate: 8.7339e-05]
	Learning Rate: 8.73395e-05
	LOSS [training: 0.05350708661695734 | validation: 0.050830416337158235]
	TIME [epoch: 8.5 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05588149859776627		[learning rate: 8.7023e-05]
	Learning Rate: 8.70225e-05
	LOSS [training: 0.05588149859776627 | validation: 0.060483406344961715]
	TIME [epoch: 8.52 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06837322265624757		[learning rate: 8.6707e-05]
	Learning Rate: 8.67067e-05
	LOSS [training: 0.06837322265624757 | validation: 0.058632124583925006]
	TIME [epoch: 8.5 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059525317358986155		[learning rate: 8.6392e-05]
	Learning Rate: 8.63921e-05
	LOSS [training: 0.059525317358986155 | validation: 0.05257015134705328]
	TIME [epoch: 8.5 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05531901591582069		[learning rate: 8.6079e-05]
	Learning Rate: 8.60785e-05
	LOSS [training: 0.05531901591582069 | validation: 0.05550974672717355]
	TIME [epoch: 8.49 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051160016760063695		[learning rate: 8.5766e-05]
	Learning Rate: 8.57661e-05
	LOSS [training: 0.051160016760063695 | validation: 0.06548217948364606]
	TIME [epoch: 8.5 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05656295026032225		[learning rate: 8.5455e-05]
	Learning Rate: 8.54549e-05
	LOSS [training: 0.05656295026032225 | validation: 0.05068912416401899]
	TIME [epoch: 8.51 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05176861625164819		[learning rate: 8.5145e-05]
	Learning Rate: 8.51448e-05
	LOSS [training: 0.05176861625164819 | validation: 0.05062233285824942]
	TIME [epoch: 8.49 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053745159210308945		[learning rate: 8.4836e-05]
	Learning Rate: 8.48358e-05
	LOSS [training: 0.053745159210308945 | validation: 0.07734196437968766]
	TIME [epoch: 8.49 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06649383503525601		[learning rate: 8.4528e-05]
	Learning Rate: 8.45279e-05
	LOSS [training: 0.06649383503525601 | validation: 0.06499112771090113]
	TIME [epoch: 8.5 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05943446674910622		[learning rate: 8.4221e-05]
	Learning Rate: 8.42211e-05
	LOSS [training: 0.05943446674910622 | validation: 0.046673302858911414]
	TIME [epoch: 8.53 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05601461524551621		[learning rate: 8.3916e-05]
	Learning Rate: 8.39155e-05
	LOSS [training: 0.05601461524551621 | validation: 0.06461757854715218]
	TIME [epoch: 8.5 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0647029887207481		[learning rate: 8.3611e-05]
	Learning Rate: 8.3611e-05
	LOSS [training: 0.0647029887207481 | validation: 0.06383306432483533]
	TIME [epoch: 8.5 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05945332566460104		[learning rate: 8.3308e-05]
	Learning Rate: 8.33075e-05
	LOSS [training: 0.05945332566460104 | validation: 0.05238982373029259]
	TIME [epoch: 8.49 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05981788557174132		[learning rate: 8.3005e-05]
	Learning Rate: 8.30052e-05
	LOSS [training: 0.05981788557174132 | validation: 0.05649287790136112]
	TIME [epoch: 8.52 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0632096023931615		[learning rate: 8.2704e-05]
	Learning Rate: 8.2704e-05
	LOSS [training: 0.0632096023931615 | validation: 0.07255232047641048]
	TIME [epoch: 8.5 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06125693381468592		[learning rate: 8.2404e-05]
	Learning Rate: 8.24038e-05
	LOSS [training: 0.06125693381468592 | validation: 0.058226061955046975]
	TIME [epoch: 8.5 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0578184061846424		[learning rate: 8.2105e-05]
	Learning Rate: 8.21048e-05
	LOSS [training: 0.0578184061846424 | validation: 0.05603473187168173]
	TIME [epoch: 8.5 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056639807969113984		[learning rate: 8.1807e-05]
	Learning Rate: 8.18068e-05
	LOSS [training: 0.056639807969113984 | validation: 0.06378483782784343]
	TIME [epoch: 8.52 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05500999584384586		[learning rate: 8.151e-05]
	Learning Rate: 8.15099e-05
	LOSS [training: 0.05500999584384586 | validation: 0.04745599601205383]
	TIME [epoch: 8.5 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05318677830360767		[learning rate: 8.1214e-05]
	Learning Rate: 8.12142e-05
	LOSS [training: 0.05318677830360767 | validation: 0.051376262061221964]
	TIME [epoch: 8.5 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05629031239796863		[learning rate: 8.0919e-05]
	Learning Rate: 8.09194e-05
	LOSS [training: 0.05629031239796863 | validation: 0.054130247159711584]
	TIME [epoch: 8.5 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05827998251784987		[learning rate: 8.0626e-05]
	Learning Rate: 8.06257e-05
	LOSS [training: 0.05827998251784987 | validation: 0.05140457744041017]
	TIME [epoch: 8.52 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05976203993897544		[learning rate: 8.0333e-05]
	Learning Rate: 8.03331e-05
	LOSS [training: 0.05976203993897544 | validation: 0.04084639972925863]
	TIME [epoch: 8.51 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05870578278031411		[learning rate: 8.0042e-05]
	Learning Rate: 8.00416e-05
	LOSS [training: 0.05870578278031411 | validation: 0.05742229216830501]
	TIME [epoch: 8.49 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04989263805353057		[learning rate: 7.9751e-05]
	Learning Rate: 7.97511e-05
	LOSS [training: 0.04989263805353057 | validation: 0.0634688510744543]
	TIME [epoch: 8.5 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05621442555533248		[learning rate: 7.9462e-05]
	Learning Rate: 7.94617e-05
	LOSS [training: 0.05621442555533248 | validation: 0.060423874978346226]
	TIME [epoch: 8.5 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055499970820824904		[learning rate: 7.9173e-05]
	Learning Rate: 7.91733e-05
	LOSS [training: 0.055499970820824904 | validation: 0.06075282559233254]
	TIME [epoch: 8.52 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05294111587537272		[learning rate: 7.8886e-05]
	Learning Rate: 7.8886e-05
	LOSS [training: 0.05294111587537272 | validation: 0.06876894652585847]
	TIME [epoch: 8.5 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05993976783034673		[learning rate: 7.86e-05]
	Learning Rate: 7.85997e-05
	LOSS [training: 0.05993976783034673 | validation: 0.0664367597632874]
	TIME [epoch: 8.5 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06835443028849761		[learning rate: 7.8315e-05]
	Learning Rate: 7.83145e-05
	LOSS [training: 0.06835443028849761 | validation: 0.06116635938652823]
	TIME [epoch: 8.5 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058994342958269705		[learning rate: 7.803e-05]
	Learning Rate: 7.80303e-05
	LOSS [training: 0.058994342958269705 | validation: 0.04897179915318145]
	TIME [epoch: 8.52 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05678361909679501		[learning rate: 7.7747e-05]
	Learning Rate: 7.77471e-05
	LOSS [training: 0.05678361909679501 | validation: 0.04761685495777594]
	TIME [epoch: 8.51 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057288239190110245		[learning rate: 7.7465e-05]
	Learning Rate: 7.7465e-05
	LOSS [training: 0.057288239190110245 | validation: 0.042031193963283524]
	TIME [epoch: 8.5 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053646785939016006		[learning rate: 7.7184e-05]
	Learning Rate: 7.71838e-05
	LOSS [training: 0.053646785939016006 | validation: 0.04887371090493819]
	TIME [epoch: 8.5 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05384111954348392		[learning rate: 7.6904e-05]
	Learning Rate: 7.69037e-05
	LOSS [training: 0.05384111954348392 | validation: 0.053559637317422346]
	TIME [epoch: 8.51 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051765045874741136		[learning rate: 7.6625e-05]
	Learning Rate: 7.66246e-05
	LOSS [training: 0.051765045874741136 | validation: 0.04680633185891473]
	TIME [epoch: 8.49 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058118587811047326		[learning rate: 7.6347e-05]
	Learning Rate: 7.63466e-05
	LOSS [training: 0.058118587811047326 | validation: 0.05332867577683875]
	TIME [epoch: 8.5 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058710522724982964		[learning rate: 7.607e-05]
	Learning Rate: 7.60695e-05
	LOSS [training: 0.058710522724982964 | validation: 0.061877593893531445]
	TIME [epoch: 8.5 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059053795910738095		[learning rate: 7.5793e-05]
	Learning Rate: 7.57935e-05
	LOSS [training: 0.059053795910738095 | validation: 0.044318147206902456]
	TIME [epoch: 8.51 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055377755134696324		[learning rate: 7.5518e-05]
	Learning Rate: 7.55184e-05
	LOSS [training: 0.055377755134696324 | validation: 0.05775275105004758]
	TIME [epoch: 8.5 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05465239515316052		[learning rate: 7.5244e-05]
	Learning Rate: 7.52443e-05
	LOSS [training: 0.05465239515316052 | validation: 0.06471913406089252]
	TIME [epoch: 8.5 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06096340928538627		[learning rate: 7.4971e-05]
	Learning Rate: 7.49712e-05
	LOSS [training: 0.06096340928538627 | validation: 0.05410546043517141]
	TIME [epoch: 8.51 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05387492023351438		[learning rate: 7.4699e-05]
	Learning Rate: 7.46992e-05
	LOSS [training: 0.05387492023351438 | validation: 0.04703583319981554]
	TIME [epoch: 8.5 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06436436396289268		[learning rate: 7.4428e-05]
	Learning Rate: 7.44281e-05
	LOSS [training: 0.06436436396289268 | validation: 0.056158548444914184]
	TIME [epoch: 8.53 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05547494030403018		[learning rate: 7.4158e-05]
	Learning Rate: 7.4158e-05
	LOSS [training: 0.05547494030403018 | validation: 0.04472893774136148]
	TIME [epoch: 8.5 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056389578886169335		[learning rate: 7.3889e-05]
	Learning Rate: 7.38889e-05
	LOSS [training: 0.056389578886169335 | validation: 0.04244600789195995]
	TIME [epoch: 8.51 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05170205354440346		[learning rate: 7.3621e-05]
	Learning Rate: 7.36207e-05
	LOSS [training: 0.05170205354440346 | validation: 0.049957147629024395]
	TIME [epoch: 8.5 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04980275324402543		[learning rate: 7.3354e-05]
	Learning Rate: 7.33536e-05
	LOSS [training: 0.04980275324402543 | validation: 0.05676575177954084]
	TIME [epoch: 8.53 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05463344232420203		[learning rate: 7.3087e-05]
	Learning Rate: 7.30873e-05
	LOSS [training: 0.05463344232420203 | validation: 0.057577945748459376]
	TIME [epoch: 8.51 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05444012098307947		[learning rate: 7.2822e-05]
	Learning Rate: 7.28221e-05
	LOSS [training: 0.05444012098307947 | validation: 0.05080010143823657]
	TIME [epoch: 8.51 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06053940930126047		[learning rate: 7.2558e-05]
	Learning Rate: 7.25578e-05
	LOSS [training: 0.06053940930126047 | validation: 0.05225757597131293]
	TIME [epoch: 8.5 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05761037428518908		[learning rate: 7.2295e-05]
	Learning Rate: 7.22945e-05
	LOSS [training: 0.05761037428518908 | validation: 0.052301158394175665]
	TIME [epoch: 8.53 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05514375104079946		[learning rate: 7.2032e-05]
	Learning Rate: 7.20321e-05
	LOSS [training: 0.05514375104079946 | validation: 0.04671562840565638]
	TIME [epoch: 8.5 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05112481076461428		[learning rate: 7.1771e-05]
	Learning Rate: 7.17707e-05
	LOSS [training: 0.05112481076461428 | validation: 0.055560176694142746]
	TIME [epoch: 8.51 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05457445801214169		[learning rate: 7.151e-05]
	Learning Rate: 7.15103e-05
	LOSS [training: 0.05457445801214169 | validation: 0.05221989925420849]
	TIME [epoch: 8.5 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049893829363154764		[learning rate: 7.1251e-05]
	Learning Rate: 7.12508e-05
	LOSS [training: 0.049893829363154764 | validation: 0.03444207388328395]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r1_20240219_233722/states/model_tr_study204_1460.pth
	Model improved!!!
EPOCH 1461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054781609604268235		[learning rate: 7.0992e-05]
	Learning Rate: 7.09922e-05
	LOSS [training: 0.054781609604268235 | validation: 0.05431258137067031]
	TIME [epoch: 8.52 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058874917310147976		[learning rate: 7.0735e-05]
	Learning Rate: 7.07345e-05
	LOSS [training: 0.058874917310147976 | validation: 0.046244910720178674]
	TIME [epoch: 8.51 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055498227211336536		[learning rate: 7.0478e-05]
	Learning Rate: 7.04778e-05
	LOSS [training: 0.055498227211336536 | validation: 0.05370702590078619]
	TIME [epoch: 8.5 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05695753853882217		[learning rate: 7.0222e-05]
	Learning Rate: 7.02221e-05
	LOSS [training: 0.05695753853882217 | validation: 0.05400695127974397]
	TIME [epoch: 8.5 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059032226856082316		[learning rate: 6.9967e-05]
	Learning Rate: 6.99672e-05
	LOSS [training: 0.059032226856082316 | validation: 0.06740489568052717]
	TIME [epoch: 8.52 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0633091145638712		[learning rate: 6.9713e-05]
	Learning Rate: 6.97133e-05
	LOSS [training: 0.0633091145638712 | validation: 0.06621498406860835]
	TIME [epoch: 8.51 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05650940961219604		[learning rate: 6.946e-05]
	Learning Rate: 6.94603e-05
	LOSS [training: 0.05650940961219604 | validation: 0.04933574101476694]
	TIME [epoch: 8.51 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05335346583092587		[learning rate: 6.9208e-05]
	Learning Rate: 6.92083e-05
	LOSS [training: 0.05335346583092587 | validation: 0.04359754285778366]
	TIME [epoch: 8.51 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05308399435909413		[learning rate: 6.8957e-05]
	Learning Rate: 6.89571e-05
	LOSS [training: 0.05308399435909413 | validation: 0.05737023217192362]
	TIME [epoch: 8.53 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05428217707636618		[learning rate: 6.8707e-05]
	Learning Rate: 6.87068e-05
	LOSS [training: 0.05428217707636618 | validation: 0.050140105141296826]
	TIME [epoch: 8.5 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054419591776877475		[learning rate: 6.8457e-05]
	Learning Rate: 6.84575e-05
	LOSS [training: 0.054419591776877475 | validation: 0.05657791738534568]
	TIME [epoch: 8.51 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057211552292589854		[learning rate: 6.8209e-05]
	Learning Rate: 6.82091e-05
	LOSS [training: 0.057211552292589854 | validation: 0.04888062993169441]
	TIME [epoch: 8.51 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05749046535406675		[learning rate: 6.7962e-05]
	Learning Rate: 6.79615e-05
	LOSS [training: 0.05749046535406675 | validation: 0.04493407210374767]
	TIME [epoch: 8.52 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05649863320573546		[learning rate: 6.7715e-05]
	Learning Rate: 6.77149e-05
	LOSS [training: 0.05649863320573546 | validation: 0.0630999539528027]
	TIME [epoch: 8.52 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053570611530491676		[learning rate: 6.7469e-05]
	Learning Rate: 6.74692e-05
	LOSS [training: 0.053570611530491676 | validation: 0.05588168122560387]
	TIME [epoch: 8.5 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05345601400047809		[learning rate: 6.7224e-05]
	Learning Rate: 6.72243e-05
	LOSS [training: 0.05345601400047809 | validation: 0.043634894298894986]
	TIME [epoch: 8.51 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053002471056345965		[learning rate: 6.698e-05]
	Learning Rate: 6.69804e-05
	LOSS [training: 0.053002471056345965 | validation: 0.05323551369758374]
	TIME [epoch: 8.52 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05525072087693428		[learning rate: 6.6737e-05]
	Learning Rate: 6.67373e-05
	LOSS [training: 0.05525072087693428 | validation: 0.051641674318878804]
	TIME [epoch: 8.52 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05222681119442324		[learning rate: 6.6495e-05]
	Learning Rate: 6.64951e-05
	LOSS [training: 0.05222681119442324 | validation: 0.05624973993284255]
	TIME [epoch: 8.51 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049836752234793544		[learning rate: 6.6254e-05]
	Learning Rate: 6.62538e-05
	LOSS [training: 0.049836752234793544 | validation: 0.05159591840961633]
	TIME [epoch: 8.5 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058151959812346055		[learning rate: 6.6013e-05]
	Learning Rate: 6.60133e-05
	LOSS [training: 0.058151959812346055 | validation: 0.060415609574408016]
	TIME [epoch: 8.5 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05810852117436003		[learning rate: 6.5774e-05]
	Learning Rate: 6.57738e-05
	LOSS [training: 0.05810852117436003 | validation: 0.05669083353254005]
	TIME [epoch: 8.51 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053149503127572564		[learning rate: 6.5535e-05]
	Learning Rate: 6.55351e-05
	LOSS [training: 0.053149503127572564 | validation: 0.05794271500141299]
	TIME [epoch: 8.5 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05832784016465251		[learning rate: 6.5297e-05]
	Learning Rate: 6.52972e-05
	LOSS [training: 0.05832784016465251 | validation: 0.06316434423373538]
	TIME [epoch: 8.5 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058674985219220786		[learning rate: 6.506e-05]
	Learning Rate: 6.50603e-05
	LOSS [training: 0.058674985219220786 | validation: 0.050082061243138104]
	TIME [epoch: 8.5 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05211595743929644		[learning rate: 6.4824e-05]
	Learning Rate: 6.48242e-05
	LOSS [training: 0.05211595743929644 | validation: 0.05136239446250779]
	TIME [epoch: 8.53 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05305186723759826		[learning rate: 6.4589e-05]
	Learning Rate: 6.45889e-05
	LOSS [training: 0.05305186723759826 | validation: 0.05708639719371841]
	TIME [epoch: 8.51 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056621993993136596		[learning rate: 6.4354e-05]
	Learning Rate: 6.43545e-05
	LOSS [training: 0.056621993993136596 | validation: 0.03985843934280652]
	TIME [epoch: 8.5 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05897013302071745		[learning rate: 6.4121e-05]
	Learning Rate: 6.4121e-05
	LOSS [training: 0.05897013302071745 | validation: 0.062346951660053995]
	TIME [epoch: 8.52 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054930787071606126		[learning rate: 6.3888e-05]
	Learning Rate: 6.38883e-05
	LOSS [training: 0.054930787071606126 | validation: 0.04912352395415366]
	TIME [epoch: 8.53 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056384337599687216		[learning rate: 6.3656e-05]
	Learning Rate: 6.36564e-05
	LOSS [training: 0.056384337599687216 | validation: 0.05592102699061994]
	TIME [epoch: 8.51 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05455561519505296		[learning rate: 6.3425e-05]
	Learning Rate: 6.34254e-05
	LOSS [training: 0.05455561519505296 | validation: 0.04035932667395581]
	TIME [epoch: 8.51 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05829085486733393		[learning rate: 6.3195e-05]
	Learning Rate: 6.31952e-05
	LOSS [training: 0.05829085486733393 | validation: 0.05120623403283617]
	TIME [epoch: 8.51 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053102281622598134		[learning rate: 6.2966e-05]
	Learning Rate: 6.29659e-05
	LOSS [training: 0.053102281622598134 | validation: 0.044844457832231]
	TIME [epoch: 8.52 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057879309655478016		[learning rate: 6.2737e-05]
	Learning Rate: 6.27374e-05
	LOSS [training: 0.057879309655478016 | validation: 0.05540409311716471]
	TIME [epoch: 8.52 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0516176063417626		[learning rate: 6.251e-05]
	Learning Rate: 6.25097e-05
	LOSS [training: 0.0516176063417626 | validation: 0.04689750060289605]
	TIME [epoch: 8.51 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05219160545901924		[learning rate: 6.2283e-05]
	Learning Rate: 6.22828e-05
	LOSS [training: 0.05219160545901924 | validation: 0.04856045438922599]
	TIME [epoch: 8.51 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0511200786642612		[learning rate: 6.2057e-05]
	Learning Rate: 6.20568e-05
	LOSS [training: 0.0511200786642612 | validation: 0.05335537368237052]
	TIME [epoch: 8.5 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055816399682251716		[learning rate: 6.1832e-05]
	Learning Rate: 6.18316e-05
	LOSS [training: 0.055816399682251716 | validation: 0.05743275020792232]
	TIME [epoch: 8.52 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05317043307929999		[learning rate: 6.1607e-05]
	Learning Rate: 6.16072e-05
	LOSS [training: 0.05317043307929999 | validation: 0.056203785146396915]
	TIME [epoch: 8.51 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05181013865672675		[learning rate: 6.1384e-05]
	Learning Rate: 6.13836e-05
	LOSS [training: 0.05181013865672675 | validation: 0.06232051484453301]
	TIME [epoch: 8.5 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05566813893392943		[learning rate: 6.1161e-05]
	Learning Rate: 6.11609e-05
	LOSS [training: 0.05566813893392943 | validation: 0.05706870621468445]
	TIME [epoch: 8.51 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05307572622460609		[learning rate: 6.0939e-05]
	Learning Rate: 6.09389e-05
	LOSS [training: 0.05307572622460609 | validation: 0.05076858436793792]
	TIME [epoch: 8.53 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05844904473228154		[learning rate: 6.0718e-05]
	Learning Rate: 6.07178e-05
	LOSS [training: 0.05844904473228154 | validation: 0.05735245144042222]
	TIME [epoch: 8.5 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06330080043696354		[learning rate: 6.0497e-05]
	Learning Rate: 6.04974e-05
	LOSS [training: 0.06330080043696354 | validation: 0.05031776800961282]
	TIME [epoch: 8.5 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049407856236497676		[learning rate: 6.0278e-05]
	Learning Rate: 6.02779e-05
	LOSS [training: 0.049407856236497676 | validation: 0.055832300934662786]
	TIME [epoch: 8.5 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04898718507805627		[learning rate: 6.0059e-05]
	Learning Rate: 6.00591e-05
	LOSS [training: 0.04898718507805627 | validation: 0.0455125203531334]
	TIME [epoch: 8.53 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06183792587958449		[learning rate: 5.9841e-05]
	Learning Rate: 5.98412e-05
	LOSS [training: 0.06183792587958449 | validation: 0.06497982119394177]
	TIME [epoch: 8.51 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0539037196077915		[learning rate: 5.9624e-05]
	Learning Rate: 5.9624e-05
	LOSS [training: 0.0539037196077915 | validation: 0.045416396086224095]
	TIME [epoch: 8.52 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04679405689677374		[learning rate: 5.9408e-05]
	Learning Rate: 5.94076e-05
	LOSS [training: 0.04679405689677374 | validation: 0.052128213311758737]
	TIME [epoch: 8.51 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05193704590328335		[learning rate: 5.9192e-05]
	Learning Rate: 5.9192e-05
	LOSS [training: 0.05193704590328335 | validation: 0.053641400671645925]
	TIME [epoch: 8.53 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05140848508506559		[learning rate: 5.8977e-05]
	Learning Rate: 5.89772e-05
	LOSS [training: 0.05140848508506559 | validation: 0.05225292469056299]
	TIME [epoch: 8.51 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05224006032307692		[learning rate: 5.8763e-05]
	Learning Rate: 5.87632e-05
	LOSS [training: 0.05224006032307692 | validation: 0.05677418474599237]
	TIME [epoch: 8.5 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058507824923248485		[learning rate: 5.855e-05]
	Learning Rate: 5.85499e-05
	LOSS [training: 0.058507824923248485 | validation: 0.06693956072458287]
	TIME [epoch: 8.51 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059928798939930084		[learning rate: 5.8337e-05]
	Learning Rate: 5.83374e-05
	LOSS [training: 0.059928798939930084 | validation: 0.061264204786024457]
	TIME [epoch: 8.51 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05225051108443868		[learning rate: 5.8126e-05]
	Learning Rate: 5.81257e-05
	LOSS [training: 0.05225051108443868 | validation: 0.05893565282047006]
	TIME [epoch: 8.52 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055984592300851885		[learning rate: 5.7915e-05]
	Learning Rate: 5.79148e-05
	LOSS [training: 0.055984592300851885 | validation: 0.06066768254033433]
	TIME [epoch: 8.5 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05721956849957682		[learning rate: 5.7705e-05]
	Learning Rate: 5.77046e-05
	LOSS [training: 0.05721956849957682 | validation: 0.048881055629805714]
	TIME [epoch: 8.5 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05392712939882523		[learning rate: 5.7495e-05]
	Learning Rate: 5.74952e-05
	LOSS [training: 0.05392712939882523 | validation: 0.04728338385516817]
	TIME [epoch: 8.51 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05476403018487295		[learning rate: 5.7287e-05]
	Learning Rate: 5.72866e-05
	LOSS [training: 0.05476403018487295 | validation: 0.05521154924644788]
	TIME [epoch: 8.53 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05347603758752088		[learning rate: 5.7079e-05]
	Learning Rate: 5.70787e-05
	LOSS [training: 0.05347603758752088 | validation: 0.049363337442428865]
	TIME [epoch: 8.51 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06134718293114081		[learning rate: 5.6872e-05]
	Learning Rate: 5.68715e-05
	LOSS [training: 0.06134718293114081 | validation: 0.04961070301648417]
	TIME [epoch: 8.5 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05374429126991263		[learning rate: 5.6665e-05]
	Learning Rate: 5.66651e-05
	LOSS [training: 0.05374429126991263 | validation: 0.04973586085572209]
	TIME [epoch: 8.51 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056562794364629		[learning rate: 5.6459e-05]
	Learning Rate: 5.64595e-05
	LOSS [training: 0.056562794364629 | validation: 0.04539069718952853]
	TIME [epoch: 8.52 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05112575956150178		[learning rate: 5.6255e-05]
	Learning Rate: 5.62546e-05
	LOSS [training: 0.05112575956150178 | validation: 0.0475371640446033]
	TIME [epoch: 8.51 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059265856440930444		[learning rate: 5.605e-05]
	Learning Rate: 5.60504e-05
	LOSS [training: 0.059265856440930444 | validation: 0.04953072433178069]
	TIME [epoch: 8.51 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053126764233994386		[learning rate: 5.5847e-05]
	Learning Rate: 5.5847e-05
	LOSS [training: 0.053126764233994386 | validation: 0.07739835668204906]
	TIME [epoch: 8.5 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0631601639615239		[learning rate: 5.5644e-05]
	Learning Rate: 5.56444e-05
	LOSS [training: 0.0631601639615239 | validation: 0.06017130797640946]
	TIME [epoch: 8.53 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060072604013169585		[learning rate: 5.5442e-05]
	Learning Rate: 5.54424e-05
	LOSS [training: 0.060072604013169585 | validation: 0.05269217780278879]
	TIME [epoch: 8.5 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05103876956542018		[learning rate: 5.5241e-05]
	Learning Rate: 5.52412e-05
	LOSS [training: 0.05103876956542018 | validation: 0.05873561846333044]
	TIME [epoch: 8.5 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05192025463579068		[learning rate: 5.5041e-05]
	Learning Rate: 5.50407e-05
	LOSS [training: 0.05192025463579068 | validation: 0.0514224958291566]
	TIME [epoch: 8.51 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05531779375658456		[learning rate: 5.4841e-05]
	Learning Rate: 5.4841e-05
	LOSS [training: 0.05531779375658456 | validation: 0.06066329948865501]
	TIME [epoch: 8.52 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048984128473598273		[learning rate: 5.4642e-05]
	Learning Rate: 5.4642e-05
	LOSS [training: 0.048984128473598273 | validation: 0.05370719131550048]
	TIME [epoch: 8.52 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05213335612848043		[learning rate: 5.4444e-05]
	Learning Rate: 5.44437e-05
	LOSS [training: 0.05213335612848043 | validation: 0.05110545434983195]
	TIME [epoch: 8.5 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05255599938271516		[learning rate: 5.4246e-05]
	Learning Rate: 5.42461e-05
	LOSS [training: 0.05255599938271516 | validation: 0.060072927166895065]
	TIME [epoch: 8.51 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05191329124822698		[learning rate: 5.4049e-05]
	Learning Rate: 5.40492e-05
	LOSS [training: 0.05191329124822698 | validation: 0.042494488729257165]
	TIME [epoch: 8.49 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056986243981030846		[learning rate: 5.3853e-05]
	Learning Rate: 5.38531e-05
	LOSS [training: 0.056986243981030846 | validation: 0.057195592735706756]
	TIME [epoch: 8.53 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05031847950222612		[learning rate: 5.3658e-05]
	Learning Rate: 5.36577e-05
	LOSS [training: 0.05031847950222612 | validation: 0.0502000744429691]
	TIME [epoch: 8.49 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04751401746139068		[learning rate: 5.3463e-05]
	Learning Rate: 5.34629e-05
	LOSS [training: 0.04751401746139068 | validation: 0.05698704545939654]
	TIME [epoch: 8.49 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05483719297905508		[learning rate: 5.3269e-05]
	Learning Rate: 5.32689e-05
	LOSS [training: 0.05483719297905508 | validation: 0.06117104104736693]
	TIME [epoch: 8.5 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05304455300651415		[learning rate: 5.3076e-05]
	Learning Rate: 5.30756e-05
	LOSS [training: 0.05304455300651415 | validation: 0.05340068003356893]
	TIME [epoch: 8.52 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05586242494684575		[learning rate: 5.2883e-05]
	Learning Rate: 5.2883e-05
	LOSS [training: 0.05586242494684575 | validation: 0.04660571567607666]
	TIME [epoch: 8.51 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050520529488688806		[learning rate: 5.2691e-05]
	Learning Rate: 5.26911e-05
	LOSS [training: 0.050520529488688806 | validation: 0.05205932702566864]
	TIME [epoch: 8.5 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054080826952042235		[learning rate: 5.25e-05]
	Learning Rate: 5.24998e-05
	LOSS [training: 0.054080826952042235 | validation: 0.05470325930815975]
	TIME [epoch: 8.5 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05250920544556849		[learning rate: 5.2309e-05]
	Learning Rate: 5.23093e-05
	LOSS [training: 0.05250920544556849 | validation: 0.0594459911598222]
	TIME [epoch: 8.52 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05250550731696585		[learning rate: 5.2119e-05]
	Learning Rate: 5.21195e-05
	LOSS [training: 0.05250550731696585 | validation: 0.0512752466000604]
	TIME [epoch: 8.5 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0519883228761198		[learning rate: 5.193e-05]
	Learning Rate: 5.19303e-05
	LOSS [training: 0.0519883228761198 | validation: 0.046735141475496206]
	TIME [epoch: 8.49 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056108078482545176		[learning rate: 5.1742e-05]
	Learning Rate: 5.17419e-05
	LOSS [training: 0.056108078482545176 | validation: 0.047297726330927534]
	TIME [epoch: 8.5 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05381986392122616		[learning rate: 5.1554e-05]
	Learning Rate: 5.15541e-05
	LOSS [training: 0.05381986392122616 | validation: 0.047010246409540705]
	TIME [epoch: 8.5 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05544827135385525		[learning rate: 5.1367e-05]
	Learning Rate: 5.1367e-05
	LOSS [training: 0.05544827135385525 | validation: 0.04513826477444464]
	TIME [epoch: 8.5 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057773250023365696		[learning rate: 5.1181e-05]
	Learning Rate: 5.11806e-05
	LOSS [training: 0.057773250023365696 | validation: 0.05300099378441421]
	TIME [epoch: 8.5 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055455597786385244		[learning rate: 5.0995e-05]
	Learning Rate: 5.09949e-05
	LOSS [training: 0.055455597786385244 | validation: 0.04874850838500541]
	TIME [epoch: 8.5 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05585785357136375		[learning rate: 5.081e-05]
	Learning Rate: 5.08098e-05
	LOSS [training: 0.05585785357136375 | validation: 0.05953760803850697]
	TIME [epoch: 8.5 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04996049871327376		[learning rate: 5.0625e-05]
	Learning Rate: 5.06254e-05
	LOSS [training: 0.04996049871327376 | validation: 0.060107918853685174]
	TIME [epoch: 8.52 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05355159661109732		[learning rate: 5.0442e-05]
	Learning Rate: 5.04417e-05
	LOSS [training: 0.05355159661109732 | validation: 0.05695511694838716]
	TIME [epoch: 8.5 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053273519603121086		[learning rate: 5.0259e-05]
	Learning Rate: 5.02586e-05
	LOSS [training: 0.053273519603121086 | validation: 0.05499545241480022]
	TIME [epoch: 8.5 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05543786336451685		[learning rate: 5.0076e-05]
	Learning Rate: 5.00762e-05
	LOSS [training: 0.05543786336451685 | validation: 0.05894538426192117]
	TIME [epoch: 8.5 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051512609339125257		[learning rate: 4.9894e-05]
	Learning Rate: 4.98945e-05
	LOSS [training: 0.051512609339125257 | validation: 0.052231350235564945]
	TIME [epoch: 8.53 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054435174505253814		[learning rate: 4.9713e-05]
	Learning Rate: 4.97134e-05
	LOSS [training: 0.054435174505253814 | validation: 0.05795292389335544]
	TIME [epoch: 8.5 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052466509667567704		[learning rate: 4.9533e-05]
	Learning Rate: 4.9533e-05
	LOSS [training: 0.052466509667567704 | validation: 0.056177773374687566]
	TIME [epoch: 8.5 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05043048939669731		[learning rate: 4.9353e-05]
	Learning Rate: 4.93533e-05
	LOSS [training: 0.05043048939669731 | validation: 0.04849594728861379]
	TIME [epoch: 8.51 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050178695788502745		[learning rate: 4.9174e-05]
	Learning Rate: 4.91742e-05
	LOSS [training: 0.050178695788502745 | validation: 0.05584817409404612]
	TIME [epoch: 8.53 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05144326206058895		[learning rate: 4.8996e-05]
	Learning Rate: 4.89957e-05
	LOSS [training: 0.05144326206058895 | validation: 0.04442101781354057]
	TIME [epoch: 8.51 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056859232112556925		[learning rate: 4.8818e-05]
	Learning Rate: 4.88179e-05
	LOSS [training: 0.056859232112556925 | validation: 0.04978667722783362]
	TIME [epoch: 8.51 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05136066132073369		[learning rate: 4.8641e-05]
	Learning Rate: 4.86407e-05
	LOSS [training: 0.05136066132073369 | validation: 0.04976473508681385]
	TIME [epoch: 8.52 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052342433637780475		[learning rate: 4.8464e-05]
	Learning Rate: 4.84642e-05
	LOSS [training: 0.052342433637780475 | validation: 0.05996095316264101]
	TIME [epoch: 8.52 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055499939373639215		[learning rate: 4.8288e-05]
	Learning Rate: 4.82883e-05
	LOSS [training: 0.055499939373639215 | validation: 0.04482034644782906]
	TIME [epoch: 8.52 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049373523871934534		[learning rate: 4.8113e-05]
	Learning Rate: 4.81131e-05
	LOSS [training: 0.049373523871934534 | validation: 0.05320041895048523]
	TIME [epoch: 8.5 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05763293206872179		[learning rate: 4.7938e-05]
	Learning Rate: 4.79385e-05
	LOSS [training: 0.05763293206872179 | validation: 0.04261820508889765]
	TIME [epoch: 8.51 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05359915594554334		[learning rate: 4.7765e-05]
	Learning Rate: 4.77645e-05
	LOSS [training: 0.05359915594554334 | validation: 0.05187504984275121]
	TIME [epoch: 8.5 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05826400819338797		[learning rate: 4.7591e-05]
	Learning Rate: 4.75912e-05
	LOSS [training: 0.05826400819338797 | validation: 0.05884506555925917]
	TIME [epoch: 8.53 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047236122678747765		[learning rate: 4.7418e-05]
	Learning Rate: 4.74185e-05
	LOSS [training: 0.047236122678747765 | validation: 0.057658764679215435]
	TIME [epoch: 8.5 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05470689880075784		[learning rate: 4.7246e-05]
	Learning Rate: 4.72464e-05
	LOSS [training: 0.05470689880075784 | validation: 0.04703944660172861]
	TIME [epoch: 8.5 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05608555517885072		[learning rate: 4.7075e-05]
	Learning Rate: 4.70749e-05
	LOSS [training: 0.05608555517885072 | validation: 0.06137025819762913]
	TIME [epoch: 8.52 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05276223035160547		[learning rate: 4.6904e-05]
	Learning Rate: 4.69041e-05
	LOSS [training: 0.05276223035160547 | validation: 0.04958022740593464]
	TIME [epoch: 8.52 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05444427597453466		[learning rate: 4.6734e-05]
	Learning Rate: 4.67339e-05
	LOSS [training: 0.05444427597453466 | validation: 0.052173340308139665]
	TIME [epoch: 8.5 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05436794125961718		[learning rate: 4.6564e-05]
	Learning Rate: 4.65643e-05
	LOSS [training: 0.05436794125961718 | validation: 0.0624133653540077]
	TIME [epoch: 8.51 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05685516486767689		[learning rate: 4.6395e-05]
	Learning Rate: 4.63953e-05
	LOSS [training: 0.05685516486767689 | validation: 0.049158971037968]
	TIME [epoch: 8.51 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052620964506654336		[learning rate: 4.6227e-05]
	Learning Rate: 4.62269e-05
	LOSS [training: 0.052620964506654336 | validation: 0.05231875539464388]
	TIME [epoch: 8.53 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051130018986922446		[learning rate: 4.6059e-05]
	Learning Rate: 4.60591e-05
	LOSS [training: 0.051130018986922446 | validation: 0.04908212550970517]
	TIME [epoch: 8.51 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051801362864722963		[learning rate: 4.5892e-05]
	Learning Rate: 4.5892e-05
	LOSS [training: 0.051801362864722963 | validation: 0.0422425618131294]
	TIME [epoch: 8.5 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04936257409144616		[learning rate: 4.5725e-05]
	Learning Rate: 4.57254e-05
	LOSS [training: 0.04936257409144616 | validation: 0.05531335546058866]
	TIME [epoch: 8.51 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05457646476518287		[learning rate: 4.556e-05]
	Learning Rate: 4.55595e-05
	LOSS [training: 0.05457646476518287 | validation: 0.05599571200420206]
	TIME [epoch: 8.52 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05337656245413176		[learning rate: 4.5394e-05]
	Learning Rate: 4.53942e-05
	LOSS [training: 0.05337656245413176 | validation: 0.05831089457776242]
	TIME [epoch: 8.52 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04898744841098805		[learning rate: 4.5229e-05]
	Learning Rate: 4.52294e-05
	LOSS [training: 0.04898744841098805 | validation: 0.05000882667925785]
	TIME [epoch: 8.51 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052696716207982976		[learning rate: 4.5065e-05]
	Learning Rate: 4.50653e-05
	LOSS [training: 0.052696716207982976 | validation: 0.053379565996673387]
	TIME [epoch: 8.5 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054955761668494696		[learning rate: 4.4902e-05]
	Learning Rate: 4.49017e-05
	LOSS [training: 0.054955761668494696 | validation: 0.04520601672235568]
	TIME [epoch: 8.51 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050133948444591944		[learning rate: 4.4739e-05]
	Learning Rate: 4.47388e-05
	LOSS [training: 0.050133948444591944 | validation: 0.0486827467994473]
	TIME [epoch: 8.52 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05065665080090749		[learning rate: 4.4576e-05]
	Learning Rate: 4.45764e-05
	LOSS [training: 0.05065665080090749 | validation: 0.052401558893546016]
	TIME [epoch: 8.5 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05617335697013692		[learning rate: 4.4415e-05]
	Learning Rate: 4.44147e-05
	LOSS [training: 0.05617335697013692 | validation: 0.05482720276324255]
	TIME [epoch: 8.5 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05423513333554275		[learning rate: 4.4253e-05]
	Learning Rate: 4.42535e-05
	LOSS [training: 0.05423513333554275 | validation: 0.056738804123703634]
	TIME [epoch: 8.5 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05506038602098242		[learning rate: 4.4093e-05]
	Learning Rate: 4.40929e-05
	LOSS [training: 0.05506038602098242 | validation: 0.0604721586586178]
	TIME [epoch: 8.52 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05475290579710388		[learning rate: 4.3933e-05]
	Learning Rate: 4.39329e-05
	LOSS [training: 0.05475290579710388 | validation: 0.04882350531638506]
	TIME [epoch: 8.5 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05177196693065158		[learning rate: 4.3773e-05]
	Learning Rate: 4.37734e-05
	LOSS [training: 0.05177196693065158 | validation: 0.057158347637805376]
	TIME [epoch: 8.5 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06188057106314661		[learning rate: 4.3615e-05]
	Learning Rate: 4.36146e-05
	LOSS [training: 0.06188057106314661 | validation: 0.05533538756600913]
	TIME [epoch: 8.51 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05407676763288619		[learning rate: 4.3456e-05]
	Learning Rate: 4.34563e-05
	LOSS [training: 0.05407676763288619 | validation: 0.05570324140652769]
	TIME [epoch: 8.52 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05235572323761863		[learning rate: 4.3299e-05]
	Learning Rate: 4.32986e-05
	LOSS [training: 0.05235572323761863 | validation: 0.05363766886053639]
	TIME [epoch: 8.5 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050618843803062384		[learning rate: 4.3141e-05]
	Learning Rate: 4.31415e-05
	LOSS [training: 0.050618843803062384 | validation: 0.055697554766816426]
	TIME [epoch: 8.51 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05223236055408944		[learning rate: 4.2985e-05]
	Learning Rate: 4.29849e-05
	LOSS [training: 0.05223236055408944 | validation: 0.05320987298347277]
	TIME [epoch: 8.5 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050995929001223		[learning rate: 4.2829e-05]
	Learning Rate: 4.28289e-05
	LOSS [training: 0.050995929001223 | validation: 0.0393117285299486]
	TIME [epoch: 8.52 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049487993086665946		[learning rate: 4.2673e-05]
	Learning Rate: 4.26735e-05
	LOSS [training: 0.049487993086665946 | validation: 0.05091579559681715]
	TIME [epoch: 8.51 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04850545555854904		[learning rate: 4.2519e-05]
	Learning Rate: 4.25186e-05
	LOSS [training: 0.04850545555854904 | validation: 0.05389657978914396]
	TIME [epoch: 8.5 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05254484875056244		[learning rate: 4.2364e-05]
	Learning Rate: 4.23643e-05
	LOSS [training: 0.05254484875056244 | validation: 0.0484127950070753]
	TIME [epoch: 8.5 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05073274723285855		[learning rate: 4.2211e-05]
	Learning Rate: 4.22106e-05
	LOSS [training: 0.05073274723285855 | validation: 0.04819751976915816]
	TIME [epoch: 8.5 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048551070835450495		[learning rate: 4.2057e-05]
	Learning Rate: 4.20574e-05
	LOSS [training: 0.048551070835450495 | validation: 0.04439759015730033]
	TIME [epoch: 8.53 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05462085495693556		[learning rate: 4.1905e-05]
	Learning Rate: 4.19047e-05
	LOSS [training: 0.05462085495693556 | validation: 0.050840838050913335]
	TIME [epoch: 8.5 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05339780885428178		[learning rate: 4.1753e-05]
	Learning Rate: 4.17527e-05
	LOSS [training: 0.05339780885428178 | validation: 0.05084786326373432]
	TIME [epoch: 8.5 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05611898990877555		[learning rate: 4.1601e-05]
	Learning Rate: 4.16012e-05
	LOSS [training: 0.05611898990877555 | validation: 0.049533165272310595]
	TIME [epoch: 8.5 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049945605885808535		[learning rate: 4.145e-05]
	Learning Rate: 4.14502e-05
	LOSS [training: 0.049945605885808535 | validation: 0.05006880291823866]
	TIME [epoch: 8.53 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04893411749811257		[learning rate: 4.13e-05]
	Learning Rate: 4.12998e-05
	LOSS [training: 0.04893411749811257 | validation: 0.04272391191431536]
	TIME [epoch: 8.5 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04823916907193916		[learning rate: 4.115e-05]
	Learning Rate: 4.11499e-05
	LOSS [training: 0.04823916907193916 | validation: 0.05601805599424885]
	TIME [epoch: 8.51 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053019313290141666		[learning rate: 4.1001e-05]
	Learning Rate: 4.10005e-05
	LOSS [training: 0.053019313290141666 | validation: 0.04612130257676851]
	TIME [epoch: 8.5 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056857274948247424		[learning rate: 4.0852e-05]
	Learning Rate: 4.08517e-05
	LOSS [training: 0.056857274948247424 | validation: 0.05734526615308289]
	TIME [epoch: 8.52 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05282515032261285		[learning rate: 4.0703e-05]
	Learning Rate: 4.07035e-05
	LOSS [training: 0.05282515032261285 | validation: 0.05872080039099491]
	TIME [epoch: 8.5 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053476222520940156		[learning rate: 4.0556e-05]
	Learning Rate: 4.05558e-05
	LOSS [training: 0.053476222520940156 | validation: 0.05885906397639899]
	TIME [epoch: 8.49 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05137997670665687		[learning rate: 4.0409e-05]
	Learning Rate: 4.04086e-05
	LOSS [training: 0.05137997670665687 | validation: 0.05508422322114087]
	TIME [epoch: 8.49 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05178698577971563		[learning rate: 4.0262e-05]
	Learning Rate: 4.0262e-05
	LOSS [training: 0.05178698577971563 | validation: 0.0609437449975079]
	TIME [epoch: 8.51 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054877494865095446		[learning rate: 4.0116e-05]
	Learning Rate: 4.01158e-05
	LOSS [training: 0.054877494865095446 | validation: 0.047833793754132596]
	TIME [epoch: 8.5 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05114774495223011		[learning rate: 3.997e-05]
	Learning Rate: 3.99703e-05
	LOSS [training: 0.05114774495223011 | validation: 0.05721476609990778]
	TIME [epoch: 8.49 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05430146607331434		[learning rate: 3.9825e-05]
	Learning Rate: 3.98252e-05
	LOSS [training: 0.05430146607331434 | validation: 0.0581452495534283]
	TIME [epoch: 8.49 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05487687290411666		[learning rate: 3.9681e-05]
	Learning Rate: 3.96807e-05
	LOSS [training: 0.05487687290411666 | validation: 0.04874093925269091]
	TIME [epoch: 8.5 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048788584753882466		[learning rate: 3.9537e-05]
	Learning Rate: 3.95367e-05
	LOSS [training: 0.048788584753882466 | validation: 0.055515502969320604]
	TIME [epoch: 8.51 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05378569361441243		[learning rate: 3.9393e-05]
	Learning Rate: 3.93932e-05
	LOSS [training: 0.05378569361441243 | validation: 0.0627755056104998]
	TIME [epoch: 8.49 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060759495856590386		[learning rate: 3.925e-05]
	Learning Rate: 3.92502e-05
	LOSS [training: 0.060759495856590386 | validation: 0.047976885016203646]
	TIME [epoch: 8.49 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04783519434617893		[learning rate: 3.9108e-05]
	Learning Rate: 3.91078e-05
	LOSS [training: 0.04783519434617893 | validation: 0.03728372765627945]
	TIME [epoch: 8.5 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05370859210961221		[learning rate: 3.8966e-05]
	Learning Rate: 3.89659e-05
	LOSS [training: 0.05370859210961221 | validation: 0.05233255153696509]
	TIME [epoch: 8.53 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057024978081970754		[learning rate: 3.8824e-05]
	Learning Rate: 3.88245e-05
	LOSS [training: 0.057024978081970754 | validation: 0.06000275615809486]
	TIME [epoch: 8.5 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05763378763352965		[learning rate: 3.8684e-05]
	Learning Rate: 3.86836e-05
	LOSS [training: 0.05763378763352965 | validation: 0.059470045936936666]
	TIME [epoch: 8.49 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0515470942618649		[learning rate: 3.8543e-05]
	Learning Rate: 3.85432e-05
	LOSS [training: 0.0515470942618649 | validation: 0.05324651433220075]
	TIME [epoch: 8.49 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05055083788442366		[learning rate: 3.8403e-05]
	Learning Rate: 3.84033e-05
	LOSS [training: 0.05055083788442366 | validation: 0.052116737626364665]
	TIME [epoch: 8.52 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05243442047819212		[learning rate: 3.8264e-05]
	Learning Rate: 3.82639e-05
	LOSS [training: 0.05243442047819212 | validation: 0.04105945896059564]
	TIME [epoch: 8.5 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05300441011822393		[learning rate: 3.8125e-05]
	Learning Rate: 3.81251e-05
	LOSS [training: 0.05300441011822393 | validation: 0.05059535018772013]
	TIME [epoch: 8.49 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05110848756887687		[learning rate: 3.7987e-05]
	Learning Rate: 3.79867e-05
	LOSS [training: 0.05110848756887687 | validation: 0.05388043099328882]
	TIME [epoch: 8.5 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05385351013151006		[learning rate: 3.7849e-05]
	Learning Rate: 3.78489e-05
	LOSS [training: 0.05385351013151006 | validation: 0.054559704529277754]
	TIME [epoch: 8.51 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050112135803475365		[learning rate: 3.7711e-05]
	Learning Rate: 3.77115e-05
	LOSS [training: 0.050112135803475365 | validation: 0.04819968010791836]
	TIME [epoch: 8.51 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05620479199435772		[learning rate: 3.7575e-05]
	Learning Rate: 3.75746e-05
	LOSS [training: 0.05620479199435772 | validation: 0.04632263814528097]
	TIME [epoch: 8.5 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05493481040085393		[learning rate: 3.7438e-05]
	Learning Rate: 3.74383e-05
	LOSS [training: 0.05493481040085393 | validation: 0.0486090729145322]
	TIME [epoch: 8.5 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0499733757624949		[learning rate: 3.7302e-05]
	Learning Rate: 3.73024e-05
	LOSS [training: 0.0499733757624949 | validation: 0.04267942827258339]
	TIME [epoch: 8.51 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05156046545877916		[learning rate: 3.7167e-05]
	Learning Rate: 3.7167e-05
	LOSS [training: 0.05156046545877916 | validation: 0.0513955248241687]
	TIME [epoch: 8.51 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057610969795258815		[learning rate: 3.7032e-05]
	Learning Rate: 3.70322e-05
	LOSS [training: 0.057610969795258815 | validation: 0.05132052565753374]
	TIME [epoch: 8.5 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05612243668980545		[learning rate: 3.6898e-05]
	Learning Rate: 3.68978e-05
	LOSS [training: 0.05612243668980545 | validation: 0.04739693069036974]
	TIME [epoch: 8.5 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049097472797330885		[learning rate: 3.6764e-05]
	Learning Rate: 3.67639e-05
	LOSS [training: 0.049097472797330885 | validation: 0.049596644021177236]
	TIME [epoch: 8.5 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05458277096846888		[learning rate: 3.663e-05]
	Learning Rate: 3.66304e-05
	LOSS [training: 0.05458277096846888 | validation: 0.04881606727566974]
	TIME [epoch: 8.52 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05584447604880882		[learning rate: 3.6498e-05]
	Learning Rate: 3.64975e-05
	LOSS [training: 0.05584447604880882 | validation: 0.05284781551846011]
	TIME [epoch: 8.5 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05237364778759901		[learning rate: 3.6365e-05]
	Learning Rate: 3.63651e-05
	LOSS [training: 0.05237364778759901 | validation: 0.050515391293468104]
	TIME [epoch: 8.49 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05356437890293294		[learning rate: 3.6233e-05]
	Learning Rate: 3.62331e-05
	LOSS [training: 0.05356437890293294 | validation: 0.04588151251107189]
	TIME [epoch: 8.49 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05519168230093681		[learning rate: 3.6102e-05]
	Learning Rate: 3.61016e-05
	LOSS [training: 0.05519168230093681 | validation: 0.053148919735145655]
	TIME [epoch: 8.52 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0528681193705122		[learning rate: 3.5971e-05]
	Learning Rate: 3.59706e-05
	LOSS [training: 0.0528681193705122 | validation: 0.05663262480460783]
	TIME [epoch: 8.5 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05179419868181271		[learning rate: 3.584e-05]
	Learning Rate: 3.584e-05
	LOSS [training: 0.05179419868181271 | validation: 0.049767141080951774]
	TIME [epoch: 8.5 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05300228926969832		[learning rate: 3.571e-05]
	Learning Rate: 3.571e-05
	LOSS [training: 0.05300228926969832 | validation: 0.04886843573574587]
	TIME [epoch: 8.49 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05317925609094112		[learning rate: 3.558e-05]
	Learning Rate: 3.55804e-05
	LOSS [training: 0.05317925609094112 | validation: 0.05096950555479433]
	TIME [epoch: 8.51 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05357415242142929		[learning rate: 3.5451e-05]
	Learning Rate: 3.54513e-05
	LOSS [training: 0.05357415242142929 | validation: 0.0518483103747094]
	TIME [epoch: 8.5 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049813358974315755		[learning rate: 3.5323e-05]
	Learning Rate: 3.53226e-05
	LOSS [training: 0.049813358974315755 | validation: 0.04685901055778827]
	TIME [epoch: 8.49 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05260379164061979		[learning rate: 3.5194e-05]
	Learning Rate: 3.51944e-05
	LOSS [training: 0.05260379164061979 | validation: 0.05826819414059306]
	TIME [epoch: 8.5 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04949945695849271		[learning rate: 3.5067e-05]
	Learning Rate: 3.50667e-05
	LOSS [training: 0.04949945695849271 | validation: 0.04487633685869852]
	TIME [epoch: 8.5 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05612282445191994		[learning rate: 3.4939e-05]
	Learning Rate: 3.49394e-05
	LOSS [training: 0.05612282445191994 | validation: 0.057196408613978525]
	TIME [epoch: 8.52 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0532774558318154		[learning rate: 3.4813e-05]
	Learning Rate: 3.48126e-05
	LOSS [training: 0.0532774558318154 | validation: 0.04090278606695124]
	TIME [epoch: 8.49 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05165842998698804		[learning rate: 3.4686e-05]
	Learning Rate: 3.46863e-05
	LOSS [training: 0.05165842998698804 | validation: 0.04944171934793479]
	TIME [epoch: 8.5 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05428366769145817		[learning rate: 3.456e-05]
	Learning Rate: 3.45604e-05
	LOSS [training: 0.05428366769145817 | validation: 0.05163721562622728]
	TIME [epoch: 8.5 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05335987635657631		[learning rate: 3.4435e-05]
	Learning Rate: 3.4435e-05
	LOSS [training: 0.05335987635657631 | validation: 0.04265975839111458]
	TIME [epoch: 8.52 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05493489917993134		[learning rate: 3.431e-05]
	Learning Rate: 3.431e-05
	LOSS [training: 0.05493489917993134 | validation: 0.05970185820918905]
	TIME [epoch: 8.49 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049604790930367716		[learning rate: 3.4186e-05]
	Learning Rate: 3.41855e-05
	LOSS [training: 0.049604790930367716 | validation: 0.05451013029891419]
	TIME [epoch: 8.49 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05793552905905802		[learning rate: 3.4061e-05]
	Learning Rate: 3.40615e-05
	LOSS [training: 0.05793552905905802 | validation: 0.051699513342817874]
	TIME [epoch: 8.49 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05652570031493927		[learning rate: 3.3938e-05]
	Learning Rate: 3.39378e-05
	LOSS [training: 0.05652570031493927 | validation: 0.053334121401523854]
	TIME [epoch: 8.52 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05670208181378376		[learning rate: 3.3815e-05]
	Learning Rate: 3.38147e-05
	LOSS [training: 0.05670208181378376 | validation: 0.05293191366458186]
	TIME [epoch: 8.5 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051978327101541356		[learning rate: 3.3692e-05]
	Learning Rate: 3.3692e-05
	LOSS [training: 0.051978327101541356 | validation: 0.059008539092335825]
	TIME [epoch: 8.49 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05120305153257563		[learning rate: 3.357e-05]
	Learning Rate: 3.35697e-05
	LOSS [training: 0.05120305153257563 | validation: 0.05542747679010245]
	TIME [epoch: 8.49 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05465591783154313		[learning rate: 3.3448e-05]
	Learning Rate: 3.34479e-05
	LOSS [training: 0.05465591783154313 | validation: 0.05896952559924955]
	TIME [epoch: 8.52 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0536947350557259		[learning rate: 3.3326e-05]
	Learning Rate: 3.33265e-05
	LOSS [training: 0.0536947350557259 | validation: 0.05708805516840555]
	TIME [epoch: 8.5 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049270826902820766		[learning rate: 3.3206e-05]
	Learning Rate: 3.32055e-05
	LOSS [training: 0.049270826902820766 | validation: 0.04961541845189771]
	TIME [epoch: 8.5 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05152718006598448		[learning rate: 3.3085e-05]
	Learning Rate: 3.3085e-05
	LOSS [training: 0.05152718006598448 | validation: 0.05097319063165444]
	TIME [epoch: 8.49 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05299637855712751		[learning rate: 3.2965e-05]
	Learning Rate: 3.2965e-05
	LOSS [training: 0.05299637855712751 | validation: 0.04847215211501968]
	TIME [epoch: 8.51 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05279299895886512		[learning rate: 3.2845e-05]
	Learning Rate: 3.28453e-05
	LOSS [training: 0.05279299895886512 | validation: 0.05172244619963139]
	TIME [epoch: 8.5 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04947229573128532		[learning rate: 3.2726e-05]
	Learning Rate: 3.27261e-05
	LOSS [training: 0.04947229573128532 | validation: 0.05502336001932359]
	TIME [epoch: 8.5 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05313851676207112		[learning rate: 3.2607e-05]
	Learning Rate: 3.26074e-05
	LOSS [training: 0.05313851676207112 | validation: 0.038882686644561446]
	TIME [epoch: 8.49 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0500156829081229		[learning rate: 3.2489e-05]
	Learning Rate: 3.2489e-05
	LOSS [training: 0.0500156829081229 | validation: 0.05585945992342986]
	TIME [epoch: 8.5 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05043518995812061		[learning rate: 3.2371e-05]
	Learning Rate: 3.23711e-05
	LOSS [training: 0.05043518995812061 | validation: 0.05229784807904557]
	TIME [epoch: 8.52 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05230749051853356		[learning rate: 3.2254e-05]
	Learning Rate: 3.22537e-05
	LOSS [training: 0.05230749051853356 | validation: 0.05648825368884808]
	TIME [epoch: 8.5 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057086126508086234		[learning rate: 3.2137e-05]
	Learning Rate: 3.21366e-05
	LOSS [training: 0.057086126508086234 | validation: 0.04881897332123787]
	TIME [epoch: 8.5 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054610493982433575		[learning rate: 3.202e-05]
	Learning Rate: 3.202e-05
	LOSS [training: 0.054610493982433575 | validation: 0.05333095558280779]
	TIME [epoch: 8.5 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05342167165554792		[learning rate: 3.1904e-05]
	Learning Rate: 3.19038e-05
	LOSS [training: 0.05342167165554792 | validation: 0.059719427457038496]
	TIME [epoch: 8.53 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055308280871098424		[learning rate: 3.1788e-05]
	Learning Rate: 3.1788e-05
	LOSS [training: 0.055308280871098424 | validation: 0.060343290361978705]
	TIME [epoch: 8.5 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055589068964475276		[learning rate: 3.1673e-05]
	Learning Rate: 3.16726e-05
	LOSS [training: 0.055589068964475276 | validation: 0.05901208154936364]
	TIME [epoch: 8.49 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052447468109034265		[learning rate: 3.1558e-05]
	Learning Rate: 3.15577e-05
	LOSS [training: 0.052447468109034265 | validation: 0.05768735362511046]
	TIME [epoch: 8.49 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05639665026293241		[learning rate: 3.1443e-05]
	Learning Rate: 3.14432e-05
	LOSS [training: 0.05639665026293241 | validation: 0.0599157847219791]
	TIME [epoch: 8.51 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05713496922578028		[learning rate: 3.1329e-05]
	Learning Rate: 3.13291e-05
	LOSS [training: 0.05713496922578028 | validation: 0.05593336963018648]
	TIME [epoch: 8.49 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051779183934748986		[learning rate: 3.1215e-05]
	Learning Rate: 3.12154e-05
	LOSS [training: 0.051779183934748986 | validation: 0.05185126508465621]
	TIME [epoch: 8.49 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05421942508752871		[learning rate: 3.1102e-05]
	Learning Rate: 3.11021e-05
	LOSS [training: 0.05421942508752871 | validation: 0.059231722285051205]
	TIME [epoch: 8.49 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04997047233532113		[learning rate: 3.0989e-05]
	Learning Rate: 3.09892e-05
	LOSS [training: 0.04997047233532113 | validation: 0.04988402561597948]
	TIME [epoch: 8.51 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04398961100567277		[learning rate: 3.0877e-05]
	Learning Rate: 3.08768e-05
	LOSS [training: 0.04398961100567277 | validation: 0.04903403941268979]
	TIME [epoch: 8.5 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04931895206028407		[learning rate: 3.0765e-05]
	Learning Rate: 3.07647e-05
	LOSS [training: 0.04931895206028407 | validation: 0.04724453681173264]
	TIME [epoch: 8.49 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05117337156150139		[learning rate: 3.0653e-05]
	Learning Rate: 3.0653e-05
	LOSS [training: 0.05117337156150139 | validation: 0.0488919396016175]
	TIME [epoch: 8.5 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05304661798695326		[learning rate: 3.0542e-05]
	Learning Rate: 3.05418e-05
	LOSS [training: 0.05304661798695326 | validation: 0.051828654041559674]
	TIME [epoch: 8.5 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05218700622440507		[learning rate: 3.0431e-05]
	Learning Rate: 3.0431e-05
	LOSS [training: 0.05218700622440507 | validation: 0.054387013465933456]
	TIME [epoch: 8.52 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05584668601485345		[learning rate: 3.0321e-05]
	Learning Rate: 3.03205e-05
	LOSS [training: 0.05584668601485345 | validation: 0.04292792764383539]
	TIME [epoch: 8.51 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04993572955333768		[learning rate: 3.0211e-05]
	Learning Rate: 3.02105e-05
	LOSS [training: 0.04993572955333768 | validation: 0.0491580108225962]
	TIME [epoch: 8.49 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05201888394506578		[learning rate: 3.0101e-05]
	Learning Rate: 3.01009e-05
	LOSS [training: 0.05201888394506578 | validation: 0.0581367040564565]
	TIME [epoch: 8.49 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054256608965078626		[learning rate: 2.9992e-05]
	Learning Rate: 2.99916e-05
	LOSS [training: 0.054256608965078626 | validation: 0.04518413787364075]
	TIME [epoch: 8.52 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04557860083003375		[learning rate: 2.9883e-05]
	Learning Rate: 2.98828e-05
	LOSS [training: 0.04557860083003375 | validation: 0.0411389588222537]
	TIME [epoch: 8.49 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05134184425097774		[learning rate: 2.9774e-05]
	Learning Rate: 2.97743e-05
	LOSS [training: 0.05134184425097774 | validation: 0.04490226008274299]
	TIME [epoch: 8.49 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05605339562700418		[learning rate: 2.9666e-05]
	Learning Rate: 2.96663e-05
	LOSS [training: 0.05605339562700418 | validation: 0.046906485906398]
	TIME [epoch: 8.49 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047923340336176616		[learning rate: 2.9559e-05]
	Learning Rate: 2.95586e-05
	LOSS [training: 0.047923340336176616 | validation: 0.05564410815287056]
	TIME [epoch: 8.52 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04739360025534688		[learning rate: 2.9451e-05]
	Learning Rate: 2.94514e-05
	LOSS [training: 0.04739360025534688 | validation: 0.042415577757263144]
	TIME [epoch: 8.5 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050940769835816066		[learning rate: 2.9344e-05]
	Learning Rate: 2.93445e-05
	LOSS [training: 0.050940769835816066 | validation: 0.04951205710423294]
	TIME [epoch: 8.5 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04999444752216092		[learning rate: 2.9238e-05]
	Learning Rate: 2.9238e-05
	LOSS [training: 0.04999444752216092 | validation: 0.0499009283334345]
	TIME [epoch: 8.5 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053868661408786635		[learning rate: 2.9132e-05]
	Learning Rate: 2.91319e-05
	LOSS [training: 0.053868661408786635 | validation: 0.04037082686678807]
	TIME [epoch: 8.51 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05229803289053682		[learning rate: 2.9026e-05]
	Learning Rate: 2.90262e-05
	LOSS [training: 0.05229803289053682 | validation: 0.04224470597474495]
	TIME [epoch: 8.51 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05175283552681461		[learning rate: 2.8921e-05]
	Learning Rate: 2.89208e-05
	LOSS [training: 0.05175283552681461 | validation: 0.04808393604000005]
	TIME [epoch: 8.5 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05438909335716745		[learning rate: 2.8816e-05]
	Learning Rate: 2.88159e-05
	LOSS [training: 0.05438909335716745 | validation: 0.05728039264056432]
	TIME [epoch: 8.5 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051639373597995475		[learning rate: 2.8711e-05]
	Learning Rate: 2.87113e-05
	LOSS [training: 0.051639373597995475 | validation: 0.05397747114385662]
	TIME [epoch: 8.49 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05261345534381764		[learning rate: 2.8607e-05]
	Learning Rate: 2.86071e-05
	LOSS [training: 0.05261345534381764 | validation: 0.05006959047303851]
	TIME [epoch: 8.53 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053203899824972076		[learning rate: 2.8503e-05]
	Learning Rate: 2.85033e-05
	LOSS [training: 0.053203899824972076 | validation: 0.056017581597072486]
	TIME [epoch: 8.49 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05385320018594873		[learning rate: 2.84e-05]
	Learning Rate: 2.83998e-05
	LOSS [training: 0.05385320018594873 | validation: 0.04287123441441318]
	TIME [epoch: 8.5 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05222951359467378		[learning rate: 2.8297e-05]
	Learning Rate: 2.82968e-05
	LOSS [training: 0.05222951359467378 | validation: 0.05228017545263842]
	TIME [epoch: 8.5 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05114119755079347		[learning rate: 2.8194e-05]
	Learning Rate: 2.81941e-05
	LOSS [training: 0.05114119755079347 | validation: 0.056731482714466805]
	TIME [epoch: 8.53 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051715496887665455		[learning rate: 2.8092e-05]
	Learning Rate: 2.80918e-05
	LOSS [training: 0.051715496887665455 | validation: 0.04855315375573743]
	TIME [epoch: 8.5 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04732819333341925		[learning rate: 2.799e-05]
	Learning Rate: 2.79898e-05
	LOSS [training: 0.04732819333341925 | validation: 0.05149833116279377]
	TIME [epoch: 8.5 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05138007432212642		[learning rate: 2.7888e-05]
	Learning Rate: 2.78882e-05
	LOSS [training: 0.05138007432212642 | validation: 0.04765689414980523]
	TIME [epoch: 8.49 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05089201379307638		[learning rate: 2.7787e-05]
	Learning Rate: 2.7787e-05
	LOSS [training: 0.05089201379307638 | validation: 0.042808552211042974]
	TIME [epoch: 8.53 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053498106124937495		[learning rate: 2.7686e-05]
	Learning Rate: 2.76862e-05
	LOSS [training: 0.053498106124937495 | validation: 0.04910213507654218]
	TIME [epoch: 8.51 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05119110901665368		[learning rate: 2.7586e-05]
	Learning Rate: 2.75857e-05
	LOSS [training: 0.05119110901665368 | validation: 0.0495317810278316]
	TIME [epoch: 8.51 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052397095033139676		[learning rate: 2.7486e-05]
	Learning Rate: 2.74856e-05
	LOSS [training: 0.052397095033139676 | validation: 0.042909681894278184]
	TIME [epoch: 8.5 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049013666320571164		[learning rate: 2.7386e-05]
	Learning Rate: 2.73859e-05
	LOSS [training: 0.049013666320571164 | validation: 0.05461312381088256]
	TIME [epoch: 8.52 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04971532356970931		[learning rate: 2.7286e-05]
	Learning Rate: 2.72865e-05
	LOSS [training: 0.04971532356970931 | validation: 0.05395279135221804]
	TIME [epoch: 8.51 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05306479572015953		[learning rate: 2.7187e-05]
	Learning Rate: 2.71875e-05
	LOSS [training: 0.05306479572015953 | validation: 0.048515324032823756]
	TIME [epoch: 8.5 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049527851521535535		[learning rate: 2.7089e-05]
	Learning Rate: 2.70888e-05
	LOSS [training: 0.049527851521535535 | validation: 0.057065917224425666]
	TIME [epoch: 8.51 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05319295036711846		[learning rate: 2.699e-05]
	Learning Rate: 2.69905e-05
	LOSS [training: 0.05319295036711846 | validation: 0.050727708093333546]
	TIME [epoch: 8.5 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053783444677924085		[learning rate: 2.6893e-05]
	Learning Rate: 2.68925e-05
	LOSS [training: 0.053783444677924085 | validation: 0.04993882689466714]
	TIME [epoch: 8.53 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049949474824202325		[learning rate: 2.6795e-05]
	Learning Rate: 2.67949e-05
	LOSS [training: 0.049949474824202325 | validation: 0.052355161413116774]
	TIME [epoch: 8.5 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04974914697434205		[learning rate: 2.6698e-05]
	Learning Rate: 2.66977e-05
	LOSS [training: 0.04974914697434205 | validation: 0.049603710035061456]
	TIME [epoch: 8.51 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05087751686606097		[learning rate: 2.6601e-05]
	Learning Rate: 2.66008e-05
	LOSS [training: 0.05087751686606097 | validation: 0.0518835061677648]
	TIME [epoch: 8.5 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05216982892262796		[learning rate: 2.6504e-05]
	Learning Rate: 2.65043e-05
	LOSS [training: 0.05216982892262796 | validation: 0.052812807582142754]
	TIME [epoch: 8.53 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052531809915434234		[learning rate: 2.6408e-05]
	Learning Rate: 2.64081e-05
	LOSS [training: 0.052531809915434234 | validation: 0.06346386101667587]
	TIME [epoch: 8.51 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05462967458947493		[learning rate: 2.6312e-05]
	Learning Rate: 2.63123e-05
	LOSS [training: 0.05462967458947493 | validation: 0.06442972307383202]
	TIME [epoch: 8.5 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050076133255904265		[learning rate: 2.6217e-05]
	Learning Rate: 2.62168e-05
	LOSS [training: 0.050076133255904265 | validation: 0.045731174026761905]
	TIME [epoch: 8.49 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049746591900898564		[learning rate: 2.6122e-05]
	Learning Rate: 2.61216e-05
	LOSS [training: 0.049746591900898564 | validation: 0.04994125336236255]
	TIME [epoch: 8.52 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04830104740576972		[learning rate: 2.6027e-05]
	Learning Rate: 2.60268e-05
	LOSS [training: 0.04830104740576972 | validation: 0.06470552174172683]
	TIME [epoch: 8.51 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055409946768576565		[learning rate: 2.5932e-05]
	Learning Rate: 2.59324e-05
	LOSS [training: 0.055409946768576565 | validation: 0.052192655368976576]
	TIME [epoch: 8.5 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05047341186266931		[learning rate: 2.5838e-05]
	Learning Rate: 2.58383e-05
	LOSS [training: 0.05047341186266931 | validation: 0.05208681682185476]
	TIME [epoch: 8.5 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05116759205410666		[learning rate: 2.5744e-05]
	Learning Rate: 2.57445e-05
	LOSS [training: 0.05116759205410666 | validation: 0.0544743142187739]
	TIME [epoch: 8.51 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05588327635745518		[learning rate: 2.5651e-05]
	Learning Rate: 2.56511e-05
	LOSS [training: 0.05588327635745518 | validation: 0.0568001700873897]
	TIME [epoch: 8.51 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052654317302832		[learning rate: 2.5558e-05]
	Learning Rate: 2.5558e-05
	LOSS [training: 0.052654317302832 | validation: 0.054536587539276274]
	TIME [epoch: 8.49 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0511410156246249		[learning rate: 2.5465e-05]
	Learning Rate: 2.54652e-05
	LOSS [training: 0.0511410156246249 | validation: 0.04709754533109282]
	TIME [epoch: 8.5 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0554925611023341		[learning rate: 2.5373e-05]
	Learning Rate: 2.53728e-05
	LOSS [training: 0.0554925611023341 | validation: 0.046798158373538304]
	TIME [epoch: 8.5 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05376797398493437		[learning rate: 2.5281e-05]
	Learning Rate: 2.52807e-05
	LOSS [training: 0.05376797398493437 | validation: 0.058102903694682476]
	TIME [epoch: 8.52 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05253402496383937		[learning rate: 2.5189e-05]
	Learning Rate: 2.5189e-05
	LOSS [training: 0.05253402496383937 | validation: 0.05925813624295511]
	TIME [epoch: 8.5 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05127313335638868		[learning rate: 2.5098e-05]
	Learning Rate: 2.50976e-05
	LOSS [training: 0.05127313335638868 | validation: 0.05411634258521325]
	TIME [epoch: 8.5 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05249790359003372		[learning rate: 2.5006e-05]
	Learning Rate: 2.50065e-05
	LOSS [training: 0.05249790359003372 | validation: 0.049603069432654606]
	TIME [epoch: 8.5 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0545032743707484		[learning rate: 2.4916e-05]
	Learning Rate: 2.49157e-05
	LOSS [training: 0.0545032743707484 | validation: 0.040602452589889176]
	TIME [epoch: 8.53 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053867982326575234		[learning rate: 2.4825e-05]
	Learning Rate: 2.48253e-05
	LOSS [training: 0.053867982326575234 | validation: 0.04965775914181149]
	TIME [epoch: 8.49 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05392291202633531		[learning rate: 2.4735e-05]
	Learning Rate: 2.47352e-05
	LOSS [training: 0.05392291202633531 | validation: 0.04667203307588872]
	TIME [epoch: 8.51 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048498313899439385		[learning rate: 2.4645e-05]
	Learning Rate: 2.46455e-05
	LOSS [training: 0.048498313899439385 | validation: 0.054198041826425424]
	TIME [epoch: 8.5 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05155740955228468		[learning rate: 2.4556e-05]
	Learning Rate: 2.4556e-05
	LOSS [training: 0.05155740955228468 | validation: 0.05411498549794608]
	TIME [epoch: 8.52 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050958292077755554		[learning rate: 2.4467e-05]
	Learning Rate: 2.44669e-05
	LOSS [training: 0.050958292077755554 | validation: 0.06108769063121107]
	TIME [epoch: 8.5 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05281659292857275		[learning rate: 2.4378e-05]
	Learning Rate: 2.43781e-05
	LOSS [training: 0.05281659292857275 | validation: 0.05267881856840896]
	TIME [epoch: 8.51 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051117416279741645		[learning rate: 2.429e-05]
	Learning Rate: 2.42896e-05
	LOSS [training: 0.051117416279741645 | validation: 0.047137267792642046]
	TIME [epoch: 8.5 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050502775533552514		[learning rate: 2.4201e-05]
	Learning Rate: 2.42015e-05
	LOSS [training: 0.050502775533552514 | validation: 0.05404505838019723]
	TIME [epoch: 8.52 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051126752797561306		[learning rate: 2.4114e-05]
	Learning Rate: 2.41137e-05
	LOSS [training: 0.051126752797561306 | validation: 0.04692491928559168]
	TIME [epoch: 8.5 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05003110350613356		[learning rate: 2.4026e-05]
	Learning Rate: 2.40262e-05
	LOSS [training: 0.05003110350613356 | validation: 0.04488734302861176]
	TIME [epoch: 8.51 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054014628641604834		[learning rate: 2.3939e-05]
	Learning Rate: 2.3939e-05
	LOSS [training: 0.054014628641604834 | validation: 0.04824553589853953]
	TIME [epoch: 8.5 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05139841544437378		[learning rate: 2.3852e-05]
	Learning Rate: 2.38521e-05
	LOSS [training: 0.05139841544437378 | validation: 0.05761473836467225]
	TIME [epoch: 8.5 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05473085075034136		[learning rate: 2.3766e-05]
	Learning Rate: 2.37655e-05
	LOSS [training: 0.05473085075034136 | validation: 0.05468406782090776]
	TIME [epoch: 8.52 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05466254975145105		[learning rate: 2.3679e-05]
	Learning Rate: 2.36793e-05
	LOSS [training: 0.05466254975145105 | validation: 0.049212062747730906]
	TIME [epoch: 8.5 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05248707359779788		[learning rate: 2.3593e-05]
	Learning Rate: 2.35933e-05
	LOSS [training: 0.05248707359779788 | validation: 0.054500844617845545]
	TIME [epoch: 8.5 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04946584615586859		[learning rate: 2.3508e-05]
	Learning Rate: 2.35077e-05
	LOSS [training: 0.04946584615586859 | validation: 0.042003916685412826]
	TIME [epoch: 8.5 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05387184058610443		[learning rate: 2.3422e-05]
	Learning Rate: 2.34224e-05
	LOSS [training: 0.05387184058610443 | validation: 0.05617477425635768]
	TIME [epoch: 8.52 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05401312635740918		[learning rate: 2.3337e-05]
	Learning Rate: 2.33374e-05
	LOSS [training: 0.05401312635740918 | validation: 0.057127434019742684]
	TIME [epoch: 8.51 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05495843364147331		[learning rate: 2.3253e-05]
	Learning Rate: 2.32527e-05
	LOSS [training: 0.05495843364147331 | validation: 0.04561528507128665]
	TIME [epoch: 8.5 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054288277520538164		[learning rate: 2.3168e-05]
	Learning Rate: 2.31683e-05
	LOSS [training: 0.054288277520538164 | validation: 0.06047595584133322]
	TIME [epoch: 8.5 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050349910884554774		[learning rate: 2.3084e-05]
	Learning Rate: 2.30843e-05
	LOSS [training: 0.050349910884554774 | validation: 0.060685546001738463]
	TIME [epoch: 8.52 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05151727084800467		[learning rate: 2.3e-05]
	Learning Rate: 2.30005e-05
	LOSS [training: 0.05151727084800467 | validation: 0.04875558117131494]
	TIME [epoch: 8.5 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05479414379075235		[learning rate: 2.2917e-05]
	Learning Rate: 2.2917e-05
	LOSS [training: 0.05479414379075235 | validation: 0.050499885405383874]
	TIME [epoch: 8.5 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051308635167114106		[learning rate: 2.2834e-05]
	Learning Rate: 2.28338e-05
	LOSS [training: 0.051308635167114106 | validation: 0.04857159781519271]
	TIME [epoch: 8.49 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052707507245164376		[learning rate: 2.2751e-05]
	Learning Rate: 2.2751e-05
	LOSS [training: 0.052707507245164376 | validation: 0.05860086723432411]
	TIME [epoch: 8.51 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053491194691142364		[learning rate: 2.2668e-05]
	Learning Rate: 2.26684e-05
	LOSS [training: 0.053491194691142364 | validation: 0.056222494890422116]
	TIME [epoch: 8.51 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05934590302061273		[learning rate: 2.2586e-05]
	Learning Rate: 2.25862e-05
	LOSS [training: 0.05934590302061273 | validation: 0.06115510377864828]
	TIME [epoch: 8.5 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05039808030037699		[learning rate: 2.2504e-05]
	Learning Rate: 2.25042e-05
	LOSS [training: 0.05039808030037699 | validation: 0.052871873008416344]
	TIME [epoch: 8.5 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0541554447892371		[learning rate: 2.2423e-05]
	Learning Rate: 2.24225e-05
	LOSS [training: 0.0541554447892371 | validation: 0.04709884314482327]
	TIME [epoch: 8.51 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05374233024736769		[learning rate: 2.2341e-05]
	Learning Rate: 2.23411e-05
	LOSS [training: 0.05374233024736769 | validation: 0.051912876525744625]
	TIME [epoch: 8.52 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055256033534005454		[learning rate: 2.226e-05]
	Learning Rate: 2.22601e-05
	LOSS [training: 0.055256033534005454 | validation: 0.05120758246151168]
	TIME [epoch: 8.51 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05995214824794952		[learning rate: 2.2179e-05]
	Learning Rate: 2.21793e-05
	LOSS [training: 0.05995214824794952 | validation: 0.05593404279523123]
	TIME [epoch: 8.5 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05629833139055568		[learning rate: 2.2099e-05]
	Learning Rate: 2.20988e-05
	LOSS [training: 0.05629833139055568 | validation: 0.04376764849834883]
	TIME [epoch: 8.51 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051424249352522836		[learning rate: 2.2019e-05]
	Learning Rate: 2.20186e-05
	LOSS [training: 0.051424249352522836 | validation: 0.055138269104548394]
	TIME [epoch: 8.53 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053252684797140584		[learning rate: 2.1939e-05]
	Learning Rate: 2.19387e-05
	LOSS [training: 0.053252684797140584 | validation: 0.05277546866520945]
	TIME [epoch: 8.51 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0483543473010625		[learning rate: 2.1859e-05]
	Learning Rate: 2.18591e-05
	LOSS [training: 0.0483543473010625 | validation: 0.040424485896866785]
	TIME [epoch: 8.5 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05290225835390407		[learning rate: 2.178e-05]
	Learning Rate: 2.17797e-05
	LOSS [training: 0.05290225835390407 | validation: 0.05066091731658704]
	TIME [epoch: 8.51 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05178623201489737		[learning rate: 2.1701e-05]
	Learning Rate: 2.17007e-05
	LOSS [training: 0.05178623201489737 | validation: 0.048774423471777045]
	TIME [epoch: 8.52 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05161370098922667		[learning rate: 2.1622e-05]
	Learning Rate: 2.16219e-05
	LOSS [training: 0.05161370098922667 | validation: 0.04391986996846324]
	TIME [epoch: 8.51 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05093390562762849		[learning rate: 2.1543e-05]
	Learning Rate: 2.15435e-05
	LOSS [training: 0.05093390562762849 | validation: 0.045642447466372804]
	TIME [epoch: 8.5 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05354548503381468		[learning rate: 2.1465e-05]
	Learning Rate: 2.14653e-05
	LOSS [training: 0.05354548503381468 | validation: 0.058061806502627294]
	TIME [epoch: 8.5 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05460342528482866		[learning rate: 2.1387e-05]
	Learning Rate: 2.13874e-05
	LOSS [training: 0.05460342528482866 | validation: 0.04763842779211508]
	TIME [epoch: 8.52 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05049421778195392		[learning rate: 2.131e-05]
	Learning Rate: 2.13098e-05
	LOSS [training: 0.05049421778195392 | validation: 0.04984139093943092]
	TIME [epoch: 8.5 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04739341888957432		[learning rate: 2.1232e-05]
	Learning Rate: 2.12325e-05
	LOSS [training: 0.04739341888957432 | validation: 0.04643593677034251]
	TIME [epoch: 8.51 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05099269179560739		[learning rate: 2.1155e-05]
	Learning Rate: 2.11554e-05
	LOSS [training: 0.05099269179560739 | validation: 0.04768793150008107]
	TIME [epoch: 8.5 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050417996652377596		[learning rate: 2.1079e-05]
	Learning Rate: 2.10786e-05
	LOSS [training: 0.050417996652377596 | validation: 0.053593696169597485]
	TIME [epoch: 8.52 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05002798911352274		[learning rate: 2.1002e-05]
	Learning Rate: 2.10021e-05
	LOSS [training: 0.05002798911352274 | validation: 0.04223424159468307]
	TIME [epoch: 8.51 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04952966083870782		[learning rate: 2.0926e-05]
	Learning Rate: 2.09259e-05
	LOSS [training: 0.04952966083870782 | validation: 0.04646493209531172]
	TIME [epoch: 8.51 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05230964734424941		[learning rate: 2.085e-05]
	Learning Rate: 2.085e-05
	LOSS [training: 0.05230964734424941 | validation: 0.05396919267792734]
	TIME [epoch: 8.5 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05182486664803473		[learning rate: 2.0774e-05]
	Learning Rate: 2.07743e-05
	LOSS [training: 0.05182486664803473 | validation: 0.05686672415767541]
	TIME [epoch: 8.51 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04883325410842075		[learning rate: 2.0699e-05]
	Learning Rate: 2.06989e-05
	LOSS [training: 0.04883325410842075 | validation: 0.05501256661761512]
	TIME [epoch: 8.52 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053688276383634694		[learning rate: 2.0624e-05]
	Learning Rate: 2.06238e-05
	LOSS [training: 0.053688276383634694 | validation: 0.04556016063634323]
	TIME [epoch: 8.5 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04900787488218898		[learning rate: 2.0549e-05]
	Learning Rate: 2.05489e-05
	LOSS [training: 0.04900787488218898 | validation: 0.0503574614754289]
	TIME [epoch: 8.5 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044689027084692044		[learning rate: 2.0474e-05]
	Learning Rate: 2.04744e-05
	LOSS [training: 0.044689027084692044 | validation: 0.05060025178846008]
	TIME [epoch: 8.49 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052531180196644545		[learning rate: 2.04e-05]
	Learning Rate: 2.04001e-05
	LOSS [training: 0.052531180196644545 | validation: 0.04735318281927782]
	TIME [epoch: 8.52 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05049228801024589		[learning rate: 2.0326e-05]
	Learning Rate: 2.0326e-05
	LOSS [training: 0.05049228801024589 | validation: 0.051647126369410726]
	TIME [epoch: 8.5 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05409197068424938		[learning rate: 2.0252e-05]
	Learning Rate: 2.02523e-05
	LOSS [training: 0.05409197068424938 | validation: 0.05287049402180376]
	TIME [epoch: 8.5 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05535000573723307		[learning rate: 2.0179e-05]
	Learning Rate: 2.01788e-05
	LOSS [training: 0.05535000573723307 | validation: 0.049846355854885546]
	TIME [epoch: 8.5 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05326789856391129		[learning rate: 2.0106e-05]
	Learning Rate: 2.01055e-05
	LOSS [training: 0.05326789856391129 | validation: 0.047327301689870455]
	TIME [epoch: 8.52 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053943878363934286		[learning rate: 2.0033e-05]
	Learning Rate: 2.00326e-05
	LOSS [training: 0.053943878363934286 | validation: 0.04437274321012973]
	TIME [epoch: 8.51 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050558332596473056		[learning rate: 1.996e-05]
	Learning Rate: 1.99599e-05
	LOSS [training: 0.050558332596473056 | validation: 0.04165262853057287]
	TIME [epoch: 8.5 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05194091999053061		[learning rate: 1.9887e-05]
	Learning Rate: 1.98874e-05
	LOSS [training: 0.05194091999053061 | validation: 0.06096664798057019]
	TIME [epoch: 8.49 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04717717780065557		[learning rate: 1.9815e-05]
	Learning Rate: 1.98153e-05
	LOSS [training: 0.04717717780065557 | validation: 0.043018354764262245]
	TIME [epoch: 8.51 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050853226165722056		[learning rate: 1.9743e-05]
	Learning Rate: 1.97434e-05
	LOSS [training: 0.050853226165722056 | validation: 0.04615373794148772]
	TIME [epoch: 8.5 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05404274853440129		[learning rate: 1.9672e-05]
	Learning Rate: 1.96717e-05
	LOSS [training: 0.05404274853440129 | validation: 0.05919441595996047]
	TIME [epoch: 8.49 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0513876764443845		[learning rate: 1.96e-05]
	Learning Rate: 1.96003e-05
	LOSS [training: 0.0513876764443845 | validation: 0.046334987989338744]
	TIME [epoch: 8.49 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05110753949150363		[learning rate: 1.9529e-05]
	Learning Rate: 1.95292e-05
	LOSS [training: 0.05110753949150363 | validation: 0.05125411419292476]
	TIME [epoch: 8.49 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052132723719780096		[learning rate: 1.9458e-05]
	Learning Rate: 1.94583e-05
	LOSS [training: 0.052132723719780096 | validation: 0.05375292967034297]
	TIME [epoch: 8.52 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0516027395047694		[learning rate: 1.9388e-05]
	Learning Rate: 1.93877e-05
	LOSS [training: 0.0516027395047694 | validation: 0.04658581250103849]
	TIME [epoch: 8.51 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053870165359362246		[learning rate: 1.9317e-05]
	Learning Rate: 1.93173e-05
	LOSS [training: 0.053870165359362246 | validation: 0.038991415478324506]
	TIME [epoch: 8.49 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048694368254584404		[learning rate: 1.9247e-05]
	Learning Rate: 1.92472e-05
	LOSS [training: 0.048694368254584404 | validation: 0.045458827133683724]
	TIME [epoch: 8.49 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052405629613566054		[learning rate: 1.9177e-05]
	Learning Rate: 1.91774e-05
	LOSS [training: 0.052405629613566054 | validation: 0.05699764782325011]
	TIME [epoch: 8.53 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05264200453681863		[learning rate: 1.9108e-05]
	Learning Rate: 1.91078e-05
	LOSS [training: 0.05264200453681863 | validation: 0.05187653566127687]
	TIME [epoch: 8.5 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053021763223636866		[learning rate: 1.9038e-05]
	Learning Rate: 1.90384e-05
	LOSS [training: 0.053021763223636866 | validation: 0.05043465458407466]
	TIME [epoch: 8.5 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05372493585584985		[learning rate: 1.8969e-05]
	Learning Rate: 1.89694e-05
	LOSS [training: 0.05372493585584985 | validation: 0.04882083075818763]
	TIME [epoch: 8.5 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053133086410458594		[learning rate: 1.8901e-05]
	Learning Rate: 1.89005e-05
	LOSS [training: 0.053133086410458594 | validation: 0.046683090727111284]
	TIME [epoch: 8.51 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048018345331078884		[learning rate: 1.8832e-05]
	Learning Rate: 1.88319e-05
	LOSS [training: 0.048018345331078884 | validation: 0.05204589212308729]
	TIME [epoch: 8.49 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05245724205084146		[learning rate: 1.8764e-05]
	Learning Rate: 1.87636e-05
	LOSS [training: 0.05245724205084146 | validation: 0.04621895261002883]
	TIME [epoch: 8.49 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04931212784041043		[learning rate: 1.8695e-05]
	Learning Rate: 1.86955e-05
	LOSS [training: 0.04931212784041043 | validation: 0.049472842382619474]
	TIME [epoch: 8.5 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051775079491398514		[learning rate: 1.8628e-05]
	Learning Rate: 1.86276e-05
	LOSS [training: 0.051775079491398514 | validation: 0.042013436549356936]
	TIME [epoch: 8.51 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04958930333548962		[learning rate: 1.856e-05]
	Learning Rate: 1.856e-05
	LOSS [training: 0.04958930333548962 | validation: 0.05386158232909643]
	TIME [epoch: 8.5 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0493854393599428		[learning rate: 1.8493e-05]
	Learning Rate: 1.84927e-05
	LOSS [training: 0.0493854393599428 | validation: 0.04728969279548732]
	TIME [epoch: 8.5 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05419324513696335		[learning rate: 1.8426e-05]
	Learning Rate: 1.84256e-05
	LOSS [training: 0.05419324513696335 | validation: 0.05592578401137706]
	TIME [epoch: 8.5 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047746250516934624		[learning rate: 1.8359e-05]
	Learning Rate: 1.83587e-05
	LOSS [training: 0.047746250516934624 | validation: 0.04743059721522229]
	TIME [epoch: 8.5 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04899580254853171		[learning rate: 1.8292e-05]
	Learning Rate: 1.82921e-05
	LOSS [training: 0.04899580254853171 | validation: 0.05609320336045291]
	TIME [epoch: 8.53 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04897670723962757		[learning rate: 1.8226e-05]
	Learning Rate: 1.82257e-05
	LOSS [training: 0.04897670723962757 | validation: 0.045115199148587595]
	TIME [epoch: 8.5 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05041442075692345		[learning rate: 1.816e-05]
	Learning Rate: 1.81596e-05
	LOSS [training: 0.05041442075692345 | validation: 0.0461672277963171]
	TIME [epoch: 8.5 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04853334487596784		[learning rate: 1.8094e-05]
	Learning Rate: 1.80937e-05
	LOSS [training: 0.04853334487596784 | validation: 0.05684263687024222]
	TIME [epoch: 8.5 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053303584278715586		[learning rate: 1.8028e-05]
	Learning Rate: 1.8028e-05
	LOSS [training: 0.053303584278715586 | validation: 0.050353876795909684]
	TIME [epoch: 8.52 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04930647624091297		[learning rate: 1.7963e-05]
	Learning Rate: 1.79626e-05
	LOSS [training: 0.04930647624091297 | validation: 0.04214465371268702]
	TIME [epoch: 8.5 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050746828882047346		[learning rate: 1.7897e-05]
	Learning Rate: 1.78974e-05
	LOSS [training: 0.050746828882047346 | validation: 0.051166194064275236]
	TIME [epoch: 8.5 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056094844766074646		[learning rate: 1.7832e-05]
	Learning Rate: 1.78324e-05
	LOSS [training: 0.056094844766074646 | validation: 0.04782603425205045]
	TIME [epoch: 8.5 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051732846589830336		[learning rate: 1.7768e-05]
	Learning Rate: 1.77677e-05
	LOSS [training: 0.051732846589830336 | validation: 0.049348837334370135]
	TIME [epoch: 8.52 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04962181779048572		[learning rate: 1.7703e-05]
	Learning Rate: 1.77032e-05
	LOSS [training: 0.04962181779048572 | validation: 0.053975935866847236]
	TIME [epoch: 8.5 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048539621623005014		[learning rate: 1.7639e-05]
	Learning Rate: 1.7639e-05
	LOSS [training: 0.048539621623005014 | validation: 0.053275391501853606]
	TIME [epoch: 8.49 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04896452713607653		[learning rate: 1.7575e-05]
	Learning Rate: 1.7575e-05
	LOSS [training: 0.04896452713607653 | validation: 0.05692857325578891]
	TIME [epoch: 8.49 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05156060317930106		[learning rate: 1.7511e-05]
	Learning Rate: 1.75112e-05
	LOSS [training: 0.05156060317930106 | validation: 0.05042806629859567]
	TIME [epoch: 8.51 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05192651884271423		[learning rate: 1.7448e-05]
	Learning Rate: 1.74476e-05
	LOSS [training: 0.05192651884271423 | validation: 0.04325988083050509]
	TIME [epoch: 8.51 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051325768899201096		[learning rate: 1.7384e-05]
	Learning Rate: 1.73843e-05
	LOSS [training: 0.051325768899201096 | validation: 0.05584056225604839]
	TIME [epoch: 8.51 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0485795695370956		[learning rate: 1.7321e-05]
	Learning Rate: 1.73212e-05
	LOSS [training: 0.0485795695370956 | validation: 0.04652107291886538]
	TIME [epoch: 8.5 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049815617900840964		[learning rate: 1.7258e-05]
	Learning Rate: 1.72584e-05
	LOSS [training: 0.049815617900840964 | validation: 0.04744960591119141]
	TIME [epoch: 8.51 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05404015085630241		[learning rate: 1.7196e-05]
	Learning Rate: 1.71957e-05
	LOSS [training: 0.05404015085630241 | validation: 0.03766767722625492]
	TIME [epoch: 8.52 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05524854243307163		[learning rate: 1.7133e-05]
	Learning Rate: 1.71333e-05
	LOSS [training: 0.05524854243307163 | validation: 0.054284220273760356]
	TIME [epoch: 8.5 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04808072789298934		[learning rate: 1.7071e-05]
	Learning Rate: 1.70712e-05
	LOSS [training: 0.04808072789298934 | validation: 0.04833062021554508]
	TIME [epoch: 8.5 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04873957283717433		[learning rate: 1.7009e-05]
	Learning Rate: 1.70092e-05
	LOSS [training: 0.04873957283717433 | validation: 0.049494252702366424]
	TIME [epoch: 8.5 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0541409511719686		[learning rate: 1.6947e-05]
	Learning Rate: 1.69475e-05
	LOSS [training: 0.0541409511719686 | validation: 0.05022799987953957]
	TIME [epoch: 8.53 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05535691647085642		[learning rate: 1.6886e-05]
	Learning Rate: 1.6886e-05
	LOSS [training: 0.05535691647085642 | validation: 0.06168865597147815]
	TIME [epoch: 8.5 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05262671397002302		[learning rate: 1.6825e-05]
	Learning Rate: 1.68247e-05
	LOSS [training: 0.05262671397002302 | validation: 0.059720430407606724]
	TIME [epoch: 8.49 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0536998285172718		[learning rate: 1.6764e-05]
	Learning Rate: 1.67636e-05
	LOSS [training: 0.0536998285172718 | validation: 0.06097583656902471]
	TIME [epoch: 8.5 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048101814891813824		[learning rate: 1.6703e-05]
	Learning Rate: 1.67028e-05
	LOSS [training: 0.048101814891813824 | validation: 0.05742841435545527]
	TIME [epoch: 8.52 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049751285769010035		[learning rate: 1.6642e-05]
	Learning Rate: 1.66422e-05
	LOSS [training: 0.049751285769010035 | validation: 0.044444663355994375]
	TIME [epoch: 8.51 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05156265590783893		[learning rate: 1.6582e-05]
	Learning Rate: 1.65818e-05
	LOSS [training: 0.05156265590783893 | validation: 0.05371071363453142]
	TIME [epoch: 8.5 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05319012750961507		[learning rate: 1.6522e-05]
	Learning Rate: 1.65216e-05
	LOSS [training: 0.05319012750961507 | validation: 0.04911523198555036]
	TIME [epoch: 8.51 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05264559508849744		[learning rate: 1.6462e-05]
	Learning Rate: 1.64617e-05
	LOSS [training: 0.05264559508849744 | validation: 0.04597346933058176]
	TIME [epoch: 8.52 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05540344256824938		[learning rate: 1.6402e-05]
	Learning Rate: 1.64019e-05
	LOSS [training: 0.05540344256824938 | validation: 0.051614564079513474]
	TIME [epoch: 8.52 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05488218539922329		[learning rate: 1.6342e-05]
	Learning Rate: 1.63424e-05
	LOSS [training: 0.05488218539922329 | validation: 0.05078822461952084]
	TIME [epoch: 8.5 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05128442420636344		[learning rate: 1.6283e-05]
	Learning Rate: 1.62831e-05
	LOSS [training: 0.05128442420636344 | validation: 0.048526578473524554]
	TIME [epoch: 8.51 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054105566089510206		[learning rate: 1.6224e-05]
	Learning Rate: 1.6224e-05
	LOSS [training: 0.054105566089510206 | validation: 0.05836653453896949]
	TIME [epoch: 8.51 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04852709352191917		[learning rate: 1.6165e-05]
	Learning Rate: 1.61651e-05
	LOSS [training: 0.04852709352191917 | validation: 0.05620801248379742]
	TIME [epoch: 8.52 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04898579381332728		[learning rate: 1.6106e-05]
	Learning Rate: 1.61065e-05
	LOSS [training: 0.04898579381332728 | validation: 0.04977193268254642]
	TIME [epoch: 8.51 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051890367135704926		[learning rate: 1.6048e-05]
	Learning Rate: 1.6048e-05
	LOSS [training: 0.051890367135704926 | validation: 0.04771303575477934]
	TIME [epoch: 8.51 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046048800352588244		[learning rate: 1.599e-05]
	Learning Rate: 1.59898e-05
	LOSS [training: 0.046048800352588244 | validation: 0.047112096406870044]
	TIME [epoch: 8.5 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05142778842177694		[learning rate: 1.5932e-05]
	Learning Rate: 1.59317e-05
	LOSS [training: 0.05142778842177694 | validation: 0.046062486311345074]
	TIME [epoch: 8.53 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04912510351160474		[learning rate: 1.5874e-05]
	Learning Rate: 1.58739e-05
	LOSS [training: 0.04912510351160474 | validation: 0.04333119343453139]
	TIME [epoch: 8.5 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04802477490202265		[learning rate: 1.5816e-05]
	Learning Rate: 1.58163e-05
	LOSS [training: 0.04802477490202265 | validation: 0.04455757972043792]
	TIME [epoch: 8.5 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049969719816968225		[learning rate: 1.5759e-05]
	Learning Rate: 1.57589e-05
	LOSS [training: 0.049969719816968225 | validation: 0.04235607673650753]
	TIME [epoch: 8.5 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049163334871130795		[learning rate: 1.5702e-05]
	Learning Rate: 1.57017e-05
	LOSS [training: 0.049163334871130795 | validation: 0.04679181019357649]
	TIME [epoch: 8.52 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05305256652223097		[learning rate: 1.5645e-05]
	Learning Rate: 1.56447e-05
	LOSS [training: 0.05305256652223097 | validation: 0.04836727076375312]
	TIME [epoch: 8.51 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05406491578128529		[learning rate: 1.5588e-05]
	Learning Rate: 1.5588e-05
	LOSS [training: 0.05406491578128529 | validation: 0.0534646014360343]
	TIME [epoch: 8.51 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04922490133822956		[learning rate: 1.5531e-05]
	Learning Rate: 1.55314e-05
	LOSS [training: 0.04922490133822956 | validation: 0.04628344282605705]
	TIME [epoch: 8.5 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05768510399872538		[learning rate: 1.5475e-05]
	Learning Rate: 1.5475e-05
	LOSS [training: 0.05768510399872538 | validation: 0.058360695555557805]
	TIME [epoch: 8.52 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05818401537918409		[learning rate: 1.5419e-05]
	Learning Rate: 1.54189e-05
	LOSS [training: 0.05818401537918409 | validation: 0.05860450465095511]
	TIME [epoch: 8.51 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05180272722730165		[learning rate: 1.5363e-05]
	Learning Rate: 1.53629e-05
	LOSS [training: 0.05180272722730165 | validation: 0.0462918270901487]
	TIME [epoch: 8.5 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05291413216268663		[learning rate: 1.5307e-05]
	Learning Rate: 1.53072e-05
	LOSS [training: 0.05291413216268663 | validation: 0.05126795645208177]
	TIME [epoch: 8.5 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053731960857510884		[learning rate: 1.5252e-05]
	Learning Rate: 1.52516e-05
	LOSS [training: 0.053731960857510884 | validation: 0.04771473826233185]
	TIME [epoch: 8.51 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05027274976432454		[learning rate: 1.5196e-05]
	Learning Rate: 1.51963e-05
	LOSS [training: 0.05027274976432454 | validation: 0.057356974207788645]
	TIME [epoch: 8.53 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052724613699104084		[learning rate: 1.5141e-05]
	Learning Rate: 1.51411e-05
	LOSS [training: 0.052724613699104084 | validation: 0.0524064083564765]
	TIME [epoch: 8.51 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05061513907079559		[learning rate: 1.5086e-05]
	Learning Rate: 1.50862e-05
	LOSS [training: 0.05061513907079559 | validation: 0.047271114573122]
	TIME [epoch: 8.5 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04912002303688191		[learning rate: 1.5031e-05]
	Learning Rate: 1.50314e-05
	LOSS [training: 0.04912002303688191 | validation: 0.05083173274006027]
	TIME [epoch: 8.5 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050641860212162014		[learning rate: 1.4977e-05]
	Learning Rate: 1.49769e-05
	LOSS [training: 0.050641860212162014 | validation: 0.04713084025510102]
	TIME [epoch: 8.52 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05519768481465857		[learning rate: 1.4923e-05]
	Learning Rate: 1.49225e-05
	LOSS [training: 0.05519768481465857 | validation: 0.0445689682428395]
	TIME [epoch: 8.5 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05213582814377633		[learning rate: 1.4868e-05]
	Learning Rate: 1.48684e-05
	LOSS [training: 0.05213582814377633 | validation: 0.05259001139195235]
	TIME [epoch: 8.5 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04827205536534864		[learning rate: 1.4814e-05]
	Learning Rate: 1.48144e-05
	LOSS [training: 0.04827205536534864 | validation: 0.049009889402390844]
	TIME [epoch: 8.5 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05264053678008527		[learning rate: 1.4761e-05]
	Learning Rate: 1.47606e-05
	LOSS [training: 0.05264053678008527 | validation: 0.05145431852418002]
	TIME [epoch: 8.52 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051433933928442185		[learning rate: 1.4707e-05]
	Learning Rate: 1.47071e-05
	LOSS [training: 0.051433933928442185 | validation: 0.0547067794742071]
	TIME [epoch: 8.5 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048876874655869956		[learning rate: 1.4654e-05]
	Learning Rate: 1.46537e-05
	LOSS [training: 0.048876874655869956 | validation: 0.041717386530224665]
	TIME [epoch: 8.5 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05290733491791348		[learning rate: 1.4601e-05]
	Learning Rate: 1.46005e-05
	LOSS [training: 0.05290733491791348 | validation: 0.0562211483751296]
	TIME [epoch: 8.5 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053900595098281635		[learning rate: 1.4548e-05]
	Learning Rate: 1.45475e-05
	LOSS [training: 0.053900595098281635 | validation: 0.06153252158233047]
	TIME [epoch: 8.53 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04975217805606662		[learning rate: 1.4495e-05]
	Learning Rate: 1.44947e-05
	LOSS [training: 0.04975217805606662 | validation: 0.05412396264446124]
	TIME [epoch: 8.51 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051252529371837344		[learning rate: 1.4442e-05]
	Learning Rate: 1.44421e-05
	LOSS [training: 0.051252529371837344 | validation: 0.04887647653294125]
	TIME [epoch: 8.51 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047751924816564296		[learning rate: 1.439e-05]
	Learning Rate: 1.43897e-05
	LOSS [training: 0.047751924816564296 | validation: 0.045684459760742056]
	TIME [epoch: 8.5 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04831992159027736		[learning rate: 1.4338e-05]
	Learning Rate: 1.43375e-05
	LOSS [training: 0.04831992159027736 | validation: 0.051021974875271645]
	TIME [epoch: 8.52 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04898307860683841		[learning rate: 1.4285e-05]
	Learning Rate: 1.42855e-05
	LOSS [training: 0.04898307860683841 | validation: 0.05629302203729515]
	TIME [epoch: 8.51 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05754996208728438		[learning rate: 1.4234e-05]
	Learning Rate: 1.42336e-05
	LOSS [training: 0.05754996208728438 | validation: 0.05795651762187767]
	TIME [epoch: 8.51 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055237057016967704		[learning rate: 1.4182e-05]
	Learning Rate: 1.4182e-05
	LOSS [training: 0.055237057016967704 | validation: 0.046209931734816155]
	TIME [epoch: 8.5 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05178859632990964		[learning rate: 1.4131e-05]
	Learning Rate: 1.41305e-05
	LOSS [training: 0.05178859632990964 | validation: 0.046460855208411]
	TIME [epoch: 8.49 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050274662460486966		[learning rate: 1.4079e-05]
	Learning Rate: 1.40792e-05
	LOSS [training: 0.050274662460486966 | validation: 0.05170808696547215]
	TIME [epoch: 8.51 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049851382706765444		[learning rate: 1.4028e-05]
	Learning Rate: 1.40281e-05
	LOSS [training: 0.049851382706765444 | validation: 0.0385217744132475]
	TIME [epoch: 8.49 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050447646561108894		[learning rate: 1.3977e-05]
	Learning Rate: 1.39772e-05
	LOSS [training: 0.050447646561108894 | validation: 0.04529487985755978]
	TIME [epoch: 8.49 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055421011435464795		[learning rate: 1.3927e-05]
	Learning Rate: 1.39265e-05
	LOSS [training: 0.055421011435464795 | validation: 0.044185239957606974]
	TIME [epoch: 8.5 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049942438848868155		[learning rate: 1.3876e-05]
	Learning Rate: 1.3876e-05
	LOSS [training: 0.049942438848868155 | validation: 0.04828276984982445]
	TIME [epoch: 8.51 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05086770133073074		[learning rate: 1.3826e-05]
	Learning Rate: 1.38256e-05
	LOSS [training: 0.05086770133073074 | validation: 0.05189076848183072]
	TIME [epoch: 8.49 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052157415476241406		[learning rate: 1.3775e-05]
	Learning Rate: 1.37754e-05
	LOSS [training: 0.052157415476241406 | validation: 0.05422550167083098]
	TIME [epoch: 8.5 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04930772219031897		[learning rate: 1.3725e-05]
	Learning Rate: 1.37254e-05
	LOSS [training: 0.04930772219031897 | validation: 0.05229015593302468]
	TIME [epoch: 8.5 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0489745380242845		[learning rate: 1.3676e-05]
	Learning Rate: 1.36756e-05
	LOSS [training: 0.0489745380242845 | validation: 0.04642663111257289]
	TIME [epoch: 8.52 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05289486003550461		[learning rate: 1.3626e-05]
	Learning Rate: 1.3626e-05
	LOSS [training: 0.05289486003550461 | validation: 0.04889958211954768]
	TIME [epoch: 8.5 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05187371001964673		[learning rate: 1.3577e-05]
	Learning Rate: 1.35766e-05
	LOSS [training: 0.05187371001964673 | validation: 0.04707347853275923]
	TIME [epoch: 8.5 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05191997430893504		[learning rate: 1.3527e-05]
	Learning Rate: 1.35273e-05
	LOSS [training: 0.05191997430893504 | validation: 0.04219794790505216]
	TIME [epoch: 8.48 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05444004960897679		[learning rate: 1.3478e-05]
	Learning Rate: 1.34782e-05
	LOSS [training: 0.05444004960897679 | validation: 0.038638655357074156]
	TIME [epoch: 8.51 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05088281149653234		[learning rate: 1.3429e-05]
	Learning Rate: 1.34293e-05
	LOSS [training: 0.05088281149653234 | validation: 0.04213199056168632]
	TIME [epoch: 8.5 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051648972805859714		[learning rate: 1.3381e-05]
	Learning Rate: 1.33805e-05
	LOSS [training: 0.051648972805859714 | validation: 0.055212247547477895]
	TIME [epoch: 8.49 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05354772096489678		[learning rate: 1.3332e-05]
	Learning Rate: 1.3332e-05
	LOSS [training: 0.05354772096489678 | validation: 0.05453133979861153]
	TIME [epoch: 8.49 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051894368843631966		[learning rate: 1.3284e-05]
	Learning Rate: 1.32836e-05
	LOSS [training: 0.051894368843631966 | validation: 0.047997374921455796]
	TIME [epoch: 8.5 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046524946590436586		[learning rate: 1.3235e-05]
	Learning Rate: 1.32354e-05
	LOSS [training: 0.046524946590436586 | validation: 0.04682916446040847]
	TIME [epoch: 8.52 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05243590818168505		[learning rate: 1.3187e-05]
	Learning Rate: 1.31874e-05
	LOSS [training: 0.05243590818168505 | validation: 0.05440145950591057]
	TIME [epoch: 8.49 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05170610474323756		[learning rate: 1.314e-05]
	Learning Rate: 1.31395e-05
	LOSS [training: 0.05170610474323756 | validation: 0.04409147463068893]
	TIME [epoch: 8.49 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056549879414334446		[learning rate: 1.3092e-05]
	Learning Rate: 1.30918e-05
	LOSS [training: 0.056549879414334446 | validation: 0.054519636336772315]
	TIME [epoch: 8.5 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04787861236920339		[learning rate: 1.3044e-05]
	Learning Rate: 1.30443e-05
	LOSS [training: 0.04787861236920339 | validation: 0.0469547633899914]
	TIME [epoch: 8.51 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0493854855618008		[learning rate: 1.2997e-05]
	Learning Rate: 1.2997e-05
	LOSS [training: 0.0493854855618008 | validation: 0.0564636803699059]
	TIME [epoch: 8.5 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04993826872346125		[learning rate: 1.295e-05]
	Learning Rate: 1.29498e-05
	LOSS [training: 0.04993826872346125 | validation: 0.04685214237120516]
	TIME [epoch: 8.5 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05191161407224708		[learning rate: 1.2903e-05]
	Learning Rate: 1.29028e-05
	LOSS [training: 0.05191161407224708 | validation: 0.05063117842117013]
	TIME [epoch: 8.49 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049617182891830335		[learning rate: 1.2856e-05]
	Learning Rate: 1.2856e-05
	LOSS [training: 0.049617182891830335 | validation: 0.048594115891413284]
	TIME [epoch: 8.51 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048255299863808505		[learning rate: 1.2809e-05]
	Learning Rate: 1.28093e-05
	LOSS [training: 0.048255299863808505 | validation: 0.050155087570123685]
	TIME [epoch: 8.5 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05115827760281992		[learning rate: 1.2763e-05]
	Learning Rate: 1.27628e-05
	LOSS [training: 0.05115827760281992 | validation: 0.05335686382464208]
	TIME [epoch: 8.49 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05148866304147015		[learning rate: 1.2717e-05]
	Learning Rate: 1.27165e-05
	LOSS [training: 0.05148866304147015 | validation: 0.05689440199583719]
	TIME [epoch: 8.49 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051808294536229885		[learning rate: 1.267e-05]
	Learning Rate: 1.26704e-05
	LOSS [training: 0.051808294536229885 | validation: 0.057709604041017076]
	TIME [epoch: 8.5 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050264774539910226		[learning rate: 1.2624e-05]
	Learning Rate: 1.26244e-05
	LOSS [training: 0.050264774539910226 | validation: 0.046407766731653366]
	TIME [epoch: 8.5 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05340242278353872		[learning rate: 1.2579e-05]
	Learning Rate: 1.25786e-05
	LOSS [training: 0.05340242278353872 | validation: 0.05194190400559717]
	TIME [epoch: 8.49 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04907013719581608		[learning rate: 1.2533e-05]
	Learning Rate: 1.25329e-05
	LOSS [training: 0.04907013719581608 | validation: 0.051577972222258336]
	TIME [epoch: 8.49 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05038230121597146		[learning rate: 1.2487e-05]
	Learning Rate: 1.24874e-05
	LOSS [training: 0.05038230121597146 | validation: 0.05551421828880969]
	TIME [epoch: 8.5 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04973497079609885		[learning rate: 1.2442e-05]
	Learning Rate: 1.24421e-05
	LOSS [training: 0.04973497079609885 | validation: 0.04332333305636083]
	TIME [epoch: 8.51 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05406806308645147		[learning rate: 1.2397e-05]
	Learning Rate: 1.2397e-05
	LOSS [training: 0.05406806308645147 | validation: 0.04803783939056712]
	TIME [epoch: 8.49 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051426638455154786		[learning rate: 1.2352e-05]
	Learning Rate: 1.2352e-05
	LOSS [training: 0.051426638455154786 | validation: 0.05540065039073805]
	TIME [epoch: 8.48 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05250682349954988		[learning rate: 1.2307e-05]
	Learning Rate: 1.23072e-05
	LOSS [training: 0.05250682349954988 | validation: 0.048747535529963026]
	TIME [epoch: 8.48 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048676172817028476		[learning rate: 1.2263e-05]
	Learning Rate: 1.22625e-05
	LOSS [training: 0.048676172817028476 | validation: 0.05422980379215975]
	TIME [epoch: 8.51 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05203104287383531		[learning rate: 1.2218e-05]
	Learning Rate: 1.2218e-05
	LOSS [training: 0.05203104287383531 | validation: 0.050470830897692484]
	TIME [epoch: 8.49 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05272756823865525		[learning rate: 1.2174e-05]
	Learning Rate: 1.21737e-05
	LOSS [training: 0.05272756823865525 | validation: 0.05060554808783839]
	TIME [epoch: 8.48 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05270500991765403		[learning rate: 1.2129e-05]
	Learning Rate: 1.21295e-05
	LOSS [training: 0.05270500991765403 | validation: 0.055953346455403064]
	TIME [epoch: 8.49 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04964420022911044		[learning rate: 1.2085e-05]
	Learning Rate: 1.20855e-05
	LOSS [training: 0.04964420022911044 | validation: 0.04752032219262525]
	TIME [epoch: 8.51 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05403639263388747		[learning rate: 1.2042e-05]
	Learning Rate: 1.20416e-05
	LOSS [training: 0.05403639263388747 | validation: 0.05944962609478402]
	TIME [epoch: 8.49 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048355166013415475		[learning rate: 1.1998e-05]
	Learning Rate: 1.19979e-05
	LOSS [training: 0.048355166013415475 | validation: 0.044173450576547466]
	TIME [epoch: 8.49 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054210398821604756		[learning rate: 1.1954e-05]
	Learning Rate: 1.19544e-05
	LOSS [training: 0.054210398821604756 | validation: 0.04757440456664502]
	TIME [epoch: 8.49 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05617611597875545		[learning rate: 1.1911e-05]
	Learning Rate: 1.1911e-05
	LOSS [training: 0.05617611597875545 | validation: 0.05131536632678678]
	TIME [epoch: 8.5 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04846513258803229		[learning rate: 1.1868e-05]
	Learning Rate: 1.18678e-05
	LOSS [training: 0.04846513258803229 | validation: 0.04639743592981714]
	TIME [epoch: 8.5 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04647137508119055		[learning rate: 1.1825e-05]
	Learning Rate: 1.18247e-05
	LOSS [training: 0.04647137508119055 | validation: 0.03678055661217053]
	TIME [epoch: 8.5 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051008054313159676		[learning rate: 1.1782e-05]
	Learning Rate: 1.17818e-05
	LOSS [training: 0.051008054313159676 | validation: 0.05341521337995123]
	TIME [epoch: 8.49 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05249350074741556		[learning rate: 1.1739e-05]
	Learning Rate: 1.1739e-05
	LOSS [training: 0.05249350074741556 | validation: 0.05034239246934498]
	TIME [epoch: 8.49 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04954519328137732		[learning rate: 1.1696e-05]
	Learning Rate: 1.16964e-05
	LOSS [training: 0.04954519328137732 | validation: 0.06065142802754033]
	TIME [epoch: 8.5 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05144621833821472		[learning rate: 1.1654e-05]
	Learning Rate: 1.1654e-05
	LOSS [training: 0.05144621833821472 | validation: 0.044723395364909206]
	TIME [epoch: 8.49 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04880176822164052		[learning rate: 1.1612e-05]
	Learning Rate: 1.16117e-05
	LOSS [training: 0.04880176822164052 | validation: 0.045596238171504176]
	TIME [epoch: 8.49 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04995577296034818		[learning rate: 1.157e-05]
	Learning Rate: 1.15695e-05
	LOSS [training: 0.04995577296034818 | validation: 0.05415628598788217]
	TIME [epoch: 8.49 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055674647183165636		[learning rate: 1.1528e-05]
	Learning Rate: 1.15275e-05
	LOSS [training: 0.055674647183165636 | validation: 0.05154339653152297]
	TIME [epoch: 8.5 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05390771924246435		[learning rate: 1.1486e-05]
	Learning Rate: 1.14857e-05
	LOSS [training: 0.05390771924246435 | validation: 0.04973107100194466]
	TIME [epoch: 8.48 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051671893943168457		[learning rate: 1.1444e-05]
	Learning Rate: 1.1444e-05
	LOSS [training: 0.051671893943168457 | validation: 0.0428324669452515]
	TIME [epoch: 8.48 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049045261725324696		[learning rate: 1.1402e-05]
	Learning Rate: 1.14025e-05
	LOSS [training: 0.049045261725324696 | validation: 0.05042477746312886]
	TIME [epoch: 8.49 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047401281096253474		[learning rate: 1.1361e-05]
	Learning Rate: 1.13611e-05
	LOSS [training: 0.047401281096253474 | validation: 0.05922995051907237]
	TIME [epoch: 8.5 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05103476284142986		[learning rate: 1.132e-05]
	Learning Rate: 1.13199e-05
	LOSS [training: 0.05103476284142986 | validation: 0.05171404173550329]
	TIME [epoch: 8.49 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05121464868080792		[learning rate: 1.1279e-05]
	Learning Rate: 1.12788e-05
	LOSS [training: 0.05121464868080792 | validation: 0.05220119245719232]
	TIME [epoch: 8.49 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0521484870663283		[learning rate: 1.1238e-05]
	Learning Rate: 1.12379e-05
	LOSS [training: 0.0521484870663283 | validation: 0.04374630662076092]
	TIME [epoch: 8.48 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051585009184568376		[learning rate: 1.1197e-05]
	Learning Rate: 1.11971e-05
	LOSS [training: 0.051585009184568376 | validation: 0.04061496218017102]
	TIME [epoch: 8.5 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05512512628741566		[learning rate: 1.1156e-05]
	Learning Rate: 1.11565e-05
	LOSS [training: 0.05512512628741566 | validation: 0.05461629122764963]
	TIME [epoch: 8.49 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05193492959044593		[learning rate: 1.1116e-05]
	Learning Rate: 1.1116e-05
	LOSS [training: 0.05193492959044593 | validation: 0.04753223164688516]
	TIME [epoch: 8.48 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045936974808314025		[learning rate: 1.1076e-05]
	Learning Rate: 1.10756e-05
	LOSS [training: 0.045936974808314025 | validation: 0.05356826014198331]
	TIME [epoch: 8.47 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048725383147245185		[learning rate: 1.1035e-05]
	Learning Rate: 1.10354e-05
	LOSS [training: 0.048725383147245185 | validation: 0.04765227699567688]
	TIME [epoch: 8.48 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05146370773258041		[learning rate: 1.0995e-05]
	Learning Rate: 1.09954e-05
	LOSS [training: 0.05146370773258041 | validation: 0.037248297910586745]
	TIME [epoch: 8.5 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05146516887835084		[learning rate: 1.0955e-05]
	Learning Rate: 1.09555e-05
	LOSS [training: 0.05146516887835084 | validation: 0.04411744914244446]
	TIME [epoch: 8.48 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05153220139507332		[learning rate: 1.0916e-05]
	Learning Rate: 1.09157e-05
	LOSS [training: 0.05153220139507332 | validation: 0.047211441857106844]
	TIME [epoch: 8.48 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04963787725824767		[learning rate: 1.0876e-05]
	Learning Rate: 1.08761e-05
	LOSS [training: 0.04963787725824767 | validation: 0.05444385170137764]
	TIME [epoch: 8.48 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05127882101636101		[learning rate: 1.0837e-05]
	Learning Rate: 1.08366e-05
	LOSS [training: 0.05127882101636101 | validation: 0.05048885860218544]
	TIME [epoch: 8.5 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0529350853853761		[learning rate: 1.0797e-05]
	Learning Rate: 1.07973e-05
	LOSS [training: 0.0529350853853761 | validation: 0.04848216449785643]
	TIME [epoch: 8.48 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05259399376744052		[learning rate: 1.0758e-05]
	Learning Rate: 1.07581e-05
	LOSS [training: 0.05259399376744052 | validation: 0.05568885782033246]
	TIME [epoch: 8.49 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049393605761391735		[learning rate: 1.0719e-05]
	Learning Rate: 1.07191e-05
	LOSS [training: 0.049393605761391735 | validation: 0.051688611339754054]
	TIME [epoch: 8.49 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04997715481033997		[learning rate: 1.068e-05]
	Learning Rate: 1.06802e-05
	LOSS [training: 0.04997715481033997 | validation: 0.0453257733155439]
	TIME [epoch: 8.51 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04856809976218289		[learning rate: 1.0641e-05]
	Learning Rate: 1.06414e-05
	LOSS [training: 0.04856809976218289 | validation: 0.055226062828623246]
	TIME [epoch: 8.48 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05395334898458498		[learning rate: 1.0603e-05]
	Learning Rate: 1.06028e-05
	LOSS [training: 0.05395334898458498 | validation: 0.05499779230402364]
	TIME [epoch: 8.48 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051677627665339954		[learning rate: 1.0564e-05]
	Learning Rate: 1.05643e-05
	LOSS [training: 0.051677627665339954 | validation: 0.06193157445014733]
	TIME [epoch: 8.48 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053005747110501635		[learning rate: 1.0526e-05]
	Learning Rate: 1.0526e-05
	LOSS [training: 0.053005747110501635 | validation: 0.05581837364949491]
	TIME [epoch: 8.49 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04901477343542717		[learning rate: 1.0488e-05]
	Learning Rate: 1.04878e-05
	LOSS [training: 0.04901477343542717 | validation: 0.05661983518689635]
	TIME [epoch: 8.5 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048027561413502354		[learning rate: 1.045e-05]
	Learning Rate: 1.04497e-05
	LOSS [training: 0.048027561413502354 | validation: 0.04391083884650411]
	TIME [epoch: 8.49 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04924281210350763		[learning rate: 1.0412e-05]
	Learning Rate: 1.04118e-05
	LOSS [training: 0.04924281210350763 | validation: 0.05136389174731919]
	TIME [epoch: 8.49 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05031091182387602		[learning rate: 1.0374e-05]
	Learning Rate: 1.0374e-05
	LOSS [training: 0.05031091182387602 | validation: 0.05172214298890381]
	TIME [epoch: 8.47 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04972960974673613		[learning rate: 1.0336e-05]
	Learning Rate: 1.03364e-05
	LOSS [training: 0.04972960974673613 | validation: 0.04753879921552394]
	TIME [epoch: 8.5 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05544187129295517		[learning rate: 1.0299e-05]
	Learning Rate: 1.02989e-05
	LOSS [training: 0.05544187129295517 | validation: 0.04385780526156119]
	TIME [epoch: 8.47 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0533649447108658		[learning rate: 1.0261e-05]
	Learning Rate: 1.02615e-05
	LOSS [training: 0.0533649447108658 | validation: 0.04295544758565065]
	TIME [epoch: 8.47 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049252690415564786		[learning rate: 1.0224e-05]
	Learning Rate: 1.02243e-05
	LOSS [training: 0.049252690415564786 | validation: 0.039969841780423815]
	TIME [epoch: 8.48 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053900056005814434		[learning rate: 1.0187e-05]
	Learning Rate: 1.01872e-05
	LOSS [training: 0.053900056005814434 | validation: 0.04974799189176359]
	TIME [epoch: 8.5 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04837321201143081		[learning rate: 1.015e-05]
	Learning Rate: 1.01502e-05
	LOSS [training: 0.04837321201143081 | validation: 0.04916046112219988]
	TIME [epoch: 8.47 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04914270378516508		[learning rate: 1.0113e-05]
	Learning Rate: 1.01133e-05
	LOSS [training: 0.04914270378516508 | validation: 0.04812076547128781]
	TIME [epoch: 8.48 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04861493103621871		[learning rate: 1.0077e-05]
	Learning Rate: 1.00766e-05
	LOSS [training: 0.04861493103621871 | validation: 0.04726239552507687]
	TIME [epoch: 8.48 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047188816585191695		[learning rate: 1.004e-05]
	Learning Rate: 1.00401e-05
	LOSS [training: 0.047188816585191695 | validation: 0.04713638010540873]
	TIME [epoch: 8.49 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049920173803969195		[learning rate: 1.0004e-05]
	Learning Rate: 1.00036e-05
	LOSS [training: 0.049920173803969195 | validation: 0.04680673919568197]
	TIME [epoch: 8.48 sec]
Finished training in 17180.002 seconds.
