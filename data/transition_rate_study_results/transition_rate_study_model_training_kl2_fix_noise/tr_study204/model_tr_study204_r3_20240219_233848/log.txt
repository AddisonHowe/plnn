Args:
Namespace(name='model_tr_study204', outdir='out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3', training_data='data/transition_rate_studies/tr_study204/tr_study204_training/r3', validation_data='data/transition_rate_studies/tr_study204/tr_study204_validation/r3', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.075, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=100, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1269155074

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 10/10] avg loss: 11.383420835825579		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.383420835825579 | validation: 10.807262922888913]
	TIME [epoch: 78.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 10/10] avg loss: 9.649761592605667		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.649761592605667 | validation: 11.159232741335716]
	TIME [epoch: 8.55 sec]
EPOCH 3/2000:
	Training over batches...
		[batch 10/10] avg loss: 10.210005501182957		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.210005501182957 | validation: 8.882839404729037]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.24038681444856		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.24038681444856 | validation: 8.613085453777362]
	TIME [epoch: 8.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.584721277428653		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.584721277428653 | validation: 7.156446773104064]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.890354004022076		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.890354004022076 | validation: 5.733012701820506]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.594581576535593		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.594581576535593 | validation: 5.131929444975544]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.0554087809660935		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.0554087809660935 | validation: 4.778450620362891]
	TIME [epoch: 8.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.350841962815136		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.350841962815136 | validation: 4.921839349918181]
	TIME [epoch: 8.53 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.2409857102081645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.2409857102081645 | validation: 5.340475669765944]
	TIME [epoch: 8.54 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.536108678344781		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.536108678344781 | validation: 4.74281393500109]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.122938943031801		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.122938943031801 | validation: 5.043109721557289]
	TIME [epoch: 8.55 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.262422799063687		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.262422799063687 | validation: 4.7414380190190375]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.380587438459241		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.380587438459241 | validation: 5.201965128412278]
	TIME [epoch: 8.53 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.407157457988493		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.407157457988493 | validation: 4.480658175719709]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.938007152057982		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.938007152057982 | validation: 4.407780466433168]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.895037524830015		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.895037524830015 | validation: 4.813738098035288]
	TIME [epoch: 8.55 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.972399248939108		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.972399248939108 | validation: 5.1470515233216165]
	TIME [epoch: 8.53 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.122419875222572		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.122419875222572 | validation: 4.6948488009417915]
	TIME [epoch: 8.54 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.004214744987289		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.004214744987289 | validation: 4.676034388793436]
	TIME [epoch: 8.53 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.0674867745891765		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.0674867745891765 | validation: 4.907912658201472]
	TIME [epoch: 8.55 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.160994406839236		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.160994406839236 | validation: 4.416137305394924]
	TIME [epoch: 8.53 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.321395027154364		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.321395027154364 | validation: 6.856042248898734]
	TIME [epoch: 8.53 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.6797559489185		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.6797559489185 | validation: 5.86366338580083]
	TIME [epoch: 8.53 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.666874608272254		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.666874608272254 | validation: 4.473790301481394]
	TIME [epoch: 8.55 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.060492022179509		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.060492022179509 | validation: 4.50439713319679]
	TIME [epoch: 8.54 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.097504056655111		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.097504056655111 | validation: 4.599169974794834]
	TIME [epoch: 8.53 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.019032710838113		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.019032710838113 | validation: 4.4948799944490725]
	TIME [epoch: 8.53 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.945984192780564		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.945984192780564 | validation: 6.014686986215062]
	TIME [epoch: 8.56 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.02087937129526		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.02087937129526 | validation: 4.1952275886478105]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.4613798893194643		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4613798893194643 | validation: 3.6129865146896685]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.6208175165806025		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6208175165806025 | validation: 4.512429246878771]
	TIME [epoch: 8.53 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.3735406549412508		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3735406549412508 | validation: 4.977362636019844]
	TIME [epoch: 8.56 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.3598504698065432		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3598504698065432 | validation: 3.6501553939672675]
	TIME [epoch: 8.53 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.9340924199751264		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9340924199751264 | validation: 3.600535991096647]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.086330229386551		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.086330229386551 | validation: 4.960828187467428]
	TIME [epoch: 8.54 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.4087881154843642		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4087881154843642 | validation: 4.102682538013361]
	TIME [epoch: 8.55 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.028507393542843		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.028507393542843 | validation: 3.3111689027934563]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1027693034787234		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1027693034787234 | validation: 6.086783996661093]
	TIME [epoch: 8.53 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.309590580588215		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.309590580588215 | validation: 3.8745037298788247]
	TIME [epoch: 8.53 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.9408542329103087		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9408542329103087 | validation: 3.445487712036344]
	TIME [epoch: 8.53 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.9518065481629407		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9518065481629407 | validation: 3.62224147394457]
	TIME [epoch: 8.56 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.9046126447783567		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9046126447783567 | validation: 3.3462932255059235]
	TIME [epoch: 8.53 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.2911781087286633		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2911781087286633 | validation: 3.3056892456309086]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.86738482619583		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.86738482619583 | validation: 3.7844331228588928]
	TIME [epoch: 8.53 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.8426518194891557		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8426518194891557 | validation: 3.317449203642802]
	TIME [epoch: 8.56 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.9043001744093933		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9043001744093933 | validation: 4.239979951732742]
	TIME [epoch: 8.54 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.956702604367057		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.956702604367057 | validation: 3.730605963972189]
	TIME [epoch: 8.54 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.9382524048074967		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9382524048074967 | validation: 4.612732683690298]
	TIME [epoch: 8.54 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.011910495201078		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.011910495201078 | validation: 3.6222986866954088]
	TIME [epoch: 8.56 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.736604765083565		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.736604765083565 | validation: 3.123695921943194]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.9894204428326843		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9894204428326843 | validation: 5.4374718588263455]
	TIME [epoch: 8.54 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.025182357893943		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.025182357893943 | validation: 5.312664318232481]
	TIME [epoch: 8.52 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.2580049503435036		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2580049503435036 | validation: 3.418324620472143]
	TIME [epoch: 8.54 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.763065396487396		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.763065396487396 | validation: 3.4710816668772346]
	TIME [epoch: 8.53 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.726300459458995		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.726300459458995 | validation: 3.340811110367121]
	TIME [epoch: 8.53 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.2144709309352337		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2144709309352337 | validation: 3.548381035836485]
	TIME [epoch: 8.52 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.735321872743535		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.735321872743535 | validation: 3.608578809257334]
	TIME [epoch: 8.53 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.687426011056556		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.687426011056556 | validation: 4.754991689364292]
	TIME [epoch: 8.55 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.0975480811443536		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0975480811443536 | validation: 3.3471490808064237]
	TIME [epoch: 8.52 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.7228395555383162		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7228395555383162 | validation: 3.4471157740310954]
	TIME [epoch: 8.52 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.791733399752359		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.791733399752359 | validation: 5.196053140239535]
	TIME [epoch: 8.53 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.416953576894695		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.416953576894695 | validation: 4.62146794805117]
	TIME [epoch: 8.56 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.458274328643104		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.458274328643104 | validation: 4.903217845572989]
	TIME [epoch: 8.52 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.2244215169992883		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2244215169992883 | validation: 4.099703139128416]
	TIME [epoch: 8.52 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.900939251483222		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.900939251483222 | validation: 3.4156119121196427]
	TIME [epoch: 8.52 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.6474261586169563		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6474261586169563 | validation: 3.329885550450256]
	TIME [epoch: 8.54 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.776745310782748		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.776745310782748 | validation: 3.3515953391939126]
	TIME [epoch: 8.52 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.783108756717339		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.783108756717339 | validation: 4.912165049788814]
	TIME [epoch: 8.51 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.534630288000559		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.534630288000559 | validation: 4.6894028910831524]
	TIME [epoch: 8.51 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.017868062553612		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.017868062553612 | validation: 3.1736137487262503]
	TIME [epoch: 8.55 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.634163236101923		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.634163236101923 | validation: 3.274841493792441]
	TIME [epoch: 8.53 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.6804527817632016		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6804527817632016 | validation: 3.225539140832441]
	TIME [epoch: 8.52 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.6592565092593983		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6592565092593983 | validation: 3.2184749226779306]
	TIME [epoch: 8.52 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.6047660427787855		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6047660427787855 | validation: 3.9542815555238096]
	TIME [epoch: 8.53 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.8117392005233546		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8117392005233546 | validation: 3.5351377654238796]
	TIME [epoch: 8.54 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.6921047335720414		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6921047335720414 | validation: 3.240001791626913]
	TIME [epoch: 8.52 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.6337283400959626		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6337283400959626 | validation: 3.365467487637653]
	TIME [epoch: 8.52 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.7050261829401965		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7050261829401965 | validation: 3.2406070065662416]
	TIME [epoch: 8.52 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.6117792944569582		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6117792944569582 | validation: 3.260123010828461]
	TIME [epoch: 8.55 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.6915857011038695		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6915857011038695 | validation: 3.2535110888740437]
	TIME [epoch: 8.52 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.61587134394244		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.61587134394244 | validation: 3.278690090761412]
	TIME [epoch: 8.52 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.7892612981593454		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7892612981593454 | validation: 4.930374681276515]
	TIME [epoch: 8.52 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.3985540609167635		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3985540609167635 | validation: 4.479352830186888]
	TIME [epoch: 8.54 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.066822503870215		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.066822503870215 | validation: 3.208136681329223]
	TIME [epoch: 8.52 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.6432410179702193		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6432410179702193 | validation: 3.112886363681649]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_86.pth
	Model improved!!!
EPOCH 87/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1642370272391127		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1642370272391127 | validation: 3.299789450144706]
	TIME [epoch: 8.52 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.928923218288129		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.928923218288129 | validation: 3.222706833397453]
	TIME [epoch: 8.54 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.8377548107294936		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8377548107294936 | validation: 3.194647647100984]
	TIME [epoch: 8.52 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.7292145839214674		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7292145839214674 | validation: 3.0863170033163154]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_90.pth
	Model improved!!!
EPOCH 91/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.634328928661189		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.634328928661189 | validation: 3.091849576403452]
	TIME [epoch: 8.52 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.721081495389777		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.721081495389777 | validation: 3.7423917658591392]
	TIME [epoch: 8.53 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.8457956031287073		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8457956031287073 | validation: 3.932953607414751]
	TIME [epoch: 8.52 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.674720170070132		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.674720170070132 | validation: 3.1133408191637963]
	TIME [epoch: 8.51 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.8001007497232018		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8001007497232018 | validation: 3.397527168218368]
	TIME [epoch: 8.52 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.630611342022708		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.630611342022708 | validation: 3.249532838188827]
	TIME [epoch: 8.51 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5069756795909974		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5069756795909974 | validation: 3.7016025992565638]
	TIME [epoch: 8.54 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.7336658579267623		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7336658579267623 | validation: 3.270048346788409]
	TIME [epoch: 8.51 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.6013727000352667		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6013727000352667 | validation: 3.1318480534286355]
	TIME [epoch: 8.52 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.6069592189552715		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6069592189552715 | validation: 3.663035744458737]
	TIME [epoch: 8.51 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5648292665336756		[learning rate: 0.0099673]
	Learning Rate: 0.00996733
	LOSS [training: 2.5648292665336756 | validation: 4.2458293445572695]
	TIME [epoch: 8.54 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.679715821808371		[learning rate: 0.0099312]
	Learning Rate: 0.00993116
	LOSS [training: 2.679715821808371 | validation: 3.3817899183171622]
	TIME [epoch: 8.52 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5000451521893408		[learning rate: 0.0098951]
	Learning Rate: 0.00989512
	LOSS [training: 2.5000451521893408 | validation: 3.1754425553278285]
	TIME [epoch: 8.52 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.6510802653360743		[learning rate: 0.0098592]
	Learning Rate: 0.00985921
	LOSS [training: 2.6510802653360743 | validation: 3.6072650074190946]
	TIME [epoch: 8.51 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.482776375468542		[learning rate: 0.0098234]
	Learning Rate: 0.00982343
	LOSS [training: 2.482776375468542 | validation: 3.1921351879248174]
	TIME [epoch: 8.54 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4333252476764797		[learning rate: 0.0097878]
	Learning Rate: 0.00978778
	LOSS [training: 2.4333252476764797 | validation: 3.0954037477662255]
	TIME [epoch: 8.52 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5237275058642408		[learning rate: 0.0097523]
	Learning Rate: 0.00975226
	LOSS [training: 2.5237275058642408 | validation: 3.5451791417277354]
	TIME [epoch: 8.51 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.491310292532793		[learning rate: 0.0097169]
	Learning Rate: 0.00971687
	LOSS [training: 2.491310292532793 | validation: 3.66960924948984]
	TIME [epoch: 8.52 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.6025273876748125		[learning rate: 0.0096816]
	Learning Rate: 0.0096816
	LOSS [training: 2.6025273876748125 | validation: 3.102157689098946]
	TIME [epoch: 8.53 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.540664124363567		[learning rate: 0.0096465]
	Learning Rate: 0.00964647
	LOSS [training: 2.540664124363567 | validation: 3.1911416947611944]
	TIME [epoch: 8.53 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4535389258331652		[learning rate: 0.0096115]
	Learning Rate: 0.00961146
	LOSS [training: 2.4535389258331652 | validation: 5.482920872825751]
	TIME [epoch: 8.52 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.112535596912243		[learning rate: 0.0095766]
	Learning Rate: 0.00957658
	LOSS [training: 3.112535596912243 | validation: 3.087085210226108]
	TIME [epoch: 8.52 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.384128592612134		[learning rate: 0.0095418]
	Learning Rate: 0.00954183
	LOSS [training: 2.384128592612134 | validation: 3.606590853387817]
	TIME [epoch: 8.52 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.495662062797049		[learning rate: 0.0095072]
	Learning Rate: 0.0095072
	LOSS [training: 2.495662062797049 | validation: 3.105913889484147]
	TIME [epoch: 8.54 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4355261396149475		[learning rate: 0.0094727]
	Learning Rate: 0.0094727
	LOSS [training: 2.4355261396149475 | validation: 3.163568821792369]
	TIME [epoch: 8.51 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4474495057568095		[learning rate: 0.0094383]
	Learning Rate: 0.00943832
	LOSS [training: 2.4474495057568095 | validation: 2.9045342037786703]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_116.pth
	Model improved!!!
EPOCH 117/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.7582336167426695		[learning rate: 0.0094041]
	Learning Rate: 0.00940407
	LOSS [training: 2.7582336167426695 | validation: 3.0144774396520866]
	TIME [epoch: 8.52 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.536346743943189		[learning rate: 0.0093699]
	Learning Rate: 0.00936994
	LOSS [training: 2.536346743943189 | validation: 2.8884581786195724]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_118.pth
	Model improved!!!
EPOCH 119/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.510049803154648		[learning rate: 0.0093359]
	Learning Rate: 0.00933594
	LOSS [training: 2.510049803154648 | validation: 3.1556406311811136]
	TIME [epoch: 8.53 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.533839476504505		[learning rate: 0.0093021]
	Learning Rate: 0.00930206
	LOSS [training: 2.533839476504505 | validation: 3.347874914600524]
	TIME [epoch: 8.53 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.34667407647611		[learning rate: 0.0092683]
	Learning Rate: 0.0092683
	LOSS [training: 2.34667407647611 | validation: 3.0959156250730473]
	TIME [epoch: 8.53 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.363523013409046		[learning rate: 0.0092347]
	Learning Rate: 0.00923466
	LOSS [training: 2.363523013409046 | validation: 3.298586979134828]
	TIME [epoch: 8.56 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4204314354734713		[learning rate: 0.0092011]
	Learning Rate: 0.00920115
	LOSS [training: 2.4204314354734713 | validation: 3.1058085761955097]
	TIME [epoch: 8.53 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.333674978472897		[learning rate: 0.0091678]
	Learning Rate: 0.00916776
	LOSS [training: 2.333674978472897 | validation: 2.937303211174367]
	TIME [epoch: 8.53 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.279320038945366		[learning rate: 0.0091345]
	Learning Rate: 0.00913449
	LOSS [training: 2.279320038945366 | validation: 3.1991694405467985]
	TIME [epoch: 8.53 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.439981157749493		[learning rate: 0.0091013]
	Learning Rate: 0.00910134
	LOSS [training: 2.439981157749493 | validation: 2.8850622473401817]
	TIME [epoch: 8.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_126.pth
	Model improved!!!
EPOCH 127/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.333667678002233		[learning rate: 0.0090683]
	Learning Rate: 0.00906831
	LOSS [training: 2.333667678002233 | validation: 2.963894499654908]
	TIME [epoch: 8.54 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.351554168769151		[learning rate: 0.0090354]
	Learning Rate: 0.0090354
	LOSS [training: 2.351554168769151 | validation: 2.9026153035685773]
	TIME [epoch: 8.53 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3295433808224986		[learning rate: 0.0090026]
	Learning Rate: 0.00900261
	LOSS [training: 2.3295433808224986 | validation: 3.6827970837362587]
	TIME [epoch: 8.53 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.425366704815777		[learning rate: 0.0089699]
	Learning Rate: 0.00896994
	LOSS [training: 2.425366704815777 | validation: 3.88858458238815]
	TIME [epoch: 8.55 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3697736527189095		[learning rate: 0.0089374]
	Learning Rate: 0.00893739
	LOSS [training: 2.3697736527189095 | validation: 3.1072406529788683]
	TIME [epoch: 8.54 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3493234342971814		[learning rate: 0.008905]
	Learning Rate: 0.00890495
	LOSS [training: 2.3493234342971814 | validation: 3.0281233017038884]
	TIME [epoch: 8.53 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.257884431451802		[learning rate: 0.0088726]
	Learning Rate: 0.00887263
	LOSS [training: 2.257884431451802 | validation: 2.93429387690491]
	TIME [epoch: 8.53 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2547182507949675		[learning rate: 0.0088404]
	Learning Rate: 0.00884044
	LOSS [training: 2.2547182507949675 | validation: 2.889867960363406]
	TIME [epoch: 8.53 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2656186351311725		[learning rate: 0.0088084]
	Learning Rate: 0.00880835
	LOSS [training: 2.2656186351311725 | validation: 3.3284359979086124]
	TIME [epoch: 8.56 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3401929018985763		[learning rate: 0.0087764]
	Learning Rate: 0.00877639
	LOSS [training: 2.3401929018985763 | validation: 2.9102171657621487]
	TIME [epoch: 8.53 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3032469175084236		[learning rate: 0.0087445]
	Learning Rate: 0.00874454
	LOSS [training: 2.3032469175084236 | validation: 3.0081816319434553]
	TIME [epoch: 8.53 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2951161915147353		[learning rate: 0.0087128]
	Learning Rate: 0.0087128
	LOSS [training: 2.2951161915147353 | validation: 3.643639912723594]
	TIME [epoch: 8.53 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.395058992447191		[learning rate: 0.0086812]
	Learning Rate: 0.00868118
	LOSS [training: 2.395058992447191 | validation: 3.180641547225129]
	TIME [epoch: 8.56 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2475474520334346		[learning rate: 0.0086497]
	Learning Rate: 0.00864968
	LOSS [training: 2.2475474520334346 | validation: 3.1812347680307527]
	TIME [epoch: 8.54 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2982881707906366		[learning rate: 0.0086183]
	Learning Rate: 0.00861829
	LOSS [training: 2.2982881707906366 | validation: 2.9543101373942173]
	TIME [epoch: 8.54 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.293043286371881		[learning rate: 0.008587]
	Learning Rate: 0.00858701
	LOSS [training: 2.293043286371881 | validation: 3.019842846248475]
	TIME [epoch: 8.53 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.245166540664894		[learning rate: 0.0085559]
	Learning Rate: 0.00855585
	LOSS [training: 2.245166540664894 | validation: 3.333826554303502]
	TIME [epoch: 8.55 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3512194566504228		[learning rate: 0.0085248]
	Learning Rate: 0.0085248
	LOSS [training: 2.3512194566504228 | validation: 3.6957290924388992]
	TIME [epoch: 8.53 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3211730953047756		[learning rate: 0.0084939]
	Learning Rate: 0.00849386
	LOSS [training: 2.3211730953047756 | validation: 3.0266684597478646]
	TIME [epoch: 8.53 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.241037100217862		[learning rate: 0.008463]
	Learning Rate: 0.00846304
	LOSS [training: 2.241037100217862 | validation: 2.9607890064283167]
	TIME [epoch: 8.53 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.220076892356884		[learning rate: 0.0084323]
	Learning Rate: 0.00843233
	LOSS [training: 2.220076892356884 | validation: 2.989070091826055]
	TIME [epoch: 8.55 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2977689033952875		[learning rate: 0.0084017]
	Learning Rate: 0.00840172
	LOSS [training: 2.2977689033952875 | validation: 3.033566432623659]
	TIME [epoch: 8.54 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.318792234958386		[learning rate: 0.0083712]
	Learning Rate: 0.00837123
	LOSS [training: 2.318792234958386 | validation: 3.5449764366112104]
	TIME [epoch: 8.53 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.392114495132111		[learning rate: 0.0083409]
	Learning Rate: 0.00834085
	LOSS [training: 2.392114495132111 | validation: 3.2282188236524814]
	TIME [epoch: 8.53 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2937911711945147		[learning rate: 0.0083106]
	Learning Rate: 0.00831059
	LOSS [training: 2.2937911711945147 | validation: 3.2503605655138768]
	TIME [epoch: 8.54 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2665661564390587		[learning rate: 0.0082804]
	Learning Rate: 0.00828043
	LOSS [training: 2.2665661564390587 | validation: 3.0509652914424867]
	TIME [epoch: 8.55 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2938496649716633		[learning rate: 0.0082504]
	Learning Rate: 0.00825037
	LOSS [training: 2.2938496649716633 | validation: 2.8982263879213503]
	TIME [epoch: 8.53 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.258783216558909		[learning rate: 0.0082204]
	Learning Rate: 0.00822043
	LOSS [training: 2.258783216558909 | validation: 3.0829181822046117]
	TIME [epoch: 8.53 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.293273210094436		[learning rate: 0.0081906]
	Learning Rate: 0.0081906
	LOSS [training: 2.293273210094436 | validation: 3.521653034183781]
	TIME [epoch: 8.53 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3564274362938535		[learning rate: 0.0081609]
	Learning Rate: 0.00816088
	LOSS [training: 2.3564274362938535 | validation: 3.0058467670072924]
	TIME [epoch: 8.56 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.28069943593263		[learning rate: 0.0081313]
	Learning Rate: 0.00813126
	LOSS [training: 2.28069943593263 | validation: 3.0261050693321043]
	TIME [epoch: 8.53 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1668947880535576		[learning rate: 0.0081018]
	Learning Rate: 0.00810175
	LOSS [training: 2.1668947880535576 | validation: 2.9119200129866893]
	TIME [epoch: 8.53 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.251776042319915		[learning rate: 0.0080724]
	Learning Rate: 0.00807235
	LOSS [training: 2.251776042319915 | validation: 3.1952232355049235]
	TIME [epoch: 8.52 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2786125960956674		[learning rate: 0.0080431]
	Learning Rate: 0.00804305
	LOSS [training: 2.2786125960956674 | validation: 3.039900838490133]
	TIME [epoch: 8.55 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.248780271594152		[learning rate: 0.0080139]
	Learning Rate: 0.00801387
	LOSS [training: 2.248780271594152 | validation: 2.913516497425463]
	TIME [epoch: 8.52 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2680382122171734		[learning rate: 0.0079848]
	Learning Rate: 0.00798478
	LOSS [training: 2.2680382122171734 | validation: 3.391252756767586]
	TIME [epoch: 8.52 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3479937605533374		[learning rate: 0.0079558]
	Learning Rate: 0.00795581
	LOSS [training: 2.3479937605533374 | validation: 3.159256261971727]
	TIME [epoch: 8.52 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.392583069813398		[learning rate: 0.0079269]
	Learning Rate: 0.00792693
	LOSS [training: 2.392583069813398 | validation: 2.835168783295164]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_164.pth
	Model improved!!!
EPOCH 165/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2546720643958955		[learning rate: 0.0078982]
	Learning Rate: 0.00789817
	LOSS [training: 2.2546720643958955 | validation: 3.3917191762540253]
	TIME [epoch: 8.54 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.433776394193708		[learning rate: 0.0078695]
	Learning Rate: 0.0078695
	LOSS [training: 2.433776394193708 | validation: 3.524641178282941]
	TIME [epoch: 8.53 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4010865299363777		[learning rate: 0.0078409]
	Learning Rate: 0.00784094
	LOSS [training: 2.4010865299363777 | validation: 3.304610528645038]
	TIME [epoch: 8.53 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.216408230592723		[learning rate: 0.0078125]
	Learning Rate: 0.00781249
	LOSS [training: 2.216408230592723 | validation: 2.799838655093122]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_168.pth
	Model improved!!!
EPOCH 169/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2960328196140045		[learning rate: 0.0077841]
	Learning Rate: 0.00778414
	LOSS [training: 2.2960328196140045 | validation: 2.974999989356391]
	TIME [epoch: 8.57 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4206412401875133		[learning rate: 0.0077559]
	Learning Rate: 0.00775589
	LOSS [training: 2.4206412401875133 | validation: 2.8700535139738284]
	TIME [epoch: 8.52 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4024780332481908		[learning rate: 0.0077277]
	Learning Rate: 0.00772774
	LOSS [training: 2.4024780332481908 | validation: 2.857728775475989]
	TIME [epoch: 8.52 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1284057822410203		[learning rate: 0.0076997]
	Learning Rate: 0.0076997
	LOSS [training: 2.1284057822410203 | validation: 3.094384768717835]
	TIME [epoch: 8.52 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2517750125565548		[learning rate: 0.0076718]
	Learning Rate: 0.00767176
	LOSS [training: 2.2517750125565548 | validation: 2.756839284410941]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_173.pth
	Model improved!!!
EPOCH 174/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.987946035831643		[learning rate: 0.0076439]
	Learning Rate: 0.00764391
	LOSS [training: 1.987946035831643 | validation: 2.948345213414652]
	TIME [epoch: 8.52 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7590727052126085		[learning rate: 0.0076162]
	Learning Rate: 0.00761617
	LOSS [training: 1.7590727052126085 | validation: 2.281279238323058]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_175.pth
	Model improved!!!
EPOCH 176/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8085168544337944		[learning rate: 0.0075885]
	Learning Rate: 0.00758853
	LOSS [training: 1.8085168544337944 | validation: 2.2057548386085593]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_176.pth
	Model improved!!!
EPOCH 177/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6348530009769786		[learning rate: 0.007561]
	Learning Rate: 0.00756099
	LOSS [training: 1.6348530009769786 | validation: 2.0946042637713846]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_177.pth
	Model improved!!!
EPOCH 178/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5898055245008418		[learning rate: 0.0075336]
	Learning Rate: 0.00753356
	LOSS [training: 1.5898055245008418 | validation: 2.0831182240297506]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_178.pth
	Model improved!!!
EPOCH 179/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4790762637765587		[learning rate: 0.0075062]
	Learning Rate: 0.00750622
	LOSS [training: 1.4790762637765587 | validation: 1.281262756302029]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_179.pth
	Model improved!!!
EPOCH 180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9645521244870736		[learning rate: 0.007479]
	Learning Rate: 0.00747897
	LOSS [training: 0.9645521244870736 | validation: 1.1097698195598347]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_180.pth
	Model improved!!!
EPOCH 181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8691931517893762		[learning rate: 0.0074518]
	Learning Rate: 0.00745183
	LOSS [training: 0.8691931517893762 | validation: 1.0850017189159638]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_181.pth
	Model improved!!!
EPOCH 182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9587033694738369		[learning rate: 0.0074248]
	Learning Rate: 0.00742479
	LOSS [training: 0.9587033694738369 | validation: 0.7512905044335911]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_182.pth
	Model improved!!!
EPOCH 183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.934103496778248		[learning rate: 0.0073978]
	Learning Rate: 0.00739784
	LOSS [training: 0.934103496778248 | validation: 1.137304067039732]
	TIME [epoch: 8.53 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7683305249013221		[learning rate: 0.007371]
	Learning Rate: 0.007371
	LOSS [training: 0.7683305249013221 | validation: 0.8904286411399309]
	TIME [epoch: 8.53 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6963356838613131		[learning rate: 0.0073442]
	Learning Rate: 0.00734425
	LOSS [training: 0.6963356838613131 | validation: 0.716811742442957]
	TIME [epoch: 8.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_185.pth
	Model improved!!!
EPOCH 186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6983415484131537		[learning rate: 0.0073176]
	Learning Rate: 0.0073176
	LOSS [training: 0.6983415484131537 | validation: 0.8056540205113045]
	TIME [epoch: 8.54 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.695042589862165		[learning rate: 0.007291]
	Learning Rate: 0.00729104
	LOSS [training: 0.695042589862165 | validation: 0.6045685051491533]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_187.pth
	Model improved!!!
EPOCH 188/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.656239687851953		[learning rate: 0.0072646]
	Learning Rate: 0.00726458
	LOSS [training: 1.656239687851953 | validation: 0.5205263645307338]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_188.pth
	Model improved!!!
EPOCH 189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5654173003962475		[learning rate: 0.0072382]
	Learning Rate: 0.00723822
	LOSS [training: 0.5654173003962475 | validation: 0.5300335463452914]
	TIME [epoch: 8.55 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5866102847967329		[learning rate: 0.0072119]
	Learning Rate: 0.00721195
	LOSS [training: 0.5866102847967329 | validation: 0.6885055075081672]
	TIME [epoch: 8.53 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6957826427931182		[learning rate: 0.0071858]
	Learning Rate: 0.00718578
	LOSS [training: 0.6957826427931182 | validation: 0.6215529770164867]
	TIME [epoch: 8.53 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5748140121113448		[learning rate: 0.0071597]
	Learning Rate: 0.0071597
	LOSS [training: 0.5748140121113448 | validation: 0.4686348633545766]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_192.pth
	Model improved!!!
EPOCH 193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7200166692067846		[learning rate: 0.0071337]
	Learning Rate: 0.00713371
	LOSS [training: 0.7200166692067846 | validation: 0.700791375686927]
	TIME [epoch: 8.54 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6110471715318108		[learning rate: 0.0071078]
	Learning Rate: 0.00710783
	LOSS [training: 0.6110471715318108 | validation: 0.5907147228359946]
	TIME [epoch: 8.52 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5896378754081085		[learning rate: 0.007082]
	Learning Rate: 0.00708203
	LOSS [training: 0.5896378754081085 | validation: 1.1154259307167127]
	TIME [epoch: 8.52 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5972683138756151		[learning rate: 0.0070563]
	Learning Rate: 0.00705633
	LOSS [training: 0.5972683138756151 | validation: 0.9893987970366532]
	TIME [epoch: 8.52 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7546693958015438		[learning rate: 0.0070307]
	Learning Rate: 0.00703072
	LOSS [training: 0.7546693958015438 | validation: 0.926547301228904]
	TIME [epoch: 8.53 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8992497920060295		[learning rate: 0.0070052]
	Learning Rate: 0.00700521
	LOSS [training: 0.8992497920060295 | validation: 0.5993899515846426]
	TIME [epoch: 8.53 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7055160913380937		[learning rate: 0.0069798]
	Learning Rate: 0.00697979
	LOSS [training: 0.7055160913380937 | validation: 0.5710821706903715]
	TIME [epoch: 8.52 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5022712110432496		[learning rate: 0.0069545]
	Learning Rate: 0.00695446
	LOSS [training: 0.5022712110432496 | validation: 0.6826810017698348]
	TIME [epoch: 8.52 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6700154275021164		[learning rate: 0.0069292]
	Learning Rate: 0.00692922
	LOSS [training: 0.6700154275021164 | validation: 0.5581807311047011]
	TIME [epoch: 8.52 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5336927427547465		[learning rate: 0.0069041]
	Learning Rate: 0.00690407
	LOSS [training: 0.5336927427547465 | validation: 0.7031075107014797]
	TIME [epoch: 8.54 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5643764997940688		[learning rate: 0.006879]
	Learning Rate: 0.00687902
	LOSS [training: 0.5643764997940688 | validation: 0.775813504873261]
	TIME [epoch: 8.51 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7285415549786888		[learning rate: 0.0068541]
	Learning Rate: 0.00685405
	LOSS [training: 0.7285415549786888 | validation: 1.173991309867786]
	TIME [epoch: 8.52 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7168960963884924		[learning rate: 0.0068292]
	Learning Rate: 0.00682918
	LOSS [training: 0.7168960963884924 | validation: 0.44614071452259]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_205.pth
	Model improved!!!
EPOCH 206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9285315901245074		[learning rate: 0.0068044]
	Learning Rate: 0.00680439
	LOSS [training: 0.9285315901245074 | validation: 0.43292922681609003]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_206.pth
	Model improved!!!
EPOCH 207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5258354649712961		[learning rate: 0.0067797]
	Learning Rate: 0.0067797
	LOSS [training: 0.5258354649712961 | validation: 1.1992796718403793]
	TIME [epoch: 8.52 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6078975131258304		[learning rate: 0.0067551]
	Learning Rate: 0.0067551
	LOSS [training: 0.6078975131258304 | validation: 0.5167244101377553]
	TIME [epoch: 8.51 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5289670937278439		[learning rate: 0.0067306]
	Learning Rate: 0.00673058
	LOSS [training: 0.5289670937278439 | validation: 0.4024228414718992]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_209.pth
	Model improved!!!
EPOCH 210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5796198628651762		[learning rate: 0.0067062]
	Learning Rate: 0.00670616
	LOSS [training: 0.5796198628651762 | validation: 0.710475886549891]
	TIME [epoch: 8.54 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6529011372190264		[learning rate: 0.0066818]
	Learning Rate: 0.00668182
	LOSS [training: 0.6529011372190264 | validation: 0.6095824829698802]
	TIME [epoch: 8.52 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4788949953978226		[learning rate: 0.0066576]
	Learning Rate: 0.00665757
	LOSS [training: 0.4788949953978226 | validation: 0.3602972443174305]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_212.pth
	Model improved!!!
EPOCH 213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5059643635050631		[learning rate: 0.0066334]
	Learning Rate: 0.00663341
	LOSS [training: 0.5059643635050631 | validation: 0.5369886848764468]
	TIME [epoch: 8.52 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7703121415383025		[learning rate: 0.0066093]
	Learning Rate: 0.00660934
	LOSS [training: 0.7703121415383025 | validation: 0.42905150383205654]
	TIME [epoch: 8.54 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6078550318315965		[learning rate: 0.0065854]
	Learning Rate: 0.00658535
	LOSS [training: 0.6078550318315965 | validation: 0.5067251952881133]
	TIME [epoch: 8.52 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5464414870453613		[learning rate: 0.0065615]
	Learning Rate: 0.00656145
	LOSS [training: 0.5464414870453613 | validation: 0.426986421951035]
	TIME [epoch: 8.51 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4660336810149766		[learning rate: 0.0065376]
	Learning Rate: 0.00653764
	LOSS [training: 0.4660336810149766 | validation: 0.3746053087934879]
	TIME [epoch: 8.51 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5946461155537727		[learning rate: 0.0065139]
	Learning Rate: 0.00651392
	LOSS [training: 0.5946461155537727 | validation: 0.8843866788746709]
	TIME [epoch: 8.52 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7644487426245675		[learning rate: 0.0064903]
	Learning Rate: 0.00649028
	LOSS [training: 0.7644487426245675 | validation: 0.7146995170073103]
	TIME [epoch: 8.53 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5007213724790984		[learning rate: 0.0064667]
	Learning Rate: 0.00646672
	LOSS [training: 0.5007213724790984 | validation: 0.9193324646779276]
	TIME [epoch: 8.51 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5275054977181703		[learning rate: 0.0064433]
	Learning Rate: 0.00644325
	LOSS [training: 0.5275054977181703 | validation: 0.704724237552794]
	TIME [epoch: 8.51 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4671150192773238		[learning rate: 0.0064199]
	Learning Rate: 0.00641987
	LOSS [training: 0.4671150192773238 | validation: 0.4547232568798728]
	TIME [epoch: 8.51 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5035459561384064		[learning rate: 0.0063966]
	Learning Rate: 0.00639657
	LOSS [training: 0.5035459561384064 | validation: 0.47513117595720356]
	TIME [epoch: 8.53 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4699953903027354		[learning rate: 0.0063734]
	Learning Rate: 0.00637336
	LOSS [training: 0.4699953903027354 | validation: 0.3217123381331787]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_224.pth
	Model improved!!!
EPOCH 225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49067171039444474		[learning rate: 0.0063502]
	Learning Rate: 0.00635023
	LOSS [training: 0.49067171039444474 | validation: 0.40794758759074423]
	TIME [epoch: 8.52 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49952779912243395		[learning rate: 0.0063272]
	Learning Rate: 0.00632718
	LOSS [training: 0.49952779912243395 | validation: 0.2988487543864038]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_226.pth
	Model improved!!!
EPOCH 227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.579622912363825		[learning rate: 0.0063042]
	Learning Rate: 0.00630422
	LOSS [training: 0.579622912363825 | validation: 0.7237230314181236]
	TIME [epoch: 8.54 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48602358535981577		[learning rate: 0.0062813]
	Learning Rate: 0.00628134
	LOSS [training: 0.48602358535981577 | validation: 0.45693885565115905]
	TIME [epoch: 8.51 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4852241681035127		[learning rate: 0.0062585]
	Learning Rate: 0.00625855
	LOSS [training: 0.4852241681035127 | validation: 0.3358064035107073]
	TIME [epoch: 8.51 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6634811226887567		[learning rate: 0.0062358]
	Learning Rate: 0.00623584
	LOSS [training: 0.6634811226887567 | validation: 0.40314544479180225]
	TIME [epoch: 8.51 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6000743069039727		[learning rate: 0.0062132]
	Learning Rate: 0.00621321
	LOSS [training: 0.6000743069039727 | validation: 0.5122911600592395]
	TIME [epoch: 8.54 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48092754506516056		[learning rate: 0.0061907]
	Learning Rate: 0.00619066
	LOSS [training: 0.48092754506516056 | validation: 0.8927195074786918]
	TIME [epoch: 8.52 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46205897380144495		[learning rate: 0.0061682]
	Learning Rate: 0.00616819
	LOSS [training: 0.46205897380144495 | validation: 0.3807809641081805]
	TIME [epoch: 8.51 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41501056332851355		[learning rate: 0.0061458]
	Learning Rate: 0.00614581
	LOSS [training: 0.41501056332851355 | validation: 0.24443475315483093]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_234.pth
	Model improved!!!
EPOCH 235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4260531606247141		[learning rate: 0.0061235]
	Learning Rate: 0.0061235
	LOSS [training: 0.4260531606247141 | validation: 0.6418481016036529]
	TIME [epoch: 8.54 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4624924768353111		[learning rate: 0.0061013]
	Learning Rate: 0.00610128
	LOSS [training: 0.4624924768353111 | validation: 0.2851160426926293]
	TIME [epoch: 8.52 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4491979921977469		[learning rate: 0.0060791]
	Learning Rate: 0.00607914
	LOSS [training: 0.4491979921977469 | validation: 1.0897889195558583]
	TIME [epoch: 8.51 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5111772613007584		[learning rate: 0.0060571]
	Learning Rate: 0.00605708
	LOSS [training: 0.5111772613007584 | validation: 0.4693921582829528]
	TIME [epoch: 8.51 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43094070432292275		[learning rate: 0.0060351]
	Learning Rate: 0.0060351
	LOSS [training: 0.43094070432292275 | validation: 0.6473394403206782]
	TIME [epoch: 8.52 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5858421628674597		[learning rate: 0.0060132]
	Learning Rate: 0.00601319
	LOSS [training: 0.5858421628674597 | validation: 0.9873338258476704]
	TIME [epoch: 8.53 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4921500419299261		[learning rate: 0.0059914]
	Learning Rate: 0.00599137
	LOSS [training: 0.4921500419299261 | validation: 0.405858251885468]
	TIME [epoch: 8.51 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.455578579597547		[learning rate: 0.0059696]
	Learning Rate: 0.00596963
	LOSS [training: 0.455578579597547 | validation: 0.5465054693624976]
	TIME [epoch: 8.51 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5864789902217733		[learning rate: 0.005948]
	Learning Rate: 0.00594797
	LOSS [training: 0.5864789902217733 | validation: 0.3348163646154997]
	TIME [epoch: 8.52 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5323216317469097		[learning rate: 0.0059264]
	Learning Rate: 0.00592638
	LOSS [training: 0.5323216317469097 | validation: 0.7551207269685304]
	TIME [epoch: 8.54 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4542196694131637		[learning rate: 0.0059049]
	Learning Rate: 0.00590487
	LOSS [training: 0.4542196694131637 | validation: 0.25205569179122583]
	TIME [epoch: 8.51 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48432748974034806		[learning rate: 0.0058834]
	Learning Rate: 0.00588344
	LOSS [training: 0.48432748974034806 | validation: 0.46890632002778987]
	TIME [epoch: 8.51 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4402528279831965		[learning rate: 0.0058621]
	Learning Rate: 0.00586209
	LOSS [training: 0.4402528279831965 | validation: 0.5768789503427092]
	TIME [epoch: 8.51 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4261228138593533		[learning rate: 0.0058408]
	Learning Rate: 0.00584082
	LOSS [training: 0.4261228138593533 | validation: 0.7967439238414766]
	TIME [epoch: 8.54 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5552126831915627		[learning rate: 0.0058196]
	Learning Rate: 0.00581962
	LOSS [training: 0.5552126831915627 | validation: 0.3928491497267059]
	TIME [epoch: 8.52 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3931478026286053		[learning rate: 0.0057985]
	Learning Rate: 0.0057985
	LOSS [training: 0.3931478026286053 | validation: 0.31089013878682814]
	TIME [epoch: 8.51 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49277375390449885		[learning rate: 0.0057775]
	Learning Rate: 0.00577746
	LOSS [training: 0.49277375390449885 | validation: 0.9022743300433425]
	TIME [epoch: 8.51 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44494580674005607		[learning rate: 0.0057565]
	Learning Rate: 0.00575649
	LOSS [training: 0.44494580674005607 | validation: 0.31216127676087846]
	TIME [epoch: 8.53 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3773460725923836		[learning rate: 0.0057356]
	Learning Rate: 0.0057356
	LOSS [training: 0.3773460725923836 | validation: 0.9002585298573541]
	TIME [epoch: 8.52 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5117234563967983		[learning rate: 0.0057148]
	Learning Rate: 0.00571479
	LOSS [training: 0.5117234563967983 | validation: 0.7613046138938773]
	TIME [epoch: 8.51 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3670465470015121		[learning rate: 0.005694]
	Learning Rate: 0.00569405
	LOSS [training: 0.3670465470015121 | validation: 0.3375459742734267]
	TIME [epoch: 8.51 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35637348712478906		[learning rate: 0.0056734]
	Learning Rate: 0.00567338
	LOSS [training: 0.35637348712478906 | validation: 0.4297571039409554]
	TIME [epoch: 8.52 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4218971862143577		[learning rate: 0.0056528]
	Learning Rate: 0.00565279
	LOSS [training: 0.4218971862143577 | validation: 0.33230645420874805]
	TIME [epoch: 8.53 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.553378397932119		[learning rate: 0.0056323]
	Learning Rate: 0.00563228
	LOSS [training: 0.553378397932119 | validation: 0.4287331575582276]
	TIME [epoch: 8.51 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.773974406462399		[learning rate: 0.0056118]
	Learning Rate: 0.00561184
	LOSS [training: 0.773974406462399 | validation: 0.36948419099062524]
	TIME [epoch: 8.51 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44053040205567057		[learning rate: 0.0055915]
	Learning Rate: 0.00559147
	LOSS [training: 0.44053040205567057 | validation: 0.274732023199639]
	TIME [epoch: 8.51 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.439771484726564		[learning rate: 0.0055712]
	Learning Rate: 0.00557118
	LOSS [training: 0.439771484726564 | validation: 0.23099717644435286]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_261.pth
	Model improved!!!
EPOCH 262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38118534453847436		[learning rate: 0.005551]
	Learning Rate: 0.00555096
	LOSS [training: 0.38118534453847436 | validation: 0.2770321902363092]
	TIME [epoch: 8.52 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.422662738325099		[learning rate: 0.0055308]
	Learning Rate: 0.00553082
	LOSS [training: 0.422662738325099 | validation: 0.26436108049782603]
	TIME [epoch: 8.51 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3490497310893829		[learning rate: 0.0055107]
	Learning Rate: 0.00551075
	LOSS [training: 0.3490497310893829 | validation: 0.47941227207313314]
	TIME [epoch: 8.52 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4470586189233082		[learning rate: 0.0054907]
	Learning Rate: 0.00549075
	LOSS [training: 0.4470586189233082 | validation: 0.2686964925973973]
	TIME [epoch: 8.54 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47184627810927626		[learning rate: 0.0054708]
	Learning Rate: 0.00547082
	LOSS [training: 0.47184627810927626 | validation: 0.5732182269919646]
	TIME [epoch: 8.52 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45894209019168086		[learning rate: 0.005451]
	Learning Rate: 0.00545097
	LOSS [training: 0.45894209019168086 | validation: 0.5533297268543184]
	TIME [epoch: 8.51 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3531251328781617		[learning rate: 0.0054312]
	Learning Rate: 0.00543119
	LOSS [training: 0.3531251328781617 | validation: 0.32403133946960483]
	TIME [epoch: 8.51 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3263782707968211		[learning rate: 0.0054115]
	Learning Rate: 0.00541148
	LOSS [training: 0.3263782707968211 | validation: 0.3411760756908052]
	TIME [epoch: 8.54 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3840505175793397		[learning rate: 0.0053918]
	Learning Rate: 0.00539184
	LOSS [training: 0.3840505175793397 | validation: 0.29137015349869044]
	TIME [epoch: 8.51 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39189896452203454		[learning rate: 0.0053723]
	Learning Rate: 0.00537227
	LOSS [training: 0.39189896452203454 | validation: 0.6520158593903687]
	TIME [epoch: 8.52 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37409458505733		[learning rate: 0.0053528]
	Learning Rate: 0.00535277
	LOSS [training: 0.37409458505733 | validation: 1.0916333801646168]
	TIME [epoch: 8.52 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6106981073585968		[learning rate: 0.0053333]
	Learning Rate: 0.00533335
	LOSS [training: 0.6106981073585968 | validation: 0.3434536986141796]
	TIME [epoch: 8.53 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38093678052717495		[learning rate: 0.005314]
	Learning Rate: 0.00531399
	LOSS [training: 0.38093678052717495 | validation: 0.4079681438476641]
	TIME [epoch: 8.54 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3209057864079485		[learning rate: 0.0052947]
	Learning Rate: 0.00529471
	LOSS [training: 0.3209057864079485 | validation: 0.3124926233244275]
	TIME [epoch: 8.52 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34239781972798017		[learning rate: 0.0052755]
	Learning Rate: 0.00527549
	LOSS [training: 0.34239781972798017 | validation: 0.3107783044375315]
	TIME [epoch: 8.52 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32922061639758804		[learning rate: 0.0052563]
	Learning Rate: 0.00525635
	LOSS [training: 0.32922061639758804 | validation: 0.4200056824403874]
	TIME [epoch: 8.52 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.316753573012292		[learning rate: 0.0052373]
	Learning Rate: 0.00523727
	LOSS [training: 0.316753573012292 | validation: 0.31660017257241996]
	TIME [epoch: 8.54 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3950623706128092		[learning rate: 0.0052183]
	Learning Rate: 0.00521827
	LOSS [training: 0.3950623706128092 | validation: 0.23555708452871593]
	TIME [epoch: 8.52 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34358204605100306		[learning rate: 0.0051993]
	Learning Rate: 0.00519933
	LOSS [training: 0.34358204605100306 | validation: 0.27818053220933964]
	TIME [epoch: 8.52 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4131878001695708		[learning rate: 0.0051805]
	Learning Rate: 0.00518046
	LOSS [training: 0.4131878001695708 | validation: 1.1231888955703409]
	TIME [epoch: 8.52 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5294569507936671		[learning rate: 0.0051617]
	Learning Rate: 0.00516166
	LOSS [training: 0.5294569507936671 | validation: 0.7619091062807448]
	TIME [epoch: 8.54 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41429303068011575		[learning rate: 0.0051429]
	Learning Rate: 0.00514293
	LOSS [training: 0.41429303068011575 | validation: 0.26366198666781815]
	TIME [epoch: 8.52 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5152645581354557		[learning rate: 0.0051243]
	Learning Rate: 0.00512426
	LOSS [training: 0.5152645581354557 | validation: 0.26693048928348884]
	TIME [epoch: 8.52 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3607363991271945		[learning rate: 0.0051057]
	Learning Rate: 0.00510567
	LOSS [training: 0.3607363991271945 | validation: 0.5111184725514154]
	TIME [epoch: 8.52 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37397569706870676		[learning rate: 0.0050871]
	Learning Rate: 0.00508714
	LOSS [training: 0.37397569706870676 | validation: 0.4848765570948106]
	TIME [epoch: 8.54 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4218634042911556		[learning rate: 0.0050687]
	Learning Rate: 0.00506868
	LOSS [training: 0.4218634042911556 | validation: 0.35568933933611047]
	TIME [epoch: 8.52 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3867598671167331		[learning rate: 0.0050503]
	Learning Rate: 0.00505028
	LOSS [training: 0.3867598671167331 | validation: 0.2319216963449942]
	TIME [epoch: 8.52 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4243184062295279		[learning rate: 0.005032]
	Learning Rate: 0.00503196
	LOSS [training: 0.4243184062295279 | validation: 0.5376645182297528]
	TIME [epoch: 8.52 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4910917492139634		[learning rate: 0.0050137]
	Learning Rate: 0.00501369
	LOSS [training: 0.4910917492139634 | validation: 0.5262727116999601]
	TIME [epoch: 8.53 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4625725527789374		[learning rate: 0.0049955]
	Learning Rate: 0.0049955
	LOSS [training: 0.4625725527789374 | validation: 0.40203122295422855]
	TIME [epoch: 8.53 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5463560587922973		[learning rate: 0.0049774]
	Learning Rate: 0.00497737
	LOSS [training: 0.5463560587922973 | validation: 0.4744077415270407]
	TIME [epoch: 8.52 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34256792682598197		[learning rate: 0.0049593]
	Learning Rate: 0.00495931
	LOSS [training: 0.34256792682598197 | validation: 0.266107143371817]
	TIME [epoch: 8.52 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33846108856015533		[learning rate: 0.0049413]
	Learning Rate: 0.00494131
	LOSS [training: 0.33846108856015533 | validation: 0.23506511563517568]
	TIME [epoch: 8.52 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31422638258260943		[learning rate: 0.0049234]
	Learning Rate: 0.00492338
	LOSS [training: 0.31422638258260943 | validation: 0.22904699204516338]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_295.pth
	Model improved!!!
EPOCH 296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2582625288828723		[learning rate: 0.0049055]
	Learning Rate: 0.00490551
	LOSS [training: 0.2582625288828723 | validation: 0.19307694138542147]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_296.pth
	Model improved!!!
EPOCH 297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3310869145134048		[learning rate: 0.0048877]
	Learning Rate: 0.00488771
	LOSS [training: 0.3310869145134048 | validation: 0.2837041367615689]
	TIME [epoch: 8.54 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5220423552728483		[learning rate: 0.00487]
	Learning Rate: 0.00486997
	LOSS [training: 0.5220423552728483 | validation: 0.3028196159234882]
	TIME [epoch: 8.54 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2734927080242691		[learning rate: 0.0048523]
	Learning Rate: 0.0048523
	LOSS [training: 0.2734927080242691 | validation: 0.43739446508086566]
	TIME [epoch: 8.56 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4316691435633417		[learning rate: 0.0048347]
	Learning Rate: 0.00483469
	LOSS [training: 0.4316691435633417 | validation: 0.39567448004653216]
	TIME [epoch: 8.54 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3054248791585264		[learning rate: 0.0048171]
	Learning Rate: 0.00481714
	LOSS [training: 0.3054248791585264 | validation: 0.18266477701914036]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_301.pth
	Model improved!!!
EPOCH 302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.374140658583772		[learning rate: 0.0047997]
	Learning Rate: 0.00479966
	LOSS [training: 0.374140658583772 | validation: 0.4144990269542096]
	TIME [epoch: 8.54 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3336480491915435		[learning rate: 0.0047822]
	Learning Rate: 0.00478224
	LOSS [training: 0.3336480491915435 | validation: 0.15628820948883487]
	TIME [epoch: 8.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_303.pth
	Model improved!!!
EPOCH 304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3609437075750153		[learning rate: 0.0047649]
	Learning Rate: 0.00476489
	LOSS [training: 0.3609437075750153 | validation: 0.6290761613891188]
	TIME [epoch: 8.54 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39777156538465863		[learning rate: 0.0047476]
	Learning Rate: 0.00474759
	LOSS [training: 0.39777156538465863 | validation: 0.25862620914552004]
	TIME [epoch: 8.54 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3908961775115987		[learning rate: 0.0047304]
	Learning Rate: 0.00473037
	LOSS [training: 0.3908961775115987 | validation: 0.2579926395203733]
	TIME [epoch: 8.54 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32954305560555885		[learning rate: 0.0047132]
	Learning Rate: 0.0047132
	LOSS [training: 0.32954305560555885 | validation: 0.18747550413604774]
	TIME [epoch: 8.56 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32297775543305535		[learning rate: 0.0046961]
	Learning Rate: 0.00469609
	LOSS [training: 0.32297775543305535 | validation: 0.2186129544492235]
	TIME [epoch: 8.54 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2956050754066786		[learning rate: 0.0046791]
	Learning Rate: 0.00467905
	LOSS [training: 0.2956050754066786 | validation: 0.2457267790230409]
	TIME [epoch: 8.54 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2915881646132475		[learning rate: 0.0046621]
	Learning Rate: 0.00466207
	LOSS [training: 0.2915881646132475 | validation: 0.4251311421945344]
	TIME [epoch: 8.53 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29041266390351606		[learning rate: 0.0046452]
	Learning Rate: 0.00464515
	LOSS [training: 0.29041266390351606 | validation: 0.23972557230064273]
	TIME [epoch: 8.55 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4376023621135082		[learning rate: 0.0046283]
	Learning Rate: 0.0046283
	LOSS [training: 0.4376023621135082 | validation: 0.29033751703482624]
	TIME [epoch: 8.55 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36643101655027005		[learning rate: 0.0046115]
	Learning Rate: 0.0046115
	LOSS [training: 0.36643101655027005 | validation: 0.4329575471412911]
	TIME [epoch: 8.53 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35061397795452864		[learning rate: 0.0045948]
	Learning Rate: 0.00459476
	LOSS [training: 0.35061397795452864 | validation: 0.26100432669103774]
	TIME [epoch: 8.53 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30351082880906155		[learning rate: 0.0045781]
	Learning Rate: 0.00457809
	LOSS [training: 0.30351082880906155 | validation: 0.46778113465850013]
	TIME [epoch: 8.54 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3755185963907725		[learning rate: 0.0045615]
	Learning Rate: 0.00456148
	LOSS [training: 0.3755185963907725 | validation: 0.6255189299680531]
	TIME [epoch: 8.56 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4269238845666431		[learning rate: 0.0045449]
	Learning Rate: 0.00454492
	LOSS [training: 0.4269238845666431 | validation: 0.28409426627606604]
	TIME [epoch: 8.53 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5201396239500926		[learning rate: 0.0045284]
	Learning Rate: 0.00452843
	LOSS [training: 0.5201396239500926 | validation: 0.2959684953600591]
	TIME [epoch: 8.53 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31210616115901124		[learning rate: 0.004512]
	Learning Rate: 0.00451199
	LOSS [training: 0.31210616115901124 | validation: 0.3731692769565269]
	TIME [epoch: 8.53 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3585896540905317		[learning rate: 0.0044956]
	Learning Rate: 0.00449562
	LOSS [training: 0.3585896540905317 | validation: 0.34448077708202196]
	TIME [epoch: 8.56 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39974055039338374		[learning rate: 0.0044793]
	Learning Rate: 0.0044793
	LOSS [training: 0.39974055039338374 | validation: 0.6306558440433836]
	TIME [epoch: 8.54 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3349536701276775		[learning rate: 0.004463]
	Learning Rate: 0.00446305
	LOSS [training: 0.3349536701276775 | validation: 0.24697560789967782]
	TIME [epoch: 8.53 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28028731996186923		[learning rate: 0.0044469]
	Learning Rate: 0.00444685
	LOSS [training: 0.28028731996186923 | validation: 0.4802079112844223]
	TIME [epoch: 8.54 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34434954836641013		[learning rate: 0.0044307]
	Learning Rate: 0.00443071
	LOSS [training: 0.34434954836641013 | validation: 0.60571297632212]
	TIME [epoch: 8.56 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3695257787173755		[learning rate: 0.0044146]
	Learning Rate: 0.00441463
	LOSS [training: 0.3695257787173755 | validation: 0.4211842280359561]
	TIME [epoch: 8.53 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2738898266595674		[learning rate: 0.0043986]
	Learning Rate: 0.00439861
	LOSS [training: 0.2738898266595674 | validation: 0.24052091139955975]
	TIME [epoch: 8.53 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42465100040608794		[learning rate: 0.0043827]
	Learning Rate: 0.00438265
	LOSS [training: 0.42465100040608794 | validation: 0.49795910346866623]
	TIME [epoch: 8.53 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3580777845644298		[learning rate: 0.0043667]
	Learning Rate: 0.00436675
	LOSS [training: 0.3580777845644298 | validation: 0.2928216707964637]
	TIME [epoch: 8.56 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27554719924748133		[learning rate: 0.0043509]
	Learning Rate: 0.0043509
	LOSS [training: 0.27554719924748133 | validation: 0.38606945100005724]
	TIME [epoch: 8.54 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29654526545751897		[learning rate: 0.0043351]
	Learning Rate: 0.00433511
	LOSS [training: 0.29654526545751897 | validation: 0.806196806560949]
	TIME [epoch: 8.54 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4358307819865989		[learning rate: 0.0043194]
	Learning Rate: 0.00431938
	LOSS [training: 0.4358307819865989 | validation: 0.33158572180044404]
	TIME [epoch: 8.53 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2995169707706771		[learning rate: 0.0043037]
	Learning Rate: 0.0043037
	LOSS [training: 0.2995169707706771 | validation: 0.39132458793550706]
	TIME [epoch: 8.54 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3056096228247675		[learning rate: 0.0042881]
	Learning Rate: 0.00428808
	LOSS [training: 0.3056096228247675 | validation: 0.37742202940795333]
	TIME [epoch: 8.56 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3098188715251041		[learning rate: 0.0042725]
	Learning Rate: 0.00427252
	LOSS [training: 0.3098188715251041 | validation: 0.2052149468254963]
	TIME [epoch: 8.53 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36642959910711925		[learning rate: 0.004257]
	Learning Rate: 0.00425702
	LOSS [training: 0.36642959910711925 | validation: 0.6079565445346271]
	TIME [epoch: 8.53 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2872065713801978		[learning rate: 0.0042416]
	Learning Rate: 0.00424157
	LOSS [training: 0.2872065713801978 | validation: 0.19536764720690455]
	TIME [epoch: 8.53 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23528325076709017		[learning rate: 0.0042262]
	Learning Rate: 0.00422617
	LOSS [training: 0.23528325076709017 | validation: 0.1635602081676824]
	TIME [epoch: 8.56 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34947649478344156		[learning rate: 0.0042108]
	Learning Rate: 0.00421084
	LOSS [training: 0.34947649478344156 | validation: 0.3453293317609634]
	TIME [epoch: 8.53 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3804820553848396		[learning rate: 0.0041956]
	Learning Rate: 0.00419556
	LOSS [training: 0.3804820553848396 | validation: 0.3218383288738705]
	TIME [epoch: 8.53 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34733866229642774		[learning rate: 0.0041803]
	Learning Rate: 0.00418033
	LOSS [training: 0.34733866229642774 | validation: 0.2829819126404409]
	TIME [epoch: 8.53 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3665113837209073		[learning rate: 0.0041652]
	Learning Rate: 0.00416516
	LOSS [training: 0.3665113837209073 | validation: 0.24878134980316247]
	TIME [epoch: 8.56 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2682072558556671		[learning rate: 0.00415]
	Learning Rate: 0.00415004
	LOSS [training: 0.2682072558556671 | validation: 0.2954884438682097]
	TIME [epoch: 8.53 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33801793739959435		[learning rate: 0.004135]
	Learning Rate: 0.00413498
	LOSS [training: 0.33801793739959435 | validation: 0.6663316819110917]
	TIME [epoch: 8.53 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4517104801598427		[learning rate: 0.00412]
	Learning Rate: 0.00411998
	LOSS [training: 0.4517104801598427 | validation: 0.548795849742683]
	TIME [epoch: 8.53 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3036669490773807		[learning rate: 0.004105]
	Learning Rate: 0.00410502
	LOSS [training: 0.3036669490773807 | validation: 0.5893038185601052]
	TIME [epoch: 8.56 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5176064864851223		[learning rate: 0.0040901]
	Learning Rate: 0.00409013
	LOSS [training: 0.5176064864851223 | validation: 0.5553212597357142]
	TIME [epoch: 8.54 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3459016113177405		[learning rate: 0.0040753]
	Learning Rate: 0.00407528
	LOSS [training: 0.3459016113177405 | validation: 0.19946922931416983]
	TIME [epoch: 8.53 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2475957397686286		[learning rate: 0.0040605]
	Learning Rate: 0.00406049
	LOSS [training: 0.2475957397686286 | validation: 0.2557315453423402]
	TIME [epoch: 8.54 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25789900838337043		[learning rate: 0.0040458]
	Learning Rate: 0.00404576
	LOSS [training: 0.25789900838337043 | validation: 0.2606959510965133]
	TIME [epoch: 8.54 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30439374743666814		[learning rate: 0.0040311]
	Learning Rate: 0.00403108
	LOSS [training: 0.30439374743666814 | validation: 0.2826984743890493]
	TIME [epoch: 8.56 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3556211012694227		[learning rate: 0.0040164]
	Learning Rate: 0.00401645
	LOSS [training: 0.3556211012694227 | validation: 0.4419127102623181]
	TIME [epoch: 8.54 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2903792534702879		[learning rate: 0.0040019]
	Learning Rate: 0.00400187
	LOSS [training: 0.2903792534702879 | validation: 0.2674811361552104]
	TIME [epoch: 8.53 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31800377567136373		[learning rate: 0.0039873]
	Learning Rate: 0.00398735
	LOSS [training: 0.31800377567136373 | validation: 0.4219874355125195]
	TIME [epoch: 8.54 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45014391475349375		[learning rate: 0.0039729]
	Learning Rate: 0.00397288
	LOSS [training: 0.45014391475349375 | validation: 0.5879002533142892]
	TIME [epoch: 8.56 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34225508266064214		[learning rate: 0.0039585]
	Learning Rate: 0.00395846
	LOSS [training: 0.34225508266064214 | validation: 0.2731922913279392]
	TIME [epoch: 8.54 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24119485149588402		[learning rate: 0.0039441]
	Learning Rate: 0.00394409
	LOSS [training: 0.24119485149588402 | validation: 0.4744802420186664]
	TIME [epoch: 8.54 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2520346018753681		[learning rate: 0.0039298]
	Learning Rate: 0.00392978
	LOSS [training: 0.2520346018753681 | validation: 0.3460572697874368]
	TIME [epoch: 8.53 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2591051191143649		[learning rate: 0.0039155]
	Learning Rate: 0.00391552
	LOSS [training: 0.2591051191143649 | validation: 0.920279394368441]
	TIME [epoch: 8.56 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43497208540375604		[learning rate: 0.0039013]
	Learning Rate: 0.00390131
	LOSS [training: 0.43497208540375604 | validation: 0.15915392601461198]
	TIME [epoch: 8.53 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23686280449904862		[learning rate: 0.0038872]
	Learning Rate: 0.00388715
	LOSS [training: 0.23686280449904862 | validation: 0.7076060625847205]
	TIME [epoch: 8.54 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37127818420334496		[learning rate: 0.003873]
	Learning Rate: 0.00387305
	LOSS [training: 0.37127818420334496 | validation: 0.8404536890874195]
	TIME [epoch: 8.53 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3477620334435687		[learning rate: 0.003859]
	Learning Rate: 0.00385899
	LOSS [training: 0.3477620334435687 | validation: 0.1862805247719522]
	TIME [epoch: 8.56 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21229913733145897		[learning rate: 0.003845]
	Learning Rate: 0.00384499
	LOSS [training: 0.21229913733145897 | validation: 0.17363348309748922]
	TIME [epoch: 8.53 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37097314430477213		[learning rate: 0.003831]
	Learning Rate: 0.00383103
	LOSS [training: 0.37097314430477213 | validation: 0.20618075938885333]
	TIME [epoch: 8.53 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28097938517457294		[learning rate: 0.0038171]
	Learning Rate: 0.00381713
	LOSS [training: 0.28097938517457294 | validation: 0.7935670721829293]
	TIME [epoch: 8.53 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42428383570157163		[learning rate: 0.0038033]
	Learning Rate: 0.00380328
	LOSS [training: 0.42428383570157163 | validation: 0.49443566342965495]
	TIME [epoch: 8.54 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26591887967393374		[learning rate: 0.0037895]
	Learning Rate: 0.00378947
	LOSS [training: 0.26591887967393374 | validation: 0.18029861199431074]
	TIME [epoch: 8.56 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2523006763110388		[learning rate: 0.0037757]
	Learning Rate: 0.00377572
	LOSS [training: 0.2523006763110388 | validation: 0.29925891147585554]
	TIME [epoch: 8.53 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34668434931250786		[learning rate: 0.003762]
	Learning Rate: 0.00376202
	LOSS [training: 0.34668434931250786 | validation: 0.23441870199122294]
	TIME [epoch: 8.53 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2789516411403577		[learning rate: 0.0037484]
	Learning Rate: 0.00374837
	LOSS [training: 0.2789516411403577 | validation: 0.3172196901044758]
	TIME [epoch: 8.53 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2829012908819738		[learning rate: 0.0037348]
	Learning Rate: 0.00373476
	LOSS [training: 0.2829012908819738 | validation: 0.47268544813516117]
	TIME [epoch: 8.55 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36007070051280265		[learning rate: 0.0037212]
	Learning Rate: 0.00372121
	LOSS [training: 0.36007070051280265 | validation: 0.20323768911542595]
	TIME [epoch: 8.53 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33482988913377143		[learning rate: 0.0037077]
	Learning Rate: 0.00370771
	LOSS [training: 0.33482988913377143 | validation: 0.4016248824033734]
	TIME [epoch: 8.53 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29844063231089046		[learning rate: 0.0036943]
	Learning Rate: 0.00369425
	LOSS [training: 0.29844063231089046 | validation: 0.36678301976044425]
	TIME [epoch: 8.53 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3135522135082746		[learning rate: 0.0036808]
	Learning Rate: 0.00368084
	LOSS [training: 0.3135522135082746 | validation: 0.3349348963367709]
	TIME [epoch: 8.55 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2505194612626481		[learning rate: 0.0036675]
	Learning Rate: 0.00366749
	LOSS [training: 0.2505194612626481 | validation: 0.27082168654291927]
	TIME [epoch: 8.53 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2993868226045602		[learning rate: 0.0036542]
	Learning Rate: 0.00365418
	LOSS [training: 0.2993868226045602 | validation: 0.3549322297986882]
	TIME [epoch: 8.53 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25223984018234397		[learning rate: 0.0036409]
	Learning Rate: 0.00364092
	LOSS [training: 0.25223984018234397 | validation: 0.5662324248160682]
	TIME [epoch: 8.53 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.284353222995566		[learning rate: 0.0036277]
	Learning Rate: 0.0036277
	LOSS [training: 0.284353222995566 | validation: 0.265993723863452]
	TIME [epoch: 8.55 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23139496335528859		[learning rate: 0.0036145]
	Learning Rate: 0.00361454
	LOSS [training: 0.23139496335528859 | validation: 0.24269394659238874]
	TIME [epoch: 8.53 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2860061384180149		[learning rate: 0.0036014]
	Learning Rate: 0.00360142
	LOSS [training: 0.2860061384180149 | validation: 0.42628102399232]
	TIME [epoch: 8.53 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31920984728074586		[learning rate: 0.0035883]
	Learning Rate: 0.00358835
	LOSS [training: 0.31920984728074586 | validation: 0.6292534896439642]
	TIME [epoch: 8.53 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3520732545461055		[learning rate: 0.0035753]
	Learning Rate: 0.00357533
	LOSS [training: 0.3520732545461055 | validation: 0.46367509385485994]
	TIME [epoch: 8.53 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2244346845329636		[learning rate: 0.0035624]
	Learning Rate: 0.00356235
	LOSS [training: 0.2244346845329636 | validation: 0.2145459332916739]
	TIME [epoch: 8.55 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2555437708396221		[learning rate: 0.0035494]
	Learning Rate: 0.00354942
	LOSS [training: 0.2555437708396221 | validation: 0.3401265081209148]
	TIME [epoch: 8.53 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3402912393282912		[learning rate: 0.0035365]
	Learning Rate: 0.00353654
	LOSS [training: 0.3402912393282912 | validation: 0.20583839060959247]
	TIME [epoch: 8.53 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2950641123465395		[learning rate: 0.0035237]
	Learning Rate: 0.00352371
	LOSS [training: 0.2950641123465395 | validation: 0.20973922680452434]
	TIME [epoch: 8.53 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25404378359233065		[learning rate: 0.0035109]
	Learning Rate: 0.00351092
	LOSS [training: 0.25404378359233065 | validation: 0.25108382953687797]
	TIME [epoch: 8.56 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21540389397070686		[learning rate: 0.0034982]
	Learning Rate: 0.00349818
	LOSS [training: 0.21540389397070686 | validation: 0.23148672737770667]
	TIME [epoch: 8.53 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2313659882941279		[learning rate: 0.0034855]
	Learning Rate: 0.00348548
	LOSS [training: 0.2313659882941279 | validation: 0.1307547731321706]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_390.pth
	Model improved!!!
EPOCH 391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27162482545544225		[learning rate: 0.0034728]
	Learning Rate: 0.00347284
	LOSS [training: 0.27162482545544225 | validation: 0.24231434683250969]
	TIME [epoch: 8.53 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38774809432708607		[learning rate: 0.0034602]
	Learning Rate: 0.00346023
	LOSS [training: 0.38774809432708607 | validation: 0.1220780860719738]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_392.pth
	Model improved!!!
EPOCH 393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3136318082035583		[learning rate: 0.0034477]
	Learning Rate: 0.00344767
	LOSS [training: 0.3136318082035583 | validation: 0.3297717227682203]
	TIME [epoch: 8.53 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34976378023878807		[learning rate: 0.0034352]
	Learning Rate: 0.00343516
	LOSS [training: 0.34976378023878807 | validation: 0.32464335804281874]
	TIME [epoch: 8.52 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3452168309749025		[learning rate: 0.0034227]
	Learning Rate: 0.0034227
	LOSS [training: 0.3452168309749025 | validation: 0.258560695387083]
	TIME [epoch: 8.52 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2727682557889686		[learning rate: 0.0034103]
	Learning Rate: 0.00341028
	LOSS [training: 0.2727682557889686 | validation: 0.18572661511855929]
	TIME [epoch: 8.55 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3825352779410976		[learning rate: 0.0033979]
	Learning Rate: 0.0033979
	LOSS [training: 0.3825352779410976 | validation: 0.19149206581508485]
	TIME [epoch: 8.53 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22265836239765607		[learning rate: 0.0033856]
	Learning Rate: 0.00338557
	LOSS [training: 0.22265836239765607 | validation: 0.22010862780129467]
	TIME [epoch: 8.52 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25407232346506986		[learning rate: 0.0033733]
	Learning Rate: 0.00337328
	LOSS [training: 0.25407232346506986 | validation: 0.3798820214314557]
	TIME [epoch: 8.52 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3498488672733298		[learning rate: 0.003361]
	Learning Rate: 0.00336104
	LOSS [training: 0.3498488672733298 | validation: 0.2992289137553844]
	TIME [epoch: 8.55 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24109987310561926		[learning rate: 0.0033488]
	Learning Rate: 0.00334884
	LOSS [training: 0.24109987310561926 | validation: 0.4024726798842311]
	TIME [epoch: 8.53 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6055665655636868		[learning rate: 0.0033367]
	Learning Rate: 0.00333669
	LOSS [training: 0.6055665655636868 | validation: 0.511104815142652]
	TIME [epoch: 8.53 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23403104725029253		[learning rate: 0.0033246]
	Learning Rate: 0.00332458
	LOSS [training: 0.23403104725029253 | validation: 0.17546830345771752]
	TIME [epoch: 8.52 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2514969113873413		[learning rate: 0.0033125]
	Learning Rate: 0.00331252
	LOSS [training: 0.2514969113873413 | validation: 0.4466747180630655]
	TIME [epoch: 8.53 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4241997808123446		[learning rate: 0.0033005]
	Learning Rate: 0.00330049
	LOSS [training: 0.4241997808123446 | validation: 0.3127824961554629]
	TIME [epoch: 8.54 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31729094345266506		[learning rate: 0.0032885]
	Learning Rate: 0.00328852
	LOSS [training: 0.31729094345266506 | validation: 0.28211797595115984]
	TIME [epoch: 8.52 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.216869567357809		[learning rate: 0.0032766]
	Learning Rate: 0.00327658
	LOSS [training: 0.216869567357809 | validation: 0.31789280493184513]
	TIME [epoch: 8.53 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25350762038601843		[learning rate: 0.0032647]
	Learning Rate: 0.00326469
	LOSS [training: 0.25350762038601843 | validation: 0.24584354482096618]
	TIME [epoch: 8.52 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2540828580624662		[learning rate: 0.0032528]
	Learning Rate: 0.00325284
	LOSS [training: 0.2540828580624662 | validation: 0.5246283218811604]
	TIME [epoch: 8.55 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2753519639895681		[learning rate: 0.003241]
	Learning Rate: 0.00324104
	LOSS [training: 0.2753519639895681 | validation: 0.26512433485512343]
	TIME [epoch: 8.53 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3289585523058774		[learning rate: 0.0032293]
	Learning Rate: 0.00322928
	LOSS [training: 0.3289585523058774 | validation: 0.23307897538104333]
	TIME [epoch: 8.53 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2467100919687813		[learning rate: 0.0032176]
	Learning Rate: 0.00321756
	LOSS [training: 0.2467100919687813 | validation: 0.16490926940607525]
	TIME [epoch: 8.52 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22585979563690342		[learning rate: 0.0032059]
	Learning Rate: 0.00320588
	LOSS [training: 0.22585979563690342 | validation: 0.1527878883211761]
	TIME [epoch: 8.55 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3585036544622168		[learning rate: 0.0031942]
	Learning Rate: 0.00319425
	LOSS [training: 0.3585036544622168 | validation: 0.4618138927859521]
	TIME [epoch: 8.52 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.336507618336224		[learning rate: 0.0031827]
	Learning Rate: 0.00318265
	LOSS [training: 0.336507618336224 | validation: 0.15021274467978726]
	TIME [epoch: 8.52 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.314290799484067		[learning rate: 0.0031711]
	Learning Rate: 0.0031711
	LOSS [training: 0.314290799484067 | validation: 0.27247381698919465]
	TIME [epoch: 8.52 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35727960675769393		[learning rate: 0.0031596]
	Learning Rate: 0.0031596
	LOSS [training: 0.35727960675769393 | validation: 0.45053705000347444]
	TIME [epoch: 8.55 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24905686758760984		[learning rate: 0.0031481]
	Learning Rate: 0.00314813
	LOSS [training: 0.24905686758760984 | validation: 0.245404944553259]
	TIME [epoch: 8.54 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2154882786896895		[learning rate: 0.0031367]
	Learning Rate: 0.00313671
	LOSS [training: 0.2154882786896895 | validation: 0.2311986003103404]
	TIME [epoch: 8.52 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25278107691758456		[learning rate: 0.0031253]
	Learning Rate: 0.00312532
	LOSS [training: 0.25278107691758456 | validation: 0.2275911957820366]
	TIME [epoch: 8.53 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23329053793264493		[learning rate: 0.003114]
	Learning Rate: 0.00311398
	LOSS [training: 0.23329053793264493 | validation: 0.17715567613983318]
	TIME [epoch: 8.53 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29012020932141913		[learning rate: 0.0031027]
	Learning Rate: 0.00310268
	LOSS [training: 0.29012020932141913 | validation: 0.5004811149586469]
	TIME [epoch: 8.55 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2401984332482514		[learning rate: 0.0030914]
	Learning Rate: 0.00309142
	LOSS [training: 0.2401984332482514 | validation: 0.21780356371180526]
	TIME [epoch: 8.53 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2306801894245452		[learning rate: 0.0030802]
	Learning Rate: 0.0030802
	LOSS [training: 0.2306801894245452 | validation: 0.40720708569568387]
	TIME [epoch: 8.53 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25496014337539175		[learning rate: 0.003069]
	Learning Rate: 0.00306902
	LOSS [training: 0.25496014337539175 | validation: 0.37681615407139]
	TIME [epoch: 8.52 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2545264943526933		[learning rate: 0.0030579]
	Learning Rate: 0.00305788
	LOSS [training: 0.2545264943526933 | validation: 0.3813092150888251]
	TIME [epoch: 8.55 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25816074910307873		[learning rate: 0.0030468]
	Learning Rate: 0.00304679
	LOSS [training: 0.25816074910307873 | validation: 0.2613158925848229]
	TIME [epoch: 8.54 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45487566017048586		[learning rate: 0.0030357]
	Learning Rate: 0.00303573
	LOSS [training: 0.45487566017048586 | validation: 0.4303213918051534]
	TIME [epoch: 8.53 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22885283780858331		[learning rate: 0.0030247]
	Learning Rate: 0.00302471
	LOSS [training: 0.22885283780858331 | validation: 0.2952939673821127]
	TIME [epoch: 8.53 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23250074151664588		[learning rate: 0.0030137]
	Learning Rate: 0.00301374
	LOSS [training: 0.23250074151664588 | validation: 0.24224848529706428]
	TIME [epoch: 8.56 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33868148345480614		[learning rate: 0.0030028]
	Learning Rate: 0.0030028
	LOSS [training: 0.33868148345480614 | validation: 0.5512867826164185]
	TIME [epoch: 8.53 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22887937467676228		[learning rate: 0.0029919]
	Learning Rate: 0.0029919
	LOSS [training: 0.22887937467676228 | validation: 0.20538108136875313]
	TIME [epoch: 8.53 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33121548838733883		[learning rate: 0.002981]
	Learning Rate: 0.00298104
	LOSS [training: 0.33121548838733883 | validation: 0.5757400162436099]
	TIME [epoch: 8.53 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2385384847851538		[learning rate: 0.0029702]
	Learning Rate: 0.00297023
	LOSS [training: 0.2385384847851538 | validation: 0.16255207011015804]
	TIME [epoch: 8.56 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44555739924604537		[learning rate: 0.0029594]
	Learning Rate: 0.00295945
	LOSS [training: 0.44555739924604537 | validation: 0.27664947948142943]
	TIME [epoch: 8.53 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2503792769384373		[learning rate: 0.0029487]
	Learning Rate: 0.00294871
	LOSS [training: 0.2503792769384373 | validation: 0.23714310709711878]
	TIME [epoch: 8.53 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3038354993162337		[learning rate: 0.002938]
	Learning Rate: 0.00293801
	LOSS [training: 0.3038354993162337 | validation: 0.29740165419779546]
	TIME [epoch: 8.54 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23759763609435466		[learning rate: 0.0029273]
	Learning Rate: 0.00292734
	LOSS [training: 0.23759763609435466 | validation: 0.5394039478253339]
	TIME [epoch: 8.54 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2226995095847944		[learning rate: 0.0029167]
	Learning Rate: 0.00291672
	LOSS [training: 0.2226995095847944 | validation: 0.2408897833459795]
	TIME [epoch: 8.55 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24306311866051758		[learning rate: 0.0029061]
	Learning Rate: 0.00290614
	LOSS [training: 0.24306311866051758 | validation: 0.25654444623939426]
	TIME [epoch: 8.53 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31694078682258625		[learning rate: 0.0028956]
	Learning Rate: 0.00289559
	LOSS [training: 0.31694078682258625 | validation: 0.14313742592281853]
	TIME [epoch: 8.52 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32193992626792667		[learning rate: 0.0028851]
	Learning Rate: 0.00288508
	LOSS [training: 0.32193992626792667 | validation: 0.19247671563951055]
	TIME [epoch: 8.54 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3229057150772777		[learning rate: 0.0028746]
	Learning Rate: 0.00287461
	LOSS [training: 0.3229057150772777 | validation: 0.6152878633525733]
	TIME [epoch: 8.55 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23215615849336477		[learning rate: 0.0028642]
	Learning Rate: 0.00286418
	LOSS [training: 0.23215615849336477 | validation: 0.6895396900502695]
	TIME [epoch: 8.53 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4816802064871076		[learning rate: 0.0028538]
	Learning Rate: 0.00285378
	LOSS [training: 0.4816802064871076 | validation: 0.26052289411047197]
	TIME [epoch: 8.54 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20576556236404295		[learning rate: 0.0028434]
	Learning Rate: 0.00284343
	LOSS [training: 0.20576556236404295 | validation: 0.20571981261811284]
	TIME [epoch: 8.53 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3191767296899158		[learning rate: 0.0028331]
	Learning Rate: 0.00283311
	LOSS [training: 0.3191767296899158 | validation: 0.30259306513291134]
	TIME [epoch: 8.56 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2708714120073095		[learning rate: 0.0028228]
	Learning Rate: 0.00282283
	LOSS [training: 0.2708714120073095 | validation: 0.22537830287632044]
	TIME [epoch: 8.54 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17976508107956526		[learning rate: 0.0028126]
	Learning Rate: 0.00281258
	LOSS [training: 0.17976508107956526 | validation: 0.14334500986648221]
	TIME [epoch: 8.53 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42789497760283196		[learning rate: 0.0028024]
	Learning Rate: 0.00280238
	LOSS [training: 0.42789497760283196 | validation: 0.18330621119274682]
	TIME [epoch: 8.56 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36838539061706005		[learning rate: 0.0027922]
	Learning Rate: 0.00279221
	LOSS [training: 0.36838539061706005 | validation: 0.18842007305357975]
	TIME [epoch: 8.55 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21033099713625486		[learning rate: 0.0027821]
	Learning Rate: 0.00278207
	LOSS [training: 0.21033099713625486 | validation: 0.32820253635209473]
	TIME [epoch: 8.54 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2600234670426572		[learning rate: 0.002772]
	Learning Rate: 0.00277198
	LOSS [training: 0.2600234670426572 | validation: 0.16232766254624126]
	TIME [epoch: 8.53 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19508317111064893		[learning rate: 0.0027619]
	Learning Rate: 0.00276192
	LOSS [training: 0.19508317111064893 | validation: 0.3596027806034905]
	TIME [epoch: 8.53 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24193211133781906		[learning rate: 0.0027519]
	Learning Rate: 0.00275189
	LOSS [training: 0.24193211133781906 | validation: 0.31567940396039873]
	TIME [epoch: 8.53 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21174460177412882		[learning rate: 0.0027419]
	Learning Rate: 0.00274191
	LOSS [training: 0.21174460177412882 | validation: 0.1709792437796372]
	TIME [epoch: 8.54 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21974048004114377		[learning rate: 0.002732]
	Learning Rate: 0.00273196
	LOSS [training: 0.21974048004114377 | validation: 0.18090449318113738]
	TIME [epoch: 8.53 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3685520291982895		[learning rate: 0.002722]
	Learning Rate: 0.00272204
	LOSS [training: 0.3685520291982895 | validation: 0.24804777274332077]
	TIME [epoch: 8.52 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24449107454018576		[learning rate: 0.0027122]
	Learning Rate: 0.00271216
	LOSS [training: 0.24449107454018576 | validation: 0.2653038843686627]
	TIME [epoch: 8.52 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2761879288255912		[learning rate: 0.0027023]
	Learning Rate: 0.00270232
	LOSS [training: 0.2761879288255912 | validation: 0.29436171976466285]
	TIME [epoch: 8.56 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2279251307131705		[learning rate: 0.0026925]
	Learning Rate: 0.00269251
	LOSS [training: 0.2279251307131705 | validation: 0.3386536450362161]
	TIME [epoch: 8.53 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2883769352048355		[learning rate: 0.0026827]
	Learning Rate: 0.00268274
	LOSS [training: 0.2883769352048355 | validation: 0.2520420198822993]
	TIME [epoch: 8.53 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2501147925470085		[learning rate: 0.002673]
	Learning Rate: 0.00267301
	LOSS [training: 0.2501147925470085 | validation: 0.2832150252144583]
	TIME [epoch: 8.53 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2375218254808376		[learning rate: 0.0026633]
	Learning Rate: 0.00266331
	LOSS [training: 0.2375218254808376 | validation: 0.1540058128740407]
	TIME [epoch: 8.55 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28216349923234574		[learning rate: 0.0026536]
	Learning Rate: 0.00265364
	LOSS [training: 0.28216349923234574 | validation: 0.28143463493941917]
	TIME [epoch: 8.52 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19612102073812987		[learning rate: 0.002644]
	Learning Rate: 0.00264401
	LOSS [training: 0.19612102073812987 | validation: 0.2704090339953915]
	TIME [epoch: 8.53 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46617002169557364		[learning rate: 0.0026344]
	Learning Rate: 0.00263441
	LOSS [training: 0.46617002169557364 | validation: 0.2050659112975738]
	TIME [epoch: 8.53 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2819014416690421		[learning rate: 0.0026249]
	Learning Rate: 0.00262485
	LOSS [training: 0.2819014416690421 | validation: 0.2801510919558382]
	TIME [epoch: 8.55 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3340337736862066		[learning rate: 0.0026153]
	Learning Rate: 0.00261533
	LOSS [training: 0.3340337736862066 | validation: 0.5155150503508235]
	TIME [epoch: 8.53 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30402840006926446		[learning rate: 0.0026058]
	Learning Rate: 0.00260584
	LOSS [training: 0.30402840006926446 | validation: 0.3011757473096148]
	TIME [epoch: 8.53 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24528639274268288		[learning rate: 0.0025964]
	Learning Rate: 0.00259638
	LOSS [training: 0.24528639274268288 | validation: 0.2858739241650088]
	TIME [epoch: 8.52 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2174457388080843		[learning rate: 0.002587]
	Learning Rate: 0.00258696
	LOSS [training: 0.2174457388080843 | validation: 0.46555038044706365]
	TIME [epoch: 8.53 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27579007650346415		[learning rate: 0.0025776]
	Learning Rate: 0.00257757
	LOSS [training: 0.27579007650346415 | validation: 0.22068019871773695]
	TIME [epoch: 8.53 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18730824044685207		[learning rate: 0.0025682]
	Learning Rate: 0.00256822
	LOSS [training: 0.18730824044685207 | validation: 0.4513355011465343]
	TIME [epoch: 8.52 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2054238063467729		[learning rate: 0.0025589]
	Learning Rate: 0.0025589
	LOSS [training: 0.2054238063467729 | validation: 0.2354515024116513]
	TIME [epoch: 8.52 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2412930825356751		[learning rate: 0.0025496]
	Learning Rate: 0.00254961
	LOSS [training: 0.2412930825356751 | validation: 0.3124867265278023]
	TIME [epoch: 8.53 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2926121789198278		[learning rate: 0.0025404]
	Learning Rate: 0.00254036
	LOSS [training: 0.2926121789198278 | validation: 0.26566154722751734]
	TIME [epoch: 8.55 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19526753745019504		[learning rate: 0.0025311]
	Learning Rate: 0.00253114
	LOSS [training: 0.19526753745019504 | validation: 0.32053504385857123]
	TIME [epoch: 8.53 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2361515322457211		[learning rate: 0.002522]
	Learning Rate: 0.00252195
	LOSS [training: 0.2361515322457211 | validation: 0.2665826438936118]
	TIME [epoch: 8.53 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2339689678025668		[learning rate: 0.0025128]
	Learning Rate: 0.0025128
	LOSS [training: 0.2339689678025668 | validation: 0.6230925405048892]
	TIME [epoch: 8.54 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32031870343473207		[learning rate: 0.0025037]
	Learning Rate: 0.00250368
	LOSS [training: 0.32031870343473207 | validation: 0.22121348335574725]
	TIME [epoch: 8.55 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2529553981939712		[learning rate: 0.0024946]
	Learning Rate: 0.00249459
	LOSS [training: 0.2529553981939712 | validation: 0.20104872193321416]
	TIME [epoch: 8.52 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2597993553818113		[learning rate: 0.0024855]
	Learning Rate: 0.00248554
	LOSS [training: 0.2597993553818113 | validation: 0.20472087299607317]
	TIME [epoch: 8.52 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23419469901993453		[learning rate: 0.0024765]
	Learning Rate: 0.00247652
	LOSS [training: 0.23419469901993453 | validation: 0.20619528478249854]
	TIME [epoch: 8.53 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20769808413202506		[learning rate: 0.0024675]
	Learning Rate: 0.00246753
	LOSS [training: 0.20769808413202506 | validation: 0.15458845569285756]
	TIME [epoch: 8.55 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22042664512109175		[learning rate: 0.0024586]
	Learning Rate: 0.00245858
	LOSS [training: 0.22042664512109175 | validation: 0.24515966970018077]
	TIME [epoch: 8.53 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31216529703680523		[learning rate: 0.0024497]
	Learning Rate: 0.00244966
	LOSS [training: 0.31216529703680523 | validation: 0.3900465040838027]
	TIME [epoch: 8.52 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2274001043165858		[learning rate: 0.0024408]
	Learning Rate: 0.00244077
	LOSS [training: 0.2274001043165858 | validation: 0.17320380111528555]
	TIME [epoch: 8.52 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2140150624684672		[learning rate: 0.0024319]
	Learning Rate: 0.00243191
	LOSS [training: 0.2140150624684672 | validation: 0.3379529414820729]
	TIME [epoch: 8.54 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34009114469056845		[learning rate: 0.0024231]
	Learning Rate: 0.00242308
	LOSS [training: 0.34009114469056845 | validation: 0.36067952485829236]
	TIME [epoch: 8.54 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16551053713048425		[learning rate: 0.0024143]
	Learning Rate: 0.00241429
	LOSS [training: 0.16551053713048425 | validation: 0.19025842895162992]
	TIME [epoch: 8.52 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2374673028490144		[learning rate: 0.0024055]
	Learning Rate: 0.00240553
	LOSS [training: 0.2374673028490144 | validation: 0.408982050949208]
	TIME [epoch: 8.53 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24365218576144612		[learning rate: 0.0023968]
	Learning Rate: 0.0023968
	LOSS [training: 0.24365218576144612 | validation: 0.5240967468359896]
	TIME [epoch: 8.53 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4751443282228983		[learning rate: 0.0023881]
	Learning Rate: 0.0023881
	LOSS [training: 0.4751443282228983 | validation: 0.18786774326233868]
	TIME [epoch: 8.55 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27082283680685626		[learning rate: 0.0023794]
	Learning Rate: 0.00237943
	LOSS [training: 0.27082283680685626 | validation: 0.17632941629204513]
	TIME [epoch: 8.54 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29921309324173384		[learning rate: 0.0023708]
	Learning Rate: 0.0023708
	LOSS [training: 0.29921309324173384 | validation: 0.3259720304525404]
	TIME [epoch: 8.52 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.191241462988513		[learning rate: 0.0023622]
	Learning Rate: 0.0023622
	LOSS [training: 0.191241462988513 | validation: 0.46712486322685565]
	TIME [epoch: 8.52 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17816008981123196		[learning rate: 0.0023536]
	Learning Rate: 0.00235362
	LOSS [training: 0.17816008981123196 | validation: 0.3279892910467957]
	TIME [epoch: 8.55 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2982670111284358		[learning rate: 0.0023451]
	Learning Rate: 0.00234508
	LOSS [training: 0.2982670111284358 | validation: 0.1921689124856537]
	TIME [epoch: 8.53 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2566666558957797		[learning rate: 0.0023366]
	Learning Rate: 0.00233657
	LOSS [training: 0.2566666558957797 | validation: 0.3025052835680372]
	TIME [epoch: 8.51 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20894270794264375		[learning rate: 0.0023281]
	Learning Rate: 0.00232809
	LOSS [training: 0.20894270794264375 | validation: 0.23192395103803948]
	TIME [epoch: 8.51 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6924150534761868		[learning rate: 0.0023196]
	Learning Rate: 0.00231964
	LOSS [training: 0.6924150534761868 | validation: 0.26314042962303974]
	TIME [epoch: 8.55 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19593583085568994		[learning rate: 0.0023112]
	Learning Rate: 0.00231122
	LOSS [training: 0.19593583085568994 | validation: 0.24786019654420588]
	TIME [epoch: 8.55 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24454703926781013		[learning rate: 0.0023028]
	Learning Rate: 0.00230284
	LOSS [training: 0.24454703926781013 | validation: 0.16027255386532602]
	TIME [epoch: 8.53 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2513510836738523		[learning rate: 0.0022945]
	Learning Rate: 0.00229448
	LOSS [training: 0.2513510836738523 | validation: 0.20103299113880724]
	TIME [epoch: 8.53 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1647961498481156		[learning rate: 0.0022862]
	Learning Rate: 0.00228615
	LOSS [training: 0.1647961498481156 | validation: 0.21599406870263843]
	TIME [epoch: 8.54 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20066426471663307		[learning rate: 0.0022779]
	Learning Rate: 0.00227786
	LOSS [training: 0.20066426471663307 | validation: 0.3323301139812634]
	TIME [epoch: 8.53 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4819907236243732		[learning rate: 0.0022696]
	Learning Rate: 0.00226959
	LOSS [training: 0.4819907236243732 | validation: 0.2567438480571409]
	TIME [epoch: 8.53 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2072555086932515		[learning rate: 0.0022614]
	Learning Rate: 0.00226135
	LOSS [training: 0.2072555086932515 | validation: 0.16719161442618927]
	TIME [epoch: 8.52 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25734030228256055		[learning rate: 0.0022531]
	Learning Rate: 0.00225315
	LOSS [training: 0.25734030228256055 | validation: 0.22950057081802205]
	TIME [epoch: 8.53 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34088236932653315		[learning rate: 0.002245]
	Learning Rate: 0.00224497
	LOSS [training: 0.34088236932653315 | validation: 0.2345711186255215]
	TIME [epoch: 8.54 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2472891856311105		[learning rate: 0.0022368]
	Learning Rate: 0.00223682
	LOSS [training: 0.2472891856311105 | validation: 0.1998533885490822]
	TIME [epoch: 8.53 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31110754615013614		[learning rate: 0.0022287]
	Learning Rate: 0.00222871
	LOSS [training: 0.31110754615013614 | validation: 0.513334027068361]
	TIME [epoch: 8.52 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24685383403386751		[learning rate: 0.0022206]
	Learning Rate: 0.00222062
	LOSS [training: 0.24685383403386751 | validation: 0.2967548514475918]
	TIME [epoch: 8.52 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2507224390483035		[learning rate: 0.0022126]
	Learning Rate: 0.00221256
	LOSS [training: 0.2507224390483035 | validation: 0.3592890147572583]
	TIME [epoch: 8.54 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22548094972338287		[learning rate: 0.0022045]
	Learning Rate: 0.00220453
	LOSS [training: 0.22548094972338287 | validation: 0.20673490836149788]
	TIME [epoch: 8.52 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24589602598786248		[learning rate: 0.0021965]
	Learning Rate: 0.00219653
	LOSS [training: 0.24589602598786248 | validation: 0.25833982956826207]
	TIME [epoch: 8.5 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20394190252676273		[learning rate: 0.0021886]
	Learning Rate: 0.00218856
	LOSS [training: 0.20394190252676273 | validation: 0.43442307793142076]
	TIME [epoch: 8.52 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48737791435921923		[learning rate: 0.0021806]
	Learning Rate: 0.00218061
	LOSS [training: 0.48737791435921923 | validation: 0.13415136887539722]
	TIME [epoch: 8.54 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4637817409507027		[learning rate: 0.0021727]
	Learning Rate: 0.0021727
	LOSS [training: 0.4637817409507027 | validation: 0.2519994008551154]
	TIME [epoch: 8.51 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19772917066074694		[learning rate: 0.0021648]
	Learning Rate: 0.00216482
	LOSS [training: 0.19772917066074694 | validation: 0.2599386354831772]
	TIME [epoch: 8.52 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20949427804503382		[learning rate: 0.002157]
	Learning Rate: 0.00215696
	LOSS [training: 0.20949427804503382 | validation: 0.14563460890923327]
	TIME [epoch: 8.52 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2291790195547463		[learning rate: 0.0021491]
	Learning Rate: 0.00214913
	LOSS [training: 0.2291790195547463 | validation: 0.33834426338600204]
	TIME [epoch: 8.54 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2331195662282192		[learning rate: 0.0021413]
	Learning Rate: 0.00214133
	LOSS [training: 0.2331195662282192 | validation: 0.44560510915641605]
	TIME [epoch: 8.53 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2666558782195896		[learning rate: 0.0021336]
	Learning Rate: 0.00213356
	LOSS [training: 0.2666558782195896 | validation: 0.30480469533927607]
	TIME [epoch: 8.52 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2158148633956099		[learning rate: 0.0021258]
	Learning Rate: 0.00212582
	LOSS [training: 0.2158148633956099 | validation: 0.13944086541921402]
	TIME [epoch: 8.52 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25680647205022716		[learning rate: 0.0021181]
	Learning Rate: 0.0021181
	LOSS [training: 0.25680647205022716 | validation: 0.3690322344880755]
	TIME [epoch: 8.51 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23543826175472832		[learning rate: 0.0021104]
	Learning Rate: 0.00211042
	LOSS [training: 0.23543826175472832 | validation: 0.17491474924232306]
	TIME [epoch: 8.54 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4187401248716499		[learning rate: 0.0021028]
	Learning Rate: 0.00210276
	LOSS [training: 0.4187401248716499 | validation: 0.3844475946638515]
	TIME [epoch: 8.51 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22598452408917108		[learning rate: 0.0020951]
	Learning Rate: 0.00209513
	LOSS [training: 0.22598452408917108 | validation: 0.20132312127284802]
	TIME [epoch: 8.51 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18961366211294797		[learning rate: 0.0020875]
	Learning Rate: 0.00208752
	LOSS [training: 0.18961366211294797 | validation: 0.2629963840309093]
	TIME [epoch: 8.51 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27082608471218306		[learning rate: 0.0020799]
	Learning Rate: 0.00207995
	LOSS [training: 0.27082608471218306 | validation: 0.20727689254944093]
	TIME [epoch: 8.54 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24639511429417352		[learning rate: 0.0020724]
	Learning Rate: 0.0020724
	LOSS [training: 0.24639511429417352 | validation: 0.24158247918227693]
	TIME [epoch: 8.52 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2192539164451827		[learning rate: 0.0020649]
	Learning Rate: 0.00206488
	LOSS [training: 0.2192539164451827 | validation: 0.2609188462775045]
	TIME [epoch: 8.52 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25754840368550996		[learning rate: 0.0020574]
	Learning Rate: 0.00205739
	LOSS [training: 0.25754840368550996 | validation: 0.23752184639132684]
	TIME [epoch: 8.51 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16142814743435163		[learning rate: 0.0020499]
	Learning Rate: 0.00204992
	LOSS [training: 0.16142814743435163 | validation: 0.20215704993167094]
	TIME [epoch: 8.54 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27352567152144436		[learning rate: 0.0020425]
	Learning Rate: 0.00204248
	LOSS [training: 0.27352567152144436 | validation: 0.22264438243656523]
	TIME [epoch: 8.51 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2710072909329443		[learning rate: 0.0020351]
	Learning Rate: 0.00203507
	LOSS [training: 0.2710072909329443 | validation: 0.2648612929702632]
	TIME [epoch: 8.51 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2006428356463434		[learning rate: 0.0020277]
	Learning Rate: 0.00202768
	LOSS [training: 0.2006428356463434 | validation: 0.25381201706065404]
	TIME [epoch: 8.51 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21273270518437482		[learning rate: 0.0020203]
	Learning Rate: 0.00202032
	LOSS [training: 0.21273270518437482 | validation: 0.6009312681136347]
	TIME [epoch: 8.53 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25895617725342884		[learning rate: 0.002013]
	Learning Rate: 0.00201299
	LOSS [training: 0.25895617725342884 | validation: 0.43677062988199344]
	TIME [epoch: 8.53 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2050296529262888		[learning rate: 0.0020057]
	Learning Rate: 0.00200569
	LOSS [training: 0.2050296529262888 | validation: 0.3159876005150482]
	TIME [epoch: 8.52 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2855252715539526		[learning rate: 0.0019984]
	Learning Rate: 0.00199841
	LOSS [training: 0.2855252715539526 | validation: 0.36459155512913105]
	TIME [epoch: 8.51 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23208255602668096		[learning rate: 0.0019912]
	Learning Rate: 0.00199116
	LOSS [training: 0.23208255602668096 | validation: 0.1877662634634119]
	TIME [epoch: 8.51 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16453538561139683		[learning rate: 0.0019839]
	Learning Rate: 0.00198393
	LOSS [training: 0.16453538561139683 | validation: 0.3072390244717821]
	TIME [epoch: 8.53 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18398013049669326		[learning rate: 0.0019767]
	Learning Rate: 0.00197673
	LOSS [training: 0.18398013049669326 | validation: 0.301680213270935]
	TIME [epoch: 8.51 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3123451418015607		[learning rate: 0.0019696]
	Learning Rate: 0.00196956
	LOSS [training: 0.3123451418015607 | validation: 0.4879816678726423]
	TIME [epoch: 8.52 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4866697139339612		[learning rate: 0.0019624]
	Learning Rate: 0.00196241
	LOSS [training: 0.4866697139339612 | validation: 0.2674977917827222]
	TIME [epoch: 8.51 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1876018563261919		[learning rate: 0.0019553]
	Learning Rate: 0.00195529
	LOSS [training: 0.1876018563261919 | validation: 0.22486947733483303]
	TIME [epoch: 8.54 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2077353171594604		[learning rate: 0.0019482]
	Learning Rate: 0.00194819
	LOSS [training: 0.2077353171594604 | validation: 0.313178393699244]
	TIME [epoch: 8.52 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23708540592328217		[learning rate: 0.0019411]
	Learning Rate: 0.00194112
	LOSS [training: 0.23708540592328217 | validation: 0.2327867225491212]
	TIME [epoch: 8.51 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27013241716510555		[learning rate: 0.0019341]
	Learning Rate: 0.00193408
	LOSS [training: 0.27013241716510555 | validation: 0.22488069784445086]
	TIME [epoch: 8.51 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19354780287423526		[learning rate: 0.0019271]
	Learning Rate: 0.00192706
	LOSS [training: 0.19354780287423526 | validation: 0.6048727354820047]
	TIME [epoch: 8.54 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22704187273779022		[learning rate: 0.0019201]
	Learning Rate: 0.00192006
	LOSS [training: 0.22704187273779022 | validation: 0.24983867962691755]
	TIME [epoch: 8.51 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2088575643280312		[learning rate: 0.0019131]
	Learning Rate: 0.0019131
	LOSS [training: 0.2088575643280312 | validation: 0.16863519297101942]
	TIME [epoch: 8.51 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16731111330873688		[learning rate: 0.0019062]
	Learning Rate: 0.00190615
	LOSS [training: 0.16731111330873688 | validation: 0.1769452937386283]
	TIME [epoch: 8.51 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28318167611886846		[learning rate: 0.0018992]
	Learning Rate: 0.00189924
	LOSS [training: 0.28318167611886846 | validation: 0.3422041220440426]
	TIME [epoch: 8.52 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2296920128893835		[learning rate: 0.0018923]
	Learning Rate: 0.00189234
	LOSS [training: 0.2296920128893835 | validation: 0.24500355136397423]
	TIME [epoch: 8.53 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18826254809206347		[learning rate: 0.0018855]
	Learning Rate: 0.00188548
	LOSS [training: 0.18826254809206347 | validation: 0.17064270948049415]
	TIME [epoch: 8.51 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2489841881271832		[learning rate: 0.0018786]
	Learning Rate: 0.00187863
	LOSS [training: 0.2489841881271832 | validation: 0.27277261347588094]
	TIME [epoch: 8.51 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2533619153748691		[learning rate: 0.0018718]
	Learning Rate: 0.00187182
	LOSS [training: 0.2533619153748691 | validation: 0.2448169542450589]
	TIME [epoch: 8.5 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1595819272824568		[learning rate: 0.001865]
	Learning Rate: 0.00186502
	LOSS [training: 0.1595819272824568 | validation: 0.19751432265511087]
	TIME [epoch: 8.54 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18915420868620486		[learning rate: 0.0018583]
	Learning Rate: 0.00185825
	LOSS [training: 0.18915420868620486 | validation: 0.21001543833071942]
	TIME [epoch: 8.52 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21289815798380912		[learning rate: 0.0018515]
	Learning Rate: 0.00185151
	LOSS [training: 0.21289815798380912 | validation: 0.16412001859584652]
	TIME [epoch: 8.51 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4081819380499809		[learning rate: 0.0018448]
	Learning Rate: 0.00184479
	LOSS [training: 0.4081819380499809 | validation: 0.21915141813500275]
	TIME [epoch: 8.51 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19971669680890664		[learning rate: 0.0018381]
	Learning Rate: 0.0018381
	LOSS [training: 0.19971669680890664 | validation: 0.30761319406229365]
	TIME [epoch: 8.54 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24134847026774547		[learning rate: 0.0018314]
	Learning Rate: 0.00183143
	LOSS [training: 0.24134847026774547 | validation: 0.1786899465371343]
	TIME [epoch: 8.52 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44855305592836825		[learning rate: 0.0018248]
	Learning Rate: 0.00182478
	LOSS [training: 0.44855305592836825 | validation: 0.29786814086668223]
	TIME [epoch: 8.52 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5215820851127492		[learning rate: 0.0018182]
	Learning Rate: 0.00181816
	LOSS [training: 0.5215820851127492 | validation: 0.1983264209306269]
	TIME [epoch: 8.51 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18477043283743105		[learning rate: 0.0018116]
	Learning Rate: 0.00181156
	LOSS [training: 0.18477043283743105 | validation: 0.20544938214313666]
	TIME [epoch: 8.54 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14707378810059302		[learning rate: 0.001805]
	Learning Rate: 0.00180499
	LOSS [training: 0.14707378810059302 | validation: 0.26273678542193557]
	TIME [epoch: 8.52 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33350988494321404		[learning rate: 0.0017984]
	Learning Rate: 0.00179844
	LOSS [training: 0.33350988494321404 | validation: 0.2659842558814717]
	TIME [epoch: 8.52 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17662726763304204		[learning rate: 0.0017919]
	Learning Rate: 0.00179191
	LOSS [training: 0.17662726763304204 | validation: 0.21715244842243484]
	TIME [epoch: 8.51 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15813748032458003		[learning rate: 0.0017854]
	Learning Rate: 0.00178541
	LOSS [training: 0.15813748032458003 | validation: 0.46390554855212285]
	TIME [epoch: 8.52 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24712437336557205		[learning rate: 0.0017789]
	Learning Rate: 0.00177893
	LOSS [training: 0.24712437336557205 | validation: 0.260671667247553]
	TIME [epoch: 8.52 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19945556452189322		[learning rate: 0.0017725]
	Learning Rate: 0.00177247
	LOSS [training: 0.19945556452189322 | validation: 0.20405033262772598]
	TIME [epoch: 8.52 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21067948671496034		[learning rate: 0.001766]
	Learning Rate: 0.00176604
	LOSS [training: 0.21067948671496034 | validation: 0.24937293580811598]
	TIME [epoch: 8.51 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2765614020989131		[learning rate: 0.0017596]
	Learning Rate: 0.00175963
	LOSS [training: 0.2765614020989131 | validation: 0.25258499566394516]
	TIME [epoch: 8.52 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20257352881425278		[learning rate: 0.0017532]
	Learning Rate: 0.00175324
	LOSS [training: 0.20257352881425278 | validation: 0.19681421700724538]
	TIME [epoch: 8.55 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30027407644468357		[learning rate: 0.0017469]
	Learning Rate: 0.00174688
	LOSS [training: 0.30027407644468357 | validation: 0.2420896895692218]
	TIME [epoch: 8.52 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2039237813473652		[learning rate: 0.0017405]
	Learning Rate: 0.00174054
	LOSS [training: 0.2039237813473652 | validation: 0.31554755177830207]
	TIME [epoch: 8.52 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20975441469332176		[learning rate: 0.0017342]
	Learning Rate: 0.00173422
	LOSS [training: 0.20975441469332176 | validation: 0.20574707466478087]
	TIME [epoch: 8.52 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21857432101497937		[learning rate: 0.0017279]
	Learning Rate: 0.00172793
	LOSS [training: 0.21857432101497937 | validation: 0.1830994570280321]
	TIME [epoch: 8.54 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15867086316299983		[learning rate: 0.0017217]
	Learning Rate: 0.00172166
	LOSS [training: 0.15867086316299983 | validation: 0.26391962737591057]
	TIME [epoch: 8.52 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19742374530874138		[learning rate: 0.0017154]
	Learning Rate: 0.00171541
	LOSS [training: 0.19742374530874138 | validation: 0.14871345710352699]
	TIME [epoch: 8.52 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4595084636944834		[learning rate: 0.0017092]
	Learning Rate: 0.00170919
	LOSS [training: 0.4595084636944834 | validation: 0.6308624375045868]
	TIME [epoch: 8.52 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32362577733240944		[learning rate: 0.001703]
	Learning Rate: 0.00170298
	LOSS [training: 0.32362577733240944 | validation: 0.1806267263757801]
	TIME [epoch: 8.55 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16617570773748033		[learning rate: 0.0016968]
	Learning Rate: 0.0016968
	LOSS [training: 0.16617570773748033 | validation: 0.23264937150594925]
	TIME [epoch: 8.52 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16229578598535355		[learning rate: 0.0016906]
	Learning Rate: 0.00169065
	LOSS [training: 0.16229578598535355 | validation: 0.15868813789323072]
	TIME [epoch: 8.52 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23276343005350247		[learning rate: 0.0016845]
	Learning Rate: 0.00168451
	LOSS [training: 0.23276343005350247 | validation: 0.15933812324077157]
	TIME [epoch: 8.53 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1647477425532503		[learning rate: 0.0016784]
	Learning Rate: 0.0016784
	LOSS [training: 0.1647477425532503 | validation: 0.16205443499172245]
	TIME [epoch: 8.54 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18122253327337592		[learning rate: 0.0016723]
	Learning Rate: 0.00167231
	LOSS [training: 0.18122253327337592 | validation: 0.24745423058772265]
	TIME [epoch: 8.53 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16118127318192538		[learning rate: 0.0016662]
	Learning Rate: 0.00166624
	LOSS [training: 0.16118127318192538 | validation: 0.20681594549645566]
	TIME [epoch: 8.52 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3165767863693315		[learning rate: 0.0016602]
	Learning Rate: 0.00166019
	LOSS [training: 0.3165767863693315 | validation: 0.16829135366192335]
	TIME [epoch: 8.52 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2831536507921657		[learning rate: 0.0016542]
	Learning Rate: 0.00165417
	LOSS [training: 0.2831536507921657 | validation: 0.1653332334090882]
	TIME [epoch: 8.53 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14966673201019268		[learning rate: 0.0016482]
	Learning Rate: 0.00164816
	LOSS [training: 0.14966673201019268 | validation: 0.22550419697537805]
	TIME [epoch: 8.54 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15216020758411902		[learning rate: 0.0016422]
	Learning Rate: 0.00164218
	LOSS [training: 0.15216020758411902 | validation: 0.18996948104491895]
	TIME [epoch: 8.52 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28044276973033155		[learning rate: 0.0016362]
	Learning Rate: 0.00163622
	LOSS [training: 0.28044276973033155 | validation: 0.18850607764439825]
	TIME [epoch: 8.51 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3163114525150673		[learning rate: 0.0016303]
	Learning Rate: 0.00163028
	LOSS [training: 0.3163114525150673 | validation: 0.28034268543514496]
	TIME [epoch: 8.52 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18013985674511404		[learning rate: 0.0016244]
	Learning Rate: 0.00162437
	LOSS [training: 0.18013985674511404 | validation: 0.31577313654539074]
	TIME [epoch: 8.55 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20185026165489411		[learning rate: 0.0016185]
	Learning Rate: 0.00161847
	LOSS [training: 0.20185026165489411 | validation: 0.5233425743455992]
	TIME [epoch: 8.52 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7315206481628842		[learning rate: 0.0016126]
	Learning Rate: 0.0016126
	LOSS [training: 0.7315206481628842 | validation: 0.15135667090305918]
	TIME [epoch: 8.52 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2185389548399949		[learning rate: 0.0016067]
	Learning Rate: 0.00160675
	LOSS [training: 0.2185389548399949 | validation: 0.39895064231237476]
	TIME [epoch: 8.52 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2905677127535252		[learning rate: 0.0016009]
	Learning Rate: 0.00160092
	LOSS [training: 0.2905677127535252 | validation: 0.1965688756214448]
	TIME [epoch: 8.55 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5215391834564955		[learning rate: 0.0015951]
	Learning Rate: 0.00159511
	LOSS [training: 0.5215391834564955 | validation: 0.22130290343316414]
	TIME [epoch: 8.52 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22541651365467485		[learning rate: 0.0015893]
	Learning Rate: 0.00158932
	LOSS [training: 0.22541651365467485 | validation: 0.30815494337645266]
	TIME [epoch: 8.51 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20843122483479326		[learning rate: 0.0015835]
	Learning Rate: 0.00158355
	LOSS [training: 0.20843122483479326 | validation: 0.19761670817500052]
	TIME [epoch: 8.52 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19295337006247704		[learning rate: 0.0015778]
	Learning Rate: 0.0015778
	LOSS [training: 0.19295337006247704 | validation: 0.1757282851997498]
	TIME [epoch: 8.55 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1616852649334019		[learning rate: 0.0015721]
	Learning Rate: 0.00157208
	LOSS [training: 0.1616852649334019 | validation: 0.24657805093135243]
	TIME [epoch: 8.53 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1645764175427687		[learning rate: 0.0015664]
	Learning Rate: 0.00156637
	LOSS [training: 0.1645764175427687 | validation: 0.17159735308154847]
	TIME [epoch: 8.52 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.207847236601771		[learning rate: 0.0015607]
	Learning Rate: 0.00156069
	LOSS [training: 0.207847236601771 | validation: 0.2337422995386607]
	TIME [epoch: 8.52 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1962173492072149		[learning rate: 0.001555]
	Learning Rate: 0.00155502
	LOSS [training: 0.1962173492072149 | validation: 0.23037650599183448]
	TIME [epoch: 8.52 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1580604799776367		[learning rate: 0.0015494]
	Learning Rate: 0.00154938
	LOSS [training: 0.1580604799776367 | validation: 0.5235884091978192]
	TIME [epoch: 8.54 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2299922027771284		[learning rate: 0.0015438]
	Learning Rate: 0.00154376
	LOSS [training: 0.2299922027771284 | validation: 0.17175287744422096]
	TIME [epoch: 8.52 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1803581999413864		[learning rate: 0.0015382]
	Learning Rate: 0.00153815
	LOSS [training: 0.1803581999413864 | validation: 0.17073757792173688]
	TIME [epoch: 8.52 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1844711698876496		[learning rate: 0.0015326]
	Learning Rate: 0.00153257
	LOSS [training: 0.1844711698876496 | validation: 0.20361647284247728]
	TIME [epoch: 8.51 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18986573310695026		[learning rate: 0.001527]
	Learning Rate: 0.00152701
	LOSS [training: 0.18986573310695026 | validation: 0.32523648024572827]
	TIME [epoch: 8.54 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2473692835840664		[learning rate: 0.0015215]
	Learning Rate: 0.00152147
	LOSS [training: 0.2473692835840664 | validation: 0.29519936922136514]
	TIME [epoch: 8.52 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22572730786523426		[learning rate: 0.0015159]
	Learning Rate: 0.00151595
	LOSS [training: 0.22572730786523426 | validation: 0.27050597123920406]
	TIME [epoch: 8.51 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2215888831694135		[learning rate: 0.0015104]
	Learning Rate: 0.00151045
	LOSS [training: 0.2215888831694135 | validation: 0.170545935884993]
	TIME [epoch: 8.51 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2126559848968311		[learning rate: 0.001505]
	Learning Rate: 0.00150496
	LOSS [training: 0.2126559848968311 | validation: 0.2759302916858952]
	TIME [epoch: 8.54 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16687252315782214		[learning rate: 0.0014995]
	Learning Rate: 0.0014995
	LOSS [training: 0.16687252315782214 | validation: 0.25734982869267087]
	TIME [epoch: 8.5 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18424613022935188		[learning rate: 0.0014941]
	Learning Rate: 0.00149406
	LOSS [training: 0.18424613022935188 | validation: 0.22930367378515087]
	TIME [epoch: 8.51 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19397356285623008		[learning rate: 0.0014886]
	Learning Rate: 0.00148864
	LOSS [training: 0.19397356285623008 | validation: 0.16027527746623169]
	TIME [epoch: 8.51 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2844938906181052		[learning rate: 0.0014832]
	Learning Rate: 0.00148324
	LOSS [training: 0.2844938906181052 | validation: 0.2711606042746575]
	TIME [epoch: 8.54 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20043315374566775		[learning rate: 0.0014779]
	Learning Rate: 0.00147785
	LOSS [training: 0.20043315374566775 | validation: 0.1366938136659624]
	TIME [epoch: 8.53 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20572332382043285		[learning rate: 0.0014725]
	Learning Rate: 0.00147249
	LOSS [training: 0.20572332382043285 | validation: 0.14589432327731788]
	TIME [epoch: 8.51 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17847411885208384		[learning rate: 0.0014671]
	Learning Rate: 0.00146715
	LOSS [training: 0.17847411885208384 | validation: 0.34831613107766046]
	TIME [epoch: 8.52 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2777954222414071		[learning rate: 0.0014618]
	Learning Rate: 0.00146182
	LOSS [training: 0.2777954222414071 | validation: 0.20103184628052984]
	TIME [epoch: 8.52 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23106185960908565		[learning rate: 0.0014565]
	Learning Rate: 0.00145652
	LOSS [training: 0.23106185960908565 | validation: 0.19282308376986]
	TIME [epoch: 8.54 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17360620309406646		[learning rate: 0.0014512]
	Learning Rate: 0.00145123
	LOSS [training: 0.17360620309406646 | validation: 0.17234132766297533]
	TIME [epoch: 8.51 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22813427742559642		[learning rate: 0.001446]
	Learning Rate: 0.00144597
	LOSS [training: 0.22813427742559642 | validation: 0.2750984036734005]
	TIME [epoch: 8.52 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2600164357996032		[learning rate: 0.0014407]
	Learning Rate: 0.00144072
	LOSS [training: 0.2600164357996032 | validation: 0.21089034234937093]
	TIME [epoch: 8.51 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17244035285228768		[learning rate: 0.0014355]
	Learning Rate: 0.00143549
	LOSS [training: 0.17244035285228768 | validation: 0.1849562206155706]
	TIME [epoch: 8.54 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16923409386085275		[learning rate: 0.0014303]
	Learning Rate: 0.00143028
	LOSS [training: 0.16923409386085275 | validation: 0.15865417202912993]
	TIME [epoch: 8.51 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21098869268745934		[learning rate: 0.0014251]
	Learning Rate: 0.00142509
	LOSS [training: 0.21098869268745934 | validation: 0.23627133645305318]
	TIME [epoch: 8.5 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2819345815988131		[learning rate: 0.0014199]
	Learning Rate: 0.00141992
	LOSS [training: 0.2819345815988131 | validation: 0.22174291668759577]
	TIME [epoch: 8.52 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1742771282823292		[learning rate: 0.0014148]
	Learning Rate: 0.00141476
	LOSS [training: 0.1742771282823292 | validation: 0.19750448591533096]
	TIME [epoch: 8.52 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1763221228504741		[learning rate: 0.0014096]
	Learning Rate: 0.00140963
	LOSS [training: 0.1763221228504741 | validation: 0.1924095456964941]
	TIME [epoch: 8.52 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1702544244634991		[learning rate: 0.0014045]
	Learning Rate: 0.00140451
	LOSS [training: 0.1702544244634991 | validation: 0.22958579486126462]
	TIME [epoch: 8.5 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34540320901987703		[learning rate: 0.0013994]
	Learning Rate: 0.00139942
	LOSS [training: 0.34540320901987703 | validation: 0.879022223824907]
	TIME [epoch: 8.51 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6446958824655973		[learning rate: 0.0013943]
	Learning Rate: 0.00139434
	LOSS [training: 0.6446958824655973 | validation: 0.31716640251411843]
	TIME [epoch: 8.54 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2878209276765569		[learning rate: 0.0013893]
	Learning Rate: 0.00138928
	LOSS [training: 0.2878209276765569 | validation: 0.2660871284562975]
	TIME [epoch: 8.52 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20815758945724888		[learning rate: 0.0013842]
	Learning Rate: 0.00138424
	LOSS [training: 0.20815758945724888 | validation: 0.23355870764426892]
	TIME [epoch: 8.51 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24322502750314126		[learning rate: 0.0013792]
	Learning Rate: 0.00137921
	LOSS [training: 0.24322502750314126 | validation: 0.29313536225604325]
	TIME [epoch: 8.51 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19235649877102223		[learning rate: 0.0013742]
	Learning Rate: 0.00137421
	LOSS [training: 0.19235649877102223 | validation: 0.17167191072073884]
	TIME [epoch: 8.53 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23700027689261086		[learning rate: 0.0013692]
	Learning Rate: 0.00136922
	LOSS [training: 0.23700027689261086 | validation: 0.2171188998605124]
	TIME [epoch: 8.53 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1953083024717182		[learning rate: 0.0013643]
	Learning Rate: 0.00136425
	LOSS [training: 0.1953083024717182 | validation: 0.2374859078811047]
	TIME [epoch: 8.52 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18941781188371262		[learning rate: 0.0013593]
	Learning Rate: 0.0013593
	LOSS [training: 0.18941781188371262 | validation: 0.3391380988668991]
	TIME [epoch: 8.52 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18858103237288032		[learning rate: 0.0013544]
	Learning Rate: 0.00135437
	LOSS [training: 0.18858103237288032 | validation: 0.19864886887316163]
	TIME [epoch: 8.51 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17479617984166002		[learning rate: 0.0013495]
	Learning Rate: 0.00134945
	LOSS [training: 0.17479617984166002 | validation: 0.4305265668998077]
	TIME [epoch: 8.53 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2083392354765475		[learning rate: 0.0013446]
	Learning Rate: 0.00134456
	LOSS [training: 0.2083392354765475 | validation: 0.32906855545585806]
	TIME [epoch: 8.52 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.232710752284353		[learning rate: 0.0013397]
	Learning Rate: 0.00133968
	LOSS [training: 0.232710752284353 | validation: 0.1824807939472891]
	TIME [epoch: 8.51 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2507248618630865		[learning rate: 0.0013348]
	Learning Rate: 0.00133481
	LOSS [training: 0.2507248618630865 | validation: 0.1703465006780721]
	TIME [epoch: 8.51 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16672584254796963		[learning rate: 0.00133]
	Learning Rate: 0.00132997
	LOSS [training: 0.16672584254796963 | validation: 0.19442731907282707]
	TIME [epoch: 8.53 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18029273314252942		[learning rate: 0.0013251]
	Learning Rate: 0.00132514
	LOSS [training: 0.18029273314252942 | validation: 0.36720746907001506]
	TIME [epoch: 8.51 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28762789748796225		[learning rate: 0.0013203]
	Learning Rate: 0.00132034
	LOSS [training: 0.28762789748796225 | validation: 0.29498269556733925]
	TIME [epoch: 8.51 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17576025419257504		[learning rate: 0.0013155]
	Learning Rate: 0.00131554
	LOSS [training: 0.17576025419257504 | validation: 0.1895550803416679]
	TIME [epoch: 8.51 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2358071272938203		[learning rate: 0.0013108]
	Learning Rate: 0.00131077
	LOSS [training: 0.2358071272938203 | validation: 0.2098225518328516]
	TIME [epoch: 8.53 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13375580145921342		[learning rate: 0.001306]
	Learning Rate: 0.00130601
	LOSS [training: 0.13375580145921342 | validation: 0.3834330399164086]
	TIME [epoch: 8.51 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6445569176651456		[learning rate: 0.0013013]
	Learning Rate: 0.00130127
	LOSS [training: 0.6445569176651456 | validation: 0.28716263290182875]
	TIME [epoch: 8.51 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21317847826605146		[learning rate: 0.0012966]
	Learning Rate: 0.00129655
	LOSS [training: 0.21317847826605146 | validation: 0.23485205704482792]
	TIME [epoch: 8.51 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15420019032452897		[learning rate: 0.0012918]
	Learning Rate: 0.00129185
	LOSS [training: 0.15420019032452897 | validation: 0.2893286774918047]
	TIME [epoch: 8.52 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16760161570703463		[learning rate: 0.0012872]
	Learning Rate: 0.00128716
	LOSS [training: 0.16760161570703463 | validation: 0.22528984275223574]
	TIME [epoch: 8.54 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15734601764625414		[learning rate: 0.0012825]
	Learning Rate: 0.00128249
	LOSS [training: 0.15734601764625414 | validation: 0.1697274414436108]
	TIME [epoch: 8.52 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.326246966689901		[learning rate: 0.0012778]
	Learning Rate: 0.00127783
	LOSS [training: 0.326246966689901 | validation: 0.25421297592477]
	TIME [epoch: 8.51 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18232508032954872		[learning rate: 0.0012732]
	Learning Rate: 0.00127319
	LOSS [training: 0.18232508032954872 | validation: 0.21068503049036297]
	TIME [epoch: 8.53 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17432768039915963		[learning rate: 0.0012686]
	Learning Rate: 0.00126857
	LOSS [training: 0.17432768039915963 | validation: 0.260343028669636]
	TIME [epoch: 8.53 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14082338561490795		[learning rate: 0.001264]
	Learning Rate: 0.00126397
	LOSS [training: 0.14082338561490795 | validation: 0.3286387192626516]
	TIME [epoch: 8.51 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23710968340425218		[learning rate: 0.0012594]
	Learning Rate: 0.00125938
	LOSS [training: 0.23710968340425218 | validation: 0.15086319445250573]
	TIME [epoch: 8.51 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2570123003523166		[learning rate: 0.0012548]
	Learning Rate: 0.00125481
	LOSS [training: 0.2570123003523166 | validation: 0.4063920259282195]
	TIME [epoch: 8.51 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2130373984787839		[learning rate: 0.0012503]
	Learning Rate: 0.00125026
	LOSS [training: 0.2130373984787839 | validation: 0.293148308218662]
	TIME [epoch: 8.54 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19905649261221314		[learning rate: 0.0012457]
	Learning Rate: 0.00124572
	LOSS [training: 0.19905649261221314 | validation: 0.2308765053894809]
	TIME [epoch: 8.52 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1950526580660972		[learning rate: 0.0012412]
	Learning Rate: 0.0012412
	LOSS [training: 0.1950526580660972 | validation: 0.1694731108348146]
	TIME [epoch: 8.51 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2167416073392161		[learning rate: 0.0012367]
	Learning Rate: 0.0012367
	LOSS [training: 0.2167416073392161 | validation: 0.15710082009348936]
	TIME [epoch: 8.52 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2080155241591087		[learning rate: 0.0012322]
	Learning Rate: 0.00123221
	LOSS [training: 0.2080155241591087 | validation: 0.16322316822841001]
	TIME [epoch: 8.55 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15503061702490134		[learning rate: 0.0012277]
	Learning Rate: 0.00122774
	LOSS [training: 0.15503061702490134 | validation: 0.282880430237069]
	TIME [epoch: 8.51 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24164296419487416		[learning rate: 0.0012233]
	Learning Rate: 0.00122328
	LOSS [training: 0.24164296419487416 | validation: 0.25858442097552187]
	TIME [epoch: 8.51 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4418959448256922		[learning rate: 0.0012188]
	Learning Rate: 0.00121884
	LOSS [training: 0.4418959448256922 | validation: 0.16558145405579666]
	TIME [epoch: 8.51 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15808783873886195		[learning rate: 0.0012144]
	Learning Rate: 0.00121442
	LOSS [training: 0.15808783873886195 | validation: 0.21466140884474771]
	TIME [epoch: 8.5 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18457102252884744		[learning rate: 0.00121]
	Learning Rate: 0.00121001
	LOSS [training: 0.18457102252884744 | validation: 0.24117880386607865]
	TIME [epoch: 8.53 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16293426202557754		[learning rate: 0.0012056]
	Learning Rate: 0.00120562
	LOSS [training: 0.16293426202557754 | validation: 0.18406967156131837]
	TIME [epoch: 8.51 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17060001950795622		[learning rate: 0.0012012]
	Learning Rate: 0.00120125
	LOSS [training: 0.17060001950795622 | validation: 0.1677679614086629]
	TIME [epoch: 8.53 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21147751910257012		[learning rate: 0.0011969]
	Learning Rate: 0.00119689
	LOSS [training: 0.21147751910257012 | validation: 0.17068386374166877]
	TIME [epoch: 8.52 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17501115439900156		[learning rate: 0.0011925]
	Learning Rate: 0.00119254
	LOSS [training: 0.17501115439900156 | validation: 0.16408714677358793]
	TIME [epoch: 8.54 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24134018046904032		[learning rate: 0.0011882]
	Learning Rate: 0.00118821
	LOSS [training: 0.24134018046904032 | validation: 0.8860904924268882]
	TIME [epoch: 8.51 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36424810075503916		[learning rate: 0.0011839]
	Learning Rate: 0.0011839
	LOSS [training: 0.36424810075503916 | validation: 0.33523658175685345]
	TIME [epoch: 8.51 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33261604501813746		[learning rate: 0.0011796]
	Learning Rate: 0.00117961
	LOSS [training: 0.33261604501813746 | validation: 0.27762820690492573]
	TIME [epoch: 8.52 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.542632423937681		[learning rate: 0.0011753]
	Learning Rate: 0.00117532
	LOSS [training: 0.542632423937681 | validation: 0.16034121274858576]
	TIME [epoch: 8.54 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18794934268613536		[learning rate: 0.0011711]
	Learning Rate: 0.00117106
	LOSS [training: 0.18794934268613536 | validation: 0.8500494073535809]
	TIME [epoch: 8.52 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3167043836915467		[learning rate: 0.0011668]
	Learning Rate: 0.00116681
	LOSS [training: 0.3167043836915467 | validation: 0.15523161550714154]
	TIME [epoch: 8.52 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1530880948525581		[learning rate: 0.0011626]
	Learning Rate: 0.00116258
	LOSS [training: 0.1530880948525581 | validation: 0.2612772260655871]
	TIME [epoch: 8.51 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14310592234363548		[learning rate: 0.0011584]
	Learning Rate: 0.00115836
	LOSS [training: 0.14310592234363548 | validation: 0.18142377995653264]
	TIME [epoch: 8.55 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45663166935634125		[learning rate: 0.0011542]
	Learning Rate: 0.00115415
	LOSS [training: 0.45663166935634125 | validation: 0.18932887910877155]
	TIME [epoch: 8.52 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1777249419947275		[learning rate: 0.00115]
	Learning Rate: 0.00114996
	LOSS [training: 0.1777249419947275 | validation: 0.29667542248801404]
	TIME [epoch: 8.52 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1547371767891042		[learning rate: 0.0011458]
	Learning Rate: 0.00114579
	LOSS [training: 0.1547371767891042 | validation: 0.18045040459984732]
	TIME [epoch: 8.52 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1636415462843657		[learning rate: 0.0011416]
	Learning Rate: 0.00114163
	LOSS [training: 0.1636415462843657 | validation: 0.2251802636706392]
	TIME [epoch: 8.52 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19635457844635754		[learning rate: 0.0011375]
	Learning Rate: 0.00113749
	LOSS [training: 0.19635457844635754 | validation: 0.31280943137935446]
	TIME [epoch: 8.53 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16805269171213255		[learning rate: 0.0011334]
	Learning Rate: 0.00113336
	LOSS [training: 0.16805269171213255 | validation: 0.15278435797800247]
	TIME [epoch: 8.51 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2321107022448511		[learning rate: 0.0011292]
	Learning Rate: 0.00112925
	LOSS [training: 0.2321107022448511 | validation: 0.8126171556292512]
	TIME [epoch: 8.5 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4023301263181612		[learning rate: 0.0011252]
	Learning Rate: 0.00112515
	LOSS [training: 0.4023301263181612 | validation: 0.30725817681795775]
	TIME [epoch: 8.51 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1496827598219443		[learning rate: 0.0011211]
	Learning Rate: 0.00112107
	LOSS [training: 0.1496827598219443 | validation: 0.2231062887115079]
	TIME [epoch: 8.54 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24834417766895997		[learning rate: 0.001117]
	Learning Rate: 0.001117
	LOSS [training: 0.24834417766895997 | validation: 0.17112973314562402]
	TIME [epoch: 8.51 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20833500720866333		[learning rate: 0.0011129]
	Learning Rate: 0.00111295
	LOSS [training: 0.20833500720866333 | validation: 0.1709306919099812]
	TIME [epoch: 8.51 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2225477469607567		[learning rate: 0.0011089]
	Learning Rate: 0.00110891
	LOSS [training: 0.2225477469607567 | validation: 0.16667889690572893]
	TIME [epoch: 8.5 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16993891340282583		[learning rate: 0.0011049]
	Learning Rate: 0.00110488
	LOSS [training: 0.16993891340282583 | validation: 0.2531405644191135]
	TIME [epoch: 8.54 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8779254382849249		[learning rate: 0.0011009]
	Learning Rate: 0.00110087
	LOSS [training: 0.8779254382849249 | validation: 0.21644130894692193]
	TIME [epoch: 8.51 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3724691495872591		[learning rate: 0.0010969]
	Learning Rate: 0.00109688
	LOSS [training: 0.3724691495872591 | validation: 0.20675698031289935]
	TIME [epoch: 8.51 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.594986482322332		[learning rate: 0.0010929]
	Learning Rate: 0.0010929
	LOSS [training: 0.594986482322332 | validation: 0.11968933403716439]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_709.pth
	Model improved!!!
EPOCH 710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1819503261151817		[learning rate: 0.0010889]
	Learning Rate: 0.00108893
	LOSS [training: 0.1819503261151817 | validation: 0.24231032365303246]
	TIME [epoch: 8.54 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21407530028467608		[learning rate: 0.001085]
	Learning Rate: 0.00108498
	LOSS [training: 0.21407530028467608 | validation: 0.15191175500403553]
	TIME [epoch: 8.52 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1661211884951801		[learning rate: 0.001081]
	Learning Rate: 0.00108104
	LOSS [training: 0.1661211884951801 | validation: 0.4012122700474374]
	TIME [epoch: 8.51 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2355874576815115		[learning rate: 0.0010771]
	Learning Rate: 0.00107712
	LOSS [training: 0.2355874576815115 | validation: 0.27864316657119104]
	TIME [epoch: 8.52 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16957685360287866		[learning rate: 0.0010732]
	Learning Rate: 0.00107321
	LOSS [training: 0.16957685360287866 | validation: 0.3162648974138209]
	TIME [epoch: 8.53 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21063884455796145		[learning rate: 0.0010693]
	Learning Rate: 0.00106931
	LOSS [training: 0.21063884455796145 | validation: 0.25642515847587743]
	TIME [epoch: 8.52 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15864672791409865		[learning rate: 0.0010654]
	Learning Rate: 0.00106543
	LOSS [training: 0.15864672791409865 | validation: 0.16344527633006117]
	TIME [epoch: 8.52 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19598960958962697		[learning rate: 0.0010616]
	Learning Rate: 0.00106157
	LOSS [training: 0.19598960958962697 | validation: 0.27184022831560456]
	TIME [epoch: 8.51 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14972971643441949		[learning rate: 0.0010577]
	Learning Rate: 0.00105771
	LOSS [training: 0.14972971643441949 | validation: 0.1492900760294883]
	TIME [epoch: 8.51 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.144807184524696		[learning rate: 0.0010539]
	Learning Rate: 0.00105388
	LOSS [training: 0.144807184524696 | validation: 0.2785548945189948]
	TIME [epoch: 8.54 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18026005852654578		[learning rate: 0.0010501]
	Learning Rate: 0.00105005
	LOSS [training: 0.18026005852654578 | validation: 0.23125323929661795]
	TIME [epoch: 8.51 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15059455086845003		[learning rate: 0.0010462]
	Learning Rate: 0.00104624
	LOSS [training: 0.15059455086845003 | validation: 0.18638402754976852]
	TIME [epoch: 8.51 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24225861137332833		[learning rate: 0.0010424]
	Learning Rate: 0.00104244
	LOSS [training: 0.24225861137332833 | validation: 0.20682614479410544]
	TIME [epoch: 8.51 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20938549036471263		[learning rate: 0.0010387]
	Learning Rate: 0.00103866
	LOSS [training: 0.20938549036471263 | validation: 0.4404504590329343]
	TIME [epoch: 8.54 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19731698873643028		[learning rate: 0.0010349]
	Learning Rate: 0.00103489
	LOSS [training: 0.19731698873643028 | validation: 0.16069712527637028]
	TIME [epoch: 8.51 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2076457442289786		[learning rate: 0.0010311]
	Learning Rate: 0.00103114
	LOSS [training: 0.2076457442289786 | validation: 0.2894514221654981]
	TIME [epoch: 8.51 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1667812052760317		[learning rate: 0.0010274]
	Learning Rate: 0.00102739
	LOSS [training: 0.1667812052760317 | validation: 0.8598520328619709]
	TIME [epoch: 8.5 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37568466081295054		[learning rate: 0.0010237]
	Learning Rate: 0.00102367
	LOSS [training: 0.37568466081295054 | validation: 0.16473046708506545]
	TIME [epoch: 8.54 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21250166342699614		[learning rate: 0.00102]
	Learning Rate: 0.00101995
	LOSS [training: 0.21250166342699614 | validation: 0.18331674580496057]
	TIME [epoch: 8.51 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40144011478336805		[learning rate: 0.0010162]
	Learning Rate: 0.00101625
	LOSS [training: 0.40144011478336805 | validation: 0.3337151734312167]
	TIME [epoch: 8.51 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21309505589096803		[learning rate: 0.0010126]
	Learning Rate: 0.00101256
	LOSS [training: 0.21309505589096803 | validation: 0.2037098421717924]
	TIME [epoch: 8.5 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1498528455565931		[learning rate: 0.0010089]
	Learning Rate: 0.00100889
	LOSS [training: 0.1498528455565931 | validation: 0.20577593282496615]
	TIME [epoch: 8.52 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3120558672476858		[learning rate: 0.0010052]
	Learning Rate: 0.00100522
	LOSS [training: 0.3120558672476858 | validation: 0.1842283144632397]
	TIME [epoch: 8.52 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2429036678729676		[learning rate: 0.0010016]
	Learning Rate: 0.00100158
	LOSS [training: 0.2429036678729676 | validation: 0.1885423471833112]
	TIME [epoch: 8.5 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14832134935274832		[learning rate: 0.00099794]
	Learning Rate: 0.000997942
	LOSS [training: 0.14832134935274832 | validation: 0.1834534956331294]
	TIME [epoch: 8.51 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15462774008673447		[learning rate: 0.00099432]
	Learning Rate: 0.00099432
	LOSS [training: 0.15462774008673447 | validation: 0.2012152004197586]
	TIME [epoch: 8.51 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17946919712034845		[learning rate: 0.00099071]
	Learning Rate: 0.000990712
	LOSS [training: 0.17946919712034845 | validation: 0.37564861980288217]
	TIME [epoch: 8.52 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2112276244306653		[learning rate: 0.00098712]
	Learning Rate: 0.000987116
	LOSS [training: 0.2112276244306653 | validation: 0.22071934675994523]
	TIME [epoch: 8.51 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15934405400211998		[learning rate: 0.00098353]
	Learning Rate: 0.000983534
	LOSS [training: 0.15934405400211998 | validation: 0.7038963896235664]
	TIME [epoch: 8.5 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25951510473000927		[learning rate: 0.00097996]
	Learning Rate: 0.000979965
	LOSS [training: 0.25951510473000927 | validation: 0.25760646735199494]
	TIME [epoch: 8.5 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1561064245600337		[learning rate: 0.00097641]
	Learning Rate: 0.000976409
	LOSS [training: 0.1561064245600337 | validation: 0.16400880268702467]
	TIME [epoch: 8.53 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14549607582785506		[learning rate: 0.00097287]
	Learning Rate: 0.000972865
	LOSS [training: 0.14549607582785506 | validation: 0.23981094435030903]
	TIME [epoch: 8.51 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2725355374821141		[learning rate: 0.00096933]
	Learning Rate: 0.000969335
	LOSS [training: 0.2725355374821141 | validation: 0.295367116885196]
	TIME [epoch: 8.5 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20664515447435985		[learning rate: 0.00096582]
	Learning Rate: 0.000965817
	LOSS [training: 0.20664515447435985 | validation: 0.13904531404370918]
	TIME [epoch: 8.5 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2651213159931355		[learning rate: 0.00096231]
	Learning Rate: 0.000962312
	LOSS [training: 0.2651213159931355 | validation: 0.17414192889835584]
	TIME [epoch: 8.53 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19101286105131682		[learning rate: 0.00095882]
	Learning Rate: 0.00095882
	LOSS [training: 0.19101286105131682 | validation: 0.30092780238897]
	TIME [epoch: 8.5 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21905020056444252		[learning rate: 0.00095534]
	Learning Rate: 0.00095534
	LOSS [training: 0.21905020056444252 | validation: 0.23435409823694464]
	TIME [epoch: 8.51 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25884217619612826		[learning rate: 0.00095187]
	Learning Rate: 0.000951873
	LOSS [training: 0.25884217619612826 | validation: 0.20408677862837432]
	TIME [epoch: 8.5 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15305383723081123		[learning rate: 0.00094842]
	Learning Rate: 0.000948419
	LOSS [training: 0.15305383723081123 | validation: 0.24736681062348637]
	TIME [epoch: 8.53 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18019068285173026		[learning rate: 0.00094498]
	Learning Rate: 0.000944977
	LOSS [training: 0.18019068285173026 | validation: 0.16478418487392377]
	TIME [epoch: 8.53 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1477922181979179		[learning rate: 0.00094155]
	Learning Rate: 0.000941547
	LOSS [training: 0.1477922181979179 | validation: 0.17524129951399608]
	TIME [epoch: 8.51 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20153863350658185		[learning rate: 0.00093813]
	Learning Rate: 0.00093813
	LOSS [training: 0.20153863350658185 | validation: 0.1884195305309814]
	TIME [epoch: 8.5 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14718219643288782		[learning rate: 0.00093473]
	Learning Rate: 0.000934726
	LOSS [training: 0.14718219643288782 | validation: 0.1828830630523885]
	TIME [epoch: 8.51 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20917976048466969		[learning rate: 0.00093133]
	Learning Rate: 0.000931334
	LOSS [training: 0.20917976048466969 | validation: 0.23172264685666474]
	TIME [epoch: 8.54 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1455406137384675		[learning rate: 0.00092795]
	Learning Rate: 0.000927954
	LOSS [training: 0.1455406137384675 | validation: 0.18921760328570442]
	TIME [epoch: 8.5 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1638447765990033		[learning rate: 0.00092459]
	Learning Rate: 0.000924586
	LOSS [training: 0.1638447765990033 | validation: 0.19657876793260415]
	TIME [epoch: 8.51 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16596990682506246		[learning rate: 0.00092123]
	Learning Rate: 0.000921231
	LOSS [training: 0.16596990682506246 | validation: 0.3036204739561461]
	TIME [epoch: 8.51 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16933945131317923		[learning rate: 0.00091789]
	Learning Rate: 0.000917888
	LOSS [training: 0.16933945131317923 | validation: 0.16442803649490007]
	TIME [epoch: 8.54 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1658572189278679		[learning rate: 0.00091456]
	Learning Rate: 0.000914556
	LOSS [training: 0.1658572189278679 | validation: 0.1869488819378171]
	TIME [epoch: 8.51 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21960614889418667		[learning rate: 0.00091124]
	Learning Rate: 0.000911237
	LOSS [training: 0.21960614889418667 | validation: 0.2266081013606071]
	TIME [epoch: 8.5 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18696869861365856		[learning rate: 0.00090793]
	Learning Rate: 0.000907931
	LOSS [training: 0.18696869861365856 | validation: 0.23313182709307934]
	TIME [epoch: 8.5 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17637519680722025		[learning rate: 0.00090464]
	Learning Rate: 0.000904636
	LOSS [training: 0.17637519680722025 | validation: 0.2483857697799147]
	TIME [epoch: 8.53 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19819434472627762		[learning rate: 0.00090135]
	Learning Rate: 0.000901353
	LOSS [training: 0.19819434472627762 | validation: 0.1910617267917759]
	TIME [epoch: 8.52 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1770805837633307		[learning rate: 0.00089808]
	Learning Rate: 0.000898082
	LOSS [training: 0.1770805837633307 | validation: 0.22240189745671501]
	TIME [epoch: 8.5 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1435688053181071		[learning rate: 0.00089482]
	Learning Rate: 0.000894822
	LOSS [training: 0.1435688053181071 | validation: 0.4609086337051863]
	TIME [epoch: 8.51 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37323402012347373		[learning rate: 0.00089157]
	Learning Rate: 0.000891575
	LOSS [training: 0.37323402012347373 | validation: 0.2110971664559831]
	TIME [epoch: 8.53 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16756677432445097		[learning rate: 0.00088834]
	Learning Rate: 0.000888339
	LOSS [training: 0.16756677432445097 | validation: 0.1690662883947358]
	TIME [epoch: 8.52 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17621311641356738		[learning rate: 0.00088512]
	Learning Rate: 0.000885116
	LOSS [training: 0.17621311641356738 | validation: 0.24022163733139856]
	TIME [epoch: 8.51 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1760441535107678		[learning rate: 0.0008819]
	Learning Rate: 0.000881903
	LOSS [training: 0.1760441535107678 | validation: 0.2817577743757952]
	TIME [epoch: 8.51 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17072521450227238		[learning rate: 0.0008787]
	Learning Rate: 0.000878703
	LOSS [training: 0.17072521450227238 | validation: 0.21901330261010482]
	TIME [epoch: 8.51 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21732491361982093		[learning rate: 0.00087551]
	Learning Rate: 0.000875514
	LOSS [training: 0.21732491361982093 | validation: 0.2155538736830499]
	TIME [epoch: 8.54 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1623240273424564		[learning rate: 0.00087234]
	Learning Rate: 0.000872337
	LOSS [training: 0.1623240273424564 | validation: 0.16458998267563024]
	TIME [epoch: 8.51 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1704304240863773		[learning rate: 0.00086917]
	Learning Rate: 0.000869171
	LOSS [training: 0.1704304240863773 | validation: 0.2265545365566012]
	TIME [epoch: 8.51 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1862641937621055		[learning rate: 0.00086602]
	Learning Rate: 0.000866017
	LOSS [training: 0.1862641937621055 | validation: 0.18233982680539437]
	TIME [epoch: 8.51 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13790971764860777		[learning rate: 0.00086287]
	Learning Rate: 0.000862874
	LOSS [training: 0.13790971764860777 | validation: 0.14179188849163227]
	TIME [epoch: 8.54 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1884127326113879		[learning rate: 0.00085974]
	Learning Rate: 0.000859743
	LOSS [training: 0.1884127326113879 | validation: 0.2255302359657128]
	TIME [epoch: 8.5 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1749991193537514		[learning rate: 0.00085662]
	Learning Rate: 0.000856623
	LOSS [training: 0.1749991193537514 | validation: 0.26346052631156114]
	TIME [epoch: 8.52 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18964950216503335		[learning rate: 0.00085351]
	Learning Rate: 0.000853514
	LOSS [training: 0.18964950216503335 | validation: 0.3230689430460408]
	TIME [epoch: 8.51 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29651217077314707		[learning rate: 0.00085042]
	Learning Rate: 0.000850416
	LOSS [training: 0.29651217077314707 | validation: 0.40276945189911695]
	TIME [epoch: 8.54 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2692815205876109		[learning rate: 0.00084733]
	Learning Rate: 0.00084733
	LOSS [training: 0.2692815205876109 | validation: 0.1858826579307366]
	TIME [epoch: 8.51 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12368159070244736		[learning rate: 0.00084426]
	Learning Rate: 0.000844255
	LOSS [training: 0.12368159070244736 | validation: 0.21354530333359195]
	TIME [epoch: 8.51 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17900942395324915		[learning rate: 0.00084119]
	Learning Rate: 0.000841191
	LOSS [training: 0.17900942395324915 | validation: 0.2443616373829216]
	TIME [epoch: 8.51 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18353546573025073		[learning rate: 0.00083814]
	Learning Rate: 0.000838139
	LOSS [training: 0.18353546573025073 | validation: 0.13124750728136067]
	TIME [epoch: 8.52 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16218074625353157		[learning rate: 0.0008351]
	Learning Rate: 0.000835097
	LOSS [training: 0.16218074625353157 | validation: 0.1963508731851008]
	TIME [epoch: 8.53 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17182435029381876		[learning rate: 0.00083207]
	Learning Rate: 0.000832066
	LOSS [training: 0.17182435029381876 | validation: 0.32256257522925996]
	TIME [epoch: 8.51 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16501855551752748		[learning rate: 0.00082905]
	Learning Rate: 0.000829046
	LOSS [training: 0.16501855551752748 | validation: 0.38932215443207696]
	TIME [epoch: 8.51 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15545946993215995		[learning rate: 0.00082604]
	Learning Rate: 0.000826038
	LOSS [training: 0.15545946993215995 | validation: 0.43831849836797887]
	TIME [epoch: 8.51 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2244548948128846		[learning rate: 0.00082304]
	Learning Rate: 0.00082304
	LOSS [training: 0.2244548948128846 | validation: 0.20600842499476935]
	TIME [epoch: 8.53 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15641998869171833		[learning rate: 0.00082005]
	Learning Rate: 0.000820053
	LOSS [training: 0.15641998869171833 | validation: 0.2945769430131643]
	TIME [epoch: 8.51 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1918405148738252		[learning rate: 0.00081708]
	Learning Rate: 0.000817077
	LOSS [training: 0.1918405148738252 | validation: 0.3041284447153709]
	TIME [epoch: 8.51 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20123102727294087		[learning rate: 0.00081411]
	Learning Rate: 0.000814112
	LOSS [training: 0.20123102727294087 | validation: 0.33307161639039284]
	TIME [epoch: 8.51 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19274638973078967		[learning rate: 0.00081116]
	Learning Rate: 0.000811158
	LOSS [training: 0.19274638973078967 | validation: 0.20530739578447577]
	TIME [epoch: 8.53 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20602036448044622		[learning rate: 0.00080821]
	Learning Rate: 0.000808214
	LOSS [training: 0.20602036448044622 | validation: 0.191002895269407]
	TIME [epoch: 8.52 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16994082771697103		[learning rate: 0.00080528]
	Learning Rate: 0.000805281
	LOSS [training: 0.16994082771697103 | validation: 0.1804593051586878]
	TIME [epoch: 8.52 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15094490969008156		[learning rate: 0.00080236]
	Learning Rate: 0.000802358
	LOSS [training: 0.15094490969008156 | validation: 0.2661555821709313]
	TIME [epoch: 8.54 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19746293153396893		[learning rate: 0.00079945]
	Learning Rate: 0.000799447
	LOSS [training: 0.19746293153396893 | validation: 0.18615203939319677]
	TIME [epoch: 8.54 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14582679850401487		[learning rate: 0.00079655]
	Learning Rate: 0.000796545
	LOSS [training: 0.14582679850401487 | validation: 0.19831257857911144]
	TIME [epoch: 8.51 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17234342063936997		[learning rate: 0.00079365]
	Learning Rate: 0.000793655
	LOSS [training: 0.17234342063936997 | validation: 0.2725043794204197]
	TIME [epoch: 8.52 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1739848570124934		[learning rate: 0.00079077]
	Learning Rate: 0.000790775
	LOSS [training: 0.1739848570124934 | validation: 0.17398398063333068]
	TIME [epoch: 8.51 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1317261423811642		[learning rate: 0.0007879]
	Learning Rate: 0.000787905
	LOSS [training: 0.1317261423811642 | validation: 0.1643945524402138]
	TIME [epoch: 8.54 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14225015036124478		[learning rate: 0.00078505]
	Learning Rate: 0.000785045
	LOSS [training: 0.14225015036124478 | validation: 0.1811437069802033]
	TIME [epoch: 8.53 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15955449363683863		[learning rate: 0.0007822]
	Learning Rate: 0.000782196
	LOSS [training: 0.15955449363683863 | validation: 0.2586329717818411]
	TIME [epoch: 8.52 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18410211588777772		[learning rate: 0.00077936]
	Learning Rate: 0.000779358
	LOSS [training: 0.18410211588777772 | validation: 0.19324528552302678]
	TIME [epoch: 8.51 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12741906306710765		[learning rate: 0.00077653]
	Learning Rate: 0.000776529
	LOSS [training: 0.12741906306710765 | validation: 0.16714508321542088]
	TIME [epoch: 8.52 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20787257018409563		[learning rate: 0.00077371]
	Learning Rate: 0.000773711
	LOSS [training: 0.20787257018409563 | validation: 0.18006484048854374]
	TIME [epoch: 8.54 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15964662018216633		[learning rate: 0.0007709]
	Learning Rate: 0.000770903
	LOSS [training: 0.15964662018216633 | validation: 0.2896263920443441]
	TIME [epoch: 8.52 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17845826604867487		[learning rate: 0.00076811]
	Learning Rate: 0.000768106
	LOSS [training: 0.17845826604867487 | validation: 0.5858290323139406]
	TIME [epoch: 8.52 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18306948449884908		[learning rate: 0.00076532]
	Learning Rate: 0.000765318
	LOSS [training: 0.18306948449884908 | validation: 0.24790220479335126]
	TIME [epoch: 8.52 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14559909682336952		[learning rate: 0.00076254]
	Learning Rate: 0.000762541
	LOSS [training: 0.14559909682336952 | validation: 0.221050472680326]
	TIME [epoch: 8.53 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12785515138815287		[learning rate: 0.00075977]
	Learning Rate: 0.000759774
	LOSS [training: 0.12785515138815287 | validation: 0.15738086514163135]
	TIME [epoch: 8.51 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13862281033986468		[learning rate: 0.00075702]
	Learning Rate: 0.000757016
	LOSS [training: 0.13862281033986468 | validation: 0.19243358350670353]
	TIME [epoch: 8.51 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27860552960383467		[learning rate: 0.00075427]
	Learning Rate: 0.000754269
	LOSS [training: 0.27860552960383467 | validation: 0.18813828073821845]
	TIME [epoch: 8.51 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.212995341249638		[learning rate: 0.00075153]
	Learning Rate: 0.000751532
	LOSS [training: 0.212995341249638 | validation: 0.3466354467183256]
	TIME [epoch: 8.52 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23535876874803954		[learning rate: 0.0007488]
	Learning Rate: 0.000748804
	LOSS [training: 0.23535876874803954 | validation: 0.14350754813544675]
	TIME [epoch: 8.52 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1808318669522569		[learning rate: 0.00074609]
	Learning Rate: 0.000746087
	LOSS [training: 0.1808318669522569 | validation: 0.3359772553251767]
	TIME [epoch: 8.52 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17275551433572273		[learning rate: 0.00074338]
	Learning Rate: 0.000743379
	LOSS [training: 0.17275551433572273 | validation: 0.18977994580479446]
	TIME [epoch: 8.51 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16823694466761108		[learning rate: 0.00074068]
	Learning Rate: 0.000740682
	LOSS [training: 0.16823694466761108 | validation: 0.24073701646959988]
	TIME [epoch: 8.53 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16092775317049374		[learning rate: 0.00073799]
	Learning Rate: 0.000737994
	LOSS [training: 0.16092775317049374 | validation: 0.1181984046277225]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_817.pth
	Model improved!!!
EPOCH 818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1810806530608087		[learning rate: 0.00073532]
	Learning Rate: 0.000735315
	LOSS [training: 0.1810806530608087 | validation: 0.14924219953804452]
	TIME [epoch: 8.53 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2702011431014666		[learning rate: 0.00073265]
	Learning Rate: 0.000732647
	LOSS [training: 0.2702011431014666 | validation: 0.20254670315025275]
	TIME [epoch: 8.52 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1154114116004978		[learning rate: 0.00072999]
	Learning Rate: 0.000729988
	LOSS [training: 0.1154114116004978 | validation: 0.20565230987866856]
	TIME [epoch: 8.52 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16102312704363858		[learning rate: 0.00072734]
	Learning Rate: 0.000727339
	LOSS [training: 0.16102312704363858 | validation: 0.192821325742778]
	TIME [epoch: 8.53 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18890733677362603		[learning rate: 0.0007247]
	Learning Rate: 0.000724699
	LOSS [training: 0.18890733677362603 | validation: 0.2584282505490167]
	TIME [epoch: 8.51 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17009196215811437		[learning rate: 0.00072207]
	Learning Rate: 0.000722069
	LOSS [training: 0.17009196215811437 | validation: 0.18499534155837827]
	TIME [epoch: 8.52 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16649216228898567		[learning rate: 0.00071945]
	Learning Rate: 0.000719449
	LOSS [training: 0.16649216228898567 | validation: 0.1785793349698933]
	TIME [epoch: 8.5 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46175547886948587		[learning rate: 0.00071684]
	Learning Rate: 0.000716838
	LOSS [training: 0.46175547886948587 | validation: 0.17543870948323517]
	TIME [epoch: 8.54 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19931214003844452		[learning rate: 0.00071424]
	Learning Rate: 0.000714237
	LOSS [training: 0.19931214003844452 | validation: 0.17651652151438907]
	TIME [epoch: 8.52 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11032705089194772		[learning rate: 0.00071164]
	Learning Rate: 0.000711645
	LOSS [training: 0.11032705089194772 | validation: 0.3137278249389388]
	TIME [epoch: 8.52 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31199608350288743		[learning rate: 0.00070906]
	Learning Rate: 0.000709062
	LOSS [training: 0.31199608350288743 | validation: 0.14539470806136362]
	TIME [epoch: 8.51 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13781059382997518		[learning rate: 0.00070649]
	Learning Rate: 0.000706489
	LOSS [training: 0.13781059382997518 | validation: 0.1343303060203473]
	TIME [epoch: 8.54 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20585040061434806		[learning rate: 0.00070392]
	Learning Rate: 0.000703925
	LOSS [training: 0.20585040061434806 | validation: 0.1669836908229554]
	TIME [epoch: 8.51 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2385550136784563		[learning rate: 0.00070137]
	Learning Rate: 0.00070137
	LOSS [training: 0.2385550136784563 | validation: 0.19742616143054648]
	TIME [epoch: 8.52 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11486962883240745		[learning rate: 0.00069883]
	Learning Rate: 0.000698825
	LOSS [training: 0.11486962883240745 | validation: 0.208734576746142]
	TIME [epoch: 8.51 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14623020569829465		[learning rate: 0.00069629]
	Learning Rate: 0.000696289
	LOSS [training: 0.14623020569829465 | validation: 0.14576792971471578]
	TIME [epoch: 8.54 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14154436770709322		[learning rate: 0.00069376]
	Learning Rate: 0.000693762
	LOSS [training: 0.14154436770709322 | validation: 0.12100529259285575]
	TIME [epoch: 8.53 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14254633438109085		[learning rate: 0.00069124]
	Learning Rate: 0.000691244
	LOSS [training: 0.14254633438109085 | validation: 0.14016564883612193]
	TIME [epoch: 8.51 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11045224856023358		[learning rate: 0.00068874]
	Learning Rate: 0.000688736
	LOSS [training: 0.11045224856023358 | validation: 0.21848671190572247]
	TIME [epoch: 8.51 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16749271033589455		[learning rate: 0.00068624]
	Learning Rate: 0.000686236
	LOSS [training: 0.16749271033589455 | validation: 0.25977469899874633]
	TIME [epoch: 8.51 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15635861465474063		[learning rate: 0.00068375]
	Learning Rate: 0.000683746
	LOSS [training: 0.15635861465474063 | validation: 0.16493154365023882]
	TIME [epoch: 8.53 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13607288008024734		[learning rate: 0.00068126]
	Learning Rate: 0.000681265
	LOSS [training: 0.13607288008024734 | validation: 0.260003491009804]
	TIME [epoch: 8.51 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18929229375657877		[learning rate: 0.00067879]
	Learning Rate: 0.000678792
	LOSS [training: 0.18929229375657877 | validation: 0.447712557228511]
	TIME [epoch: 8.51 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1897364132304228		[learning rate: 0.00067633]
	Learning Rate: 0.000676329
	LOSS [training: 0.1897364132304228 | validation: 0.16734788420129065]
	TIME [epoch: 8.52 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14015669753645857		[learning rate: 0.00067387]
	Learning Rate: 0.000673874
	LOSS [training: 0.14015669753645857 | validation: 0.1441418274385009]
	TIME [epoch: 8.54 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17487213700279103		[learning rate: 0.00067143]
	Learning Rate: 0.000671429
	LOSS [training: 0.17487213700279103 | validation: 1.0224111073140028]
	TIME [epoch: 8.52 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26268069429730734		[learning rate: 0.00066899]
	Learning Rate: 0.000668992
	LOSS [training: 0.26268069429730734 | validation: 0.12628067080554456]
	TIME [epoch: 8.52 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11281196003293817		[learning rate: 0.00066656]
	Learning Rate: 0.000666564
	LOSS [training: 0.11281196003293817 | validation: 0.11503673090575428]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_845.pth
	Model improved!!!
EPOCH 846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1424820705055449		[learning rate: 0.00066415]
	Learning Rate: 0.000664145
	LOSS [training: 0.1424820705055449 | validation: 0.17990857105529634]
	TIME [epoch: 8.54 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13290041639568512		[learning rate: 0.00066174]
	Learning Rate: 0.000661735
	LOSS [training: 0.13290041639568512 | validation: 0.21555664137337824]
	TIME [epoch: 8.52 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1306483850158245		[learning rate: 0.00065933]
	Learning Rate: 0.000659334
	LOSS [training: 0.1306483850158245 | validation: 0.17182860616119028]
	TIME [epoch: 8.51 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1527721411710702		[learning rate: 0.00065694]
	Learning Rate: 0.000656941
	LOSS [training: 0.1527721411710702 | validation: 0.1910404608839281]
	TIME [epoch: 8.51 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1619160584710298		[learning rate: 0.00065456]
	Learning Rate: 0.000654557
	LOSS [training: 0.1619160584710298 | validation: 0.3727110980061106]
	TIME [epoch: 8.54 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1606176832605175		[learning rate: 0.00065218]
	Learning Rate: 0.000652182
	LOSS [training: 0.1606176832605175 | validation: 0.14510292670805816]
	TIME [epoch: 8.52 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14759467979897847		[learning rate: 0.00064981]
	Learning Rate: 0.000649815
	LOSS [training: 0.14759467979897847 | validation: 0.38988205848354246]
	TIME [epoch: 8.51 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18287296123443952		[learning rate: 0.00064746]
	Learning Rate: 0.000647456
	LOSS [training: 0.18287296123443952 | validation: 0.21878124839817217]
	TIME [epoch: 8.5 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23417403604258108		[learning rate: 0.00064511]
	Learning Rate: 0.000645107
	LOSS [training: 0.23417403604258108 | validation: 0.1770012232335399]
	TIME [epoch: 8.5 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19835224494000317		[learning rate: 0.00064277]
	Learning Rate: 0.000642766
	LOSS [training: 0.19835224494000317 | validation: 0.1970472489227425]
	TIME [epoch: 8.52 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13760693631074286		[learning rate: 0.00064043]
	Learning Rate: 0.000640433
	LOSS [training: 0.13760693631074286 | validation: 0.21397823301424435]
	TIME [epoch: 8.51 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15476412973234258		[learning rate: 0.00063811]
	Learning Rate: 0.000638109
	LOSS [training: 0.15476412973234258 | validation: 0.1975002193129182]
	TIME [epoch: 8.51 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16306958584020864		[learning rate: 0.00063579]
	Learning Rate: 0.000635793
	LOSS [training: 0.16306958584020864 | validation: 0.3363554159926404]
	TIME [epoch: 8.51 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2667727067688436		[learning rate: 0.00063349]
	Learning Rate: 0.000633486
	LOSS [training: 0.2667727067688436 | validation: 0.12230856466881303]
	TIME [epoch: 8.53 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10907504089637654		[learning rate: 0.00063119]
	Learning Rate: 0.000631187
	LOSS [training: 0.10907504089637654 | validation: 0.12521338384189643]
	TIME [epoch: 8.51 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1731544659386876		[learning rate: 0.0006289]
	Learning Rate: 0.000628896
	LOSS [training: 0.1731544659386876 | validation: 0.14420749226687982]
	TIME [epoch: 8.51 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10893627446201773		[learning rate: 0.00062661]
	Learning Rate: 0.000626614
	LOSS [training: 0.10893627446201773 | validation: 0.5183261532273679]
	TIME [epoch: 8.51 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21761888481883324		[learning rate: 0.00062434]
	Learning Rate: 0.00062434
	LOSS [training: 0.21761888481883324 | validation: 0.12798369806972087]
	TIME [epoch: 8.54 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11865461202871208		[learning rate: 0.00062207]
	Learning Rate: 0.000622074
	LOSS [training: 0.11865461202871208 | validation: 0.42327667516334233]
	TIME [epoch: 8.52 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1898510869128009		[learning rate: 0.00061982]
	Learning Rate: 0.000619816
	LOSS [training: 0.1898510869128009 | validation: 0.1445010149795462]
	TIME [epoch: 8.51 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1558753860700134		[learning rate: 0.00061757]
	Learning Rate: 0.000617567
	LOSS [training: 0.1558753860700134 | validation: 0.15273592028863686]
	TIME [epoch: 8.51 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14473785978114073		[learning rate: 0.00061533]
	Learning Rate: 0.000615326
	LOSS [training: 0.14473785978114073 | validation: 0.16597702951468707]
	TIME [epoch: 8.54 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12523915778197778		[learning rate: 0.00061309]
	Learning Rate: 0.000613093
	LOSS [training: 0.12523915778197778 | validation: 0.13936640079753546]
	TIME [epoch: 8.51 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14229580058322353		[learning rate: 0.00061087]
	Learning Rate: 0.000610868
	LOSS [training: 0.14229580058322353 | validation: 0.21305536319010582]
	TIME [epoch: 8.51 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1419723485621415		[learning rate: 0.00060865]
	Learning Rate: 0.000608651
	LOSS [training: 0.1419723485621415 | validation: 0.17223821972315234]
	TIME [epoch: 8.51 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1069440274050428		[learning rate: 0.00060644]
	Learning Rate: 0.000606442
	LOSS [training: 0.1069440274050428 | validation: 0.32418040910925605]
	TIME [epoch: 8.51 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13932615474789484		[learning rate: 0.00060424]
	Learning Rate: 0.000604242
	LOSS [training: 0.13932615474789484 | validation: 0.2073146286083211]
	TIME [epoch: 8.52 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19937017108978386		[learning rate: 0.00060205]
	Learning Rate: 0.000602049
	LOSS [training: 0.19937017108978386 | validation: 0.12268651475731454]
	TIME [epoch: 8.5 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2044254207629957		[learning rate: 0.00059986]
	Learning Rate: 0.000599864
	LOSS [training: 0.2044254207629957 | validation: 0.12689612077003126]
	TIME [epoch: 8.5 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12837887665847442		[learning rate: 0.00059769]
	Learning Rate: 0.000597687
	LOSS [training: 0.12837887665847442 | validation: 0.2020541151542798]
	TIME [epoch: 8.51 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24535747431933505		[learning rate: 0.00059552]
	Learning Rate: 0.000595518
	LOSS [training: 0.24535747431933505 | validation: 0.22951559914814068]
	TIME [epoch: 8.54 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14448534494248771		[learning rate: 0.00059336]
	Learning Rate: 0.000593357
	LOSS [training: 0.14448534494248771 | validation: 0.2739640296836826]
	TIME [epoch: 8.51 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14557668758286305		[learning rate: 0.0005912]
	Learning Rate: 0.000591203
	LOSS [training: 0.14557668758286305 | validation: 0.2568257790811228]
	TIME [epoch: 8.51 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31246665421010167		[learning rate: 0.00058906]
	Learning Rate: 0.000589058
	LOSS [training: 0.31246665421010167 | validation: 0.20740929808180253]
	TIME [epoch: 8.51 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14883506821820366		[learning rate: 0.00058692]
	Learning Rate: 0.00058692
	LOSS [training: 0.14883506821820366 | validation: 0.1307534521374069]
	TIME [epoch: 8.53 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18355363698873745		[learning rate: 0.00058479]
	Learning Rate: 0.00058479
	LOSS [training: 0.18355363698873745 | validation: 0.3365077297691126]
	TIME [epoch: 8.51 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1534492901481001		[learning rate: 0.00058267]
	Learning Rate: 0.000582668
	LOSS [training: 0.1534492901481001 | validation: 0.11529588024040298]
	TIME [epoch: 8.51 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11651272182573794		[learning rate: 0.00058055]
	Learning Rate: 0.000580553
	LOSS [training: 0.11651272182573794 | validation: 0.29404709978953325]
	TIME [epoch: 8.51 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17175839891536568		[learning rate: 0.00057845]
	Learning Rate: 0.000578446
	LOSS [training: 0.17175839891536568 | validation: 0.20562869086324823]
	TIME [epoch: 8.53 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13724347399866801		[learning rate: 0.00057635]
	Learning Rate: 0.000576347
	LOSS [training: 0.13724347399866801 | validation: 0.4283897260381336]
	TIME [epoch: 8.51 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21793545728217284		[learning rate: 0.00057426]
	Learning Rate: 0.000574256
	LOSS [training: 0.21793545728217284 | validation: 0.1576024886283872]
	TIME [epoch: 8.5 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15334338097588354		[learning rate: 0.00057217]
	Learning Rate: 0.000572172
	LOSS [training: 0.15334338097588354 | validation: 0.19130338513684503]
	TIME [epoch: 8.51 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1443393925780613		[learning rate: 0.0005701]
	Learning Rate: 0.000570095
	LOSS [training: 0.1443393925780613 | validation: 0.212591809532494]
	TIME [epoch: 8.51 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.164655333244961		[learning rate: 0.00056803]
	Learning Rate: 0.000568026
	LOSS [training: 0.164655333244961 | validation: 0.15849685010171496]
	TIME [epoch: 8.53 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14317876762558335		[learning rate: 0.00056596]
	Learning Rate: 0.000565965
	LOSS [training: 0.14317876762558335 | validation: 0.18198188258069126]
	TIME [epoch: 8.51 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12711557996294978		[learning rate: 0.00056391]
	Learning Rate: 0.000563911
	LOSS [training: 0.12711557996294978 | validation: 0.20019164942561057]
	TIME [epoch: 8.51 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1381337554250715		[learning rate: 0.00056186]
	Learning Rate: 0.000561864
	LOSS [training: 0.1381337554250715 | validation: 0.3466956657140171]
	TIME [epoch: 8.5 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18164173235256256		[learning rate: 0.00055983]
	Learning Rate: 0.000559825
	LOSS [training: 0.18164173235256256 | validation: 0.2005403579193876]
	TIME [epoch: 8.53 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16018465313676808		[learning rate: 0.00055779]
	Learning Rate: 0.000557794
	LOSS [training: 0.16018465313676808 | validation: 1.0355289912604904]
	TIME [epoch: 8.51 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40235022905390194		[learning rate: 0.00055577]
	Learning Rate: 0.00055577
	LOSS [training: 0.40235022905390194 | validation: 0.16299556610294344]
	TIME [epoch: 8.5 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16502344294741156		[learning rate: 0.00055375]
	Learning Rate: 0.000553753
	LOSS [training: 0.16502344294741156 | validation: 0.20175915980782705]
	TIME [epoch: 8.5 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12058821695464643		[learning rate: 0.00055174]
	Learning Rate: 0.000551743
	LOSS [training: 0.12058821695464643 | validation: 0.23084760171571717]
	TIME [epoch: 8.52 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1246300755466175		[learning rate: 0.00054974]
	Learning Rate: 0.000549741
	LOSS [training: 0.1246300755466175 | validation: 0.15958939181623816]
	TIME [epoch: 8.5 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12710587096710418		[learning rate: 0.00054775]
	Learning Rate: 0.000547746
	LOSS [training: 0.12710587096710418 | validation: 0.2656606744505858]
	TIME [epoch: 8.5 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1886838341973785		[learning rate: 0.00054576]
	Learning Rate: 0.000545758
	LOSS [training: 0.1886838341973785 | validation: 0.21121329608019973]
	TIME [epoch: 8.5 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13125422526757016		[learning rate: 0.00054378]
	Learning Rate: 0.000543777
	LOSS [training: 0.13125422526757016 | validation: 0.16629317028948848]
	TIME [epoch: 8.52 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10635878675080068		[learning rate: 0.0005418]
	Learning Rate: 0.000541804
	LOSS [training: 0.10635878675080068 | validation: 0.26863040689179074]
	TIME [epoch: 8.5 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18067992875763372		[learning rate: 0.00053984]
	Learning Rate: 0.000539838
	LOSS [training: 0.18067992875763372 | validation: 0.121545683876701]
	TIME [epoch: 8.5 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1252683645053215		[learning rate: 0.00053788]
	Learning Rate: 0.000537879
	LOSS [training: 0.1252683645053215 | validation: 0.15577920077822885]
	TIME [epoch: 8.5 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19431481738195924		[learning rate: 0.00053593]
	Learning Rate: 0.000535926
	LOSS [training: 0.19431481738195924 | validation: 0.2619051971976851]
	TIME [epoch: 8.5 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18964123981084455		[learning rate: 0.00053398]
	Learning Rate: 0.000533982
	LOSS [training: 0.18964123981084455 | validation: 0.2633185672639678]
	TIME [epoch: 8.52 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19868474375924253		[learning rate: 0.00053204]
	Learning Rate: 0.000532044
	LOSS [training: 0.19868474375924253 | validation: 0.1412922375805604]
	TIME [epoch: 8.5 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1202653716730148		[learning rate: 0.00053011]
	Learning Rate: 0.000530113
	LOSS [training: 0.1202653716730148 | validation: 0.10643476267071655]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_908.pth
	Model improved!!!
EPOCH 909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09022065192117432		[learning rate: 0.00052819]
	Learning Rate: 0.000528189
	LOSS [training: 0.09022065192117432 | validation: 0.17039358887671394]
	TIME [epoch: 8.52 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10153635674705644		[learning rate: 0.00052627]
	Learning Rate: 0.000526272
	LOSS [training: 0.10153635674705644 | validation: 0.1721728784605265]
	TIME [epoch: 8.53 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10800058919905145		[learning rate: 0.00052436]
	Learning Rate: 0.000524362
	LOSS [training: 0.10800058919905145 | validation: 0.25240801161536364]
	TIME [epoch: 8.51 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2508622065547056		[learning rate: 0.00052246]
	Learning Rate: 0.00052246
	LOSS [training: 0.2508622065547056 | validation: 0.11227985696405492]
	TIME [epoch: 8.51 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17128893363126632		[learning rate: 0.00052056]
	Learning Rate: 0.000520563
	LOSS [training: 0.17128893363126632 | validation: 0.20347406114691746]
	TIME [epoch: 8.5 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11738524877701988		[learning rate: 0.00051867]
	Learning Rate: 0.000518674
	LOSS [training: 0.11738524877701988 | validation: 0.203750956561375]
	TIME [epoch: 8.54 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1210920367204155		[learning rate: 0.00051679]
	Learning Rate: 0.000516792
	LOSS [training: 0.1210920367204155 | validation: 0.15273590700912432]
	TIME [epoch: 8.52 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10678760714990773		[learning rate: 0.00051492]
	Learning Rate: 0.000514917
	LOSS [training: 0.10678760714990773 | validation: 0.1722551162241029]
	TIME [epoch: 8.51 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12074239619384619		[learning rate: 0.00051305]
	Learning Rate: 0.000513048
	LOSS [training: 0.12074239619384619 | validation: 0.1137004242228328]
	TIME [epoch: 8.52 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1290434984035391		[learning rate: 0.00051119]
	Learning Rate: 0.000511186
	LOSS [training: 0.1290434984035391 | validation: 0.1488925632349748]
	TIME [epoch: 8.54 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14849252939863739		[learning rate: 0.00050933]
	Learning Rate: 0.000509331
	LOSS [training: 0.14849252939863739 | validation: 0.12893923379470187]
	TIME [epoch: 8.51 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09083189584306181		[learning rate: 0.00050748]
	Learning Rate: 0.000507483
	LOSS [training: 0.09083189584306181 | validation: 0.16979747122476552]
	TIME [epoch: 8.52 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18262457216927752		[learning rate: 0.00050564]
	Learning Rate: 0.000505641
	LOSS [training: 0.18262457216927752 | validation: 0.22881837831717916]
	TIME [epoch: 8.51 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16214345257653145		[learning rate: 0.00050381]
	Learning Rate: 0.000503806
	LOSS [training: 0.16214345257653145 | validation: 0.18081581795048018]
	TIME [epoch: 8.53 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10959869944798517		[learning rate: 0.00050198]
	Learning Rate: 0.000501977
	LOSS [training: 0.10959869944798517 | validation: 0.1543054137480796]
	TIME [epoch: 8.52 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12341220085235757		[learning rate: 0.00050016]
	Learning Rate: 0.000500156
	LOSS [training: 0.12341220085235757 | validation: 0.14533666172467546]
	TIME [epoch: 8.52 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12148841832231187		[learning rate: 0.00049834]
	Learning Rate: 0.000498341
	LOSS [training: 0.12148841832231187 | validation: 0.15128268445106535]
	TIME [epoch: 8.52 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15462451911915437		[learning rate: 0.00049653]
	Learning Rate: 0.000496532
	LOSS [training: 0.15462451911915437 | validation: 0.3264342371629535]
	TIME [epoch: 8.51 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13064410849154356		[learning rate: 0.00049473]
	Learning Rate: 0.00049473
	LOSS [training: 0.13064410849154356 | validation: 0.10387023531566866]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_927.pth
	Model improved!!!
EPOCH 928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17315449926982318		[learning rate: 0.00049293]
	Learning Rate: 0.000492935
	LOSS [training: 0.17315449926982318 | validation: 0.11270384226378205]
	TIME [epoch: 8.51 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15862862602873107		[learning rate: 0.00049115]
	Learning Rate: 0.000491146
	LOSS [training: 0.15862862602873107 | validation: 0.2598682160181093]
	TIME [epoch: 8.5 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12138157873108782		[learning rate: 0.00048936]
	Learning Rate: 0.000489364
	LOSS [training: 0.12138157873108782 | validation: 0.18479461365709632]
	TIME [epoch: 8.51 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09509800888680402		[learning rate: 0.00048759]
	Learning Rate: 0.000487588
	LOSS [training: 0.09509800888680402 | validation: 0.12557329772163547]
	TIME [epoch: 8.52 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13329768620362545		[learning rate: 0.00048582]
	Learning Rate: 0.000485818
	LOSS [training: 0.13329768620362545 | validation: 0.156889472913364]
	TIME [epoch: 8.51 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12512385155112535		[learning rate: 0.00048406]
	Learning Rate: 0.000484055
	LOSS [training: 0.12512385155112535 | validation: 0.5977385489486029]
	TIME [epoch: 8.51 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1984999119184138		[learning rate: 0.0004823]
	Learning Rate: 0.000482298
	LOSS [training: 0.1984999119184138 | validation: 0.12914855880019485]
	TIME [epoch: 8.51 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13473711017520737		[learning rate: 0.00048055]
	Learning Rate: 0.000480548
	LOSS [training: 0.13473711017520737 | validation: 0.16606686197426704]
	TIME [epoch: 8.52 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1364606046419042		[learning rate: 0.0004788]
	Learning Rate: 0.000478804
	LOSS [training: 0.1364606046419042 | validation: 0.23565891198147884]
	TIME [epoch: 8.51 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33168086265250524		[learning rate: 0.00047707]
	Learning Rate: 0.000477067
	LOSS [training: 0.33168086265250524 | validation: 0.31402069542038635]
	TIME [epoch: 8.5 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20576567580061073		[learning rate: 0.00047534]
	Learning Rate: 0.000475335
	LOSS [training: 0.20576567580061073 | validation: 0.16697232379276053]
	TIME [epoch: 8.51 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11490592757337574		[learning rate: 0.00047361]
	Learning Rate: 0.00047361
	LOSS [training: 0.11490592757337574 | validation: 0.17226344066941543]
	TIME [epoch: 8.52 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1855518367577469		[learning rate: 0.00047189]
	Learning Rate: 0.000471891
	LOSS [training: 0.1855518367577469 | validation: 0.15676773384933554]
	TIME [epoch: 8.52 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11979768220015725		[learning rate: 0.00047018]
	Learning Rate: 0.000470179
	LOSS [training: 0.11979768220015725 | validation: 0.11072307280246313]
	TIME [epoch: 8.51 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11991886727169869		[learning rate: 0.00046847]
	Learning Rate: 0.000468473
	LOSS [training: 0.11991886727169869 | validation: 0.1414265875852669]
	TIME [epoch: 8.51 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11534281226950001		[learning rate: 0.00046677]
	Learning Rate: 0.000466773
	LOSS [training: 0.11534281226950001 | validation: 0.1331926224562327]
	TIME [epoch: 8.51 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12048133091808717		[learning rate: 0.00046508]
	Learning Rate: 0.000465079
	LOSS [training: 0.12048133091808717 | validation: 0.12863497583469335]
	TIME [epoch: 8.53 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10880512809301968		[learning rate: 0.00046339]
	Learning Rate: 0.000463391
	LOSS [training: 0.10880512809301968 | validation: 0.12314533177214199]
	TIME [epoch: 8.5 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11044142692977288		[learning rate: 0.00046171]
	Learning Rate: 0.000461709
	LOSS [training: 0.11044142692977288 | validation: 0.1476871877333662]
	TIME [epoch: 8.5 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11870820185633413		[learning rate: 0.00046003]
	Learning Rate: 0.000460034
	LOSS [training: 0.11870820185633413 | validation: 0.24204279448418756]
	TIME [epoch: 8.5 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12545914759741084		[learning rate: 0.00045836]
	Learning Rate: 0.000458364
	LOSS [training: 0.12545914759741084 | validation: 0.14604064789826152]
	TIME [epoch: 8.54 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12483929157413717		[learning rate: 0.0004567]
	Learning Rate: 0.000456701
	LOSS [training: 0.12483929157413717 | validation: 0.1316098687291153]
	TIME [epoch: 8.51 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16668727604232633		[learning rate: 0.00045504]
	Learning Rate: 0.000455043
	LOSS [training: 0.16668727604232633 | validation: 0.11275847202018821]
	TIME [epoch: 8.51 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09442698231468791		[learning rate: 0.00045339]
	Learning Rate: 0.000453392
	LOSS [training: 0.09442698231468791 | validation: 0.187176707061258]
	TIME [epoch: 8.51 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1373766244813181		[learning rate: 0.00045175]
	Learning Rate: 0.000451746
	LOSS [training: 0.1373766244813181 | validation: 0.11525064140486418]
	TIME [epoch: 8.53 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13784668266732053		[learning rate: 0.00045011]
	Learning Rate: 0.000450107
	LOSS [training: 0.13784668266732053 | validation: 0.15841962394896536]
	TIME [epoch: 8.51 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12488797962513024		[learning rate: 0.00044847]
	Learning Rate: 0.000448474
	LOSS [training: 0.12488797962513024 | validation: 0.13447911950273714]
	TIME [epoch: 8.5 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13485487173576982		[learning rate: 0.00044685]
	Learning Rate: 0.000446846
	LOSS [training: 0.13485487173576982 | validation: 0.23641036362196644]
	TIME [epoch: 8.5 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27686603909398977		[learning rate: 0.00044522]
	Learning Rate: 0.000445224
	LOSS [training: 0.27686603909398977 | validation: 0.12023218216714947]
	TIME [epoch: 8.52 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14294635405628928		[learning rate: 0.00044361]
	Learning Rate: 0.000443609
	LOSS [training: 0.14294635405628928 | validation: 0.1880489536075359]
	TIME [epoch: 8.51 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15562310993512188		[learning rate: 0.000442]
	Learning Rate: 0.000441999
	LOSS [training: 0.15562310993512188 | validation: 0.09470259329873251]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_958.pth
	Model improved!!!
EPOCH 959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12507910980040973		[learning rate: 0.00044039]
	Learning Rate: 0.000440395
	LOSS [training: 0.12507910980040973 | validation: 0.20231259665407136]
	TIME [epoch: 8.51 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1290638035872857		[learning rate: 0.0004388]
	Learning Rate: 0.000438797
	LOSS [training: 0.1290638035872857 | validation: 0.23125869365516977]
	TIME [epoch: 8.52 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13238021724134838		[learning rate: 0.0004372]
	Learning Rate: 0.000437204
	LOSS [training: 0.13238021724134838 | validation: 0.10228342181990827]
	TIME [epoch: 8.54 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11659332629910613		[learning rate: 0.00043562]
	Learning Rate: 0.000435617
	LOSS [training: 0.11659332629910613 | validation: 0.1857817419975576]
	TIME [epoch: 8.51 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14408130385002413		[learning rate: 0.00043404]
	Learning Rate: 0.000434037
	LOSS [training: 0.14408130385002413 | validation: 0.1578294159249125]
	TIME [epoch: 8.51 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1051253361734014		[learning rate: 0.00043246]
	Learning Rate: 0.000432461
	LOSS [training: 0.1051253361734014 | validation: 0.13788978040677338]
	TIME [epoch: 8.52 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14114608766243592		[learning rate: 0.00043089]
	Learning Rate: 0.000430892
	LOSS [training: 0.14114608766243592 | validation: 0.194056229750953]
	TIME [epoch: 8.54 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1291755722732456		[learning rate: 0.00042933]
	Learning Rate: 0.000429328
	LOSS [training: 0.1291755722732456 | validation: 0.15562579732796517]
	TIME [epoch: 8.52 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10451573892851332		[learning rate: 0.00042777]
	Learning Rate: 0.00042777
	LOSS [training: 0.10451573892851332 | validation: 0.18135051838726746]
	TIME [epoch: 8.52 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12574153537973967		[learning rate: 0.00042622]
	Learning Rate: 0.000426218
	LOSS [training: 0.12574153537973967 | validation: 0.17317611890621304]
	TIME [epoch: 8.51 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09616849928442436		[learning rate: 0.00042467]
	Learning Rate: 0.000424671
	LOSS [training: 0.09616849928442436 | validation: 0.1789699862731332]
	TIME [epoch: 8.54 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13598087149749127		[learning rate: 0.00042313]
	Learning Rate: 0.00042313
	LOSS [training: 0.13598087149749127 | validation: 0.3556910399092537]
	TIME [epoch: 8.51 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24467565499087396		[learning rate: 0.00042159]
	Learning Rate: 0.000421594
	LOSS [training: 0.24467565499087396 | validation: 0.1801799573147465]
	TIME [epoch: 8.51 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11700812561029994		[learning rate: 0.00042006]
	Learning Rate: 0.000420064
	LOSS [training: 0.11700812561029994 | validation: 0.17350676700498507]
	TIME [epoch: 8.51 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12550838317658045		[learning rate: 0.00041854]
	Learning Rate: 0.00041854
	LOSS [training: 0.12550838317658045 | validation: 0.13638287836038662]
	TIME [epoch: 8.54 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0995385190272248		[learning rate: 0.00041702]
	Learning Rate: 0.000417021
	LOSS [training: 0.0995385190272248 | validation: 0.1905760760427301]
	TIME [epoch: 8.51 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11706206737372742		[learning rate: 0.00041551]
	Learning Rate: 0.000415508
	LOSS [training: 0.11706206737372742 | validation: 0.16717094357464216]
	TIME [epoch: 8.51 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12988644341604666		[learning rate: 0.000414]
	Learning Rate: 0.000414
	LOSS [training: 0.12988644341604666 | validation: 0.11126278166452538]
	TIME [epoch: 8.51 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13444541860870424		[learning rate: 0.0004125]
	Learning Rate: 0.000412497
	LOSS [training: 0.13444541860870424 | validation: 0.23493669129997186]
	TIME [epoch: 8.52 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11196722697558215		[learning rate: 0.000411]
	Learning Rate: 0.000411
	LOSS [training: 0.11196722697558215 | validation: 0.186569628955288]
	TIME [epoch: 8.53 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10918719675505453		[learning rate: 0.00040951]
	Learning Rate: 0.000409509
	LOSS [training: 0.10918719675505453 | validation: 0.12227913160926673]
	TIME [epoch: 8.51 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10785658472333179		[learning rate: 0.00040802]
	Learning Rate: 0.000408023
	LOSS [training: 0.10785658472333179 | validation: 0.16123723981531993]
	TIME [epoch: 8.51 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11716075727493494		[learning rate: 0.00040654]
	Learning Rate: 0.000406542
	LOSS [training: 0.11716075727493494 | validation: 0.13901745925644327]
	TIME [epoch: 8.52 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10656486023844816		[learning rate: 0.00040507]
	Learning Rate: 0.000405067
	LOSS [training: 0.10656486023844816 | validation: 0.21703757301687981]
	TIME [epoch: 8.54 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11798236736152072		[learning rate: 0.0004036]
	Learning Rate: 0.000403597
	LOSS [training: 0.11798236736152072 | validation: 0.10012267064975201]
	TIME [epoch: 8.52 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16267591071619086		[learning rate: 0.00040213]
	Learning Rate: 0.000402132
	LOSS [training: 0.16267591071619086 | validation: 0.30216075535142295]
	TIME [epoch: 8.51 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3325415774977898		[learning rate: 0.00040067]
	Learning Rate: 0.000400672
	LOSS [training: 0.3325415774977898 | validation: 0.13701626675130701]
	TIME [epoch: 8.51 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10756764649157838		[learning rate: 0.00039922]
	Learning Rate: 0.000399218
	LOSS [training: 0.10756764649157838 | validation: 0.18661417712718092]
	TIME [epoch: 8.54 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11331336881098034		[learning rate: 0.00039777]
	Learning Rate: 0.00039777
	LOSS [training: 0.11331336881098034 | validation: 0.1286467821968347]
	TIME [epoch: 8.51 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11720865426450282		[learning rate: 0.00039633]
	Learning Rate: 0.000396326
	LOSS [training: 0.11720865426450282 | validation: 0.12148913644784093]
	TIME [epoch: 8.51 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10054206569844926		[learning rate: 0.00039489]
	Learning Rate: 0.000394888
	LOSS [training: 0.10054206569844926 | validation: 0.16282784269069536]
	TIME [epoch: 8.51 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10250546893383498		[learning rate: 0.00039345]
	Learning Rate: 0.000393455
	LOSS [training: 0.10250546893383498 | validation: 0.1591026717561737]
	TIME [epoch: 8.54 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17155721862674744		[learning rate: 0.00039203]
	Learning Rate: 0.000392027
	LOSS [training: 0.17155721862674744 | validation: 0.4394395776837402]
	TIME [epoch: 8.51 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15382043412514212		[learning rate: 0.0003906]
	Learning Rate: 0.000390604
	LOSS [training: 0.15382043412514212 | validation: 0.20156435324116004]
	TIME [epoch: 8.52 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12969045482552216		[learning rate: 0.00038919]
	Learning Rate: 0.000389187
	LOSS [training: 0.12969045482552216 | validation: 0.1047376922522268]
	TIME [epoch: 8.51 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09833289188865295		[learning rate: 0.00038777]
	Learning Rate: 0.000387774
	LOSS [training: 0.09833289188865295 | validation: 0.2589862133887447]
	TIME [epoch: 8.53 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17624778533232305		[learning rate: 0.00038637]
	Learning Rate: 0.000386367
	LOSS [training: 0.17624778533232305 | validation: 0.18996867030639852]
	TIME [epoch: 8.53 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22726918326558093		[learning rate: 0.00038496]
	Learning Rate: 0.000384965
	LOSS [training: 0.22726918326558093 | validation: 0.2900189913131126]
	TIME [epoch: 8.51 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1267881463130364		[learning rate: 0.00038357]
	Learning Rate: 0.000383568
	LOSS [training: 0.1267881463130364 | validation: 0.11446097346769285]
	TIME [epoch: 8.52 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10107026173608155		[learning rate: 0.00038218]
	Learning Rate: 0.000382176
	LOSS [training: 0.10107026173608155 | validation: 0.12437633715427482]
	TIME [epoch: 8.51 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12086595127226081		[learning rate: 0.00038079]
	Learning Rate: 0.000380789
	LOSS [training: 0.12086595127226081 | validation: 0.15612380282272326]
	TIME [epoch: 8.53 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19718198378601576		[learning rate: 0.00037941]
	Learning Rate: 0.000379407
	LOSS [training: 0.19718198378601576 | validation: 0.12251270262019685]
	TIME [epoch: 8.51 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11288784554178799		[learning rate: 0.00037803]
	Learning Rate: 0.00037803
	LOSS [training: 0.11288784554178799 | validation: 0.1501996352196795]
	TIME [epoch: 8.51 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10590643973923253		[learning rate: 0.00037666]
	Learning Rate: 0.000376658
	LOSS [training: 0.10590643973923253 | validation: 0.1657036184639828]
	TIME [epoch: 8.51 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18174345394508296		[learning rate: 0.00037529]
	Learning Rate: 0.000375291
	LOSS [training: 0.18174345394508296 | validation: 0.4559716709173012]
	TIME [epoch: 8.54 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13745654319796252		[learning rate: 0.00037393]
	Learning Rate: 0.000373929
	LOSS [training: 0.13745654319796252 | validation: 0.16366434018565323]
	TIME [epoch: 8.52 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10043370462113133		[learning rate: 0.00037257]
	Learning Rate: 0.000372572
	LOSS [training: 0.10043370462113133 | validation: 0.12292381622342671]
	TIME [epoch: 8.51 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1426934282516401		[learning rate: 0.00037122]
	Learning Rate: 0.00037122
	LOSS [training: 0.1426934282516401 | validation: 0.14626771255447285]
	TIME [epoch: 8.52 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18295457452855945		[learning rate: 0.00036987]
	Learning Rate: 0.000369873
	LOSS [training: 0.18295457452855945 | validation: 0.2064634224655178]
	TIME [epoch: 8.53 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1600239354939515		[learning rate: 0.00036853]
	Learning Rate: 0.000368531
	LOSS [training: 0.1600239354939515 | validation: 0.18789610456365347]
	TIME [epoch: 8.52 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12950832326956813		[learning rate: 0.00036719]
	Learning Rate: 0.000367193
	LOSS [training: 0.12950832326956813 | validation: 0.14900461864696712]
	TIME [epoch: 8.52 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10927740935945685		[learning rate: 0.00036586]
	Learning Rate: 0.000365861
	LOSS [training: 0.10927740935945685 | validation: 0.1554636571324682]
	TIME [epoch: 8.51 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14024026443286494		[learning rate: 0.00036453]
	Learning Rate: 0.000364533
	LOSS [training: 0.14024026443286494 | validation: 0.17718090326924568]
	TIME [epoch: 8.53 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15326443839540266		[learning rate: 0.00036321]
	Learning Rate: 0.00036321
	LOSS [training: 0.15326443839540266 | validation: 0.10444302573602776]
	TIME [epoch: 8.52 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11847478464788914		[learning rate: 0.00036189]
	Learning Rate: 0.000361892
	LOSS [training: 0.11847478464788914 | validation: 0.10378247872136329]
	TIME [epoch: 8.51 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12703917884679486		[learning rate: 0.00036058]
	Learning Rate: 0.000360579
	LOSS [training: 0.12703917884679486 | validation: 0.14465648198123857]
	TIME [epoch: 8.51 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13157017495590095		[learning rate: 0.00035927]
	Learning Rate: 0.00035927
	LOSS [training: 0.13157017495590095 | validation: 0.15992944008703885]
	TIME [epoch: 8.51 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11821666992211474		[learning rate: 0.00035797]
	Learning Rate: 0.000357966
	LOSS [training: 0.11821666992211474 | validation: 0.13954491071961875]
	TIME [epoch: 8.53 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11595400247869314		[learning rate: 0.00035667]
	Learning Rate: 0.000356667
	LOSS [training: 0.11595400247869314 | validation: 0.15662655648637788]
	TIME [epoch: 8.51 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12136322535674711		[learning rate: 0.00035537]
	Learning Rate: 0.000355373
	LOSS [training: 0.12136322535674711 | validation: 0.1303182783268981]
	TIME [epoch: 8.51 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14150820600913147		[learning rate: 0.00035408]
	Learning Rate: 0.000354083
	LOSS [training: 0.14150820600913147 | validation: 0.17232017548752895]
	TIME [epoch: 8.51 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12791617346224476		[learning rate: 0.0003528]
	Learning Rate: 0.000352798
	LOSS [training: 0.12791617346224476 | validation: 0.18067366770855106]
	TIME [epoch: 8.54 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1169212109301517		[learning rate: 0.00035152]
	Learning Rate: 0.000351518
	LOSS [training: 0.1169212109301517 | validation: 0.12497335308912201]
	TIME [epoch: 8.51 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11695970633642412		[learning rate: 0.00035024]
	Learning Rate: 0.000350242
	LOSS [training: 0.11695970633642412 | validation: 0.21028093944425857]
	TIME [epoch: 8.51 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11834055445071623		[learning rate: 0.00034897]
	Learning Rate: 0.000348971
	LOSS [training: 0.11834055445071623 | validation: 0.1122167052425958]
	TIME [epoch: 8.51 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15366512058727683		[learning rate: 0.0003477]
	Learning Rate: 0.000347705
	LOSS [training: 0.15366512058727683 | validation: 0.12803944723588892]
	TIME [epoch: 8.53 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14358563077798117		[learning rate: 0.00034644]
	Learning Rate: 0.000346443
	LOSS [training: 0.14358563077798117 | validation: 0.17207093122092845]
	TIME [epoch: 8.51 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19234334650913357		[learning rate: 0.00034519]
	Learning Rate: 0.000345186
	LOSS [training: 0.19234334650913357 | validation: 0.16104153838070698]
	TIME [epoch: 8.51 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14621206679618617		[learning rate: 0.00034393]
	Learning Rate: 0.000343933
	LOSS [training: 0.14621206679618617 | validation: 0.13869524396301247]
	TIME [epoch: 8.51 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11950869472650046		[learning rate: 0.00034268]
	Learning Rate: 0.000342685
	LOSS [training: 0.11950869472650046 | validation: 0.24017712617897685]
	TIME [epoch: 8.52 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1466890579373717		[learning rate: 0.00034144]
	Learning Rate: 0.000341441
	LOSS [training: 0.1466890579373717 | validation: 0.14806639546980366]
	TIME [epoch: 8.52 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12240882157057424		[learning rate: 0.0003402]
	Learning Rate: 0.000340202
	LOSS [training: 0.12240882157057424 | validation: 0.17398799278786184]
	TIME [epoch: 8.51 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14544547324284393		[learning rate: 0.00033897]
	Learning Rate: 0.000338967
	LOSS [training: 0.14544547324284393 | validation: 0.1292273476773568]
	TIME [epoch: 8.51 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1549313939967822		[learning rate: 0.00033774]
	Learning Rate: 0.000337737
	LOSS [training: 0.1549313939967822 | validation: 0.12473760853741865]
	TIME [epoch: 8.51 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12569353891066398		[learning rate: 0.00033651]
	Learning Rate: 0.000336512
	LOSS [training: 0.12569353891066398 | validation: 0.13367187992252072]
	TIME [epoch: 8.53 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12987420172684572		[learning rate: 0.00033529]
	Learning Rate: 0.00033529
	LOSS [training: 0.12987420172684572 | validation: 0.12628651220115658]
	TIME [epoch: 8.51 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16275954881985133		[learning rate: 0.00033407]
	Learning Rate: 0.000334074
	LOSS [training: 0.16275954881985133 | validation: 0.1632932781553789]
	TIME [epoch: 8.5 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12301836328961346		[learning rate: 0.00033286]
	Learning Rate: 0.000332861
	LOSS [training: 0.12301836328961346 | validation: 0.11154480865075661]
	TIME [epoch: 8.5 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11752127917738839		[learning rate: 0.00033165]
	Learning Rate: 0.000331653
	LOSS [training: 0.11752127917738839 | validation: 0.17544511913591276]
	TIME [epoch: 8.53 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10666064756168861		[learning rate: 0.00033045]
	Learning Rate: 0.00033045
	LOSS [training: 0.10666064756168861 | validation: 0.17742557510337437]
	TIME [epoch: 8.5 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18158649906839044		[learning rate: 0.00032925]
	Learning Rate: 0.00032925
	LOSS [training: 0.18158649906839044 | validation: 0.11053691255748663]
	TIME [epoch: 8.5 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10603024432798205		[learning rate: 0.00032806]
	Learning Rate: 0.000328056
	LOSS [training: 0.10603024432798205 | validation: 0.21251621544189797]
	TIME [epoch: 8.51 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11875985406571248		[learning rate: 0.00032686]
	Learning Rate: 0.000326865
	LOSS [training: 0.11875985406571248 | validation: 0.12303714533093055]
	TIME [epoch: 8.54 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16095691108776483		[learning rate: 0.00032568]
	Learning Rate: 0.000325679
	LOSS [training: 0.16095691108776483 | validation: 0.12366005880935649]
	TIME [epoch: 8.5 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09959331411471314		[learning rate: 0.0003245]
	Learning Rate: 0.000324497
	LOSS [training: 0.09959331411471314 | validation: 0.12927014825120323]
	TIME [epoch: 8.5 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11760761838331373		[learning rate: 0.00032332]
	Learning Rate: 0.000323319
	LOSS [training: 0.11760761838331373 | validation: 0.19076294725417808]
	TIME [epoch: 8.5 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1280464320431411		[learning rate: 0.00032215]
	Learning Rate: 0.000322146
	LOSS [training: 0.1280464320431411 | validation: 0.19698059152102249]
	TIME [epoch: 8.52 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2236777660894011		[learning rate: 0.00032098]
	Learning Rate: 0.000320977
	LOSS [training: 0.2236777660894011 | validation: 0.18306155941526767]
	TIME [epoch: 8.52 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12530556259415693		[learning rate: 0.00031981]
	Learning Rate: 0.000319812
	LOSS [training: 0.12530556259415693 | validation: 0.13458711536073378]
	TIME [epoch: 8.5 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1126651594602748		[learning rate: 0.00031865]
	Learning Rate: 0.000318651
	LOSS [training: 0.1126651594602748 | validation: 0.15997831559269057]
	TIME [epoch: 8.51 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1216538479299734		[learning rate: 0.0003175]
	Learning Rate: 0.000317495
	LOSS [training: 0.1216538479299734 | validation: 0.14992623713796005]
	TIME [epoch: 8.51 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11523634763170958		[learning rate: 0.00031634]
	Learning Rate: 0.000316343
	LOSS [training: 0.11523634763170958 | validation: 0.1683752348595975]
	TIME [epoch: 8.53 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14739946948886806		[learning rate: 0.00031519]
	Learning Rate: 0.000315195
	LOSS [training: 0.14739946948886806 | validation: 0.21372006227586393]
	TIME [epoch: 8.51 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1322888690705444		[learning rate: 0.00031405]
	Learning Rate: 0.000314051
	LOSS [training: 0.1322888690705444 | validation: 0.18556058761973804]
	TIME [epoch: 8.51 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11767805868352899		[learning rate: 0.00031291]
	Learning Rate: 0.000312911
	LOSS [training: 0.11767805868352899 | validation: 0.11917670381005346]
	TIME [epoch: 8.51 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11436892286589115		[learning rate: 0.00031178]
	Learning Rate: 0.000311776
	LOSS [training: 0.11436892286589115 | validation: 0.14143872227889437]
	TIME [epoch: 8.53 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12920284326990275		[learning rate: 0.00031064]
	Learning Rate: 0.000310644
	LOSS [training: 0.12920284326990275 | validation: 0.20766006068926168]
	TIME [epoch: 8.51 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1323360504510626		[learning rate: 0.00030952]
	Learning Rate: 0.000309517
	LOSS [training: 0.1323360504510626 | validation: 0.1744039139869416]
	TIME [epoch: 8.51 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1297190641825903		[learning rate: 0.00030839]
	Learning Rate: 0.000308394
	LOSS [training: 0.1297190641825903 | validation: 0.25629482514484814]
	TIME [epoch: 8.51 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13329396606174326		[learning rate: 0.00030727]
	Learning Rate: 0.000307274
	LOSS [training: 0.13329396606174326 | validation: 0.16292478779174632]
	TIME [epoch: 8.53 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11380660998490182		[learning rate: 0.00030616]
	Learning Rate: 0.000306159
	LOSS [training: 0.11380660998490182 | validation: 0.17902816245211753]
	TIME [epoch: 8.52 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10376602707056601		[learning rate: 0.00030505]
	Learning Rate: 0.000305048
	LOSS [training: 0.10376602707056601 | validation: 0.1425322834906509]
	TIME [epoch: 8.5 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10364199841630999		[learning rate: 0.00030394]
	Learning Rate: 0.000303941
	LOSS [training: 0.10364199841630999 | validation: 0.16869744927581737]
	TIME [epoch: 8.5 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11700740386622219		[learning rate: 0.00030284]
	Learning Rate: 0.000302838
	LOSS [training: 0.11700740386622219 | validation: 0.12682249227510048]
	TIME [epoch: 8.52 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09111826595325281		[learning rate: 0.00030174]
	Learning Rate: 0.000301739
	LOSS [training: 0.09111826595325281 | validation: 0.14108154931038766]
	TIME [epoch: 8.51 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10985741602369		[learning rate: 0.00030064]
	Learning Rate: 0.000300644
	LOSS [training: 0.10985741602369 | validation: 0.16669677662512608]
	TIME [epoch: 8.5 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11234620780284506		[learning rate: 0.00029955]
	Learning Rate: 0.000299553
	LOSS [training: 0.11234620780284506 | validation: 0.1269985969171839]
	TIME [epoch: 8.51 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1113749946709329		[learning rate: 0.00029847]
	Learning Rate: 0.000298466
	LOSS [training: 0.1113749946709329 | validation: 0.11863904194197752]
	TIME [epoch: 8.51 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11460697866636176		[learning rate: 0.00029738]
	Learning Rate: 0.000297383
	LOSS [training: 0.11460697866636176 | validation: 0.20015376312991326]
	TIME [epoch: 8.53 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1282002612056393		[learning rate: 0.0002963]
	Learning Rate: 0.000296304
	LOSS [training: 0.1282002612056393 | validation: 0.156709235028498]
	TIME [epoch: 8.5 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13111267535470683		[learning rate: 0.00029523]
	Learning Rate: 0.000295228
	LOSS [training: 0.13111267535470683 | validation: 0.13030557022206554]
	TIME [epoch: 8.5 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11998016917028716		[learning rate: 0.00029416]
	Learning Rate: 0.000294157
	LOSS [training: 0.11998016917028716 | validation: 0.15950592391568413]
	TIME [epoch: 8.5 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11184681906120837		[learning rate: 0.00029309]
	Learning Rate: 0.000293089
	LOSS [training: 0.11184681906120837 | validation: 0.17065199865175104]
	TIME [epoch: 8.53 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0986484075650506		[learning rate: 0.00029203]
	Learning Rate: 0.000292026
	LOSS [training: 0.0986484075650506 | validation: 0.12596405260824117]
	TIME [epoch: 8.51 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11063513501203251		[learning rate: 0.00029097]
	Learning Rate: 0.000290966
	LOSS [training: 0.11063513501203251 | validation: 0.11769399035508399]
	TIME [epoch: 8.5 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1037111410599236		[learning rate: 0.00028991]
	Learning Rate: 0.00028991
	LOSS [training: 0.1037111410599236 | validation: 0.1644420766438416]
	TIME [epoch: 8.5 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09968296274289704		[learning rate: 0.00028886]
	Learning Rate: 0.000288858
	LOSS [training: 0.09968296274289704 | validation: 0.17028890238656597]
	TIME [epoch: 8.53 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12745356719461712		[learning rate: 0.00028781]
	Learning Rate: 0.00028781
	LOSS [training: 0.12745356719461712 | validation: 0.2417267690661981]
	TIME [epoch: 8.51 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12156773939315275		[learning rate: 0.00028677]
	Learning Rate: 0.000286765
	LOSS [training: 0.12156773939315275 | validation: 0.2017574535107943]
	TIME [epoch: 8.51 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09402606147431287		[learning rate: 0.00028572]
	Learning Rate: 0.000285724
	LOSS [training: 0.09402606147431287 | validation: 0.12526318827185431]
	TIME [epoch: 8.5 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12725419752581216		[learning rate: 0.00028469]
	Learning Rate: 0.000284688
	LOSS [training: 0.12725419752581216 | validation: 0.17737211381696943]
	TIME [epoch: 8.52 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11107212227029264		[learning rate: 0.00028365]
	Learning Rate: 0.000283654
	LOSS [training: 0.11107212227029264 | validation: 0.13375668311490513]
	TIME [epoch: 8.52 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09605044058731632		[learning rate: 0.00028263]
	Learning Rate: 0.000282625
	LOSS [training: 0.09605044058731632 | validation: 0.15909475652739263]
	TIME [epoch: 8.51 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11168043647195		[learning rate: 0.0002816]
	Learning Rate: 0.000281599
	LOSS [training: 0.11168043647195 | validation: 0.1173542746212577]
	TIME [epoch: 8.5 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09278362390661869		[learning rate: 0.00028058]
	Learning Rate: 0.000280577
	LOSS [training: 0.09278362390661869 | validation: 0.1339698892877262]
	TIME [epoch: 8.51 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09852330727892974		[learning rate: 0.00027956]
	Learning Rate: 0.000279559
	LOSS [training: 0.09852330727892974 | validation: 0.13719388492188833]
	TIME [epoch: 8.52 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0894578297662352		[learning rate: 0.00027854]
	Learning Rate: 0.000278545
	LOSS [training: 0.0894578297662352 | validation: 0.12405591118791319]
	TIME [epoch: 8.51 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10556573018412836		[learning rate: 0.00027753]
	Learning Rate: 0.000277534
	LOSS [training: 0.10556573018412836 | validation: 0.21812250746001227]
	TIME [epoch: 8.51 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11347917938557961		[learning rate: 0.00027653]
	Learning Rate: 0.000276527
	LOSS [training: 0.11347917938557961 | validation: 0.12055380635376647]
	TIME [epoch: 8.51 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11281898053944986		[learning rate: 0.00027552]
	Learning Rate: 0.000275523
	LOSS [training: 0.11281898053944986 | validation: 0.1473740098667276]
	TIME [epoch: 8.53 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11918018268698516		[learning rate: 0.00027452]
	Learning Rate: 0.000274523
	LOSS [training: 0.11918018268698516 | validation: 0.11944628159247014]
	TIME [epoch: 8.51 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09632644157211796		[learning rate: 0.00027353]
	Learning Rate: 0.000273527
	LOSS [training: 0.09632644157211796 | validation: 0.1275243206852636]
	TIME [epoch: 8.5 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10703819045503593		[learning rate: 0.00027253]
	Learning Rate: 0.000272534
	LOSS [training: 0.10703819045503593 | validation: 0.14330916060849433]
	TIME [epoch: 8.51 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12680967859883557		[learning rate: 0.00027155]
	Learning Rate: 0.000271545
	LOSS [training: 0.12680967859883557 | validation: 0.2200200986740406]
	TIME [epoch: 8.53 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11583676663707879		[learning rate: 0.00027056]
	Learning Rate: 0.00027056
	LOSS [training: 0.11583676663707879 | validation: 0.1231643451585375]
	TIME [epoch: 8.5 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13509083305270358		[learning rate: 0.00026958]
	Learning Rate: 0.000269578
	LOSS [training: 0.13509083305270358 | validation: 0.12994070846086242]
	TIME [epoch: 8.51 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0874583758548917		[learning rate: 0.0002686]
	Learning Rate: 0.0002686
	LOSS [training: 0.0874583758548917 | validation: 0.12551464194276976]
	TIME [epoch: 8.5 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11197979268504614		[learning rate: 0.00026762]
	Learning Rate: 0.000267625
	LOSS [training: 0.11197979268504614 | validation: 0.10251398484390116]
	TIME [epoch: 8.52 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1291816566541114		[learning rate: 0.00026665]
	Learning Rate: 0.000266654
	LOSS [training: 0.1291816566541114 | validation: 0.15131934537027925]
	TIME [epoch: 8.52 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0857335779287987		[learning rate: 0.00026569]
	Learning Rate: 0.000265686
	LOSS [training: 0.0857335779287987 | validation: 0.12602819101774096]
	TIME [epoch: 8.5 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09913592505367944		[learning rate: 0.00026472]
	Learning Rate: 0.000264722
	LOSS [training: 0.09913592505367944 | validation: 0.15597185889390586]
	TIME [epoch: 8.51 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13950506985619354		[learning rate: 0.00026376]
	Learning Rate: 0.000263761
	LOSS [training: 0.13950506985619354 | validation: 0.15853251747864144]
	TIME [epoch: 8.5 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10810205491585059		[learning rate: 0.0002628]
	Learning Rate: 0.000262804
	LOSS [training: 0.10810205491585059 | validation: 0.14778423358206397]
	TIME [epoch: 8.53 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09559876111850032		[learning rate: 0.00026185]
	Learning Rate: 0.00026185
	LOSS [training: 0.09559876111850032 | validation: 0.16418095109203484]
	TIME [epoch: 8.5 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11673963750151914		[learning rate: 0.0002609]
	Learning Rate: 0.0002609
	LOSS [training: 0.11673963750151914 | validation: 0.16147553115400498]
	TIME [epoch: 8.5 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10625304349485369		[learning rate: 0.00025995]
	Learning Rate: 0.000259953
	LOSS [training: 0.10625304349485369 | validation: 0.19970149667664738]
	TIME [epoch: 8.5 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13039044234635305		[learning rate: 0.00025901]
	Learning Rate: 0.00025901
	LOSS [training: 0.13039044234635305 | validation: 0.1335173185691792]
	TIME [epoch: 8.52 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09815542019823462		[learning rate: 0.00025807]
	Learning Rate: 0.00025807
	LOSS [training: 0.09815542019823462 | validation: 0.26759793443323104]
	TIME [epoch: 8.51 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12896695139695086		[learning rate: 0.00025713]
	Learning Rate: 0.000257133
	LOSS [training: 0.12896695139695086 | validation: 0.12925190532811234]
	TIME [epoch: 8.5 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17286872107645845		[learning rate: 0.0002562]
	Learning Rate: 0.0002562
	LOSS [training: 0.17286872107645845 | validation: 0.26021346602019413]
	TIME [epoch: 8.5 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09667535259649107		[learning rate: 0.00025527]
	Learning Rate: 0.00025527
	LOSS [training: 0.09667535259649107 | validation: 0.12348924407900086]
	TIME [epoch: 8.53 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10354762636990875		[learning rate: 0.00025434]
	Learning Rate: 0.000254344
	LOSS [training: 0.10354762636990875 | validation: 0.14906062768053424]
	TIME [epoch: 8.51 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14926332777463353		[learning rate: 0.00025342]
	Learning Rate: 0.000253421
	LOSS [training: 0.14926332777463353 | validation: 0.1487906673171713]
	TIME [epoch: 8.51 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09698541478013414		[learning rate: 0.0002525]
	Learning Rate: 0.000252501
	LOSS [training: 0.09698541478013414 | validation: 0.16574924102388466]
	TIME [epoch: 8.5 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09206078112751356		[learning rate: 0.00025158]
	Learning Rate: 0.000251585
	LOSS [training: 0.09206078112751356 | validation: 0.17168515491197056]
	TIME [epoch: 8.52 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13542912220360614		[learning rate: 0.00025067]
	Learning Rate: 0.000250672
	LOSS [training: 0.13542912220360614 | validation: 0.18569275891694087]
	TIME [epoch: 8.51 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09658647018940791		[learning rate: 0.00024976]
	Learning Rate: 0.000249762
	LOSS [training: 0.09658647018940791 | validation: 0.1637790207246576]
	TIME [epoch: 8.51 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17515648144565876		[learning rate: 0.00024886]
	Learning Rate: 0.000248856
	LOSS [training: 0.17515648144565876 | validation: 0.19358691163502342]
	TIME [epoch: 8.5 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10381112726337474		[learning rate: 0.00024795]
	Learning Rate: 0.000247952
	LOSS [training: 0.10381112726337474 | validation: 0.13687483661409172]
	TIME [epoch: 8.51 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09588041992064619		[learning rate: 0.00024705]
	Learning Rate: 0.000247053
	LOSS [training: 0.09588041992064619 | validation: 0.12691976862837648]
	TIME [epoch: 8.54 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1368727299088706		[learning rate: 0.00024616]
	Learning Rate: 0.000246156
	LOSS [training: 0.1368727299088706 | validation: 0.13363065697493584]
	TIME [epoch: 8.5 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09639752304793758		[learning rate: 0.00024526]
	Learning Rate: 0.000245263
	LOSS [training: 0.09639752304793758 | validation: 0.09770257476237078]
	TIME [epoch: 8.5 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10165426509776072		[learning rate: 0.00024437]
	Learning Rate: 0.000244373
	LOSS [training: 0.10165426509776072 | validation: 0.1920174932171818]
	TIME [epoch: 8.51 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11806732454392588		[learning rate: 0.00024349]
	Learning Rate: 0.000243486
	LOSS [training: 0.11806732454392588 | validation: 0.1315706097952089]
	TIME [epoch: 8.53 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09565656205960119		[learning rate: 0.0002426]
	Learning Rate: 0.000242602
	LOSS [training: 0.09565656205960119 | validation: 0.11564284622083501]
	TIME [epoch: 8.51 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20437329353106004		[learning rate: 0.00024172]
	Learning Rate: 0.000241722
	LOSS [training: 0.20437329353106004 | validation: 0.12422406666506233]
	TIME [epoch: 8.51 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08337080469496923		[learning rate: 0.00024084]
	Learning Rate: 0.000240845
	LOSS [training: 0.08337080469496923 | validation: 0.11141666312502559]
	TIME [epoch: 8.51 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09783500514196371		[learning rate: 0.00023997]
	Learning Rate: 0.000239971
	LOSS [training: 0.09783500514196371 | validation: 0.1767390518115197]
	TIME [epoch: 8.52 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10859920072704077		[learning rate: 0.0002391]
	Learning Rate: 0.0002391
	LOSS [training: 0.10859920072704077 | validation: 0.18926016468658963]
	TIME [epoch: 8.5 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10716799323747364		[learning rate: 0.00023823]
	Learning Rate: 0.000238232
	LOSS [training: 0.10716799323747364 | validation: 0.1585905560948629]
	TIME [epoch: 8.5 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09971074089396312		[learning rate: 0.00023737]
	Learning Rate: 0.000237367
	LOSS [training: 0.09971074089396312 | validation: 0.14749856762730906]
	TIME [epoch: 8.5 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11603464557486662		[learning rate: 0.00023651]
	Learning Rate: 0.000236506
	LOSS [training: 0.11603464557486662 | validation: 0.12423782578149883]
	TIME [epoch: 8.52 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09155357410586293		[learning rate: 0.00023565]
	Learning Rate: 0.000235648
	LOSS [training: 0.09155357410586293 | validation: 0.1010187394815621]
	TIME [epoch: 8.51 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10956574317131221		[learning rate: 0.00023479]
	Learning Rate: 0.000234793
	LOSS [training: 0.10956574317131221 | validation: 0.1324300320768901]
	TIME [epoch: 8.51 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10205543128242385		[learning rate: 0.00023394]
	Learning Rate: 0.00023394
	LOSS [training: 0.10205543128242385 | validation: 0.1550691694561114]
	TIME [epoch: 8.5 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10412688300373099		[learning rate: 0.00023309]
	Learning Rate: 0.000233091
	LOSS [training: 0.10412688300373099 | validation: 0.11918627528520051]
	TIME [epoch: 8.51 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08781342612434306		[learning rate: 0.00023225]
	Learning Rate: 0.000232246
	LOSS [training: 0.08781342612434306 | validation: 0.1774626406839146]
	TIME [epoch: 8.52 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10327438268629985		[learning rate: 0.0002314]
	Learning Rate: 0.000231403
	LOSS [training: 0.10327438268629985 | validation: 0.10935154656674814]
	TIME [epoch: 8.51 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10854556162011608		[learning rate: 0.00023056]
	Learning Rate: 0.000230563
	LOSS [training: 0.10854556162011608 | validation: 0.12334148716987621]
	TIME [epoch: 8.5 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10028544252074878		[learning rate: 0.00022973]
	Learning Rate: 0.000229726
	LOSS [training: 0.10028544252074878 | validation: 0.1653832884555828]
	TIME [epoch: 8.5 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09871329668813904		[learning rate: 0.00022889]
	Learning Rate: 0.000228893
	LOSS [training: 0.09871329668813904 | validation: 0.1993505889619404]
	TIME [epoch: 8.52 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11686462637699749		[learning rate: 0.00022806]
	Learning Rate: 0.000228062
	LOSS [training: 0.11686462637699749 | validation: 0.14157523600590133]
	TIME [epoch: 8.5 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09300494912795854		[learning rate: 0.00022723]
	Learning Rate: 0.000227234
	LOSS [training: 0.09300494912795854 | validation: 0.14366990816457884]
	TIME [epoch: 8.5 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08480215743799133		[learning rate: 0.00022641]
	Learning Rate: 0.00022641
	LOSS [training: 0.08480215743799133 | validation: 0.23742471526404646]
	TIME [epoch: 8.49 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19710728587095486		[learning rate: 0.00022559]
	Learning Rate: 0.000225588
	LOSS [training: 0.19710728587095486 | validation: 0.10890768207429968]
	TIME [epoch: 8.53 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10396135363377268		[learning rate: 0.00022477]
	Learning Rate: 0.000224769
	LOSS [training: 0.10396135363377268 | validation: 0.17026507005711364]
	TIME [epoch: 8.5 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08312436873248111		[learning rate: 0.00022395]
	Learning Rate: 0.000223954
	LOSS [training: 0.08312436873248111 | validation: 0.11023972141219499]
	TIME [epoch: 8.5 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1022473102468725		[learning rate: 0.00022314]
	Learning Rate: 0.000223141
	LOSS [training: 0.1022473102468725 | validation: 0.20898310468447245]
	TIME [epoch: 8.5 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1035770193281138		[learning rate: 0.00022233]
	Learning Rate: 0.000222331
	LOSS [training: 0.1035770193281138 | validation: 0.1519431585773031]
	TIME [epoch: 8.52 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10331448475958335		[learning rate: 0.00022152]
	Learning Rate: 0.000221524
	LOSS [training: 0.10331448475958335 | validation: 0.13461320705193622]
	TIME [epoch: 8.51 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10923801208348916		[learning rate: 0.00022072]
	Learning Rate: 0.00022072
	LOSS [training: 0.10923801208348916 | validation: 0.1632323815847604]
	TIME [epoch: 8.5 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10593697547063478		[learning rate: 0.00021992]
	Learning Rate: 0.000219919
	LOSS [training: 0.10593697547063478 | validation: 0.15243257845962782]
	TIME [epoch: 8.5 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12788284601804037		[learning rate: 0.00021912]
	Learning Rate: 0.000219121
	LOSS [training: 0.12788284601804037 | validation: 0.1752722798408042]
	TIME [epoch: 8.51 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11772370244817854		[learning rate: 0.00021833]
	Learning Rate: 0.000218326
	LOSS [training: 0.11772370244817854 | validation: 0.14046955954577786]
	TIME [epoch: 8.53 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11197351618324962		[learning rate: 0.00021753]
	Learning Rate: 0.000217534
	LOSS [training: 0.11197351618324962 | validation: 0.1943983357589596]
	TIME [epoch: 8.51 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1052506669155671		[learning rate: 0.00021674]
	Learning Rate: 0.000216744
	LOSS [training: 0.1052506669155671 | validation: 0.1696425237573756]
	TIME [epoch: 8.5 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10481861230569747		[learning rate: 0.00021596]
	Learning Rate: 0.000215958
	LOSS [training: 0.10481861230569747 | validation: 0.1570402739921895]
	TIME [epoch: 8.51 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13875967716811904		[learning rate: 0.00021517]
	Learning Rate: 0.000215174
	LOSS [training: 0.13875967716811904 | validation: 0.1119870860705943]
	TIME [epoch: 8.52 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0943245938555433		[learning rate: 0.00021439]
	Learning Rate: 0.000214393
	LOSS [training: 0.0943245938555433 | validation: 0.17098133900018767]
	TIME [epoch: 8.51 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09402652190790026		[learning rate: 0.00021361]
	Learning Rate: 0.000213615
	LOSS [training: 0.09402652190790026 | validation: 0.13248393019255805]
	TIME [epoch: 8.5 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09825560847343694		[learning rate: 0.00021284]
	Learning Rate: 0.00021284
	LOSS [training: 0.09825560847343694 | validation: 0.2363861158384272]
	TIME [epoch: 8.5 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09414931269580709		[learning rate: 0.00021207]
	Learning Rate: 0.000212067
	LOSS [training: 0.09414931269580709 | validation: 0.11707801927110471]
	TIME [epoch: 8.52 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10823864969624877		[learning rate: 0.0002113]
	Learning Rate: 0.000211298
	LOSS [training: 0.10823864969624877 | validation: 0.1370668378663925]
	TIME [epoch: 8.5 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09388421736365957		[learning rate: 0.00021053]
	Learning Rate: 0.000210531
	LOSS [training: 0.09388421736365957 | validation: 0.15534479986352961]
	TIME [epoch: 8.5 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10076090418403867		[learning rate: 0.00020977]
	Learning Rate: 0.000209767
	LOSS [training: 0.10076090418403867 | validation: 0.11289169792522434]
	TIME [epoch: 8.5 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11271387231348673		[learning rate: 0.00020901]
	Learning Rate: 0.000209006
	LOSS [training: 0.11271387231348673 | validation: 0.2796486365571813]
	TIME [epoch: 8.51 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11274350929394797		[learning rate: 0.00020825]
	Learning Rate: 0.000208247
	LOSS [training: 0.11274350929394797 | validation: 0.12272817380202981]
	TIME [epoch: 8.51 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09530009270126182		[learning rate: 0.00020749]
	Learning Rate: 0.000207491
	LOSS [training: 0.09530009270126182 | validation: 0.13476396370026963]
	TIME [epoch: 8.5 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09669301277096118		[learning rate: 0.00020674]
	Learning Rate: 0.000206738
	LOSS [training: 0.09669301277096118 | validation: 0.23552212367601222]
	TIME [epoch: 8.5 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10542629890142954		[learning rate: 0.00020599]
	Learning Rate: 0.000205988
	LOSS [training: 0.10542629890142954 | validation: 0.11586932582727238]
	TIME [epoch: 8.5 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09798635407680756		[learning rate: 0.00020524]
	Learning Rate: 0.000205241
	LOSS [training: 0.09798635407680756 | validation: 0.13930772468268077]
	TIME [epoch: 8.52 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10083237338021982		[learning rate: 0.0002045]
	Learning Rate: 0.000204496
	LOSS [training: 0.10083237338021982 | validation: 0.13218261705660142]
	TIME [epoch: 8.5 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13597145103211064		[learning rate: 0.00020375]
	Learning Rate: 0.000203754
	LOSS [training: 0.13597145103211064 | validation: 0.1434287516501298]
	TIME [epoch: 8.51 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08828100099403677		[learning rate: 0.00020301]
	Learning Rate: 0.000203014
	LOSS [training: 0.08828100099403677 | validation: 0.13104231378403342]
	TIME [epoch: 8.5 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19560914104627491		[learning rate: 0.00020228]
	Learning Rate: 0.000202277
	LOSS [training: 0.19560914104627491 | validation: 0.13856521300253183]
	TIME [epoch: 8.53 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10590461332456418		[learning rate: 0.00020154]
	Learning Rate: 0.000201543
	LOSS [training: 0.10590461332456418 | validation: 0.1928733969393216]
	TIME [epoch: 8.51 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08386029672413095		[learning rate: 0.00020081]
	Learning Rate: 0.000200812
	LOSS [training: 0.08386029672413095 | validation: 0.12186849109837379]
	TIME [epoch: 8.5 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09534789655909308		[learning rate: 0.00020008]
	Learning Rate: 0.000200083
	LOSS [training: 0.09534789655909308 | validation: 0.12721123555074754]
	TIME [epoch: 8.5 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10767706603661968		[learning rate: 0.00019936]
	Learning Rate: 0.000199357
	LOSS [training: 0.10767706603661968 | validation: 0.12061493643889094]
	TIME [epoch: 8.52 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10254650359265072		[learning rate: 0.00019863]
	Learning Rate: 0.000198634
	LOSS [training: 0.10254650359265072 | validation: 0.11326583500496434]
	TIME [epoch: 8.5 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08859747207727499		[learning rate: 0.00019791]
	Learning Rate: 0.000197913
	LOSS [training: 0.08859747207727499 | validation: 0.22704412333724977]
	TIME [epoch: 8.5 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10284848336390513		[learning rate: 0.00019719]
	Learning Rate: 0.000197194
	LOSS [training: 0.10284848336390513 | validation: 0.1393826881284247]
	TIME [epoch: 8.5 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10102345809150348		[learning rate: 0.00019648]
	Learning Rate: 0.000196479
	LOSS [training: 0.10102345809150348 | validation: 0.11986398010462956]
	TIME [epoch: 8.52 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2193146682867591		[learning rate: 0.00019577]
	Learning Rate: 0.000195766
	LOSS [training: 0.2193146682867591 | validation: 0.143213821212695]
	TIME [epoch: 8.51 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08984197961283404		[learning rate: 0.00019506]
	Learning Rate: 0.000195055
	LOSS [training: 0.08984197961283404 | validation: 0.19920428732175666]
	TIME [epoch: 8.51 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09306868601804758		[learning rate: 0.00019435]
	Learning Rate: 0.000194347
	LOSS [training: 0.09306868601804758 | validation: 0.142168627574307]
	TIME [epoch: 8.5 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10058692062173583		[learning rate: 0.00019364]
	Learning Rate: 0.000193642
	LOSS [training: 0.10058692062173583 | validation: 0.12909943228390133]
	TIME [epoch: 8.51 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08103415032587408		[learning rate: 0.00019294]
	Learning Rate: 0.000192939
	LOSS [training: 0.08103415032587408 | validation: 0.11713841608299103]
	TIME [epoch: 8.52 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08967940070660842		[learning rate: 0.00019224]
	Learning Rate: 0.000192239
	LOSS [training: 0.08967940070660842 | validation: 0.1630769686579477]
	TIME [epoch: 8.5 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0908686757387569		[learning rate: 0.00019154]
	Learning Rate: 0.000191542
	LOSS [training: 0.0908686757387569 | validation: 0.12524343942070182]
	TIME [epoch: 8.5 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0877730797943856		[learning rate: 0.00019085]
	Learning Rate: 0.000190846
	LOSS [training: 0.0877730797943856 | validation: 0.18390481663037578]
	TIME [epoch: 8.5 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08554515647335625		[learning rate: 0.00019015]
	Learning Rate: 0.000190154
	LOSS [training: 0.08554515647335625 | validation: 0.14427052572225987]
	TIME [epoch: 8.53 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0920209296815014		[learning rate: 0.00018946]
	Learning Rate: 0.000189464
	LOSS [training: 0.0920209296815014 | validation: 0.14884726058802053]
	TIME [epoch: 8.49 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09691463908769317		[learning rate: 0.00018878]
	Learning Rate: 0.000188776
	LOSS [training: 0.09691463908769317 | validation: 0.1050382849881395]
	TIME [epoch: 8.5 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10215029725478073		[learning rate: 0.00018809]
	Learning Rate: 0.000188091
	LOSS [training: 0.10215029725478073 | validation: 0.26827878553733014]
	TIME [epoch: 8.49 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1303898215802755		[learning rate: 0.00018741]
	Learning Rate: 0.000187409
	LOSS [training: 0.1303898215802755 | validation: 0.118294989167329]
	TIME [epoch: 8.52 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09198725291885221		[learning rate: 0.00018673]
	Learning Rate: 0.000186729
	LOSS [training: 0.09198725291885221 | validation: 0.12289418954487923]
	TIME [epoch: 8.5 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08914530564483111		[learning rate: 0.00018605]
	Learning Rate: 0.000186051
	LOSS [training: 0.08914530564483111 | validation: 0.12361742621272824]
	TIME [epoch: 8.49 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09364499578141794		[learning rate: 0.00018538]
	Learning Rate: 0.000185376
	LOSS [training: 0.09364499578141794 | validation: 0.1225586195042715]
	TIME [epoch: 8.5 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15390153878103324		[learning rate: 0.0001847]
	Learning Rate: 0.000184703
	LOSS [training: 0.15390153878103324 | validation: 0.10444656263809382]
	TIME [epoch: 8.52 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09602482842317739		[learning rate: 0.00018403]
	Learning Rate: 0.000184033
	LOSS [training: 0.09602482842317739 | validation: 0.1118179024603961]
	TIME [epoch: 8.51 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0852218150784639		[learning rate: 0.00018336]
	Learning Rate: 0.000183365
	LOSS [training: 0.0852218150784639 | validation: 0.1356564254363533]
	TIME [epoch: 8.5 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09039498657537483		[learning rate: 0.0001827]
	Learning Rate: 0.000182699
	LOSS [training: 0.09039498657537483 | validation: 0.18074989495853486]
	TIME [epoch: 8.49 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10643553059610762		[learning rate: 0.00018204]
	Learning Rate: 0.000182036
	LOSS [training: 0.10643553059610762 | validation: 0.13905021866572947]
	TIME [epoch: 8.49 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14873359214261403		[learning rate: 0.00018138]
	Learning Rate: 0.000181376
	LOSS [training: 0.14873359214261403 | validation: 0.23296101364051555]
	TIME [epoch: 8.52 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1056693048593442		[learning rate: 0.00018072]
	Learning Rate: 0.000180717
	LOSS [training: 0.1056693048593442 | validation: 0.13898602693018372]
	TIME [epoch: 8.49 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09103559357786246		[learning rate: 0.00018006]
	Learning Rate: 0.000180062
	LOSS [training: 0.09103559357786246 | validation: 0.14956169208305845]
	TIME [epoch: 8.49 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09605066266572139		[learning rate: 0.00017941]
	Learning Rate: 0.000179408
	LOSS [training: 0.09605066266572139 | validation: 0.10789137610520604]
	TIME [epoch: 8.5 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08866461488040882		[learning rate: 0.00017876]
	Learning Rate: 0.000178757
	LOSS [training: 0.08866461488040882 | validation: 0.11178118997259276]
	TIME [epoch: 8.52 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0826362108830322		[learning rate: 0.00017811]
	Learning Rate: 0.000178108
	LOSS [training: 0.0826362108830322 | validation: 0.12411418068014743]
	TIME [epoch: 8.5 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1113221337528399		[learning rate: 0.00017746]
	Learning Rate: 0.000177462
	LOSS [training: 0.1113221337528399 | validation: 0.32262573785049425]
	TIME [epoch: 8.49 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12247439235615834		[learning rate: 0.00017682]
	Learning Rate: 0.000176818
	LOSS [training: 0.12247439235615834 | validation: 0.317222614077376]
	TIME [epoch: 8.49 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.139030654996522		[learning rate: 0.00017618]
	Learning Rate: 0.000176176
	LOSS [training: 0.139030654996522 | validation: 0.1314124519851083]
	TIME [epoch: 8.51 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08030258715017116		[learning rate: 0.00017554]
	Learning Rate: 0.000175537
	LOSS [training: 0.08030258715017116 | validation: 0.16147004458269582]
	TIME [epoch: 8.49 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17783851873592543		[learning rate: 0.0001749]
	Learning Rate: 0.0001749
	LOSS [training: 0.17783851873592543 | validation: 0.11098723731503708]
	TIME [epoch: 8.49 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09791783995754905		[learning rate: 0.00017427]
	Learning Rate: 0.000174265
	LOSS [training: 0.09791783995754905 | validation: 0.09968613619928891]
	TIME [epoch: 8.49 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09543269506374615		[learning rate: 0.00017363]
	Learning Rate: 0.000173633
	LOSS [training: 0.09543269506374615 | validation: 0.13019469169567494]
	TIME [epoch: 8.51 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10869792662408932		[learning rate: 0.000173]
	Learning Rate: 0.000173003
	LOSS [training: 0.10869792662408932 | validation: 0.150521137381242]
	TIME [epoch: 8.5 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2642253456420992		[learning rate: 0.00017237]
	Learning Rate: 0.000172375
	LOSS [training: 0.2642253456420992 | validation: 0.17669626812418657]
	TIME [epoch: 8.5 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08359895830167303		[learning rate: 0.00017175]
	Learning Rate: 0.000171749
	LOSS [training: 0.08359895830167303 | validation: 0.14541128953047813]
	TIME [epoch: 8.5 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08442095534833967		[learning rate: 0.00017113]
	Learning Rate: 0.000171126
	LOSS [training: 0.08442095534833967 | validation: 0.1589299673875303]
	TIME [epoch: 8.5 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14603230557295221		[learning rate: 0.0001705]
	Learning Rate: 0.000170505
	LOSS [training: 0.14603230557295221 | validation: 0.22719447621203873]
	TIME [epoch: 8.52 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18888742654248142		[learning rate: 0.00016989]
	Learning Rate: 0.000169886
	LOSS [training: 0.18888742654248142 | validation: 0.25730107499242477]
	TIME [epoch: 8.49 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11902568465074059		[learning rate: 0.00016927]
	Learning Rate: 0.00016927
	LOSS [training: 0.11902568465074059 | validation: 0.13997339867532071]
	TIME [epoch: 8.5 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09422688727030663		[learning rate: 0.00016866]
	Learning Rate: 0.000168655
	LOSS [training: 0.09422688727030663 | validation: 0.13493583044443058]
	TIME [epoch: 8.49 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09768361588526442		[learning rate: 0.00016804]
	Learning Rate: 0.000168043
	LOSS [training: 0.09768361588526442 | validation: 0.13233023381382086]
	TIME [epoch: 8.52 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08798465257964214		[learning rate: 0.00016743]
	Learning Rate: 0.000167433
	LOSS [training: 0.08798465257964214 | validation: 0.1510279570851488]
	TIME [epoch: 8.5 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10992703253210105		[learning rate: 0.00016683]
	Learning Rate: 0.000166826
	LOSS [training: 0.10992703253210105 | validation: 0.11622375345689584]
	TIME [epoch: 8.5 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08282468337952203		[learning rate: 0.00016622]
	Learning Rate: 0.00016622
	LOSS [training: 0.08282468337952203 | validation: 0.146432790300606]
	TIME [epoch: 8.49 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10205131132116782		[learning rate: 0.00016562]
	Learning Rate: 0.000165617
	LOSS [training: 0.10205131132116782 | validation: 0.11243355612387991]
	TIME [epoch: 8.51 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12572732582042945		[learning rate: 0.00016502]
	Learning Rate: 0.000165016
	LOSS [training: 0.12572732582042945 | validation: 0.12223274017835754]
	TIME [epoch: 8.49 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09081538332811588		[learning rate: 0.00016442]
	Learning Rate: 0.000164417
	LOSS [training: 0.09081538332811588 | validation: 0.12333944437618764]
	TIME [epoch: 8.49 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11385271075423935		[learning rate: 0.00016382]
	Learning Rate: 0.000163821
	LOSS [training: 0.11385271075423935 | validation: 0.1509200581614659]
	TIME [epoch: 8.5 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11187372079108882		[learning rate: 0.00016323]
	Learning Rate: 0.000163226
	LOSS [training: 0.11187372079108882 | validation: 0.12038861790156692]
	TIME [epoch: 8.51 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09149545564057787		[learning rate: 0.00016263]
	Learning Rate: 0.000162634
	LOSS [training: 0.09149545564057787 | validation: 0.15309389823394795]
	TIME [epoch: 8.5 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11607086304691709		[learning rate: 0.00016204]
	Learning Rate: 0.000162043
	LOSS [training: 0.11607086304691709 | validation: 0.27651518336683106]
	TIME [epoch: 8.5 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13395260068948217		[learning rate: 0.00016146]
	Learning Rate: 0.000161455
	LOSS [training: 0.13395260068948217 | validation: 0.16422852082753908]
	TIME [epoch: 8.49 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11694764994311266		[learning rate: 0.00016087]
	Learning Rate: 0.000160869
	LOSS [training: 0.11694764994311266 | validation: 0.13568908106586228]
	TIME [epoch: 8.5 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09791711708702137		[learning rate: 0.00016029]
	Learning Rate: 0.000160286
	LOSS [training: 0.09791711708702137 | validation: 0.13214419587439893]
	TIME [epoch: 8.51 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08046287409760731		[learning rate: 0.0001597]
	Learning Rate: 0.000159704
	LOSS [training: 0.08046287409760731 | validation: 0.151138865807333]
	TIME [epoch: 8.49 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10731865988785923		[learning rate: 0.00015912]
	Learning Rate: 0.000159124
	LOSS [training: 0.10731865988785923 | validation: 0.11347510555642676]
	TIME [epoch: 8.49 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0920413431788207		[learning rate: 0.00015855]
	Learning Rate: 0.000158547
	LOSS [training: 0.0920413431788207 | validation: 0.10988539923620275]
	TIME [epoch: 8.49 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08216061481295839		[learning rate: 0.00015797]
	Learning Rate: 0.000157972
	LOSS [training: 0.08216061481295839 | validation: 0.11449057459697576]
	TIME [epoch: 8.52 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1016976778890942		[learning rate: 0.0001574]
	Learning Rate: 0.000157398
	LOSS [training: 0.1016976778890942 | validation: 0.1771429755291265]
	TIME [epoch: 8.49 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09582277184304958		[learning rate: 0.00015683]
	Learning Rate: 0.000156827
	LOSS [training: 0.09582277184304958 | validation: 0.104015402458854]
	TIME [epoch: 8.49 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07963744822176608		[learning rate: 0.00015626]
	Learning Rate: 0.000156258
	LOSS [training: 0.07963744822176608 | validation: 0.11171521983684815]
	TIME [epoch: 8.49 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09625226481215622		[learning rate: 0.00015569]
	Learning Rate: 0.000155691
	LOSS [training: 0.09625226481215622 | validation: 0.10114208462449037]
	TIME [epoch: 8.51 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09524887932345182		[learning rate: 0.00015513]
	Learning Rate: 0.000155126
	LOSS [training: 0.09524887932345182 | validation: 0.10758127233934972]
	TIME [epoch: 8.49 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08626373169550963		[learning rate: 0.00015456]
	Learning Rate: 0.000154563
	LOSS [training: 0.08626373169550963 | validation: 0.1766887800885335]
	TIME [epoch: 8.49 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09003095343489712		[learning rate: 0.000154]
	Learning Rate: 0.000154002
	LOSS [training: 0.09003095343489712 | validation: 0.1416965502635519]
	TIME [epoch: 8.49 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08139521048301361		[learning rate: 0.00015344]
	Learning Rate: 0.000153443
	LOSS [training: 0.08139521048301361 | validation: 0.14436443833565554]
	TIME [epoch: 8.5 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0894749769437093		[learning rate: 0.00015289]
	Learning Rate: 0.000152886
	LOSS [training: 0.0894749769437093 | validation: 0.10795219789567656]
	TIME [epoch: 8.5 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08485069416129992		[learning rate: 0.00015233]
	Learning Rate: 0.000152331
	LOSS [training: 0.08485069416129992 | validation: 0.13672595056311196]
	TIME [epoch: 8.49 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08877638235700923		[learning rate: 0.00015178]
	Learning Rate: 0.000151779
	LOSS [training: 0.08877638235700923 | validation: 0.13186461946080577]
	TIME [epoch: 8.49 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08017081011943215		[learning rate: 0.00015123]
	Learning Rate: 0.000151228
	LOSS [training: 0.08017081011943215 | validation: 0.11352529948716453]
	TIME [epoch: 8.49 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07955693393066587		[learning rate: 0.00015068]
	Learning Rate: 0.000150679
	LOSS [training: 0.07955693393066587 | validation: 0.19435102912612573]
	TIME [epoch: 8.51 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10876583842122974		[learning rate: 0.00015013]
	Learning Rate: 0.000150132
	LOSS [training: 0.10876583842122974 | validation: 0.18986073276990856]
	TIME [epoch: 8.49 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09118797644677837		[learning rate: 0.00014959]
	Learning Rate: 0.000149587
	LOSS [training: 0.09118797644677837 | validation: 0.1451975900870669]
	TIME [epoch: 8.49 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08200309810318385		[learning rate: 0.00014904]
	Learning Rate: 0.000149044
	LOSS [training: 0.08200309810318385 | validation: 0.13307288058493671]
	TIME [epoch: 8.49 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0937356376039608		[learning rate: 0.0001485]
	Learning Rate: 0.000148504
	LOSS [training: 0.0937356376039608 | validation: 0.12722626911485743]
	TIME [epoch: 8.51 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07524801951347089		[learning rate: 0.00014796]
	Learning Rate: 0.000147965
	LOSS [training: 0.07524801951347089 | validation: 0.11084361059411903]
	TIME [epoch: 8.5 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09388397272344212		[learning rate: 0.00014743]
	Learning Rate: 0.000147428
	LOSS [training: 0.09388397272344212 | validation: 0.12349275739611386]
	TIME [epoch: 8.49 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07711747270407991		[learning rate: 0.00014689]
	Learning Rate: 0.000146893
	LOSS [training: 0.07711747270407991 | validation: 0.12013526478111441]
	TIME [epoch: 8.49 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10338623213472968		[learning rate: 0.00014636]
	Learning Rate: 0.00014636
	LOSS [training: 0.10338623213472968 | validation: 0.18999907057916135]
	TIME [epoch: 8.51 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09010421294288695		[learning rate: 0.00014583]
	Learning Rate: 0.000145828
	LOSS [training: 0.09010421294288695 | validation: 0.11892629569274159]
	TIME [epoch: 8.49 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09359711998490902		[learning rate: 0.0001453]
	Learning Rate: 0.000145299
	LOSS [training: 0.09359711998490902 | validation: 0.14582036872761817]
	TIME [epoch: 8.49 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1057740218606699		[learning rate: 0.00014477]
	Learning Rate: 0.000144772
	LOSS [training: 0.1057740218606699 | validation: 0.11530864501650055]
	TIME [epoch: 8.48 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09099882929396999		[learning rate: 0.00014425]
	Learning Rate: 0.000144247
	LOSS [training: 0.09099882929396999 | validation: 0.12062260756004406]
	TIME [epoch: 8.5 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08428434188393799		[learning rate: 0.00014372]
	Learning Rate: 0.000143723
	LOSS [training: 0.08428434188393799 | validation: 0.134226911476577]
	TIME [epoch: 8.5 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07889409547562841		[learning rate: 0.0001432]
	Learning Rate: 0.000143201
	LOSS [training: 0.07889409547562841 | validation: 0.11196895937805756]
	TIME [epoch: 8.49 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08654794639482974		[learning rate: 0.00014268]
	Learning Rate: 0.000142682
	LOSS [training: 0.08654794639482974 | validation: 0.11656655673806615]
	TIME [epoch: 8.49 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09840428622621973		[learning rate: 0.00014216]
	Learning Rate: 0.000142164
	LOSS [training: 0.09840428622621973 | validation: 0.22848855146862485]
	TIME [epoch: 8.49 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20959774760659816		[learning rate: 0.00014165]
	Learning Rate: 0.000141648
	LOSS [training: 0.20959774760659816 | validation: 0.15286705158620784]
	TIME [epoch: 8.51 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09406900494926244		[learning rate: 0.00014113]
	Learning Rate: 0.000141134
	LOSS [training: 0.09406900494926244 | validation: 0.11481829574268207]
	TIME [epoch: 8.48 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0878204738406194		[learning rate: 0.00014062]
	Learning Rate: 0.000140622
	LOSS [training: 0.0878204738406194 | validation: 0.12122581644104737]
	TIME [epoch: 8.49 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08251498024102316		[learning rate: 0.00014011]
	Learning Rate: 0.000140112
	LOSS [training: 0.08251498024102316 | validation: 0.13812654220057502]
	TIME [epoch: 8.48 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14645046184987148		[learning rate: 0.0001396]
	Learning Rate: 0.000139603
	LOSS [training: 0.14645046184987148 | validation: 0.3600971477537544]
	TIME [epoch: 8.52 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11071142141128498		[learning rate: 0.0001391]
	Learning Rate: 0.000139096
	LOSS [training: 0.11071142141128498 | validation: 0.11168545225989543]
	TIME [epoch: 8.5 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08425204960912429		[learning rate: 0.00013859]
	Learning Rate: 0.000138592
	LOSS [training: 0.08425204960912429 | validation: 0.12783432939290806]
	TIME [epoch: 8.49 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09561554946833666		[learning rate: 0.00013809]
	Learning Rate: 0.000138089
	LOSS [training: 0.09561554946833666 | validation: 0.26050232727932243]
	TIME [epoch: 8.49 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13930690859429468		[learning rate: 0.00013759]
	Learning Rate: 0.000137587
	LOSS [training: 0.13930690859429468 | validation: 0.1388907947434529]
	TIME [epoch: 8.52 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08837470669722358		[learning rate: 0.00013709]
	Learning Rate: 0.000137088
	LOSS [training: 0.08837470669722358 | validation: 0.17574965767828626]
	TIME [epoch: 8.49 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1010908006477514		[learning rate: 0.00013659]
	Learning Rate: 0.000136591
	LOSS [training: 0.1010908006477514 | validation: 0.13428364804871895]
	TIME [epoch: 8.49 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11192654771116231		[learning rate: 0.00013609]
	Learning Rate: 0.000136095
	LOSS [training: 0.11192654771116231 | validation: 0.13458274577353085]
	TIME [epoch: 8.49 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11979998982427346		[learning rate: 0.0001356]
	Learning Rate: 0.000135601
	LOSS [training: 0.11979998982427346 | validation: 0.210707790248703]
	TIME [epoch: 8.5 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08960772725257593		[learning rate: 0.00013511]
	Learning Rate: 0.000135109
	LOSS [training: 0.08960772725257593 | validation: 0.16232615938890704]
	TIME [epoch: 8.5 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09396593022681879		[learning rate: 0.00013462]
	Learning Rate: 0.000134619
	LOSS [training: 0.09396593022681879 | validation: 0.12639449321244842]
	TIME [epoch: 8.49 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08445366737427099		[learning rate: 0.00013413]
	Learning Rate: 0.00013413
	LOSS [training: 0.08445366737427099 | validation: 0.14807196801879555]
	TIME [epoch: 8.49 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07999398655609699		[learning rate: 0.00013364]
	Learning Rate: 0.000133643
	LOSS [training: 0.07999398655609699 | validation: 0.10933318969954295]
	TIME [epoch: 8.49 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08079394474278352		[learning rate: 0.00013316]
	Learning Rate: 0.000133158
	LOSS [training: 0.08079394474278352 | validation: 0.09429945977246931]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_1288.pth
	Model improved!!!
EPOCH 1289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1271331945889865		[learning rate: 0.00013268]
	Learning Rate: 0.000132675
	LOSS [training: 0.1271331945889865 | validation: 0.1383828598335299]
	TIME [epoch: 8.5 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08663882920220675		[learning rate: 0.00013219]
	Learning Rate: 0.000132194
	LOSS [training: 0.08663882920220675 | validation: 0.12694305627642535]
	TIME [epoch: 8.49 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17802895468885377		[learning rate: 0.00013171]
	Learning Rate: 0.000131714
	LOSS [training: 0.17802895468885377 | validation: 0.13145590612993677]
	TIME [epoch: 8.5 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08543210879852113		[learning rate: 0.00013124]
	Learning Rate: 0.000131236
	LOSS [training: 0.08543210879852113 | validation: 0.11793950700608599]
	TIME [epoch: 8.52 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13846591445724685		[learning rate: 0.00013076]
	Learning Rate: 0.00013076
	LOSS [training: 0.13846591445724685 | validation: 0.13199077127439138]
	TIME [epoch: 8.5 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08106615236403042		[learning rate: 0.00013029]
	Learning Rate: 0.000130285
	LOSS [training: 0.08106615236403042 | validation: 0.10565149596884836]
	TIME [epoch: 8.5 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0752529036418789		[learning rate: 0.00012981]
	Learning Rate: 0.000129812
	LOSS [training: 0.0752529036418789 | validation: 0.11086580795135947]
	TIME [epoch: 8.49 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11845666779222283		[learning rate: 0.00012934]
	Learning Rate: 0.000129341
	LOSS [training: 0.11845666779222283 | validation: 0.16878355290278518]
	TIME [epoch: 8.51 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08317165489559274		[learning rate: 0.00012887]
	Learning Rate: 0.000128872
	LOSS [training: 0.08317165489559274 | validation: 0.11040073502515899]
	TIME [epoch: 8.5 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09906997767601547		[learning rate: 0.0001284]
	Learning Rate: 0.000128404
	LOSS [training: 0.09906997767601547 | validation: 0.14178430140276102]
	TIME [epoch: 8.49 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0858510188236906		[learning rate: 0.00012794]
	Learning Rate: 0.000127938
	LOSS [training: 0.0858510188236906 | validation: 0.17684819826779097]
	TIME [epoch: 8.49 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09675972757659035		[learning rate: 0.00012747]
	Learning Rate: 0.000127474
	LOSS [training: 0.09675972757659035 | validation: 0.1545160300400728]
	TIME [epoch: 8.51 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08435177360716453		[learning rate: 0.00012701]
	Learning Rate: 0.000127011
	LOSS [training: 0.08435177360716453 | validation: 0.1106218728080165]
	TIME [epoch: 8.5 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07844127564563856		[learning rate: 0.00012655]
	Learning Rate: 0.00012655
	LOSS [training: 0.07844127564563856 | validation: 0.12645212561545688]
	TIME [epoch: 8.49 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08222191718503136		[learning rate: 0.00012609]
	Learning Rate: 0.000126091
	LOSS [training: 0.08222191718503136 | validation: 0.11186876094362001]
	TIME [epoch: 8.5 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07453575118852995		[learning rate: 0.00012563]
	Learning Rate: 0.000125633
	LOSS [training: 0.07453575118852995 | validation: 0.19716800169251397]
	TIME [epoch: 8.49 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1284241301643386		[learning rate: 0.00012518]
	Learning Rate: 0.000125178
	LOSS [training: 0.1284241301643386 | validation: 0.13661476034392553]
	TIME [epoch: 8.52 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.104973144372451		[learning rate: 0.00012472]
	Learning Rate: 0.000124723
	LOSS [training: 0.104973144372451 | validation: 0.12120782546426453]
	TIME [epoch: 8.49 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07872793954843954		[learning rate: 0.00012427]
	Learning Rate: 0.000124271
	LOSS [training: 0.07872793954843954 | validation: 0.1211605304669382]
	TIME [epoch: 8.49 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0740316351381948		[learning rate: 0.00012382]
	Learning Rate: 0.00012382
	LOSS [training: 0.0740316351381948 | validation: 0.1378035843400117]
	TIME [epoch: 8.5 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07534257799524871		[learning rate: 0.00012337]
	Learning Rate: 0.00012337
	LOSS [training: 0.07534257799524871 | validation: 0.1212879408879079]
	TIME [epoch: 8.51 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09272100747616453		[learning rate: 0.00012292]
	Learning Rate: 0.000122923
	LOSS [training: 0.09272100747616453 | validation: 0.12544240376444005]
	TIME [epoch: 8.49 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08071681893125335		[learning rate: 0.00012248]
	Learning Rate: 0.000122476
	LOSS [training: 0.08071681893125335 | validation: 0.12830717622898483]
	TIME [epoch: 8.49 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07957511556042325		[learning rate: 0.00012203]
	Learning Rate: 0.000122032
	LOSS [training: 0.07957511556042325 | validation: 0.19897693988341802]
	TIME [epoch: 8.5 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11084677296908167		[learning rate: 0.00012159]
	Learning Rate: 0.000121589
	LOSS [training: 0.11084677296908167 | validation: 0.14016052033643572]
	TIME [epoch: 8.52 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09795506445874982		[learning rate: 0.00012115]
	Learning Rate: 0.000121148
	LOSS [training: 0.09795506445874982 | validation: 0.10973245352596664]
	TIME [epoch: 8.5 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07456118639828181		[learning rate: 0.00012071]
	Learning Rate: 0.000120708
	LOSS [training: 0.07456118639828181 | validation: 0.10966824461074337]
	TIME [epoch: 8.49 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07439489982447298		[learning rate: 0.00012027]
	Learning Rate: 0.00012027
	LOSS [training: 0.07439489982447298 | validation: 0.13209498660065488]
	TIME [epoch: 8.49 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08180350329036463		[learning rate: 0.00011983]
	Learning Rate: 0.000119834
	LOSS [training: 0.08180350329036463 | validation: 0.1134184082011972]
	TIME [epoch: 8.52 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0778211158347335		[learning rate: 0.0001194]
	Learning Rate: 0.000119399
	LOSS [training: 0.0778211158347335 | validation: 0.12875721585077296]
	TIME [epoch: 8.5 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06896289539101594		[learning rate: 0.00011897]
	Learning Rate: 0.000118966
	LOSS [training: 0.06896289539101594 | validation: 0.1066309131154223]
	TIME [epoch: 8.49 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07703166544360296		[learning rate: 0.00011853]
	Learning Rate: 0.000118534
	LOSS [training: 0.07703166544360296 | validation: 0.09941457309635618]
	TIME [epoch: 8.5 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0732782527415731		[learning rate: 0.0001181]
	Learning Rate: 0.000118104
	LOSS [training: 0.0732782527415731 | validation: 0.11784949894145497]
	TIME [epoch: 8.49 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07287923851644859		[learning rate: 0.00011767]
	Learning Rate: 0.000117675
	LOSS [training: 0.07287923851644859 | validation: 0.1371233263097121]
	TIME [epoch: 8.51 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07836658474665556		[learning rate: 0.00011725]
	Learning Rate: 0.000117248
	LOSS [training: 0.07836658474665556 | validation: 0.10207876420116219]
	TIME [epoch: 8.49 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08138726739407154		[learning rate: 0.00011682]
	Learning Rate: 0.000116822
	LOSS [training: 0.08138726739407154 | validation: 0.11491835771640783]
	TIME [epoch: 8.49 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07737286234385664		[learning rate: 0.0001164]
	Learning Rate: 0.000116398
	LOSS [training: 0.07737286234385664 | validation: 0.11985161456877301]
	TIME [epoch: 8.49 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07291897427298606		[learning rate: 0.00011598]
	Learning Rate: 0.000115976
	LOSS [training: 0.07291897427298606 | validation: 0.1457381127032498]
	TIME [epoch: 8.51 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11894046479515356		[learning rate: 0.00011556]
	Learning Rate: 0.000115555
	LOSS [training: 0.11894046479515356 | validation: 0.11719647233901345]
	TIME [epoch: 8.49 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06999623669313063		[learning rate: 0.00011514]
	Learning Rate: 0.000115136
	LOSS [training: 0.06999623669313063 | validation: 0.11031308943269622]
	TIME [epoch: 8.49 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07217738213617633		[learning rate: 0.00011472]
	Learning Rate: 0.000114718
	LOSS [training: 0.07217738213617633 | validation: 0.11225082922812094]
	TIME [epoch: 8.49 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07043073678842107		[learning rate: 0.0001143]
	Learning Rate: 0.000114302
	LOSS [training: 0.07043073678842107 | validation: 0.10460445172455143]
	TIME [epoch: 8.51 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07767863236842712		[learning rate: 0.00011389]
	Learning Rate: 0.000113887
	LOSS [training: 0.07767863236842712 | validation: 0.12332463632701238]
	TIME [epoch: 8.5 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08946636696446118		[learning rate: 0.00011347]
	Learning Rate: 0.000113474
	LOSS [training: 0.08946636696446118 | validation: 0.14937802612357964]
	TIME [epoch: 8.49 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0739232189951851		[learning rate: 0.00011306]
	Learning Rate: 0.000113062
	LOSS [training: 0.0739232189951851 | validation: 0.11327481020586362]
	TIME [epoch: 8.5 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08900055969612855		[learning rate: 0.00011265]
	Learning Rate: 0.000112651
	LOSS [training: 0.08900055969612855 | validation: 0.12340804737828251]
	TIME [epoch: 8.51 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10406048284177807		[learning rate: 0.00011224]
	Learning Rate: 0.000112243
	LOSS [training: 0.10406048284177807 | validation: 0.14115804354744566]
	TIME [epoch: 8.49 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10048838798809423		[learning rate: 0.00011184]
	Learning Rate: 0.000111835
	LOSS [training: 0.10048838798809423 | validation: 0.1181416901374324]
	TIME [epoch: 8.49 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07884120334887104		[learning rate: 0.00011143]
	Learning Rate: 0.000111429
	LOSS [training: 0.07884120334887104 | validation: 0.1144432212672074]
	TIME [epoch: 8.49 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08359867787775156		[learning rate: 0.00011103]
	Learning Rate: 0.000111025
	LOSS [training: 0.08359867787775156 | validation: 0.1300116554441157]
	TIME [epoch: 8.5 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07372985077176201		[learning rate: 0.00011062]
	Learning Rate: 0.000110622
	LOSS [training: 0.07372985077176201 | validation: 0.152122573140539]
	TIME [epoch: 8.52 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08900785522305919		[learning rate: 0.00011022]
	Learning Rate: 0.000110221
	LOSS [training: 0.08900785522305919 | validation: 0.109645361061465]
	TIME [epoch: 8.49 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07969721808610837		[learning rate: 0.00010982]
	Learning Rate: 0.000109821
	LOSS [training: 0.07969721808610837 | validation: 0.13445821391852925]
	TIME [epoch: 8.49 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0970633760109905		[learning rate: 0.00010942]
	Learning Rate: 0.000109422
	LOSS [training: 0.0970633760109905 | validation: 0.1276648667594559]
	TIME [epoch: 8.49 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0800140984045202		[learning rate: 0.00010903]
	Learning Rate: 0.000109025
	LOSS [training: 0.0800140984045202 | validation: 0.10353736028330715]
	TIME [epoch: 8.51 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08706558296217644		[learning rate: 0.00010863]
	Learning Rate: 0.000108629
	LOSS [training: 0.08706558296217644 | validation: 0.12167403712913391]
	TIME [epoch: 8.49 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11148878633972552		[learning rate: 0.00010824]
	Learning Rate: 0.000108235
	LOSS [training: 0.11148878633972552 | validation: 0.11853159707244414]
	TIME [epoch: 8.5 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0739956972424233		[learning rate: 0.00010784]
	Learning Rate: 0.000107842
	LOSS [training: 0.0739956972424233 | validation: 0.16103402610327253]
	TIME [epoch: 8.49 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08732023590865977		[learning rate: 0.00010745]
	Learning Rate: 0.000107451
	LOSS [training: 0.08732023590865977 | validation: 0.12483602369915797]
	TIME [epoch: 8.52 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07129421627070924		[learning rate: 0.00010706]
	Learning Rate: 0.000107061
	LOSS [training: 0.07129421627070924 | validation: 0.11896905794445906]
	TIME [epoch: 8.49 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07957292251853453		[learning rate: 0.00010667]
	Learning Rate: 0.000106673
	LOSS [training: 0.07957292251853453 | validation: 0.1733972000893896]
	TIME [epoch: 8.49 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08907028171499945		[learning rate: 0.00010629]
	Learning Rate: 0.000106285
	LOSS [training: 0.08907028171499945 | validation: 0.14801086658524834]
	TIME [epoch: 8.49 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0763615405268983		[learning rate: 0.0001059]
	Learning Rate: 0.0001059
	LOSS [training: 0.0763615405268983 | validation: 0.1311836365342527]
	TIME [epoch: 8.51 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12759220433280818		[learning rate: 0.00010552]
	Learning Rate: 0.000105515
	LOSS [training: 0.12759220433280818 | validation: 0.1194277649908472]
	TIME [epoch: 8.49 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08868495402689516		[learning rate: 0.00010513]
	Learning Rate: 0.000105132
	LOSS [training: 0.08868495402689516 | validation: 0.11483837844382289]
	TIME [epoch: 8.49 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09000706623907413		[learning rate: 0.00010475]
	Learning Rate: 0.000104751
	LOSS [training: 0.09000706623907413 | validation: 0.12078750708770414]
	TIME [epoch: 8.49 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08153610980707553		[learning rate: 0.00010437]
	Learning Rate: 0.000104371
	LOSS [training: 0.08153610980707553 | validation: 0.15775542174671295]
	TIME [epoch: 8.5 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08089577348421945		[learning rate: 0.00010399]
	Learning Rate: 0.000103992
	LOSS [training: 0.08089577348421945 | validation: 0.11431090491166111]
	TIME [epoch: 8.51 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07919920610792532		[learning rate: 0.00010361]
	Learning Rate: 0.000103615
	LOSS [training: 0.07919920610792532 | validation: 0.10871073248426102]
	TIME [epoch: 8.5 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07529598644363622		[learning rate: 0.00010324]
	Learning Rate: 0.000103239
	LOSS [training: 0.07529598644363622 | validation: 0.13899001786376858]
	TIME [epoch: 8.49 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09692056213070994		[learning rate: 0.00010286]
	Learning Rate: 0.000102864
	LOSS [training: 0.09692056213070994 | validation: 0.12144609966297204]
	TIME [epoch: 8.5 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0918913209296175		[learning rate: 0.00010249]
	Learning Rate: 0.000102491
	LOSS [training: 0.0918913209296175 | validation: 0.11384126303362038]
	TIME [epoch: 8.52 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08149720722890948		[learning rate: 0.00010212]
	Learning Rate: 0.000102119
	LOSS [training: 0.08149720722890948 | validation: 0.11207983411850786]
	TIME [epoch: 8.5 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07360925073342714		[learning rate: 0.00010175]
	Learning Rate: 0.000101748
	LOSS [training: 0.07360925073342714 | validation: 0.11953889624368519]
	TIME [epoch: 8.49 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09038170637087813		[learning rate: 0.00010138]
	Learning Rate: 0.000101379
	LOSS [training: 0.09038170637087813 | validation: 0.11394992841808871]
	TIME [epoch: 8.49 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08341252862904977		[learning rate: 0.00010101]
	Learning Rate: 0.000101011
	LOSS [training: 0.08341252862904977 | validation: 0.1173774334691016]
	TIME [epoch: 8.51 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07233884633530578		[learning rate: 0.00010064]
	Learning Rate: 0.000100644
	LOSS [training: 0.07233884633530578 | validation: 0.09665448735107189]
	TIME [epoch: 8.49 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08847031051770538		[learning rate: 0.00010028]
	Learning Rate: 0.000100279
	LOSS [training: 0.08847031051770538 | validation: 0.10969241057219419]
	TIME [epoch: 8.49 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07954808694647664		[learning rate: 9.9915e-05]
	Learning Rate: 9.99152e-05
	LOSS [training: 0.07954808694647664 | validation: 0.12621179228483775]
	TIME [epoch: 8.49 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07855712078067392		[learning rate: 9.9553e-05]
	Learning Rate: 9.95526e-05
	LOSS [training: 0.07855712078067392 | validation: 0.1301376451794257]
	TIME [epoch: 8.51 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0674559184814312		[learning rate: 9.9191e-05]
	Learning Rate: 9.91913e-05
	LOSS [training: 0.0674559184814312 | validation: 0.11651395243561907]
	TIME [epoch: 8.49 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07372141605069722		[learning rate: 9.8831e-05]
	Learning Rate: 9.88314e-05
	LOSS [training: 0.07372141605069722 | validation: 0.10920995209224352]
	TIME [epoch: 8.52 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08102011398717145		[learning rate: 9.8473e-05]
	Learning Rate: 9.84727e-05
	LOSS [training: 0.08102011398717145 | validation: 0.18743917805527865]
	TIME [epoch: 8.49 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08887667662639734		[learning rate: 9.8115e-05]
	Learning Rate: 9.81153e-05
	LOSS [training: 0.08887667662639734 | validation: 0.12063218900091083]
	TIME [epoch: 8.49 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0772846759198469		[learning rate: 9.7759e-05]
	Learning Rate: 9.77592e-05
	LOSS [training: 0.0772846759198469 | validation: 0.11419560980346563]
	TIME [epoch: 8.52 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0724874246472469		[learning rate: 9.7404e-05]
	Learning Rate: 9.74045e-05
	LOSS [training: 0.0724874246472469 | validation: 0.14647329257808261]
	TIME [epoch: 8.49 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08871078238264235		[learning rate: 9.7051e-05]
	Learning Rate: 9.7051e-05
	LOSS [training: 0.08871078238264235 | validation: 0.10606579721463935]
	TIME [epoch: 8.49 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0900282983561719		[learning rate: 9.6699e-05]
	Learning Rate: 9.66988e-05
	LOSS [training: 0.0900282983561719 | validation: 0.12494847098005768]
	TIME [epoch: 8.49 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10556057209320804		[learning rate: 9.6348e-05]
	Learning Rate: 9.63479e-05
	LOSS [training: 0.10556057209320804 | validation: 0.18024839383537014]
	TIME [epoch: 8.52 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08220876042187093		[learning rate: 9.5998e-05]
	Learning Rate: 9.59982e-05
	LOSS [training: 0.08220876042187093 | validation: 0.11828591392527539]
	TIME [epoch: 8.49 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06918816617594181		[learning rate: 9.565e-05]
	Learning Rate: 9.56499e-05
	LOSS [training: 0.06918816617594181 | validation: 0.1129017816999463]
	TIME [epoch: 8.49 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09512620361444504		[learning rate: 9.5303e-05]
	Learning Rate: 9.53027e-05
	LOSS [training: 0.09512620361444504 | validation: 0.1741719366817771]
	TIME [epoch: 8.49 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08076889704487625		[learning rate: 9.4957e-05]
	Learning Rate: 9.49569e-05
	LOSS [training: 0.08076889704487625 | validation: 0.10414640829586067]
	TIME [epoch: 8.52 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09070846988544631		[learning rate: 9.4612e-05]
	Learning Rate: 9.46122e-05
	LOSS [training: 0.09070846988544631 | validation: 0.11507170087200554]
	TIME [epoch: 8.49 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08603835834717011		[learning rate: 9.4269e-05]
	Learning Rate: 9.42689e-05
	LOSS [training: 0.08603835834717011 | validation: 0.11696227677489368]
	TIME [epoch: 8.5 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07495393360654184		[learning rate: 9.3927e-05]
	Learning Rate: 9.39268e-05
	LOSS [training: 0.07495393360654184 | validation: 0.11859138499644473]
	TIME [epoch: 8.49 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06853775974662088		[learning rate: 9.3586e-05]
	Learning Rate: 9.35859e-05
	LOSS [training: 0.06853775974662088 | validation: 0.11304443521421216]
	TIME [epoch: 8.51 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07035714107477323		[learning rate: 9.3246e-05]
	Learning Rate: 9.32463e-05
	LOSS [training: 0.07035714107477323 | validation: 0.12706168480350982]
	TIME [epoch: 8.5 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07429213402295058		[learning rate: 9.2908e-05]
	Learning Rate: 9.29079e-05
	LOSS [training: 0.07429213402295058 | validation: 0.1240249774183122]
	TIME [epoch: 8.49 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07314231510429912		[learning rate: 9.2571e-05]
	Learning Rate: 9.25707e-05
	LOSS [training: 0.07314231510429912 | validation: 0.12708863462465345]
	TIME [epoch: 8.49 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07795905260749927		[learning rate: 9.2235e-05]
	Learning Rate: 9.22348e-05
	LOSS [training: 0.07795905260749927 | validation: 0.12530314968213635]
	TIME [epoch: 8.49 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08497013425906409		[learning rate: 9.19e-05]
	Learning Rate: 9.19001e-05
	LOSS [training: 0.08497013425906409 | validation: 0.12948492086818855]
	TIME [epoch: 8.51 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08774434701652595		[learning rate: 9.1567e-05]
	Learning Rate: 9.15665e-05
	LOSS [training: 0.08774434701652595 | validation: 0.14776559904782338]
	TIME [epoch: 8.5 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14923297769956392		[learning rate: 9.1234e-05]
	Learning Rate: 9.12343e-05
	LOSS [training: 0.14923297769956392 | validation: 0.12505065180544345]
	TIME [epoch: 8.49 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08228750671812131		[learning rate: 9.0903e-05]
	Learning Rate: 9.09031e-05
	LOSS [training: 0.08228750671812131 | validation: 0.10422575794145301]
	TIME [epoch: 8.49 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07467577012256296		[learning rate: 9.0573e-05]
	Learning Rate: 9.05733e-05
	LOSS [training: 0.07467577012256296 | validation: 0.11943145318317697]
	TIME [epoch: 8.52 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07371826286398914		[learning rate: 9.0245e-05]
	Learning Rate: 9.02446e-05
	LOSS [training: 0.07371826286398914 | validation: 0.11445906690559098]
	TIME [epoch: 8.49 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07189894722558111		[learning rate: 8.9917e-05]
	Learning Rate: 8.99171e-05
	LOSS [training: 0.07189894722558111 | validation: 0.12489273862181097]
	TIME [epoch: 8.5 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08723900316964127		[learning rate: 8.9591e-05]
	Learning Rate: 8.95908e-05
	LOSS [training: 0.08723900316964127 | validation: 0.17274311436674672]
	TIME [epoch: 8.49 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09025852028677439		[learning rate: 8.9266e-05]
	Learning Rate: 8.92656e-05
	LOSS [training: 0.09025852028677439 | validation: 0.09727562329209669]
	TIME [epoch: 8.51 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06937657049433117		[learning rate: 8.8942e-05]
	Learning Rate: 8.89417e-05
	LOSS [training: 0.06937657049433117 | validation: 0.11104392350679822]
	TIME [epoch: 8.49 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0785570070711541		[learning rate: 8.8619e-05]
	Learning Rate: 8.86189e-05
	LOSS [training: 0.0785570070711541 | validation: 0.13085926126733638]
	TIME [epoch: 8.49 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07086203273312494		[learning rate: 8.8297e-05]
	Learning Rate: 8.82973e-05
	LOSS [training: 0.07086203273312494 | validation: 0.10095220394448857]
	TIME [epoch: 8.49 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07240823716855588		[learning rate: 8.7977e-05]
	Learning Rate: 8.79769e-05
	LOSS [training: 0.07240823716855588 | validation: 0.11440667474326693]
	TIME [epoch: 8.52 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07761269519002445		[learning rate: 8.7658e-05]
	Learning Rate: 8.76576e-05
	LOSS [training: 0.07761269519002445 | validation: 0.11667202962401041]
	TIME [epoch: 8.49 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06585210496864359		[learning rate: 8.7339e-05]
	Learning Rate: 8.73395e-05
	LOSS [training: 0.06585210496864359 | validation: 0.11487583297810522]
	TIME [epoch: 8.49 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07213897386943682		[learning rate: 8.7023e-05]
	Learning Rate: 8.70225e-05
	LOSS [training: 0.07213897386943682 | validation: 0.09813166784250164]
	TIME [epoch: 8.49 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06405717425113508		[learning rate: 8.6707e-05]
	Learning Rate: 8.67067e-05
	LOSS [training: 0.06405717425113508 | validation: 0.09525340808612046]
	TIME [epoch: 8.49 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07153753265210741		[learning rate: 8.6392e-05]
	Learning Rate: 8.63921e-05
	LOSS [training: 0.07153753265210741 | validation: 0.103968136170304]
	TIME [epoch: 8.51 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0804535962965016		[learning rate: 8.6079e-05]
	Learning Rate: 8.60785e-05
	LOSS [training: 0.0804535962965016 | validation: 0.15315812083440522]
	TIME [epoch: 8.49 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08048765440712594		[learning rate: 8.5766e-05]
	Learning Rate: 8.57661e-05
	LOSS [training: 0.08048765440712594 | validation: 0.11052370695617414]
	TIME [epoch: 8.49 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0734153567293804		[learning rate: 8.5455e-05]
	Learning Rate: 8.54549e-05
	LOSS [training: 0.0734153567293804 | validation: 0.10783794841804092]
	TIME [epoch: 8.5 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07809878242713261		[learning rate: 8.5145e-05]
	Learning Rate: 8.51448e-05
	LOSS [training: 0.07809878242713261 | validation: 0.13091896581637344]
	TIME [epoch: 8.52 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08593331640380755		[learning rate: 8.4836e-05]
	Learning Rate: 8.48358e-05
	LOSS [training: 0.08593331640380755 | validation: 0.10735997245008982]
	TIME [epoch: 8.49 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06811728409495979		[learning rate: 8.4528e-05]
	Learning Rate: 8.45279e-05
	LOSS [training: 0.06811728409495979 | validation: 0.12788353449672385]
	TIME [epoch: 8.49 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07614337474814617		[learning rate: 8.4221e-05]
	Learning Rate: 8.42211e-05
	LOSS [training: 0.07614337474814617 | validation: 0.15574265676532292]
	TIME [epoch: 8.5 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07726362986891334		[learning rate: 8.3916e-05]
	Learning Rate: 8.39155e-05
	LOSS [training: 0.07726362986891334 | validation: 0.12527461905642023]
	TIME [epoch: 8.51 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08303012932318851		[learning rate: 8.3611e-05]
	Learning Rate: 8.3611e-05
	LOSS [training: 0.08303012932318851 | validation: 0.14210145855196923]
	TIME [epoch: 8.49 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07372283747870721		[learning rate: 8.3308e-05]
	Learning Rate: 8.33075e-05
	LOSS [training: 0.07372283747870721 | validation: 0.12137688704793308]
	TIME [epoch: 8.48 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06705424119371137		[learning rate: 8.3005e-05]
	Learning Rate: 8.30052e-05
	LOSS [training: 0.06705424119371137 | validation: 0.1287572521937294]
	TIME [epoch: 8.49 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08184643631841636		[learning rate: 8.2704e-05]
	Learning Rate: 8.2704e-05
	LOSS [training: 0.08184643631841636 | validation: 0.11685920974389288]
	TIME [epoch: 8.51 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10559774351402824		[learning rate: 8.2404e-05]
	Learning Rate: 8.24038e-05
	LOSS [training: 0.10559774351402824 | validation: 0.10532581316575533]
	TIME [epoch: 8.49 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06711625230955463		[learning rate: 8.2105e-05]
	Learning Rate: 8.21048e-05
	LOSS [training: 0.06711625230955463 | validation: 0.10251873484170165]
	TIME [epoch: 8.48 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06890407868439312		[learning rate: 8.1807e-05]
	Learning Rate: 8.18068e-05
	LOSS [training: 0.06890407868439312 | validation: 0.10811810570780048]
	TIME [epoch: 8.48 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08639697657871812		[learning rate: 8.151e-05]
	Learning Rate: 8.15099e-05
	LOSS [training: 0.08639697657871812 | validation: 0.11454559992380564]
	TIME [epoch: 8.49 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06897386372245673		[learning rate: 8.1214e-05]
	Learning Rate: 8.12142e-05
	LOSS [training: 0.06897386372245673 | validation: 0.1002872719374861]
	TIME [epoch: 8.52 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06612079394496621		[learning rate: 8.0919e-05]
	Learning Rate: 8.09194e-05
	LOSS [training: 0.06612079394496621 | validation: 0.10975843975748906]
	TIME [epoch: 8.49 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07310025615876045		[learning rate: 8.0626e-05]
	Learning Rate: 8.06257e-05
	LOSS [training: 0.07310025615876045 | validation: 0.11436595038880203]
	TIME [epoch: 8.5 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0747760668500842		[learning rate: 8.0333e-05]
	Learning Rate: 8.03331e-05
	LOSS [training: 0.0747760668500842 | validation: 0.1177216371561732]
	TIME [epoch: 8.5 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07760762418337594		[learning rate: 8.0042e-05]
	Learning Rate: 8.00416e-05
	LOSS [training: 0.07760762418337594 | validation: 0.10124742821155663]
	TIME [epoch: 8.52 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0665777410130263		[learning rate: 7.9751e-05]
	Learning Rate: 7.97511e-05
	LOSS [training: 0.0665777410130263 | validation: 0.10180310319778106]
	TIME [epoch: 8.49 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07934150244355606		[learning rate: 7.9462e-05]
	Learning Rate: 7.94617e-05
	LOSS [training: 0.07934150244355606 | validation: 0.12270554531096659]
	TIME [epoch: 8.5 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07733327724267414		[learning rate: 7.9173e-05]
	Learning Rate: 7.91733e-05
	LOSS [training: 0.07733327724267414 | validation: 0.11732664155813227]
	TIME [epoch: 8.49 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06671913794236906		[learning rate: 7.8886e-05]
	Learning Rate: 7.8886e-05
	LOSS [training: 0.06671913794236906 | validation: 0.10078515282433832]
	TIME [epoch: 8.5 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07419450699618138		[learning rate: 7.86e-05]
	Learning Rate: 7.85997e-05
	LOSS [training: 0.07419450699618138 | validation: 0.15013454504266072]
	TIME [epoch: 8.5 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08748804594696397		[learning rate: 7.8315e-05]
	Learning Rate: 7.83145e-05
	LOSS [training: 0.08748804594696397 | validation: 0.28681831963704213]
	TIME [epoch: 8.48 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15444455043774627		[learning rate: 7.803e-05]
	Learning Rate: 7.80303e-05
	LOSS [training: 0.15444455043774627 | validation: 0.11873712301853305]
	TIME [epoch: 8.49 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07079914812267263		[learning rate: 7.7747e-05]
	Learning Rate: 7.77471e-05
	LOSS [training: 0.07079914812267263 | validation: 0.095883399009378]
	TIME [epoch: 8.5 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07229635597431347		[learning rate: 7.7465e-05]
	Learning Rate: 7.7465e-05
	LOSS [training: 0.07229635597431347 | validation: 0.09940956576973502]
	TIME [epoch: 8.5 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06449093865508623		[learning rate: 7.7184e-05]
	Learning Rate: 7.71838e-05
	LOSS [training: 0.06449093865508623 | validation: 0.11187096084423134]
	TIME [epoch: 8.49 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07968993806235591		[learning rate: 7.6904e-05]
	Learning Rate: 7.69037e-05
	LOSS [training: 0.07968993806235591 | validation: 0.09923369341717561]
	TIME [epoch: 8.48 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06643101985048787		[learning rate: 7.6625e-05]
	Learning Rate: 7.66246e-05
	LOSS [training: 0.06643101985048787 | validation: 0.1338009508474423]
	TIME [epoch: 8.5 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08059821142815887		[learning rate: 7.6347e-05]
	Learning Rate: 7.63466e-05
	LOSS [training: 0.08059821142815887 | validation: 0.09140524065933131]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_1441.pth
	Model improved!!!
EPOCH 1442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07305767966764862		[learning rate: 7.607e-05]
	Learning Rate: 7.60695e-05
	LOSS [training: 0.07305767966764862 | validation: 0.09293002164706402]
	TIME [epoch: 8.49 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07228877642658593		[learning rate: 7.5793e-05]
	Learning Rate: 7.57935e-05
	LOSS [training: 0.07228877642658593 | validation: 0.16594684723293454]
	TIME [epoch: 8.49 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08744323391533823		[learning rate: 7.5518e-05]
	Learning Rate: 7.55184e-05
	LOSS [training: 0.08744323391533823 | validation: 0.12774034461693026]
	TIME [epoch: 8.5 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06791087691099096		[learning rate: 7.5244e-05]
	Learning Rate: 7.52443e-05
	LOSS [training: 0.06791087691099096 | validation: 0.10868044453527882]
	TIME [epoch: 8.5 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08313548998232627		[learning rate: 7.4971e-05]
	Learning Rate: 7.49712e-05
	LOSS [training: 0.08313548998232627 | validation: 0.09462114569713623]
	TIME [epoch: 8.49 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09258683912764726		[learning rate: 7.4699e-05]
	Learning Rate: 7.46992e-05
	LOSS [training: 0.09258683912764726 | validation: 0.15146520654228077]
	TIME [epoch: 8.48 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07924634594073611		[learning rate: 7.4428e-05]
	Learning Rate: 7.44281e-05
	LOSS [training: 0.07924634594073611 | validation: 0.0985268509761205]
	TIME [epoch: 8.49 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06766073151337329		[learning rate: 7.4158e-05]
	Learning Rate: 7.4158e-05
	LOSS [training: 0.06766073151337329 | validation: 0.11249779638989346]
	TIME [epoch: 8.53 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07299082697094876		[learning rate: 7.3889e-05]
	Learning Rate: 7.38889e-05
	LOSS [training: 0.07299082697094876 | validation: 0.09764844194621902]
	TIME [epoch: 8.5 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07289850844834388		[learning rate: 7.3621e-05]
	Learning Rate: 7.36207e-05
	LOSS [training: 0.07289850844834388 | validation: 0.12711885666153988]
	TIME [epoch: 8.5 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08380437298586511		[learning rate: 7.3354e-05]
	Learning Rate: 7.33536e-05
	LOSS [training: 0.08380437298586511 | validation: 0.09719610898659813]
	TIME [epoch: 8.49 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07086332831477407		[learning rate: 7.3087e-05]
	Learning Rate: 7.30873e-05
	LOSS [training: 0.07086332831477407 | validation: 0.11758346447705754]
	TIME [epoch: 8.51 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07613404304543389		[learning rate: 7.2822e-05]
	Learning Rate: 7.28221e-05
	LOSS [training: 0.07613404304543389 | validation: 0.10755254959827179]
	TIME [epoch: 8.49 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07412928683313325		[learning rate: 7.2558e-05]
	Learning Rate: 7.25578e-05
	LOSS [training: 0.07412928683313325 | validation: 0.10613608487039275]
	TIME [epoch: 8.48 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06474527378122925		[learning rate: 7.2295e-05]
	Learning Rate: 7.22945e-05
	LOSS [training: 0.06474527378122925 | validation: 0.10700319432240156]
	TIME [epoch: 8.49 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07212068506156294		[learning rate: 7.2032e-05]
	Learning Rate: 7.20321e-05
	LOSS [training: 0.07212068506156294 | validation: 0.11677229663269321]
	TIME [epoch: 8.5 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06803975886247668		[learning rate: 7.1771e-05]
	Learning Rate: 7.17707e-05
	LOSS [training: 0.06803975886247668 | validation: 0.09834607558478203]
	TIME [epoch: 8.51 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.148012453103811		[learning rate: 7.151e-05]
	Learning Rate: 7.15103e-05
	LOSS [training: 0.148012453103811 | validation: 0.2969291960058552]
	TIME [epoch: 8.5 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11385253594775271		[learning rate: 7.1251e-05]
	Learning Rate: 7.12508e-05
	LOSS [training: 0.11385253594775271 | validation: 0.12112783610148822]
	TIME [epoch: 8.48 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07068944213799601		[learning rate: 7.0992e-05]
	Learning Rate: 7.09922e-05
	LOSS [training: 0.07068944213799601 | validation: 0.09026484337905263]
	TIME [epoch: 8.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_1461.pth
	Model improved!!!
EPOCH 1462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07138452233521117		[learning rate: 7.0735e-05]
	Learning Rate: 7.07345e-05
	LOSS [training: 0.07138452233521117 | validation: 0.1259154792083509]
	TIME [epoch: 8.51 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1159092303308481		[learning rate: 7.0478e-05]
	Learning Rate: 7.04778e-05
	LOSS [training: 0.1159092303308481 | validation: 0.13220645104062725]
	TIME [epoch: 8.49 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0753283140218852		[learning rate: 7.0222e-05]
	Learning Rate: 7.02221e-05
	LOSS [training: 0.0753283140218852 | validation: 0.09447374069049869]
	TIME [epoch: 8.49 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07542873279360758		[learning rate: 6.9967e-05]
	Learning Rate: 6.99672e-05
	LOSS [training: 0.07542873279360758 | validation: 0.12327626465913845]
	TIME [epoch: 8.49 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10960470641055739		[learning rate: 6.9713e-05]
	Learning Rate: 6.97133e-05
	LOSS [training: 0.10960470641055739 | validation: 0.1453502415512421]
	TIME [epoch: 8.51 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09056433887332857		[learning rate: 6.946e-05]
	Learning Rate: 6.94603e-05
	LOSS [training: 0.09056433887332857 | validation: 0.11603915997614847]
	TIME [epoch: 8.49 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07883323769469283		[learning rate: 6.9208e-05]
	Learning Rate: 6.92083e-05
	LOSS [training: 0.07883323769469283 | validation: 0.14538700000584762]
	TIME [epoch: 8.49 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0907041582232342		[learning rate: 6.8957e-05]
	Learning Rate: 6.89571e-05
	LOSS [training: 0.0907041582232342 | validation: 0.1089318031880277]
	TIME [epoch: 8.49 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07363810775767846		[learning rate: 6.8707e-05]
	Learning Rate: 6.87068e-05
	LOSS [training: 0.07363810775767846 | validation: 0.12080085017783651]
	TIME [epoch: 8.52 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07147261627545269		[learning rate: 6.8457e-05]
	Learning Rate: 6.84575e-05
	LOSS [training: 0.07147261627545269 | validation: 0.15021512558258768]
	TIME [epoch: 8.49 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08564809562447498		[learning rate: 6.8209e-05]
	Learning Rate: 6.82091e-05
	LOSS [training: 0.08564809562447498 | validation: 0.08892286558292195]
	TIME [epoch: 8.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_1472.pth
	Model improved!!!
EPOCH 1473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0837063389435946		[learning rate: 6.7962e-05]
	Learning Rate: 6.79615e-05
	LOSS [training: 0.0837063389435946 | validation: 0.0977525803626729]
	TIME [epoch: 8.5 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0696312157852042		[learning rate: 6.7715e-05]
	Learning Rate: 6.77149e-05
	LOSS [training: 0.0696312157852042 | validation: 0.10143310655224694]
	TIME [epoch: 8.52 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08431560498802369		[learning rate: 6.7469e-05]
	Learning Rate: 6.74692e-05
	LOSS [training: 0.08431560498802369 | validation: 0.1074229826410611]
	TIME [epoch: 8.5 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07449212871841401		[learning rate: 6.7224e-05]
	Learning Rate: 6.72243e-05
	LOSS [training: 0.07449212871841401 | validation: 0.12202946983602919]
	TIME [epoch: 8.49 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07656570546482515		[learning rate: 6.698e-05]
	Learning Rate: 6.69804e-05
	LOSS [training: 0.07656570546482515 | validation: 0.19344733886855836]
	TIME [epoch: 8.5 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08308142495100536		[learning rate: 6.6737e-05]
	Learning Rate: 6.67373e-05
	LOSS [training: 0.08308142495100536 | validation: 0.09925856906249063]
	TIME [epoch: 8.5 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0667432645874898		[learning rate: 6.6495e-05]
	Learning Rate: 6.64951e-05
	LOSS [training: 0.0667432645874898 | validation: 0.1242799961486445]
	TIME [epoch: 8.51 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07198950967584007		[learning rate: 6.6254e-05]
	Learning Rate: 6.62538e-05
	LOSS [training: 0.07198950967584007 | validation: 0.11046403022158538]
	TIME [epoch: 8.5 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06336724469094322		[learning rate: 6.6013e-05]
	Learning Rate: 6.60133e-05
	LOSS [training: 0.06336724469094322 | validation: 0.12461642370776208]
	TIME [epoch: 8.5 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07704767625425044		[learning rate: 6.5774e-05]
	Learning Rate: 6.57738e-05
	LOSS [training: 0.07704767625425044 | validation: 0.11403385376196655]
	TIME [epoch: 8.5 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07248795665733757		[learning rate: 6.5535e-05]
	Learning Rate: 6.55351e-05
	LOSS [training: 0.07248795665733757 | validation: 0.1082749611927333]
	TIME [epoch: 8.51 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07969507434762192		[learning rate: 6.5297e-05]
	Learning Rate: 6.52972e-05
	LOSS [training: 0.07969507434762192 | validation: 0.09495854037288784]
	TIME [epoch: 8.5 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06800947859353551		[learning rate: 6.506e-05]
	Learning Rate: 6.50603e-05
	LOSS [training: 0.06800947859353551 | validation: 0.1083650773603218]
	TIME [epoch: 8.5 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09267687794491926		[learning rate: 6.4824e-05]
	Learning Rate: 6.48242e-05
	LOSS [training: 0.09267687794491926 | validation: 0.16877088145872476]
	TIME [epoch: 8.49 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12734362699326282		[learning rate: 6.4589e-05]
	Learning Rate: 6.45889e-05
	LOSS [training: 0.12734362699326282 | validation: 0.14219529123768146]
	TIME [epoch: 8.52 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08803063340049243		[learning rate: 6.4354e-05]
	Learning Rate: 6.43545e-05
	LOSS [training: 0.08803063340049243 | validation: 0.10860848262417874]
	TIME [epoch: 8.5 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07170509258235562		[learning rate: 6.4121e-05]
	Learning Rate: 6.4121e-05
	LOSS [training: 0.07170509258235562 | validation: 0.09302872029936951]
	TIME [epoch: 8.5 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06540322790813909		[learning rate: 6.3888e-05]
	Learning Rate: 6.38883e-05
	LOSS [training: 0.06540322790813909 | validation: 0.14619426917535716]
	TIME [epoch: 8.49 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0722412154864583		[learning rate: 6.3656e-05]
	Learning Rate: 6.36564e-05
	LOSS [training: 0.0722412154864583 | validation: 0.131945241569916]
	TIME [epoch: 8.51 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07689669617397167		[learning rate: 6.3425e-05]
	Learning Rate: 6.34254e-05
	LOSS [training: 0.07689669617397167 | validation: 0.11259280222362508]
	TIME [epoch: 8.49 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06532477396835956		[learning rate: 6.3195e-05]
	Learning Rate: 6.31952e-05
	LOSS [training: 0.06532477396835956 | validation: 0.12047468442063997]
	TIME [epoch: 8.49 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08118725623251807		[learning rate: 6.2966e-05]
	Learning Rate: 6.29659e-05
	LOSS [training: 0.08118725623251807 | validation: 0.13402617481776305]
	TIME [epoch: 8.5 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07245291486819647		[learning rate: 6.2737e-05]
	Learning Rate: 6.27374e-05
	LOSS [training: 0.07245291486819647 | validation: 0.11263990357492289]
	TIME [epoch: 8.49 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06566181205921327		[learning rate: 6.251e-05]
	Learning Rate: 6.25097e-05
	LOSS [training: 0.06566181205921327 | validation: 0.1380296667578121]
	TIME [epoch: 8.52 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07510310218879242		[learning rate: 6.2283e-05]
	Learning Rate: 6.22828e-05
	LOSS [training: 0.07510310218879242 | validation: 0.1069918826584954]
	TIME [epoch: 8.49 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08697790709448025		[learning rate: 6.2057e-05]
	Learning Rate: 6.20568e-05
	LOSS [training: 0.08697790709448025 | validation: 0.11346686200754766]
	TIME [epoch: 8.5 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06801396027745489		[learning rate: 6.1832e-05]
	Learning Rate: 6.18316e-05
	LOSS [training: 0.06801396027745489 | validation: 0.09486619036263429]
	TIME [epoch: 8.51 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06332821571285958		[learning rate: 6.1607e-05]
	Learning Rate: 6.16072e-05
	LOSS [training: 0.06332821571285958 | validation: 0.10632846665790276]
	TIME [epoch: 8.52 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06709117431801662		[learning rate: 6.1384e-05]
	Learning Rate: 6.13836e-05
	LOSS [training: 0.06709117431801662 | validation: 0.14189121208736366]
	TIME [epoch: 8.5 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11512382381948676		[learning rate: 6.1161e-05]
	Learning Rate: 6.11609e-05
	LOSS [training: 0.11512382381948676 | validation: 0.10451415880082525]
	TIME [epoch: 8.5 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06785737987083483		[learning rate: 6.0939e-05]
	Learning Rate: 6.09389e-05
	LOSS [training: 0.06785737987083483 | validation: 0.10562797206996227]
	TIME [epoch: 8.49 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06572371150610175		[learning rate: 6.0718e-05]
	Learning Rate: 6.07178e-05
	LOSS [training: 0.06572371150610175 | validation: 0.11390739880106186]
	TIME [epoch: 8.51 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06718815861608465		[learning rate: 6.0497e-05]
	Learning Rate: 6.04974e-05
	LOSS [training: 0.06718815861608465 | validation: 0.11850757393695525]
	TIME [epoch: 8.49 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06653833933140883		[learning rate: 6.0278e-05]
	Learning Rate: 6.02779e-05
	LOSS [training: 0.06653833933140883 | validation: 0.10415370863067429]
	TIME [epoch: 8.48 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06015507020198331		[learning rate: 6.0059e-05]
	Learning Rate: 6.00591e-05
	LOSS [training: 0.06015507020198331 | validation: 0.09100415328878089]
	TIME [epoch: 8.49 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07007290665570083		[learning rate: 5.9841e-05]
	Learning Rate: 5.98412e-05
	LOSS [training: 0.07007290665570083 | validation: 0.10268209833661934]
	TIME [epoch: 8.51 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07267730413263536		[learning rate: 5.9624e-05]
	Learning Rate: 5.9624e-05
	LOSS [training: 0.07267730413263536 | validation: 0.10834056533144054]
	TIME [epoch: 8.49 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07019290274270132		[learning rate: 5.9408e-05]
	Learning Rate: 5.94076e-05
	LOSS [training: 0.07019290274270132 | validation: 0.11379032368535172]
	TIME [epoch: 8.49 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06293153362217		[learning rate: 5.9192e-05]
	Learning Rate: 5.9192e-05
	LOSS [training: 0.06293153362217 | validation: 0.11427381901888269]
	TIME [epoch: 8.49 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07624492397692569		[learning rate: 5.8977e-05]
	Learning Rate: 5.89772e-05
	LOSS [training: 0.07624492397692569 | validation: 0.10338817101283182]
	TIME [epoch: 8.49 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06598743884756599		[learning rate: 5.8763e-05]
	Learning Rate: 5.87632e-05
	LOSS [training: 0.06598743884756599 | validation: 0.11295089487127749]
	TIME [epoch: 8.51 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06857062064164712		[learning rate: 5.855e-05]
	Learning Rate: 5.85499e-05
	LOSS [training: 0.06857062064164712 | validation: 0.10011891118743062]
	TIME [epoch: 8.49 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07052506156603836		[learning rate: 5.8337e-05]
	Learning Rate: 5.83374e-05
	LOSS [training: 0.07052506156603836 | validation: 0.11649172748729367]
	TIME [epoch: 8.48 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06858496404857224		[learning rate: 5.8126e-05]
	Learning Rate: 5.81257e-05
	LOSS [training: 0.06858496404857224 | validation: 0.11059793374741238]
	TIME [epoch: 8.49 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06794843743553289		[learning rate: 5.7915e-05]
	Learning Rate: 5.79148e-05
	LOSS [training: 0.06794843743553289 | validation: 0.10980663140083512]
	TIME [epoch: 8.51 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07202885125365929		[learning rate: 5.7705e-05]
	Learning Rate: 5.77046e-05
	LOSS [training: 0.07202885125365929 | validation: 0.11465029670347057]
	TIME [epoch: 8.48 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0641786917786537		[learning rate: 5.7495e-05]
	Learning Rate: 5.74952e-05
	LOSS [training: 0.0641786917786537 | validation: 0.11006252675648089]
	TIME [epoch: 8.49 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07070907924650532		[learning rate: 5.7287e-05]
	Learning Rate: 5.72866e-05
	LOSS [training: 0.07070907924650532 | validation: 0.09017068618196196]
	TIME [epoch: 8.48 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07733718382746904		[learning rate: 5.7079e-05]
	Learning Rate: 5.70787e-05
	LOSS [training: 0.07733718382746904 | validation: 0.1718215876030996]
	TIME [epoch: 8.51 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09662076086164469		[learning rate: 5.6872e-05]
	Learning Rate: 5.68715e-05
	LOSS [training: 0.09662076086164469 | validation: 0.13453251798342392]
	TIME [epoch: 8.49 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.078114306120348		[learning rate: 5.6665e-05]
	Learning Rate: 5.66651e-05
	LOSS [training: 0.078114306120348 | validation: 0.09907906392821801]
	TIME [epoch: 8.49 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07357112667675551		[learning rate: 5.6459e-05]
	Learning Rate: 5.64595e-05
	LOSS [training: 0.07357112667675551 | validation: 0.10124904497125468]
	TIME [epoch: 8.49 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07089430033747204		[learning rate: 5.6255e-05]
	Learning Rate: 5.62546e-05
	LOSS [training: 0.07089430033747204 | validation: 0.10333858322690193]
	TIME [epoch: 8.51 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06799550611663532		[learning rate: 5.605e-05]
	Learning Rate: 5.60504e-05
	LOSS [training: 0.06799550611663532 | validation: 0.13198179683684036]
	TIME [epoch: 8.49 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07583313932348168		[learning rate: 5.5847e-05]
	Learning Rate: 5.5847e-05
	LOSS [training: 0.07583313932348168 | validation: 0.09372126779407344]
	TIME [epoch: 8.49 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0688056458411683		[learning rate: 5.5644e-05]
	Learning Rate: 5.56444e-05
	LOSS [training: 0.0688056458411683 | validation: 0.09356084378500108]
	TIME [epoch: 8.49 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06776736665632901		[learning rate: 5.5442e-05]
	Learning Rate: 5.54424e-05
	LOSS [training: 0.06776736665632901 | validation: 0.1106924736697078]
	TIME [epoch: 8.49 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06936065923412249		[learning rate: 5.5241e-05]
	Learning Rate: 5.52412e-05
	LOSS [training: 0.06936065923412249 | validation: 0.10604588204951601]
	TIME [epoch: 8.51 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07458470163983962		[learning rate: 5.5041e-05]
	Learning Rate: 5.50407e-05
	LOSS [training: 0.07458470163983962 | validation: 0.11604163391928266]
	TIME [epoch: 8.49 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0642033697780052		[learning rate: 5.4841e-05]
	Learning Rate: 5.4841e-05
	LOSS [training: 0.0642033697780052 | validation: 0.09858077369306312]
	TIME [epoch: 8.49 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06923912696333431		[learning rate: 5.4642e-05]
	Learning Rate: 5.4642e-05
	LOSS [training: 0.06923912696333431 | validation: 0.10573029645169811]
	TIME [epoch: 8.49 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06433382518370453		[learning rate: 5.4444e-05]
	Learning Rate: 5.44437e-05
	LOSS [training: 0.06433382518370453 | validation: 0.1201762709689711]
	TIME [epoch: 8.51 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.079849012787672		[learning rate: 5.4246e-05]
	Learning Rate: 5.42461e-05
	LOSS [training: 0.079849012787672 | validation: 0.11220368427967792]
	TIME [epoch: 8.49 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07643742975861868		[learning rate: 5.4049e-05]
	Learning Rate: 5.40492e-05
	LOSS [training: 0.07643742975861868 | validation: 0.16958265543845286]
	TIME [epoch: 8.49 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08802739842533928		[learning rate: 5.3853e-05]
	Learning Rate: 5.38531e-05
	LOSS [training: 0.08802739842533928 | validation: 0.11009088949973528]
	TIME [epoch: 8.48 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07678278965220248		[learning rate: 5.3658e-05]
	Learning Rate: 5.36577e-05
	LOSS [training: 0.07678278965220248 | validation: 0.10054960810240476]
	TIME [epoch: 8.51 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06843207128274595		[learning rate: 5.3463e-05]
	Learning Rate: 5.34629e-05
	LOSS [training: 0.06843207128274595 | validation: 0.10803244926109212]
	TIME [epoch: 8.49 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0669120753353589		[learning rate: 5.3269e-05]
	Learning Rate: 5.32689e-05
	LOSS [training: 0.0669120753353589 | validation: 0.10783560437111467]
	TIME [epoch: 8.49 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07270745274396709		[learning rate: 5.3076e-05]
	Learning Rate: 5.30756e-05
	LOSS [training: 0.07270745274396709 | validation: 0.11349274821130761]
	TIME [epoch: 8.49 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06459297528870149		[learning rate: 5.2883e-05]
	Learning Rate: 5.2883e-05
	LOSS [training: 0.06459297528870149 | validation: 0.11517904514949565]
	TIME [epoch: 8.51 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07457317539493868		[learning rate: 5.2691e-05]
	Learning Rate: 5.26911e-05
	LOSS [training: 0.07457317539493868 | validation: 0.09449476383606772]
	TIME [epoch: 8.49 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06585934247127925		[learning rate: 5.25e-05]
	Learning Rate: 5.24998e-05
	LOSS [training: 0.06585934247127925 | validation: 0.10724234465708618]
	TIME [epoch: 8.49 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0711751833798213		[learning rate: 5.2309e-05]
	Learning Rate: 5.23093e-05
	LOSS [training: 0.0711751833798213 | validation: 0.09870332223714122]
	TIME [epoch: 8.49 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06540516558445171		[learning rate: 5.2119e-05]
	Learning Rate: 5.21195e-05
	LOSS [training: 0.06540516558445171 | validation: 0.09686352435014306]
	TIME [epoch: 8.49 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0610836750177862		[learning rate: 5.193e-05]
	Learning Rate: 5.19303e-05
	LOSS [training: 0.0610836750177862 | validation: 0.0993837973393]
	TIME [epoch: 8.51 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060836635783749426		[learning rate: 5.1742e-05]
	Learning Rate: 5.17419e-05
	LOSS [training: 0.060836635783749426 | validation: 0.10091154366745195]
	TIME [epoch: 8.49 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06726869863283982		[learning rate: 5.1554e-05]
	Learning Rate: 5.15541e-05
	LOSS [training: 0.06726869863283982 | validation: 0.101212135768752]
	TIME [epoch: 8.49 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06511699005905917		[learning rate: 5.1367e-05]
	Learning Rate: 5.1367e-05
	LOSS [training: 0.06511699005905917 | validation: 0.09712198196844288]
	TIME [epoch: 8.49 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06283982712506578		[learning rate: 5.1181e-05]
	Learning Rate: 5.11806e-05
	LOSS [training: 0.06283982712506578 | validation: 0.10237512603522687]
	TIME [epoch: 8.51 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07033302289684257		[learning rate: 5.0995e-05]
	Learning Rate: 5.09949e-05
	LOSS [training: 0.07033302289684257 | validation: 0.11089882585032651]
	TIME [epoch: 8.49 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06476635895790664		[learning rate: 5.081e-05]
	Learning Rate: 5.08098e-05
	LOSS [training: 0.06476635895790664 | validation: 0.11594532540433575]
	TIME [epoch: 8.49 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06844511057318511		[learning rate: 5.0625e-05]
	Learning Rate: 5.06254e-05
	LOSS [training: 0.06844511057318511 | validation: 0.1134172163491308]
	TIME [epoch: 8.49 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07509735155006733		[learning rate: 5.0442e-05]
	Learning Rate: 5.04417e-05
	LOSS [training: 0.07509735155006733 | validation: 0.11134265345431854]
	TIME [epoch: 8.51 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06352872203984264		[learning rate: 5.0259e-05]
	Learning Rate: 5.02586e-05
	LOSS [training: 0.06352872203984264 | validation: 0.09371099209166993]
	TIME [epoch: 8.49 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07465540681095244		[learning rate: 5.0076e-05]
	Learning Rate: 5.00762e-05
	LOSS [training: 0.07465540681095244 | validation: 0.12730934589289322]
	TIME [epoch: 8.49 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0803241588501682		[learning rate: 4.9894e-05]
	Learning Rate: 4.98945e-05
	LOSS [training: 0.0803241588501682 | validation: 0.1267692049302454]
	TIME [epoch: 8.49 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07121647446863905		[learning rate: 4.9713e-05]
	Learning Rate: 4.97134e-05
	LOSS [training: 0.07121647446863905 | validation: 0.11065698115116882]
	TIME [epoch: 8.51 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06476892576230231		[learning rate: 4.9533e-05]
	Learning Rate: 4.9533e-05
	LOSS [training: 0.06476892576230231 | validation: 0.10082624553299108]
	TIME [epoch: 8.49 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06424474254222153		[learning rate: 4.9353e-05]
	Learning Rate: 4.93533e-05
	LOSS [training: 0.06424474254222153 | validation: 0.09762819601409271]
	TIME [epoch: 8.5 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06570321877471266		[learning rate: 4.9174e-05]
	Learning Rate: 4.91742e-05
	LOSS [training: 0.06570321877471266 | validation: 0.1287507430399519]
	TIME [epoch: 8.49 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12642904844188343		[learning rate: 4.8996e-05]
	Learning Rate: 4.89957e-05
	LOSS [training: 0.12642904844188343 | validation: 0.16267271784581255]
	TIME [epoch: 8.5 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07786787900919924		[learning rate: 4.8818e-05]
	Learning Rate: 4.88179e-05
	LOSS [training: 0.07786787900919924 | validation: 0.12871249659258976]
	TIME [epoch: 8.5 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07218116543724874		[learning rate: 4.8641e-05]
	Learning Rate: 4.86407e-05
	LOSS [training: 0.07218116543724874 | validation: 0.1519672278429352]
	TIME [epoch: 8.5 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07959219205178408		[learning rate: 4.8464e-05]
	Learning Rate: 4.84642e-05
	LOSS [training: 0.07959219205178408 | validation: 0.1313305441442465]
	TIME [epoch: 8.5 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07925460866608743		[learning rate: 4.8288e-05]
	Learning Rate: 4.82883e-05
	LOSS [training: 0.07925460866608743 | validation: 0.09537328014766303]
	TIME [epoch: 8.49 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06531065636137677		[learning rate: 4.8113e-05]
	Learning Rate: 4.81131e-05
	LOSS [training: 0.06531065636137677 | validation: 0.10970862122374311]
	TIME [epoch: 8.51 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07018153996892099		[learning rate: 4.7938e-05]
	Learning Rate: 4.79385e-05
	LOSS [training: 0.07018153996892099 | validation: 0.11083054078287727]
	TIME [epoch: 8.49 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06724983072710633		[learning rate: 4.7765e-05]
	Learning Rate: 4.77645e-05
	LOSS [training: 0.06724983072710633 | validation: 0.11890415155782892]
	TIME [epoch: 8.5 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07012370932503306		[learning rate: 4.7591e-05]
	Learning Rate: 4.75912e-05
	LOSS [training: 0.07012370932503306 | validation: 0.1004306471531043]
	TIME [epoch: 8.49 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06814289028728278		[learning rate: 4.7418e-05]
	Learning Rate: 4.74185e-05
	LOSS [training: 0.06814289028728278 | validation: 0.10188685222860538]
	TIME [epoch: 8.52 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06630457582868272		[learning rate: 4.7246e-05]
	Learning Rate: 4.72464e-05
	LOSS [training: 0.06630457582868272 | validation: 0.1044923424234861]
	TIME [epoch: 8.5 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07233927033374589		[learning rate: 4.7075e-05]
	Learning Rate: 4.70749e-05
	LOSS [training: 0.07233927033374589 | validation: 0.11452248479635563]
	TIME [epoch: 8.5 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06310308418898511		[learning rate: 4.6904e-05]
	Learning Rate: 4.69041e-05
	LOSS [training: 0.06310308418898511 | validation: 0.09694813244151987]
	TIME [epoch: 8.49 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06709361252194976		[learning rate: 4.6734e-05]
	Learning Rate: 4.67339e-05
	LOSS [training: 0.06709361252194976 | validation: 0.11942398023322306]
	TIME [epoch: 8.52 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06961454734196035		[learning rate: 4.6564e-05]
	Learning Rate: 4.65643e-05
	LOSS [training: 0.06961454734196035 | validation: 0.13220589345205083]
	TIME [epoch: 8.5 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09908947022991618		[learning rate: 4.6395e-05]
	Learning Rate: 4.63953e-05
	LOSS [training: 0.09908947022991618 | validation: 0.12832438107936417]
	TIME [epoch: 8.5 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08656184682660154		[learning rate: 4.6227e-05]
	Learning Rate: 4.62269e-05
	LOSS [training: 0.08656184682660154 | validation: 0.10876476455211818]
	TIME [epoch: 8.49 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09021283706251931		[learning rate: 4.6059e-05]
	Learning Rate: 4.60591e-05
	LOSS [training: 0.09021283706251931 | validation: 0.1488480790922227]
	TIME [epoch: 8.51 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07558748622983245		[learning rate: 4.5892e-05]
	Learning Rate: 4.5892e-05
	LOSS [training: 0.07558748622983245 | validation: 0.12776315427863624]
	TIME [epoch: 8.5 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07875697804609241		[learning rate: 4.5725e-05]
	Learning Rate: 4.57254e-05
	LOSS [training: 0.07875697804609241 | validation: 0.11025953140716227]
	TIME [epoch: 8.5 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06958029626431862		[learning rate: 4.556e-05]
	Learning Rate: 4.55595e-05
	LOSS [training: 0.06958029626431862 | validation: 0.10370876252787666]
	TIME [epoch: 8.49 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07110529359066582		[learning rate: 4.5394e-05]
	Learning Rate: 4.53942e-05
	LOSS [training: 0.07110529359066582 | validation: 0.09631123272982157]
	TIME [epoch: 8.49 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07441447969232169		[learning rate: 4.5229e-05]
	Learning Rate: 4.52294e-05
	LOSS [training: 0.07441447969232169 | validation: 0.09691208639260708]
	TIME [epoch: 8.51 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08382210782087685		[learning rate: 4.5065e-05]
	Learning Rate: 4.50653e-05
	LOSS [training: 0.08382210782087685 | validation: 0.1400043136700397]
	TIME [epoch: 8.49 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07586415018992074		[learning rate: 4.4902e-05]
	Learning Rate: 4.49017e-05
	LOSS [training: 0.07586415018992074 | validation: 0.1456434290257542]
	TIME [epoch: 8.49 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07354640835482293		[learning rate: 4.4739e-05]
	Learning Rate: 4.47388e-05
	LOSS [training: 0.07354640835482293 | validation: 0.11364483755173455]
	TIME [epoch: 8.5 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0714144194377899		[learning rate: 4.4576e-05]
	Learning Rate: 4.45764e-05
	LOSS [training: 0.0714144194377899 | validation: 0.10511839565022017]
	TIME [epoch: 8.51 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06453446876957894		[learning rate: 4.4415e-05]
	Learning Rate: 4.44147e-05
	LOSS [training: 0.06453446876957894 | validation: 0.11097299697984528]
	TIME [epoch: 8.5 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06773247963110686		[learning rate: 4.4253e-05]
	Learning Rate: 4.42535e-05
	LOSS [training: 0.06773247963110686 | validation: 0.09993771162605135]
	TIME [epoch: 8.5 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0717496913235344		[learning rate: 4.4093e-05]
	Learning Rate: 4.40929e-05
	LOSS [training: 0.0717496913235344 | validation: 0.10625262885247147]
	TIME [epoch: 8.5 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07814873453310398		[learning rate: 4.3933e-05]
	Learning Rate: 4.39329e-05
	LOSS [training: 0.07814873453310398 | validation: 0.136031945054994]
	TIME [epoch: 8.51 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06854184324197017		[learning rate: 4.3773e-05]
	Learning Rate: 4.37734e-05
	LOSS [training: 0.06854184324197017 | validation: 0.08837778909196047]
	TIME [epoch: 8.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_1594.pth
	Model improved!!!
EPOCH 1595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0659796896086317		[learning rate: 4.3615e-05]
	Learning Rate: 4.36146e-05
	LOSS [training: 0.0659796896086317 | validation: 0.08888358826244218]
	TIME [epoch: 8.5 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07722056183897003		[learning rate: 4.3456e-05]
	Learning Rate: 4.34563e-05
	LOSS [training: 0.07722056183897003 | validation: 0.12741358012730253]
	TIME [epoch: 8.5 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11180546572706		[learning rate: 4.3299e-05]
	Learning Rate: 4.32986e-05
	LOSS [training: 0.11180546572706 | validation: 0.12985120174856918]
	TIME [epoch: 8.51 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07226189643239647		[learning rate: 4.3141e-05]
	Learning Rate: 4.31415e-05
	LOSS [training: 0.07226189643239647 | validation: 0.09096576195321113]
	TIME [epoch: 8.5 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06438709139287568		[learning rate: 4.2985e-05]
	Learning Rate: 4.29849e-05
	LOSS [training: 0.06438709139287568 | validation: 0.0902051698986549]
	TIME [epoch: 8.49 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06684710283564028		[learning rate: 4.2829e-05]
	Learning Rate: 4.28289e-05
	LOSS [training: 0.06684710283564028 | validation: 0.10941227861665687]
	TIME [epoch: 8.49 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09642859933312017		[learning rate: 4.2673e-05]
	Learning Rate: 4.26735e-05
	LOSS [training: 0.09642859933312017 | validation: 0.11051631275327208]
	TIME [epoch: 8.49 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06797016350566899		[learning rate: 4.2519e-05]
	Learning Rate: 4.25186e-05
	LOSS [training: 0.06797016350566899 | validation: 0.09884257067890205]
	TIME [epoch: 8.52 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07212299106042425		[learning rate: 4.2364e-05]
	Learning Rate: 4.23643e-05
	LOSS [training: 0.07212299106042425 | validation: 0.12375643321407812]
	TIME [epoch: 8.49 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07104146311882518		[learning rate: 4.2211e-05]
	Learning Rate: 4.22106e-05
	LOSS [training: 0.07104146311882518 | validation: 0.10773021675587818]
	TIME [epoch: 8.48 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06860642221604867		[learning rate: 4.2057e-05]
	Learning Rate: 4.20574e-05
	LOSS [training: 0.06860642221604867 | validation: 0.10879186236880992]
	TIME [epoch: 8.49 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06681581440717535		[learning rate: 4.1905e-05]
	Learning Rate: 4.19047e-05
	LOSS [training: 0.06681581440717535 | validation: 0.09827007386117878]
	TIME [epoch: 8.51 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07303567425501077		[learning rate: 4.1753e-05]
	Learning Rate: 4.17527e-05
	LOSS [training: 0.07303567425501077 | validation: 0.12429707376957436]
	TIME [epoch: 8.49 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08071872319470202		[learning rate: 4.1601e-05]
	Learning Rate: 4.16012e-05
	LOSS [training: 0.08071872319470202 | validation: 0.12390957839838021]
	TIME [epoch: 8.49 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07215604949437734		[learning rate: 4.145e-05]
	Learning Rate: 4.14502e-05
	LOSS [training: 0.07215604949437734 | validation: 0.1018952143823926]
	TIME [epoch: 8.49 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07359580991236606		[learning rate: 4.13e-05]
	Learning Rate: 4.12998e-05
	LOSS [training: 0.07359580991236606 | validation: 0.10889279158472787]
	TIME [epoch: 8.52 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06978900960988126		[learning rate: 4.115e-05]
	Learning Rate: 4.11499e-05
	LOSS [training: 0.06978900960988126 | validation: 0.11819586221153588]
	TIME [epoch: 8.49 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0676040322527567		[learning rate: 4.1001e-05]
	Learning Rate: 4.10005e-05
	LOSS [training: 0.0676040322527567 | validation: 0.0957557921022228]
	TIME [epoch: 8.5 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08358849364040152		[learning rate: 4.0852e-05]
	Learning Rate: 4.08517e-05
	LOSS [training: 0.08358849364040152 | validation: 0.08761008307182369]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_1613.pth
	Model improved!!!
EPOCH 1614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06880618472285192		[learning rate: 4.0703e-05]
	Learning Rate: 4.07035e-05
	LOSS [training: 0.06880618472285192 | validation: 0.11098169365362809]
	TIME [epoch: 8.52 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07209118583194239		[learning rate: 4.0556e-05]
	Learning Rate: 4.05558e-05
	LOSS [training: 0.07209118583194239 | validation: 0.1000398127266234]
	TIME [epoch: 8.5 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08530398555517578		[learning rate: 4.0409e-05]
	Learning Rate: 4.04086e-05
	LOSS [training: 0.08530398555517578 | validation: 0.15512361314553938]
	TIME [epoch: 8.49 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0941812120883829		[learning rate: 4.0262e-05]
	Learning Rate: 4.0262e-05
	LOSS [training: 0.0941812120883829 | validation: 0.08107419159053703]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_1617.pth
	Model improved!!!
EPOCH 1618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07000851478355634		[learning rate: 4.0116e-05]
	Learning Rate: 4.01158e-05
	LOSS [training: 0.07000851478355634 | validation: 0.0885819021287749]
	TIME [epoch: 8.51 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06694297548844447		[learning rate: 3.997e-05]
	Learning Rate: 3.99703e-05
	LOSS [training: 0.06694297548844447 | validation: 0.09370142033617393]
	TIME [epoch: 8.51 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06967051338065501		[learning rate: 3.9825e-05]
	Learning Rate: 3.98252e-05
	LOSS [training: 0.06967051338065501 | validation: 0.09706141460351934]
	TIME [epoch: 8.48 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07890860809138522		[learning rate: 3.9681e-05]
	Learning Rate: 3.96807e-05
	LOSS [training: 0.07890860809138522 | validation: 0.11357035297591261]
	TIME [epoch: 8.49 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06986723010720512		[learning rate: 3.9537e-05]
	Learning Rate: 3.95367e-05
	LOSS [training: 0.06986723010720512 | validation: 0.08652517644263774]
	TIME [epoch: 8.49 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07693514620738263		[learning rate: 3.9393e-05]
	Learning Rate: 3.93932e-05
	LOSS [training: 0.07693514620738263 | validation: 0.10671622900773493]
	TIME [epoch: 8.52 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11244973098792847		[learning rate: 3.925e-05]
	Learning Rate: 3.92502e-05
	LOSS [training: 0.11244973098792847 | validation: 0.13748911626158378]
	TIME [epoch: 8.48 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08501686873382527		[learning rate: 3.9108e-05]
	Learning Rate: 3.91078e-05
	LOSS [training: 0.08501686873382527 | validation: 0.12431571260874705]
	TIME [epoch: 8.49 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07180566394521871		[learning rate: 3.8966e-05]
	Learning Rate: 3.89659e-05
	LOSS [training: 0.07180566394521871 | validation: 0.12793765257424305]
	TIME [epoch: 8.49 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0802758561530956		[learning rate: 3.8824e-05]
	Learning Rate: 3.88245e-05
	LOSS [training: 0.0802758561530956 | validation: 0.08940170369698831]
	TIME [epoch: 8.51 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06777263900405421		[learning rate: 3.8684e-05]
	Learning Rate: 3.86836e-05
	LOSS [training: 0.06777263900405421 | validation: 0.10176175244081356]
	TIME [epoch: 8.5 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07691858557615402		[learning rate: 3.8543e-05]
	Learning Rate: 3.85432e-05
	LOSS [training: 0.07691858557615402 | validation: 0.10140788469328607]
	TIME [epoch: 8.48 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0820498321701963		[learning rate: 3.8403e-05]
	Learning Rate: 3.84033e-05
	LOSS [training: 0.0820498321701963 | validation: 0.11637577654940919]
	TIME [epoch: 8.49 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08717229294754561		[learning rate: 3.8264e-05]
	Learning Rate: 3.82639e-05
	LOSS [training: 0.08717229294754561 | validation: 0.12263192084882885]
	TIME [epoch: 8.52 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07582436717169572		[learning rate: 3.8125e-05]
	Learning Rate: 3.81251e-05
	LOSS [training: 0.07582436717169572 | validation: 0.15978073035095972]
	TIME [epoch: 8.49 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12531729432273403		[learning rate: 3.7987e-05]
	Learning Rate: 3.79867e-05
	LOSS [training: 0.12531729432273403 | validation: 0.1572366916788643]
	TIME [epoch: 8.51 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08371902923166491		[learning rate: 3.7849e-05]
	Learning Rate: 3.78489e-05
	LOSS [training: 0.08371902923166491 | validation: 0.1401011825880656]
	TIME [epoch: 8.49 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1036093384197215		[learning rate: 3.7711e-05]
	Learning Rate: 3.77115e-05
	LOSS [training: 0.1036093384197215 | validation: 0.11097249365444993]
	TIME [epoch: 8.5 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07651213803093306		[learning rate: 3.7575e-05]
	Learning Rate: 3.75746e-05
	LOSS [training: 0.07651213803093306 | validation: 0.09466061789641018]
	TIME [epoch: 8.5 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07466481576979254		[learning rate: 3.7438e-05]
	Learning Rate: 3.74383e-05
	LOSS [training: 0.07466481576979254 | validation: 0.10240352003113354]
	TIME [epoch: 8.49 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0683739902839282		[learning rate: 3.7302e-05]
	Learning Rate: 3.73024e-05
	LOSS [training: 0.0683739902839282 | validation: 0.10401891095889765]
	TIME [epoch: 8.5 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07455674407956117		[learning rate: 3.7167e-05]
	Learning Rate: 3.7167e-05
	LOSS [training: 0.07455674407956117 | validation: 0.12462976386613474]
	TIME [epoch: 8.5 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08178912854715643		[learning rate: 3.7032e-05]
	Learning Rate: 3.70322e-05
	LOSS [training: 0.08178912854715643 | validation: 0.09667071833129035]
	TIME [epoch: 8.51 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07142416058173681		[learning rate: 3.6898e-05]
	Learning Rate: 3.68978e-05
	LOSS [training: 0.07142416058173681 | validation: 0.1011194356474126]
	TIME [epoch: 8.48 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07654442681823503		[learning rate: 3.6764e-05]
	Learning Rate: 3.67639e-05
	LOSS [training: 0.07654442681823503 | validation: 0.1260530687536413]
	TIME [epoch: 8.49 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07209692744135829		[learning rate: 3.663e-05]
	Learning Rate: 3.66304e-05
	LOSS [training: 0.07209692744135829 | validation: 0.09684143507438278]
	TIME [epoch: 8.49 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0661764683002793		[learning rate: 3.6498e-05]
	Learning Rate: 3.64975e-05
	LOSS [training: 0.0661764683002793 | validation: 0.10978111993816134]
	TIME [epoch: 8.52 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06646996872768372		[learning rate: 3.6365e-05]
	Learning Rate: 3.63651e-05
	LOSS [training: 0.06646996872768372 | validation: 0.09667167323338675]
	TIME [epoch: 8.5 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0653480693116636		[learning rate: 3.6233e-05]
	Learning Rate: 3.62331e-05
	LOSS [training: 0.0653480693116636 | validation: 0.1298048805781403]
	TIME [epoch: 8.49 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07160554848272221		[learning rate: 3.6102e-05]
	Learning Rate: 3.61016e-05
	LOSS [training: 0.07160554848272221 | validation: 0.11355947808962819]
	TIME [epoch: 8.49 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06886091046846048		[learning rate: 3.5971e-05]
	Learning Rate: 3.59706e-05
	LOSS [training: 0.06886091046846048 | validation: 0.10320503653595663]
	TIME [epoch: 8.51 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07262078895713857		[learning rate: 3.584e-05]
	Learning Rate: 3.584e-05
	LOSS [training: 0.07262078895713857 | validation: 0.1107875932923345]
	TIME [epoch: 8.49 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06850036539094227		[learning rate: 3.571e-05]
	Learning Rate: 3.571e-05
	LOSS [training: 0.06850036539094227 | validation: 0.10213824632183147]
	TIME [epoch: 8.5 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0681977924362736		[learning rate: 3.558e-05]
	Learning Rate: 3.55804e-05
	LOSS [training: 0.0681977924362736 | validation: 0.10448346093158789]
	TIME [epoch: 8.5 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061009478665672655		[learning rate: 3.5451e-05]
	Learning Rate: 3.54513e-05
	LOSS [training: 0.061009478665672655 | validation: 0.11372550091447785]
	TIME [epoch: 8.51 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06446739815211813		[learning rate: 3.5323e-05]
	Learning Rate: 3.53226e-05
	LOSS [training: 0.06446739815211813 | validation: 0.10616565411535091]
	TIME [epoch: 8.5 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07712317822591998		[learning rate: 3.5194e-05]
	Learning Rate: 3.51944e-05
	LOSS [training: 0.07712317822591998 | validation: 0.111062800367724]
	TIME [epoch: 8.49 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06807754135726843		[learning rate: 3.5067e-05]
	Learning Rate: 3.50667e-05
	LOSS [training: 0.06807754135726843 | validation: 0.10254610412437185]
	TIME [epoch: 8.49 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06328435438640008		[learning rate: 3.4939e-05]
	Learning Rate: 3.49394e-05
	LOSS [training: 0.06328435438640008 | validation: 0.09774567859916083]
	TIME [epoch: 8.5 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06557283894723798		[learning rate: 3.4813e-05]
	Learning Rate: 3.48126e-05
	LOSS [training: 0.06557283894723798 | validation: 0.09069471248684213]
	TIME [epoch: 8.52 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060356213111915955		[learning rate: 3.4686e-05]
	Learning Rate: 3.46863e-05
	LOSS [training: 0.060356213111915955 | validation: 0.09582151878732481]
	TIME [epoch: 8.5 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06340565063504121		[learning rate: 3.456e-05]
	Learning Rate: 3.45604e-05
	LOSS [training: 0.06340565063504121 | validation: 0.08703911629366014]
	TIME [epoch: 8.49 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06404303744894313		[learning rate: 3.4435e-05]
	Learning Rate: 3.4435e-05
	LOSS [training: 0.06404303744894313 | validation: 0.12027620627967447]
	TIME [epoch: 8.49 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06958127022052898		[learning rate: 3.431e-05]
	Learning Rate: 3.431e-05
	LOSS [training: 0.06958127022052898 | validation: 0.09645088454147756]
	TIME [epoch: 8.51 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06495860454863273		[learning rate: 3.4186e-05]
	Learning Rate: 3.41855e-05
	LOSS [training: 0.06495860454863273 | validation: 0.09462104664265254]
	TIME [epoch: 8.5 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06399294247351833		[learning rate: 3.4061e-05]
	Learning Rate: 3.40615e-05
	LOSS [training: 0.06399294247351833 | validation: 0.1007913619993252]
	TIME [epoch: 8.49 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06936774159191525		[learning rate: 3.3938e-05]
	Learning Rate: 3.39378e-05
	LOSS [training: 0.06936774159191525 | validation: 0.09375928660936972]
	TIME [epoch: 8.49 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05954842301694876		[learning rate: 3.3815e-05]
	Learning Rate: 3.38147e-05
	LOSS [training: 0.05954842301694876 | validation: 0.10876522293973143]
	TIME [epoch: 8.52 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.067243349588151		[learning rate: 3.3692e-05]
	Learning Rate: 3.3692e-05
	LOSS [training: 0.067243349588151 | validation: 0.09052840397692712]
	TIME [epoch: 8.5 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06092584293998312		[learning rate: 3.357e-05]
	Learning Rate: 3.35697e-05
	LOSS [training: 0.06092584293998312 | validation: 0.10379960293974633]
	TIME [epoch: 8.5 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060555527271737776		[learning rate: 3.3448e-05]
	Learning Rate: 3.34479e-05
	LOSS [training: 0.060555527271737776 | validation: 0.09318059914830645]
	TIME [epoch: 8.49 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06901267221735602		[learning rate: 3.3326e-05]
	Learning Rate: 3.33265e-05
	LOSS [training: 0.06901267221735602 | validation: 0.09684814365814307]
	TIME [epoch: 8.51 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061705617095849444		[learning rate: 3.3206e-05]
	Learning Rate: 3.32055e-05
	LOSS [training: 0.061705617095849444 | validation: 0.0952704559816415]
	TIME [epoch: 8.5 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06517493293626037		[learning rate: 3.3085e-05]
	Learning Rate: 3.3085e-05
	LOSS [training: 0.06517493293626037 | validation: 0.09090789081431344]
	TIME [epoch: 8.49 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06707941704425777		[learning rate: 3.2965e-05]
	Learning Rate: 3.2965e-05
	LOSS [training: 0.06707941704425777 | validation: 0.10992379674923536]
	TIME [epoch: 8.49 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06843594753421234		[learning rate: 3.2845e-05]
	Learning Rate: 3.28453e-05
	LOSS [training: 0.06843594753421234 | validation: 0.11563818134789663]
	TIME [epoch: 8.5 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06518206403391047		[learning rate: 3.2726e-05]
	Learning Rate: 3.27261e-05
	LOSS [training: 0.06518206403391047 | validation: 0.088544576192233]
	TIME [epoch: 8.52 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06278386384530603		[learning rate: 3.2607e-05]
	Learning Rate: 3.26074e-05
	LOSS [training: 0.06278386384530603 | validation: 0.09909814014303407]
	TIME [epoch: 8.49 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06974650971102679		[learning rate: 3.2489e-05]
	Learning Rate: 3.2489e-05
	LOSS [training: 0.06974650971102679 | validation: 0.10456613788834128]
	TIME [epoch: 8.49 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06289012516077734		[learning rate: 3.2371e-05]
	Learning Rate: 3.23711e-05
	LOSS [training: 0.06289012516077734 | validation: 0.09373577889127853]
	TIME [epoch: 8.5 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05695676913817512		[learning rate: 3.2254e-05]
	Learning Rate: 3.22537e-05
	LOSS [training: 0.05695676913817512 | validation: 0.09460484699364824]
	TIME [epoch: 8.52 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06670547524192738		[learning rate: 3.2137e-05]
	Learning Rate: 3.21366e-05
	LOSS [training: 0.06670547524192738 | validation: 0.09988144818193556]
	TIME [epoch: 8.5 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06454339948533389		[learning rate: 3.202e-05]
	Learning Rate: 3.202e-05
	LOSS [training: 0.06454339948533389 | validation: 0.09645539128027485]
	TIME [epoch: 8.48 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06560414373474585		[learning rate: 3.1904e-05]
	Learning Rate: 3.19038e-05
	LOSS [training: 0.06560414373474585 | validation: 0.09850176738820522]
	TIME [epoch: 8.48 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06436281654621898		[learning rate: 3.1788e-05]
	Learning Rate: 3.1788e-05
	LOSS [training: 0.06436281654621898 | validation: 0.10043936309221137]
	TIME [epoch: 8.52 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06438291862527684		[learning rate: 3.1673e-05]
	Learning Rate: 3.16726e-05
	LOSS [training: 0.06438291862527684 | validation: 0.11843487866637972]
	TIME [epoch: 8.5 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07040182058318573		[learning rate: 3.1558e-05]
	Learning Rate: 3.15577e-05
	LOSS [training: 0.07040182058318573 | validation: 0.10993956589632002]
	TIME [epoch: 8.51 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06272110504624528		[learning rate: 3.1443e-05]
	Learning Rate: 3.14432e-05
	LOSS [training: 0.06272110504624528 | validation: 0.111247570036]
	TIME [epoch: 8.5 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06243684031607155		[learning rate: 3.1329e-05]
	Learning Rate: 3.13291e-05
	LOSS [training: 0.06243684031607155 | validation: 0.10863921804863447]
	TIME [epoch: 8.51 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06812567616502829		[learning rate: 3.1215e-05]
	Learning Rate: 3.12154e-05
	LOSS [training: 0.06812567616502829 | validation: 0.129194869367311]
	TIME [epoch: 8.52 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07023286690199093		[learning rate: 3.1102e-05]
	Learning Rate: 3.11021e-05
	LOSS [training: 0.07023286690199093 | validation: 0.11649242280378691]
	TIME [epoch: 8.5 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06798269618396532		[learning rate: 3.0989e-05]
	Learning Rate: 3.09892e-05
	LOSS [training: 0.06798269618396532 | validation: 0.09970482950754117]
	TIME [epoch: 8.5 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06427687652173812		[learning rate: 3.0877e-05]
	Learning Rate: 3.08768e-05
	LOSS [training: 0.06427687652173812 | validation: 0.10630364464850671]
	TIME [epoch: 8.49 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06604588425851646		[learning rate: 3.0765e-05]
	Learning Rate: 3.07647e-05
	LOSS [training: 0.06604588425851646 | validation: 0.10319235013659395]
	TIME [epoch: 8.52 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06324096595285209		[learning rate: 3.0653e-05]
	Learning Rate: 3.0653e-05
	LOSS [training: 0.06324096595285209 | validation: 0.09709875279676458]
	TIME [epoch: 8.49 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0650436922921043		[learning rate: 3.0542e-05]
	Learning Rate: 3.05418e-05
	LOSS [training: 0.0650436922921043 | validation: 0.0980191053764544]
	TIME [epoch: 8.5 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06633701793936109		[learning rate: 3.0431e-05]
	Learning Rate: 3.0431e-05
	LOSS [training: 0.06633701793936109 | validation: 0.10607760427135286]
	TIME [epoch: 8.49 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0656409156901806		[learning rate: 3.0321e-05]
	Learning Rate: 3.03205e-05
	LOSS [training: 0.0656409156901806 | validation: 0.09708625036906485]
	TIME [epoch: 8.52 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0628302680914479		[learning rate: 3.0211e-05]
	Learning Rate: 3.02105e-05
	LOSS [training: 0.0628302680914479 | validation: 0.1009765913401067]
	TIME [epoch: 8.49 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07036782284082575		[learning rate: 3.0101e-05]
	Learning Rate: 3.01009e-05
	LOSS [training: 0.07036782284082575 | validation: 0.09725617870169188]
	TIME [epoch: 8.49 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06815714524883201		[learning rate: 2.9992e-05]
	Learning Rate: 2.99916e-05
	LOSS [training: 0.06815714524883201 | validation: 0.09872167969630655]
	TIME [epoch: 8.49 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07863929000443928		[learning rate: 2.9883e-05]
	Learning Rate: 2.98828e-05
	LOSS [training: 0.07863929000443928 | validation: 0.10828658113763362]
	TIME [epoch: 8.51 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07686105177645586		[learning rate: 2.9774e-05]
	Learning Rate: 2.97743e-05
	LOSS [training: 0.07686105177645586 | validation: 0.1518371830269506]
	TIME [epoch: 8.5 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09928130435708934		[learning rate: 2.9666e-05]
	Learning Rate: 2.96663e-05
	LOSS [training: 0.09928130435708934 | validation: 0.11114534704616515]
	TIME [epoch: 8.49 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06403095511852146		[learning rate: 2.9559e-05]
	Learning Rate: 2.95586e-05
	LOSS [training: 0.06403095511852146 | validation: 0.09753589370642998]
	TIME [epoch: 8.49 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07763345624722244		[learning rate: 2.9451e-05]
	Learning Rate: 2.94514e-05
	LOSS [training: 0.07763345624722244 | validation: 0.10200547717977754]
	TIME [epoch: 8.52 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06714952329877809		[learning rate: 2.9344e-05]
	Learning Rate: 2.93445e-05
	LOSS [training: 0.06714952329877809 | validation: 0.11245902234090899]
	TIME [epoch: 8.51 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07720532323487508		[learning rate: 2.9238e-05]
	Learning Rate: 2.9238e-05
	LOSS [training: 0.07720532323487508 | validation: 0.10534338778079158]
	TIME [epoch: 8.5 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06830890946484405		[learning rate: 2.9132e-05]
	Learning Rate: 2.91319e-05
	LOSS [training: 0.06830890946484405 | validation: 0.12526444487648053]
	TIME [epoch: 8.5 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06567614251294993		[learning rate: 2.9026e-05]
	Learning Rate: 2.90262e-05
	LOSS [training: 0.06567614251294993 | validation: 0.12367151056213546]
	TIME [epoch: 8.51 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06357653607838441		[learning rate: 2.8921e-05]
	Learning Rate: 2.89208e-05
	LOSS [training: 0.06357653607838441 | validation: 0.09746078210072472]
	TIME [epoch: 8.52 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06778321677110903		[learning rate: 2.8816e-05]
	Learning Rate: 2.88159e-05
	LOSS [training: 0.06778321677110903 | validation: 0.09540191765158713]
	TIME [epoch: 8.5 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06203771859777307		[learning rate: 2.8711e-05]
	Learning Rate: 2.87113e-05
	LOSS [training: 0.06203771859777307 | validation: 0.09985670619296935]
	TIME [epoch: 8.5 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06121779074347629		[learning rate: 2.8607e-05]
	Learning Rate: 2.86071e-05
	LOSS [training: 0.06121779074347629 | validation: 0.09779595951038285]
	TIME [epoch: 8.5 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07141748071986573		[learning rate: 2.8503e-05]
	Learning Rate: 2.85033e-05
	LOSS [training: 0.07141748071986573 | validation: 0.11546235067684771]
	TIME [epoch: 8.52 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06219261294620593		[learning rate: 2.84e-05]
	Learning Rate: 2.83998e-05
	LOSS [training: 0.06219261294620593 | validation: 0.0914322997127185]
	TIME [epoch: 8.5 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06458060661867654		[learning rate: 2.8297e-05]
	Learning Rate: 2.82968e-05
	LOSS [training: 0.06458060661867654 | validation: 0.12455323007968275]
	TIME [epoch: 8.5 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06475759749533494		[learning rate: 2.8194e-05]
	Learning Rate: 2.81941e-05
	LOSS [training: 0.06475759749533494 | validation: 0.0946774940319596]
	TIME [epoch: 8.5 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058422854408756476		[learning rate: 2.8092e-05]
	Learning Rate: 2.80918e-05
	LOSS [training: 0.058422854408756476 | validation: 0.10257294204380493]
	TIME [epoch: 8.51 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0647780969130906		[learning rate: 2.799e-05]
	Learning Rate: 2.79898e-05
	LOSS [training: 0.0647780969130906 | validation: 0.09982544293497148]
	TIME [epoch: 8.5 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062143920364810146		[learning rate: 2.7888e-05]
	Learning Rate: 2.78882e-05
	LOSS [training: 0.062143920364810146 | validation: 0.08998089406757435]
	TIME [epoch: 8.49 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06526878839763343		[learning rate: 2.7787e-05]
	Learning Rate: 2.7787e-05
	LOSS [training: 0.06526878839763343 | validation: 0.09853579146005434]
	TIME [epoch: 8.5 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06645204835759552		[learning rate: 2.7686e-05]
	Learning Rate: 2.76862e-05
	LOSS [training: 0.06645204835759552 | validation: 0.11041755626876401]
	TIME [epoch: 8.52 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06346227019834985		[learning rate: 2.7586e-05]
	Learning Rate: 2.75857e-05
	LOSS [training: 0.06346227019834985 | validation: 0.10258326877419413]
	TIME [epoch: 8.5 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06157547692831489		[learning rate: 2.7486e-05]
	Learning Rate: 2.74856e-05
	LOSS [training: 0.06157547692831489 | validation: 0.09722544225972704]
	TIME [epoch: 8.5 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07479279878186718		[learning rate: 2.7386e-05]
	Learning Rate: 2.73859e-05
	LOSS [training: 0.07479279878186718 | validation: 0.1159626236188336]
	TIME [epoch: 8.5 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0825894503451268		[learning rate: 2.7286e-05]
	Learning Rate: 2.72865e-05
	LOSS [training: 0.0825894503451268 | validation: 0.1123546650560108]
	TIME [epoch: 8.51 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06389254764379244		[learning rate: 2.7187e-05]
	Learning Rate: 2.71875e-05
	LOSS [training: 0.06389254764379244 | validation: 0.11216343616077316]
	TIME [epoch: 8.51 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06719773520676246		[learning rate: 2.7089e-05]
	Learning Rate: 2.70888e-05
	LOSS [training: 0.06719773520676246 | validation: 0.14216585756053568]
	TIME [epoch: 8.5 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06764224996577503		[learning rate: 2.699e-05]
	Learning Rate: 2.69905e-05
	LOSS [training: 0.06764224996577503 | validation: 0.11310032919273341]
	TIME [epoch: 8.5 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06442333039288932		[learning rate: 2.6893e-05]
	Learning Rate: 2.68925e-05
	LOSS [training: 0.06442333039288932 | validation: 0.10115687384987782]
	TIME [epoch: 8.5 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06576307595568537		[learning rate: 2.6795e-05]
	Learning Rate: 2.67949e-05
	LOSS [training: 0.06576307595568537 | validation: 0.09818494924090154]
	TIME [epoch: 8.52 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06408275977953841		[learning rate: 2.6698e-05]
	Learning Rate: 2.66977e-05
	LOSS [training: 0.06408275977953841 | validation: 0.0946055416035357]
	TIME [epoch: 8.5 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062200389638400876		[learning rate: 2.6601e-05]
	Learning Rate: 2.66008e-05
	LOSS [training: 0.062200389638400876 | validation: 0.0971137328180078]
	TIME [epoch: 8.5 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061984146880815175		[learning rate: 2.6504e-05]
	Learning Rate: 2.65043e-05
	LOSS [training: 0.061984146880815175 | validation: 0.10361605690926379]
	TIME [epoch: 8.49 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06978611531947151		[learning rate: 2.6408e-05]
	Learning Rate: 2.64081e-05
	LOSS [training: 0.06978611531947151 | validation: 0.12326175516194834]
	TIME [epoch: 8.52 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07181808770377701		[learning rate: 2.6312e-05]
	Learning Rate: 2.63123e-05
	LOSS [training: 0.07181808770377701 | validation: 0.10932310700483858]
	TIME [epoch: 8.51 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06551845778328075		[learning rate: 2.6217e-05]
	Learning Rate: 2.62168e-05
	LOSS [training: 0.06551845778328075 | validation: 0.10577942996369516]
	TIME [epoch: 8.5 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06594155742214729		[learning rate: 2.6122e-05]
	Learning Rate: 2.61216e-05
	LOSS [training: 0.06594155742214729 | validation: 0.09938321884071008]
	TIME [epoch: 8.5 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05913068732232365		[learning rate: 2.6027e-05]
	Learning Rate: 2.60268e-05
	LOSS [training: 0.05913068732232365 | validation: 0.09857383189556533]
	TIME [epoch: 8.51 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06292781310962811		[learning rate: 2.5932e-05]
	Learning Rate: 2.59324e-05
	LOSS [training: 0.06292781310962811 | validation: 0.09462359191230647]
	TIME [epoch: 8.5 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06547535696375366		[learning rate: 2.5838e-05]
	Learning Rate: 2.58383e-05
	LOSS [training: 0.06547535696375366 | validation: 0.10751542138131985]
	TIME [epoch: 8.5 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06666458843930581		[learning rate: 2.5744e-05]
	Learning Rate: 2.57445e-05
	LOSS [training: 0.06666458843930581 | validation: 0.10425134832286445]
	TIME [epoch: 8.5 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06269248263411932		[learning rate: 2.5651e-05]
	Learning Rate: 2.56511e-05
	LOSS [training: 0.06269248263411932 | validation: 0.10332130085509744]
	TIME [epoch: 8.5 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0762366935832705		[learning rate: 2.5558e-05]
	Learning Rate: 2.5558e-05
	LOSS [training: 0.0762366935832705 | validation: 0.11946856089845304]
	TIME [epoch: 8.51 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07583788640175596		[learning rate: 2.5465e-05]
	Learning Rate: 2.54652e-05
	LOSS [training: 0.07583788640175596 | validation: 0.11239203138393614]
	TIME [epoch: 8.48 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07151373714513821		[learning rate: 2.5373e-05]
	Learning Rate: 2.53728e-05
	LOSS [training: 0.07151373714513821 | validation: 0.11915012017836119]
	TIME [epoch: 8.49 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06879976124781732		[learning rate: 2.5281e-05]
	Learning Rate: 2.52807e-05
	LOSS [training: 0.06879976124781732 | validation: 0.09567664324762937]
	TIME [epoch: 8.5 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06430919720593038		[learning rate: 2.5189e-05]
	Learning Rate: 2.5189e-05
	LOSS [training: 0.06430919720593038 | validation: 0.0818614075914538]
	TIME [epoch: 8.51 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06491788060621416		[learning rate: 2.5098e-05]
	Learning Rate: 2.50976e-05
	LOSS [training: 0.06491788060621416 | validation: 0.09534408065589456]
	TIME [epoch: 8.49 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06298592960814309		[learning rate: 2.5006e-05]
	Learning Rate: 2.50065e-05
	LOSS [training: 0.06298592960814309 | validation: 0.10036153773604199]
	TIME [epoch: 8.5 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06163159949064765		[learning rate: 2.4916e-05]
	Learning Rate: 2.49157e-05
	LOSS [training: 0.06163159949064765 | validation: 0.09887464602860263]
	TIME [epoch: 8.5 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06089958801263705		[learning rate: 2.4825e-05]
	Learning Rate: 2.48253e-05
	LOSS [training: 0.06089958801263705 | validation: 0.08699671070606872]
	TIME [epoch: 8.52 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06501497288911892		[learning rate: 2.4735e-05]
	Learning Rate: 2.47352e-05
	LOSS [training: 0.06501497288911892 | validation: 0.10415274755700712]
	TIME [epoch: 8.5 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0625208567034433		[learning rate: 2.4645e-05]
	Learning Rate: 2.46455e-05
	LOSS [training: 0.0625208567034433 | validation: 0.10487996395619692]
	TIME [epoch: 8.5 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058398387357608696		[learning rate: 2.4556e-05]
	Learning Rate: 2.4556e-05
	LOSS [training: 0.058398387357608696 | validation: 0.08706197911253935]
	TIME [epoch: 8.5 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0615956573247531		[learning rate: 2.4467e-05]
	Learning Rate: 2.44669e-05
	LOSS [training: 0.0615956573247531 | validation: 0.10786552451129654]
	TIME [epoch: 8.51 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07270971362259804		[learning rate: 2.4378e-05]
	Learning Rate: 2.43781e-05
	LOSS [training: 0.07270971362259804 | validation: 0.13293448729691618]
	TIME [epoch: 8.49 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07162940659507663		[learning rate: 2.429e-05]
	Learning Rate: 2.42896e-05
	LOSS [training: 0.07162940659507663 | validation: 0.10549977273956858]
	TIME [epoch: 8.5 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060127605894161364		[learning rate: 2.4201e-05]
	Learning Rate: 2.42015e-05
	LOSS [training: 0.060127605894161364 | validation: 0.1102043269357042]
	TIME [epoch: 8.5 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0646107703787984		[learning rate: 2.4114e-05]
	Learning Rate: 2.41137e-05
	LOSS [training: 0.0646107703787984 | validation: 0.10047886315592774]
	TIME [epoch: 8.5 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05813983502459028		[learning rate: 2.4026e-05]
	Learning Rate: 2.40262e-05
	LOSS [training: 0.05813983502459028 | validation: 0.09683095876566743]
	TIME [epoch: 8.52 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05849086113069897		[learning rate: 2.3939e-05]
	Learning Rate: 2.3939e-05
	LOSS [training: 0.05849086113069897 | validation: 0.09478800864438128]
	TIME [epoch: 8.5 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06281127487494201		[learning rate: 2.3852e-05]
	Learning Rate: 2.38521e-05
	LOSS [training: 0.06281127487494201 | validation: 0.10148123273636804]
	TIME [epoch: 8.5 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06336295145298636		[learning rate: 2.3766e-05]
	Learning Rate: 2.37655e-05
	LOSS [training: 0.06336295145298636 | validation: 0.0989297709239901]
	TIME [epoch: 8.5 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06301449719765181		[learning rate: 2.3679e-05]
	Learning Rate: 2.36793e-05
	LOSS [training: 0.06301449719765181 | validation: 0.09755441377651075]
	TIME [epoch: 8.53 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05945718226985317		[learning rate: 2.3593e-05]
	Learning Rate: 2.35933e-05
	LOSS [training: 0.05945718226985317 | validation: 0.10066143396643734]
	TIME [epoch: 8.5 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06240670513160969		[learning rate: 2.3508e-05]
	Learning Rate: 2.35077e-05
	LOSS [training: 0.06240670513160969 | validation: 0.10403415583698561]
	TIME [epoch: 8.51 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06715942653611648		[learning rate: 2.3422e-05]
	Learning Rate: 2.34224e-05
	LOSS [training: 0.06715942653611648 | validation: 0.11447036461557934]
	TIME [epoch: 8.5 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06123287301643562		[learning rate: 2.3337e-05]
	Learning Rate: 2.33374e-05
	LOSS [training: 0.06123287301643562 | validation: 0.10633969216651887]
	TIME [epoch: 8.52 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05968465117096515		[learning rate: 2.3253e-05]
	Learning Rate: 2.32527e-05
	LOSS [training: 0.05968465117096515 | validation: 0.09009628949369544]
	TIME [epoch: 8.5 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058722434052693936		[learning rate: 2.3168e-05]
	Learning Rate: 2.31683e-05
	LOSS [training: 0.058722434052693936 | validation: 0.09790590463654578]
	TIME [epoch: 8.49 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06545649659581546		[learning rate: 2.3084e-05]
	Learning Rate: 2.30843e-05
	LOSS [training: 0.06545649659581546 | validation: 0.11212080934264239]
	TIME [epoch: 8.5 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06597511548249584		[learning rate: 2.3e-05]
	Learning Rate: 2.30005e-05
	LOSS [training: 0.06597511548249584 | validation: 0.11241322396276879]
	TIME [epoch: 8.52 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06548034891178431		[learning rate: 2.2917e-05]
	Learning Rate: 2.2917e-05
	LOSS [training: 0.06548034891178431 | validation: 0.10011919009938916]
	TIME [epoch: 8.5 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06651668476794696		[learning rate: 2.2834e-05]
	Learning Rate: 2.28338e-05
	LOSS [training: 0.06651668476794696 | validation: 0.10864128107517662]
	TIME [epoch: 8.5 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06532992371335225		[learning rate: 2.2751e-05]
	Learning Rate: 2.2751e-05
	LOSS [training: 0.06532992371335225 | validation: 0.10054010506713892]
	TIME [epoch: 8.49 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06437370138873959		[learning rate: 2.2668e-05]
	Learning Rate: 2.26684e-05
	LOSS [training: 0.06437370138873959 | validation: 0.0929336414637226]
	TIME [epoch: 8.52 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05946219270844057		[learning rate: 2.2586e-05]
	Learning Rate: 2.25862e-05
	LOSS [training: 0.05946219270844057 | validation: 0.0975064925986088]
	TIME [epoch: 8.51 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06285327210977194		[learning rate: 2.2504e-05]
	Learning Rate: 2.25042e-05
	LOSS [training: 0.06285327210977194 | validation: 0.0996519897912301]
	TIME [epoch: 8.5 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0627546960270336		[learning rate: 2.2423e-05]
	Learning Rate: 2.24225e-05
	LOSS [training: 0.0627546960270336 | validation: 0.09860774504705577]
	TIME [epoch: 8.49 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059945908185648725		[learning rate: 2.2341e-05]
	Learning Rate: 2.23411e-05
	LOSS [training: 0.059945908185648725 | validation: 0.11330712713673363]
	TIME [epoch: 8.5 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06743339339048124		[learning rate: 2.226e-05]
	Learning Rate: 2.22601e-05
	LOSS [training: 0.06743339339048124 | validation: 0.10340936598665629]
	TIME [epoch: 8.5 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05569440358318346		[learning rate: 2.2179e-05]
	Learning Rate: 2.21793e-05
	LOSS [training: 0.05569440358318346 | validation: 0.08858581507257152]
	TIME [epoch: 8.49 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06167679584494005		[learning rate: 2.2099e-05]
	Learning Rate: 2.20988e-05
	LOSS [training: 0.06167679584494005 | validation: 0.07765087517780445]
	TIME [epoch: 8.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study204/model_tr_study204_r3_20240219_233848/states/model_tr_study204_1782.pth
	Model improved!!!
EPOCH 1783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06568072342743012		[learning rate: 2.2019e-05]
	Learning Rate: 2.20186e-05
	LOSS [training: 0.06568072342743012 | validation: 0.08119371872802165]
	TIME [epoch: 8.49 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06539627807409602		[learning rate: 2.1939e-05]
	Learning Rate: 2.19387e-05
	LOSS [training: 0.06539627807409602 | validation: 0.08655217227004527]
	TIME [epoch: 8.51 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06714119877623127		[learning rate: 2.1859e-05]
	Learning Rate: 2.18591e-05
	LOSS [training: 0.06714119877623127 | validation: 0.10223303556876454]
	TIME [epoch: 8.51 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06180171083277895		[learning rate: 2.178e-05]
	Learning Rate: 2.17797e-05
	LOSS [training: 0.06180171083277895 | validation: 0.09718169710790234]
	TIME [epoch: 8.5 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05950342210874441		[learning rate: 2.1701e-05]
	Learning Rate: 2.17007e-05
	LOSS [training: 0.05950342210874441 | validation: 0.09041774463227806]
	TIME [epoch: 8.5 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06231616061036356		[learning rate: 2.1622e-05]
	Learning Rate: 2.16219e-05
	LOSS [training: 0.06231616061036356 | validation: 0.0799780547370734]
	TIME [epoch: 8.53 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06299116015373118		[learning rate: 2.1543e-05]
	Learning Rate: 2.15435e-05
	LOSS [training: 0.06299116015373118 | validation: 0.09817745827283293]
	TIME [epoch: 8.51 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06161976847916628		[learning rate: 2.1465e-05]
	Learning Rate: 2.14653e-05
	LOSS [training: 0.06161976847916628 | validation: 0.08714498905135248]
	TIME [epoch: 8.51 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05982026518856456		[learning rate: 2.1387e-05]
	Learning Rate: 2.13874e-05
	LOSS [training: 0.05982026518856456 | validation: 0.08305276315801537]
	TIME [epoch: 8.5 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06441550654641982		[learning rate: 2.131e-05]
	Learning Rate: 2.13098e-05
	LOSS [training: 0.06441550654641982 | validation: 0.09715059304459492]
	TIME [epoch: 8.52 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06188092013300102		[learning rate: 2.1232e-05]
	Learning Rate: 2.12325e-05
	LOSS [training: 0.06188092013300102 | validation: 0.11483410078992573]
	TIME [epoch: 8.52 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06749545726582863		[learning rate: 2.1155e-05]
	Learning Rate: 2.11554e-05
	LOSS [training: 0.06749545726582863 | validation: 0.09699597826496462]
	TIME [epoch: 8.5 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07061810148803585		[learning rate: 2.1079e-05]
	Learning Rate: 2.10786e-05
	LOSS [training: 0.07061810148803585 | validation: 0.09444527475996133]
	TIME [epoch: 8.5 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06187174055708071		[learning rate: 2.1002e-05]
	Learning Rate: 2.10021e-05
	LOSS [training: 0.06187174055708071 | validation: 0.0992361420039273]
	TIME [epoch: 8.51 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060166048296654964		[learning rate: 2.0926e-05]
	Learning Rate: 2.09259e-05
	LOSS [training: 0.060166048296654964 | validation: 0.1075614429082716]
	TIME [epoch: 8.51 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058223621577314214		[learning rate: 2.085e-05]
	Learning Rate: 2.085e-05
	LOSS [training: 0.058223621577314214 | validation: 0.0979895971797615]
	TIME [epoch: 8.51 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061309362758403374		[learning rate: 2.0774e-05]
	Learning Rate: 2.07743e-05
	LOSS [training: 0.061309362758403374 | validation: 0.0974699561035206]
	TIME [epoch: 8.51 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06859515710713474		[learning rate: 2.0699e-05]
	Learning Rate: 2.06989e-05
	LOSS [training: 0.06859515710713474 | validation: 0.0973112493232833]
	TIME [epoch: 8.51 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06120304593641054		[learning rate: 2.0624e-05]
	Learning Rate: 2.06238e-05
	LOSS [training: 0.06120304593641054 | validation: 0.0998717518401449]
	TIME [epoch: 8.52 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06577413537451458		[learning rate: 2.0549e-05]
	Learning Rate: 2.05489e-05
	LOSS [training: 0.06577413537451458 | validation: 0.10347555069503453]
	TIME [epoch: 8.5 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06629645660828466		[learning rate: 2.0474e-05]
	Learning Rate: 2.04744e-05
	LOSS [training: 0.06629645660828466 | validation: 0.08927302787509964]
	TIME [epoch: 8.51 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06079885079991004		[learning rate: 2.04e-05]
	Learning Rate: 2.04001e-05
	LOSS [training: 0.06079885079991004 | validation: 0.09307249843529194]
	TIME [epoch: 8.49 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06644019985219633		[learning rate: 2.0326e-05]
	Learning Rate: 2.0326e-05
	LOSS [training: 0.06644019985219633 | validation: 0.11962418926221569]
	TIME [epoch: 8.52 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07425269240463567		[learning rate: 2.0252e-05]
	Learning Rate: 2.02523e-05
	LOSS [training: 0.07425269240463567 | validation: 0.10013427570155504]
	TIME [epoch: 8.49 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0625790436365187		[learning rate: 2.0179e-05]
	Learning Rate: 2.01788e-05
	LOSS [training: 0.0625790436365187 | validation: 0.09632572304786047]
	TIME [epoch: 8.5 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06409509146679261		[learning rate: 2.0106e-05]
	Learning Rate: 2.01055e-05
	LOSS [training: 0.06409509146679261 | validation: 0.10475146153061456]
	TIME [epoch: 8.5 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06344435882375549		[learning rate: 2.0033e-05]
	Learning Rate: 2.00326e-05
	LOSS [training: 0.06344435882375549 | validation: 0.08739859091131712]
	TIME [epoch: 8.52 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06029037080051898		[learning rate: 1.996e-05]
	Learning Rate: 1.99599e-05
	LOSS [training: 0.06029037080051898 | validation: 0.08755567882550087]
	TIME [epoch: 8.5 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06491524148077854		[learning rate: 1.9887e-05]
	Learning Rate: 1.98874e-05
	LOSS [training: 0.06491524148077854 | validation: 0.09076142341696693]
	TIME [epoch: 8.5 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.064748549460571		[learning rate: 1.9815e-05]
	Learning Rate: 1.98153e-05
	LOSS [training: 0.064748549460571 | validation: 0.10136628699561807]
	TIME [epoch: 8.5 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062367682607532636		[learning rate: 1.9743e-05]
	Learning Rate: 1.97434e-05
	LOSS [training: 0.062367682607532636 | validation: 0.08823545179986116]
	TIME [epoch: 8.5 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0613574094569766		[learning rate: 1.9672e-05]
	Learning Rate: 1.96717e-05
	LOSS [training: 0.0613574094569766 | validation: 0.09492922007461635]
	TIME [epoch: 8.52 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06184960296048336		[learning rate: 1.96e-05]
	Learning Rate: 1.96003e-05
	LOSS [training: 0.06184960296048336 | validation: 0.09607242789237613]
	TIME [epoch: 8.5 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0591885701582769		[learning rate: 1.9529e-05]
	Learning Rate: 1.95292e-05
	LOSS [training: 0.0591885701582769 | validation: 0.0864980829240965]
	TIME [epoch: 8.5 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05826602142456133		[learning rate: 1.9458e-05]
	Learning Rate: 1.94583e-05
	LOSS [training: 0.05826602142456133 | validation: 0.09945963319920575]
	TIME [epoch: 8.5 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06186967160381759		[learning rate: 1.9388e-05]
	Learning Rate: 1.93877e-05
	LOSS [training: 0.06186967160381759 | validation: 0.09489765823002747]
	TIME [epoch: 8.53 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061628544824902744		[learning rate: 1.9317e-05]
	Learning Rate: 1.93173e-05
	LOSS [training: 0.061628544824902744 | validation: 0.10258804687428617]
	TIME [epoch: 8.51 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05794438669719813		[learning rate: 1.9247e-05]
	Learning Rate: 1.92472e-05
	LOSS [training: 0.05794438669719813 | validation: 0.10711107884945413]
	TIME [epoch: 8.5 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060069176426227125		[learning rate: 1.9177e-05]
	Learning Rate: 1.91774e-05
	LOSS [training: 0.060069176426227125 | validation: 0.08613918115991888]
	TIME [epoch: 8.5 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0651105849121979		[learning rate: 1.9108e-05]
	Learning Rate: 1.91078e-05
	LOSS [training: 0.0651105849121979 | validation: 0.09095042531147088]
	TIME [epoch: 8.51 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061758370638852075		[learning rate: 1.9038e-05]
	Learning Rate: 1.90384e-05
	LOSS [training: 0.061758370638852075 | validation: 0.08661093202692398]
	TIME [epoch: 8.49 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0615263314835285		[learning rate: 1.8969e-05]
	Learning Rate: 1.89694e-05
	LOSS [training: 0.0615263314835285 | validation: 0.10403305766258918]
	TIME [epoch: 8.5 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05869973926284474		[learning rate: 1.8901e-05]
	Learning Rate: 1.89005e-05
	LOSS [training: 0.05869973926284474 | validation: 0.09303409594477123]
	TIME [epoch: 8.49 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057396883239414775		[learning rate: 1.8832e-05]
	Learning Rate: 1.88319e-05
	LOSS [training: 0.057396883239414775 | validation: 0.08800377165088843]
	TIME [epoch: 8.52 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06078633546635979		[learning rate: 1.8764e-05]
	Learning Rate: 1.87636e-05
	LOSS [training: 0.06078633546635979 | validation: 0.09487902685520508]
	TIME [epoch: 8.5 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06184386223804694		[learning rate: 1.8695e-05]
	Learning Rate: 1.86955e-05
	LOSS [training: 0.06184386223804694 | validation: 0.09461643280746823]
	TIME [epoch: 8.5 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06152144171462531		[learning rate: 1.8628e-05]
	Learning Rate: 1.86276e-05
	LOSS [training: 0.06152144171462531 | validation: 0.1100911769587505]
	TIME [epoch: 8.51 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059682637671632156		[learning rate: 1.856e-05]
	Learning Rate: 1.856e-05
	LOSS [training: 0.059682637671632156 | validation: 0.09242667088417064]
	TIME [epoch: 8.51 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058899915763757915		[learning rate: 1.8493e-05]
	Learning Rate: 1.84927e-05
	LOSS [training: 0.058899915763757915 | validation: 0.10052699448723093]
	TIME [epoch: 8.53 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0684508533438087		[learning rate: 1.8426e-05]
	Learning Rate: 1.84256e-05
	LOSS [training: 0.0684508533438087 | validation: 0.10021460619832868]
	TIME [epoch: 8.5 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05948188439920452		[learning rate: 1.8359e-05]
	Learning Rate: 1.83587e-05
	LOSS [training: 0.05948188439920452 | validation: 0.0940067508610063]
	TIME [epoch: 8.52 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059703108601782476		[learning rate: 1.8292e-05]
	Learning Rate: 1.82921e-05
	LOSS [training: 0.059703108601782476 | validation: 0.08243250412478292]
	TIME [epoch: 8.51 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06251271486154159		[learning rate: 1.8226e-05]
	Learning Rate: 1.82257e-05
	LOSS [training: 0.06251271486154159 | validation: 0.10087047351875891]
	TIME [epoch: 8.53 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05985699062290887		[learning rate: 1.816e-05]
	Learning Rate: 1.81596e-05
	LOSS [training: 0.05985699062290887 | validation: 0.08747218440912871]
	TIME [epoch: 8.5 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06525965523041619		[learning rate: 1.8094e-05]
	Learning Rate: 1.80937e-05
	LOSS [training: 0.06525965523041619 | validation: 0.12319293278739415]
	TIME [epoch: 8.51 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07793352981793647		[learning rate: 1.8028e-05]
	Learning Rate: 1.8028e-05
	LOSS [training: 0.07793352981793647 | validation: 0.09505395045388082]
	TIME [epoch: 8.51 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06202219728590987		[learning rate: 1.7963e-05]
	Learning Rate: 1.79626e-05
	LOSS [training: 0.06202219728590987 | validation: 0.11901980864468795]
	TIME [epoch: 8.52 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06329350466600413		[learning rate: 1.7897e-05]
	Learning Rate: 1.78974e-05
	LOSS [training: 0.06329350466600413 | validation: 0.09776699829106283]
	TIME [epoch: 8.51 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05911316309570023		[learning rate: 1.7832e-05]
	Learning Rate: 1.78324e-05
	LOSS [training: 0.05911316309570023 | validation: 0.10325450961774088]
	TIME [epoch: 8.51 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06087741049683924		[learning rate: 1.7768e-05]
	Learning Rate: 1.77677e-05
	LOSS [training: 0.06087741049683924 | validation: 0.08244903126476238]
	TIME [epoch: 8.5 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0612535528270791		[learning rate: 1.7703e-05]
	Learning Rate: 1.77032e-05
	LOSS [training: 0.0612535528270791 | validation: 0.09002805012733393]
	TIME [epoch: 8.52 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061554563899816915		[learning rate: 1.7639e-05]
	Learning Rate: 1.7639e-05
	LOSS [training: 0.061554563899816915 | validation: 0.09795696602379006]
	TIME [epoch: 8.49 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05822079931710765		[learning rate: 1.7575e-05]
	Learning Rate: 1.7575e-05
	LOSS [training: 0.05822079931710765 | validation: 0.1131093746868195]
	TIME [epoch: 8.49 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06471437113874871		[learning rate: 1.7511e-05]
	Learning Rate: 1.75112e-05
	LOSS [training: 0.06471437113874871 | validation: 0.09529778074306547]
	TIME [epoch: 8.5 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06263083964021818		[learning rate: 1.7448e-05]
	Learning Rate: 1.74476e-05
	LOSS [training: 0.06263083964021818 | validation: 0.10074336285288132]
	TIME [epoch: 8.5 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06805775446369147		[learning rate: 1.7384e-05]
	Learning Rate: 1.73843e-05
	LOSS [training: 0.06805775446369147 | validation: 0.10472653890643455]
	TIME [epoch: 8.51 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06527629248085456		[learning rate: 1.7321e-05]
	Learning Rate: 1.73212e-05
	LOSS [training: 0.06527629248085456 | validation: 0.10033143048757073]
	TIME [epoch: 8.5 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06608186154488184		[learning rate: 1.7258e-05]
	Learning Rate: 1.72584e-05
	LOSS [training: 0.06608186154488184 | validation: 0.10655016004853546]
	TIME [epoch: 8.5 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061107725038807514		[learning rate: 1.7196e-05]
	Learning Rate: 1.71957e-05
	LOSS [training: 0.061107725038807514 | validation: 0.10608888763219981]
	TIME [epoch: 8.5 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0682114530345915		[learning rate: 1.7133e-05]
	Learning Rate: 1.71333e-05
	LOSS [training: 0.0682114530345915 | validation: 0.1122589591690951]
	TIME [epoch: 8.52 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062119684053261556		[learning rate: 1.7071e-05]
	Learning Rate: 1.70712e-05
	LOSS [training: 0.062119684053261556 | validation: 0.09343142285315514]
	TIME [epoch: 8.5 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061235943977522245		[learning rate: 1.7009e-05]
	Learning Rate: 1.70092e-05
	LOSS [training: 0.061235943977522245 | validation: 0.10268187073451138]
	TIME [epoch: 8.51 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059264802682489216		[learning rate: 1.6947e-05]
	Learning Rate: 1.69475e-05
	LOSS [training: 0.059264802682489216 | validation: 0.1004049069981783]
	TIME [epoch: 8.5 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0605559193485391		[learning rate: 1.6886e-05]
	Learning Rate: 1.6886e-05
	LOSS [training: 0.0605559193485391 | validation: 0.10653645530096785]
	TIME [epoch: 8.53 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06122039276974315		[learning rate: 1.6825e-05]
	Learning Rate: 1.68247e-05
	LOSS [training: 0.06122039276974315 | validation: 0.09599236339612296]
	TIME [epoch: 8.5 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0624596337254804		[learning rate: 1.6764e-05]
	Learning Rate: 1.67636e-05
	LOSS [training: 0.0624596337254804 | validation: 0.09880962465787568]
	TIME [epoch: 8.5 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06299705042443382		[learning rate: 1.6703e-05]
	Learning Rate: 1.67028e-05
	LOSS [training: 0.06299705042443382 | validation: 0.09424683700897354]
	TIME [epoch: 8.51 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06185897297959575		[learning rate: 1.6642e-05]
	Learning Rate: 1.66422e-05
	LOSS [training: 0.06185897297959575 | validation: 0.09755198490915627]
	TIME [epoch: 8.53 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06082171271533447		[learning rate: 1.6582e-05]
	Learning Rate: 1.65818e-05
	LOSS [training: 0.06082171271533447 | validation: 0.0973731739025073]
	TIME [epoch: 8.51 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06279538486554231		[learning rate: 1.6522e-05]
	Learning Rate: 1.65216e-05
	LOSS [training: 0.06279538486554231 | validation: 0.11249397808753138]
	TIME [epoch: 8.5 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06574038382288493		[learning rate: 1.6462e-05]
	Learning Rate: 1.64617e-05
	LOSS [training: 0.06574038382288493 | validation: 0.10855727297541545]
	TIME [epoch: 8.51 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06337409820355415		[learning rate: 1.6402e-05]
	Learning Rate: 1.64019e-05
	LOSS [training: 0.06337409820355415 | validation: 0.10027507486685974]
	TIME [epoch: 8.51 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06168161082915813		[learning rate: 1.6342e-05]
	Learning Rate: 1.63424e-05
	LOSS [training: 0.06168161082915813 | validation: 0.10270722854468614]
	TIME [epoch: 8.52 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06810876677784661		[learning rate: 1.6283e-05]
	Learning Rate: 1.62831e-05
	LOSS [training: 0.06810876677784661 | validation: 0.11142533129418676]
	TIME [epoch: 8.49 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05984213415162826		[learning rate: 1.6224e-05]
	Learning Rate: 1.6224e-05
	LOSS [training: 0.05984213415162826 | validation: 0.09693489617160936]
	TIME [epoch: 8.5 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059341751951838585		[learning rate: 1.6165e-05]
	Learning Rate: 1.61651e-05
	LOSS [training: 0.059341751951838585 | validation: 0.09200710183628821]
	TIME [epoch: 8.5 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06431161191037135		[learning rate: 1.6106e-05]
	Learning Rate: 1.61065e-05
	LOSS [training: 0.06431161191037135 | validation: 0.10487128021137297]
	TIME [epoch: 8.53 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06493486004284652		[learning rate: 1.6048e-05]
	Learning Rate: 1.6048e-05
	LOSS [training: 0.06493486004284652 | validation: 0.09992114991617615]
	TIME [epoch: 8.51 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06481483605582108		[learning rate: 1.599e-05]
	Learning Rate: 1.59898e-05
	LOSS [training: 0.06481483605582108 | validation: 0.10239030813015922]
	TIME [epoch: 8.5 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05898136530200047		[learning rate: 1.5932e-05]
	Learning Rate: 1.59317e-05
	LOSS [training: 0.05898136530200047 | validation: 0.11678791502887499]
	TIME [epoch: 8.51 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058613937041945216		[learning rate: 1.5874e-05]
	Learning Rate: 1.58739e-05
	LOSS [training: 0.058613937041945216 | validation: 0.09714308725307011]
	TIME [epoch: 8.54 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06708664998724767		[learning rate: 1.5816e-05]
	Learning Rate: 1.58163e-05
	LOSS [training: 0.06708664998724767 | validation: 0.0978747807028254]
	TIME [epoch: 8.51 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059724694922335744		[learning rate: 1.5759e-05]
	Learning Rate: 1.57589e-05
	LOSS [training: 0.059724694922335744 | validation: 0.09895630567327088]
	TIME [epoch: 8.5 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0610840069497675		[learning rate: 1.5702e-05]
	Learning Rate: 1.57017e-05
	LOSS [training: 0.0610840069497675 | validation: 0.09144210917291384]
	TIME [epoch: 8.51 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06417036852889418		[learning rate: 1.5645e-05]
	Learning Rate: 1.56447e-05
	LOSS [training: 0.06417036852889418 | validation: 0.09039324093762861]
	TIME [epoch: 8.51 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06096107648737921		[learning rate: 1.5588e-05]
	Learning Rate: 1.5588e-05
	LOSS [training: 0.06096107648737921 | validation: 0.09300011067396044]
	TIME [epoch: 8.51 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05881403100620201		[learning rate: 1.5531e-05]
	Learning Rate: 1.55314e-05
	LOSS [training: 0.05881403100620201 | validation: 0.09512809187017271]
	TIME [epoch: 8.51 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06101237444906373		[learning rate: 1.5475e-05]
	Learning Rate: 1.5475e-05
	LOSS [training: 0.06101237444906373 | validation: 0.09200232861198082]
	TIME [epoch: 8.5 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06421810132780022		[learning rate: 1.5419e-05]
	Learning Rate: 1.54189e-05
	LOSS [training: 0.06421810132780022 | validation: 0.10418994003165634]
	TIME [epoch: 8.51 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06283238565430707		[learning rate: 1.5363e-05]
	Learning Rate: 1.53629e-05
	LOSS [training: 0.06283238565430707 | validation: 0.11964881407193423]
	TIME [epoch: 8.52 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06499827648123122		[learning rate: 1.5307e-05]
	Learning Rate: 1.53072e-05
	LOSS [training: 0.06499827648123122 | validation: 0.09427600873311817]
	TIME [epoch: 8.5 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059540942018069		[learning rate: 1.5252e-05]
	Learning Rate: 1.52516e-05
	LOSS [training: 0.059540942018069 | validation: 0.09727362534680152]
	TIME [epoch: 8.52 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062140128587303355		[learning rate: 1.5196e-05]
	Learning Rate: 1.51963e-05
	LOSS [training: 0.062140128587303355 | validation: 0.09204454688050163]
	TIME [epoch: 8.51 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06264324361462811		[learning rate: 1.5141e-05]
	Learning Rate: 1.51411e-05
	LOSS [training: 0.06264324361462811 | validation: 0.08736932914919542]
	TIME [epoch: 8.53 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061423953874836304		[learning rate: 1.5086e-05]
	Learning Rate: 1.50862e-05
	LOSS [training: 0.061423953874836304 | validation: 0.09811540614521141]
	TIME [epoch: 8.51 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06032508157816382		[learning rate: 1.5031e-05]
	Learning Rate: 1.50314e-05
	LOSS [training: 0.06032508157816382 | validation: 0.08749781567734673]
	TIME [epoch: 8.51 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06037279637639244		[learning rate: 1.4977e-05]
	Learning Rate: 1.49769e-05
	LOSS [training: 0.06037279637639244 | validation: 0.09171679592063925]
	TIME [epoch: 8.52 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06374477497011696		[learning rate: 1.4923e-05]
	Learning Rate: 1.49225e-05
	LOSS [training: 0.06374477497011696 | validation: 0.09412910981324733]
	TIME [epoch: 8.54 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.066914367714872		[learning rate: 1.4868e-05]
	Learning Rate: 1.48684e-05
	LOSS [training: 0.066914367714872 | validation: 0.08699881333266264]
	TIME [epoch: 8.52 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058736214990918176		[learning rate: 1.4814e-05]
	Learning Rate: 1.48144e-05
	LOSS [training: 0.058736214990918176 | validation: 0.09351196203032311]
	TIME [epoch: 8.51 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06603679450415312		[learning rate: 1.4761e-05]
	Learning Rate: 1.47606e-05
	LOSS [training: 0.06603679450415312 | validation: 0.10419984011150052]
	TIME [epoch: 8.51 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0666162828477987		[learning rate: 1.4707e-05]
	Learning Rate: 1.47071e-05
	LOSS [training: 0.0666162828477987 | validation: 0.11643168715675987]
	TIME [epoch: 8.53 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06953898834734384		[learning rate: 1.4654e-05]
	Learning Rate: 1.46537e-05
	LOSS [training: 0.06953898834734384 | validation: 0.0915529106138066]
	TIME [epoch: 8.52 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06479874520273246		[learning rate: 1.4601e-05]
	Learning Rate: 1.46005e-05
	LOSS [training: 0.06479874520273246 | validation: 0.1002857004794363]
	TIME [epoch: 8.51 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06092224672451849		[learning rate: 1.4548e-05]
	Learning Rate: 1.45475e-05
	LOSS [training: 0.06092224672451849 | validation: 0.08623192915833874]
	TIME [epoch: 8.51 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06293941448661905		[learning rate: 1.4495e-05]
	Learning Rate: 1.44947e-05
	LOSS [training: 0.06293941448661905 | validation: 0.10182086287413872]
	TIME [epoch: 8.54 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06643225207276224		[learning rate: 1.4442e-05]
	Learning Rate: 1.44421e-05
	LOSS [training: 0.06643225207276224 | validation: 0.11906783042738539]
	TIME [epoch: 8.51 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07183787591308906		[learning rate: 1.439e-05]
	Learning Rate: 1.43897e-05
	LOSS [training: 0.07183787591308906 | validation: 0.09265694531368172]
	TIME [epoch: 8.51 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.065950399575236		[learning rate: 1.4338e-05]
	Learning Rate: 1.43375e-05
	LOSS [training: 0.065950399575236 | validation: 0.09358737436288406]
	TIME [epoch: 8.51 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06750241502070174		[learning rate: 1.4285e-05]
	Learning Rate: 1.42855e-05
	LOSS [training: 0.06750241502070174 | validation: 0.09385552271917569]
	TIME [epoch: 8.52 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061716409878239654		[learning rate: 1.4234e-05]
	Learning Rate: 1.42336e-05
	LOSS [training: 0.061716409878239654 | validation: 0.09941569381142656]
	TIME [epoch: 8.53 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06177541425366399		[learning rate: 1.4182e-05]
	Learning Rate: 1.4182e-05
	LOSS [training: 0.06177541425366399 | validation: 0.09515329042615656]
	TIME [epoch: 8.5 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0643641569863299		[learning rate: 1.4131e-05]
	Learning Rate: 1.41305e-05
	LOSS [training: 0.0643641569863299 | validation: 0.09176153225631657]
	TIME [epoch: 8.51 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06373789851815624		[learning rate: 1.4079e-05]
	Learning Rate: 1.40792e-05
	LOSS [training: 0.06373789851815624 | validation: 0.09548816936523213]
	TIME [epoch: 8.51 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06313930544392075		[learning rate: 1.4028e-05]
	Learning Rate: 1.40281e-05
	LOSS [training: 0.06313930544392075 | validation: 0.09814549444775758]
	TIME [epoch: 8.53 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07397290770172153		[learning rate: 1.3977e-05]
	Learning Rate: 1.39772e-05
	LOSS [training: 0.07397290770172153 | validation: 0.10810164385628232]
	TIME [epoch: 8.51 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0747746788292297		[learning rate: 1.3927e-05]
	Learning Rate: 1.39265e-05
	LOSS [training: 0.0747746788292297 | validation: 0.09422227531489501]
	TIME [epoch: 8.52 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07424107794008385		[learning rate: 1.3876e-05]
	Learning Rate: 1.3876e-05
	LOSS [training: 0.07424107794008385 | validation: 0.10782681318928598]
	TIME [epoch: 8.51 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0723440496936518		[learning rate: 1.3826e-05]
	Learning Rate: 1.38256e-05
	LOSS [training: 0.0723440496936518 | validation: 0.10478885843788094]
	TIME [epoch: 8.53 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0657555396466238		[learning rate: 1.3775e-05]
	Learning Rate: 1.37754e-05
	LOSS [training: 0.0657555396466238 | validation: 0.10123482744630682]
	TIME [epoch: 8.51 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05815894914513349		[learning rate: 1.3725e-05]
	Learning Rate: 1.37254e-05
	LOSS [training: 0.05815894914513349 | validation: 0.12387308995630315]
	TIME [epoch: 8.51 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05913689682173566		[learning rate: 1.3676e-05]
	Learning Rate: 1.36756e-05
	LOSS [training: 0.05913689682173566 | validation: 0.09884098537441188]
	TIME [epoch: 8.5 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06436308337614297		[learning rate: 1.3626e-05]
	Learning Rate: 1.3626e-05
	LOSS [training: 0.06436308337614297 | validation: 0.09839322472384664]
	TIME [epoch: 8.53 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06068129970875276		[learning rate: 1.3577e-05]
	Learning Rate: 1.35766e-05
	LOSS [training: 0.06068129970875276 | validation: 0.09951381526650874]
	TIME [epoch: 8.51 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06600769024941816		[learning rate: 1.3527e-05]
	Learning Rate: 1.35273e-05
	LOSS [training: 0.06600769024941816 | validation: 0.09520570316686122]
	TIME [epoch: 8.51 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06254017842035245		[learning rate: 1.3478e-05]
	Learning Rate: 1.34782e-05
	LOSS [training: 0.06254017842035245 | validation: 0.10603452177904486]
	TIME [epoch: 8.51 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06414619663310996		[learning rate: 1.3429e-05]
	Learning Rate: 1.34293e-05
	LOSS [training: 0.06414619663310996 | validation: 0.09683709244912615]
	TIME [epoch: 8.52 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0665908528255477		[learning rate: 1.3381e-05]
	Learning Rate: 1.33805e-05
	LOSS [training: 0.0665908528255477 | validation: 0.09955926385212512]
	TIME [epoch: 8.52 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07277998169096497		[learning rate: 1.3332e-05]
	Learning Rate: 1.3332e-05
	LOSS [training: 0.07277998169096497 | validation: 0.11351442034801698]
	TIME [epoch: 8.51 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07243925244375458		[learning rate: 1.3284e-05]
	Learning Rate: 1.32836e-05
	LOSS [training: 0.07243925244375458 | validation: 0.1050348776171753]
	TIME [epoch: 8.51 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07236699873068933		[learning rate: 1.3235e-05]
	Learning Rate: 1.32354e-05
	LOSS [training: 0.07236699873068933 | validation: 0.10634683796554403]
	TIME [epoch: 8.51 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06981391869982564		[learning rate: 1.3187e-05]
	Learning Rate: 1.31874e-05
	LOSS [training: 0.06981391869982564 | validation: 0.11908012532060283]
	TIME [epoch: 8.52 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0697155687140335		[learning rate: 1.314e-05]
	Learning Rate: 1.31395e-05
	LOSS [training: 0.0697155687140335 | validation: 0.1108873267509489]
	TIME [epoch: 8.49 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07153392135213846		[learning rate: 1.3092e-05]
	Learning Rate: 1.30918e-05
	LOSS [training: 0.07153392135213846 | validation: 0.11604504317753155]
	TIME [epoch: 8.5 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07144613345268994		[learning rate: 1.3044e-05]
	Learning Rate: 1.30443e-05
	LOSS [training: 0.07144613345268994 | validation: 0.09839268831412126]
	TIME [epoch: 8.5 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061326864205040556		[learning rate: 1.2997e-05]
	Learning Rate: 1.2997e-05
	LOSS [training: 0.061326864205040556 | validation: 0.10743746491613315]
	TIME [epoch: 8.53 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06787078386220206		[learning rate: 1.295e-05]
	Learning Rate: 1.29498e-05
	LOSS [training: 0.06787078386220206 | validation: 0.09713003146569825]
	TIME [epoch: 8.51 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05930594131658181		[learning rate: 1.2903e-05]
	Learning Rate: 1.29028e-05
	LOSS [training: 0.05930594131658181 | validation: 0.08939894917520774]
	TIME [epoch: 8.5 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06371832933198424		[learning rate: 1.2856e-05]
	Learning Rate: 1.2856e-05
	LOSS [training: 0.06371832933198424 | validation: 0.09314536666685375]
	TIME [epoch: 8.5 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0664551556239492		[learning rate: 1.2809e-05]
	Learning Rate: 1.28093e-05
	LOSS [training: 0.0664551556239492 | validation: 0.0916795547014801]
	TIME [epoch: 8.53 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06243121665520919		[learning rate: 1.2763e-05]
	Learning Rate: 1.27628e-05
	LOSS [training: 0.06243121665520919 | validation: 0.09330052628990002]
	TIME [epoch: 8.51 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06015899624833543		[learning rate: 1.2717e-05]
	Learning Rate: 1.27165e-05
	LOSS [training: 0.06015899624833543 | validation: 0.09890337987264838]
	TIME [epoch: 8.51 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06343386372369667		[learning rate: 1.267e-05]
	Learning Rate: 1.26704e-05
	LOSS [training: 0.06343386372369667 | validation: 0.09764675091256846]
	TIME [epoch: 8.51 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06555936987560301		[learning rate: 1.2624e-05]
	Learning Rate: 1.26244e-05
	LOSS [training: 0.06555936987560301 | validation: 0.09981781375749146]
	TIME [epoch: 8.52 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06145247767717722		[learning rate: 1.2579e-05]
	Learning Rate: 1.25786e-05
	LOSS [training: 0.06145247767717722 | validation: 0.08851383071918699]
	TIME [epoch: 8.53 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06161628269522561		[learning rate: 1.2533e-05]
	Learning Rate: 1.25329e-05
	LOSS [training: 0.06161628269522561 | validation: 0.10091180110935268]
	TIME [epoch: 8.51 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061185366830994424		[learning rate: 1.2487e-05]
	Learning Rate: 1.24874e-05
	LOSS [training: 0.061185366830994424 | validation: 0.10253621108774794]
	TIME [epoch: 8.51 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06386346399794667		[learning rate: 1.2442e-05]
	Learning Rate: 1.24421e-05
	LOSS [training: 0.06386346399794667 | validation: 0.09823373124193363]
	TIME [epoch: 8.51 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06166237191709255		[learning rate: 1.2397e-05]
	Learning Rate: 1.2397e-05
	LOSS [training: 0.06166237191709255 | validation: 0.10467301947252768]
	TIME [epoch: 8.53 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05997083494217863		[learning rate: 1.2352e-05]
	Learning Rate: 1.2352e-05
	LOSS [training: 0.05997083494217863 | validation: 0.09878077421486212]
	TIME [epoch: 8.51 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058305278279050174		[learning rate: 1.2307e-05]
	Learning Rate: 1.23072e-05
	LOSS [training: 0.058305278279050174 | validation: 0.09617374010745225]
	TIME [epoch: 8.51 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05914468016306196		[learning rate: 1.2263e-05]
	Learning Rate: 1.22625e-05
	LOSS [training: 0.05914468016306196 | validation: 0.12638518715204272]
	TIME [epoch: 8.52 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06302696791658945		[learning rate: 1.2218e-05]
	Learning Rate: 1.2218e-05
	LOSS [training: 0.06302696791658945 | validation: 0.09478525127104744]
	TIME [epoch: 8.53 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06107573770686904		[learning rate: 1.2174e-05]
	Learning Rate: 1.21737e-05
	LOSS [training: 0.06107573770686904 | validation: 0.08660119582673899]
	TIME [epoch: 8.5 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06408819650949607		[learning rate: 1.2129e-05]
	Learning Rate: 1.21295e-05
	LOSS [training: 0.06408819650949607 | validation: 0.0881947296678174]
	TIME [epoch: 8.52 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06161610402346239		[learning rate: 1.2085e-05]
	Learning Rate: 1.20855e-05
	LOSS [training: 0.06161610402346239 | validation: 0.12043209393672179]
	TIME [epoch: 8.51 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062736228982905		[learning rate: 1.2042e-05]
	Learning Rate: 1.20416e-05
	LOSS [training: 0.062736228982905 | validation: 0.09371695226125767]
	TIME [epoch: 8.54 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06589732749797655		[learning rate: 1.1998e-05]
	Learning Rate: 1.19979e-05
	LOSS [training: 0.06589732749797655 | validation: 0.10476623177592831]
	TIME [epoch: 8.51 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07018172559057581		[learning rate: 1.1954e-05]
	Learning Rate: 1.19544e-05
	LOSS [training: 0.07018172559057581 | validation: 0.09757390762351659]
	TIME [epoch: 8.5 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06131766709116808		[learning rate: 1.1911e-05]
	Learning Rate: 1.1911e-05
	LOSS [training: 0.06131766709116808 | validation: 0.09320942002787017]
	TIME [epoch: 8.5 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061998121372162554		[learning rate: 1.1868e-05]
	Learning Rate: 1.18678e-05
	LOSS [training: 0.061998121372162554 | validation: 0.1074417080266412]
	TIME [epoch: 8.51 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06828397550109512		[learning rate: 1.1825e-05]
	Learning Rate: 1.18247e-05
	LOSS [training: 0.06828397550109512 | validation: 0.10659409468876824]
	TIME [epoch: 8.51 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06500209918947825		[learning rate: 1.1782e-05]
	Learning Rate: 1.17818e-05
	LOSS [training: 0.06500209918947825 | validation: 0.11185814717846318]
	TIME [epoch: 8.5 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0671408742725083		[learning rate: 1.1739e-05]
	Learning Rate: 1.1739e-05
	LOSS [training: 0.0671408742725083 | validation: 0.09070818797783073]
	TIME [epoch: 8.49 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06946421461841092		[learning rate: 1.1696e-05]
	Learning Rate: 1.16964e-05
	LOSS [training: 0.06946421461841092 | validation: 0.11879127186890076]
	TIME [epoch: 8.5 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06570291155871376		[learning rate: 1.1654e-05]
	Learning Rate: 1.1654e-05
	LOSS [training: 0.06570291155871376 | validation: 0.10678691640471888]
	TIME [epoch: 8.52 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06914593896376373		[learning rate: 1.1612e-05]
	Learning Rate: 1.16117e-05
	LOSS [training: 0.06914593896376373 | validation: 0.09659712586390948]
	TIME [epoch: 8.5 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06391512937838001		[learning rate: 1.157e-05]
	Learning Rate: 1.15695e-05
	LOSS [training: 0.06391512937838001 | validation: 0.09989613986572815]
	TIME [epoch: 8.49 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06845451195449703		[learning rate: 1.1528e-05]
	Learning Rate: 1.15275e-05
	LOSS [training: 0.06845451195449703 | validation: 0.10160721733324843]
	TIME [epoch: 8.5 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06452809052111777		[learning rate: 1.1486e-05]
	Learning Rate: 1.14857e-05
	LOSS [training: 0.06452809052111777 | validation: 0.11053455995116346]
	TIME [epoch: 8.51 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0582115752631732		[learning rate: 1.1444e-05]
	Learning Rate: 1.1444e-05
	LOSS [training: 0.0582115752631732 | validation: 0.09398644618724113]
	TIME [epoch: 8.5 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0684500136879855		[learning rate: 1.1402e-05]
	Learning Rate: 1.14025e-05
	LOSS [training: 0.0684500136879855 | validation: 0.11003251443582249]
	TIME [epoch: 8.5 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061804037297763		[learning rate: 1.1361e-05]
	Learning Rate: 1.13611e-05
	LOSS [training: 0.061804037297763 | validation: 0.0984293630093048]
	TIME [epoch: 8.5 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056105330477456736		[learning rate: 1.132e-05]
	Learning Rate: 1.13199e-05
	LOSS [training: 0.056105330477456736 | validation: 0.09470742977366887]
	TIME [epoch: 8.51 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0583535319318114		[learning rate: 1.1279e-05]
	Learning Rate: 1.12788e-05
	LOSS [training: 0.0583535319318114 | validation: 0.09746471700276452]
	TIME [epoch: 8.5 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060322654820206364		[learning rate: 1.1238e-05]
	Learning Rate: 1.12379e-05
	LOSS [training: 0.060322654820206364 | validation: 0.08621274684774449]
	TIME [epoch: 8.5 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05984959654515787		[learning rate: 1.1197e-05]
	Learning Rate: 1.11971e-05
	LOSS [training: 0.05984959654515787 | validation: 0.09446470506609389]
	TIME [epoch: 8.5 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06236350743112075		[learning rate: 1.1156e-05]
	Learning Rate: 1.11565e-05
	LOSS [training: 0.06236350743112075 | validation: 0.0845734944103452]
	TIME [epoch: 8.51 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061930216271896855		[learning rate: 1.1116e-05]
	Learning Rate: 1.1116e-05
	LOSS [training: 0.061930216271896855 | validation: 0.1000973128655507]
	TIME [epoch: 8.5 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06024683737049428		[learning rate: 1.1076e-05]
	Learning Rate: 1.10756e-05
	LOSS [training: 0.06024683737049428 | validation: 0.0995972524413068]
	TIME [epoch: 8.5 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05710812851037187		[learning rate: 1.1035e-05]
	Learning Rate: 1.10354e-05
	LOSS [training: 0.05710812851037187 | validation: 0.08535107703034113]
	TIME [epoch: 8.49 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058453598714013136		[learning rate: 1.0995e-05]
	Learning Rate: 1.09954e-05
	LOSS [training: 0.058453598714013136 | validation: 0.09172834186230727]
	TIME [epoch: 8.49 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05916214334462681		[learning rate: 1.0955e-05]
	Learning Rate: 1.09555e-05
	LOSS [training: 0.05916214334462681 | validation: 0.10404147502771534]
	TIME [epoch: 8.52 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06081789412081717		[learning rate: 1.0916e-05]
	Learning Rate: 1.09157e-05
	LOSS [training: 0.06081789412081717 | validation: 0.0946462547622793]
	TIME [epoch: 8.5 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05889317535067716		[learning rate: 1.0876e-05]
	Learning Rate: 1.08761e-05
	LOSS [training: 0.05889317535067716 | validation: 0.1098423303052925]
	TIME [epoch: 8.5 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06848197003585547		[learning rate: 1.0837e-05]
	Learning Rate: 1.08366e-05
	LOSS [training: 0.06848197003585547 | validation: 0.11660622390812067]
	TIME [epoch: 8.5 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06683930338341075		[learning rate: 1.0797e-05]
	Learning Rate: 1.07973e-05
	LOSS [training: 0.06683930338341075 | validation: 0.12543421889478343]
	TIME [epoch: 8.51 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07074616195909203		[learning rate: 1.0758e-05]
	Learning Rate: 1.07581e-05
	LOSS [training: 0.07074616195909203 | validation: 0.12059384523053546]
	TIME [epoch: 8.5 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0659598974912949		[learning rate: 1.0719e-05]
	Learning Rate: 1.07191e-05
	LOSS [training: 0.0659598974912949 | validation: 0.10685499479406699]
	TIME [epoch: 8.5 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061908435436116696		[learning rate: 1.068e-05]
	Learning Rate: 1.06802e-05
	LOSS [training: 0.061908435436116696 | validation: 0.09856528183820343]
	TIME [epoch: 8.5 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06589622393050862		[learning rate: 1.0641e-05]
	Learning Rate: 1.06414e-05
	LOSS [training: 0.06589622393050862 | validation: 0.10567430778286456]
	TIME [epoch: 8.52 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06194261837183031		[learning rate: 1.0603e-05]
	Learning Rate: 1.06028e-05
	LOSS [training: 0.06194261837183031 | validation: 0.1004419229701808]
	TIME [epoch: 8.5 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06097431149098559		[learning rate: 1.0564e-05]
	Learning Rate: 1.05643e-05
	LOSS [training: 0.06097431149098559 | validation: 0.09559025379032077]
	TIME [epoch: 8.49 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06320177219300092		[learning rate: 1.0526e-05]
	Learning Rate: 1.0526e-05
	LOSS [training: 0.06320177219300092 | validation: 0.10033569447145252]
	TIME [epoch: 8.5 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05804804566683508		[learning rate: 1.0488e-05]
	Learning Rate: 1.04878e-05
	LOSS [training: 0.05804804566683508 | validation: 0.09150064804256662]
	TIME [epoch: 8.52 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06224323940084188		[learning rate: 1.045e-05]
	Learning Rate: 1.04497e-05
	LOSS [training: 0.06224323940084188 | validation: 0.09675133761965926]
	TIME [epoch: 8.5 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06707991817339323		[learning rate: 1.0412e-05]
	Learning Rate: 1.04118e-05
	LOSS [training: 0.06707991817339323 | validation: 0.09344420606269388]
	TIME [epoch: 8.51 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0590003511354012		[learning rate: 1.0374e-05]
	Learning Rate: 1.0374e-05
	LOSS [training: 0.0590003511354012 | validation: 0.10930859361422637]
	TIME [epoch: 8.5 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06319013593529738		[learning rate: 1.0336e-05]
	Learning Rate: 1.03364e-05
	LOSS [training: 0.06319013593529738 | validation: 0.0876726641168464]
	TIME [epoch: 8.5 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06227345757160724		[learning rate: 1.0299e-05]
	Learning Rate: 1.02989e-05
	LOSS [training: 0.06227345757160724 | validation: 0.10082220965439007]
	TIME [epoch: 8.51 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060271245998109645		[learning rate: 1.0261e-05]
	Learning Rate: 1.02615e-05
	LOSS [training: 0.060271245998109645 | validation: 0.09935410474518677]
	TIME [epoch: 8.5 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061880908692938406		[learning rate: 1.0224e-05]
	Learning Rate: 1.02243e-05
	LOSS [training: 0.061880908692938406 | validation: 0.08899844135444292]
	TIME [epoch: 8.5 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06453494762431584		[learning rate: 1.0187e-05]
	Learning Rate: 1.01872e-05
	LOSS [training: 0.06453494762431584 | validation: 0.09903913654964822]
	TIME [epoch: 8.5 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06267150536877311		[learning rate: 1.015e-05]
	Learning Rate: 1.01502e-05
	LOSS [training: 0.06267150536877311 | validation: 0.08818706188393485]
	TIME [epoch: 8.52 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05708681670319993		[learning rate: 1.0113e-05]
	Learning Rate: 1.01133e-05
	LOSS [training: 0.05708681670319993 | validation: 0.0920157345262638]
	TIME [epoch: 8.5 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05842557681659081		[learning rate: 1.0077e-05]
	Learning Rate: 1.00766e-05
	LOSS [training: 0.05842557681659081 | validation: 0.10004084110883671]
	TIME [epoch: 8.5 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058478631587329036		[learning rate: 1.004e-05]
	Learning Rate: 1.00401e-05
	LOSS [training: 0.058478631587329036 | validation: 0.08669004906625803]
	TIME [epoch: 8.5 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06086934662074358		[learning rate: 1.0004e-05]
	Learning Rate: 1.00036e-05
	LOSS [training: 0.06086934662074358 | validation: 0.10124967885326214]
	TIME [epoch: 8.51 sec]
Finished training in 17185.027 seconds.
