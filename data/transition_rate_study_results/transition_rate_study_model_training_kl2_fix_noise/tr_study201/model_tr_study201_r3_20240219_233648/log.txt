Args:
Namespace(name='model_tr_study201', outdir='out/transition_rate_study_model_training_kl2_fix_noise/tr_study201/model_tr_study201_r3', training_data='data/transition_rate_studies/tr_study201/tr_study201_training/r3', validation_data='data/transition_rate_studies/tr_study201/tr_study201_validation/r3', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.075, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=100, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 4041924911

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study201/model_tr_study201_r3_20240219_233648/states/model_tr_study201_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 10/20] avg loss: 11.628683415794367		[learning rate: 0.01]
		[batch 20/20] avg loss: 10.595270328174632		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.1119768719845 | validation: 9.604398745536642]
	TIME [epoch: 78.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study201/model_tr_study201_r3_20240219_233648/states/model_tr_study201_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 10/20] avg loss: 9.599583447188515		[learning rate: 0.01]
		[batch 20/20] avg loss: 9.614412647323935		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.606998047256223 | validation: 9.799416474591077]
	TIME [epoch: 8.23 sec]
EPOCH 3/2000:
	Training over batches...
		[batch 10/20] avg loss: 8.301217092423652		[learning rate: 0.01]
		[batch 20/20] avg loss: 9.911844374313768		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.106530733368709 | validation: 11.044463642260679]
	TIME [epoch: 8.22 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 10/20] avg loss: 10.030451822402608		[learning rate: 0.01]
		[batch 20/20] avg loss: 8.144316801550435		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.087384311976523 | validation: 8.29937674969882]
	TIME [epoch: 8.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study201/model_tr_study201_r3_20240219_233648/states/model_tr_study201_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 10/20] avg loss: 8.120392128157665		[learning rate: 0.01]
		[batch 20/20] avg loss: 7.372996651798777		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.746694389978224 | validation: 6.55973923743811]
	TIME [epoch: 8.23 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study201/model_tr_study201_r3_20240219_233648/states/model_tr_study201_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 10/20] avg loss: 6.5444002009228255		[learning rate: 0.01]
		[batch 20/20] avg loss: 6.5076190713241875		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.526009636123507 | validation: 5.4394636433279855]
	TIME [epoch: 8.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study201/model_tr_study201_r3_20240219_233648/states/model_tr_study201_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 10/20] avg loss: 6.965373868762043		[learning rate: 0.01]
		[batch 20/20] avg loss: 6.484253250390647		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.724813559576345 | validation: 6.702147655121354]
	TIME [epoch: 8.19 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 10/20] avg loss: 6.1774748954216125		[learning rate: 0.01]
		[batch 20/20] avg loss: 6.360874188209268		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.26917454181544 | validation: 8.135482638668027]
	TIME [epoch: 8.18 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 10/20] avg loss: 7.037707312079489		[learning rate: 0.01]
		[batch 20/20] avg loss: 6.126607541496305		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.582157426787896 | validation: 5.262838241935737]
	TIME [epoch: 8.22 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study201/model_tr_study201_r3_20240219_233648/states/model_tr_study201_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 10/20] avg loss: 5.58393427740879		[learning rate: 0.01]
		[batch 20/20] avg loss: 5.616704859464295		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.600319568436543 | validation: 5.061187403616744]
	TIME [epoch: 8.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study201/model_tr_study201_r3_20240219_233648/states/model_tr_study201_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 10/20] avg loss: 5.574794838371347		[learning rate: 0.01]
		[batch 20/20] avg loss: 5.487408201159579		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.531101519765462 | validation: 4.916345633704258]
	TIME [epoch: 8.19 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study201/model_tr_study201_r3_20240219_233648/states/model_tr_study201_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 10/20] avg loss: 5.501946684892192		[learning rate: 0.01]
		[batch 20/20] avg loss: 5.481552950157253		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.491749817524722 | validation: 6.121053793515405]
	TIME [epoch: 8.21 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 10/20] avg loss: 5.4011905756501815		[learning rate: 0.01]
		[batch 20/20] avg loss: 5.269413122818347		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.335301849234264 | validation: 5.155199289608381]
	TIME [epoch: 8.2 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 10/20] avg loss: 5.338195990931129		[learning rate: 0.01]
		[batch 20/20] avg loss: 5.041908007380871		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.190051999156 | validation: 5.254237866976541]
	TIME [epoch: 8.24 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 10/20] avg loss: 5.078200639234409		[learning rate: 0.01]
		[batch 20/20] avg loss: 5.0043955703763805		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.041298104805394 | validation: 4.990285669229554]
	TIME [epoch: 8.21 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 10/20] avg loss: 4.998101464854804		[learning rate: 0.01]
		[batch 20/20] avg loss: 4.921455321010389		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.959778392932597 | validation: 4.957447204794455]
	TIME [epoch: 8.22 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 10/20] avg loss: 4.679486607919771		[learning rate: 0.01]
		[batch 20/20] avg loss: 4.846545150560808		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.763015879240289 | validation: 4.7024561436816095]
	TIME [epoch: 8.21 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study201/model_tr_study201_r3_20240219_233648/states/model_tr_study201_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 10/20] avg loss: 4.947883890756947		[learning rate: 0.01]
		[batch 20/20] avg loss: 4.677540643738268		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.812712267247607 | validation: 4.274727042541197]
	TIME [epoch: 8.24 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study201/model_tr_study201_r3_20240219_233648/states/model_tr_study201_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 10/20] avg loss: 4.551036145606904		[learning rate: 0.01]
		[batch 20/20] avg loss: 4.653828454589823		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.602432300098364 | validation: 4.255583933574642]
	TIME [epoch: 8.22 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study201/model_tr_study201_r3_20240219_233648/states/model_tr_study201_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 10/20] avg loss: 4.596451941234744		[learning rate: 0.01]
		[batch 20/20] avg loss: 4.455185690011815		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.52581881562328 | validation: 3.8543283529825603]
	TIME [epoch: 8.21 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study201/model_tr_study201_r3_20240219_233648/states/model_tr_study201_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 10/20] avg loss: 4.462982485440586		[learning rate: 0.01]
		[batch 20/20] avg loss: 4.670540868371743		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.566761676906164 | validation: 4.170729828725317]
	TIME [epoch: 8.21 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 10/20] avg loss: 4.4336061529408415		[learning rate: 0.01]
		[batch 20/20] avg loss: 4.258576739616743		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.346091446278792 | validation: 3.5405513187103907]
	TIME [epoch: 8.23 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study201/model_tr_study201_r3_20240219_233648/states/model_tr_study201_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 10/20] avg loss: 4.220221713315612		[learning rate: 0.01]
		[batch 20/20] avg loss: 4.206608635446537		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.213415174381074 | validation: 4.690858555477545]
	TIME [epoch: 8.22 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 10/20] avg loss: 4.255109813942762		[learning rate: 0.01]
		[batch 20/20] avg loss: 4.32523056832036		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.290170191131561 | validation: 4.1500985044766]
	TIME [epoch: 8.21 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.984570183677801		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.7537181740125014		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8691441788451515 | validation: 3.16306725578385]
	TIME [epoch: 8.21 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study201/model_tr_study201_r3_20240219_233648/states/model_tr_study201_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.700963114147639		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.6841409311943436		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6925520226709914 | validation: 3.641966037500972]
	TIME [epoch: 8.23 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.8127680587861086		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.5484807029763408		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6806243808812256 | validation: 2.8490343496122703]
	TIME [epoch: 8.24 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study201/model_tr_study201_r3_20240219_233648/states/model_tr_study201_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.5188524365323217		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.7420940003259866		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6304732184291546 | validation: 5.876767943308542]
	TIME [epoch: 8.22 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 10/20] avg loss: 4.001093885878065		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.475683382134963		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7383886340065144 | validation: 3.2084643070537764]
	TIME [epoch: 8.21 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.35865680320903		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.4197054827570037		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.389181142983017 | validation: 2.8767237422862997]
	TIME [epoch: 8.21 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.2876105001309512		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.3164980997931863		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3020542999620686 | validation: 2.923529573730832]
	TIME [epoch: 8.24 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.556073937988942		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.1509727180703555		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.353523328029649 | validation: 3.400278922418072]
	TIME [epoch: 8.21 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.3027275211826512		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.2611183272439193		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2819229242132857 | validation: 2.6092023571672343]
	TIME [epoch: 8.21 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study201/model_tr_study201_r3_20240219_233648/states/model_tr_study201_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.2111312338227167		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.1334990831301273		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1723151584764215 | validation: 2.4490482341049136]
	TIME [epoch: 8.21 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study201/model_tr_study201_r3_20240219_233648/states/model_tr_study201_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.0891437958763683		[learning rate: 0.01]
		[batch 20/20] avg loss: 4.034842582845409		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.561993189360888 | validation: 2.391808985511239]
	TIME [epoch: 8.23 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study201/model_tr_study201_r3_20240219_233648/states/model_tr_study201_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 10/20] avg loss: 2.94840854023455		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.734550848522135		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8414796943783425 | validation: 2.126256552220443]
	TIME [epoch: 8.22 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study201/model_tr_study201_r3_20240219_233648/states/model_tr_study201_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 10/20] avg loss: 2.4452004028302325		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.139610334492876		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.292405368661554 | validation: 2.021547252271448]
	TIME [epoch: 8.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study201/model_tr_study201_r3_20240219_233648/states/model_tr_study201_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 10/20] avg loss: 2.128393922937461		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.09138931331805		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.109891618127756 | validation: 2.2325286191969393]
	TIME [epoch: 8.21 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 10/20] avg loss: 2.089506684218686		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.4530978167873787		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2713022505030325 | validation: 2.8573895043738937]
	TIME [epoch: 8.22 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 10/20] avg loss: 2.143815567378978		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.132007448702436		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1379115080407067 | validation: 2.4139376128651726]
	TIME [epoch: 8.21 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.7015196758464346		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.7688179020736274		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.735168788960031 | validation: 1.8563912152063775]
	TIME [epoch: 8.22 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study201/model_tr_study201_r3_20240219_233648/states/model_tr_study201_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.549426164285605		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.6168568198017383		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.583141492043672 | validation: 1.3225693978891222]
	TIME [epoch: 8.21 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study201/model_tr_study201_r3_20240219_233648/states/model_tr_study201_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.5375823097963475		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.5402255154456896		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5389039126210182 | validation: 1.5789283739955149]
	TIME [epoch: 8.22 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.4800252007810406		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.916540918343761		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6982830595624008 | validation: 1.6792247961250855]
	TIME [epoch: 8.24 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.5789321007728776		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.6463434253356866		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6126377630542819 | validation: 1.490731794644465]
	TIME [epoch: 8.21 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 10/20] avg loss: 2.1296243338438097		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.831072037738234		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9803481857910217 | validation: 1.2770728289644664]
	TIME [epoch: 8.21 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study201/model_tr_study201_r3_20240219_233648/states/model_tr_study201_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.6708260335855265		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.6267757073780307		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6488008704817783 | validation: 1.734581256374293]
	TIME [epoch: 8.21 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.665916432800882		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.6033629044822462		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6346396686415645 | validation: 1.6804839410327075]
	TIME [epoch: 8.24 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.7891754171569303		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.765123424626087		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7771494208915084 | validation: 2.508396197120624]
	TIME [epoch: 8.21 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.7080049657134027		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.617098051085327		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6625515083993652 | validation: 1.5087058556115154]
	TIME [epoch: 8.21 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.6071459999545383		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.052556908260107		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8298514541073228 | validation: 1.4393272014887395]
	TIME [epoch: 8.21 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.5721806348300542		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.634154494289815		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6031675645599344 | validation: 1.413804157351939]
	TIME [epoch: 8.22 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.6730440327631757		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.7756628038956528		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.724353418329414 | validation: 1.4927545502756492]
	TIME [epoch: 8.24 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.6154617451264748		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.6220398036204462		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6187507743734604 | validation: 1.6352105495624492]
	TIME [epoch: 8.21 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.635504425218468		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.5330548596600024		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5842796424392351 | validation: 1.8861181069972668]
	TIME [epoch: 8.22 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.6702614124727937		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.9676084080363494		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8189349102545715 | validation: 1.3523477572875082]
	TIME [epoch: 8.21 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.7210854940955778		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.6124876752378854		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6667865846667311 | validation: 1.2672877243792602]
	TIME [epoch: 8.24 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study201/model_tr_study201_r3_20240219_233648/states/model_tr_study201_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.6398545664573831		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.6057986816329168		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.62282662404515 | validation: 1.4399278382535354]
	TIME [epoch: 8.22 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.577108119394002		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.633629065917783		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6053685926558927 | validation: 3.1512615046095327]
	TIME [epoch: 8.22 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.8446459454114936		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.9099877573734083		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8773168513924514 | validation: 2.430451567629722]
	TIME [epoch: 8.22 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.964267349196107		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.4901253508599472		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7271963500280272 | validation: 1.6418184192292817]
	TIME [epoch: 8.23 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.5447544850883745		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.5501446743824738		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.547449579735424 | validation: 1.7781173542665114]
	TIME [epoch: 8.22 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.6295857869097177		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.5350637538048895		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5823247703573036 | validation: 2.9468776834500097]
	TIME [epoch: 8.22 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 10/20] avg loss: 2.2243362024413584		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.5196825119518178		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8720093571965883 | validation: 1.521037896312954]
	TIME [epoch: 8.21 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.730154319346486		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.7038605026287932		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7170074109876396 | validation: 1.510479516096297]
	TIME [epoch: 8.22 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.8243082504643897		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.5852192872663884		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.704763768865389 | validation: 1.3814168760467025]
	TIME [epoch: 8.25 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.488376487948989		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.4722139676803945		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4802952278146915 | validation: 1.4845939457993909]
	TIME [epoch: 8.22 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.5546785572542423		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.5161812260432073		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5354298916487248 | validation: 1.2181393852501068]
	TIME [epoch: 8.22 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study201/model_tr_study201_r3_20240219_233648/states/model_tr_study201_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.48900540683778		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.4791344426781936		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.484069924757987 | validation: 1.6956539096103735]
	TIME [epoch: 8.21 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.877920161935067		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.0763400629442383		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9771301124396525 | validation: 1.2711426589764714]
	TIME [epoch: 8.22 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.637501581474396		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.4734868095761566		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5554941955252761 | validation: 1.0059941595778834]
	TIME [epoch: 8.21 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study201/model_tr_study201_r3_20240219_233648/states/model_tr_study201_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.6785031997026707		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.5645150560945582		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6215091278986145 | validation: 1.2579407494853827]
	TIME [epoch: 8.21 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.4583916721503736		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.486471498340455		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.472431585245414 | validation: 1.8502688739808573]
	TIME [epoch: 8.21 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.5517186435023365		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.6183970764011648		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5850578599517506 | validation: 1.274791540548431]
	TIME [epoch: 8.23 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.4847047235233561		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.3738595134891742		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4292821185062647 | validation: 1.5572739913109868]
	TIME [epoch: 8.23 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.5300875410585064		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.5004135116136637		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5152505263360854 | validation: 1.2158794354155775]
	TIME [epoch: 8.22 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.5202409619744903		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.543265852229606		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5317534071020484 | validation: 1.6477782232909148]
	TIME [epoch: 8.22 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.5701851917774594		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.4830201310411903		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5266026614093249 | validation: 1.4534982643826044]
	TIME [epoch: 8.21 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.5698347674337811		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.3908682483593706		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4803515078965757 | validation: 1.154196555885023]
	TIME [epoch: 8.24 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.4743830967479028		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.5929477940428198		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5336654453953615 | validation: 1.0540636096966556]
	TIME [epoch: 8.22 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.3740088150955656		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.4179384583231713		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3959736367093685 | validation: 1.0714484594759992]
	TIME [epoch: 8.22 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.3823001784050044		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.5130868983675203		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4476935383862624 | validation: 2.779741938613214]
	TIME [epoch: 8.21 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.6980816456783132		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.5390588269023295		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6185702362903212 | validation: 2.497481921530136]
	TIME [epoch: 8.24 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.621580165959024		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.3273699785991138		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.474475072279069 | validation: 0.9629539303114513]
	TIME [epoch: 8.22 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study201/model_tr_study201_r3_20240219_233648/states/model_tr_study201_84.pth
	Model improved!!!
EPOCH 85/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.2579552156187885		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.2739093817493319		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2659322986840604 | validation: 1.1546603165501932]
	TIME [epoch: 8.21 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.50674123338528		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.4378743029191094		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4723077681521948 | validation: 1.7354838042286749]
	TIME [epoch: 8.2 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.5083012144993444		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.3510555420277728		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4296783782635587 | validation: 1.0527825006609777]
	TIME [epoch: 8.2 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.2875902651211617		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.29972917479684		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.293659719959001 | validation: 1.315633065951388]
	TIME [epoch: 8.22 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.2373784678855164		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.2339174506087047		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2356479592471106 | validation: 2.061014067262568]
	TIME [epoch: 8.2 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.5483416500497438		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.3137889598925612		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4310653049711521 | validation: 0.9523809710908824]
	TIME [epoch: 8.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study201/model_tr_study201_r3_20240219_233648/states/model_tr_study201_90.pth
	Model improved!!!
EPOCH 91/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.5163118377854228		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.171599783843608		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3439558108145155 | validation: 1.7019812227677575]
	TIME [epoch: 8.22 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.3587462567258113		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.427013802970469		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.39288002984814 | validation: 0.9483782302336565]
	TIME [epoch: 8.23 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study201/model_tr_study201_r3_20240219_233648/states/model_tr_study201_92.pth
	Model improved!!!
EPOCH 93/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.4519786187207997		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.163921757293061		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3079501880069304 | validation: 1.6294715033305696]
	TIME [epoch: 8.22 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.2568655183132211		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.3481252429005541		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.302495380606888 | validation: 0.9246586391077813]
	TIME [epoch: 8.21 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study201/model_tr_study201_r3_20240219_233648/states/model_tr_study201_94.pth
	Model improved!!!
EPOCH 95/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.5083525466369354		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.3486835589606971		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4285180527988166 | validation: 1.8233475980955283]
	TIME [epoch: 8.22 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.3396074522288317		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.4211604782014886		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.38038396521516 | validation: 0.8775593117847049]
	TIME [epoch: 8.23 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study201/model_tr_study201_r3_20240219_233648/states/model_tr_study201_96.pth
	Model improved!!!
EPOCH 97/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.2300066806820493		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.5102232133125164		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3701149469972826 | validation: 1.8340327229739235]
	TIME [epoch: 8.22 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.4464053413103268		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.3105617526677151		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3784835469890213 | validation: 2.7523006361310873]
	TIME [epoch: 8.21 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.5169255090762763		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.16401132655349		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3404684178148827 | validation: 1.273965579319203]
	TIME [epoch: 8.21 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.3415919171640482		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.1815554039151575		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2615736605396028 | validation: 0.8306422386941118]
	TIME [epoch: 8.22 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study201/model_tr_study201_r3_20240219_233648/states/model_tr_study201_100.pth
	Model improved!!!
EPOCH 101/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.3045475954147956		[learning rate: 0.0099837]
		[batch 20/20] avg loss: 1.1491384348229159		[learning rate: 0.0099655]
	Learning Rate: 0.00996552
	LOSS [training: 1.226843015118856 | validation: 2.3243387270879774]
	TIME [epoch: 8.25 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.2999166483149722		[learning rate: 0.0099474]
		[batch 20/20] avg loss: 1.3253035298263909		[learning rate: 0.0099294]
	Learning Rate: 0.00992935
	LOSS [training: 1.3126100890706818 | validation: 1.0414390629114672]
	TIME [epoch: 8.22 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.2680563142770065		[learning rate: 0.0099113]
		[batch 20/20] avg loss: 1.2569720777152127		[learning rate: 0.0098933]
	Learning Rate: 0.00989332
	LOSS [training: 1.2625141959961095 | validation: 0.8257106844180953]
	TIME [epoch: 8.21 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study201/model_tr_study201_r3_20240219_233648/states/model_tr_study201_103.pth
	Model improved!!!
EPOCH 104/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.158483531318484		[learning rate: 0.0098754]
		[batch 20/20] avg loss: 1.2716207714435144		[learning rate: 0.0098574]
	Learning Rate: 0.00985742
	LOSS [training: 1.2150521513809989 | validation: 1.111449897306895]
	TIME [epoch: 8.2 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.211252154159793		[learning rate: 0.0098395]
		[batch 20/20] avg loss: 1.6122825339436122		[learning rate: 0.0098216]
	Learning Rate: 0.00982164
	LOSS [training: 1.4117673440517025 | validation: 1.786518426428276]
	TIME [epoch: 8.23 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.322533185060387		[learning rate: 0.0098038]
		[batch 20/20] avg loss: 1.1520698335890274		[learning rate: 0.009786]
	Learning Rate: 0.009786
	LOSS [training: 1.237301509324707 | validation: 1.0119603745914092]
	TIME [epoch: 8.2 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.294838447832137		[learning rate: 0.0097682]
		[batch 20/20] avg loss: 1.2006096364809957		[learning rate: 0.0097505]
	Learning Rate: 0.00975049
	LOSS [training: 1.2477240421565665 | validation: 1.1774125024861577]
	TIME [epoch: 8.21 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.1064185579910593		[learning rate: 0.0097328]
		[batch 20/20] avg loss: 1.1856682519632786		[learning rate: 0.0097151]
	Learning Rate: 0.0097151
	LOSS [training: 1.1460434049771688 | validation: 1.0229863324767132]
	TIME [epoch: 8.2 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.3694966667303239		[learning rate: 0.0096975]
		[batch 20/20] avg loss: 1.0657772252253956		[learning rate: 0.0096798]
	Learning Rate: 0.00967984
	LOSS [training: 1.2176369459778598 | validation: 1.2287808820543082]
	TIME [epoch: 8.22 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.6632729712343584		[learning rate: 0.0096623]
		[batch 20/20] avg loss: 1.532152602711357		[learning rate: 0.0096447]
	Learning Rate: 0.00964472
	LOSS [training: 1.5977127869728578 | validation: 0.7763617777427991]
	TIME [epoch: 8.22 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study201/model_tr_study201_r3_20240219_233648/states/model_tr_study201_110.pth
	Model improved!!!
EPOCH 111/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.086130322485889		[learning rate: 0.0096272]
		[batch 20/20] avg loss: 1.0316234927013987		[learning rate: 0.0096097]
	Learning Rate: 0.00960972
	LOSS [training: 1.058876907593644 | validation: 0.9830556425549183]
	TIME [epoch: 8.21 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.4757752756885598		[learning rate: 0.0095923]
		[batch 20/20] avg loss: 1.7214412442786724		[learning rate: 0.0095748]
	Learning Rate: 0.00957484
	LOSS [training: 1.598608259983616 | validation: 1.5303583667692178]
	TIME [epoch: 8.21 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.25885854693403		[learning rate: 0.0095575]
		[batch 20/20] avg loss: 1.0417055377481956		[learning rate: 0.0095401]
	Learning Rate: 0.00954009
	LOSS [training: 1.1502820423411126 | validation: 1.9613769279566968]
	TIME [epoch: 8.2 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.4034569428304828		[learning rate: 0.0095228]
		[batch 20/20] avg loss: 1.2387360576567088		[learning rate: 0.0095055]
	Learning Rate: 0.00950547
	LOSS [training: 1.3210965002435957 | validation: 0.9059708372605662]
	TIME [epoch: 8.24 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.3005928036439303		[learning rate: 0.0094882]
		[batch 20/20] avg loss: 1.1148407418206534		[learning rate: 0.009471]
	Learning Rate: 0.00947098
	LOSS [training: 1.2077167727322922 | validation: 0.6964588073191404]
	TIME [epoch: 8.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study201/model_tr_study201_r3_20240219_233648/states/model_tr_study201_115.pth
	Model improved!!!
EPOCH 116/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.2146106318235934		[learning rate: 0.0094538]
		[batch 20/20] avg loss: 1.9747315307807258		[learning rate: 0.0094366]
	Learning Rate: 0.0094366
	LOSS [training: 1.59467108130216 | validation: 2.492381039721761]
	TIME [epoch: 8.21 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.4614663987239012		[learning rate: 0.0094195]
		[batch 20/20] avg loss: 1.19944640380997		[learning rate: 0.0094024]
	Learning Rate: 0.00940236
	LOSS [training: 1.3304564012669355 | validation: 0.8933339657137512]
	TIME [epoch: 8.21 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.0525926617505799		[learning rate: 0.0093853]
		[batch 20/20] avg loss: 1.344740837525399		[learning rate: 0.0093682]
	Learning Rate: 0.00936824
	LOSS [training: 1.1986667496379897 | validation: 0.7212967777301974]
	TIME [epoch: 8.23 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.2536694301684757		[learning rate: 0.0093512]
		[batch 20/20] avg loss: 0.9736321973757761		[learning rate: 0.0093342]
	Learning Rate: 0.00933424
	LOSS [training: 1.1136508137721257 | validation: 1.142953362617646]
	TIME [epoch: 8.21 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.036282644556699		[learning rate: 0.0093173]
		[batch 20/20] avg loss: 1.1798997406601126		[learning rate: 0.0093004]
	Learning Rate: 0.00930036
	LOSS [training: 1.1080911926084058 | validation: 1.2764685368497264]
	TIME [epoch: 8.2 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.0721765993362173		[learning rate: 0.0092835]
		[batch 20/20] avg loss: 1.8450307932999013		[learning rate: 0.0092666]
	Learning Rate: 0.00926661
	LOSS [training: 1.4586036963180595 | validation: 2.163724340267887]
	TIME [epoch: 8.21 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.4405236169686475		[learning rate: 0.0092498]
		[batch 20/20] avg loss: 1.051563023452151		[learning rate: 0.009233]
	Learning Rate: 0.00923298
	LOSS [training: 1.2460433202103993 | validation: 0.9686591163570917]
	TIME [epoch: 8.23 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.088084869628612		[learning rate: 0.0092162]
		[batch 20/20] avg loss: 1.2496679219551245		[learning rate: 0.0091995]
	Learning Rate: 0.00919948
	LOSS [training: 1.1688763957918682 | validation: 0.818470239609888]
	TIME [epoch: 8.22 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.181440601250179		[learning rate: 0.0091828]
		[batch 20/20] avg loss: 1.031706473362447		[learning rate: 0.0091661]
	Learning Rate: 0.00916609
	LOSS [training: 1.1065735373063128 | validation: 1.2015512547658203]
	TIME [epoch: 8.21 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.022831388847706		[learning rate: 0.0091494]
		[batch 20/20] avg loss: 0.9335468054685219		[learning rate: 0.0091328]
	Learning Rate: 0.00913283
	LOSS [training: 0.9781890971581142 | validation: 0.7912593028437573]
	TIME [epoch: 8.2 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.0809695418134955		[learning rate: 0.0091162]
		[batch 20/20] avg loss: 0.9503876988699226		[learning rate: 0.0090997]
	Learning Rate: 0.00909968
	LOSS [training: 1.0156786203417094 | validation: 1.540294322427977]
	TIME [epoch: 8.21 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.039510818040335		[learning rate: 0.0090832]
		[batch 20/20] avg loss: 0.9708588515070998		[learning rate: 0.0090667]
	Learning Rate: 0.00906666
	LOSS [training: 1.0051848347737173 | validation: 0.9857915932297645]
	TIME [epoch: 8.23 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.0732620610681693		[learning rate: 0.0090502]
		[batch 20/20] avg loss: 1.0667216052284902		[learning rate: 0.0090338]
	Learning Rate: 0.00903376
	LOSS [training: 1.0699918331483298 | validation: 0.5679078799391223]
	TIME [epoch: 8.21 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study201/model_tr_study201_r3_20240219_233648/states/model_tr_study201_128.pth
	Model improved!!!
EPOCH 129/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.0949814345932762		[learning rate: 0.0090174]
		[batch 20/20] avg loss: 1.9742562066978082		[learning rate: 0.009001]
	Learning Rate: 0.00900097
	LOSS [training: 1.5346188206455422 | validation: 1.9844663097444974]
	TIME [epoch: 8.21 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.6682406108514674		[learning rate: 0.0089846]
		[batch 20/20] avg loss: 1.1425529127438674		[learning rate: 0.0089683]
	Learning Rate: 0.00896831
	LOSS [training: 1.4053967617976675 | validation: 0.7278553315885227]
	TIME [epoch: 8.2 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.9575042001803513		[learning rate: 0.008952]
		[batch 20/20] avg loss: 1.2247115472576506		[learning rate: 0.0089358]
	Learning Rate: 0.00893576
	LOSS [training: 1.0911078737190012 | validation: 0.7246157768883605]
	TIME [epoch: 8.22 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.8595127753062926		[learning rate: 0.0089195]
		[batch 20/20] avg loss: 1.0548638267397532		[learning rate: 0.0089033]
	Learning Rate: 0.00890333
	LOSS [training: 0.9571883010230231 | validation: 1.268053482566397]
	TIME [epoch: 8.21 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.396508617994162		[learning rate: 0.0088872]
		[batch 20/20] avg loss: 0.9897500826350593		[learning rate: 0.008871]
	Learning Rate: 0.00887102
	LOSS [training: 1.1931293503146105 | validation: 0.9830936874992706]
	TIME [epoch: 8.21 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.9573377444090367		[learning rate: 0.0088549]
		[batch 20/20] avg loss: 0.9732398964588442		[learning rate: 0.0088388]
	Learning Rate: 0.00883883
	LOSS [training: 0.9652888204339403 | validation: 0.6748529701891887]
	TIME [epoch: 8.21 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.935552846158898		[learning rate: 0.0088228]
		[batch 20/20] avg loss: 1.1190397319467082		[learning rate: 0.0088068]
	Learning Rate: 0.00880675
	LOSS [training: 1.0272962890528032 | validation: 0.8863813364182386]
	TIME [epoch: 8.21 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.9919914159652004		[learning rate: 0.0087908]
		[batch 20/20] avg loss: 0.8464673756623385		[learning rate: 0.0087748]
	Learning Rate: 0.00877479
	LOSS [training: 0.9192293958137693 | validation: 1.5484943917862635]
	TIME [epoch: 8.24 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.3642513715739755		[learning rate: 0.0087589]
		[batch 20/20] avg loss: 1.2952390705105707		[learning rate: 0.0087429]
	Learning Rate: 0.00874295
	LOSS [training: 1.329745221042273 | validation: 0.560571139218882]
	TIME [epoch: 8.21 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study201/model_tr_study201_r3_20240219_233648/states/model_tr_study201_137.pth
	Model improved!!!
EPOCH 138/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.1833945795455088		[learning rate: 0.0087271]
		[batch 20/20] avg loss: 1.1972486199835282		[learning rate: 0.0087112]
	Learning Rate: 0.00871122
	LOSS [training: 1.1903215997645185 | validation: 1.1893305151425768]
	TIME [epoch: 8.21 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.2989824007666706		[learning rate: 0.0086954]
		[batch 20/20] avg loss: 1.036798521183179		[learning rate: 0.0086796]
	Learning Rate: 0.00867961
	LOSS [training: 1.167890460974925 | validation: 0.8385882802541044]
	TIME [epoch: 8.2 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.2658608929093798		[learning rate: 0.0086638]
		[batch 20/20] avg loss: 1.1754497948976188		[learning rate: 0.0086481]
	Learning Rate: 0.00864811
	LOSS [training: 1.2206553439034993 | validation: 0.8420749544981357]
	TIME [epoch: 8.23 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.8499122944116045		[learning rate: 0.0086324]
		[batch 20/20] avg loss: 1.2407745758057782		[learning rate: 0.0086167]
	Learning Rate: 0.00861672
	LOSS [training: 1.0453434351086912 | validation: 1.6236829345776183]
	TIME [epoch: 8.21 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.3515426615646802		[learning rate: 0.0086011]
		[batch 20/20] avg loss: 0.850575297546148		[learning rate: 0.0085855]
	Learning Rate: 0.00858545
	LOSS [training: 1.1010589795554142 | validation: 0.7573407974245066]
	TIME [epoch: 8.2 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.0710873069720508		[learning rate: 0.0085699]
		[batch 20/20] avg loss: 1.4287120347445104		[learning rate: 0.0085543]
	Learning Rate: 0.00855429
	LOSS [training: 1.2498996708582806 | validation: 0.85481553609239]
	TIME [epoch: 8.21 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.8902753324524199		[learning rate: 0.0085388]
		[batch 20/20] avg loss: 0.861390838450725		[learning rate: 0.0085232]
	Learning Rate: 0.00852325
	LOSS [training: 0.8758330854515723 | validation: 1.0541043801814756]
	TIME [epoch: 8.22 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.0869339604771902		[learning rate: 0.0085078]
		[batch 20/20] avg loss: 1.0185620525336154		[learning rate: 0.0084923]
	Learning Rate: 0.00849232
	LOSS [training: 1.052748006505403 | validation: 0.8930927312142068]
	TIME [epoch: 8.21 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.9387592170295426		[learning rate: 0.0084769]
		[batch 20/20] avg loss: 0.8703567828874462		[learning rate: 0.0084615]
	Learning Rate: 0.0084615
	LOSS [training: 0.9045579999584945 | validation: 1.1975130870963555]
	TIME [epoch: 8.2 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.252575704614606		[learning rate: 0.0084461]
		[batch 20/20] avg loss: 1.0349711551850502		[learning rate: 0.0084308]
	Learning Rate: 0.00843079
	LOSS [training: 1.1437734298998286 | validation: 0.8826490975283837]
	TIME [epoch: 8.2 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.0094058350185773		[learning rate: 0.0084155]
		[batch 20/20] avg loss: 0.9855717066500407		[learning rate: 0.0084002]
	Learning Rate: 0.0084002
	LOSS [training: 0.997488770834309 | validation: 0.5761352744323585]
	TIME [epoch: 8.21 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.0251775915117824		[learning rate: 0.0083849]
		[batch 20/20] avg loss: 1.8879066197790262		[learning rate: 0.0083697]
	Learning Rate: 0.00836971
	LOSS [training: 1.4565421056454044 | validation: 1.3490053631132721]
	TIME [epoch: 8.23 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.6054131173366777		[learning rate: 0.0083545]
		[batch 20/20] avg loss: 1.1161894428866999		[learning rate: 0.0083393]
	Learning Rate: 0.00833934
	LOSS [training: 1.3608012801116893 | validation: 0.8913347678780503]
	TIME [epoch: 8.2 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.9896216309315102		[learning rate: 0.0083242]
		[batch 20/20] avg loss: 1.0890670672021034		[learning rate: 0.0083091]
	Learning Rate: 0.00830907
	LOSS [training: 1.0393443490668068 | validation: 0.9791042252806079]
	TIME [epoch: 8.2 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.8994185171817846		[learning rate: 0.008294]
		[batch 20/20] avg loss: 0.8068026375050776		[learning rate: 0.0082789]
	Learning Rate: 0.00827892
	LOSS [training: 0.8531105773434311 | validation: 0.9826668945418728]
	TIME [epoch: 8.2 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.9417276870737077		[learning rate: 0.0082639]
		[batch 20/20] avg loss: 1.3150346708832532		[learning rate: 0.0082489]
	Learning Rate: 0.00824887
	LOSS [training: 1.1283811789784806 | validation: 0.8439959601111645]
	TIME [epoch: 8.21 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.1595914844798085		[learning rate: 0.0082339]
		[batch 20/20] avg loss: 1.2372386573303555		[learning rate: 0.0082189]
	Learning Rate: 0.00821894
	LOSS [training: 1.198415070905082 | validation: 0.5386265010337278]
	TIME [epoch: 8.21 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study201/model_tr_study201_r3_20240219_233648/states/model_tr_study201_154.pth
	Model improved!!!
EPOCH 155/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.1610947870289583		[learning rate: 0.008204]
		[batch 20/20] avg loss: 0.8674268345244156		[learning rate: 0.0081891]
	Learning Rate: 0.00818911
	LOSS [training: 1.014260810776687 | validation: 0.9371185259221675]
	TIME [epoch: 8.2 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.0279622224760663		[learning rate: 0.0081742]
		[batch 20/20] avg loss: 0.9892068256207265		[learning rate: 0.0081594]
	Learning Rate: 0.00815939
	LOSS [training: 1.0085845240483964 | validation: 1.160679234898532]
	TIME [epoch: 8.2 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.7790607147364363		[learning rate: 0.0081446]
		[batch 20/20] avg loss: 0.9065561843999212		[learning rate: 0.0081298]
	Learning Rate: 0.00812978
	LOSS [training: 0.8428084495681787 | validation: 1.1478764933887748]
	TIME [epoch: 8.21 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.0157696772249412		[learning rate: 0.008115]
		[batch 20/20] avg loss: 0.9369637322860165		[learning rate: 0.0081003]
	Learning Rate: 0.00810028
	LOSS [training: 0.976366704755479 | validation: 1.1901316636496237]
	TIME [epoch: 8.24 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.9724838000330379		[learning rate: 0.0080856]
		[batch 20/20] avg loss: 1.073678442193888		[learning rate: 0.0080709]
	Learning Rate: 0.00807088
	LOSS [training: 1.023081121113463 | validation: 0.6589641815402529]
	TIME [epoch: 8.21 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.84064303968025		[learning rate: 0.0080562]
		[batch 20/20] avg loss: 0.9698884143359752		[learning rate: 0.0080416]
	Learning Rate: 0.00804159
	LOSS [training: 0.9052657270081126 | validation: 0.8048194948515163]
	TIME [epoch: 8.21 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.9252382920771056		[learning rate: 0.008027]
		[batch 20/20] avg loss: 0.9023344277726217		[learning rate: 0.0080124]
	Learning Rate: 0.00801241
	LOSS [training: 0.9137863599248636 | validation: 0.880718558752355]
	TIME [epoch: 8.21 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.1056837334329401		[learning rate: 0.0079979]
		[batch 20/20] avg loss: 1.044814285978695		[learning rate: 0.0079833]
	Learning Rate: 0.00798333
	LOSS [training: 1.0752490097058178 | validation: 0.8457439132454041]
	TIME [epoch: 8.23 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.1287891107672992		[learning rate: 0.0079688]
		[batch 20/20] avg loss: 0.8181589409542575		[learning rate: 0.0079544]
	Learning Rate: 0.00795436
	LOSS [training: 0.9734740258607782 | validation: 0.851317250590457]
	TIME [epoch: 8.21 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.817686141542343		[learning rate: 0.0079399]
		[batch 20/20] avg loss: 0.7770516724768997		[learning rate: 0.0079255]
	Learning Rate: 0.00792549
	LOSS [training: 0.7973689070096215 | validation: 0.6635257863088595]
	TIME [epoch: 8.2 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.7926160230306813		[learning rate: 0.0079111]
		[batch 20/20] avg loss: 1.0586512069999021		[learning rate: 0.0078967]
	Learning Rate: 0.00789673
	LOSS [training: 0.9256336150152915 | validation: 0.6551705108374202]
	TIME [epoch: 8.21 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.8857170037291011		[learning rate: 0.0078824]
		[batch 20/20] avg loss: 0.7096882485248976		[learning rate: 0.0078681]
	Learning Rate: 0.00786807
	LOSS [training: 0.7977026261269995 | validation: 0.7486302058512131]
	TIME [epoch: 8.21 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.7720663712404052		[learning rate: 0.0078538]
		[batch 20/20] avg loss: 0.757736186813835		[learning rate: 0.0078395]
	Learning Rate: 0.00783952
	LOSS [training: 0.7649012790271199 | validation: 0.7162400449345415]
	TIME [epoch: 8.23 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.8794084588461999		[learning rate: 0.0078253]
		[batch 20/20] avg loss: 0.8018773419587439		[learning rate: 0.0078111]
	Learning Rate: 0.00781107
	LOSS [training: 0.8406429004024719 | validation: 0.6294582947937251]
	TIME [epoch: 8.21 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.914041335642558		[learning rate: 0.0077969]
		[batch 20/20] avg loss: 0.7513030540447608		[learning rate: 0.0077827]
	Learning Rate: 0.00778272
	LOSS [training: 0.8326721948436594 | validation: 0.6126310106331246]
	TIME [epoch: 8.21 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.7745369074498857		[learning rate: 0.0077686]
		[batch 20/20] avg loss: 0.9056642396320671		[learning rate: 0.0077545]
	Learning Rate: 0.00775448
	LOSS [training: 0.8401005735409764 | validation: 0.49268654016549296]
	TIME [epoch: 8.21 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study201/model_tr_study201_r3_20240219_233648/states/model_tr_study201_170.pth
	Model improved!!!
EPOCH 171/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.7961307482516864		[learning rate: 0.0077404]
		[batch 20/20] avg loss: 0.771226286392883		[learning rate: 0.0077263]
	Learning Rate: 0.00772634
	LOSS [training: 0.7836785173222846 | validation: 0.7398844545995676]
	TIME [epoch: 8.23 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.0525807032126617		[learning rate: 0.0077123]
		[batch 20/20] avg loss: 0.9867824396409903		[learning rate: 0.0076983]
	Learning Rate: 0.0076983
	LOSS [training: 1.0196815714268257 | validation: 0.9346225753359511]
	TIME [epoch: 8.21 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.9507093248349744		[learning rate: 0.0076843]
		[batch 20/20] avg loss: 1.0506585101570591		[learning rate: 0.0076704]
	Learning Rate: 0.00767036
	LOSS [training: 1.0006839174960167 | validation: 0.6521688773968232]
	TIME [epoch: 8.21 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.8239434045681747		[learning rate: 0.0076564]
		[batch 20/20] avg loss: 0.9904019029952554		[learning rate: 0.0076425]
	Learning Rate: 0.00764252
	LOSS [training: 0.9071726537817151 | validation: 0.6606883023932089]
	TIME [epoch: 8.21 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.9499822912955741		[learning rate: 0.0076286]
		[batch 20/20] avg loss: 1.0979576230947088		[learning rate: 0.0076148]
	Learning Rate: 0.00761479
	LOSS [training: 1.0239699571951413 | validation: 0.7937416249178071]
	TIME [epoch: 8.22 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.0010503415646197		[learning rate: 0.007601]
		[batch 20/20] avg loss: 0.8050219217714286		[learning rate: 0.0075872]
	Learning Rate: 0.00758715
	LOSS [training: 0.9030361316680242 | validation: 0.6548608529380264]
	TIME [epoch: 8.21 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.8876524682593976		[learning rate: 0.0075734]
		[batch 20/20] avg loss: 0.7906588495750345		[learning rate: 0.0075596]
	Learning Rate: 0.00755962
	LOSS [training: 0.8391556589172161 | validation: 0.562587989597669]
	TIME [epoch: 8.19 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.9873804210223923		[learning rate: 0.0075459]
		[batch 20/20] avg loss: 0.7172899437134028		[learning rate: 0.0075322]
	Learning Rate: 0.00753219
	LOSS [training: 0.8523351823678975 | validation: 0.7954018040304249]
	TIME [epoch: 8.19 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.8882359436206742		[learning rate: 0.0075185]
		[batch 20/20] avg loss: 0.7555862243677921		[learning rate: 0.0075049]
	Learning Rate: 0.00750485
	LOSS [training: 0.8219110839942332 | validation: 0.6988143025073958]
	TIME [epoch: 8.21 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.8792887566146084		[learning rate: 0.0074912]
		[batch 20/20] avg loss: 0.9490223479280244		[learning rate: 0.0074776]
	Learning Rate: 0.00747762
	LOSS [training: 0.9141555522713165 | validation: 0.5718931854311817]
	TIME [epoch: 8.22 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.9623159668038902		[learning rate: 0.007464]
		[batch 20/20] avg loss: 0.8423596352273215		[learning rate: 0.0074505]
	Learning Rate: 0.00745048
	LOSS [training: 0.9023378010156058 | validation: 0.4360976095075649]
	TIME [epoch: 8.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study201/model_tr_study201_r3_20240219_233648/states/model_tr_study201_181.pth
	Model improved!!!
EPOCH 182/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.853444780997183		[learning rate: 0.0074369]
		[batch 20/20] avg loss: 1.1344237157816466		[learning rate: 0.0074234]
	Learning Rate: 0.00742344
	LOSS [training: 0.9939342483894146 | validation: 1.1846841292674162]
	TIME [epoch: 8.21 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.8632189614108977		[learning rate: 0.00741]
		[batch 20/20] avg loss: 0.8376648143745756		[learning rate: 0.0073965]
	Learning Rate: 0.0073965
	LOSS [training: 0.8504418878927368 | validation: 1.0075483486300667]
	TIME [epoch: 8.21 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.1132574441380831		[learning rate: 0.0073831]
		[batch 20/20] avg loss: 0.9151573221796138		[learning rate: 0.0073697]
	Learning Rate: 0.00736966
	LOSS [training: 1.0142073831588485 | validation: 0.5837678175516945]
	TIME [epoch: 8.22 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.7747444296819938		[learning rate: 0.0073563]
		[batch 20/20] avg loss: 1.2269049164781014		[learning rate: 0.0073429]
	Learning Rate: 0.00734291
	LOSS [training: 1.0008246730800476 | validation: 0.6835693747417293]
	TIME [epoch: 8.24 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.0011695728182126		[learning rate: 0.0073296]
		[batch 20/20] avg loss: 0.7407860571481631		[learning rate: 0.0073163]
	Learning Rate: 0.00731627
	LOSS [training: 0.8709778149831878 | validation: 1.367371877879268]
	TIME [epoch: 8.29 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.895175067438258		[learning rate: 0.007303]
		[batch 20/20] avg loss: 0.7427925135493126		[learning rate: 0.0072897]
	Learning Rate: 0.00728971
	LOSS [training: 0.8189837904937853 | validation: 0.636876363179474]
	TIME [epoch: 8.25 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.7504086945554423		[learning rate: 0.0072765]
		[batch 20/20] avg loss: 0.7058548496230768		[learning rate: 0.0072633]
	Learning Rate: 0.00726326
	LOSS [training: 0.7281317720892597 | validation: 0.5795196673784592]
	TIME [epoch: 8.25 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.0744498563114537		[learning rate: 0.0072501]
		[batch 20/20] avg loss: 0.9118824386824713		[learning rate: 0.0072369]
	Learning Rate: 0.0072369
	LOSS [training: 0.9931661474969626 | validation: 0.9003586005350024]
	TIME [epoch: 8.31 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.2173101384453744		[learning rate: 0.0072238]
		[batch 20/20] avg loss: 0.8140080914093698		[learning rate: 0.0072106]
	Learning Rate: 0.00721064
	LOSS [training: 1.0156591149273722 | validation: 0.4951744549522859]
	TIME [epoch: 8.3 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.0069449586392885		[learning rate: 0.0071975]
		[batch 20/20] avg loss: 0.9198693619744335		[learning rate: 0.0071845]
	Learning Rate: 0.00718447
	LOSS [training: 0.963407160306861 | validation: 0.6632215086073823]
	TIME [epoch: 8.29 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.6620498331816466		[learning rate: 0.0071714]
		[batch 20/20] avg loss: 0.9919323537991781		[learning rate: 0.0071584]
	Learning Rate: 0.0071584
	LOSS [training: 0.8269910934904123 | validation: 0.6313367268654085]
	TIME [epoch: 8.29 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.7971707376674028		[learning rate: 0.0071454]
		[batch 20/20] avg loss: 0.7856690633943525		[learning rate: 0.0071324]
	Learning Rate: 0.00713242
	LOSS [training: 0.7914199005308776 | validation: 1.163131159027044]
	TIME [epoch: 8.4 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.8371113387003568		[learning rate: 0.0071195]
		[batch 20/20] avg loss: 0.7828840299624271		[learning rate: 0.0071065]
	Learning Rate: 0.00710653
	LOSS [training: 0.809997684331392 | validation: 0.5820156046131393]
	TIME [epoch: 8.39 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.8767569543877359		[learning rate: 0.0070936]
		[batch 20/20] avg loss: 1.073772656052585		[learning rate: 0.0070807]
	Learning Rate: 0.00708074
	LOSS [training: 0.9752648052201603 | validation: 0.816195189918973]
	TIME [epoch: 8.33 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.0565418151875259		[learning rate: 0.0070679]
		[batch 20/20] avg loss: 0.7795992301425876		[learning rate: 0.007055]
	Learning Rate: 0.00705505
	LOSS [training: 0.9180705226650565 | validation: 0.8408933376712997]
	TIME [epoch: 8.25 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.8054978495243852		[learning rate: 0.0070422]
		[batch 20/20] avg loss: 0.9135199456767713		[learning rate: 0.0070294]
	Learning Rate: 0.00702945
	LOSS [training: 0.8595088976005784 | validation: 0.99770955515479]
	TIME [epoch: 8.28 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.0050990303600151		[learning rate: 0.0070167]
		[batch 20/20] avg loss: 0.9332437103831678		[learning rate: 0.0070039]
	Learning Rate: 0.00700394
	LOSS [training: 0.9691713703715917 | validation: 0.48739444994664194]
	TIME [epoch: 8.25 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.827748955295526		[learning rate: 0.0069912]
		[batch 20/20] avg loss: 1.1682946313911895		[learning rate: 0.0069785]
	Learning Rate: 0.00697852
	LOSS [training: 0.9980217933433575 | validation: 1.0674044657375787]
	TIME [epoch: 8.27 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.1067228887256124		[learning rate: 0.0069658]
		[batch 20/20] avg loss: 0.8137826021406473		[learning rate: 0.0069532]
	Learning Rate: 0.00695319
	LOSS [training: 0.9602527454331298 | validation: 1.1988135392611898]
	TIME [epoch: 8.3 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.8439252713617857		[learning rate: 0.0069406]
		[batch 20/20] avg loss: 0.9674870883590085		[learning rate: 0.006928]
	Learning Rate: 0.00692796
	LOSS [training: 0.9057061798603969 | validation: 0.8543356804778163]
	TIME [epoch: 8.31 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.9634768425471958		[learning rate: 0.0069154]
		[batch 20/20] avg loss: 0.7767336804652143		[learning rate: 0.0069028]
	Learning Rate: 0.00690282
	LOSS [training: 0.8701052615062052 | validation: 0.8825343986990924]
	TIME [epoch: 8.27 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.0775540536558539		[learning rate: 0.0068903]
		[batch 20/20] avg loss: 0.6667713168819633		[learning rate: 0.0068778]
	Learning Rate: 0.00687777
	LOSS [training: 0.8721626852689086 | validation: 0.7115716743473561]
	TIME [epoch: 8.33 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.997407127975211		[learning rate: 0.0068653]
		[batch 20/20] avg loss: 1.0619713938598314		[learning rate: 0.0068528]
	Learning Rate: 0.00685281
	LOSS [training: 1.0296892609175212 | validation: 1.8952217597684995]
	TIME [epoch: 8.38 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.9298187507794451		[learning rate: 0.0068404]
		[batch 20/20] avg loss: 0.8653879872719316		[learning rate: 0.0068279]
	Learning Rate: 0.00682794
	LOSS [training: 0.8976033690256882 | validation: 0.704868785494236]
	TIME [epoch: 8.36 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.8429996039383001		[learning rate: 0.0068155]
		[batch 20/20] avg loss: 2.2357733986317068		[learning rate: 0.0068032]
	Learning Rate: 0.00680316
	LOSS [training: 1.5393865012850036 | validation: 1.614487550029633]
	TIME [epoch: 8.41 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.2131423481761836		[learning rate: 0.0067908]
		[batch 20/20] avg loss: 0.9296276885689769		[learning rate: 0.0067785]
	Learning Rate: 0.00677847
	LOSS [training: 1.0713850183725804 | validation: 1.64499496679763]
	TIME [epoch: 8.41 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.1888284521219803		[learning rate: 0.0067662]
		[batch 20/20] avg loss: 0.9204975875318965		[learning rate: 0.0067539]
	Learning Rate: 0.00675387
	LOSS [training: 1.0546630198269384 | validation: 0.7429264209275718]
	TIME [epoch: 8.51 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.9733766539303179		[learning rate: 0.0067416]
		[batch 20/20] avg loss: 1.0850700120899355		[learning rate: 0.0067294]
	Learning Rate: 0.00672936
	LOSS [training: 1.0292233330101266 | validation: 0.8451568337763737]
	TIME [epoch: 8.49 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.9504173227622361		[learning rate: 0.0067171]
		[batch 20/20] avg loss: 0.9099548610539621		[learning rate: 0.0067049]
	Learning Rate: 0.00670494
	LOSS [training: 0.9301860919080992 | validation: 0.9311418216984139]
	TIME [epoch: 8.44 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.9171631011859537		[learning rate: 0.0066928]
		[batch 20/20] avg loss: 1.0876982152580967		[learning rate: 0.0066806]
	Learning Rate: 0.0066806
	LOSS [training: 1.0024306582220253 | validation: 2.1851109992187467]
	TIME [epoch: 8.41 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.3217682500044277		[learning rate: 0.0066685]
		[batch 20/20] avg loss: 0.9183006851803365		[learning rate: 0.0066564]
	Learning Rate: 0.00665636
	LOSS [training: 1.1200344675923821 | validation: 0.7817065369703701]
	TIME [epoch: 8.38 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.94761126903355		[learning rate: 0.0066443]
		[batch 20/20] avg loss: 1.1120348678890768		[learning rate: 0.0066322]
	Learning Rate: 0.0066322
	LOSS [training: 1.0298230684613134 | validation: 2.636115719007915]
	TIME [epoch: 8.38 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.1102841146937517		[learning rate: 0.0066202]
		[batch 20/20] avg loss: 1.0826333294651984		[learning rate: 0.0066081]
	Learning Rate: 0.00660814
	LOSS [training: 1.0964587220794753 | validation: 1.2225447952980768]
	TIME [epoch: 8.42 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.0784058533695466		[learning rate: 0.0065961]
		[batch 20/20] avg loss: 1.4058684905785255		[learning rate: 0.0065842]
	Learning Rate: 0.00658415
	LOSS [training: 1.2421371719740362 | validation: 2.3581894450826466]
	TIME [epoch: 8.45 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.2159682530704172		[learning rate: 0.0065722]
		[batch 20/20] avg loss: 1.1706119355106406		[learning rate: 0.0065603]
	Learning Rate: 0.00656026
	LOSS [training: 1.1932900942905287 | validation: 1.0918854582093975]
	TIME [epoch: 8.4 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.8491950166975066		[learning rate: 0.0065483]
		[batch 20/20] avg loss: 0.7802387529645356		[learning rate: 0.0065365]
	Learning Rate: 0.00653645
	LOSS [training: 0.814716884831021 | validation: 1.052924208456712]
	TIME [epoch: 8.36 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.8021864757845909		[learning rate: 0.0065246]
		[batch 20/20] avg loss: 0.7842074286250748		[learning rate: 0.0065127]
	Learning Rate: 0.00651273
	LOSS [training: 0.793196952204833 | validation: 0.5851411934743795]
	TIME [epoch: 8.28 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.3227365233740027		[learning rate: 0.0065009]
		[batch 20/20] avg loss: 0.9109429051524088		[learning rate: 0.0064891]
	Learning Rate: 0.0064891
	LOSS [training: 1.116839714263206 | validation: 1.106769636034009]
	TIME [epoch: 8.28 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.7889875385239938		[learning rate: 0.0064773]
		[batch 20/20] avg loss: 0.9496304281411468		[learning rate: 0.0064655]
	Learning Rate: 0.00646555
	LOSS [training: 0.8693089833325705 | validation: 0.518115092263026]
	TIME [epoch: 8.25 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.7277980611078512		[learning rate: 0.0064538]
		[batch 20/20] avg loss: 1.0362041510212714		[learning rate: 0.0064421]
	Learning Rate: 0.00644208
	LOSS [training: 0.8820011060645614 | validation: 2.0382440758526865]
	TIME [epoch: 8.25 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.463313851811769		[learning rate: 0.0064304]
		[batch 20/20] avg loss: 1.153202061267096		[learning rate: 0.0064187]
	Learning Rate: 0.0064187
	LOSS [training: 1.3082579565394323 | validation: 0.6308014877649347]
	TIME [epoch: 8.32 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.9598854389210935		[learning rate: 0.006407]
		[batch 20/20] avg loss: 0.8031597150475754		[learning rate: 0.0063954]
	Learning Rate: 0.00639541
	LOSS [training: 0.8815225769843347 | validation: 2.1327814712478865]
	TIME [epoch: 8.42 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.0394338637946423		[learning rate: 0.0063838]
		[batch 20/20] avg loss: 0.9435919889060779		[learning rate: 0.0063722]
	Learning Rate: 0.0063722
	LOSS [training: 0.9915129263503601 | validation: 0.895282509271229]
	TIME [epoch: 8.47 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.8545577502073698		[learning rate: 0.0063606]
		[batch 20/20] avg loss: 0.6965081782664466		[learning rate: 0.0063491]
	Learning Rate: 0.00634908
	LOSS [training: 0.7755329642369083 | validation: 0.8679482521278145]
	TIME [epoch: 8.34 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.6870992724101621		[learning rate: 0.0063375]
		[batch 20/20] avg loss: 1.168652319282866		[learning rate: 0.006326]
	Learning Rate: 0.00632603
	LOSS [training: 0.927875795846514 | validation: 0.5979153637338411]
	TIME [epoch: 8.3 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.167549334636446		[learning rate: 0.0063145]
		[batch 20/20] avg loss: 0.9692458508179312		[learning rate: 0.0063031]
	Learning Rate: 0.00630308
	LOSS [training: 1.0683975927271887 | validation: 1.3058685993560986]
	TIME [epoch: 8.32 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.8941987002048872		[learning rate: 0.0062916]
		[batch 20/20] avg loss: 0.8744800244947509		[learning rate: 0.0062802]
	Learning Rate: 0.0062802
	LOSS [training: 0.8843393623498189 | validation: 0.8748546520103876]
	TIME [epoch: 8.39 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.7728946968534277		[learning rate: 0.0062688]
		[batch 20/20] avg loss: 0.7407151866509007		[learning rate: 0.0062574]
	Learning Rate: 0.00625741
	LOSS [training: 0.7568049417521643 | validation: 0.7447104136403614]
	TIME [epoch: 8.37 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.6820740106716008		[learning rate: 0.006246]
		[batch 20/20] avg loss: 0.9960071544703878		[learning rate: 0.0062347]
	Learning Rate: 0.0062347
	LOSS [training: 0.8390405825709942 | validation: 0.6878952849167885]
	TIME [epoch: 8.36 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.8574276483841997		[learning rate: 0.0062234]
		[batch 20/20] avg loss: 0.7306344690977161		[learning rate: 0.0062121]
	Learning Rate: 0.00621208
	LOSS [training: 0.7940310587409577 | validation: 0.8684789153160558]
	TIME [epoch: 8.23 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.6605425989664011		[learning rate: 0.0062008]
		[batch 20/20] avg loss: 0.6452161485608806		[learning rate: 0.0061895]
	Learning Rate: 0.00618953
	LOSS [training: 0.6528793737636408 | validation: 0.6901609365230184]
	TIME [epoch: 8.26 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.8513659378478688		[learning rate: 0.0061783]
		[batch 20/20] avg loss: 0.6187064147936322		[learning rate: 0.0061671]
	Learning Rate: 0.00616707
	LOSS [training: 0.7350361763207506 | validation: 0.5031771896364754]
	TIME [epoch: 8.25 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.782371826562036		[learning rate: 0.0061559]
		[batch 20/20] avg loss: 0.6841682755336245		[learning rate: 0.0061447]
	Learning Rate: 0.00614469
	LOSS [training: 0.7332700510478303 | validation: 0.9394049331567622]
	TIME [epoch: 8.41 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.9813199399100541		[learning rate: 0.0061335]
		[batch 20/20] avg loss: 0.6133151147050856		[learning rate: 0.0061224]
	Learning Rate: 0.00612239
	LOSS [training: 0.7973175273075699 | validation: 3.3306241950719846]
	TIME [epoch: 8.38 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.3343071021809494		[learning rate: 0.0061113]
		[batch 20/20] avg loss: 0.9747488444335666		[learning rate: 0.0061002]
	Learning Rate: 0.00610017
	LOSS [training: 1.1545279733072582 | validation: 1.4771175539944625]
	TIME [epoch: 8.37 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.8987193955908369		[learning rate: 0.0060891]
		[batch 20/20] avg loss: 0.9142494018359738		[learning rate: 0.006078]
	Learning Rate: 0.00607803
	LOSS [training: 0.9064843987134055 | validation: 1.2200343293405702]
	TIME [epoch: 8.42 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.7717988116015432		[learning rate: 0.006067]
		[batch 20/20] avg loss: 0.7792773953723958		[learning rate: 0.006056]
	Learning Rate: 0.00605598
	LOSS [training: 0.7755381034869695 | validation: 0.5048986594649975]
	TIME [epoch: 8.44 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.722479260063326		[learning rate: 0.006045]
		[batch 20/20] avg loss: 0.8651213416789947		[learning rate: 0.006034]
	Learning Rate: 0.006034
	LOSS [training: 1.2938003008711603 | validation: 0.5972441076521795]
	TIME [epoch: 8.44 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.7080455526216068		[learning rate: 0.006023]
		[batch 20/20] avg loss: 0.6545166298955041		[learning rate: 0.0060121]
	Learning Rate: 0.0060121
	LOSS [training: 0.6812810912585555 | validation: 0.5824053947656811]
	TIME [epoch: 8.23 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.7361982083699017		[learning rate: 0.0060012]
		[batch 20/20] avg loss: 0.8778338607839787		[learning rate: 0.0059903]
	Learning Rate: 0.00599028
	LOSS [training: 0.8070160345769402 | validation: 0.7767662065784628]
	TIME [epoch: 8.29 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.9418730800311792		[learning rate: 0.0059794]
		[batch 20/20] avg loss: 0.912347528610348		[learning rate: 0.0059685]
	Learning Rate: 0.00596854
	LOSS [training: 0.9271103043207635 | validation: 1.4949377343997106]
	TIME [epoch: 8.26 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.8756535649599915		[learning rate: 0.0059577]
		[batch 20/20] avg loss: 0.8895659615882545		[learning rate: 0.0059469]
	Learning Rate: 0.00594688
	LOSS [training: 0.8826097632741232 | validation: 1.2699657502053623]
	TIME [epoch: 8.27 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.7707449744513601		[learning rate: 0.0059361]
		[batch 20/20] avg loss: 0.6007078853573619		[learning rate: 0.0059253]
	Learning Rate: 0.0059253
	LOSS [training: 0.6857264299043608 | validation: 0.42024305394886613]
	TIME [epoch: 8.25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study201/model_tr_study201_r3_20240219_233648/states/model_tr_study201_244.pth
	Model improved!!!
EPOCH 245/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.674857295246049		[learning rate: 0.0059145]
		[batch 20/20] avg loss: 0.9883055270828411		[learning rate: 0.0059038]
	Learning Rate: 0.0059038
	LOSS [training: 0.8315814111644452 | validation: 0.5370347990765931]
	TIME [epoch: 8.3 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.8285053129620426		[learning rate: 0.0058931]
		[batch 20/20] avg loss: 0.8738968468191963		[learning rate: 0.0058824]
	Learning Rate: 0.00588237
	LOSS [training: 0.8512010798906197 | validation: 0.6018061301879212]
	TIME [epoch: 8.24 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.9127271569635094		[learning rate: 0.0058717]
		[batch 20/20] avg loss: 0.8544925247619242		[learning rate: 0.005861]
	Learning Rate: 0.00586103
	LOSS [training: 0.8836098408627169 | validation: 0.8769757966311191]
	TIME [epoch: 8.22 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.6176359190641293		[learning rate: 0.0058504]
		[batch 20/20] avg loss: 0.627726429675513		[learning rate: 0.0058398]
	Learning Rate: 0.00583976
	LOSS [training: 0.6226811743698211 | validation: 0.5508655002101065]
	TIME [epoch: 8.28 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.7006132550003732		[learning rate: 0.0058291]
		[batch 20/20] avg loss: 0.6022640829985739		[learning rate: 0.0058186]
	Learning Rate: 0.00581856
	LOSS [training: 0.6514386689994736 | validation: 0.5277829879195346]
	TIME [epoch: 8.35 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.6350950715743411		[learning rate: 0.005808]
		[batch 20/20] avg loss: 0.6138656468626363		[learning rate: 0.0057974]
	Learning Rate: 0.00579745
	LOSS [training: 0.6244803592184889 | validation: 0.6402013019545758]
	TIME [epoch: 8.52 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.9033769709737707		[learning rate: 0.0057869]
		[batch 20/20] avg loss: 1.0407120397447833		[learning rate: 0.0057764]
	Learning Rate: 0.00577641
	LOSS [training: 0.9720445053592769 | validation: 0.41188279525566]
	TIME [epoch: 8.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study201/model_tr_study201_r3_20240219_233648/states/model_tr_study201_251.pth
	Model improved!!!
EPOCH 252/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.6768027727927917		[learning rate: 0.0057659]
		[batch 20/20] avg loss: 0.8091271371110075		[learning rate: 0.0057554]
	Learning Rate: 0.00575545
	LOSS [training: 0.7429649549518996 | validation: 0.710380048824435]
	TIME [epoch: 8.44 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.8183972189086208		[learning rate: 0.005745]
		[batch 20/20] avg loss: 0.8745102073861906		[learning rate: 0.0057346]
	Learning Rate: 0.00573456
	LOSS [training: 0.8464537131474055 | validation: 1.2854785317313384]
	TIME [epoch: 8.4 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.9803866151157135		[learning rate: 0.0057241]
		[batch 20/20] avg loss: 0.713957173969877		[learning rate: 0.0057137]
	Learning Rate: 0.00571375
	LOSS [training: 0.8471718945427952 | validation: 0.34272733273363515]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study201/model_tr_study201_r3_20240219_233648/states/model_tr_study201_254.pth
	Model improved!!!
EPOCH 255/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.9712125715337555		[learning rate: 0.0057034]
		[batch 20/20] avg loss: 0.7578069280802251		[learning rate: 0.005693]
	Learning Rate: 0.00569301
	LOSS [training: 0.8645097498069904 | validation: 0.4458114114616229]
	TIME [epoch: 8.42 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.1123439598911111		[learning rate: 0.0056827]
		[batch 20/20] avg loss: 0.8222785047261171		[learning rate: 0.0056724]
	Learning Rate: 0.00567235
	LOSS [training: 0.9673112323086143 | validation: 0.6978396506765254]
	TIME [epoch: 8.4 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.9129277459734346		[learning rate: 0.005662]
		[batch 20/20] avg loss: 0.9460763913376043		[learning rate: 0.0056518]
	Learning Rate: 0.00565177
	LOSS [training: 0.9295020686555192 | validation: 0.526471042582882]
	TIME [epoch: 8.39 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.8384993885153568		[learning rate: 0.0056415]
		[batch 20/20] avg loss: 1.2853492316089066		[learning rate: 0.0056313]
	Learning Rate: 0.00563126
	LOSS [training: 1.0619243100621318 | validation: 0.7837836380569472]
	TIME [epoch: 8.41 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.6419510038712882		[learning rate: 0.005621]
		[batch 20/20] avg loss: 0.6016040241988267		[learning rate: 0.0056108]
	Learning Rate: 0.00561082
	LOSS [training: 0.6217775140350574 | validation: 0.48372124770665076]
	TIME [epoch: 8.37 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.6601522722227838		[learning rate: 0.0056006]
		[batch 20/20] avg loss: 0.6616394140353965		[learning rate: 0.0055905]
	Learning Rate: 0.00559046
	LOSS [training: 0.6608958431290902 | validation: 0.49796225243103065]
	TIME [epoch: 8.34 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.554718392041986		[learning rate: 0.0055803]
		[batch 20/20] avg loss: 1.268448627683044		[learning rate: 0.0055702]
	Learning Rate: 0.00557017
	LOSS [training: 0.9115835098625149 | validation: 1.1437700729256017]
	TIME [epoch: 8.39 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.8975026301078752		[learning rate: 0.0055601]
		[batch 20/20] avg loss: 2.2381751227158784		[learning rate: 0.00555]
	Learning Rate: 0.00554996
	LOSS [training: 2.0678388764118774 | validation: 1.837239270396848]
	TIME [epoch: 8.33 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 10/20] avg loss: 2.0652210711560453		[learning rate: 0.0055399]
		[batch 20/20] avg loss: 1.8965913727011992		[learning rate: 0.0055298]
	Learning Rate: 0.00552981
	LOSS [training: 1.9809062219286222 | validation: 1.1003450361909501]
	TIME [epoch: 8.24 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.8550376054580977		[learning rate: 0.0055198]
		[batch 20/20] avg loss: 2.022158518542237		[learning rate: 0.0055097]
	Learning Rate: 0.00550975
	LOSS [training: 1.9385980620001668 | validation: 1.2822632832751535]
	TIME [epoch: 8.26 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 10/20] avg loss: 2.024017443837242		[learning rate: 0.0054997]
		[batch 20/20] avg loss: 1.8643934718209398		[learning rate: 0.0054898]
	Learning Rate: 0.00548975
	LOSS [training: 1.944205457829091 | validation: 1.2049393503312162]
	TIME [epoch: 8.27 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.7994145113944147		[learning rate: 0.0054798]
Encountered nan in loss. Reverting update and performing model surgery.
	New model confinement_factor: 0.05
Encountered nan in loss. Reverting update and performing model surgery.
	New model confinement_factor: 0.025
Encountered nan in loss. Reverting update and performing model surgery.
	New model confinement_factor: 0.0125
Encountered nan in loss. Reverting update and performing model surgery.
	New model confinement_factor: 0.00625
ERROR:
Encountered nan in loss and reached the maximum number of model alterations: 4.
