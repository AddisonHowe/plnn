Args:
Namespace(name='model_tr_study206', outdir='out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0', training_data='data/transition_rate_studies/tr_study206/tr_study206_training/r0', validation_data='data/transition_rate_studies/tr_study206/tr_study206_validation/r0', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.075, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=100, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 917408570

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 5/5] avg loss: 10.317088513140886		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.317088513140886 | validation: 9.61260914060364]
	TIME [epoch: 79.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.283395701715232		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.283395701715232 | validation: 7.805979762073252]
	TIME [epoch: 9.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.723303417916258		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.723303417916258 | validation: 7.40469558352555]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.902200722481217		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.902200722481217 | validation: 6.086169471455556]
	TIME [epoch: 9.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.324919328415585		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.324919328415585 | validation: 5.6665986220182125]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.6914692985404844		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.6914692985404844 | validation: 5.9555167731733905]
	TIME [epoch: 9.54 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.596043191492263		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.596043191492263 | validation: 4.879610648802469]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.655375005263092		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.655375005263092 | validation: 5.725073373257648]
	TIME [epoch: 9.57 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.432452092497237		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.432452092497237 | validation: 4.864684257092847]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.275644038254424		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.275644038254424 | validation: 4.839609496884983]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.336228674890971		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.336228674890971 | validation: 4.892148386952733]
	TIME [epoch: 9.55 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.102874590997506		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.102874590997506 | validation: 5.161361993500618]
	TIME [epoch: 9.54 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.186630232146042		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.186630232146042 | validation: 4.871076050958651]
	TIME [epoch: 9.54 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.16832442912708		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.16832442912708 | validation: 4.936499988315249]
	TIME [epoch: 9.53 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.2594668064900905		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.2594668064900905 | validation: 4.87174741999561]
	TIME [epoch: 9.56 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.2435980510329205		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.2435980510329205 | validation: 4.920733387881415]
	TIME [epoch: 9.53 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.549726143154818		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.549726143154818 | validation: 5.593737966927943]
	TIME [epoch: 9.53 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.441090714156143		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.441090714156143 | validation: 4.915506464430873]
	TIME [epoch: 9.54 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.188122098440645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.188122098440645 | validation: 4.8772038319370585]
	TIME [epoch: 9.54 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.208812293059947		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.208812293059947 | validation: 4.925394865622436]
	TIME [epoch: 9.54 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.284706431786255		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.284706431786255 | validation: 4.8576841382855935]
	TIME [epoch: 9.53 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.4013664581338805		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.4013664581338805 | validation: 5.070175765283288]
	TIME [epoch: 9.56 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.23451059457823		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.23451059457823 | validation: 5.344112619753733]
	TIME [epoch: 9.53 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.417693873904812		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.417693873904812 | validation: 4.655099302547833]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.234021089080192		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.234021089080192 | validation: 5.008019884394337]
	TIME [epoch: 9.54 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.324360464007152		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.324360464007152 | validation: 4.896123797533355]
	TIME [epoch: 9.56 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.141886529531348		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.141886529531348 | validation: 4.711207580221278]
	TIME [epoch: 9.55 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.282137012937803		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.282137012937803 | validation: 5.565284281957461]
	TIME [epoch: 9.54 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.4176929219823595		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.4176929219823595 | validation: 4.875595337314861]
	TIME [epoch: 9.57 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.247319087185781		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.247319087185781 | validation: 5.119566920366342]
	TIME [epoch: 9.55 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.271760878803457		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.271760878803457 | validation: 4.773343504720439]
	TIME [epoch: 9.54 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.258977002147401		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.258977002147401 | validation: 4.949785662488779]
	TIME [epoch: 9.56 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.204251581844085		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.204251581844085 | validation: 4.628351525644951]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.149568867134276		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.149568867134276 | validation: 4.999012601112294]
	TIME [epoch: 9.55 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.195669157705398		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.195669157705398 | validation: 4.871665650788402]
	TIME [epoch: 9.55 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.134656269228346		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.134656269228346 | validation: 4.808537095191372]
	TIME [epoch: 9.55 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.3787094240175035		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.3787094240175035 | validation: 4.623928140817002]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.057999795592294		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.057999795592294 | validation: 5.245529396735576]
	TIME [epoch: 9.53 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.073733219630663		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.073733219630663 | validation: 4.651643906393007]
	TIME [epoch: 9.59 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.13186471033351		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.13186471033351 | validation: 5.576436794941962]
	TIME [epoch: 9.55 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.44756051000154		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.44756051000154 | validation: 4.810403950743916]
	TIME [epoch: 9.54 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.126985149474349		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.126985149474349 | validation: 4.891362760400446]
	TIME [epoch: 9.55 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.1472506904278195		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.1472506904278195 | validation: 4.877041743241835]
	TIME [epoch: 9.56 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.039396179378689		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.039396179378689 | validation: 4.676989591098122]
	TIME [epoch: 9.54 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.9898249790387785		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.9898249790387785 | validation: 4.4721924840062375]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.007175897459793		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.007175897459793 | validation: 4.722780029421575]
	TIME [epoch: 9.56 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.171981123238758		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.171981123238758 | validation: 4.7422026154258266]
	TIME [epoch: 9.55 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.224032901323808		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.224032901323808 | validation: 4.624180953484768]
	TIME [epoch: 9.54 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.059618618091633		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.059618618091633 | validation: 4.900725946643615]
	TIME [epoch: 9.54 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.159596284588633		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.159596284588633 | validation: 4.431661871476588]
	TIME [epoch: 9.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.026814270913299		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.026814270913299 | validation: 4.53461369961748]
	TIME [epoch: 9.54 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.155868593539713		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.155868593539713 | validation: 4.327898947163882]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.130964100720388		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.130964100720388 | validation: 4.468173074183949]
	TIME [epoch: 9.57 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.2327297359780305		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.2327297359780305 | validation: 3.9976266848338167]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.381558135451151		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.381558135451151 | validation: 3.8061437311306565]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.125132312248835		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.125132312248835 | validation: 3.7105006480375455]
	TIME [epoch: 9.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.024256643796411		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.024256643796411 | validation: 3.577140337861765]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.418573201636095		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.418573201636095 | validation: 4.207868861334016]
	TIME [epoch: 9.53 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.047054612135827		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.047054612135827 | validation: 3.846378785089023]
	TIME [epoch: 9.55 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.88704775417663		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.88704775417663 | validation: 3.362035190493356]
	TIME [epoch: 9.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.302981486088667		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.302981486088667 | validation: 3.4519799592475593]
	TIME [epoch: 9.83 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9366629203708596		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9366629203708596 | validation: 4.564871310719]
	TIME [epoch: 9.53 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.97139784837895		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.97139784837895 | validation: 3.830038943879231]
	TIME [epoch: 9.57 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.875148683671644		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.875148683671644 | validation: 3.519464720953857]
	TIME [epoch: 9.53 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.768125988382912		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.768125988382912 | validation: 3.3631455681974343]
	TIME [epoch: 9.53 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.223779267206596		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.223779267206596 | validation: 3.614762545657941]
	TIME [epoch: 9.54 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.878927662293851		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.878927662293851 | validation: 3.329205705289236]
	TIME [epoch: 9.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.054153498982933		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.054153498982933 | validation: 3.7590262091407016]
	TIME [epoch: 9.53 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.039973211358047		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.039973211358047 | validation: 3.5562017652588533]
	TIME [epoch: 9.53 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.8680717061013907		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8680717061013907 | validation: 3.73197935370147]
	TIME [epoch: 9.55 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.983874984919423		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.983874984919423 | validation: 4.225788508619061]
	TIME [epoch: 9.54 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9225953448966373		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9225953448966373 | validation: 3.5022044014645592]
	TIME [epoch: 9.53 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.901214455455416		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.901214455455416 | validation: 3.8542599073476946]
	TIME [epoch: 9.53 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.065599818857586		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.065599818857586 | validation: 3.291795699562007]
	TIME [epoch: 9.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_74.pth
	Model improved!!!
EPOCH 75/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9552240577129374		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9552240577129374 | validation: 3.315943905257273]
	TIME [epoch: 9.53 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.8415785175743324		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8415785175743324 | validation: 3.2921766957145606]
	TIME [epoch: 9.53 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.929463670949935		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.929463670949935 | validation: 4.147941059826409]
	TIME [epoch: 9.56 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.8289975765089137		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8289975765089137 | validation: 3.298118721333917]
	TIME [epoch: 9.54 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.776595505312091		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.776595505312091 | validation: 3.1867800399007273]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6960808636577966		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6960808636577966 | validation: 3.312615458803117]
	TIME [epoch: 9.54 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9478062807162764		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9478062807162764 | validation: 3.6368809385865437]
	TIME [epoch: 9.55 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.795109838222827		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.795109838222827 | validation: 3.364375886728434]
	TIME [epoch: 9.53 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.802767950707735		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.802767950707735 | validation: 3.2314203561426122]
	TIME [epoch: 9.52 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.7719218432020583		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7719218432020583 | validation: 3.363091305264853]
	TIME [epoch: 9.55 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.056460012232589		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.056460012232589 | validation: 3.2675574468023587]
	TIME [epoch: 9.53 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.2009584726579945		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.2009584726579945 | validation: 3.3862169480851207]
	TIME [epoch: 9.53 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6591475593554796		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6591475593554796 | validation: 3.542721324044643]
	TIME [epoch: 9.53 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.76424839054584		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.76424839054584 | validation: 3.154822849734618]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_88.pth
	Model improved!!!
EPOCH 89/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6291236090290986		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6291236090290986 | validation: 3.2765130741821236]
	TIME [epoch: 9.53 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.59017200154236		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.59017200154236 | validation: 3.9582823133093274]
	TIME [epoch: 9.52 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.854131922714457		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.854131922714457 | validation: 4.280997871142464]
	TIME [epoch: 9.55 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.751765978878338		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.751765978878338 | validation: 3.1890479057212873]
	TIME [epoch: 9.53 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.8765928684728386		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8765928684728386 | validation: 3.6142754054962247]
	TIME [epoch: 9.53 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.666566274618165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.666566274618165 | validation: 3.038978240999236]
	TIME [epoch: 9.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_94.pth
	Model improved!!!
EPOCH 95/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.5563513506686846		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5563513506686846 | validation: 3.3656694682893096]
	TIME [epoch: 9.54 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.7210715408209163		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7210715408209163 | validation: 3.0828542931550698]
	TIME [epoch: 9.52 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.531837813645166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.531837813645166 | validation: 3.24317850080383]
	TIME [epoch: 9.52 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4636389328521		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4636389328521 | validation: 3.031619508341907]
	TIME [epoch: 9.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_98.pth
	Model improved!!!
EPOCH 99/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4464893197278625		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4464893197278625 | validation: 2.965082703714529]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_99.pth
	Model improved!!!
EPOCH 100/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4158026606939536		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4158026606939536 | validation: 2.8388562587722412]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_100.pth
	Model improved!!!
EPOCH 101/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.590166296770748		[learning rate: 0.009971]
	Learning Rate: 0.00997096
	LOSS [training: 3.590166296770748 | validation: 4.049057730993432]
	TIME [epoch: 9.55 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.8662341736040715		[learning rate: 0.0099348]
	Learning Rate: 0.00993477
	LOSS [training: 3.8662341736040715 | validation: 3.0718566833181704]
	TIME [epoch: 9.55 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4600622430274948		[learning rate: 0.0098987]
	Learning Rate: 0.00989872
	LOSS [training: 3.4600622430274948 | validation: 2.757427827147241]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_103.pth
	Model improved!!!
EPOCH 104/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.317934231653954		[learning rate: 0.0098628]
	Learning Rate: 0.00986279
	LOSS [training: 3.317934231653954 | validation: 3.4481222538366896]
	TIME [epoch: 9.53 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2782133057715557		[learning rate: 0.009827]
	Learning Rate: 0.009827
	LOSS [training: 3.2782133057715557 | validation: 2.6835729817455376]
	TIME [epoch: 9.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_105.pth
	Model improved!!!
EPOCH 106/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.242535347420067		[learning rate: 0.0097913]
	Learning Rate: 0.00979134
	LOSS [training: 3.242535347420067 | validation: 2.469553465720438]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_106.pth
	Model improved!!!
EPOCH 107/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.283647508216839		[learning rate: 0.0097558]
	Learning Rate: 0.00975581
	LOSS [training: 3.283647508216839 | validation: 3.2965886401961932]
	TIME [epoch: 9.53 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.976069566740851		[learning rate: 0.0097204]
	Learning Rate: 0.0097204
	LOSS [training: 2.976069566740851 | validation: 2.2910672776460954]
	TIME [epoch: 9.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_108.pth
	Model improved!!!
EPOCH 109/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5597654344562786		[learning rate: 0.0096851]
	Learning Rate: 0.00968513
	LOSS [training: 2.5597654344562786 | validation: 2.1937494832903672]
	TIME [epoch: 9.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_109.pth
	Model improved!!!
EPOCH 110/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5630968510080043		[learning rate: 0.00965]
	Learning Rate: 0.00964998
	LOSS [training: 2.5630968510080043 | validation: 2.047233281335538]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_110.pth
	Model improved!!!
EPOCH 111/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4301814192487425		[learning rate: 0.009615]
	Learning Rate: 0.00961496
	LOSS [training: 2.4301814192487425 | validation: 2.6285076833129497]
	TIME [epoch: 9.57 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.539364166674139		[learning rate: 0.0095801]
	Learning Rate: 0.00958006
	LOSS [training: 2.539364166674139 | validation: 2.281829656565834]
	TIME [epoch: 9.55 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.366989353067019		[learning rate: 0.0095453]
	Learning Rate: 0.0095453
	LOSS [training: 2.366989353067019 | validation: 2.3843767346417644]
	TIME [epoch: 9.54 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.317451579854029		[learning rate: 0.0095107]
	Learning Rate: 0.00951066
	LOSS [training: 2.317451579854029 | validation: 1.8945511871338738]
	TIME [epoch: 9.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_114.pth
	Model improved!!!
EPOCH 115/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5488083762323233		[learning rate: 0.0094761]
	Learning Rate: 0.00947614
	LOSS [training: 2.5488083762323233 | validation: 11.892159258578554]
	TIME [epoch: 9.57 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.341341065776792		[learning rate: 0.0094418]
	Learning Rate: 0.00944175
	LOSS [training: 9.341341065776792 | validation: 3.3726292799426494]
	TIME [epoch: 9.55 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0648835329693904		[learning rate: 0.0094075]
	Learning Rate: 0.00940749
	LOSS [training: 3.0648835329693904 | validation: 1.9967279064180405]
	TIME [epoch: 9.55 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.316090711021361		[learning rate: 0.0093733]
	Learning Rate: 0.00937335
	LOSS [training: 2.316090711021361 | validation: 2.2634266595735544]
	TIME [epoch: 9.55 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3333800048809925		[learning rate: 0.0093393]
	Learning Rate: 0.00933933
	LOSS [training: 2.3333800048809925 | validation: 2.810044244598604]
	TIME [epoch: 9.56 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.862065200600381		[learning rate: 0.0093054]
	Learning Rate: 0.00930544
	LOSS [training: 5.862065200600381 | validation: 6.681680731441324]
	TIME [epoch: 9.54 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.91861689010494		[learning rate: 0.0092717]
	Learning Rate: 0.00927167
	LOSS [training: 3.91861689010494 | validation: 1.992392252990595]
	TIME [epoch: 9.54 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.334070945562181		[learning rate: 0.009238]
	Learning Rate: 0.00923802
	LOSS [training: 2.334070945562181 | validation: 1.8701112612622237]
	TIME [epoch: 9.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_122.pth
	Model improved!!!
EPOCH 123/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.362497277121728		[learning rate: 0.0092045]
	Learning Rate: 0.0092045
	LOSS [training: 2.362497277121728 | validation: 2.5556802133961454]
	TIME [epoch: 9.54 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.359532364852014		[learning rate: 0.0091711]
	Learning Rate: 0.00917109
	LOSS [training: 2.359532364852014 | validation: 1.7276310452396815]
	TIME [epoch: 9.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_124.pth
	Model improved!!!
EPOCH 125/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3617520605901094		[learning rate: 0.0091378]
	Learning Rate: 0.00913781
	LOSS [training: 2.3617520605901094 | validation: 1.828722418660068]
	TIME [epoch: 9.57 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2265301579023458		[learning rate: 0.0091046]
	Learning Rate: 0.00910465
	LOSS [training: 2.2265301579023458 | validation: 1.9126966051546463]
	TIME [epoch: 9.54 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2267225017512313		[learning rate: 0.0090716]
	Learning Rate: 0.00907161
	LOSS [training: 2.2267225017512313 | validation: 1.762727529883445]
	TIME [epoch: 9.54 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1899170210382293		[learning rate: 0.0090387]
	Learning Rate: 0.00903868
	LOSS [training: 2.1899170210382293 | validation: 2.413775411589487]
	TIME [epoch: 9.54 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4953270677718167		[learning rate: 0.0090059]
	Learning Rate: 0.00900588
	LOSS [training: 3.4953270677718167 | validation: 6.836007755881496]
	TIME [epoch: 9.58 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6674078596949196		[learning rate: 0.0089732]
	Learning Rate: 0.0089732
	LOSS [training: 3.6674078596949196 | validation: 2.1568791918595163]
	TIME [epoch: 9.54 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2040660323291936		[learning rate: 0.0089406]
	Learning Rate: 0.00894064
	LOSS [training: 2.2040660323291936 | validation: 1.6736579321294658]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_131.pth
	Model improved!!!
EPOCH 132/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.184848107473031		[learning rate: 0.0089082]
	Learning Rate: 0.00890819
	LOSS [training: 2.184848107473031 | validation: 1.6317233648613598]
	TIME [epoch: 9.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_132.pth
	Model improved!!!
EPOCH 133/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1148867235631092		[learning rate: 0.0088759]
	Learning Rate: 0.00887586
	LOSS [training: 2.1148867235631092 | validation: 2.0649486707691067]
	TIME [epoch: 9.53 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.413946073932126		[learning rate: 0.0088437]
	Learning Rate: 0.00884365
	LOSS [training: 2.413946073932126 | validation: 2.037168181078875]
	TIME [epoch: 9.54 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2513213755309085		[learning rate: 0.0088116]
	Learning Rate: 0.00881156
	LOSS [training: 2.2513213755309085 | validation: 1.8296454193732417]
	TIME [epoch: 9.54 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.142684242399601		[learning rate: 0.0087796]
	Learning Rate: 0.00877958
	LOSS [training: 2.142684242399601 | validation: 1.8337503272640663]
	TIME [epoch: 9.54 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.089866096241371		[learning rate: 0.0087477]
	Learning Rate: 0.00874772
	LOSS [training: 2.089866096241371 | validation: 2.1078460818183276]
	TIME [epoch: 9.53 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.186123069812275		[learning rate: 0.008716]
	Learning Rate: 0.00871597
	LOSS [training: 2.186123069812275 | validation: 1.5874809739668445]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_138.pth
	Model improved!!!
EPOCH 139/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.172954132519927		[learning rate: 0.0086843]
	Learning Rate: 0.00868434
	LOSS [training: 2.172954132519927 | validation: 2.075452490413881]
	TIME [epoch: 9.56 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.083292297983644		[learning rate: 0.0086528]
	Learning Rate: 0.00865282
	LOSS [training: 2.083292297983644 | validation: 1.743294867464619]
	TIME [epoch: 9.52 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.479896141405778		[learning rate: 0.0086214]
	Learning Rate: 0.00862142
	LOSS [training: 2.479896141405778 | validation: 3.470462037750715]
	TIME [epoch: 9.52 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5602332956580525		[learning rate: 0.0085901]
	Learning Rate: 0.00859013
	LOSS [training: 2.5602332956580525 | validation: 2.1981643539870555]
	TIME [epoch: 9.53 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1591546572667046		[learning rate: 0.008559]
	Learning Rate: 0.00855896
	LOSS [training: 2.1591546572667046 | validation: 1.710614864770668]
	TIME [epoch: 9.54 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1334072768382617		[learning rate: 0.0085279]
	Learning Rate: 0.0085279
	LOSS [training: 2.1334072768382617 | validation: 1.8337072758094894]
	TIME [epoch: 9.53 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.133452790392292		[learning rate: 0.008497]
	Learning Rate: 0.00849695
	LOSS [training: 2.133452790392292 | validation: 2.058913234277722]
	TIME [epoch: 9.53 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2297897832789717		[learning rate: 0.0084661]
	Learning Rate: 0.00846612
	LOSS [training: 2.2297897832789717 | validation: 1.718507424107807]
	TIME [epoch: 9.54 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1506869121913974		[learning rate: 0.0084354]
	Learning Rate: 0.00843539
	LOSS [training: 2.1506869121913974 | validation: 1.7231212007902201]
	TIME [epoch: 9.53 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1755236242155385		[learning rate: 0.0084048]
	Learning Rate: 0.00840478
	LOSS [training: 2.1755236242155385 | validation: 1.6315438740065475]
	TIME [epoch: 9.52 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.048428642056221		[learning rate: 0.0083743]
	Learning Rate: 0.00837428
	LOSS [training: 2.048428642056221 | validation: 1.7794912053190808]
	TIME [epoch: 9.54 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1275397891420185		[learning rate: 0.0083439]
	Learning Rate: 0.00834389
	LOSS [training: 2.1275397891420185 | validation: 1.6127971939029917]
	TIME [epoch: 9.54 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2192475440293924		[learning rate: 0.0083136]
	Learning Rate: 0.00831361
	LOSS [training: 2.2192475440293924 | validation: 1.8206722260232644]
	TIME [epoch: 9.53 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2449004025971164		[learning rate: 0.0082834]
	Learning Rate: 0.00828344
	LOSS [training: 2.2449004025971164 | validation: 1.9535575288124511]
	TIME [epoch: 9.52 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2378471391244004		[learning rate: 0.0082534]
	Learning Rate: 0.00825338
	LOSS [training: 2.2378471391244004 | validation: 2.0380664191475883]
	TIME [epoch: 9.55 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2610601186933765		[learning rate: 0.0082234]
	Learning Rate: 0.00822342
	LOSS [training: 2.2610601186933765 | validation: 2.173479335916511]
	TIME [epoch: 9.52 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.632572001931353		[learning rate: 0.0081936]
	Learning Rate: 0.00819358
	LOSS [training: 2.632572001931353 | validation: 2.4524305793206778]
	TIME [epoch: 9.52 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1542235186990837		[learning rate: 0.0081638]
	Learning Rate: 0.00816384
	LOSS [training: 2.1542235186990837 | validation: 1.5694783597704032]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_156.pth
	Model improved!!!
EPOCH 157/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3399764926653632		[learning rate: 0.0081342]
	Learning Rate: 0.00813422
	LOSS [training: 2.3399764926653632 | validation: 1.672367559202487]
	TIME [epoch: 9.53 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.8592397198501303		[learning rate: 0.0081047]
	Learning Rate: 0.0081047
	LOSS [training: 3.8592397198501303 | validation: 2.4638070674308516]
	TIME [epoch: 9.52 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2814525400994934		[learning rate: 0.0080753]
	Learning Rate: 0.00807529
	LOSS [training: 2.2814525400994934 | validation: 1.7461417342151953]
	TIME [epoch: 9.52 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9472085844989515		[learning rate: 0.008046]
	Learning Rate: 0.00804598
	LOSS [training: 1.9472085844989515 | validation: 1.5885862402590385]
	TIME [epoch: 9.55 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.007978859478586		[learning rate: 0.0080168]
	Learning Rate: 0.00801678
	LOSS [training: 2.007978859478586 | validation: 1.9083126721984842]
	TIME [epoch: 9.53 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0428128881110497		[learning rate: 0.0079877]
	Learning Rate: 0.00798769
	LOSS [training: 2.0428128881110497 | validation: 2.254541103183142]
	TIME [epoch: 9.51 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0450073122233783		[learning rate: 0.0079587]
	Learning Rate: 0.0079587
	LOSS [training: 2.0450073122233783 | validation: 1.5453561179754798]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_163.pth
	Model improved!!!
EPOCH 164/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.173087910483619		[learning rate: 0.0079298]
	Learning Rate: 0.00792982
	LOSS [training: 2.173087910483619 | validation: 1.628655710021947]
	TIME [epoch: 9.52 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1176068523318454		[learning rate: 0.007901]
	Learning Rate: 0.00790104
	LOSS [training: 2.1176068523318454 | validation: 1.6521504612938294]
	TIME [epoch: 9.53 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.034888478420706		[learning rate: 0.0078724]
	Learning Rate: 0.00787237
	LOSS [training: 2.034888478420706 | validation: 1.5782559343695102]
	TIME [epoch: 9.52 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.046411045036207		[learning rate: 0.0078438]
	Learning Rate: 0.0078438
	LOSS [training: 2.046411045036207 | validation: 1.7368409753842997]
	TIME [epoch: 9.56 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0684005667049803		[learning rate: 0.0078153]
	Learning Rate: 0.00781533
	LOSS [training: 2.0684005667049803 | validation: 1.5698688808172279]
	TIME [epoch: 9.51 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0541256457068924		[learning rate: 0.007787]
	Learning Rate: 0.00778697
	LOSS [training: 2.0541256457068924 | validation: 2.355828628129962]
	TIME [epoch: 9.52 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1230941065257465		[learning rate: 0.0077587]
	Learning Rate: 0.00775871
	LOSS [training: 2.1230941065257465 | validation: 1.5850109777730435]
	TIME [epoch: 9.54 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.122751953534717		[learning rate: 0.0077306]
	Learning Rate: 0.00773055
	LOSS [training: 2.122751953534717 | validation: 1.8471344751692527]
	TIME [epoch: 9.53 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1234721364023685		[learning rate: 0.0077025]
	Learning Rate: 0.0077025
	LOSS [training: 2.1234721364023685 | validation: 1.6343458307859788]
	TIME [epoch: 9.52 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0643091414756105		[learning rate: 0.0076745]
	Learning Rate: 0.00767455
	LOSS [training: 2.0643091414756105 | validation: 1.5730231383707491]
	TIME [epoch: 9.52 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.283851373291731		[learning rate: 0.0076467]
	Learning Rate: 0.00764669
	LOSS [training: 2.283851373291731 | validation: 1.6791585578001087]
	TIME [epoch: 9.56 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0946958501975628		[learning rate: 0.0076189]
	Learning Rate: 0.00761894
	LOSS [training: 2.0946958501975628 | validation: 1.8089739715748112]
	TIME [epoch: 9.52 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.091576408671446		[learning rate: 0.0075913]
	Learning Rate: 0.00759129
	LOSS [training: 2.091576408671446 | validation: 1.6199188342687325]
	TIME [epoch: 9.52 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.03812555182338		[learning rate: 0.0075637]
	Learning Rate: 0.00756374
	LOSS [training: 2.03812555182338 | validation: 1.8259813756901435]
	TIME [epoch: 9.55 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1089377454903815		[learning rate: 0.0075363]
	Learning Rate: 0.00753629
	LOSS [training: 2.1089377454903815 | validation: 1.6344376261606277]
	TIME [epoch: 9.53 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0611855374976704		[learning rate: 0.0075089]
	Learning Rate: 0.00750895
	LOSS [training: 2.0611855374976704 | validation: 1.9430179971106651]
	TIME [epoch: 9.54 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1686587513696427		[learning rate: 0.0074817]
	Learning Rate: 0.00748169
	LOSS [training: 2.1686587513696427 | validation: 1.683660721668082]
	TIME [epoch: 9.53 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1824765239842128		[learning rate: 0.0074545]
	Learning Rate: 0.00745454
	LOSS [training: 2.1824765239842128 | validation: 1.6772675664489292]
	TIME [epoch: 9.55 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0416369302207436		[learning rate: 0.0074275]
	Learning Rate: 0.00742749
	LOSS [training: 2.0416369302207436 | validation: 1.8055653082763443]
	TIME [epoch: 9.52 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0541736606913688		[learning rate: 0.0074005]
	Learning Rate: 0.00740054
	LOSS [training: 2.0541736606913688 | validation: 1.5779714049158406]
	TIME [epoch: 9.52 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.018494337426072		[learning rate: 0.0073737]
	Learning Rate: 0.00737368
	LOSS [training: 2.018494337426072 | validation: 1.6663928470842655]
	TIME [epoch: 9.56 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0046849079633495		[learning rate: 0.0073469]
	Learning Rate: 0.00734692
	LOSS [training: 2.0046849079633495 | validation: 1.7534171032164245]
	TIME [epoch: 9.53 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9470723603292104		[learning rate: 0.0073203]
	Learning Rate: 0.00732026
	LOSS [training: 1.9470723603292104 | validation: 1.7154680193601395]
	TIME [epoch: 9.52 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5361232312106496		[learning rate: 0.0072937]
	Learning Rate: 0.00729369
	LOSS [training: 2.5361232312106496 | validation: 3.1914649075942685]
	TIME [epoch: 9.53 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.294527785174657		[learning rate: 0.0072672]
	Learning Rate: 0.00726722
	LOSS [training: 2.294527785174657 | validation: 1.8373582674978752]
	TIME [epoch: 9.54 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.135235444658048		[learning rate: 0.0072408]
	Learning Rate: 0.00724085
	LOSS [training: 2.135235444658048 | validation: 1.5645905818221917]
	TIME [epoch: 9.53 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.128095222251538		[learning rate: 0.0072146]
	Learning Rate: 0.00721457
	LOSS [training: 2.128095222251538 | validation: 1.657449609250746]
	TIME [epoch: 9.53 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.958907276236308		[learning rate: 0.0071884]
	Learning Rate: 0.00718839
	LOSS [training: 1.958907276236308 | validation: 1.7910255523126242]
	TIME [epoch: 9.55 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.041569182699977		[learning rate: 0.0071623]
	Learning Rate: 0.0071623
	LOSS [training: 2.041569182699977 | validation: 1.5295723491467856]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_192.pth
	Model improved!!!
EPOCH 193/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9663960210538687		[learning rate: 0.0071363]
	Learning Rate: 0.00713631
	LOSS [training: 1.9663960210538687 | validation: 1.704131121927715]
	TIME [epoch: 9.53 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0555730330171134		[learning rate: 0.0071104]
	Learning Rate: 0.00711041
	LOSS [training: 2.0555730330171134 | validation: 1.5156035892099222]
	TIME [epoch: 9.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_194.pth
	Model improved!!!
EPOCH 195/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9743218420852748		[learning rate: 0.0070846]
	Learning Rate: 0.00708461
	LOSS [training: 1.9743218420852748 | validation: 2.0352482180586473]
	TIME [epoch: 9.54 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.092197531236599		[learning rate: 0.0070589]
	Learning Rate: 0.0070589
	LOSS [training: 2.092197531236599 | validation: 2.3662800088694262]
	TIME [epoch: 9.53 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1270956210867857		[learning rate: 0.0070333]
	Learning Rate: 0.00703328
	LOSS [training: 2.1270956210867857 | validation: 1.6036034398841106]
	TIME [epoch: 9.52 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.021492431246105		[learning rate: 0.0070078]
	Learning Rate: 0.00700776
	LOSS [training: 2.021492431246105 | validation: 1.9437979780479056]
	TIME [epoch: 9.55 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.044894830677064		[learning rate: 0.0069823]
	Learning Rate: 0.00698232
	LOSS [training: 2.044894830677064 | validation: 1.8069093130036793]
	TIME [epoch: 9.53 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0992130544914183		[learning rate: 0.006957]
	Learning Rate: 0.00695698
	LOSS [training: 2.0992130544914183 | validation: 1.7392139899306063]
	TIME [epoch: 9.52 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1502049564052825		[learning rate: 0.0069317]
	Learning Rate: 0.00693174
	LOSS [training: 2.1502049564052825 | validation: 1.5258274836638543]
	TIME [epoch: 9.54 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.975877464735317		[learning rate: 0.0069066]
	Learning Rate: 0.00690658
	LOSS [training: 1.975877464735317 | validation: 1.8300203924016256]
	TIME [epoch: 9.54 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.040057281628692		[learning rate: 0.0068815]
	Learning Rate: 0.00688152
	LOSS [training: 2.040057281628692 | validation: 1.6784694348132307]
	TIME [epoch: 9.52 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4310300321967118		[learning rate: 0.0068565]
	Learning Rate: 0.00685654
	LOSS [training: 3.4310300321967118 | validation: 1.9827593984165088]
	TIME [epoch: 9.53 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0779766307168996		[learning rate: 0.0068317]
	Learning Rate: 0.00683166
	LOSS [training: 2.0779766307168996 | validation: 1.5505690508736272]
	TIME [epoch: 9.56 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1001348983428665		[learning rate: 0.0068069]
	Learning Rate: 0.00680687
	LOSS [training: 2.1001348983428665 | validation: 1.553314315666799]
	TIME [epoch: 9.53 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9430761278797253		[learning rate: 0.0067822]
	Learning Rate: 0.00678217
	LOSS [training: 1.9430761278797253 | validation: 1.6791586320860552]
	TIME [epoch: 9.53 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1379447188522342		[learning rate: 0.0067576]
	Learning Rate: 0.00675755
	LOSS [training: 2.1379447188522342 | validation: 1.7549095755221515]
	TIME [epoch: 9.55 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0526637073485356		[learning rate: 0.006733]
	Learning Rate: 0.00673303
	LOSS [training: 2.0526637073485356 | validation: 1.9951639552088023]
	TIME [epoch: 9.54 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.996840359988126		[learning rate: 0.0067086]
	Learning Rate: 0.00670859
	LOSS [training: 1.996840359988126 | validation: 1.5166116136510743]
	TIME [epoch: 9.54 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.949999852811143		[learning rate: 0.0066842]
	Learning Rate: 0.00668425
	LOSS [training: 1.949999852811143 | validation: 1.6041351999453088]
	TIME [epoch: 9.52 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.999837397652827		[learning rate: 0.00666]
	Learning Rate: 0.00665999
	LOSS [training: 1.999837397652827 | validation: 1.5565586429377667]
	TIME [epoch: 9.56 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9241337137219674		[learning rate: 0.0066358]
	Learning Rate: 0.00663582
	LOSS [training: 1.9241337137219674 | validation: 1.56304901368347]
	TIME [epoch: 9.53 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9843353227317428		[learning rate: 0.0066117]
	Learning Rate: 0.00661174
	LOSS [training: 1.9843353227317428 | validation: 1.4186449715739624]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_214.pth
	Model improved!!!
EPOCH 215/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8926731637494505		[learning rate: 0.0065877]
	Learning Rate: 0.00658775
	LOSS [training: 1.8926731637494505 | validation: 1.4487213961974343]
	TIME [epoch: 9.56 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9374486412005774		[learning rate: 0.0065638]
	Learning Rate: 0.00656384
	LOSS [training: 1.9374486412005774 | validation: 1.4416766839766735]
	TIME [epoch: 9.54 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.998728711982005		[learning rate: 0.00654]
	Learning Rate: 0.00654002
	LOSS [training: 1.998728711982005 | validation: 1.4923007253038152]
	TIME [epoch: 9.53 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9664198138237297		[learning rate: 0.0065163]
	Learning Rate: 0.00651628
	LOSS [training: 1.9664198138237297 | validation: 1.6490761417871589]
	TIME [epoch: 9.53 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.162156705756156		[learning rate: 0.0064926]
	Learning Rate: 0.00649264
	LOSS [training: 2.162156705756156 | validation: 1.5713516779268994]
	TIME [epoch: 9.56 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.069624516413521		[learning rate: 0.0064691]
	Learning Rate: 0.00646907
	LOSS [training: 2.069624516413521 | validation: 1.6548286128813363]
	TIME [epoch: 9.52 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0902780150688627		[learning rate: 0.0064456]
	Learning Rate: 0.0064456
	LOSS [training: 2.0902780150688627 | validation: 1.7862192699921362]
	TIME [epoch: 9.53 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.016915600424424		[learning rate: 0.0064222]
	Learning Rate: 0.00642221
	LOSS [training: 2.016915600424424 | validation: 1.6000114035756943]
	TIME [epoch: 9.56 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0935716244275717		[learning rate: 0.0063989]
	Learning Rate: 0.0063989
	LOSS [training: 2.0935716244275717 | validation: 1.594559595092286]
	TIME [epoch: 9.54 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.03566076226089		[learning rate: 0.0063757]
	Learning Rate: 0.00637568
	LOSS [training: 2.03566076226089 | validation: 1.6169745636884574]
	TIME [epoch: 9.54 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3878882629600313		[learning rate: 0.0063525]
	Learning Rate: 0.00635254
	LOSS [training: 2.3878882629600313 | validation: 1.6967389953653567]
	TIME [epoch: 9.54 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0247039615666607		[learning rate: 0.0063295]
	Learning Rate: 0.00632949
	LOSS [training: 2.0247039615666607 | validation: 1.532276485386293]
	TIME [epoch: 9.56 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.932231905679841		[learning rate: 0.0063065]
	Learning Rate: 0.00630652
	LOSS [training: 1.932231905679841 | validation: 3.0509940054274898]
	TIME [epoch: 9.54 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.207669935138589		[learning rate: 0.0062836]
	Learning Rate: 0.00628363
	LOSS [training: 2.207669935138589 | validation: 1.5794704296401805]
	TIME [epoch: 9.54 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9932628761281523		[learning rate: 0.0062608]
	Learning Rate: 0.00626082
	LOSS [training: 1.9932628761281523 | validation: 1.5471927539172896]
	TIME [epoch: 9.56 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0115727947920177		[learning rate: 0.0062381]
	Learning Rate: 0.0062381
	LOSS [training: 2.0115727947920177 | validation: 1.7857790446637878]
	TIME [epoch: 9.54 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9997593907853126		[learning rate: 0.0062155]
	Learning Rate: 0.00621547
	LOSS [training: 1.9997593907853126 | validation: 1.6659478338215843]
	TIME [epoch: 9.54 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0991938605039815		[learning rate: 0.0061929]
	Learning Rate: 0.00619291
	LOSS [training: 2.0991938605039815 | validation: 1.652630786558516]
	TIME [epoch: 9.53 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.984942082359757		[learning rate: 0.0061704]
	Learning Rate: 0.00617043
	LOSS [training: 1.984942082359757 | validation: 1.6432027208426416]
	TIME [epoch: 9.56 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9475674742780122		[learning rate: 0.006148]
	Learning Rate: 0.00614804
	LOSS [training: 1.9475674742780122 | validation: 1.9742715378758524]
	TIME [epoch: 9.54 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1557051620460266		[learning rate: 0.0061257]
	Learning Rate: 0.00612573
	LOSS [training: 2.1557051620460266 | validation: 1.6466531429324776]
	TIME [epoch: 9.53 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.039173532411568		[learning rate: 0.0061035]
	Learning Rate: 0.0061035
	LOSS [training: 2.039173532411568 | validation: 1.666285669743296]
	TIME [epoch: 9.55 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1387301298089962		[learning rate: 0.0060814]
	Learning Rate: 0.00608135
	LOSS [training: 2.1387301298089962 | validation: 2.088339944674946]
	TIME [epoch: 9.54 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0919766744307564		[learning rate: 0.0060593]
	Learning Rate: 0.00605928
	LOSS [training: 2.0919766744307564 | validation: 1.669347659391446]
	TIME [epoch: 9.53 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0349200411515147		[learning rate: 0.0060373]
	Learning Rate: 0.00603729
	LOSS [training: 2.0349200411515147 | validation: 1.631974463418403]
	TIME [epoch: 9.53 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.033597957940507		[learning rate: 0.0060154]
	Learning Rate: 0.00601538
	LOSS [training: 2.033597957940507 | validation: 1.9710652731229135]
	TIME [epoch: 9.55 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.021744270546907		[learning rate: 0.0059936]
	Learning Rate: 0.00599355
	LOSS [training: 2.021744270546907 | validation: 1.7670083400900638]
	TIME [epoch: 9.54 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9686633832604863		[learning rate: 0.0059718]
	Learning Rate: 0.0059718
	LOSS [training: 1.9686633832604863 | validation: 1.563836971614082]
	TIME [epoch: 9.53 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2884704699585496		[learning rate: 0.0059501]
	Learning Rate: 0.00595013
	LOSS [training: 2.2884704699585496 | validation: 1.5196387451967635]
	TIME [epoch: 9.55 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0687199187489798		[learning rate: 0.0059285]
	Learning Rate: 0.00592853
	LOSS [training: 2.0687199187489798 | validation: 1.9388382935216009]
	TIME [epoch: 9.53 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.049686617053891		[learning rate: 0.005907]
	Learning Rate: 0.00590702
	LOSS [training: 2.049686617053891 | validation: 1.5430707584776098]
	TIME [epoch: 9.53 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8801342897816646		[learning rate: 0.0058856]
	Learning Rate: 0.00588558
	LOSS [training: 1.8801342897816646 | validation: 1.5216397888046027]
	TIME [epoch: 9.54 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.650124310849983		[learning rate: 0.0058642]
	Learning Rate: 0.00586422
	LOSS [training: 2.650124310849983 | validation: 1.9898907632983156]
	TIME [epoch: 9.56 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.036172116279112		[learning rate: 0.0058429]
	Learning Rate: 0.00584294
	LOSS [training: 2.036172116279112 | validation: 1.6801774601332848]
	TIME [epoch: 9.53 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9902436332598352		[learning rate: 0.0058217]
	Learning Rate: 0.00582174
	LOSS [training: 1.9902436332598352 | validation: 1.5522876793007203]
	TIME [epoch: 9.53 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9657402458973383		[learning rate: 0.0058006]
	Learning Rate: 0.00580061
	LOSS [training: 1.9657402458973383 | validation: 1.5594674041676775]
	TIME [epoch: 9.56 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9900526219269115		[learning rate: 0.0057796]
	Learning Rate: 0.00577956
	LOSS [training: 1.9900526219269115 | validation: 1.6767486158103566]
	TIME [epoch: 9.53 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9522381005367198		[learning rate: 0.0057586]
	Learning Rate: 0.00575859
	LOSS [training: 1.9522381005367198 | validation: 1.7168765361952314]
	TIME [epoch: 9.54 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9690932097448481		[learning rate: 0.0057377]
	Learning Rate: 0.00573769
	LOSS [training: 1.9690932097448481 | validation: 1.748479038129105]
	TIME [epoch: 9.54 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0429878183528656		[learning rate: 0.0057169]
	Learning Rate: 0.00571686
	LOSS [training: 2.0429878183528656 | validation: 1.8015263445253684]
	TIME [epoch: 9.56 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9706854476686022		[learning rate: 0.0056961]
	Learning Rate: 0.00569612
	LOSS [training: 1.9706854476686022 | validation: 1.714231197459601]
	TIME [epoch: 9.54 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1306622055353466		[learning rate: 0.0056754]
	Learning Rate: 0.00567545
	LOSS [training: 2.1306622055353466 | validation: 1.6771674617780128]
	TIME [epoch: 9.53 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.057126936930552		[learning rate: 0.0056548]
	Learning Rate: 0.00565485
	LOSS [training: 2.057126936930552 | validation: 1.697222239788025]
	TIME [epoch: 9.55 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9705264608161817		[learning rate: 0.0056343]
	Learning Rate: 0.00563433
	LOSS [training: 1.9705264608161817 | validation: 2.8465260235442034]
	TIME [epoch: 9.53 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1737943849403254		[learning rate: 0.0056139]
	Learning Rate: 0.00561388
	LOSS [training: 2.1737943849403254 | validation: 2.068683322307389]
	TIME [epoch: 9.53 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.004991746991854		[learning rate: 0.0055935]
	Learning Rate: 0.00559351
	LOSS [training: 2.004991746991854 | validation: 1.6789617685182907]
	TIME [epoch: 9.54 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9155536111602007		[learning rate: 0.0055732]
	Learning Rate: 0.00557321
	LOSS [training: 1.9155536111602007 | validation: 1.6733650485861231]
	TIME [epoch: 9.54 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9212799424400462		[learning rate: 0.005553]
	Learning Rate: 0.00555298
	LOSS [training: 1.9212799424400462 | validation: 1.4583133304966924]
	TIME [epoch: 9.53 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8310313672039065		[learning rate: 0.0055328]
	Learning Rate: 0.00553283
	LOSS [training: 1.8310313672039065 | validation: 1.3395770149853505]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_263.pth
	Model improved!!!
EPOCH 264/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.829335087993762		[learning rate: 0.0055128]
	Learning Rate: 0.00551275
	LOSS [training: 1.829335087993762 | validation: 1.5329043717038893]
	TIME [epoch: 9.57 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.78747127318894		[learning rate: 0.0054927]
	Learning Rate: 0.00549274
	LOSS [training: 1.78747127318894 | validation: 1.4382343543578657]
	TIME [epoch: 9.54 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.833193566592121		[learning rate: 0.0054728]
	Learning Rate: 0.00547281
	LOSS [training: 1.833193566592121 | validation: 1.4451464368567333]
	TIME [epoch: 9.54 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8121810671899836		[learning rate: 0.005453]
	Learning Rate: 0.00545295
	LOSS [training: 1.8121810671899836 | validation: 1.289200519000439]
	TIME [epoch: 9.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_267.pth
	Model improved!!!
EPOCH 268/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8666640385592999		[learning rate: 0.0054332]
	Learning Rate: 0.00543316
	LOSS [training: 1.8666640385592999 | validation: 1.6317234305279382]
	TIME [epoch: 9.56 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.832343683902876		[learning rate: 0.0054134]
	Learning Rate: 0.00541344
	LOSS [training: 1.832343683902876 | validation: 1.4049420899466856]
	TIME [epoch: 9.54 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.876759681587903		[learning rate: 0.0053938]
	Learning Rate: 0.0053938
	LOSS [training: 1.876759681587903 | validation: 1.5459052315376118]
	TIME [epoch: 9.54 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7657142190650112		[learning rate: 0.0053742]
	Learning Rate: 0.00537422
	LOSS [training: 1.7657142190650112 | validation: 1.3195305062970735]
	TIME [epoch: 9.56 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.789614018038085		[learning rate: 0.0053547]
	Learning Rate: 0.00535472
	LOSS [training: 1.789614018038085 | validation: 1.617355038925345]
	TIME [epoch: 9.54 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8192629655788082		[learning rate: 0.0053353]
	Learning Rate: 0.00533529
	LOSS [training: 1.8192629655788082 | validation: 1.26625483494873]
	TIME [epoch: 9.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_273.pth
	Model improved!!!
EPOCH 274/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7010650578651567		[learning rate: 0.0053159]
	Learning Rate: 0.00531593
	LOSS [training: 1.7010650578651567 | validation: 3.843451666879336]
	TIME [epoch: 9.54 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4467174914832888		[learning rate: 0.0052966]
	Learning Rate: 0.00529663
	LOSS [training: 2.4467174914832888 | validation: 1.6866500667819608]
	TIME [epoch: 9.56 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7807875375705469		[learning rate: 0.0052774]
	Learning Rate: 0.00527741
	LOSS [training: 1.7807875375705469 | validation: 1.2423871871921046]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_276.pth
	Model improved!!!
EPOCH 277/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7830788301319611		[learning rate: 0.0052583]
	Learning Rate: 0.00525826
	LOSS [training: 1.7830788301319611 | validation: 1.2840767939072584]
	TIME [epoch: 9.55 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8027357081445459		[learning rate: 0.0052392]
	Learning Rate: 0.00523918
	LOSS [training: 1.8027357081445459 | validation: 1.3065931394095747]
	TIME [epoch: 9.57 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0498036350586935		[learning rate: 0.0052202]
	Learning Rate: 0.00522017
	LOSS [training: 2.0498036350586935 | validation: 1.3744533659826965]
	TIME [epoch: 9.55 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7291405889926021		[learning rate: 0.0052012]
	Learning Rate: 0.00520122
	LOSS [training: 1.7291405889926021 | validation: 1.2776543041510982]
	TIME [epoch: 9.54 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7036196627749944		[learning rate: 0.0051823]
	Learning Rate: 0.00518234
	LOSS [training: 1.7036196627749944 | validation: 1.2589063423597149]
	TIME [epoch: 9.57 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5996956027497222		[learning rate: 0.0051635]
	Learning Rate: 0.00516354
	LOSS [training: 1.5996956027497222 | validation: 1.2005803410993179]
	TIME [epoch: 9.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_282.pth
	Model improved!!!
EPOCH 283/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5734998678356398		[learning rate: 0.0051448]
	Learning Rate: 0.0051448
	LOSS [training: 1.5734998678356398 | validation: 1.2205078950217954]
	TIME [epoch: 9.54 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4530666371747039		[learning rate: 0.0051261]
	Learning Rate: 0.00512613
	LOSS [training: 1.4530666371747039 | validation: 1.1752889603422]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_284.pth
	Model improved!!!
EPOCH 285/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1670271055963448		[learning rate: 0.0051075]
	Learning Rate: 0.00510753
	LOSS [training: 1.1670271055963448 | validation: 0.6316337626256066]
	TIME [epoch: 9.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_285.pth
	Model improved!!!
EPOCH 286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8700958811016821		[learning rate: 0.005089]
	Learning Rate: 0.00508899
	LOSS [training: 0.8700958811016821 | validation: 0.8558270735132671]
	TIME [epoch: 9.53 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9074795649533322		[learning rate: 0.0050705]
	Learning Rate: 0.00507052
	LOSS [training: 0.9074795649533322 | validation: 0.7243747943007096]
	TIME [epoch: 9.54 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0005248435536889		[learning rate: 0.0050521]
	Learning Rate: 0.00505212
	LOSS [training: 1.0005248435536889 | validation: 0.6008598811690773]
	TIME [epoch: 9.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_288.pth
	Model improved!!!
EPOCH 289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8849089100257702		[learning rate: 0.0050338]
	Learning Rate: 0.00503379
	LOSS [training: 0.8849089100257702 | validation: 0.9983567608471501]
	TIME [epoch: 9.54 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9852840455980278		[learning rate: 0.0050155]
	Learning Rate: 0.00501552
	LOSS [training: 0.9852840455980278 | validation: 0.6491179194450575]
	TIME [epoch: 9.53 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9392279727140925		[learning rate: 0.0049973]
	Learning Rate: 0.00499732
	LOSS [training: 0.9392279727140925 | validation: 0.6527360090196085]
	TIME [epoch: 9.54 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7837384753375136		[learning rate: 0.0049792]
	Learning Rate: 0.00497918
	LOSS [training: 0.7837384753375136 | validation: 0.7326729592030404]
	TIME [epoch: 9.55 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7791181063463863		[learning rate: 0.0049611]
	Learning Rate: 0.00496111
	LOSS [training: 0.7791181063463863 | validation: 0.832076047087892]
	TIME [epoch: 9.53 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9243073573749531		[learning rate: 0.0049431]
	Learning Rate: 0.00494311
	LOSS [training: 0.9243073573749531 | validation: 0.6479950027682645]
	TIME [epoch: 9.53 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0155693264468864		[learning rate: 0.0049252]
	Learning Rate: 0.00492517
	LOSS [training: 1.0155693264468864 | validation: 0.6638918348334235]
	TIME [epoch: 9.55 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8412864326004857		[learning rate: 0.0049073]
	Learning Rate: 0.00490729
	LOSS [training: 0.8412864326004857 | validation: 0.6190174352190784]
	TIME [epoch: 9.53 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8612096449538592		[learning rate: 0.0048895]
	Learning Rate: 0.00488948
	LOSS [training: 0.8612096449538592 | validation: 0.9168432519404115]
	TIME [epoch: 9.53 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.054155261364937		[learning rate: 0.0048717]
	Learning Rate: 0.00487174
	LOSS [training: 1.054155261364937 | validation: 1.049113313221235]
	TIME [epoch: 9.54 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0111110557571208		[learning rate: 0.0048541]
	Learning Rate: 0.00485406
	LOSS [training: 1.0111110557571208 | validation: 0.5681393200681909]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_299.pth
	Model improved!!!
EPOCH 300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7724716514875032		[learning rate: 0.0048364]
	Learning Rate: 0.00483645
	LOSS [training: 0.7724716514875032 | validation: 0.731432982407238]
	TIME [epoch: 9.54 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9387108812584166		[learning rate: 0.0048189]
	Learning Rate: 0.00481889
	LOSS [training: 0.9387108812584166 | validation: 0.5596287799227484]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_301.pth
	Model improved!!!
EPOCH 302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7460855875080141		[learning rate: 0.0048014]
	Learning Rate: 0.00480141
	LOSS [training: 0.7460855875080141 | validation: 0.548596301374761]
	TIME [epoch: 9.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_302.pth
	Model improved!!!
EPOCH 303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7962847337464857		[learning rate: 0.004784]
	Learning Rate: 0.00478398
	LOSS [training: 0.7962847337464857 | validation: 0.8497651053720638]
	TIME [epoch: 9.53 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8049668152262317		[learning rate: 0.0047666]
	Learning Rate: 0.00476662
	LOSS [training: 0.8049668152262317 | validation: 0.6238229148596115]
	TIME [epoch: 9.53 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.894242304780142		[learning rate: 0.0047493]
	Learning Rate: 0.00474932
	LOSS [training: 0.894242304780142 | validation: 0.6463190364466658]
	TIME [epoch: 9.55 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9852309735054204		[learning rate: 0.0047321]
	Learning Rate: 0.00473209
	LOSS [training: 0.9852309735054204 | validation: 0.768568527345578]
	TIME [epoch: 9.53 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7934920584557885		[learning rate: 0.0047149]
	Learning Rate: 0.00471491
	LOSS [training: 0.7934920584557885 | validation: 0.5183615452355472]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_307.pth
	Model improved!!!
EPOCH 308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7246825378618672		[learning rate: 0.0046978]
	Learning Rate: 0.0046978
	LOSS [training: 0.7246825378618672 | validation: 0.5208040123554369]
	TIME [epoch: 9.53 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.827156673197084		[learning rate: 0.0046808]
	Learning Rate: 0.00468075
	LOSS [training: 0.827156673197084 | validation: 0.6423079975453273]
	TIME [epoch: 9.57 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7989458658475507		[learning rate: 0.0046638]
	Learning Rate: 0.00466377
	LOSS [training: 0.7989458658475507 | validation: 0.742295348822379]
	TIME [epoch: 9.53 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.821162854883472		[learning rate: 0.0046468]
	Learning Rate: 0.00464684
	LOSS [training: 0.821162854883472 | validation: 0.6256250106327466]
	TIME [epoch: 9.53 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8830351941695449		[learning rate: 0.00463]
	Learning Rate: 0.00462998
	LOSS [training: 0.8830351941695449 | validation: 0.8213023646816232]
	TIME [epoch: 9.55 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9304177194149563		[learning rate: 0.0046132]
	Learning Rate: 0.00461318
	LOSS [training: 0.9304177194149563 | validation: 0.8438718960629941]
	TIME [epoch: 9.54 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0342438034328771		[learning rate: 0.0045964]
	Learning Rate: 0.00459643
	LOSS [training: 1.0342438034328771 | validation: 0.5768573858366578]
	TIME [epoch: 9.54 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7993458269238086		[learning rate: 0.0045798]
	Learning Rate: 0.00457975
	LOSS [training: 0.7993458269238086 | validation: 0.6789672161012072]
	TIME [epoch: 9.53 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.928647249639363		[learning rate: 0.0045631]
	Learning Rate: 0.00456313
	LOSS [training: 0.928647249639363 | validation: 0.7494053412530446]
	TIME [epoch: 9.56 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8440540028266085		[learning rate: 0.0045466]
	Learning Rate: 0.00454657
	LOSS [training: 0.8440540028266085 | validation: 0.5244609744527969]
	TIME [epoch: 9.53 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8661006152921559		[learning rate: 0.0045301]
	Learning Rate: 0.00453007
	LOSS [training: 0.8661006152921559 | validation: 0.6819051186708162]
	TIME [epoch: 9.53 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8718902740133103		[learning rate: 0.0045136]
	Learning Rate: 0.00451363
	LOSS [training: 0.8718902740133103 | validation: 0.5204394700975168]
	TIME [epoch: 9.55 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7022217380365271		[learning rate: 0.0044973]
	Learning Rate: 0.00449725
	LOSS [training: 0.7022217380365271 | validation: 0.5830375546415196]
	TIME [epoch: 9.54 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7752866702499052		[learning rate: 0.0044809]
	Learning Rate: 0.00448093
	LOSS [training: 0.7752866702499052 | validation: 0.5012948644045876]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_321.pth
	Model improved!!!
EPOCH 322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7641037137219888		[learning rate: 0.0044647]
	Learning Rate: 0.00446467
	LOSS [training: 0.7641037137219888 | validation: 0.5512325075362651]
	TIME [epoch: 9.54 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8926300285430786		[learning rate: 0.0044485]
	Learning Rate: 0.00444847
	LOSS [training: 0.8926300285430786 | validation: 0.8292681058423981]
	TIME [epoch: 9.55 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7722614457951033		[learning rate: 0.0044323]
	Learning Rate: 0.00443232
	LOSS [training: 0.7722614457951033 | validation: 0.6981419605472311]
	TIME [epoch: 9.86 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.804008175994829		[learning rate: 0.0044162]
	Learning Rate: 0.00441624
	LOSS [training: 0.804008175994829 | validation: 0.5702702838657934]
	TIME [epoch: 9.54 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7621773253740074		[learning rate: 0.0044002]
	Learning Rate: 0.00440021
	LOSS [training: 0.7621773253740074 | validation: 0.900264397167125]
	TIME [epoch: 9.58 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7898028679285997		[learning rate: 0.0043842]
	Learning Rate: 0.00438424
	LOSS [training: 0.7898028679285997 | validation: 0.5654295323327717]
	TIME [epoch: 9.54 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7838151730812911		[learning rate: 0.0043683]
	Learning Rate: 0.00436833
	LOSS [training: 0.7838151730812911 | validation: 0.5768283215425667]
	TIME [epoch: 9.55 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7650102360785056		[learning rate: 0.0043525]
	Learning Rate: 0.00435248
	LOSS [training: 0.7650102360785056 | validation: 0.6363370822441988]
	TIME [epoch: 9.54 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8433175959891421		[learning rate: 0.0043367]
	Learning Rate: 0.00433668
	LOSS [training: 0.8433175959891421 | validation: 0.586635048232753]
	TIME [epoch: 9.57 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7831851426394401		[learning rate: 0.0043209]
	Learning Rate: 0.00432095
	LOSS [training: 0.7831851426394401 | validation: 0.9408911425007733]
	TIME [epoch: 9.54 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8177321798488851		[learning rate: 0.0043053]
	Learning Rate: 0.00430527
	LOSS [training: 0.8177321798488851 | validation: 0.856555097919264]
	TIME [epoch: 9.55 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8305464512546846		[learning rate: 0.0042896]
	Learning Rate: 0.00428964
	LOSS [training: 0.8305464512546846 | validation: 0.6345531874333491]
	TIME [epoch: 9.56 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8085656835846142		[learning rate: 0.0042741]
	Learning Rate: 0.00427407
	LOSS [training: 0.8085656835846142 | validation: 0.5825629683795633]
	TIME [epoch: 9.55 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8012212440147335		[learning rate: 0.0042586]
	Learning Rate: 0.00425856
	LOSS [training: 0.8012212440147335 | validation: 0.7762576503517946]
	TIME [epoch: 9.54 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7713529139641484		[learning rate: 0.0042431]
	Learning Rate: 0.00424311
	LOSS [training: 0.7713529139641484 | validation: 0.5431464685030221]
	TIME [epoch: 9.55 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.752190385735051		[learning rate: 0.0042277]
	Learning Rate: 0.00422771
	LOSS [training: 0.752190385735051 | validation: 0.6765345251668982]
	TIME [epoch: 9.57 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7058463416769813		[learning rate: 0.0042124]
	Learning Rate: 0.00421237
	LOSS [training: 0.7058463416769813 | validation: 0.5855167099744161]
	TIME [epoch: 9.55 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7269839839356134		[learning rate: 0.0041971]
	Learning Rate: 0.00419708
	LOSS [training: 0.7269839839356134 | validation: 0.5883322318795622]
	TIME [epoch: 9.54 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8576879002646324		[learning rate: 0.0041818]
	Learning Rate: 0.00418185
	LOSS [training: 0.8576879002646324 | validation: 0.6890219855085324]
	TIME [epoch: 9.57 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7460316041780419		[learning rate: 0.0041667]
	Learning Rate: 0.00416667
	LOSS [training: 0.7460316041780419 | validation: 0.5185644889225656]
	TIME [epoch: 9.55 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7746713843091709		[learning rate: 0.0041516]
	Learning Rate: 0.00415155
	LOSS [training: 0.7746713843091709 | validation: 0.5269626367587216]
	TIME [epoch: 9.55 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7180991859818902		[learning rate: 0.0041365]
	Learning Rate: 0.00413649
	LOSS [training: 0.7180991859818902 | validation: 1.2005516883753224]
	TIME [epoch: 9.55 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8589206709333445		[learning rate: 0.0041215]
	Learning Rate: 0.00412147
	LOSS [training: 0.8589206709333445 | validation: 0.5571598233199068]
	TIME [epoch: 9.58 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7471944942923298		[learning rate: 0.0041065]
	Learning Rate: 0.00410652
	LOSS [training: 0.7471944942923298 | validation: 0.5877493140019334]
	TIME [epoch: 9.54 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7552678411335101		[learning rate: 0.0040916]
	Learning Rate: 0.00409161
	LOSS [training: 0.7552678411335101 | validation: 0.6456729716661656]
	TIME [epoch: 9.54 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8680794770671871		[learning rate: 0.0040768]
	Learning Rate: 0.00407677
	LOSS [training: 0.8680794770671871 | validation: 0.5208371580902764]
	TIME [epoch: 9.56 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8236244486152383		[learning rate: 0.004062]
	Learning Rate: 0.00406197
	LOSS [training: 0.8236244486152383 | validation: 0.5823869319904532]
	TIME [epoch: 9.55 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8150690055710179		[learning rate: 0.0040472]
	Learning Rate: 0.00404723
	LOSS [training: 0.8150690055710179 | validation: 0.5516358981378054]
	TIME [epoch: 9.55 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8754487131924286		[learning rate: 0.0040325]
	Learning Rate: 0.00403254
	LOSS [training: 0.8754487131924286 | validation: 0.5655008690603944]
	TIME [epoch: 9.55 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7014266197555001		[learning rate: 0.0040179]
	Learning Rate: 0.00401791
	LOSS [training: 0.7014266197555001 | validation: 0.6088408725917385]
	TIME [epoch: 9.56 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7039724524069334		[learning rate: 0.0040033]
	Learning Rate: 0.00400333
	LOSS [training: 0.7039724524069334 | validation: 0.5198871095469451]
	TIME [epoch: 9.55 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7663246680991872		[learning rate: 0.0039888]
	Learning Rate: 0.0039888
	LOSS [training: 0.7663246680991872 | validation: 0.552247303934191]
	TIME [epoch: 9.54 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7562319199832129		[learning rate: 0.0039743]
	Learning Rate: 0.00397432
	LOSS [training: 0.7562319199832129 | validation: 0.9813884935112032]
	TIME [epoch: 9.57 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7707475331365081		[learning rate: 0.0039599]
	Learning Rate: 0.0039599
	LOSS [training: 0.7707475331365081 | validation: 0.6519761990408753]
	TIME [epoch: 9.55 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7678036210450477		[learning rate: 0.0039455]
	Learning Rate: 0.00394553
	LOSS [training: 0.7678036210450477 | validation: 0.5728168826707029]
	TIME [epoch: 9.55 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7718626754366558		[learning rate: 0.0039312]
	Learning Rate: 0.00393121
	LOSS [training: 0.7718626754366558 | validation: 0.6231910670227263]
	TIME [epoch: 9.55 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6731200328871116		[learning rate: 0.0039169]
	Learning Rate: 0.00391694
	LOSS [training: 0.6731200328871116 | validation: 0.592137729337002]
	TIME [epoch: 9.56 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7562650541580558		[learning rate: 0.0039027]
	Learning Rate: 0.00390273
	LOSS [training: 0.7562650541580558 | validation: 0.5244856779868567]
	TIME [epoch: 9.54 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6884361817725025		[learning rate: 0.0038886]
	Learning Rate: 0.00388857
	LOSS [training: 0.6884361817725025 | validation: 0.49109737107634843]
	TIME [epoch: 9.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_360.pth
	Model improved!!!
EPOCH 361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7855206897731362		[learning rate: 0.0038745]
	Learning Rate: 0.00387445
	LOSS [training: 0.7855206897731362 | validation: 0.5652645143501422]
	TIME [epoch: 9.58 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7174256941346936		[learning rate: 0.0038604]
	Learning Rate: 0.00386039
	LOSS [training: 0.7174256941346936 | validation: 0.7495110115059265]
	TIME [epoch: 9.55 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7061676608252817		[learning rate: 0.0038464]
	Learning Rate: 0.00384638
	LOSS [training: 0.7061676608252817 | validation: 0.7615680385964416]
	TIME [epoch: 9.54 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7891881527890202		[learning rate: 0.0038324]
	Learning Rate: 0.00383242
	LOSS [training: 0.7891881527890202 | validation: 0.7667056395096918]
	TIME [epoch: 9.56 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7815788165042756		[learning rate: 0.0038185]
	Learning Rate: 0.00381852
	LOSS [training: 0.7815788165042756 | validation: 0.6718411102441237]
	TIME [epoch: 9.56 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.796307697003688		[learning rate: 0.0038047]
	Learning Rate: 0.00380466
	LOSS [training: 0.796307697003688 | validation: 0.7767413352406868]
	TIME [epoch: 9.55 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7369564727715562		[learning rate: 0.0037909]
	Learning Rate: 0.00379085
	LOSS [training: 0.7369564727715562 | validation: 0.4770345426476817]
	TIME [epoch: 9.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_367.pth
	Model improved!!!
EPOCH 368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7854295828562854		[learning rate: 0.0037771]
	Learning Rate: 0.00377709
	LOSS [training: 0.7854295828562854 | validation: 0.6675587112979651]
	TIME [epoch: 9.58 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7232286747388394		[learning rate: 0.0037634]
	Learning Rate: 0.00376339
	LOSS [training: 0.7232286747388394 | validation: 0.621605523411378]
	TIME [epoch: 9.55 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.746348123194022		[learning rate: 0.0037497]
	Learning Rate: 0.00374973
	LOSS [training: 0.746348123194022 | validation: 0.6614860123770984]
	TIME [epoch: 9.55 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6839468930976008		[learning rate: 0.0037361]
	Learning Rate: 0.00373612
	LOSS [training: 0.6839468930976008 | validation: 0.5134981205710023]
	TIME [epoch: 9.57 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7166641530443257		[learning rate: 0.0037226]
	Learning Rate: 0.00372256
	LOSS [training: 0.7166641530443257 | validation: 0.5617292737450422]
	TIME [epoch: 9.55 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0057460279443542		[learning rate: 0.0037091]
	Learning Rate: 0.00370905
	LOSS [training: 1.0057460279443542 | validation: 0.5083797778502716]
	TIME [epoch: 9.54 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7427043668630042		[learning rate: 0.0036956]
	Learning Rate: 0.00369559
	LOSS [training: 0.7427043668630042 | validation: 0.6002608017257548]
	TIME [epoch: 9.55 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.707244746598281		[learning rate: 0.0036822]
	Learning Rate: 0.00368218
	LOSS [training: 0.707244746598281 | validation: 0.6420473048718199]
	TIME [epoch: 9.57 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6933529822249822		[learning rate: 0.0036688]
	Learning Rate: 0.00366882
	LOSS [training: 0.6933529822249822 | validation: 0.816556938846933]
	TIME [epoch: 9.56 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7236002016447769		[learning rate: 0.0036555]
	Learning Rate: 0.0036555
	LOSS [training: 0.7236002016447769 | validation: 0.5892438141778304]
	TIME [epoch: 9.55 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8741798314206438		[learning rate: 0.0036422]
	Learning Rate: 0.00364224
	LOSS [training: 0.8741798314206438 | validation: 0.5980031924820611]
	TIME [epoch: 9.58 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6753465727137484		[learning rate: 0.003629]
	Learning Rate: 0.00362902
	LOSS [training: 0.6753465727137484 | validation: 0.632120436836822]
	TIME [epoch: 9.56 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6933955229856726		[learning rate: 0.0036159]
	Learning Rate: 0.00361585
	LOSS [training: 0.6933955229856726 | validation: 0.5915161450741082]
	TIME [epoch: 9.55 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7643530228931434		[learning rate: 0.0036027]
	Learning Rate: 0.00360273
	LOSS [training: 0.7643530228931434 | validation: 0.6690494267328236]
	TIME [epoch: 9.55 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7419805376344747		[learning rate: 0.0035897]
	Learning Rate: 0.00358965
	LOSS [training: 0.7419805376344747 | validation: 0.5131040749743163]
	TIME [epoch: 9.58 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8492101258298088		[learning rate: 0.0035766]
	Learning Rate: 0.00357663
	LOSS [training: 0.8492101258298088 | validation: 0.6744691462598001]
	TIME [epoch: 9.55 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7130975407368075		[learning rate: 0.0035636]
	Learning Rate: 0.00356365
	LOSS [training: 0.7130975407368075 | validation: 0.6101814029390099]
	TIME [epoch: 9.56 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7550201014686377		[learning rate: 0.0035507]
	Learning Rate: 0.00355072
	LOSS [training: 0.7550201014686377 | validation: 0.5389514341457055]
	TIME [epoch: 9.57 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7427764147369509		[learning rate: 0.0035378]
	Learning Rate: 0.00353783
	LOSS [training: 0.7427764147369509 | validation: 0.5146949675328047]
	TIME [epoch: 9.56 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7779719971384856		[learning rate: 0.003525]
	Learning Rate: 0.00352499
	LOSS [training: 0.7779719971384856 | validation: 0.5189942759274755]
	TIME [epoch: 9.55 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6917483454109689		[learning rate: 0.0035122]
	Learning Rate: 0.0035122
	LOSS [training: 0.6917483454109689 | validation: 0.7558055256645119]
	TIME [epoch: 9.55 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7657580554737466		[learning rate: 0.0034995]
	Learning Rate: 0.00349945
	LOSS [training: 0.7657580554737466 | validation: 0.7107984070162853]
	TIME [epoch: 9.57 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7179503054688319		[learning rate: 0.0034868]
	Learning Rate: 0.00348675
	LOSS [training: 0.7179503054688319 | validation: 0.6140717534231118]
	TIME [epoch: 9.54 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6794666471903701		[learning rate: 0.0034741]
	Learning Rate: 0.0034741
	LOSS [training: 0.6794666471903701 | validation: 0.6710349079857235]
	TIME [epoch: 9.55 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.732674695306269		[learning rate: 0.0034615]
	Learning Rate: 0.00346149
	LOSS [training: 0.732674695306269 | validation: 0.6985019899120386]
	TIME [epoch: 9.57 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7186470413499408		[learning rate: 0.0034489]
	Learning Rate: 0.00344893
	LOSS [training: 0.7186470413499408 | validation: 0.5101116451127214]
	TIME [epoch: 9.54 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.684368442595796		[learning rate: 0.0034364]
	Learning Rate: 0.00343641
	LOSS [training: 0.684368442595796 | validation: 0.5672702196803483]
	TIME [epoch: 9.55 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7394392719715508		[learning rate: 0.0034239]
	Learning Rate: 0.00342394
	LOSS [training: 0.7394392719715508 | validation: 0.5926947366656742]
	TIME [epoch: 9.56 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6712021398488378		[learning rate: 0.0034115]
	Learning Rate: 0.00341152
	LOSS [training: 0.6712021398488378 | validation: 0.5456051295301589]
	TIME [epoch: 9.57 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8322172712637418		[learning rate: 0.0033991]
	Learning Rate: 0.00339914
	LOSS [training: 0.8322172712637418 | validation: 0.5770010054013252]
	TIME [epoch: 9.55 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8208332909934638		[learning rate: 0.0033868]
	Learning Rate: 0.0033868
	LOSS [training: 0.8208332909934638 | validation: 0.7064814118759642]
	TIME [epoch: 9.54 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7654293692619498		[learning rate: 0.0033745]
	Learning Rate: 0.00337451
	LOSS [training: 0.7654293692619498 | validation: 0.5537995561695971]
	TIME [epoch: 9.57 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7070775715743167		[learning rate: 0.0033623]
	Learning Rate: 0.00336226
	LOSS [training: 0.7070775715743167 | validation: 0.6103835488494346]
	TIME [epoch: 9.54 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6950661203698737		[learning rate: 0.0033501]
	Learning Rate: 0.00335006
	LOSS [training: 0.6950661203698737 | validation: 0.559665062341335]
	TIME [epoch: 9.53 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.707437903616773		[learning rate: 0.0033379]
	Learning Rate: 0.0033379
	LOSS [training: 0.707437903616773 | validation: 0.4952266249744212]
	TIME [epoch: 9.54 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6589651832265668		[learning rate: 0.0033258]
	Learning Rate: 0.00332579
	LOSS [training: 0.6589651832265668 | validation: 0.47323836310972617]
	TIME [epoch: 9.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_403.pth
	Model improved!!!
EPOCH 404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6707739801516861		[learning rate: 0.0033137]
	Learning Rate: 0.00331372
	LOSS [training: 0.6707739801516861 | validation: 0.706605683553274]
	TIME [epoch: 9.54 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7121476620838338		[learning rate: 0.0033017]
	Learning Rate: 0.00330169
	LOSS [training: 0.7121476620838338 | validation: 0.49521780389559483]
	TIME [epoch: 9.54 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7074993562862406		[learning rate: 0.0032897]
	Learning Rate: 0.00328971
	LOSS [training: 0.7074993562862406 | validation: 0.49467621572879067]
	TIME [epoch: 9.55 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.789330338184379		[learning rate: 0.0032778]
	Learning Rate: 0.00327777
	LOSS [training: 0.789330338184379 | validation: 0.5244341832750067]
	TIME [epoch: 9.54 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.702191847748359		[learning rate: 0.0032659]
	Learning Rate: 0.00326588
	LOSS [training: 0.702191847748359 | validation: 0.6724136111988105]
	TIME [epoch: 9.54 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7153837628122386		[learning rate: 0.003254]
	Learning Rate: 0.00325403
	LOSS [training: 0.7153837628122386 | validation: 0.5514452087299995]
	TIME [epoch: 9.55 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6784176910301564		[learning rate: 0.0032422]
	Learning Rate: 0.00324222
	LOSS [training: 0.6784176910301564 | validation: 0.9024996736297393]
	TIME [epoch: 9.55 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7746833071603774		[learning rate: 0.0032305]
	Learning Rate: 0.00323045
	LOSS [training: 0.7746833071603774 | validation: 0.5099053124873917]
	TIME [epoch: 9.54 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6789611868818695		[learning rate: 0.0032187]
	Learning Rate: 0.00321873
	LOSS [training: 0.6789611868818695 | validation: 0.5089665710162485]
	TIME [epoch: 9.54 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6744072192130564		[learning rate: 0.003207]
	Learning Rate: 0.00320705
	LOSS [training: 0.6744072192130564 | validation: 0.6915849877652868]
	TIME [epoch: 9.57 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7425208510648561		[learning rate: 0.0031954]
	Learning Rate: 0.00319541
	LOSS [training: 0.7425208510648561 | validation: 0.4996034900733122]
	TIME [epoch: 9.54 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8089342969301498		[learning rate: 0.0031838]
	Learning Rate: 0.00318381
	LOSS [training: 0.8089342969301498 | validation: 0.5973068687168861]
	TIME [epoch: 9.54 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6659566430737691		[learning rate: 0.0031723]
	Learning Rate: 0.00317226
	LOSS [training: 0.6659566430737691 | validation: 0.6044452508130833]
	TIME [epoch: 9.55 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6667046974975518		[learning rate: 0.0031607]
	Learning Rate: 0.00316075
	LOSS [training: 0.6667046974975518 | validation: 0.5768754320299986]
	TIME [epoch: 9.55 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6635480458381174		[learning rate: 0.0031493]
	Learning Rate: 0.00314927
	LOSS [training: 0.6635480458381174 | validation: 0.5199469680365963]
	TIME [epoch: 9.54 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6965394413105452		[learning rate: 0.0031378]
	Learning Rate: 0.00313785
	LOSS [training: 0.6965394413105452 | validation: 0.6351925717977254]
	TIME [epoch: 9.55 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6821396985405488		[learning rate: 0.0031265]
	Learning Rate: 0.00312646
	LOSS [training: 0.6821396985405488 | validation: 0.6421351248189028]
	TIME [epoch: 9.56 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6545564050374948		[learning rate: 0.0031151]
	Learning Rate: 0.00311511
	LOSS [training: 0.6545564050374948 | validation: 0.7904882846906169]
	TIME [epoch: 9.54 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7202924590555577		[learning rate: 0.0031038]
	Learning Rate: 0.00310381
	LOSS [training: 0.7202924590555577 | validation: 0.5094431524856153]
	TIME [epoch: 9.54 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.729035990133652		[learning rate: 0.0030925]
	Learning Rate: 0.00309254
	LOSS [training: 0.729035990133652 | validation: 0.929244213356847]
	TIME [epoch: 9.57 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7315456484314949		[learning rate: 0.0030813]
	Learning Rate: 0.00308132
	LOSS [training: 0.7315456484314949 | validation: 0.620651260675814]
	TIME [epoch: 9.54 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6644605154200678		[learning rate: 0.0030701]
	Learning Rate: 0.00307014
	LOSS [training: 0.6644605154200678 | validation: 0.6609568077429016]
	TIME [epoch: 9.54 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6710301542577197		[learning rate: 0.003059]
	Learning Rate: 0.003059
	LOSS [training: 0.6710301542577197 | validation: 0.5613602580733216]
	TIME [epoch: 9.54 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6589759621541338		[learning rate: 0.0030479]
	Learning Rate: 0.0030479
	LOSS [training: 0.6589759621541338 | validation: 0.6353103244593836]
	TIME [epoch: 9.57 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7292892133054175		[learning rate: 0.0030368]
	Learning Rate: 0.00303683
	LOSS [training: 0.7292892133054175 | validation: 0.5436529351492003]
	TIME [epoch: 9.55 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7595123459934945		[learning rate: 0.0030258]
	Learning Rate: 0.00302581
	LOSS [training: 0.7595123459934945 | validation: 0.48933326182714026]
	TIME [epoch: 9.54 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6647378938005798		[learning rate: 0.0030148]
	Learning Rate: 0.00301483
	LOSS [training: 0.6647378938005798 | validation: 0.5720291173855302]
	TIME [epoch: 9.55 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7496147663477479		[learning rate: 0.0030039]
	Learning Rate: 0.00300389
	LOSS [training: 0.7496147663477479 | validation: 0.5455055659249787]
	TIME [epoch: 9.54 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6901549737984072		[learning rate: 0.002993]
	Learning Rate: 0.00299299
	LOSS [training: 0.6901549737984072 | validation: 0.47228159666562863]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_432.pth
	Model improved!!!
EPOCH 433/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0169367871508126		[learning rate: 0.0029821]
	Learning Rate: 0.00298213
	LOSS [training: 1.0169367871508126 | validation: 0.47560800905316064]
	TIME [epoch: 9.53 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8049798556478558		[learning rate: 0.0029713]
	Learning Rate: 0.00297131
	LOSS [training: 0.8049798556478558 | validation: 0.5125311658217946]
	TIME [epoch: 9.56 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7263309935803839		[learning rate: 0.0029605]
	Learning Rate: 0.00296052
	LOSS [training: 0.7263309935803839 | validation: 0.5379018462304812]
	TIME [epoch: 9.54 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7466467128105353		[learning rate: 0.0029498]
	Learning Rate: 0.00294978
	LOSS [training: 0.7466467128105353 | validation: 0.5524597589801633]
	TIME [epoch: 9.53 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6651822125124973		[learning rate: 0.0029391]
	Learning Rate: 0.00293907
	LOSS [training: 0.6651822125124973 | validation: 0.5075486694722574]
	TIME [epoch: 9.55 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6654993010492317		[learning rate: 0.0029284]
	Learning Rate: 0.00292841
	LOSS [training: 0.6654993010492317 | validation: 0.4979145057435524]
	TIME [epoch: 9.54 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6766509076935738		[learning rate: 0.0029178]
	Learning Rate: 0.00291778
	LOSS [training: 0.6766509076935738 | validation: 0.5379790021540611]
	TIME [epoch: 9.53 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6324104041449835		[learning rate: 0.0029072]
	Learning Rate: 0.00290719
	LOSS [training: 0.6324104041449835 | validation: 0.6050142214830981]
	TIME [epoch: 9.53 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6409165374196386		[learning rate: 0.0028966]
	Learning Rate: 0.00289664
	LOSS [training: 0.6409165374196386 | validation: 0.6002521625476187]
	TIME [epoch: 9.55 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7057873409539066		[learning rate: 0.0028861]
	Learning Rate: 0.00288613
	LOSS [training: 0.7057873409539066 | validation: 0.45975891291781423]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_442.pth
	Model improved!!!
EPOCH 443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6908681190820877		[learning rate: 0.0028757]
	Learning Rate: 0.00287566
	LOSS [training: 0.6908681190820877 | validation: 0.7244095271852851]
	TIME [epoch: 9.54 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6890168089909492		[learning rate: 0.0028652]
	Learning Rate: 0.00286522
	LOSS [training: 0.6890168089909492 | validation: 0.7772136854562263]
	TIME [epoch: 9.56 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7912376708322123		[learning rate: 0.0028548]
	Learning Rate: 0.00285482
	LOSS [training: 0.7912376708322123 | validation: 0.549562358625108]
	TIME [epoch: 9.54 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6350441918634814		[learning rate: 0.0028445]
	Learning Rate: 0.00284446
	LOSS [training: 0.6350441918634814 | validation: 0.4967750482864402]
	TIME [epoch: 9.53 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6776726879880355		[learning rate: 0.0028341]
	Learning Rate: 0.00283414
	LOSS [training: 0.6776726879880355 | validation: 0.4949224618164616]
	TIME [epoch: 9.53 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6829383559721174		[learning rate: 0.0028239]
	Learning Rate: 0.00282385
	LOSS [training: 0.6829383559721174 | validation: 0.4608144096123596]
	TIME [epoch: 9.55 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6632841191056592		[learning rate: 0.0028136]
	Learning Rate: 0.00281361
	LOSS [training: 0.6632841191056592 | validation: 0.5044471273131064]
	TIME [epoch: 9.53 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6254912274716077		[learning rate: 0.0028034]
	Learning Rate: 0.00280339
	LOSS [training: 0.6254912274716077 | validation: 0.575010077792212]
	TIME [epoch: 9.53 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7145852684476984		[learning rate: 0.0027932]
	Learning Rate: 0.00279322
	LOSS [training: 0.7145852684476984 | validation: 0.491268286024733]
	TIME [epoch: 9.56 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6580409432806122		[learning rate: 0.0027831]
	Learning Rate: 0.00278308
	LOSS [training: 0.6580409432806122 | validation: 0.5227914825125757]
	TIME [epoch: 9.54 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.663812094674134		[learning rate: 0.002773]
	Learning Rate: 0.00277298
	LOSS [training: 0.663812094674134 | validation: 0.4877894533437679]
	TIME [epoch: 9.53 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6816182652536165		[learning rate: 0.0027629]
	Learning Rate: 0.00276292
	LOSS [training: 0.6816182652536165 | validation: 0.4896925120330986]
	TIME [epoch: 9.54 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6879967155593222		[learning rate: 0.0027529]
	Learning Rate: 0.00275289
	LOSS [training: 0.6879967155593222 | validation: 0.6222024590168584]
	TIME [epoch: 9.56 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6444426928883347		[learning rate: 0.0027429]
	Learning Rate: 0.0027429
	LOSS [training: 0.6444426928883347 | validation: 0.6320405111916573]
	TIME [epoch: 9.54 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6496775367253516		[learning rate: 0.0027329]
	Learning Rate: 0.00273295
	LOSS [training: 0.6496775367253516 | validation: 0.7376039289382615]
	TIME [epoch: 9.53 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6775204634086768		[learning rate: 0.002723]
	Learning Rate: 0.00272303
	LOSS [training: 0.6775204634086768 | validation: 0.6135688881547279]
	TIME [epoch: 9.55 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7059739631042985		[learning rate: 0.0027131]
	Learning Rate: 0.00271315
	LOSS [training: 0.7059739631042985 | validation: 0.9563405960514112]
	TIME [epoch: 9.53 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7507169822517392		[learning rate: 0.0027033]
	Learning Rate: 0.0027033
	LOSS [training: 0.7507169822517392 | validation: 0.5660479944512187]
	TIME [epoch: 9.53 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.664635183446045		[learning rate: 0.0026935]
	Learning Rate: 0.00269349
	LOSS [training: 0.664635183446045 | validation: 0.562065403725036]
	TIME [epoch: 9.55 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6481243949880696		[learning rate: 0.0026837]
	Learning Rate: 0.00268372
	LOSS [training: 0.6481243949880696 | validation: 0.5811902399183639]
	TIME [epoch: 9.54 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6818293099112707		[learning rate: 0.002674]
	Learning Rate: 0.00267398
	LOSS [training: 0.6818293099112707 | validation: 0.5111056956255005]
	TIME [epoch: 9.53 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6943856805603443		[learning rate: 0.0026643]
	Learning Rate: 0.00266427
	LOSS [training: 0.6943856805603443 | validation: 0.5326215908390999]
	TIME [epoch: 9.53 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6543305489417334		[learning rate: 0.0026546]
	Learning Rate: 0.00265461
	LOSS [training: 0.6543305489417334 | validation: 0.711099586057733]
	TIME [epoch: 9.56 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7285838850944898		[learning rate: 0.002645]
	Learning Rate: 0.00264497
	LOSS [training: 0.7285838850944898 | validation: 0.5059927731981344]
	TIME [epoch: 9.54 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6839551050916926		[learning rate: 0.0026354]
	Learning Rate: 0.00263537
	LOSS [training: 0.6839551050916926 | validation: 0.5265625958715547]
	TIME [epoch: 9.54 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7161509871025645		[learning rate: 0.0026258]
	Learning Rate: 0.00262581
	LOSS [training: 0.7161509871025645 | validation: 0.5014392969736056]
	TIME [epoch: 9.55 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6629180937619584		[learning rate: 0.0026163]
	Learning Rate: 0.00261628
	LOSS [training: 0.6629180937619584 | validation: 0.608793212677389]
	TIME [epoch: 9.54 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6361541246713618		[learning rate: 0.0026068]
	Learning Rate: 0.00260679
	LOSS [training: 0.6361541246713618 | validation: 0.4933611488586469]
	TIME [epoch: 9.53 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6685643993589803		[learning rate: 0.0025973]
	Learning Rate: 0.00259733
	LOSS [training: 0.6685643993589803 | validation: 0.5252628978772718]
	TIME [epoch: 9.53 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6502331183041694		[learning rate: 0.0025879]
	Learning Rate: 0.0025879
	LOSS [training: 0.6502331183041694 | validation: 0.5476418850222288]
	TIME [epoch: 9.56 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6436532297006392		[learning rate: 0.0025785]
	Learning Rate: 0.00257851
	LOSS [training: 0.6436532297006392 | validation: 0.5670604616670137]
	TIME [epoch: 9.54 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6366394244610569		[learning rate: 0.0025691]
	Learning Rate: 0.00256915
	LOSS [training: 0.6366394244610569 | validation: 0.54565333308242]
	TIME [epoch: 9.54 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6644006102703932		[learning rate: 0.0025598]
	Learning Rate: 0.00255983
	LOSS [training: 0.6644006102703932 | validation: 0.5254575559690114]
	TIME [epoch: 9.55 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6569924078316257		[learning rate: 0.0025505]
	Learning Rate: 0.00255054
	LOSS [training: 0.6569924078316257 | validation: 0.48734192541710725]
	TIME [epoch: 9.53 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6158181482428973		[learning rate: 0.0025413]
	Learning Rate: 0.00254128
	LOSS [training: 0.6158181482428973 | validation: 0.6266573313523237]
	TIME [epoch: 9.53 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.664181899365073		[learning rate: 0.0025321]
	Learning Rate: 0.00253206
	LOSS [training: 0.664181899365073 | validation: 0.7083564901752801]
	TIME [epoch: 9.53 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6786850228638578		[learning rate: 0.0025229]
	Learning Rate: 0.00252287
	LOSS [training: 0.6786850228638578 | validation: 0.5246530296645439]
	TIME [epoch: 9.55 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6092124278407258		[learning rate: 0.0025137]
	Learning Rate: 0.00251371
	LOSS [training: 0.6092124278407258 | validation: 0.6874202550115379]
	TIME [epoch: 9.53 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.658452353671795		[learning rate: 0.0025046]
	Learning Rate: 0.00250459
	LOSS [training: 0.658452353671795 | validation: 0.5233962209279449]
	TIME [epoch: 9.53 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6744606951983159		[learning rate: 0.0024955]
	Learning Rate: 0.0024955
	LOSS [training: 0.6744606951983159 | validation: 0.5765850098291637]
	TIME [epoch: 9.55 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7192906865032922		[learning rate: 0.0024864]
	Learning Rate: 0.00248645
	LOSS [training: 0.7192906865032922 | validation: 0.7854048906454204]
	TIME [epoch: 9.54 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7280062176289597		[learning rate: 0.0024774]
	Learning Rate: 0.00247742
	LOSS [training: 0.7280062176289597 | validation: 0.5425635453035833]
	TIME [epoch: 9.53 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6782896570048125		[learning rate: 0.0024684]
	Learning Rate: 0.00246843
	LOSS [training: 0.6782896570048125 | validation: 0.5178239664637073]
	TIME [epoch: 9.53 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6293254864177132		[learning rate: 0.0024595]
	Learning Rate: 0.00245947
	LOSS [training: 0.6293254864177132 | validation: 0.5380747148203129]
	TIME [epoch: 9.57 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6905936467146023		[learning rate: 0.0024505]
	Learning Rate: 0.00245055
	LOSS [training: 0.6905936467146023 | validation: 0.6665296607094845]
	TIME [epoch: 9.54 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6394318913659565		[learning rate: 0.0024417]
	Learning Rate: 0.00244165
	LOSS [training: 0.6394318913659565 | validation: 0.5296645693594423]
	TIME [epoch: 9.54 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6539183386816326		[learning rate: 0.0024328]
	Learning Rate: 0.00243279
	LOSS [training: 0.6539183386816326 | validation: 0.6500562730019088]
	TIME [epoch: 9.55 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6969228665741258		[learning rate: 0.002424]
	Learning Rate: 0.00242396
	LOSS [training: 0.6969228665741258 | validation: 0.5364434885838467]
	TIME [epoch: 9.54 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6192125294651464		[learning rate: 0.0024152]
	Learning Rate: 0.00241517
	LOSS [training: 0.6192125294651464 | validation: 0.5450786134170431]
	TIME [epoch: 9.53 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6903448283899658		[learning rate: 0.0024064]
	Learning Rate: 0.0024064
	LOSS [training: 0.6903448283899658 | validation: 0.6488763483001393]
	TIME [epoch: 9.53 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7419191587932714		[learning rate: 0.0023977]
	Learning Rate: 0.00239767
	LOSS [training: 0.7419191587932714 | validation: 0.8190133270078178]
	TIME [epoch: 9.56 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7205163558786728		[learning rate: 0.002389]
	Learning Rate: 0.00238897
	LOSS [training: 0.7205163558786728 | validation: 0.7112166128064148]
	TIME [epoch: 9.53 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7052714087744363		[learning rate: 0.0023803]
	Learning Rate: 0.0023803
	LOSS [training: 0.7052714087744363 | validation: 0.4956951341414906]
	TIME [epoch: 9.54 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6563316410727644		[learning rate: 0.0023717]
	Learning Rate: 0.00237166
	LOSS [training: 0.6563316410727644 | validation: 0.5489729841651101]
	TIME [epoch: 9.55 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6590254505092044		[learning rate: 0.0023631]
	Learning Rate: 0.00236305
	LOSS [training: 0.6590254505092044 | validation: 0.4638990281116718]
	TIME [epoch: 9.53 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.80326708129721		[learning rate: 0.0023545]
	Learning Rate: 0.00235448
	LOSS [training: 0.80326708129721 | validation: 0.4513760056536211]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_498.pth
	Model improved!!!
EPOCH 499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9268079534776387		[learning rate: 0.0023459]
	Learning Rate: 0.00234593
	LOSS [training: 0.9268079534776387 | validation: 0.8370587608641071]
	TIME [epoch: 9.54 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7177018188094844		[learning rate: 0.0023374]
	Learning Rate: 0.00233742
	LOSS [training: 0.7177018188094844 | validation: 0.5565217390963165]
	TIME [epoch: 9.55 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6449922954442455		[learning rate: 0.0023289]
	Learning Rate: 0.00232894
	LOSS [training: 0.6449922954442455 | validation: 0.5919345817967444]
	TIME [epoch: 9.53 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6465436503757541		[learning rate: 0.0023205]
	Learning Rate: 0.00232049
	LOSS [training: 0.6465436503757541 | validation: 0.5109223199945581]
	TIME [epoch: 9.53 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6459616397379631		[learning rate: 0.0023121]
	Learning Rate: 0.00231206
	LOSS [training: 0.6459616397379631 | validation: 0.559978208522259]
	TIME [epoch: 9.55 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6513042270319577		[learning rate: 0.0023037]
	Learning Rate: 0.00230367
	LOSS [training: 0.6513042270319577 | validation: 0.6254473575406135]
	TIME [epoch: 9.53 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6407849259535627		[learning rate: 0.0022953]
	Learning Rate: 0.00229531
	LOSS [training: 0.6407849259535627 | validation: 0.4669539313692572]
	TIME [epoch: 9.52 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7415884796406033		[learning rate: 0.002287]
	Learning Rate: 0.00228698
	LOSS [training: 0.7415884796406033 | validation: 0.5759675466398474]
	TIME [epoch: 9.53 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6762373114401452		[learning rate: 0.0022787]
	Learning Rate: 0.00227868
	LOSS [training: 0.6762373114401452 | validation: 0.6042639314785183]
	TIME [epoch: 9.54 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6787362832445394		[learning rate: 0.0022704]
	Learning Rate: 0.00227042
	LOSS [training: 0.6787362832445394 | validation: 0.5775507595018436]
	TIME [epoch: 9.52 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6471901508544549		[learning rate: 0.0022622]
	Learning Rate: 0.00226218
	LOSS [training: 0.6471901508544549 | validation: 0.5247785845246884]
	TIME [epoch: 9.52 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6386000932863138		[learning rate: 0.002254]
	Learning Rate: 0.00225397
	LOSS [training: 0.6386000932863138 | validation: 0.5095948437333193]
	TIME [epoch: 9.55 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6152073734964204		[learning rate: 0.0022458]
	Learning Rate: 0.00224579
	LOSS [training: 0.6152073734964204 | validation: 0.5335306801476479]
	TIME [epoch: 9.52 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6572781610151677		[learning rate: 0.0022376]
	Learning Rate: 0.00223764
	LOSS [training: 0.6572781610151677 | validation: 0.7948996361514676]
	TIME [epoch: 9.53 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6811152841592861		[learning rate: 0.0022295]
	Learning Rate: 0.00222952
	LOSS [training: 0.6811152841592861 | validation: 0.505546506583215]
	TIME [epoch: 9.54 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7561283656691492		[learning rate: 0.0022214]
	Learning Rate: 0.00222142
	LOSS [training: 0.7561283656691492 | validation: 0.5093059726916385]
	TIME [epoch: 9.55 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.612194025312504		[learning rate: 0.0022134]
	Learning Rate: 0.00221336
	LOSS [training: 0.612194025312504 | validation: 0.49598723343558904]
	TIME [epoch: 9.52 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.616336290199809		[learning rate: 0.0022053]
	Learning Rate: 0.00220533
	LOSS [training: 0.616336290199809 | validation: 0.4823764873176882]
	TIME [epoch: 9.53 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.666558660101199		[learning rate: 0.0021973]
	Learning Rate: 0.00219733
	LOSS [training: 0.666558660101199 | validation: 0.424794788067806]
	TIME [epoch: 9.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_517.pth
	Model improved!!!
EPOCH 518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6534700485523246		[learning rate: 0.0021894]
	Learning Rate: 0.00218935
	LOSS [training: 0.6534700485523246 | validation: 0.45591405383806205]
	TIME [epoch: 9.53 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6796100858808043		[learning rate: 0.0021814]
	Learning Rate: 0.00218141
	LOSS [training: 0.6796100858808043 | validation: 0.5065078382927172]
	TIME [epoch: 9.53 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6673578360356999		[learning rate: 0.0021735]
	Learning Rate: 0.00217349
	LOSS [training: 0.6673578360356999 | validation: 0.5166271418099846]
	TIME [epoch: 9.54 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6271374783154988		[learning rate: 0.0021656]
	Learning Rate: 0.0021656
	LOSS [training: 0.6271374783154988 | validation: 0.6285127789775775]
	TIME [epoch: 9.54 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6246128405107063		[learning rate: 0.0021577]
	Learning Rate: 0.00215774
	LOSS [training: 0.6246128405107063 | validation: 0.5674663729828872]
	TIME [epoch: 9.53 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6308368185537873		[learning rate: 0.0021499]
	Learning Rate: 0.00214991
	LOSS [training: 0.6308368185537873 | validation: 0.5188323614742137]
	TIME [epoch: 9.53 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6513633237191596		[learning rate: 0.0021421]
	Learning Rate: 0.00214211
	LOSS [training: 0.6513633237191596 | validation: 0.5471437465923045]
	TIME [epoch: 9.55 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6435680354860166		[learning rate: 0.0021343]
	Learning Rate: 0.00213434
	LOSS [training: 0.6435680354860166 | validation: 0.5230160941848694]
	TIME [epoch: 9.53 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6163059553914507		[learning rate: 0.0021266]
	Learning Rate: 0.00212659
	LOSS [training: 0.6163059553914507 | validation: 0.6459768288641532]
	TIME [epoch: 9.53 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6348332407970902		[learning rate: 0.0021189]
	Learning Rate: 0.00211887
	LOSS [training: 0.6348332407970902 | validation: 0.7469362265387289]
	TIME [epoch: 9.54 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6143804833360733		[learning rate: 0.0021112]
	Learning Rate: 0.00211119
	LOSS [training: 0.6143804833360733 | validation: 0.5935716276587453]
	TIME [epoch: 9.53 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6449177300985918		[learning rate: 0.0021035]
	Learning Rate: 0.00210352
	LOSS [training: 0.6449177300985918 | validation: 0.5413065237811086]
	TIME [epoch: 9.53 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5927641813373072		[learning rate: 0.0020959]
	Learning Rate: 0.00209589
	LOSS [training: 0.5927641813373072 | validation: 0.49953569210619614]
	TIME [epoch: 9.53 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6274856957536084		[learning rate: 0.0020883]
	Learning Rate: 0.00208828
	LOSS [training: 0.6274856957536084 | validation: 0.5866580245497034]
	TIME [epoch: 9.55 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6645223828078399		[learning rate: 0.0020807]
	Learning Rate: 0.00208071
	LOSS [training: 0.6645223828078399 | validation: 0.47118551418168175]
	TIME [epoch: 9.53 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6314464425707229		[learning rate: 0.0020732]
	Learning Rate: 0.00207315
	LOSS [training: 0.6314464425707229 | validation: 0.4924457612539915]
	TIME [epoch: 9.52 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6857000580580965		[learning rate: 0.0020656]
	Learning Rate: 0.00206563
	LOSS [training: 0.6857000580580965 | validation: 0.5685135589172111]
	TIME [epoch: 9.54 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6298408518184686		[learning rate: 0.0020581]
	Learning Rate: 0.00205813
	LOSS [training: 0.6298408518184686 | validation: 0.6111309186930171]
	TIME [epoch: 9.53 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6265405537389391		[learning rate: 0.0020507]
	Learning Rate: 0.00205067
	LOSS [training: 0.6265405537389391 | validation: 0.46142516435707137]
	TIME [epoch: 9.52 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.61135576770293		[learning rate: 0.0020432]
	Learning Rate: 0.00204322
	LOSS [training: 0.61135576770293 | validation: 0.6247050175924668]
	TIME [epoch: 9.52 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6290630300375114		[learning rate: 0.0020358]
	Learning Rate: 0.00203581
	LOSS [training: 0.6290630300375114 | validation: 0.532886089649377]
	TIME [epoch: 9.55 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6234211982807331		[learning rate: 0.0020284]
	Learning Rate: 0.00202842
	LOSS [training: 0.6234211982807331 | validation: 0.5718174483081717]
	TIME [epoch: 9.53 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6729434014858423		[learning rate: 0.0020211]
	Learning Rate: 0.00202106
	LOSS [training: 0.6729434014858423 | validation: 0.45817576728257836]
	TIME [epoch: 9.53 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6266978401214072		[learning rate: 0.0020137]
	Learning Rate: 0.00201372
	LOSS [training: 0.6266978401214072 | validation: 0.47904663658196567]
	TIME [epoch: 9.54 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6151884022258346		[learning rate: 0.0020064]
	Learning Rate: 0.00200642
	LOSS [training: 0.6151884022258346 | validation: 0.5782274281511113]
	TIME [epoch: 9.54 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6697482855383303		[learning rate: 0.0019991]
	Learning Rate: 0.00199913
	LOSS [training: 0.6697482855383303 | validation: 0.4934649721630311]
	TIME [epoch: 9.52 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.610276138034646		[learning rate: 0.0019919]
	Learning Rate: 0.00199188
	LOSS [training: 0.610276138034646 | validation: 0.4804604306154888]
	TIME [epoch: 9.53 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6280159778556601		[learning rate: 0.0019847]
	Learning Rate: 0.00198465
	LOSS [training: 0.6280159778556601 | validation: 0.4658438369490662]
	TIME [epoch: 9.55 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6369116319866388		[learning rate: 0.0019774]
	Learning Rate: 0.00197745
	LOSS [training: 0.6369116319866388 | validation: 0.46711408077678657]
	TIME [epoch: 9.53 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6317403396985835		[learning rate: 0.0019703]
	Learning Rate: 0.00197027
	LOSS [training: 0.6317403396985835 | validation: 0.4801067062592705]
	TIME [epoch: 9.52 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6244703796762979		[learning rate: 0.0019631]
	Learning Rate: 0.00196312
	LOSS [training: 0.6244703796762979 | validation: 0.4942640992020025]
	TIME [epoch: 9.54 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6334777237916767		[learning rate: 0.001956]
	Learning Rate: 0.001956
	LOSS [training: 0.6334777237916767 | validation: 0.5010176176550502]
	TIME [epoch: 9.53 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6162163575257942		[learning rate: 0.0019489]
	Learning Rate: 0.0019489
	LOSS [training: 0.6162163575257942 | validation: 0.5408732651928809]
	TIME [epoch: 9.52 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6394702126108929		[learning rate: 0.0019418]
	Learning Rate: 0.00194183
	LOSS [training: 0.6394702126108929 | validation: 0.4513907394250262]
	TIME [epoch: 9.53 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6023542204399552		[learning rate: 0.0019348]
	Learning Rate: 0.00193478
	LOSS [training: 0.6023542204399552 | validation: 0.49021423969766076]
	TIME [epoch: 9.55 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6539674108902338		[learning rate: 0.0019278]
	Learning Rate: 0.00192776
	LOSS [training: 0.6539674108902338 | validation: 0.5197897359701611]
	TIME [epoch: 9.53 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5985221688273246		[learning rate: 0.0019208]
	Learning Rate: 0.00192076
	LOSS [training: 0.5985221688273246 | validation: 0.44418557823392346]
	TIME [epoch: 9.52 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6400337460285577		[learning rate: 0.0019138]
	Learning Rate: 0.00191379
	LOSS [training: 0.6400337460285577 | validation: 0.4782565190399115]
	TIME [epoch: 9.55 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6484819839906348		[learning rate: 0.0019068]
	Learning Rate: 0.00190685
	LOSS [training: 0.6484819839906348 | validation: 0.6170237563752382]
	TIME [epoch: 9.53 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6123064694754211		[learning rate: 0.0018999]
	Learning Rate: 0.00189993
	LOSS [training: 0.6123064694754211 | validation: 0.5185606613555531]
	TIME [epoch: 9.53 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6023435281376506		[learning rate: 0.001893]
	Learning Rate: 0.00189303
	LOSS [training: 0.6023435281376506 | validation: 0.5797897859881253]
	TIME [epoch: 9.53 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6147650758416447		[learning rate: 0.0018862]
	Learning Rate: 0.00188616
	LOSS [training: 0.6147650758416447 | validation: 0.48117954870820323]
	TIME [epoch: 9.54 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.640159900361697		[learning rate: 0.0018793]
	Learning Rate: 0.00187932
	LOSS [training: 0.640159900361697 | validation: 0.60239387672746]
	TIME [epoch: 9.53 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6241699335852908		[learning rate: 0.0018725]
	Learning Rate: 0.0018725
	LOSS [training: 0.6241699335852908 | validation: 0.4472257212431001]
	TIME [epoch: 9.53 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6073679430286207		[learning rate: 0.0018657]
	Learning Rate: 0.0018657
	LOSS [training: 0.6073679430286207 | validation: 0.5455873214683656]
	TIME [epoch: 9.55 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5968234432012912		[learning rate: 0.0018589]
	Learning Rate: 0.00185893
	LOSS [training: 0.5968234432012912 | validation: 0.4868619566383056]
	TIME [epoch: 9.52 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6133035312681848		[learning rate: 0.0018522]
	Learning Rate: 0.00185218
	LOSS [training: 0.6133035312681848 | validation: 0.4725422085804206]
	TIME [epoch: 9.53 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6200626607264542		[learning rate: 0.0018455]
	Learning Rate: 0.00184546
	LOSS [training: 0.6200626607264542 | validation: 0.5443046992160545]
	TIME [epoch: 9.53 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6123306103825512		[learning rate: 0.0018388]
	Learning Rate: 0.00183877
	LOSS [training: 0.6123306103825512 | validation: 0.46211941519408173]
	TIME [epoch: 9.54 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6179577946128438		[learning rate: 0.0018321]
	Learning Rate: 0.00183209
	LOSS [training: 0.6179577946128438 | validation: 0.6181829631351745]
	TIME [epoch: 9.53 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5988877561637581		[learning rate: 0.0018254]
	Learning Rate: 0.00182544
	LOSS [training: 0.5988877561637581 | validation: 0.5955191142567194]
	TIME [epoch: 9.52 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6267324056759771		[learning rate: 0.0018188]
	Learning Rate: 0.00181882
	LOSS [training: 0.6267324056759771 | validation: 0.4717782501440651]
	TIME [epoch: 9.55 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.582014397447004		[learning rate: 0.0018122]
	Learning Rate: 0.00181222
	LOSS [training: 0.582014397447004 | validation: 0.5688388466856121]
	TIME [epoch: 9.52 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6039800834327039		[learning rate: 0.0018056]
	Learning Rate: 0.00180564
	LOSS [training: 0.6039800834327039 | validation: 0.5244039116005766]
	TIME [epoch: 9.52 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6196977595565694		[learning rate: 0.0017991]
	Learning Rate: 0.00179909
	LOSS [training: 0.6196977595565694 | validation: 0.47903926024442156]
	TIME [epoch: 9.53 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6339236531043629		[learning rate: 0.0017926]
	Learning Rate: 0.00179256
	LOSS [training: 0.6339236531043629 | validation: 0.5695051111694451]
	TIME [epoch: 9.54 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6352825189120556		[learning rate: 0.0017861]
	Learning Rate: 0.00178605
	LOSS [training: 0.6352825189120556 | validation: 0.5577990073309386]
	TIME [epoch: 9.53 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6330424591711192		[learning rate: 0.0017796]
	Learning Rate: 0.00177957
	LOSS [training: 0.6330424591711192 | validation: 0.48719728506936205]
	TIME [epoch: 9.52 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6225271946359692		[learning rate: 0.0017731]
	Learning Rate: 0.00177311
	LOSS [training: 0.6225271946359692 | validation: 0.476965284453558]
	TIME [epoch: 9.55 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6067070437926916		[learning rate: 0.0017667]
	Learning Rate: 0.00176668
	LOSS [training: 0.6067070437926916 | validation: 0.4997408334484797]
	TIME [epoch: 9.52 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6610463097223589		[learning rate: 0.0017603]
	Learning Rate: 0.00176027
	LOSS [training: 0.6610463097223589 | validation: 0.48147487295129465]
	TIME [epoch: 9.53 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6012890626206016		[learning rate: 0.0017539]
	Learning Rate: 0.00175388
	LOSS [training: 0.6012890626206016 | validation: 0.43154994275117375]
	TIME [epoch: 9.53 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5897766338036854		[learning rate: 0.0017475]
	Learning Rate: 0.00174752
	LOSS [training: 0.5897766338036854 | validation: 0.47692151319581877]
	TIME [epoch: 9.55 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6477972770178193		[learning rate: 0.0017412]
	Learning Rate: 0.00174117
	LOSS [training: 0.6477972770178193 | validation: 0.6664383968916318]
	TIME [epoch: 9.52 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6278599336214283		[learning rate: 0.0017349]
	Learning Rate: 0.00173486
	LOSS [training: 0.6278599336214283 | validation: 0.5461095315411768]
	TIME [epoch: 9.53 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6374317957104879		[learning rate: 0.0017286]
	Learning Rate: 0.00172856
	LOSS [training: 0.6374317957104879 | validation: 0.4883420738210801]
	TIME [epoch: 9.54 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6164279777272232		[learning rate: 0.0017223]
	Learning Rate: 0.00172229
	LOSS [training: 0.6164279777272232 | validation: 0.49105929603115395]
	TIME [epoch: 9.52 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.624468819487469		[learning rate: 0.001716]
	Learning Rate: 0.00171604
	LOSS [training: 0.624468819487469 | validation: 0.505524539426349]
	TIME [epoch: 9.53 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6635090914705495		[learning rate: 0.0017098]
	Learning Rate: 0.00170981
	LOSS [training: 0.6635090914705495 | validation: 0.49791198833439665]
	TIME [epoch: 9.54 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.614869460828855		[learning rate: 0.0017036]
	Learning Rate: 0.0017036
	LOSS [training: 0.614869460828855 | validation: 0.514460124510942]
	TIME [epoch: 9.53 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5891839732252512		[learning rate: 0.0016974]
	Learning Rate: 0.00169742
	LOSS [training: 0.5891839732252512 | validation: 0.5346092593764642]
	TIME [epoch: 9.52 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6168512145735503		[learning rate: 0.0016913]
	Learning Rate: 0.00169126
	LOSS [training: 0.6168512145735503 | validation: 0.49609065375841965]
	TIME [epoch: 9.52 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6445810776165951		[learning rate: 0.0016851]
	Learning Rate: 0.00168512
	LOSS [training: 0.6445810776165951 | validation: 0.5546340425997712]
	TIME [epoch: 9.55 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5988553796531824		[learning rate: 0.001679]
	Learning Rate: 0.00167901
	LOSS [training: 0.5988553796531824 | validation: 0.5084440517165247]
	TIME [epoch: 9.53 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5813030644119355		[learning rate: 0.0016729]
	Learning Rate: 0.00167291
	LOSS [training: 0.5813030644119355 | validation: 0.5431879491231533]
	TIME [epoch: 9.53 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6411281125614872		[learning rate: 0.0016668]
	Learning Rate: 0.00166684
	LOSS [training: 0.6411281125614872 | validation: 0.44545633763785725]
	TIME [epoch: 9.54 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6069043654780779		[learning rate: 0.0016608]
	Learning Rate: 0.00166079
	LOSS [training: 0.6069043654780779 | validation: 0.4579775044803303]
	TIME [epoch: 9.53 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6020901678688		[learning rate: 0.0016548]
	Learning Rate: 0.00165477
	LOSS [training: 0.6020901678688 | validation: 0.5323039305590227]
	TIME [epoch: 9.52 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5936806054787512		[learning rate: 0.0016488]
	Learning Rate: 0.00164876
	LOSS [training: 0.5936806054787512 | validation: 0.4750920484168831]
	TIME [epoch: 9.53 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5898588806558818		[learning rate: 0.0016428]
	Learning Rate: 0.00164278
	LOSS [training: 0.5898588806558818 | validation: 0.5169091459385957]
	TIME [epoch: 9.54 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6224738899948036		[learning rate: 0.0016368]
	Learning Rate: 0.00163682
	LOSS [training: 0.6224738899948036 | validation: 0.48733855195979525]
	TIME [epoch: 9.52 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6231843144476361		[learning rate: 0.0016309]
	Learning Rate: 0.00163088
	LOSS [training: 0.6231843144476361 | validation: 0.5253962780340063]
	TIME [epoch: 9.53 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5962142340139428		[learning rate: 0.001625]
	Learning Rate: 0.00162496
	LOSS [training: 0.5962142340139428 | validation: 0.6076292006573071]
	TIME [epoch: 9.54 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6170861885597143		[learning rate: 0.0016191]
	Learning Rate: 0.00161906
	LOSS [training: 0.6170861885597143 | validation: 0.5404743165528125]
	TIME [epoch: 9.53 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6271586486968534		[learning rate: 0.0016132]
	Learning Rate: 0.00161319
	LOSS [training: 0.6271586486968534 | validation: 0.5285443188878052]
	TIME [epoch: 9.52 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6031575267791296		[learning rate: 0.0016073]
	Learning Rate: 0.00160733
	LOSS [training: 0.6031575267791296 | validation: 0.4367771675750827]
	TIME [epoch: 9.53 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.585087957095707		[learning rate: 0.0016015]
	Learning Rate: 0.0016015
	LOSS [training: 0.585087957095707 | validation: 0.5260338908535329]
	TIME [epoch: 9.54 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6079125436778279		[learning rate: 0.0015957]
	Learning Rate: 0.00159569
	LOSS [training: 0.6079125436778279 | validation: 0.46865901388309605]
	TIME [epoch: 9.53 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5974434755417259		[learning rate: 0.0015899]
	Learning Rate: 0.00158989
	LOSS [training: 0.5974434755417259 | validation: 0.44337490564438997]
	TIME [epoch: 9.52 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.615532096999991		[learning rate: 0.0015841]
	Learning Rate: 0.00158413
	LOSS [training: 0.615532096999991 | validation: 0.602226939175985]
	TIME [epoch: 9.54 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6429800980598046		[learning rate: 0.0015784]
	Learning Rate: 0.00157838
	LOSS [training: 0.6429800980598046 | validation: 0.5230492137349649]
	TIME [epoch: 9.52 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6338260660687205		[learning rate: 0.0015726]
	Learning Rate: 0.00157265
	LOSS [training: 0.6338260660687205 | validation: 0.4962961650907754]
	TIME [epoch: 9.52 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5956711477742347		[learning rate: 0.0015669]
	Learning Rate: 0.00156694
	LOSS [training: 0.5956711477742347 | validation: 0.655323852277833]
	TIME [epoch: 9.52 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6480261532788163		[learning rate: 0.0015613]
	Learning Rate: 0.00156125
	LOSS [training: 0.6480261532788163 | validation: 0.44200584903293433]
	TIME [epoch: 9.54 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6185685390002588		[learning rate: 0.0015556]
	Learning Rate: 0.00155559
	LOSS [training: 0.6185685390002588 | validation: 0.464871348373403]
	TIME [epoch: 9.53 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5669911574660518		[learning rate: 0.0015499]
	Learning Rate: 0.00154994
	LOSS [training: 0.5669911574660518 | validation: 0.4289662882570305]
	TIME [epoch: 9.52 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5820919491363249		[learning rate: 0.0015443]
	Learning Rate: 0.00154432
	LOSS [training: 0.5820919491363249 | validation: 0.4834564406401525]
	TIME [epoch: 9.54 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6242334378692878		[learning rate: 0.0015387]
	Learning Rate: 0.00153871
	LOSS [training: 0.6242334378692878 | validation: 0.6635970769833562]
	TIME [epoch: 9.52 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6684603098962055		[learning rate: 0.0015331]
	Learning Rate: 0.00153313
	LOSS [training: 0.6684603098962055 | validation: 0.4743209181825591]
	TIME [epoch: 9.52 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6163368509123692		[learning rate: 0.0015276]
	Learning Rate: 0.00152757
	LOSS [training: 0.6163368509123692 | validation: 0.47989684581541364]
	TIME [epoch: 9.52 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6741965557040436		[learning rate: 0.001522]
	Learning Rate: 0.00152202
	LOSS [training: 0.6741965557040436 | validation: 0.5592800761268305]
	TIME [epoch: 9.55 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6220785118193957		[learning rate: 0.0015165]
	Learning Rate: 0.0015165
	LOSS [training: 0.6220785118193957 | validation: 0.47331574245427294]
	TIME [epoch: 9.52 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5706711746279701		[learning rate: 0.001511]
	Learning Rate: 0.001511
	LOSS [training: 0.5706711746279701 | validation: 0.4938119105237573]
	TIME [epoch: 9.52 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6156540744843959		[learning rate: 0.0015055]
	Learning Rate: 0.00150551
	LOSS [training: 0.6156540744843959 | validation: 0.632831631685271]
	TIME [epoch: 9.53 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6060547807101677		[learning rate: 0.0015]
	Learning Rate: 0.00150005
	LOSS [training: 0.6060547807101677 | validation: 0.4499740066114573]
	TIME [epoch: 9.52 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5920205430932005		[learning rate: 0.0014946]
	Learning Rate: 0.0014946
	LOSS [training: 0.5920205430932005 | validation: 0.5093146627490992]
	TIME [epoch: 9.52 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5670406824140848		[learning rate: 0.0014892]
	Learning Rate: 0.00148918
	LOSS [training: 0.5670406824140848 | validation: 0.4970880859615999]
	TIME [epoch: 9.52 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5771466723242843		[learning rate: 0.0014838]
	Learning Rate: 0.00148378
	LOSS [training: 0.5771466723242843 | validation: 0.4941657478920928]
	TIME [epoch: 9.55 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5998626392675237		[learning rate: 0.0014784]
	Learning Rate: 0.00147839
	LOSS [training: 0.5998626392675237 | validation: 0.5398389523435491]
	TIME [epoch: 9.51 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6024617716894884		[learning rate: 0.001473]
	Learning Rate: 0.00147303
	LOSS [training: 0.6024617716894884 | validation: 0.5546877982031708]
	TIME [epoch: 9.52 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6068963500939594		[learning rate: 0.0014677]
	Learning Rate: 0.00146768
	LOSS [training: 0.6068963500939594 | validation: 0.45162273575432355]
	TIME [epoch: 9.54 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6125426548741951		[learning rate: 0.0014624]
	Learning Rate: 0.00146235
	LOSS [training: 0.6125426548741951 | validation: 0.4759195027603805]
	TIME [epoch: 9.53 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6051609678868567		[learning rate: 0.001457]
	Learning Rate: 0.00145705
	LOSS [training: 0.6051609678868567 | validation: 0.44560961218186734]
	TIME [epoch: 9.52 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5932646062666582		[learning rate: 0.0014518]
	Learning Rate: 0.00145176
	LOSS [training: 0.5932646062666582 | validation: 0.518273943462881]
	TIME [epoch: 9.53 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6094731911975816		[learning rate: 0.0014465]
	Learning Rate: 0.00144649
	LOSS [training: 0.6094731911975816 | validation: 0.5089919069485913]
	TIME [epoch: 9.54 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6443388202931268		[learning rate: 0.0014412]
	Learning Rate: 0.00144124
	LOSS [training: 0.6443388202931268 | validation: 0.529274228499643]
	TIME [epoch: 9.52 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5973758350464682		[learning rate: 0.001436]
	Learning Rate: 0.00143601
	LOSS [training: 0.5973758350464682 | validation: 0.4986720516347756]
	TIME [epoch: 9.52 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.585229248130569		[learning rate: 0.0014308]
	Learning Rate: 0.0014308
	LOSS [training: 0.585229248130569 | validation: 0.4993191716757214]
	TIME [epoch: 9.54 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6065575388509791		[learning rate: 0.0014256]
	Learning Rate: 0.00142561
	LOSS [training: 0.6065575388509791 | validation: 0.6801758529755747]
	TIME [epoch: 9.52 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6084757187810953		[learning rate: 0.0014204]
	Learning Rate: 0.00142043
	LOSS [training: 0.6084757187810953 | validation: 0.4696693166839357]
	TIME [epoch: 9.52 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5840103491506423		[learning rate: 0.0014153]
	Learning Rate: 0.00141528
	LOSS [training: 0.5840103491506423 | validation: 0.5777900086728518]
	TIME [epoch: 9.52 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5968546662316012		[learning rate: 0.0014101]
	Learning Rate: 0.00141014
	LOSS [training: 0.5968546662316012 | validation: 0.5273079492467333]
	TIME [epoch: 9.54 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5959547949746404		[learning rate: 0.001405]
	Learning Rate: 0.00140503
	LOSS [training: 0.5959547949746404 | validation: 0.49907377474251896]
	TIME [epoch: 9.52 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5998165974543865		[learning rate: 0.0013999]
	Learning Rate: 0.00139993
	LOSS [training: 0.5998165974543865 | validation: 0.4951928798414294]
	TIME [epoch: 9.52 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5975056829950021		[learning rate: 0.0013948]
	Learning Rate: 0.00139485
	LOSS [training: 0.5975056829950021 | validation: 0.4714612011278442]
	TIME [epoch: 9.53 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6231913883522119		[learning rate: 0.0013898]
	Learning Rate: 0.00138978
	LOSS [training: 0.6231913883522119 | validation: 0.4556136539588617]
	TIME [epoch: 9.52 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6161056103493833		[learning rate: 0.0013847]
	Learning Rate: 0.00138474
	LOSS [training: 0.6161056103493833 | validation: 0.5512105200065948]
	TIME [epoch: 9.52 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5983407858125018		[learning rate: 0.0013797]
	Learning Rate: 0.00137972
	LOSS [training: 0.5983407858125018 | validation: 0.45960728121256095]
	TIME [epoch: 9.52 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5790332603350541		[learning rate: 0.0013747]
	Learning Rate: 0.00137471
	LOSS [training: 0.5790332603350541 | validation: 0.45781136632193364]
	TIME [epoch: 9.54 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5918797461105105		[learning rate: 0.0013697]
	Learning Rate: 0.00136972
	LOSS [training: 0.5918797461105105 | validation: 0.4769642082430704]
	TIME [epoch: 9.52 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6477431691097589		[learning rate: 0.0013647]
	Learning Rate: 0.00136475
	LOSS [training: 0.6477431691097589 | validation: 0.44197414789129114]
	TIME [epoch: 9.52 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6679418823386871		[learning rate: 0.0013598]
	Learning Rate: 0.0013598
	LOSS [training: 0.6679418823386871 | validation: 0.6052404920857611]
	TIME [epoch: 9.54 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5877350673637163		[learning rate: 0.0013549]
	Learning Rate: 0.00135486
	LOSS [training: 0.5877350673637163 | validation: 0.4472135438283815]
	TIME [epoch: 9.52 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5992637503694336		[learning rate: 0.0013499]
	Learning Rate: 0.00134994
	LOSS [training: 0.5992637503694336 | validation: 0.46301010654809965]
	TIME [epoch: 9.52 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5718080303398051		[learning rate: 0.001345]
	Learning Rate: 0.00134505
	LOSS [training: 0.5718080303398051 | validation: 0.4382124954524887]
	TIME [epoch: 9.53 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5697977573910938		[learning rate: 0.0013402]
	Learning Rate: 0.00134016
	LOSS [training: 0.5697977573910938 | validation: 0.5240263588893527]
	TIME [epoch: 9.53 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6039507500222643		[learning rate: 0.0013353]
	Learning Rate: 0.0013353
	LOSS [training: 0.6039507500222643 | validation: 0.5455821599209502]
	TIME [epoch: 9.52 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6134790306497161		[learning rate: 0.0013305]
	Learning Rate: 0.00133045
	LOSS [training: 0.6134790306497161 | validation: 0.6254993092355666]
	TIME [epoch: 9.52 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6500771817704772		[learning rate: 0.0013256]
	Learning Rate: 0.00132563
	LOSS [training: 0.6500771817704772 | validation: 0.5773696960372916]
	TIME [epoch: 9.54 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.623342124443225		[learning rate: 0.0013208]
	Learning Rate: 0.00132082
	LOSS [training: 0.623342124443225 | validation: 0.5332655314563014]
	TIME [epoch: 9.52 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6209370836906527		[learning rate: 0.001316]
	Learning Rate: 0.00131602
	LOSS [training: 0.6209370836906527 | validation: 0.6363628940802322]
	TIME [epoch: 9.52 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6247874153679069		[learning rate: 0.0013112]
	Learning Rate: 0.00131125
	LOSS [training: 0.6247874153679069 | validation: 0.5452123192071249]
	TIME [epoch: 9.53 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5882448484374325		[learning rate: 0.0013065]
	Learning Rate: 0.00130649
	LOSS [training: 0.5882448484374325 | validation: 0.5166073576073693]
	TIME [epoch: 9.53 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6352009839337939		[learning rate: 0.0013017]
	Learning Rate: 0.00130175
	LOSS [training: 0.6352009839337939 | validation: 0.5556015619689604]
	TIME [epoch: 9.53 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6091649328503906		[learning rate: 0.001297]
	Learning Rate: 0.00129702
	LOSS [training: 0.6091649328503906 | validation: 0.4638605387499657]
	TIME [epoch: 9.52 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6631645335672289		[learning rate: 0.0012923]
	Learning Rate: 0.00129232
	LOSS [training: 0.6631645335672289 | validation: 0.493444467442194]
	TIME [epoch: 9.54 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5949826980018529		[learning rate: 0.0012876]
	Learning Rate: 0.00128763
	LOSS [training: 0.5949826980018529 | validation: 0.489351331993729]
	TIME [epoch: 9.52 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6031837975422285		[learning rate: 0.001283]
	Learning Rate: 0.00128295
	LOSS [training: 0.6031837975422285 | validation: 0.536557831383645]
	TIME [epoch: 9.52 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6028909489104418		[learning rate: 0.0012783]
	Learning Rate: 0.0012783
	LOSS [training: 0.6028909489104418 | validation: 0.4905171495779648]
	TIME [epoch: 9.53 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5749385179192228		[learning rate: 0.0012737]
	Learning Rate: 0.00127366
	LOSS [training: 0.5749385179192228 | validation: 0.4636197106599229]
	TIME [epoch: 9.53 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6183598957792993		[learning rate: 0.001269]
	Learning Rate: 0.00126904
	LOSS [training: 0.6183598957792993 | validation: 0.5032655937731724]
	TIME [epoch: 9.52 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5918875812503416		[learning rate: 0.0012644]
	Learning Rate: 0.00126443
	LOSS [training: 0.5918875812503416 | validation: 0.464786085684657]
	TIME [epoch: 9.52 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5943038851119542		[learning rate: 0.0012598]
	Learning Rate: 0.00125984
	LOSS [training: 0.5943038851119542 | validation: 0.5592907709889537]
	TIME [epoch: 9.54 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5892349660713208		[learning rate: 0.0012553]
	Learning Rate: 0.00125527
	LOSS [training: 0.5892349660713208 | validation: 0.5046680695159413]
	TIME [epoch: 9.52 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.608380256650791		[learning rate: 0.0012507]
	Learning Rate: 0.00125071
	LOSS [training: 0.608380256650791 | validation: 0.46062790998803094]
	TIME [epoch: 9.52 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.586808986681206		[learning rate: 0.0012462]
	Learning Rate: 0.00124617
	LOSS [training: 0.586808986681206 | validation: 0.4607411816224718]
	TIME [epoch: 9.54 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.62904803540403		[learning rate: 0.0012417]
	Learning Rate: 0.00124165
	LOSS [training: 0.62904803540403 | validation: 0.5524341931732877]
	TIME [epoch: 9.53 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.616725273720977		[learning rate: 0.0012371]
	Learning Rate: 0.00123715
	LOSS [training: 0.616725273720977 | validation: 0.5494206189858659]
	TIME [epoch: 9.52 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5707636478683827		[learning rate: 0.0012327]
	Learning Rate: 0.00123266
	LOSS [training: 0.5707636478683827 | validation: 0.4591927470620965]
	TIME [epoch: 9.52 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5902875156436036		[learning rate: 0.0012282]
	Learning Rate: 0.00122818
	LOSS [training: 0.5902875156436036 | validation: 0.5578383856221929]
	TIME [epoch: 9.54 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6014378948057676		[learning rate: 0.0012237]
	Learning Rate: 0.00122373
	LOSS [training: 0.6014378948057676 | validation: 0.4906823547685525]
	TIME [epoch: 9.52 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.597765561988391		[learning rate: 0.0012193]
	Learning Rate: 0.00121929
	LOSS [training: 0.597765561988391 | validation: 0.4533962172013669]
	TIME [epoch: 9.52 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.579345015243631		[learning rate: 0.0012149]
	Learning Rate: 0.00121486
	LOSS [training: 0.579345015243631 | validation: 0.48526229176716146]
	TIME [epoch: 9.54 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6028612743751982		[learning rate: 0.0012105]
	Learning Rate: 0.00121045
	LOSS [training: 0.6028612743751982 | validation: 0.5618840056376996]
	TIME [epoch: 9.53 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5936610148624857		[learning rate: 0.0012061]
	Learning Rate: 0.00120606
	LOSS [training: 0.5936610148624857 | validation: 0.5022469628803197]
	TIME [epoch: 9.52 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5978334225355136		[learning rate: 0.0012017]
	Learning Rate: 0.00120168
	LOSS [training: 0.5978334225355136 | validation: 0.48407641554525643]
	TIME [epoch: 9.52 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5943919209568642		[learning rate: 0.0011973]
	Learning Rate: 0.00119732
	LOSS [training: 0.5943919209568642 | validation: 0.586354880608653]
	TIME [epoch: 9.54 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.605312983070151		[learning rate: 0.001193]
	Learning Rate: 0.00119298
	LOSS [training: 0.605312983070151 | validation: 0.47824805017604916]
	TIME [epoch: 9.53 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5850268855123075		[learning rate: 0.0011886]
	Learning Rate: 0.00118865
	LOSS [training: 0.5850268855123075 | validation: 0.4954308664420815]
	TIME [epoch: 9.52 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5766154586581819		[learning rate: 0.0011843]
	Learning Rate: 0.00118433
	LOSS [training: 0.5766154586581819 | validation: 0.4884278466414958]
	TIME [epoch: 9.54 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6030762106693698		[learning rate: 0.00118]
	Learning Rate: 0.00118003
	LOSS [training: 0.6030762106693698 | validation: 0.512783205529789]
	TIME [epoch: 9.52 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5975908619610293		[learning rate: 0.0011758]
	Learning Rate: 0.00117575
	LOSS [training: 0.5975908619610293 | validation: 0.47356026160447806]
	TIME [epoch: 9.53 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5762876042380417		[learning rate: 0.0011715]
	Learning Rate: 0.00117149
	LOSS [training: 0.5762876042380417 | validation: 0.5191357649674125]
	TIME [epoch: 9.52 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6159565254385092		[learning rate: 0.0011672]
	Learning Rate: 0.00116723
	LOSS [training: 0.6159565254385092 | validation: 0.4852102888601171]
	TIME [epoch: 9.55 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5696843413036973		[learning rate: 0.001163]
	Learning Rate: 0.001163
	LOSS [training: 0.5696843413036973 | validation: 0.46771396975629215]
	TIME [epoch: 9.53 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5650860125612484		[learning rate: 0.0011588]
	Learning Rate: 0.00115878
	LOSS [training: 0.5650860125612484 | validation: 0.4903169069895759]
	TIME [epoch: 9.52 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5760085789199026		[learning rate: 0.0011546]
	Learning Rate: 0.00115457
	LOSS [training: 0.5760085789199026 | validation: 0.5080863843097475]
	TIME [epoch: 9.54 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5717142666191461		[learning rate: 0.0011504]
	Learning Rate: 0.00115038
	LOSS [training: 0.5717142666191461 | validation: 0.5138896454718817]
	TIME [epoch: 9.52 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.600009543269626		[learning rate: 0.0011462]
	Learning Rate: 0.00114621
	LOSS [training: 0.600009543269626 | validation: 0.4988836573008578]
	TIME [epoch: 9.52 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5787432581091003		[learning rate: 0.001142]
	Learning Rate: 0.00114205
	LOSS [training: 0.5787432581091003 | validation: 0.5306233801487085]
	TIME [epoch: 9.52 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5887948878764145		[learning rate: 0.0011379]
	Learning Rate: 0.0011379
	LOSS [training: 0.5887948878764145 | validation: 0.4505148427154411]
	TIME [epoch: 9.54 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5769824250382468		[learning rate: 0.0011338]
	Learning Rate: 0.00113377
	LOSS [training: 0.5769824250382468 | validation: 0.469742014043638]
	TIME [epoch: 9.52 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6084599788056501		[learning rate: 0.0011297]
	Learning Rate: 0.00112966
	LOSS [training: 0.6084599788056501 | validation: 0.4341736964630022]
	TIME [epoch: 9.52 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6081258304774645		[learning rate: 0.0011256]
	Learning Rate: 0.00112556
	LOSS [training: 0.6081258304774645 | validation: 0.5871763286697468]
	TIME [epoch: 9.54 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5839866036560958		[learning rate: 0.0011215]
	Learning Rate: 0.00112147
	LOSS [training: 0.5839866036560958 | validation: 0.49050319976526097]
	TIME [epoch: 9.52 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5953296573955966		[learning rate: 0.0011174]
	Learning Rate: 0.0011174
	LOSS [training: 0.5953296573955966 | validation: 0.4564888405299986]
	TIME [epoch: 9.51 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6200731010959205		[learning rate: 0.0011133]
	Learning Rate: 0.00111335
	LOSS [training: 0.6200731010959205 | validation: 0.4725073943597313]
	TIME [epoch: 9.53 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5800372250147912		[learning rate: 0.0011093]
	Learning Rate: 0.00110931
	LOSS [training: 0.5800372250147912 | validation: 0.4519129203839766]
	TIME [epoch: 9.53 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5662669653407862		[learning rate: 0.0011053]
	Learning Rate: 0.00110528
	LOSS [training: 0.5662669653407862 | validation: 0.5353274347081775]
	TIME [epoch: 9.52 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5718510677386758		[learning rate: 0.0011013]
	Learning Rate: 0.00110127
	LOSS [training: 0.5718510677386758 | validation: 0.4647519079724485]
	TIME [epoch: 9.52 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5828919046031734		[learning rate: 0.0010973]
	Learning Rate: 0.00109728
	LOSS [training: 0.5828919046031734 | validation: 0.4627623498207848]
	TIME [epoch: 9.54 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6075630592865658		[learning rate: 0.0010933]
	Learning Rate: 0.00109329
	LOSS [training: 0.6075630592865658 | validation: 0.4497179546335406]
	TIME [epoch: 9.52 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.575495902145847		[learning rate: 0.0010893]
	Learning Rate: 0.00108933
	LOSS [training: 0.575495902145847 | validation: 0.4700900365399734]
	TIME [epoch: 9.52 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5786305276322172		[learning rate: 0.0010854]
	Learning Rate: 0.00108537
	LOSS [training: 0.5786305276322172 | validation: 0.46760356879075765]
	TIME [epoch: 9.52 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5844317848098993		[learning rate: 0.0010814]
	Learning Rate: 0.00108143
	LOSS [training: 0.5844317848098993 | validation: 0.46012117480978715]
	TIME [epoch: 9.53 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6062800370791492		[learning rate: 0.0010775]
	Learning Rate: 0.00107751
	LOSS [training: 0.6062800370791492 | validation: 0.44726549887808853]
	TIME [epoch: 9.52 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5673706540984564		[learning rate: 0.0010736]
	Learning Rate: 0.0010736
	LOSS [training: 0.5673706540984564 | validation: 0.5111910686353162]
	TIME [epoch: 9.52 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6137255031825971		[learning rate: 0.0010697]
	Learning Rate: 0.0010697
	LOSS [training: 0.6137255031825971 | validation: 0.5245557933643972]
	TIME [epoch: 9.54 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5826520614055173		[learning rate: 0.0010658]
	Learning Rate: 0.00106582
	LOSS [training: 0.5826520614055173 | validation: 0.5528829981989906]
	TIME [epoch: 9.52 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5799738391968174		[learning rate: 0.001062]
	Learning Rate: 0.00106195
	LOSS [training: 0.5799738391968174 | validation: 0.467349148056519]
	TIME [epoch: 9.52 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5792611191738868		[learning rate: 0.0010581]
	Learning Rate: 0.0010581
	LOSS [training: 0.5792611191738868 | validation: 0.5869441581444835]
	TIME [epoch: 9.53 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.58111739808985		[learning rate: 0.0010543]
	Learning Rate: 0.00105426
	LOSS [training: 0.58111739808985 | validation: 0.42472781361855083]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_719.pth
	Model improved!!!
EPOCH 720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.573137318934204		[learning rate: 0.0010504]
	Learning Rate: 0.00105043
	LOSS [training: 0.573137318934204 | validation: 0.47638534155180123]
	TIME [epoch: 9.52 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5728236727339253		[learning rate: 0.0010466]
	Learning Rate: 0.00104662
	LOSS [training: 0.5728236727339253 | validation: 0.4662501993469257]
	TIME [epoch: 9.53 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5779952317898831		[learning rate: 0.0010428]
	Learning Rate: 0.00104282
	LOSS [training: 0.5779952317898831 | validation: 0.5157891889158707]
	TIME [epoch: 9.55 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5835755271301697		[learning rate: 0.001039]
	Learning Rate: 0.00103904
	LOSS [training: 0.5835755271301697 | validation: 0.4918023550085293]
	TIME [epoch: 9.51 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5672119356536002		[learning rate: 0.0010353]
	Learning Rate: 0.00103527
	LOSS [training: 0.5672119356536002 | validation: 0.41659451876559933]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_724.pth
	Model improved!!!
EPOCH 725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5751243320831337		[learning rate: 0.0010315]
	Learning Rate: 0.00103151
	LOSS [training: 0.5751243320831337 | validation: 0.4836337779679809]
	TIME [epoch: 9.53 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.561647141129875		[learning rate: 0.0010278]
	Learning Rate: 0.00102777
	LOSS [training: 0.561647141129875 | validation: 0.5133281400201181]
	TIME [epoch: 9.53 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5807599224118496		[learning rate: 0.001024]
	Learning Rate: 0.00102404
	LOSS [training: 0.5807599224118496 | validation: 0.5284852947220718]
	TIME [epoch: 9.52 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5893982699907465		[learning rate: 0.0010203]
	Learning Rate: 0.00102032
	LOSS [training: 0.5893982699907465 | validation: 0.6663363703936233]
	TIME [epoch: 9.52 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6286295163303246		[learning rate: 0.0010166]
	Learning Rate: 0.00101662
	LOSS [training: 0.6286295163303246 | validation: 0.48002198343372593]
	TIME [epoch: 9.54 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5658174940812476		[learning rate: 0.0010129]
	Learning Rate: 0.00101293
	LOSS [training: 0.5658174940812476 | validation: 0.4700668106756507]
	TIME [epoch: 9.51 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5773719277227432		[learning rate: 0.0010093]
	Learning Rate: 0.00100925
	LOSS [training: 0.5773719277227432 | validation: 0.47024527037058017]
	TIME [epoch: 9.52 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5628583079468477		[learning rate: 0.0010056]
	Learning Rate: 0.00100559
	LOSS [training: 0.5628583079468477 | validation: 0.4761140230206437]
	TIME [epoch: 9.53 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5624234713637816		[learning rate: 0.0010019]
	Learning Rate: 0.00100194
	LOSS [training: 0.5624234713637816 | validation: 0.4620973517045556]
	TIME [epoch: 9.52 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5945400706997257		[learning rate: 0.0009983]
	Learning Rate: 0.000998305
	LOSS [training: 0.5945400706997257 | validation: 0.48801310747190746]
	TIME [epoch: 9.52 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5651004163248103		[learning rate: 0.00099468]
	Learning Rate: 0.000994682
	LOSS [training: 0.5651004163248103 | validation: 0.4947013219715652]
	TIME [epoch: 9.52 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5622492397129683		[learning rate: 0.00099107]
	Learning Rate: 0.000991072
	LOSS [training: 0.5622492397129683 | validation: 0.491006062197399]
	TIME [epoch: 9.55 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5587940763620962		[learning rate: 0.00098748]
	Learning Rate: 0.000987475
	LOSS [training: 0.5587940763620962 | validation: 0.7504360581531168]
	TIME [epoch: 9.52 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6606835354148097		[learning rate: 0.00098389]
	Learning Rate: 0.000983892
	LOSS [training: 0.6606835354148097 | validation: 0.49860617307883304]
	TIME [epoch: 9.52 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5738614459547435		[learning rate: 0.00098032]
	Learning Rate: 0.000980321
	LOSS [training: 0.5738614459547435 | validation: 0.437510017621763]
	TIME [epoch: 9.53 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.579715506046346		[learning rate: 0.00097676]
	Learning Rate: 0.000976764
	LOSS [training: 0.579715506046346 | validation: 0.4773322617782498]
	TIME [epoch: 9.52 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6139380609239566		[learning rate: 0.00097322]
	Learning Rate: 0.000973219
	LOSS [training: 0.6139380609239566 | validation: 0.46134013056744977]
	TIME [epoch: 9.52 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5704597271747605		[learning rate: 0.00096969]
	Learning Rate: 0.000969687
	LOSS [training: 0.5704597271747605 | validation: 0.5161933691747289]
	TIME [epoch: 9.53 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5880613591020591		[learning rate: 0.00096617]
	Learning Rate: 0.000966168
	LOSS [training: 0.5880613591020591 | validation: 0.5628947612962767]
	TIME [epoch: 9.54 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6032351171429666		[learning rate: 0.00096266]
	Learning Rate: 0.000962662
	LOSS [training: 0.6032351171429666 | validation: 0.4228533649367407]
	TIME [epoch: 9.53 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5774916631984002		[learning rate: 0.00095917]
	Learning Rate: 0.000959168
	LOSS [training: 0.5774916631984002 | validation: 0.48533687169105194]
	TIME [epoch: 9.52 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5545913364180171		[learning rate: 0.00095569]
	Learning Rate: 0.000955687
	LOSS [training: 0.5545913364180171 | validation: 0.4987111520477908]
	TIME [epoch: 9.55 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5616106073117763		[learning rate: 0.00095222]
	Learning Rate: 0.000952219
	LOSS [training: 0.5616106073117763 | validation: 0.4873244180273351]
	TIME [epoch: 9.53 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5703407559291623		[learning rate: 0.00094876]
	Learning Rate: 0.000948763
	LOSS [training: 0.5703407559291623 | validation: 0.5306291769335866]
	TIME [epoch: 9.52 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5861416897173417		[learning rate: 0.00094532]
	Learning Rate: 0.00094532
	LOSS [training: 0.5861416897173417 | validation: 0.457236752141952]
	TIME [epoch: 9.52 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5719793354030289		[learning rate: 0.00094189]
	Learning Rate: 0.000941889
	LOSS [training: 0.5719793354030289 | validation: 0.4715510260102279]
	TIME [epoch: 9.55 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5667472846045232		[learning rate: 0.00093847]
	Learning Rate: 0.000938471
	LOSS [training: 0.5667472846045232 | validation: 0.4350891072734618]
	TIME [epoch: 9.52 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5916437271036695		[learning rate: 0.00093507]
	Learning Rate: 0.000935066
	LOSS [training: 0.5916437271036695 | validation: 0.46322129226010506]
	TIME [epoch: 9.53 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5672343244444485		[learning rate: 0.00093167]
	Learning Rate: 0.000931672
	LOSS [training: 0.5672343244444485 | validation: 0.4856957750556131]
	TIME [epoch: 9.53 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5883045587013295		[learning rate: 0.00092829]
	Learning Rate: 0.000928291
	LOSS [training: 0.5883045587013295 | validation: 0.4759482095769023]
	TIME [epoch: 9.52 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5831994770500588		[learning rate: 0.00092492]
	Learning Rate: 0.000924922
	LOSS [training: 0.5831994770500588 | validation: 0.43615695817134303]
	TIME [epoch: 9.51 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5721849466548478		[learning rate: 0.00092157]
	Learning Rate: 0.000921566
	LOSS [training: 0.5721849466548478 | validation: 0.45244738065620754]
	TIME [epoch: 9.52 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5604050641077388		[learning rate: 0.00091822]
	Learning Rate: 0.000918221
	LOSS [training: 0.5604050641077388 | validation: 0.49815016442594345]
	TIME [epoch: 9.54 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5748181838486108		[learning rate: 0.00091489]
	Learning Rate: 0.000914889
	LOSS [training: 0.5748181838486108 | validation: 0.5347332243525368]
	TIME [epoch: 9.52 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5783385435563428		[learning rate: 0.00091157]
	Learning Rate: 0.000911569
	LOSS [training: 0.5783385435563428 | validation: 0.5106701942466944]
	TIME [epoch: 9.52 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5553326215136031		[learning rate: 0.00090826]
	Learning Rate: 0.000908261
	LOSS [training: 0.5553326215136031 | validation: 0.4971319411777395]
	TIME [epoch: 9.53 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5681937232111768		[learning rate: 0.00090496]
	Learning Rate: 0.000904965
	LOSS [training: 0.5681937232111768 | validation: 0.47360638727533705]
	TIME [epoch: 9.52 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5840245491508138		[learning rate: 0.00090168]
	Learning Rate: 0.00090168
	LOSS [training: 0.5840245491508138 | validation: 0.49023717578495535]
	TIME [epoch: 9.53 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5783464609750429		[learning rate: 0.00089841]
	Learning Rate: 0.000898408
	LOSS [training: 0.5783464609750429 | validation: 0.4354644081983432]
	TIME [epoch: 9.52 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5635746481638069		[learning rate: 0.00089515]
	Learning Rate: 0.000895148
	LOSS [training: 0.5635746481638069 | validation: 0.42460312672460143]
	TIME [epoch: 9.54 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5673022287443749		[learning rate: 0.0008919]
	Learning Rate: 0.000891899
	LOSS [training: 0.5673022287443749 | validation: 0.5251362866289709]
	TIME [epoch: 9.53 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5516077469772878		[learning rate: 0.00088866]
	Learning Rate: 0.000888663
	LOSS [training: 0.5516077469772878 | validation: 0.45015062207594614]
	TIME [epoch: 9.52 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5729644550436402		[learning rate: 0.00088544]
	Learning Rate: 0.000885438
	LOSS [training: 0.5729644550436402 | validation: 0.46954112291365924]
	TIME [epoch: 9.54 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5800552994381263		[learning rate: 0.00088222]
	Learning Rate: 0.000882224
	LOSS [training: 0.5800552994381263 | validation: 0.494489232282576]
	TIME [epoch: 9.52 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5927225023735846		[learning rate: 0.00087902]
	Learning Rate: 0.000879022
	LOSS [training: 0.5927225023735846 | validation: 0.5008719038618257]
	TIME [epoch: 9.52 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5709991655119937		[learning rate: 0.00087583]
	Learning Rate: 0.000875833
	LOSS [training: 0.5709991655119937 | validation: 0.49693155166562764]
	TIME [epoch: 9.52 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5738342087763798		[learning rate: 0.00087265]
	Learning Rate: 0.000872654
	LOSS [training: 0.5738342087763798 | validation: 0.5024585210535477]
	TIME [epoch: 9.53 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5569118004889921		[learning rate: 0.00086949]
	Learning Rate: 0.000869487
	LOSS [training: 0.5569118004889921 | validation: 0.49159445848815114]
	TIME [epoch: 9.53 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5870236247720564		[learning rate: 0.00086633]
	Learning Rate: 0.000866332
	LOSS [training: 0.5870236247720564 | validation: 0.4692207830830884]
	TIME [epoch: 9.52 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5871623427826562		[learning rate: 0.00086319]
	Learning Rate: 0.000863188
	LOSS [training: 0.5871623427826562 | validation: 0.4883481477033509]
	TIME [epoch: 9.55 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5699996322937495		[learning rate: 0.00086006]
	Learning Rate: 0.000860055
	LOSS [training: 0.5699996322937495 | validation: 0.5148236610476146]
	TIME [epoch: 9.52 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5869097357956555		[learning rate: 0.00085693]
	Learning Rate: 0.000856934
	LOSS [training: 0.5869097357956555 | validation: 0.5619782563570744]
	TIME [epoch: 9.53 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5785635041922514		[learning rate: 0.00085382]
	Learning Rate: 0.000853824
	LOSS [training: 0.5785635041922514 | validation: 0.4746083975915562]
	TIME [epoch: 9.52 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5599518835643111		[learning rate: 0.00085073]
	Learning Rate: 0.000850726
	LOSS [training: 0.5599518835643111 | validation: 0.4444520684635978]
	TIME [epoch: 9.54 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5749398695871004		[learning rate: 0.00084764]
	Learning Rate: 0.000847638
	LOSS [training: 0.5749398695871004 | validation: 0.5008171545217838]
	TIME [epoch: 9.53 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5693498852324781		[learning rate: 0.00084456]
	Learning Rate: 0.000844562
	LOSS [training: 0.5693498852324781 | validation: 0.5739775259754468]
	TIME [epoch: 9.52 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5874211312436094		[learning rate: 0.0008415]
	Learning Rate: 0.000841497
	LOSS [training: 0.5874211312436094 | validation: 0.45983839402456483]
	TIME [epoch: 9.55 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5520449419368817		[learning rate: 0.00083844]
	Learning Rate: 0.000838443
	LOSS [training: 0.5520449419368817 | validation: 0.43843903373203263]
	TIME [epoch: 9.53 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5602755369980363		[learning rate: 0.0008354]
	Learning Rate: 0.000835401
	LOSS [training: 0.5602755369980363 | validation: 0.4488076448451607]
	TIME [epoch: 9.52 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.620591489548332		[learning rate: 0.00083237]
	Learning Rate: 0.000832369
	LOSS [training: 0.620591489548332 | validation: 0.4459503994076848]
	TIME [epoch: 9.52 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.576246648349225		[learning rate: 0.00082935]
	Learning Rate: 0.000829348
	LOSS [training: 0.576246648349225 | validation: 0.4439273385034827]
	TIME [epoch: 9.54 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5551775951893326		[learning rate: 0.00082634]
	Learning Rate: 0.000826338
	LOSS [training: 0.5551775951893326 | validation: 0.5275166870566708]
	TIME [epoch: 9.52 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5849409658171696		[learning rate: 0.00082334]
	Learning Rate: 0.00082334
	LOSS [training: 0.5849409658171696 | validation: 0.580552655251818]
	TIME [epoch: 9.52 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5750681492779366		[learning rate: 0.00082035]
	Learning Rate: 0.000820352
	LOSS [training: 0.5750681492779366 | validation: 0.47217347063092446]
	TIME [epoch: 9.54 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5523682159386603		[learning rate: 0.00081737]
	Learning Rate: 0.000817375
	LOSS [training: 0.5523682159386603 | validation: 0.49174281774092626]
	TIME [epoch: 9.52 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5867818608009205		[learning rate: 0.00081441]
	Learning Rate: 0.000814408
	LOSS [training: 0.5867818608009205 | validation: 0.45039990813962405]
	TIME [epoch: 9.52 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5737748756051354		[learning rate: 0.00081145]
	Learning Rate: 0.000811453
	LOSS [training: 0.5737748756051354 | validation: 0.4334777874111537]
	TIME [epoch: 9.54 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5636206276469446		[learning rate: 0.00080851]
	Learning Rate: 0.000808508
	LOSS [training: 0.5636206276469446 | validation: 0.49228142719845375]
	TIME [epoch: 9.54 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5733802956862434		[learning rate: 0.00080557]
	Learning Rate: 0.000805574
	LOSS [training: 0.5733802956862434 | validation: 0.4620766124958757]
	TIME [epoch: 9.52 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5803581555685864		[learning rate: 0.00080265]
	Learning Rate: 0.00080265
	LOSS [training: 0.5803581555685864 | validation: 0.45974911447816114]
	TIME [epoch: 9.53 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5793603627622653		[learning rate: 0.00079974]
	Learning Rate: 0.000799737
	LOSS [training: 0.5793603627622653 | validation: 0.4415504135034669]
	TIME [epoch: 9.54 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5883634690234264		[learning rate: 0.00079684]
	Learning Rate: 0.000796835
	LOSS [training: 0.5883634690234264 | validation: 0.48647392900769604]
	TIME [epoch: 9.52 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5666284141651778		[learning rate: 0.00079394]
	Learning Rate: 0.000793943
	LOSS [training: 0.5666284141651778 | validation: 0.5329833017356557]
	TIME [epoch: 9.51 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5762878277483697		[learning rate: 0.00079106]
	Learning Rate: 0.000791062
	LOSS [training: 0.5762878277483697 | validation: 0.4559491212485237]
	TIME [epoch: 9.54 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5570320437432279		[learning rate: 0.00078819]
	Learning Rate: 0.000788191
	LOSS [training: 0.5570320437432279 | validation: 0.45538383428728024]
	TIME [epoch: 9.53 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5793054049403203		[learning rate: 0.00078533]
	Learning Rate: 0.000785331
	LOSS [training: 0.5793054049403203 | validation: 0.4572342225311134]
	TIME [epoch: 9.52 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5737363116375918		[learning rate: 0.00078248]
	Learning Rate: 0.000782481
	LOSS [training: 0.5737363116375918 | validation: 0.4925974366592568]
	TIME [epoch: 9.52 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5491167943321248		[learning rate: 0.00077964]
	Learning Rate: 0.000779641
	LOSS [training: 0.5491167943321248 | validation: 0.47130267141829396]
	TIME [epoch: 9.55 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.585920552353264		[learning rate: 0.00077681]
	Learning Rate: 0.000776812
	LOSS [training: 0.585920552353264 | validation: 0.4584962250665649]
	TIME [epoch: 9.52 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5593849628781096		[learning rate: 0.00077399]
	Learning Rate: 0.000773993
	LOSS [training: 0.5593849628781096 | validation: 0.45049029394373874]
	TIME [epoch: 9.52 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5745843791119647		[learning rate: 0.00077118]
	Learning Rate: 0.000771184
	LOSS [training: 0.5745843791119647 | validation: 0.4606977540943684]
	TIME [epoch: 9.54 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5559508207954755		[learning rate: 0.00076839]
	Learning Rate: 0.000768385
	LOSS [training: 0.5559508207954755 | validation: 0.44965411166809766]
	TIME [epoch: 9.52 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5599714152640543		[learning rate: 0.0007656]
	Learning Rate: 0.000765597
	LOSS [training: 0.5599714152640543 | validation: 0.485180545653175]
	TIME [epoch: 9.52 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5636980681094589		[learning rate: 0.00076282]
	Learning Rate: 0.000762818
	LOSS [training: 0.5636980681094589 | validation: 0.45750462228184513]
	TIME [epoch: 9.52 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5713439394229988		[learning rate: 0.00076005]
	Learning Rate: 0.00076005
	LOSS [training: 0.5713439394229988 | validation: 0.5092387436807946]
	TIME [epoch: 9.54 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.567617564230711		[learning rate: 0.00075729]
	Learning Rate: 0.000757292
	LOSS [training: 0.567617564230711 | validation: 0.48049832896464006]
	TIME [epoch: 9.53 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5807960444294006		[learning rate: 0.00075454]
	Learning Rate: 0.000754543
	LOSS [training: 0.5807960444294006 | validation: 0.5073923889231589]
	TIME [epoch: 9.53 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5664009360576461		[learning rate: 0.00075181]
	Learning Rate: 0.000751805
	LOSS [training: 0.5664009360576461 | validation: 0.49956603038476205]
	TIME [epoch: 9.55 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5732509663422596		[learning rate: 0.00074908]
	Learning Rate: 0.000749077
	LOSS [training: 0.5732509663422596 | validation: 0.47363050496508563]
	TIME [epoch: 9.53 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5580507772999127		[learning rate: 0.00074636]
	Learning Rate: 0.000746358
	LOSS [training: 0.5580507772999127 | validation: 0.49418786113901675]
	TIME [epoch: 9.53 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5382049829494322		[learning rate: 0.00074365]
	Learning Rate: 0.00074365
	LOSS [training: 0.5382049829494322 | validation: 0.4348989290322854]
	TIME [epoch: 9.53 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5619691256593706		[learning rate: 0.00074095]
	Learning Rate: 0.000740951
	LOSS [training: 0.5619691256593706 | validation: 0.4758326930274328]
	TIME [epoch: 9.55 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5527344124719435		[learning rate: 0.00073826]
	Learning Rate: 0.000738262
	LOSS [training: 0.5527344124719435 | validation: 0.4556799764580376]
	TIME [epoch: 9.52 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5787347003406321		[learning rate: 0.00073558]
	Learning Rate: 0.000735583
	LOSS [training: 0.5787347003406321 | validation: 0.460914180836272]
	TIME [epoch: 9.52 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5740794452254534		[learning rate: 0.00073291]
	Learning Rate: 0.000732913
	LOSS [training: 0.5740794452254534 | validation: 0.46952251486503727]
	TIME [epoch: 9.54 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5644426891755369		[learning rate: 0.00073025]
	Learning Rate: 0.000730254
	LOSS [training: 0.5644426891755369 | validation: 0.4508644391612044]
	TIME [epoch: 9.53 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5548497370960745		[learning rate: 0.0007276]
	Learning Rate: 0.000727603
	LOSS [training: 0.5548497370960745 | validation: 0.48385964130658055]
	TIME [epoch: 9.52 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5743158157436326		[learning rate: 0.00072496]
	Learning Rate: 0.000724963
	LOSS [training: 0.5743158157436326 | validation: 0.48768531445933966]
	TIME [epoch: 9.52 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6026655174976794		[learning rate: 0.00072233]
	Learning Rate: 0.000722332
	LOSS [training: 0.6026655174976794 | validation: 0.49732645724643465]
	TIME [epoch: 9.54 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5708079457670819		[learning rate: 0.00071971]
	Learning Rate: 0.000719711
	LOSS [training: 0.5708079457670819 | validation: 0.49745771878511497]
	TIME [epoch: 9.52 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5601365603960803		[learning rate: 0.0007171]
	Learning Rate: 0.000717099
	LOSS [training: 0.5601365603960803 | validation: 0.5004270526359098]
	TIME [epoch: 9.52 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5709683906569277		[learning rate: 0.0007145]
	Learning Rate: 0.000714496
	LOSS [training: 0.5709683906569277 | validation: 0.4758191910833135]
	TIME [epoch: 9.53 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5716394489994017		[learning rate: 0.0007119]
	Learning Rate: 0.000711903
	LOSS [training: 0.5716394489994017 | validation: 0.5104857879027426]
	TIME [epoch: 9.53 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5694949273256759		[learning rate: 0.00070932]
	Learning Rate: 0.00070932
	LOSS [training: 0.5694949273256759 | validation: 0.5065158932676859]
	TIME [epoch: 9.53 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5622248313225559		[learning rate: 0.00070675]
	Learning Rate: 0.000706746
	LOSS [training: 0.5622248313225559 | validation: 0.5190228176720886]
	TIME [epoch: 9.52 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5529944011929422		[learning rate: 0.00070418]
	Learning Rate: 0.000704181
	LOSS [training: 0.5529944011929422 | validation: 0.4608177195439164]
	TIME [epoch: 9.54 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.55949215443161		[learning rate: 0.00070163]
	Learning Rate: 0.000701625
	LOSS [training: 0.55949215443161 | validation: 0.6615721111016228]
	TIME [epoch: 9.52 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5998949455376905		[learning rate: 0.00069908]
	Learning Rate: 0.000699079
	LOSS [training: 0.5998949455376905 | validation: 0.4737984342866878]
	TIME [epoch: 9.53 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.550328076939184		[learning rate: 0.00069654]
	Learning Rate: 0.000696542
	LOSS [training: 0.550328076939184 | validation: 0.46835597655088856]
	TIME [epoch: 9.54 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5463835253458795		[learning rate: 0.00069401]
	Learning Rate: 0.000694014
	LOSS [training: 0.5463835253458795 | validation: 0.44304066940071823]
	TIME [epoch: 9.53 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5884772327253824		[learning rate: 0.0006915]
	Learning Rate: 0.000691496
	LOSS [training: 0.5884772327253824 | validation: 0.5962677287175391]
	TIME [epoch: 9.52 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6096817115183409		[learning rate: 0.00068899]
	Learning Rate: 0.000688986
	LOSS [training: 0.6096817115183409 | validation: 0.44958502856640375]
	TIME [epoch: 9.52 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5880704518418665		[learning rate: 0.00068649]
	Learning Rate: 0.000686486
	LOSS [training: 0.5880704518418665 | validation: 0.5213588395272685]
	TIME [epoch: 9.54 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5818414308935758		[learning rate: 0.00068399]
	Learning Rate: 0.000683994
	LOSS [training: 0.5818414308935758 | validation: 0.4924618803792894]
	TIME [epoch: 9.53 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5615372872503692		[learning rate: 0.00068151]
	Learning Rate: 0.000681512
	LOSS [training: 0.5615372872503692 | validation: 0.5132188629857316]
	TIME [epoch: 9.52 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5550243365999156		[learning rate: 0.00067904]
	Learning Rate: 0.000679039
	LOSS [training: 0.5550243365999156 | validation: 0.5114553292617404]
	TIME [epoch: 9.54 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5683740501736053		[learning rate: 0.00067657]
	Learning Rate: 0.000676575
	LOSS [training: 0.5683740501736053 | validation: 0.5124631740088451]
	TIME [epoch: 9.53 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5688429611924322		[learning rate: 0.00067412]
	Learning Rate: 0.00067412
	LOSS [training: 0.5688429611924322 | validation: 0.4590637051239911]
	TIME [epoch: 9.52 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5598442054394339		[learning rate: 0.00067167]
	Learning Rate: 0.000671673
	LOSS [training: 0.5598442054394339 | validation: 0.4738948973887176]
	TIME [epoch: 9.52 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5891177982888427		[learning rate: 0.00066924]
	Learning Rate: 0.000669235
	LOSS [training: 0.5891177982888427 | validation: 0.49962476389149457]
	TIME [epoch: 9.54 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5649060176305231		[learning rate: 0.00066681]
	Learning Rate: 0.000666807
	LOSS [training: 0.5649060176305231 | validation: 0.4461693972303701]
	TIME [epoch: 9.52 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5626962000256504		[learning rate: 0.00066439]
	Learning Rate: 0.000664387
	LOSS [training: 0.5626962000256504 | validation: 0.4697812540023332]
	TIME [epoch: 9.52 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5518703501790467		[learning rate: 0.00066198]
	Learning Rate: 0.000661976
	LOSS [training: 0.5518703501790467 | validation: 0.498544499959487]
	TIME [epoch: 9.54 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5674642001475754		[learning rate: 0.00065957]
	Learning Rate: 0.000659573
	LOSS [training: 0.5674642001475754 | validation: 0.43918631944004605]
	TIME [epoch: 9.52 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5676275992214295		[learning rate: 0.00065718]
	Learning Rate: 0.00065718
	LOSS [training: 0.5676275992214295 | validation: 0.4582934013080129]
	TIME [epoch: 9.52 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.554352762050182		[learning rate: 0.00065479]
	Learning Rate: 0.000654795
	LOSS [training: 0.554352762050182 | validation: 0.5077285146617434]
	TIME [epoch: 9.52 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5780214998089434		[learning rate: 0.00065242]
	Learning Rate: 0.000652419
	LOSS [training: 0.5780214998089434 | validation: 0.5144331695086226]
	TIME [epoch: 9.54 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5616867660057636		[learning rate: 0.00065005]
	Learning Rate: 0.000650051
	LOSS [training: 0.5616867660057636 | validation: 0.4523845984848396]
	TIME [epoch: 9.52 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5573044267132057		[learning rate: 0.00064769]
	Learning Rate: 0.000647692
	LOSS [training: 0.5573044267132057 | validation: 0.4679781824566278]
	TIME [epoch: 9.52 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5447379836647566		[learning rate: 0.00064534]
	Learning Rate: 0.000645341
	LOSS [training: 0.5447379836647566 | validation: 0.4424343442333166]
	TIME [epoch: 9.55 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5561349089916181		[learning rate: 0.000643]
	Learning Rate: 0.000642999
	LOSS [training: 0.5561349089916181 | validation: 0.4642105067701985]
	TIME [epoch: 9.52 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5559138926439464		[learning rate: 0.00064067]
	Learning Rate: 0.000640666
	LOSS [training: 0.5559138926439464 | validation: 0.4730699721194443]
	TIME [epoch: 9.53 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.554333368099775		[learning rate: 0.00063834]
	Learning Rate: 0.000638341
	LOSS [training: 0.554333368099775 | validation: 0.46568394283922476]
	TIME [epoch: 9.53 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5604930964780352		[learning rate: 0.00063602]
	Learning Rate: 0.000636024
	LOSS [training: 0.5604930964780352 | validation: 0.5091081824566033]
	TIME [epoch: 9.53 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5604697877221979		[learning rate: 0.00063372]
	Learning Rate: 0.000633716
	LOSS [training: 0.5604697877221979 | validation: 0.4833119033764735]
	TIME [epoch: 9.51 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5519385930183442		[learning rate: 0.00063142]
	Learning Rate: 0.000631416
	LOSS [training: 0.5519385930183442 | validation: 0.5012824805121092]
	TIME [epoch: 9.51 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5572211489039853		[learning rate: 0.00062912]
	Learning Rate: 0.000629125
	LOSS [training: 0.5572211489039853 | validation: 0.4462228701566493]
	TIME [epoch: 9.54 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5566638935928065		[learning rate: 0.00062684]
	Learning Rate: 0.000626842
	LOSS [training: 0.5566638935928065 | validation: 0.5095729780077279]
	TIME [epoch: 9.52 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.60529366630614		[learning rate: 0.00062457]
	Learning Rate: 0.000624567
	LOSS [training: 0.60529366630614 | validation: 0.43891482981791546]
	TIME [epoch: 9.52 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.551087436875448		[learning rate: 0.0006223]
	Learning Rate: 0.0006223
	LOSS [training: 0.551087436875448 | validation: 0.4335002919159623]
	TIME [epoch: 9.54 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5699754840219656		[learning rate: 0.00062004]
	Learning Rate: 0.000620042
	LOSS [training: 0.5699754840219656 | validation: 0.43251989023522763]
	TIME [epoch: 9.52 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5559013136266723		[learning rate: 0.00061779]
	Learning Rate: 0.000617792
	LOSS [training: 0.5559013136266723 | validation: 0.4332990395150179]
	TIME [epoch: 9.51 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5616655907981087		[learning rate: 0.00061555]
	Learning Rate: 0.00061555
	LOSS [training: 0.5616655907981087 | validation: 0.4612199920302645]
	TIME [epoch: 9.52 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5687191608938822		[learning rate: 0.00061332]
	Learning Rate: 0.000613316
	LOSS [training: 0.5687191608938822 | validation: 0.49375426471563133]
	TIME [epoch: 9.54 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5555137790506535		[learning rate: 0.00061109]
	Learning Rate: 0.00061109
	LOSS [training: 0.5555137790506535 | validation: 0.4224931896870942]
	TIME [epoch: 9.52 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.55154321634071		[learning rate: 0.00060887]
	Learning Rate: 0.000608872
	LOSS [training: 0.55154321634071 | validation: 0.4348550591421859]
	TIME [epoch: 9.52 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5651710788570476		[learning rate: 0.00060666]
	Learning Rate: 0.000606663
	LOSS [training: 0.5651710788570476 | validation: 0.4431961795604448]
	TIME [epoch: 9.54 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.555311152718099		[learning rate: 0.00060446]
	Learning Rate: 0.000604461
	LOSS [training: 0.555311152718099 | validation: 0.46293924297039846]
	TIME [epoch: 9.53 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5594460303803397		[learning rate: 0.00060227]
	Learning Rate: 0.000602268
	LOSS [training: 0.5594460303803397 | validation: 0.46450357651786234]
	TIME [epoch: 9.52 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5412064230121402		[learning rate: 0.00060008]
	Learning Rate: 0.000600082
	LOSS [training: 0.5412064230121402 | validation: 0.5225910262062994]
	TIME [epoch: 9.52 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5476692135580203		[learning rate: 0.0005979]
	Learning Rate: 0.000597904
	LOSS [training: 0.5476692135580203 | validation: 0.525687271134191]
	TIME [epoch: 9.54 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5778920139371208		[learning rate: 0.00059573]
	Learning Rate: 0.000595734
	LOSS [training: 0.5778920139371208 | validation: 0.5450388751690433]
	TIME [epoch: 9.52 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5612558662994397		[learning rate: 0.00059357]
	Learning Rate: 0.000593572
	LOSS [training: 0.5612558662994397 | validation: 0.4469434616226479]
	TIME [epoch: 9.52 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5408525835698356		[learning rate: 0.00059142]
	Learning Rate: 0.000591418
	LOSS [training: 0.5408525835698356 | validation: 0.4772988255432078]
	TIME [epoch: 9.54 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5599353346586953		[learning rate: 0.00058927]
	Learning Rate: 0.000589272
	LOSS [training: 0.5599353346586953 | validation: 0.4585066733899062]
	TIME [epoch: 9.53 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.563156392195297		[learning rate: 0.00058713]
	Learning Rate: 0.000587133
	LOSS [training: 0.563156392195297 | validation: 0.47268266783158214]
	TIME [epoch: 9.52 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5455576307533841		[learning rate: 0.000585]
	Learning Rate: 0.000585003
	LOSS [training: 0.5455576307533841 | validation: 0.4459462728172091]
	TIME [epoch: 9.52 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5570461367488007		[learning rate: 0.00058288]
	Learning Rate: 0.00058288
	LOSS [training: 0.5570461367488007 | validation: 0.43952369102796296]
	TIME [epoch: 9.54 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5607603894430465		[learning rate: 0.00058076]
	Learning Rate: 0.000580764
	LOSS [training: 0.5607603894430465 | validation: 0.44962155245074514]
	TIME [epoch: 9.52 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5469365514102668		[learning rate: 0.00057866]
	Learning Rate: 0.000578657
	LOSS [training: 0.5469365514102668 | validation: 0.48044078511445576]
	TIME [epoch: 9.52 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.580414204334762		[learning rate: 0.00057656]
	Learning Rate: 0.000576557
	LOSS [training: 0.580414204334762 | validation: 0.4671299601307781]
	TIME [epoch: 9.54 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5862029918250392		[learning rate: 0.00057446]
	Learning Rate: 0.000574465
	LOSS [training: 0.5862029918250392 | validation: 0.43563619998733766]
	TIME [epoch: 9.53 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5466043685378569		[learning rate: 0.00057238]
	Learning Rate: 0.00057238
	LOSS [training: 0.5466043685378569 | validation: 0.45840304138184634]
	TIME [epoch: 9.52 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5563090580161791		[learning rate: 0.0005703]
	Learning Rate: 0.000570303
	LOSS [training: 0.5563090580161791 | validation: 0.489464920021035]
	TIME [epoch: 9.52 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5387476348425073		[learning rate: 0.00056823]
	Learning Rate: 0.000568233
	LOSS [training: 0.5387476348425073 | validation: 0.4610616837937158]
	TIME [epoch: 9.54 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5649019872355308		[learning rate: 0.00056617]
	Learning Rate: 0.000566171
	LOSS [training: 0.5649019872355308 | validation: 0.4506804164166695]
	TIME [epoch: 9.52 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5915937939676067		[learning rate: 0.00056412]
	Learning Rate: 0.000564116
	LOSS [training: 0.5915937939676067 | validation: 0.4609873517332572]
	TIME [epoch: 9.52 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5688344121542294		[learning rate: 0.00056207]
	Learning Rate: 0.000562069
	LOSS [training: 0.5688344121542294 | validation: 0.5119137428323058]
	TIME [epoch: 9.54 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5658670114918071		[learning rate: 0.00056003]
	Learning Rate: 0.000560029
	LOSS [training: 0.5658670114918071 | validation: 0.4944972972463233]
	TIME [epoch: 9.52 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.558405361901915		[learning rate: 0.000558]
	Learning Rate: 0.000557997
	LOSS [training: 0.558405361901915 | validation: 0.4821532619971093]
	TIME [epoch: 9.52 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5649882673130179		[learning rate: 0.00055597]
	Learning Rate: 0.000555972
	LOSS [training: 0.5649882673130179 | validation: 0.47312033987916524]
	TIME [epoch: 9.52 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5439219874638446		[learning rate: 0.00055395]
	Learning Rate: 0.000553954
	LOSS [training: 0.5439219874638446 | validation: 0.5741867034813088]
	TIME [epoch: 9.54 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5890458189339957		[learning rate: 0.00055194]
	Learning Rate: 0.000551944
	LOSS [training: 0.5890458189339957 | validation: 0.5131147357301018]
	TIME [epoch: 9.52 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5655533194800123		[learning rate: 0.00054994]
	Learning Rate: 0.000549941
	LOSS [training: 0.5655533194800123 | validation: 0.5125981721468312]
	TIME [epoch: 9.53 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5571793537123758		[learning rate: 0.00054794]
	Learning Rate: 0.000547945
	LOSS [training: 0.5571793537123758 | validation: 0.5408919295760173]
	TIME [epoch: 9.54 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5604737736745665		[learning rate: 0.00054596]
	Learning Rate: 0.000545956
	LOSS [training: 0.5604737736745665 | validation: 0.4752081115817444]
	TIME [epoch: 9.53 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5578081920946634		[learning rate: 0.00054397]
	Learning Rate: 0.000543975
	LOSS [training: 0.5578081920946634 | validation: 0.46466770982195094]
	TIME [epoch: 9.52 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5510267663597659		[learning rate: 0.000542]
	Learning Rate: 0.000542001
	LOSS [training: 0.5510267663597659 | validation: 0.49856616156225897]
	TIME [epoch: 9.53 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5609159105870749		[learning rate: 0.00054003]
	Learning Rate: 0.000540034
	LOSS [training: 0.5609159105870749 | validation: 0.4536760261479028]
	TIME [epoch: 9.54 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5583794828543259		[learning rate: 0.00053807]
	Learning Rate: 0.000538074
	LOSS [training: 0.5583794828543259 | validation: 0.4940937591396914]
	TIME [epoch: 9.52 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5697274648633405		[learning rate: 0.00053612]
	Learning Rate: 0.000536121
	LOSS [training: 0.5697274648633405 | validation: 0.4695249453464436]
	TIME [epoch: 9.52 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5610217938896823		[learning rate: 0.00053418]
	Learning Rate: 0.000534176
	LOSS [training: 0.5610217938896823 | validation: 0.44861011380599886]
	TIME [epoch: 9.54 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5482860974246371		[learning rate: 0.00053224]
	Learning Rate: 0.000532237
	LOSS [training: 0.5482860974246371 | validation: 0.4655404887717424]
	TIME [epoch: 9.52 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5486891920080269		[learning rate: 0.00053031]
	Learning Rate: 0.000530306
	LOSS [training: 0.5486891920080269 | validation: 0.5008897094360121]
	TIME [epoch: 9.52 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5690722112107777		[learning rate: 0.00052838]
	Learning Rate: 0.000528381
	LOSS [training: 0.5690722112107777 | validation: 0.44333223731840876]
	TIME [epoch: 9.53 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5540485488980714		[learning rate: 0.00052646]
	Learning Rate: 0.000526464
	LOSS [training: 0.5540485488980714 | validation: 0.47837602486670355]
	TIME [epoch: 9.54 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5516261772375636		[learning rate: 0.00052455]
	Learning Rate: 0.000524553
	LOSS [training: 0.5516261772375636 | validation: 0.45487836317125707]
	TIME [epoch: 9.53 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5526230461371568		[learning rate: 0.00052265]
	Learning Rate: 0.000522649
	LOSS [training: 0.5526230461371568 | validation: 0.4619012492545146]
	TIME [epoch: 9.53 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5502968133234075		[learning rate: 0.00052075]
	Learning Rate: 0.000520753
	LOSS [training: 0.5502968133234075 | validation: 0.4405654818860566]
	TIME [epoch: 9.55 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5861822680553475		[learning rate: 0.00051886]
	Learning Rate: 0.000518863
	LOSS [training: 0.5861822680553475 | validation: 0.460115315518131]
	TIME [epoch: 9.53 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5679708399588556		[learning rate: 0.00051698]
	Learning Rate: 0.00051698
	LOSS [training: 0.5679708399588556 | validation: 0.47890228453564376]
	TIME [epoch: 9.52 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5424020835976087		[learning rate: 0.0005151]
	Learning Rate: 0.000515104
	LOSS [training: 0.5424020835976087 | validation: 0.47354549481304575]
	TIME [epoch: 9.53 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5549295115994124		[learning rate: 0.00051323]
	Learning Rate: 0.000513235
	LOSS [training: 0.5549295115994124 | validation: 0.45669841910113046]
	TIME [epoch: 9.55 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5510258054926176		[learning rate: 0.00051137]
	Learning Rate: 0.000511372
	LOSS [training: 0.5510258054926176 | validation: 0.45032267659398373]
	TIME [epoch: 9.53 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5396091072613183		[learning rate: 0.00050952]
	Learning Rate: 0.000509516
	LOSS [training: 0.5396091072613183 | validation: 0.5048690577603618]
	TIME [epoch: 9.53 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5460912034907986		[learning rate: 0.00050767]
	Learning Rate: 0.000507667
	LOSS [training: 0.5460912034907986 | validation: 0.4414728053463138]
	TIME [epoch: 9.54 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.545530260284223		[learning rate: 0.00050582]
	Learning Rate: 0.000505825
	LOSS [training: 0.545530260284223 | validation: 0.458177801534176]
	TIME [epoch: 9.53 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.555473933794162		[learning rate: 0.00050399]
	Learning Rate: 0.000503989
	LOSS [training: 0.555473933794162 | validation: 0.49706560391967186]
	TIME [epoch: 9.52 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5600436752759853		[learning rate: 0.00050216]
	Learning Rate: 0.00050216
	LOSS [training: 0.5600436752759853 | validation: 0.5125761816002355]
	TIME [epoch: 9.54 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.563393333803603		[learning rate: 0.00050034]
	Learning Rate: 0.000500338
	LOSS [training: 0.563393333803603 | validation: 0.43350708300996316]
	TIME [epoch: 9.54 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5644337947870307		[learning rate: 0.00049852]
	Learning Rate: 0.000498522
	LOSS [training: 0.5644337947870307 | validation: 0.49333991296836116]
	TIME [epoch: 9.52 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5674905677926017		[learning rate: 0.00049671]
	Learning Rate: 0.000496713
	LOSS [training: 0.5674905677926017 | validation: 0.4870071934760896]
	TIME [epoch: 9.52 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5495423655395126		[learning rate: 0.00049491]
	Learning Rate: 0.00049491
	LOSS [training: 0.5495423655395126 | validation: 0.45246702900679003]
	TIME [epoch: 9.55 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5606674031605591		[learning rate: 0.00049311]
	Learning Rate: 0.000493114
	LOSS [training: 0.5606674031605591 | validation: 0.4797422469383983]
	TIME [epoch: 9.52 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5648566223088696		[learning rate: 0.00049132]
	Learning Rate: 0.000491325
	LOSS [training: 0.5648566223088696 | validation: 0.44548695099684993]
	TIME [epoch: 9.52 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5555987764899912		[learning rate: 0.00048954]
	Learning Rate: 0.000489542
	LOSS [training: 0.5555987764899912 | validation: 0.44989580375191185]
	TIME [epoch: 9.53 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5662571664350426		[learning rate: 0.00048776]
	Learning Rate: 0.000487765
	LOSS [training: 0.5662571664350426 | validation: 0.4481825443874593]
	TIME [epoch: 9.53 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5441702040795642		[learning rate: 0.00048599]
	Learning Rate: 0.000485995
	LOSS [training: 0.5441702040795642 | validation: 0.4619355643860606]
	TIME [epoch: 9.52 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5371917612968033		[learning rate: 0.00048423]
	Learning Rate: 0.000484231
	LOSS [training: 0.5371917612968033 | validation: 0.4876100455122554]
	TIME [epoch: 9.52 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5537622029238379		[learning rate: 0.00048247]
	Learning Rate: 0.000482474
	LOSS [training: 0.5537622029238379 | validation: 0.44568514518617347]
	TIME [epoch: 9.54 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5796185451410925		[learning rate: 0.00048072]
	Learning Rate: 0.000480723
	LOSS [training: 0.5796185451410925 | validation: 0.4480485686658811]
	TIME [epoch: 9.53 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5723194006317252		[learning rate: 0.00047898]
	Learning Rate: 0.000478978
	LOSS [training: 0.5723194006317252 | validation: 0.45770409164266385]
	TIME [epoch: 9.53 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5496241736725965		[learning rate: 0.00047724]
	Learning Rate: 0.00047724
	LOSS [training: 0.5496241736725965 | validation: 0.48807268178138785]
	TIME [epoch: 9.55 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5499052044763874		[learning rate: 0.00047551]
	Learning Rate: 0.000475508
	LOSS [training: 0.5499052044763874 | validation: 0.4528319129353195]
	TIME [epoch: 9.53 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5420041793134669		[learning rate: 0.00047378]
	Learning Rate: 0.000473782
	LOSS [training: 0.5420041793134669 | validation: 0.47888676491973764]
	TIME [epoch: 9.53 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5577106184234548		[learning rate: 0.00047206]
	Learning Rate: 0.000472063
	LOSS [training: 0.5577106184234548 | validation: 0.4450931141425527]
	TIME [epoch: 9.53 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5536597653225787		[learning rate: 0.00047035]
	Learning Rate: 0.00047035
	LOSS [training: 0.5536597653225787 | validation: 0.44376308852125707]
	TIME [epoch: 9.55 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.573011407271924		[learning rate: 0.00046864]
	Learning Rate: 0.000468643
	LOSS [training: 0.573011407271924 | validation: 0.4515956920682308]
	TIME [epoch: 9.53 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5618912131699185		[learning rate: 0.00046694]
	Learning Rate: 0.000466942
	LOSS [training: 0.5618912131699185 | validation: 0.44122594197184295]
	TIME [epoch: 9.53 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5412614064179639		[learning rate: 0.00046525]
	Learning Rate: 0.000465248
	LOSS [training: 0.5412614064179639 | validation: 0.47931024254885]
	TIME [epoch: 9.54 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5600102964784478		[learning rate: 0.00046356]
	Learning Rate: 0.000463559
	LOSS [training: 0.5600102964784478 | validation: 0.4536122466293091]
	TIME [epoch: 9.53 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5605419663776654		[learning rate: 0.00046188]
	Learning Rate: 0.000461877
	LOSS [training: 0.5605419663776654 | validation: 0.45078357316175466]
	TIME [epoch: 9.53 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5428725484243622		[learning rate: 0.0004602]
	Learning Rate: 0.000460201
	LOSS [training: 0.5428725484243622 | validation: 0.4449130562409028]
	TIME [epoch: 9.53 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5441774386377908		[learning rate: 0.00045853]
	Learning Rate: 0.000458531
	LOSS [training: 0.5441774386377908 | validation: 0.44205383587180824]
	TIME [epoch: 9.55 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5602457337539347		[learning rate: 0.00045687]
	Learning Rate: 0.000456867
	LOSS [training: 0.5602457337539347 | validation: 0.46226999854881684]
	TIME [epoch: 9.53 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5339222627338869		[learning rate: 0.00045521]
	Learning Rate: 0.000455209
	LOSS [training: 0.5339222627338869 | validation: 0.49469234965656117]
	TIME [epoch: 9.52 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5532925577836602		[learning rate: 0.00045356]
	Learning Rate: 0.000453557
	LOSS [training: 0.5532925577836602 | validation: 0.4608108543437498]
	TIME [epoch: 9.55 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5582530364505216		[learning rate: 0.00045191]
	Learning Rate: 0.000451911
	LOSS [training: 0.5582530364505216 | validation: 0.42879984099881385]
	TIME [epoch: 9.52 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5587366089730942		[learning rate: 0.00045027]
	Learning Rate: 0.000450271
	LOSS [training: 0.5587366089730942 | validation: 0.4200547628069991]
	TIME [epoch: 9.53 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5502031289924385		[learning rate: 0.00044864]
	Learning Rate: 0.000448637
	LOSS [training: 0.5502031289924385 | validation: 0.4362928313406015]
	TIME [epoch: 9.52 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5619317019402622		[learning rate: 0.00044701]
	Learning Rate: 0.000447009
	LOSS [training: 0.5619317019402622 | validation: 0.49016337407609784]
	TIME [epoch: 9.55 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5670729166662734		[learning rate: 0.00044539]
	Learning Rate: 0.000445386
	LOSS [training: 0.5670729166662734 | validation: 0.46337392712476755]
	TIME [epoch: 9.53 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.547349536073284		[learning rate: 0.00044377]
	Learning Rate: 0.00044377
	LOSS [training: 0.547349536073284 | validation: 0.4475307835957281]
	TIME [epoch: 9.53 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5515784196846806		[learning rate: 0.00044216]
	Learning Rate: 0.00044216
	LOSS [training: 0.5515784196846806 | validation: 0.47687921983846115]
	TIME [epoch: 9.54 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.543692241892723		[learning rate: 0.00044055]
	Learning Rate: 0.000440555
	LOSS [training: 0.543692241892723 | validation: 0.5095428773385213]
	TIME [epoch: 9.53 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.544197014359347		[learning rate: 0.00043896]
	Learning Rate: 0.000438956
	LOSS [training: 0.544197014359347 | validation: 0.45388780903887366]
	TIME [epoch: 9.53 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5418980640884146		[learning rate: 0.00043736]
	Learning Rate: 0.000437363
	LOSS [training: 0.5418980640884146 | validation: 0.46279205997246536]
	TIME [epoch: 9.53 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5478131306334779		[learning rate: 0.00043578]
	Learning Rate: 0.000435776
	LOSS [training: 0.5478131306334779 | validation: 0.46308027755095027]
	TIME [epoch: 9.55 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5519073615304246		[learning rate: 0.00043419]
	Learning Rate: 0.000434194
	LOSS [training: 0.5519073615304246 | validation: 0.5176330325784205]
	TIME [epoch: 9.53 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5511244042844458		[learning rate: 0.00043262]
	Learning Rate: 0.000432619
	LOSS [training: 0.5511244042844458 | validation: 0.44348953703895067]
	TIME [epoch: 9.53 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5628921048872325		[learning rate: 0.00043105]
	Learning Rate: 0.000431049
	LOSS [training: 0.5628921048872325 | validation: 0.45343836675877114]
	TIME [epoch: 9.54 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5495530201967563		[learning rate: 0.00042948]
	Learning Rate: 0.000429484
	LOSS [training: 0.5495530201967563 | validation: 0.4583931845705089]
	TIME [epoch: 9.53 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5457370841477964		[learning rate: 0.00042793]
	Learning Rate: 0.000427926
	LOSS [training: 0.5457370841477964 | validation: 0.46860961453627836]
	TIME [epoch: 9.53 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5350526583754467		[learning rate: 0.00042637]
	Learning Rate: 0.000426373
	LOSS [training: 0.5350526583754467 | validation: 0.41546466959537964]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_968.pth
	Model improved!!!
EPOCH 969/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5559221874815182		[learning rate: 0.00042483]
	Learning Rate: 0.000424825
	LOSS [training: 0.5559221874815182 | validation: 0.4496808348462332]
	TIME [epoch: 9.54 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.550241474196075		[learning rate: 0.00042328]
	Learning Rate: 0.000423284
	LOSS [training: 0.550241474196075 | validation: 0.4222559940646918]
	TIME [epoch: 9.53 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5498214789762327		[learning rate: 0.00042175]
	Learning Rate: 0.000421748
	LOSS [training: 0.5498214789762327 | validation: 0.47520244850823157]
	TIME [epoch: 9.52 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5726441069108296		[learning rate: 0.00042022]
	Learning Rate: 0.000420217
	LOSS [training: 0.5726441069108296 | validation: 0.4422334187570293]
	TIME [epoch: 9.54 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5404822925793159		[learning rate: 0.00041869]
	Learning Rate: 0.000418692
	LOSS [training: 0.5404822925793159 | validation: 0.4288721186198683]
	TIME [epoch: 9.52 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5504613800258371		[learning rate: 0.00041717]
	Learning Rate: 0.000417173
	LOSS [training: 0.5504613800258371 | validation: 0.42164177267927067]
	TIME [epoch: 9.53 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5473268297926278		[learning rate: 0.00041566]
	Learning Rate: 0.000415659
	LOSS [training: 0.5473268297926278 | validation: 0.4587091011808183]
	TIME [epoch: 9.53 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5433435048138244		[learning rate: 0.00041415]
	Learning Rate: 0.00041415
	LOSS [training: 0.5433435048138244 | validation: 0.42693925941701977]
	TIME [epoch: 9.54 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5405935186242878		[learning rate: 0.00041265]
	Learning Rate: 0.000412647
	LOSS [training: 0.5405935186242878 | validation: 0.43635205557689916]
	TIME [epoch: 9.52 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5406439514137442		[learning rate: 0.00041115]
	Learning Rate: 0.00041115
	LOSS [training: 0.5406439514137442 | validation: 0.4591281665720493]
	TIME [epoch: 9.52 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.55038671828496		[learning rate: 0.00040966]
	Learning Rate: 0.000409658
	LOSS [training: 0.55038671828496 | validation: 0.47687316183118605]
	TIME [epoch: 9.55 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5667058113206279		[learning rate: 0.00040817]
	Learning Rate: 0.000408171
	LOSS [training: 0.5667058113206279 | validation: 0.4611108767448483]
	TIME [epoch: 9.52 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5474907033414846		[learning rate: 0.00040669]
	Learning Rate: 0.00040669
	LOSS [training: 0.5474907033414846 | validation: 0.47447113316039147]
	TIME [epoch: 9.53 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.551215062849066		[learning rate: 0.00040521]
	Learning Rate: 0.000405214
	LOSS [training: 0.551215062849066 | validation: 0.4608596944935182]
	TIME [epoch: 9.52 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5745478988947299		[learning rate: 0.00040374]
	Learning Rate: 0.000403743
	LOSS [training: 0.5745478988947299 | validation: 0.4678252347881632]
	TIME [epoch: 9.54 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.561807994001628		[learning rate: 0.00040228]
	Learning Rate: 0.000402278
	LOSS [training: 0.561807994001628 | validation: 0.487519888539575]
	TIME [epoch: 9.52 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5712569998742929		[learning rate: 0.00040082]
	Learning Rate: 0.000400818
	LOSS [training: 0.5712569998742929 | validation: 0.5320487427688372]
	TIME [epoch: 9.53 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5609434928724724		[learning rate: 0.00039936]
	Learning Rate: 0.000399364
	LOSS [training: 0.5609434928724724 | validation: 0.44193200283743184]
	TIME [epoch: 9.54 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5396388964229745		[learning rate: 0.00039791]
	Learning Rate: 0.000397914
	LOSS [training: 0.5396388964229745 | validation: 0.4519989632289456]
	TIME [epoch: 9.53 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.55108913939552		[learning rate: 0.00039647]
	Learning Rate: 0.00039647
	LOSS [training: 0.55108913939552 | validation: 0.4696969955070695]
	TIME [epoch: 9.52 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5617918177165127		[learning rate: 0.00039503]
	Learning Rate: 0.000395031
	LOSS [training: 0.5617918177165127 | validation: 0.4508222388448111]
	TIME [epoch: 9.54 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5456802382546558		[learning rate: 0.0003936]
	Learning Rate: 0.000393598
	LOSS [training: 0.5456802382546558 | validation: 0.43552628536131827]
	TIME [epoch: 9.53 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.557283288711213		[learning rate: 0.00039217]
	Learning Rate: 0.000392169
	LOSS [training: 0.557283288711213 | validation: 0.4760505673656087]
	TIME [epoch: 9.52 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5379726819625624		[learning rate: 0.00039075]
	Learning Rate: 0.000390746
	LOSS [training: 0.5379726819625624 | validation: 0.5065848563377897]
	TIME [epoch: 9.52 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5738508260372239		[learning rate: 0.00038933]
	Learning Rate: 0.000389328
	LOSS [training: 0.5738508260372239 | validation: 0.42753276475975677]
	TIME [epoch: 9.55 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5404157809589847		[learning rate: 0.00038792]
	Learning Rate: 0.000387915
	LOSS [training: 0.5404157809589847 | validation: 0.4524778032248273]
	TIME [epoch: 9.53 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5445215714077406		[learning rate: 0.00038651]
	Learning Rate: 0.000386508
	LOSS [training: 0.5445215714077406 | validation: 0.44369655288908066]
	TIME [epoch: 9.53 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5366185997954106		[learning rate: 0.0003851]
	Learning Rate: 0.000385105
	LOSS [training: 0.5366185997954106 | validation: 0.4316762053772156]
	TIME [epoch: 9.53 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5526508972618986		[learning rate: 0.00038371]
	Learning Rate: 0.000383707
	LOSS [training: 0.5526508972618986 | validation: 0.43283547764618746]
	TIME [epoch: 9.53 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5411277025112536		[learning rate: 0.00038231]
	Learning Rate: 0.000382315
	LOSS [training: 0.5411277025112536 | validation: 0.473250915017286]
	TIME [epoch: 9.52 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5552867488694584		[learning rate: 0.00038093]
	Learning Rate: 0.000380927
	LOSS [training: 0.5552867488694584 | validation: 0.5284744639298056]
	TIME [epoch: 9.52 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5557034102405918		[learning rate: 0.00037954]
	Learning Rate: 0.000379545
	LOSS [training: 0.5557034102405918 | validation: 0.44411862918608164]
	TIME [epoch: 9.54 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5539281425186589		[learning rate: 0.00037817]
	Learning Rate: 0.000378167
	LOSS [training: 0.5539281425186589 | validation: 0.43148666498116767]
	TIME [epoch: 9.53 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5519317992506881		[learning rate: 0.0003768]
	Learning Rate: 0.000376795
	LOSS [training: 0.5519317992506881 | validation: 0.4335384549267235]
	TIME [epoch: 9.53 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.552014079406297		[learning rate: 0.00037543]
	Learning Rate: 0.000375428
	LOSS [training: 0.552014079406297 | validation: 0.4233416684231081]
	TIME [epoch: 9.54 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5485566636064416		[learning rate: 0.00037407]
	Learning Rate: 0.000374065
	LOSS [training: 0.5485566636064416 | validation: 0.4528615882294304]
	TIME [epoch: 9.52 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5463296550130493		[learning rate: 0.00037271]
	Learning Rate: 0.000372708
	LOSS [training: 0.5463296550130493 | validation: 0.4330852583800515]
	TIME [epoch: 9.52 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5469539764507564		[learning rate: 0.00037136]
	Learning Rate: 0.000371355
	LOSS [training: 0.5469539764507564 | validation: 0.4493589817878285]
	TIME [epoch: 9.53 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5487742016027319		[learning rate: 0.00037001]
	Learning Rate: 0.000370008
	LOSS [training: 0.5487742016027319 | validation: 0.43422930689999023]
	TIME [epoch: 9.54 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5535496580285365		[learning rate: 0.00036866]
	Learning Rate: 0.000368665
	LOSS [training: 0.5535496580285365 | validation: 0.4581060114659684]
	TIME [epoch: 9.52 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5548405510979002		[learning rate: 0.00036733]
	Learning Rate: 0.000367327
	LOSS [training: 0.5548405510979002 | validation: 0.4980086259149115]
	TIME [epoch: 9.51 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5417599855328972		[learning rate: 0.00036599]
	Learning Rate: 0.000365994
	LOSS [training: 0.5417599855328972 | validation: 0.47518938319387216]
	TIME [epoch: 9.54 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.574540057342084		[learning rate: 0.00036467]
	Learning Rate: 0.000364666
	LOSS [training: 0.574540057342084 | validation: 0.5277698968819791]
	TIME [epoch: 9.52 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5646255257178197		[learning rate: 0.00036334]
	Learning Rate: 0.000363342
	LOSS [training: 0.5646255257178197 | validation: 0.5502362115368991]
	TIME [epoch: 9.52 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5624820190449051		[learning rate: 0.00036202]
	Learning Rate: 0.000362024
	LOSS [training: 0.5624820190449051 | validation: 0.45306467322593386]
	TIME [epoch: 9.52 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5472182513873147		[learning rate: 0.00036071]
	Learning Rate: 0.00036071
	LOSS [training: 0.5472182513873147 | validation: 0.4331938740336975]
	TIME [epoch: 9.54 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5484676651402313		[learning rate: 0.0003594]
	Learning Rate: 0.000359401
	LOSS [training: 0.5484676651402313 | validation: 0.481490713589062]
	TIME [epoch: 9.52 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5454842599730524		[learning rate: 0.0003581]
	Learning Rate: 0.000358096
	LOSS [training: 0.5454842599730524 | validation: 0.4979297932610205]
	TIME [epoch: 9.52 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.558297453594339		[learning rate: 0.0003568]
	Learning Rate: 0.000356797
	LOSS [training: 0.558297453594339 | validation: 0.6254753471277289]
	TIME [epoch: 9.54 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6330914983547975		[learning rate: 0.0003555]
	Learning Rate: 0.000355502
	LOSS [training: 0.6330914983547975 | validation: 0.4760362618157947]
	TIME [epoch: 9.53 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5444677718899502		[learning rate: 0.00035421]
	Learning Rate: 0.000354212
	LOSS [training: 0.5444677718899502 | validation: 0.4974328026019178]
	TIME [epoch: 9.51 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5378027724243716		[learning rate: 0.00035293]
	Learning Rate: 0.000352926
	LOSS [training: 0.5378027724243716 | validation: 0.4851696945659779]
	TIME [epoch: 9.52 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5502512957674994		[learning rate: 0.00035165]
	Learning Rate: 0.000351646
	LOSS [training: 0.5502512957674994 | validation: 0.44494824089229995]
	TIME [epoch: 9.55 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5447915313948055		[learning rate: 0.00035037]
	Learning Rate: 0.00035037
	LOSS [training: 0.5447915313948055 | validation: 0.4869063007035328]
	TIME [epoch: 9.52 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5434107780566805		[learning rate: 0.0003491]
	Learning Rate: 0.000349098
	LOSS [training: 0.5434107780566805 | validation: 0.4606982408762997]
	TIME [epoch: 9.53 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.537653832704529		[learning rate: 0.00034783]
	Learning Rate: 0.000347831
	LOSS [training: 0.537653832704529 | validation: 0.46626579896203113]
	TIME [epoch: 9.53 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5483176643131731		[learning rate: 0.00034657]
	Learning Rate: 0.000346569
	LOSS [training: 0.5483176643131731 | validation: 0.4911171576012339]
	TIME [epoch: 9.52 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5312225122901759		[learning rate: 0.00034531]
	Learning Rate: 0.000345311
	LOSS [training: 0.5312225122901759 | validation: 0.46784445643215267]
	TIME [epoch: 9.52 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.584937108090134		[learning rate: 0.00034406]
	Learning Rate: 0.000344058
	LOSS [training: 0.584937108090134 | validation: 0.5126503199144179]
	TIME [epoch: 9.52 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5665359232854009		[learning rate: 0.00034281]
	Learning Rate: 0.000342809
	LOSS [training: 0.5665359232854009 | validation: 0.4300920781983254]
	TIME [epoch: 9.53 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5224917732114729		[learning rate: 0.00034157]
	Learning Rate: 0.000341565
	LOSS [training: 0.5224917732114729 | validation: 0.4540230211743407]
	TIME [epoch: 9.53 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5422710365267257		[learning rate: 0.00034033]
	Learning Rate: 0.000340326
	LOSS [training: 0.5422710365267257 | validation: 0.43244298112673535]
	TIME [epoch: 9.52 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5346408778575744		[learning rate: 0.00033909]
	Learning Rate: 0.000339091
	LOSS [training: 0.5346408778575744 | validation: 0.44945658539523736]
	TIME [epoch: 9.54 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5290227148990028		[learning rate: 0.00033786]
	Learning Rate: 0.00033786
	LOSS [training: 0.5290227148990028 | validation: 0.4409889525796284]
	TIME [epoch: 9.52 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5195405787596042		[learning rate: 0.00033663]
	Learning Rate: 0.000336634
	LOSS [training: 0.5195405787596042 | validation: 0.4559340248372323]
	TIME [epoch: 9.52 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.545900469233586		[learning rate: 0.00033541]
	Learning Rate: 0.000335412
	LOSS [training: 0.545900469233586 | validation: 0.45795200909566836]
	TIME [epoch: 9.52 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5552548867305376		[learning rate: 0.0003342]
	Learning Rate: 0.000334195
	LOSS [training: 0.5552548867305376 | validation: 0.4512447077549153]
	TIME [epoch: 9.54 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5324827441232414		[learning rate: 0.00033298]
	Learning Rate: 0.000332982
	LOSS [training: 0.5324827441232414 | validation: 0.4870716856853592]
	TIME [epoch: 9.52 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5426842950883314		[learning rate: 0.00033177]
	Learning Rate: 0.000331774
	LOSS [training: 0.5426842950883314 | validation: 0.4321217219332315]
	TIME [epoch: 9.52 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5666224255029797		[learning rate: 0.00033057]
	Learning Rate: 0.00033057
	LOSS [training: 0.5666224255029797 | validation: 0.4661509259293332]
	TIME [epoch: 9.54 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5405915906563199		[learning rate: 0.00032937]
	Learning Rate: 0.00032937
	LOSS [training: 0.5405915906563199 | validation: 0.43736597288624496]
	TIME [epoch: 9.52 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5363793451462187		[learning rate: 0.00032817]
	Learning Rate: 0.000328175
	LOSS [training: 0.5363793451462187 | validation: 0.46257200436030477]
	TIME [epoch: 9.52 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.562161743862623		[learning rate: 0.00032698]
	Learning Rate: 0.000326984
	LOSS [training: 0.562161743862623 | validation: 0.46782292070506837]
	TIME [epoch: 9.52 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5430318962116477		[learning rate: 0.0003258]
	Learning Rate: 0.000325797
	LOSS [training: 0.5430318962116477 | validation: 0.4477847461924078]
	TIME [epoch: 9.54 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.532848860007016		[learning rate: 0.00032461]
	Learning Rate: 0.000324615
	LOSS [training: 0.532848860007016 | validation: 0.4870672263217254]
	TIME [epoch: 9.52 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5450350112155771		[learning rate: 0.00032344]
	Learning Rate: 0.000323437
	LOSS [training: 0.5450350112155771 | validation: 0.44695152763250906]
	TIME [epoch: 9.52 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5433022022806508		[learning rate: 0.00032226]
	Learning Rate: 0.000322263
	LOSS [training: 0.5433022022806508 | validation: 0.45341495272496196]
	TIME [epoch: 9.54 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5509307299052975		[learning rate: 0.00032109]
	Learning Rate: 0.000321094
	LOSS [training: 0.5509307299052975 | validation: 0.475508227304189]
	TIME [epoch: 9.52 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5551008222553757		[learning rate: 0.00031993]
	Learning Rate: 0.000319928
	LOSS [training: 0.5551008222553757 | validation: 0.4764571678897669]
	TIME [epoch: 9.52 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5480556351833916		[learning rate: 0.00031877]
	Learning Rate: 0.000318767
	LOSS [training: 0.5480556351833916 | validation: 0.4858641138357809]
	TIME [epoch: 9.52 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5508562323737941		[learning rate: 0.00031761]
	Learning Rate: 0.000317611
	LOSS [training: 0.5508562323737941 | validation: 0.5067565898026026]
	TIME [epoch: 9.53 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5505681629263		[learning rate: 0.00031646]
	Learning Rate: 0.000316458
	LOSS [training: 0.5505681629263 | validation: 0.4767815177880788]
	TIME [epoch: 9.52 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.538045704110808		[learning rate: 0.00031531]
	Learning Rate: 0.000315309
	LOSS [training: 0.538045704110808 | validation: 0.47098819914753615]
	TIME [epoch: 9.52 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5468651924682393		[learning rate: 0.00031417]
	Learning Rate: 0.000314165
	LOSS [training: 0.5468651924682393 | validation: 0.44752347606715637]
	TIME [epoch: 9.54 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5525396250987157		[learning rate: 0.00031302]
	Learning Rate: 0.000313025
	LOSS [training: 0.5525396250987157 | validation: 0.4560182808277229]
	TIME [epoch: 9.52 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5326880700988067		[learning rate: 0.00031189]
	Learning Rate: 0.000311889
	LOSS [training: 0.5326880700988067 | validation: 0.47708378683243735]
	TIME [epoch: 9.52 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5389773580783913		[learning rate: 0.00031076]
	Learning Rate: 0.000310757
	LOSS [training: 0.5389773580783913 | validation: 0.45807237716731025]
	TIME [epoch: 9.54 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5304338235989092		[learning rate: 0.00030963]
	Learning Rate: 0.000309629
	LOSS [training: 0.5304338235989092 | validation: 0.41260636388849975]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_1056.pth
	Model improved!!!
EPOCH 1057/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5274355951138074		[learning rate: 0.00030851]
	Learning Rate: 0.000308506
	LOSS [training: 0.5274355951138074 | validation: 0.4512121486680904]
	TIME [epoch: 9.52 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5495504092160898		[learning rate: 0.00030739]
	Learning Rate: 0.000307386
	LOSS [training: 0.5495504092160898 | validation: 0.4693099239619503]
	TIME [epoch: 9.52 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5377787070534348		[learning rate: 0.00030627]
	Learning Rate: 0.000306271
	LOSS [training: 0.5377787070534348 | validation: 0.522190717404798]
	TIME [epoch: 9.54 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5554348068145323		[learning rate: 0.00030516]
	Learning Rate: 0.000305159
	LOSS [training: 0.5554348068145323 | validation: 0.5398153446880832]
	TIME [epoch: 9.52 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5504490745323268		[learning rate: 0.00030405]
	Learning Rate: 0.000304052
	LOSS [training: 0.5504490745323268 | validation: 0.456819707412232]
	TIME [epoch: 9.52 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5455456016589744		[learning rate: 0.00030295]
	Learning Rate: 0.000302948
	LOSS [training: 0.5455456016589744 | validation: 0.48487090149985973]
	TIME [epoch: 9.54 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5368151447151075		[learning rate: 0.00030185]
	Learning Rate: 0.000301849
	LOSS [training: 0.5368151447151075 | validation: 0.48917433364244567]
	TIME [epoch: 9.53 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5318649427543234		[learning rate: 0.00030075]
	Learning Rate: 0.000300753
	LOSS [training: 0.5318649427543234 | validation: 0.4616893342052633]
	TIME [epoch: 9.52 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5281214466226839		[learning rate: 0.00029966]
	Learning Rate: 0.000299662
	LOSS [training: 0.5281214466226839 | validation: 0.4380423798666415]
	TIME [epoch: 9.52 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5475248412426362		[learning rate: 0.00029857]
	Learning Rate: 0.000298574
	LOSS [training: 0.5475248412426362 | validation: 0.45664313704568815]
	TIME [epoch: 9.54 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5492284702452176		[learning rate: 0.00029749]
	Learning Rate: 0.000297491
	LOSS [training: 0.5492284702452176 | validation: 0.45520635034500717]
	TIME [epoch: 9.53 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5431929579769855		[learning rate: 0.00029641]
	Learning Rate: 0.000296411
	LOSS [training: 0.5431929579769855 | validation: 0.4786584557603189]
	TIME [epoch: 9.52 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5440451394262537		[learning rate: 0.00029534]
	Learning Rate: 0.000295336
	LOSS [training: 0.5440451394262537 | validation: 0.49273907913625453]
	TIME [epoch: 9.54 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5364069040165813		[learning rate: 0.00029426]
	Learning Rate: 0.000294264
	LOSS [training: 0.5364069040165813 | validation: 0.48083378396210097]
	TIME [epoch: 9.52 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5533198015966454		[learning rate: 0.0002932]
	Learning Rate: 0.000293196
	LOSS [training: 0.5533198015966454 | validation: 0.4831866199895917]
	TIME [epoch: 9.52 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5297433317716217		[learning rate: 0.00029213]
	Learning Rate: 0.000292132
	LOSS [training: 0.5297433317716217 | validation: 0.4506296120340428]
	TIME [epoch: 9.53 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5373190049520346		[learning rate: 0.00029107]
	Learning Rate: 0.000291072
	LOSS [training: 0.5373190049520346 | validation: 0.4533371423416926]
	TIME [epoch: 9.54 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5400004351190516		[learning rate: 0.00029002]
	Learning Rate: 0.000290015
	LOSS [training: 0.5400004351190516 | validation: 0.4608173465555131]
	TIME [epoch: 9.52 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5329041608183791		[learning rate: 0.00028896]
	Learning Rate: 0.000288963
	LOSS [training: 0.5329041608183791 | validation: 0.4546962660146924]
	TIME [epoch: 9.52 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5486371663077765		[learning rate: 0.00028791]
	Learning Rate: 0.000287914
	LOSS [training: 0.5486371663077765 | validation: 0.4627823779905609]
	TIME [epoch: 9.54 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5353911207257179		[learning rate: 0.00028687]
	Learning Rate: 0.000286869
	LOSS [training: 0.5353911207257179 | validation: 0.440499974010026]
	TIME [epoch: 9.52 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5426788386873925		[learning rate: 0.00028583]
	Learning Rate: 0.000285828
	LOSS [training: 0.5426788386873925 | validation: 0.48928615751491744]
	TIME [epoch: 9.52 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.535203886493987		[learning rate: 0.00028479]
	Learning Rate: 0.000284791
	LOSS [training: 0.535203886493987 | validation: 0.47826337036988115]
	TIME [epoch: 9.52 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5357501507478665		[learning rate: 0.00028376]
	Learning Rate: 0.000283758
	LOSS [training: 0.5357501507478665 | validation: 0.4436419806243269]
	TIME [epoch: 9.54 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5442099302026702		[learning rate: 0.00028273]
	Learning Rate: 0.000282728
	LOSS [training: 0.5442099302026702 | validation: 0.4653704187854412]
	TIME [epoch: 9.51 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5371948183119556		[learning rate: 0.0002817]
	Learning Rate: 0.000281702
	LOSS [training: 0.5371948183119556 | validation: 0.4359048855388211]
	TIME [epoch: 9.53 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5362581493524851		[learning rate: 0.00028068]
	Learning Rate: 0.000280679
	LOSS [training: 0.5362581493524851 | validation: 0.4903026476165907]
	TIME [epoch: 9.54 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5469838346236804		[learning rate: 0.00027966]
	Learning Rate: 0.000279661
	LOSS [training: 0.5469838346236804 | validation: 0.46784138853407087]
	TIME [epoch: 9.53 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.528652062066422		[learning rate: 0.00027865]
	Learning Rate: 0.000278646
	LOSS [training: 0.528652062066422 | validation: 0.45174434445698214]
	TIME [epoch: 9.52 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5470122314404126		[learning rate: 0.00027763]
	Learning Rate: 0.000277635
	LOSS [training: 0.5470122314404126 | validation: 0.45878603483555663]
	TIME [epoch: 9.53 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5451240470462031		[learning rate: 0.00027663]
	Learning Rate: 0.000276627
	LOSS [training: 0.5451240470462031 | validation: 0.44747220442062424]
	TIME [epoch: 9.54 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5457101842050178		[learning rate: 0.00027562]
	Learning Rate: 0.000275623
	LOSS [training: 0.5457101842050178 | validation: 0.44413735636879936]
	TIME [epoch: 9.52 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5435401046640709		[learning rate: 0.00027462]
	Learning Rate: 0.000274623
	LOSS [training: 0.5435401046640709 | validation: 0.4460748605987248]
	TIME [epoch: 9.53 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.551724585148019		[learning rate: 0.00027363]
	Learning Rate: 0.000273626
	LOSS [training: 0.551724585148019 | validation: 0.4720825397961954]
	TIME [epoch: 9.54 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5546496429093277		[learning rate: 0.00027263]
	Learning Rate: 0.000272633
	LOSS [training: 0.5546496429093277 | validation: 0.4359747557904135]
	TIME [epoch: 9.53 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5351550412930564		[learning rate: 0.00027164]
	Learning Rate: 0.000271644
	LOSS [training: 0.5351550412930564 | validation: 0.5082622997245604]
	TIME [epoch: 9.52 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5425363101514965		[learning rate: 0.00027066]
	Learning Rate: 0.000270658
	LOSS [training: 0.5425363101514965 | validation: 0.45533969389986395]
	TIME [epoch: 9.52 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5362654149868691		[learning rate: 0.00026968]
	Learning Rate: 0.000269676
	LOSS [training: 0.5362654149868691 | validation: 0.46899468823028045]
	TIME [epoch: 9.54 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5351339009955781		[learning rate: 0.0002687]
	Learning Rate: 0.000268697
	LOSS [training: 0.5351339009955781 | validation: 0.42321824062127095]
	TIME [epoch: 9.53 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5436011254967321		[learning rate: 0.00026772]
	Learning Rate: 0.000267722
	LOSS [training: 0.5436011254967321 | validation: 0.4447879250560763]
	TIME [epoch: 9.52 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5314667837085182		[learning rate: 0.00026675]
	Learning Rate: 0.000266751
	LOSS [training: 0.5314667837085182 | validation: 0.4679548291874142]
	TIME [epoch: 9.54 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5311123963017407		[learning rate: 0.00026578]
	Learning Rate: 0.000265782
	LOSS [training: 0.5311123963017407 | validation: 0.4450117785299592]
	TIME [epoch: 9.52 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.535290278297696		[learning rate: 0.00026482]
	Learning Rate: 0.000264818
	LOSS [training: 0.535290278297696 | validation: 0.4340967979741226]
	TIME [epoch: 9.52 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5344801992905669		[learning rate: 0.00026386]
	Learning Rate: 0.000263857
	LOSS [training: 0.5344801992905669 | validation: 0.4297167219314036]
	TIME [epoch: 9.52 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5333581347820829		[learning rate: 0.0002629]
	Learning Rate: 0.000262899
	LOSS [training: 0.5333581347820829 | validation: 0.43782877178807894]
	TIME [epoch: 9.53 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5224221093619		[learning rate: 0.00026195]
	Learning Rate: 0.000261945
	LOSS [training: 0.5224221093619 | validation: 0.4857114913041358]
	TIME [epoch: 9.52 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5391732281193481		[learning rate: 0.00026099]
	Learning Rate: 0.000260995
	LOSS [training: 0.5391732281193481 | validation: 0.42298144182614716]
	TIME [epoch: 9.52 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5344741786391183		[learning rate: 0.00026005]
	Learning Rate: 0.000260047
	LOSS [training: 0.5344741786391183 | validation: 0.45117074293187104]
	TIME [epoch: 9.54 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.523692750710659		[learning rate: 0.0002591]
	Learning Rate: 0.000259104
	LOSS [training: 0.523692750710659 | validation: 0.4336751412781722]
	TIME [epoch: 9.52 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5324914625259334		[learning rate: 0.00025816]
	Learning Rate: 0.000258163
	LOSS [training: 0.5324914625259334 | validation: 0.43906020628996617]
	TIME [epoch: 9.52 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.534953647687715		[learning rate: 0.00025723]
	Learning Rate: 0.000257227
	LOSS [training: 0.534953647687715 | validation: 0.45770484582111365]
	TIME [epoch: 9.52 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5368489672873354		[learning rate: 0.00025629]
	Learning Rate: 0.000256293
	LOSS [training: 0.5368489672873354 | validation: 0.46585832658497595]
	TIME [epoch: 9.54 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5476953033378852		[learning rate: 0.00025536]
	Learning Rate: 0.000255363
	LOSS [training: 0.5476953033378852 | validation: 0.44361173677665]
	TIME [epoch: 9.52 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5426681243712074		[learning rate: 0.00025444]
	Learning Rate: 0.000254436
	LOSS [training: 0.5426681243712074 | validation: 0.4361498116491159]
	TIME [epoch: 9.52 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5388839625479094		[learning rate: 0.00025351]
	Learning Rate: 0.000253513
	LOSS [training: 0.5388839625479094 | validation: 0.42857370239912695]
	TIME [epoch: 9.55 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5352149380582001		[learning rate: 0.00025259]
	Learning Rate: 0.000252593
	LOSS [training: 0.5352149380582001 | validation: 0.42697127665881235]
	TIME [epoch: 9.52 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5386953809636159		[learning rate: 0.00025168]
	Learning Rate: 0.000251676
	LOSS [training: 0.5386953809636159 | validation: 0.47101464464846116]
	TIME [epoch: 9.53 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5329008320025317		[learning rate: 0.00025076]
	Learning Rate: 0.000250763
	LOSS [training: 0.5329008320025317 | validation: 0.46879137908188795]
	TIME [epoch: 9.53 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5361725408180321		[learning rate: 0.00024985]
	Learning Rate: 0.000249853
	LOSS [training: 0.5361725408180321 | validation: 0.42507201148152446]
	TIME [epoch: 9.53 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5402352577665481		[learning rate: 0.00024895]
	Learning Rate: 0.000248946
	LOSS [training: 0.5402352577665481 | validation: 0.4780730469216627]
	TIME [epoch: 9.52 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5415985601124278		[learning rate: 0.00024804]
	Learning Rate: 0.000248043
	LOSS [training: 0.5415985601124278 | validation: 0.4536697180278585]
	TIME [epoch: 9.52 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5553524400043217		[learning rate: 0.00024714]
	Learning Rate: 0.000247142
	LOSS [training: 0.5553524400043217 | validation: 0.47968427905368155]
	TIME [epoch: 9.53 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5603554310161188		[learning rate: 0.00024625]
	Learning Rate: 0.000246246
	LOSS [training: 0.5603554310161188 | validation: 0.5411044222413124]
	TIME [epoch: 9.52 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5732484949553248		[learning rate: 0.00024535]
	Learning Rate: 0.000245352
	LOSS [training: 0.5732484949553248 | validation: 0.4897408748419707]
	TIME [epoch: 9.51 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5344189530295522		[learning rate: 0.00024446]
	Learning Rate: 0.000244462
	LOSS [training: 0.5344189530295522 | validation: 0.46821239348927296]
	TIME [epoch: 9.53 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5413185745102315		[learning rate: 0.00024357]
	Learning Rate: 0.000243574
	LOSS [training: 0.5413185745102315 | validation: 0.4874678844103904]
	TIME [epoch: 9.53 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5300093992815835		[learning rate: 0.00024269]
	Learning Rate: 0.00024269
	LOSS [training: 0.5300093992815835 | validation: 0.47418690402502806]
	TIME [epoch: 9.52 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5416551441639258		[learning rate: 0.00024181]
	Learning Rate: 0.00024181
	LOSS [training: 0.5416551441639258 | validation: 0.4588356960067078]
	TIME [epoch: 9.52 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5474668594544769		[learning rate: 0.00024093]
	Learning Rate: 0.000240932
	LOSS [training: 0.5474668594544769 | validation: 0.4901004612149021]
	TIME [epoch: 9.54 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.543756587621305		[learning rate: 0.00024006]
	Learning Rate: 0.000240058
	LOSS [training: 0.543756587621305 | validation: 0.4382354341526314]
	TIME [epoch: 9.52 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5418428363842248		[learning rate: 0.00023919]
	Learning Rate: 0.000239187
	LOSS [training: 0.5418428363842248 | validation: 0.44656777809041986]
	TIME [epoch: 9.52 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5393546942348177		[learning rate: 0.00023832]
	Learning Rate: 0.000238319
	LOSS [training: 0.5393546942348177 | validation: 0.4243694285764438]
	TIME [epoch: 9.53 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5481361331641776		[learning rate: 0.00023745]
	Learning Rate: 0.000237454
	LOSS [training: 0.5481361331641776 | validation: 0.4378679317578056]
	TIME [epoch: 9.53 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5306430715515333		[learning rate: 0.00023659]
	Learning Rate: 0.000236592
	LOSS [training: 0.5306430715515333 | validation: 0.4488070668359194]
	TIME [epoch: 9.52 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.543498264065684		[learning rate: 0.00023573]
	Learning Rate: 0.000235733
	LOSS [training: 0.543498264065684 | validation: 0.44290604965869035]
	TIME [epoch: 9.52 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5264972363490112		[learning rate: 0.00023488]
	Learning Rate: 0.000234878
	LOSS [training: 0.5264972363490112 | validation: 0.4543499139288874]
	TIME [epoch: 9.54 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5506333269320312		[learning rate: 0.00023403]
	Learning Rate: 0.000234026
	LOSS [training: 0.5506333269320312 | validation: 0.42221712053257177]
	TIME [epoch: 9.52 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5317855316970477		[learning rate: 0.00023318]
	Learning Rate: 0.000233176
	LOSS [training: 0.5317855316970477 | validation: 0.45404513564346216]
	TIME [epoch: 9.51 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5347570769809977		[learning rate: 0.00023233]
	Learning Rate: 0.00023233
	LOSS [training: 0.5347570769809977 | validation: 0.4513575358654761]
	TIME [epoch: 9.54 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5184136726629207		[learning rate: 0.00023149]
	Learning Rate: 0.000231487
	LOSS [training: 0.5184136726629207 | validation: 0.4592153250045934]
	TIME [epoch: 9.53 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5342918257303407		[learning rate: 0.00023065]
	Learning Rate: 0.000230647
	LOSS [training: 0.5342918257303407 | validation: 0.45285247849692495]
	TIME [epoch: 9.52 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5539055652788184		[learning rate: 0.00022981]
	Learning Rate: 0.00022981
	LOSS [training: 0.5539055652788184 | validation: 0.4391361849282239]
	TIME [epoch: 9.51 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5396442944990135		[learning rate: 0.00022898]
	Learning Rate: 0.000228976
	LOSS [training: 0.5396442944990135 | validation: 0.4337895888566268]
	TIME [epoch: 9.54 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5401390142158412		[learning rate: 0.00022814]
	Learning Rate: 0.000228145
	LOSS [training: 0.5401390142158412 | validation: 0.40990513428476505]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study206/model_tr_study206_r0_20240219_235423/states/model_tr_study206_1140.pth
	Model improved!!!
EPOCH 1141/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5438014852932043		[learning rate: 0.00022732]
	Learning Rate: 0.000227317
	LOSS [training: 0.5438014852932043 | validation: 0.4577469418247166]
	TIME [epoch: 9.52 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5399861312700034		[learning rate: 0.00022649]
	Learning Rate: 0.000226492
	LOSS [training: 0.5399861312700034 | validation: 0.4658607331829404]
	TIME [epoch: 9.54 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.553836067932831		[learning rate: 0.00022567]
	Learning Rate: 0.00022567
	LOSS [training: 0.553836067932831 | validation: 0.44515301714460564]
	TIME [epoch: 9.53 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5522518765054106		[learning rate: 0.00022485]
	Learning Rate: 0.000224851
	LOSS [training: 0.5522518765054106 | validation: 0.46309897405897277]
	TIME [epoch: 9.52 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5338632219621915		[learning rate: 0.00022403]
	Learning Rate: 0.000224035
	LOSS [training: 0.5338632219621915 | validation: 0.4454373264987265]
	TIME [epoch: 9.52 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5261968652872675		[learning rate: 0.00022322]
	Learning Rate: 0.000223222
	LOSS [training: 0.5261968652872675 | validation: 0.4552437572801826]
	TIME [epoch: 9.55 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5347180825403743		[learning rate: 0.00022241]
	Learning Rate: 0.000222412
	LOSS [training: 0.5347180825403743 | validation: 0.4271906723516238]
	TIME [epoch: 9.53 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5245767508841885		[learning rate: 0.0002216]
	Learning Rate: 0.000221605
	LOSS [training: 0.5245767508841885 | validation: 0.446550147016103]
	TIME [epoch: 9.52 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5169896534913632		[learning rate: 0.0002208]
	Learning Rate: 0.0002208
	LOSS [training: 0.5169896534913632 | validation: 0.44260679619601084]
	TIME [epoch: 9.54 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5342597643710361		[learning rate: 0.00022]
	Learning Rate: 0.000219999
	LOSS [training: 0.5342597643710361 | validation: 0.4589639128849033]
	TIME [epoch: 9.54 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5328128211798362		[learning rate: 0.0002192]
	Learning Rate: 0.000219201
	LOSS [training: 0.5328128211798362 | validation: 0.4571570080823988]
	TIME [epoch: 9.53 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5386583079400412		[learning rate: 0.00021841]
	Learning Rate: 0.000218405
	LOSS [training: 0.5386583079400412 | validation: 0.43800600470856516]
	TIME [epoch: 9.52 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5436956815871523		[learning rate: 0.00021761]
	Learning Rate: 0.000217613
	LOSS [training: 0.5436956815871523 | validation: 0.46286863975643067]
	TIME [epoch: 9.55 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5422457228850508		[learning rate: 0.00021682]
	Learning Rate: 0.000216823
	LOSS [training: 0.5422457228850508 | validation: 0.4569639938259968]
	TIME [epoch: 9.53 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5470261906574045		[learning rate: 0.00021604]
	Learning Rate: 0.000216036
	LOSS [training: 0.5470261906574045 | validation: 0.4659999277676932]
	TIME [epoch: 9.52 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5402973732386736		[learning rate: 0.00021525]
	Learning Rate: 0.000215252
	LOSS [training: 0.5402973732386736 | validation: 0.4723048779242231]
	TIME [epoch: 9.54 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5475667762643628		[learning rate: 0.00021447]
	Learning Rate: 0.000214471
	LOSS [training: 0.5475667762643628 | validation: 0.4462836950812168]
	TIME [epoch: 9.53 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5361390595954744		[learning rate: 0.00021369]
	Learning Rate: 0.000213693
	LOSS [training: 0.5361390595954744 | validation: 0.46001514689680173]
	TIME [epoch: 9.52 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5335838669805779		[learning rate: 0.00021292]
	Learning Rate: 0.000212917
	LOSS [training: 0.5335838669805779 | validation: 0.4472545254537137]
	TIME [epoch: 9.52 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5381061507696965		[learning rate: 0.00021214]
	Learning Rate: 0.000212144
	LOSS [training: 0.5381061507696965 | validation: 0.4934076837441201]
	TIME [epoch: 9.55 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5479339517698273		[learning rate: 0.00021137]
	Learning Rate: 0.000211375
	LOSS [training: 0.5479339517698273 | validation: 0.5183359912882631]
	TIME [epoch: 9.52 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5543855515881297		[learning rate: 0.00021061]
	Learning Rate: 0.000210607
	LOSS [training: 0.5543855515881297 | validation: 0.45749420019932857]
	TIME [epoch: 9.53 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5344186855190274		[learning rate: 0.00020984]
	Learning Rate: 0.000209843
	LOSS [training: 0.5344186855190274 | validation: 0.4394673570131761]
	TIME [epoch: 9.54 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5331441931705002		[learning rate: 0.00020908]
	Learning Rate: 0.000209082
	LOSS [training: 0.5331441931705002 | validation: 0.4676113848698553]
	TIME [epoch: 9.53 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5325164918187809		[learning rate: 0.00020832]
	Learning Rate: 0.000208323
	LOSS [training: 0.5325164918187809 | validation: 0.45672146844661626]
	TIME [epoch: 9.52 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5456112941800502		[learning rate: 0.00020757]
	Learning Rate: 0.000207567
	LOSS [training: 0.5456112941800502 | validation: 0.46773159721703195]
	TIME [epoch: 9.53 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5477729841660879		[learning rate: 0.00020681]
	Learning Rate: 0.000206814
	LOSS [training: 0.5477729841660879 | validation: 0.44455353740548903]
	TIME [epoch: 9.55 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5379499497213431		[learning rate: 0.00020606]
	Learning Rate: 0.000206063
	LOSS [training: 0.5379499497213431 | validation: 0.44472259908146017]
	TIME [epoch: 9.52 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.54090935680597		[learning rate: 0.00020532]
	Learning Rate: 0.000205315
	LOSS [training: 0.54090935680597 | validation: 0.46722258366765573]
	TIME [epoch: 9.52 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5251406329061656		[learning rate: 0.00020457]
	Learning Rate: 0.00020457
	LOSS [training: 0.5251406329061656 | validation: 0.466790158017431]
	TIME [epoch: 9.54 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5354047246148683		[learning rate: 0.00020383]
	Learning Rate: 0.000203828
	LOSS [training: 0.5354047246148683 | validation: 0.47958917492947606]
	TIME [epoch: 9.53 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.535444139366932		[learning rate: 0.00020309]
	Learning Rate: 0.000203088
	LOSS [training: 0.535444139366932 | validation: 0.46790106477156046]
	TIME [epoch: 9.52 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5413630060702672		[learning rate: 0.00020235]
	Learning Rate: 0.000202351
	LOSS [training: 0.5413630060702672 | validation: 0.4445865861594679]
	TIME [epoch: 9.52 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5417640647317974		[learning rate: 0.00020162]
	Learning Rate: 0.000201617
	LOSS [training: 0.5417640647317974 | validation: 0.42410646586264245]
	TIME [epoch: 9.54 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.533668600181586		[learning rate: 0.00020088]
	Learning Rate: 0.000200885
	LOSS [training: 0.533668600181586 | validation: 0.4604490598343924]
	TIME [epoch: 9.52 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5377936150595829		[learning rate: 0.00020016]
	Learning Rate: 0.000200156
	LOSS [training: 0.5377936150595829 | validation: 0.43494094385308596]
	TIME [epoch: 9.52 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5351901009402383		[learning rate: 0.00019943]
	Learning Rate: 0.00019943
	LOSS [training: 0.5351901009402383 | validation: 0.4264368328414103]
	TIME [epoch: 9.54 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5188885547263813		[learning rate: 0.00019871]
	Learning Rate: 0.000198706
	LOSS [training: 0.5188885547263813 | validation: 0.4338027080935082]
	TIME [epoch: 9.53 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5398994498325788		[learning rate: 0.00019798]
	Learning Rate: 0.000197985
	LOSS [training: 0.5398994498325788 | validation: 0.47258297414339195]
	TIME [epoch: 9.52 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5395941337877436		[learning rate: 0.00019727]
	Learning Rate: 0.000197266
	LOSS [training: 0.5395941337877436 | validation: 0.4582620779092781]
	TIME [epoch: 9.53 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5408888799151024		[learning rate: 0.00019655]
	Learning Rate: 0.00019655
	LOSS [training: 0.5408888799151024 | validation: 0.4476794089109133]
	TIME [epoch: 9.54 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5329262471964664		[learning rate: 0.00019584]
	Learning Rate: 0.000195837
	LOSS [training: 0.5329262471964664 | validation: 0.43664312763150875]
	TIME [epoch: 9.53 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5299441056277459		[learning rate: 0.00019513]
	Learning Rate: 0.000195126
	LOSS [training: 0.5299441056277459 | validation: 0.43337781759390026]
	TIME [epoch: 9.53 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5272604072780687		[learning rate: 0.00019442]
	Learning Rate: 0.000194418
	LOSS [training: 0.5272604072780687 | validation: 0.4535754387515703]
	TIME [epoch: 9.54 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5125185207606676		[learning rate: 0.00019371]
	Learning Rate: 0.000193713
	LOSS [training: 0.5125185207606676 | validation: 0.43797528691079174]
	TIME [epoch: 9.53 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5235277241605507		[learning rate: 0.00019301]
	Learning Rate: 0.00019301
	LOSS [training: 0.5235277241605507 | validation: 0.4350069628638579]
	TIME [epoch: 9.52 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5282884257063085		[learning rate: 0.00019231]
	Learning Rate: 0.000192309
	LOSS [training: 0.5282884257063085 | validation: 0.44752053692244326]
	TIME [epoch: 9.52 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5373175507701908		[learning rate: 0.00019161]
	Learning Rate: 0.000191611
	LOSS [training: 0.5373175507701908 | validation: 0.42265806821101676]
	TIME [epoch: 9.54 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5392203383581488		[learning rate: 0.00019092]
	Learning Rate: 0.000190916
	LOSS [training: 0.5392203383581488 | validation: 0.42902441548094794]
	TIME [epoch: 9.53 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5397279563703219		[learning rate: 0.00019022]
	Learning Rate: 0.000190223
	LOSS [training: 0.5397279563703219 | validation: 0.4366274666796005]
	TIME [epoch: 9.53 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5262237975467892		[learning rate: 0.00018953]
	Learning Rate: 0.000189533
	LOSS [training: 0.5262237975467892 | validation: 0.4513759121165407]
	TIME [epoch: 9.54 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5250230421846463		[learning rate: 0.00018884]
	Learning Rate: 0.000188845
	LOSS [training: 0.5250230421846463 | validation: 0.47757800115374066]
	TIME [epoch: 9.53 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5358994785837892		[learning rate: 0.00018816]
	Learning Rate: 0.00018816
	LOSS [training: 0.5358994785837892 | validation: 0.47530970714287735]
	TIME [epoch: 9.53 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5415202248887331		[learning rate: 0.00018748]
	Learning Rate: 0.000187477
	LOSS [training: 0.5415202248887331 | validation: 0.45245268286892015]
	TIME [epoch: 9.53 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5295137302223643		[learning rate: 0.0001868]
	Learning Rate: 0.000186796
	LOSS [training: 0.5295137302223643 | validation: 0.4662009052437863]
	TIME [epoch: 9.54 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5399514890391512		[learning rate: 0.00018612]
	Learning Rate: 0.000186119
	LOSS [training: 0.5399514890391512 | validation: 0.45180924940116046]
	TIME [epoch: 9.52 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5329660604868537		[learning rate: 0.00018544]
	Learning Rate: 0.000185443
	LOSS [training: 0.5329660604868537 | validation: 0.4701747673170435]
	TIME [epoch: 9.53 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5323565514521797		[learning rate: 0.00018477]
	Learning Rate: 0.00018477
	LOSS [training: 0.5323565514521797 | validation: 0.449981157115972]
	TIME [epoch: 9.54 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5367915514208116		[learning rate: 0.0001841]
	Learning Rate: 0.000184099
	LOSS [training: 0.5367915514208116 | validation: 0.4549772131575033]
	TIME [epoch: 9.53 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5577293776140215		[learning rate: 0.00018343]
	Learning Rate: 0.000183431
	LOSS [training: 0.5577293776140215 | validation: 0.47472291021155694]
	TIME [epoch: 9.53 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5315507606598617		[learning rate: 0.00018277]
	Learning Rate: 0.000182766
	LOSS [training: 0.5315507606598617 | validation: 0.4485813072840478]
	TIME [epoch: 9.54 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5344219228906317		[learning rate: 0.0001821]
	Learning Rate: 0.000182102
	LOSS [training: 0.5344219228906317 | validation: 0.4664040869595678]
	TIME [epoch: 9.53 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5242059734877731		[learning rate: 0.00018144]
	Learning Rate: 0.000181442
	LOSS [training: 0.5242059734877731 | validation: 0.4519352010667741]
	TIME [epoch: 9.53 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5410301515509872		[learning rate: 0.00018078]
	Learning Rate: 0.000180783
	LOSS [training: 0.5410301515509872 | validation: 0.46114961655838815]
	TIME [epoch: 9.53 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.538270314895237		[learning rate: 0.00018013]
	Learning Rate: 0.000180127
	LOSS [training: 0.538270314895237 | validation: 0.465634851114589]
	TIME [epoch: 9.55 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5290109544356139		[learning rate: 0.00017947]
	Learning Rate: 0.000179473
	LOSS [training: 0.5290109544356139 | validation: 0.4717061725373147]
	TIME [epoch: 9.52 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5251769715715306		[learning rate: 0.00017882]
	Learning Rate: 0.000178822
	LOSS [training: 0.5251769715715306 | validation: 0.45094263907591936]
	TIME [epoch: 9.53 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5242410809364206		[learning rate: 0.00017817]
	Learning Rate: 0.000178173
	LOSS [training: 0.5242410809364206 | validation: 0.46150264537629954]
	TIME [epoch: 9.54 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5668989180748821		[learning rate: 0.00017753]
	Learning Rate: 0.000177526
	LOSS [training: 0.5668989180748821 | validation: 0.4369079888165618]
	TIME [epoch: 9.54 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5333171984908447		[learning rate: 0.00017688]
	Learning Rate: 0.000176882
	LOSS [training: 0.5333171984908447 | validation: 0.43740609466495883]
	TIME [epoch: 9.52 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5573208461959072		[learning rate: 0.00017624]
	Learning Rate: 0.00017624
	LOSS [training: 0.5573208461959072 | validation: 0.4468230061409305]
	TIME [epoch: 9.52 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5364750657359395		[learning rate: 0.0001756]
	Learning Rate: 0.000175601
	LOSS [training: 0.5364750657359395 | validation: 0.44294894505511806]
	TIME [epoch: 9.55 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5445771640701373		[learning rate: 0.00017496]
	Learning Rate: 0.000174964
	LOSS [training: 0.5445771640701373 | validation: 0.45948661141424624]
	TIME [epoch: 9.53 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5340592052561217		[learning rate: 0.00017433]
	Learning Rate: 0.000174329
	LOSS [training: 0.5340592052561217 | validation: 0.44848927413501555]
	TIME [epoch: 9.53 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5204489379696727		[learning rate: 0.0001737]
	Learning Rate: 0.000173696
	LOSS [training: 0.5204489379696727 | validation: 0.4540259507059399]
	TIME [epoch: 9.54 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.520678220230778		[learning rate: 0.00017307]
	Learning Rate: 0.000173066
	LOSS [training: 0.520678220230778 | validation: 0.4553804181899592]
	TIME [epoch: 9.54 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5265089087804464		[learning rate: 0.00017244]
	Learning Rate: 0.000172437
	LOSS [training: 0.5265089087804464 | validation: 0.4737257590833332]
	TIME [epoch: 9.53 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5424415406480128		[learning rate: 0.00017181]
	Learning Rate: 0.000171812
	LOSS [training: 0.5424415406480128 | validation: 0.4827900361430082]
	TIME [epoch: 9.53 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5310903624890451		[learning rate: 0.00017119]
	Learning Rate: 0.000171188
	LOSS [training: 0.5310903624890451 | validation: 0.4748301391051316]
	TIME [epoch: 9.54 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5409061775207926		[learning rate: 0.00017057]
	Learning Rate: 0.000170567
	LOSS [training: 0.5409061775207926 | validation: 0.46740243457089603]
	TIME [epoch: 9.52 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5328869441181573		[learning rate: 0.00016995]
	Learning Rate: 0.000169948
	LOSS [training: 0.5328869441181573 | validation: 0.4609783900384602]
	TIME [epoch: 9.52 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5245572817244957		[learning rate: 0.00016933]
	Learning Rate: 0.000169331
	LOSS [training: 0.5245572817244957 | validation: 0.4743622487099329]
	TIME [epoch: 9.54 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5295654701542613		[learning rate: 0.00016872]
	Learning Rate: 0.000168717
	LOSS [training: 0.5295654701542613 | validation: 0.4586980219307495]
	TIME [epoch: 9.53 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5470282921842097		[learning rate: 0.0001681]
	Learning Rate: 0.000168104
	LOSS [training: 0.5470282921842097 | validation: 0.5435756677518259]
	TIME [epoch: 9.52 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5744846401120332		[learning rate: 0.00016749]
	Learning Rate: 0.000167494
	LOSS [training: 0.5744846401120332 | validation: 0.4689106185353872]
	TIME [epoch: 9.52 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.513465010137061		[learning rate: 0.00016689]
	Learning Rate: 0.000166886
	LOSS [training: 0.513465010137061 | validation: 0.4696778540455415]
	TIME [epoch: 9.55 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5247861856461755		[learning rate: 0.00016628]
	Learning Rate: 0.000166281
	LOSS [training: 0.5247861856461755 | validation: 0.4589236151092949]
	TIME [epoch: 9.52 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5343040907378467		[learning rate: 0.00016568]
	Learning Rate: 0.000165677
	LOSS [training: 0.5343040907378467 | validation: 0.4737752646132527]
	TIME [epoch: 9.52 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5278914564220196		[learning rate: 0.00016508]
	Learning Rate: 0.000165076
	LOSS [training: 0.5278914564220196 | validation: 0.46031753512080414]
	TIME [epoch: 9.54 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5302746817571106		[learning rate: 0.00016448]
	Learning Rate: 0.000164477
	LOSS [training: 0.5302746817571106 | validation: 0.4513372464446455]
	TIME [epoch: 9.53 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.532166498835992		[learning rate: 0.00016388]
	Learning Rate: 0.00016388
	LOSS [training: 0.532166498835992 | validation: 0.44308688434255006]
	TIME [epoch: 9.52 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5307983526401807		[learning rate: 0.00016329]
	Learning Rate: 0.000163285
	LOSS [training: 0.5307983526401807 | validation: 0.49176259001052425]
	TIME [epoch: 9.53 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5324878589503055		[learning rate: 0.00016269]
	Learning Rate: 0.000162693
	LOSS [training: 0.5324878589503055 | validation: 0.447456698362136]
	TIME [epoch: 9.55 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.530521154017591		[learning rate: 0.0001621]
	Learning Rate: 0.000162102
	LOSS [training: 0.530521154017591 | validation: 0.45030700328523254]
	TIME [epoch: 9.52 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5292153118009153		[learning rate: 0.00016151]
	Learning Rate: 0.000161514
	LOSS [training: 0.5292153118009153 | validation: 0.44827583002512483]
	TIME [epoch: 9.52 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5235161644930084		[learning rate: 0.00016093]
	Learning Rate: 0.000160928
	LOSS [training: 0.5235161644930084 | validation: 0.4532397222938236]
	TIME [epoch: 9.54 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5403615680031735		[learning rate: 0.00016034]
	Learning Rate: 0.000160344
	LOSS [training: 0.5403615680031735 | validation: 0.477430113108135]
	TIME [epoch: 9.53 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5366842404007923		[learning rate: 0.00015976]
	Learning Rate: 0.000159762
	LOSS [training: 0.5366842404007923 | validation: 0.45940793131061325]
	TIME [epoch: 9.52 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5394564476786882		[learning rate: 0.00015918]
	Learning Rate: 0.000159182
	LOSS [training: 0.5394564476786882 | validation: 0.45671220061880946]
	TIME [epoch: 9.53 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5274767830151793		[learning rate: 0.0001586]
	Learning Rate: 0.000158605
	LOSS [training: 0.5274767830151793 | validation: 0.43365228003890627]
	TIME [epoch: 9.54 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5375851310689516		[learning rate: 0.00015803]
	Learning Rate: 0.000158029
	LOSS [training: 0.5375851310689516 | validation: 0.4390374840960395]
	TIME [epoch: 9.53 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5320033890532712		[learning rate: 0.00015746]
	Learning Rate: 0.000157456
	LOSS [training: 0.5320033890532712 | validation: 0.44054635047892915]
	TIME [epoch: 9.52 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5200180416612046		[learning rate: 0.00015688]
	Learning Rate: 0.000156884
	LOSS [training: 0.5200180416612046 | validation: 0.4518948493530271]
	TIME [epoch: 9.54 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5316407510201986		[learning rate: 0.00015631]
	Learning Rate: 0.000156315
	LOSS [training: 0.5316407510201986 | validation: 0.44897442481206656]
	TIME [epoch: 9.53 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5217282796080237		[learning rate: 0.00015575]
	Learning Rate: 0.000155748
	LOSS [training: 0.5217282796080237 | validation: 0.45350019735584063]
	TIME [epoch: 9.53 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5324441553444426		[learning rate: 0.00015518]
	Learning Rate: 0.000155182
	LOSS [training: 0.5324441553444426 | validation: 0.46931474739448775]
	TIME [epoch: 9.52 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5417012786293504		[learning rate: 0.00015462]
	Learning Rate: 0.000154619
	LOSS [training: 0.5417012786293504 | validation: 0.46482866028175907]
	TIME [epoch: 9.54 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5325512759030098		[learning rate: 0.00015406]
	Learning Rate: 0.000154058
	LOSS [training: 0.5325512759030098 | validation: 0.4506024971168426]
	TIME [epoch: 9.52 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5398129844143474		[learning rate: 0.0001535]
	Learning Rate: 0.000153499
	LOSS [training: 0.5398129844143474 | validation: 0.45090026197580685]
	TIME [epoch: 9.52 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5255411867924218		[learning rate: 0.00015294]
	Learning Rate: 0.000152942
	LOSS [training: 0.5255411867924218 | validation: 0.4331831476753291]
	TIME [epoch: 9.54 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5349575846935932		[learning rate: 0.00015239]
	Learning Rate: 0.000152387
	LOSS [training: 0.5349575846935932 | validation: 0.4350484837424262]
	TIME [epoch: 9.53 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5220781776472417		[learning rate: 0.00015183]
	Learning Rate: 0.000151834
	LOSS [training: 0.5220781776472417 | validation: 0.44292403848546286]
	TIME [epoch: 9.53 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5379417110059805		[learning rate: 0.00015128]
	Learning Rate: 0.000151283
	LOSS [training: 0.5379417110059805 | validation: 0.4583532652207066]
	TIME [epoch: 9.53 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5344355784444242		[learning rate: 0.00015073]
	Learning Rate: 0.000150734
	LOSS [training: 0.5344355784444242 | validation: 0.4620822285864656]
	TIME [epoch: 9.54 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5334675189359863		[learning rate: 0.00015019]
	Learning Rate: 0.000150187
	LOSS [training: 0.5334675189359863 | validation: 0.4464610910514727]
	TIME [epoch: 9.52 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5505429972691209		[learning rate: 0.00014964]
	Learning Rate: 0.000149642
	LOSS [training: 0.5505429972691209 | validation: 0.4353795783380998]
	TIME [epoch: 9.52 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5237912177009283		[learning rate: 0.0001491]
	Learning Rate: 0.000149099
	LOSS [training: 0.5237912177009283 | validation: 0.4541296378263613]
	TIME [epoch: 9.55 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5350749031223323		[learning rate: 0.00014856]
	Learning Rate: 0.000148558
	LOSS [training: 0.5350749031223323 | validation: 0.47858551306754976]
	TIME [epoch: 9.53 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5326337273041316		[learning rate: 0.00014802]
	Learning Rate: 0.000148018
	LOSS [training: 0.5326337273041316 | validation: 0.47978402060752684]
	TIME [epoch: 9.53 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5505659035174432		[learning rate: 0.00014748]
	Learning Rate: 0.000147481
	LOSS [training: 0.5505659035174432 | validation: 0.4619616660205572]
	TIME [epoch: 9.53 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5283912556391981		[learning rate: 0.00014695]
	Learning Rate: 0.000146946
	LOSS [training: 0.5283912556391981 | validation: 0.4543278527932353]
	TIME [epoch: 9.55 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5231133441641024		[learning rate: 0.00014641]
	Learning Rate: 0.000146413
	LOSS [training: 0.5231133441641024 | validation: 0.44724902266758626]
	TIME [epoch: 9.53 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5268859346161434		[learning rate: 0.00014588]
	Learning Rate: 0.000145881
	LOSS [training: 0.5268859346161434 | validation: 0.4657209010383941]
	TIME [epoch: 9.52 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5297807494462596		[learning rate: 0.00014535]
	Learning Rate: 0.000145352
	LOSS [training: 0.5297807494462596 | validation: 0.46190831946477184]
	TIME [epoch: 9.55 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5329160281340618		[learning rate: 0.00014482]
	Learning Rate: 0.000144825
	LOSS [training: 0.5329160281340618 | validation: 0.4648171669776754]
	TIME [epoch: 9.53 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5283372427366985		[learning rate: 0.0001443]
	Learning Rate: 0.000144299
	LOSS [training: 0.5283372427366985 | validation: 0.4703695745140661]
	TIME [epoch: 9.51 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5165264524959173		[learning rate: 0.00014378]
	Learning Rate: 0.000143775
	LOSS [training: 0.5165264524959173 | validation: 0.47714195632655476]
	TIME [epoch: 9.54 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5400733540706455		[learning rate: 0.00014325]
	Learning Rate: 0.000143253
	LOSS [training: 0.5400733540706455 | validation: 0.4948413440960792]
	TIME [epoch: 9.53 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.525290705398336		[learning rate: 0.00014273]
	Learning Rate: 0.000142734
	LOSS [training: 0.525290705398336 | validation: 0.48667510902005895]
	TIME [epoch: 9.53 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5395273649792919		[learning rate: 0.00014222]
	Learning Rate: 0.000142216
	LOSS [training: 0.5395273649792919 | validation: 0.45119097051760165]
	TIME [epoch: 9.53 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5431229785533941		[learning rate: 0.0001417]
	Learning Rate: 0.0001417
	LOSS [training: 0.5431229785533941 | validation: 0.45686349048156927]
	TIME [epoch: 9.55 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5277672280366342		[learning rate: 0.00014119]
	Learning Rate: 0.000141185
	LOSS [training: 0.5277672280366342 | validation: 0.4536520508804626]
	TIME [epoch: 9.55 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5310774317627526		[learning rate: 0.00014067]
	Learning Rate: 0.000140673
	LOSS [training: 0.5310774317627526 | validation: 0.4369021012940542]
	TIME [epoch: 9.53 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5296395492457122		[learning rate: 0.00014016]
	Learning Rate: 0.000140162
	LOSS [training: 0.5296395492457122 | validation: 0.4828176184291871]
	TIME [epoch: 9.53 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5487706086707412		[learning rate: 0.00013965]
	Learning Rate: 0.000139654
	LOSS [training: 0.5487706086707412 | validation: 0.4815360256722396]
	TIME [epoch: 9.53 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.545217974991771		[learning rate: 0.00013915]
	Learning Rate: 0.000139147
	LOSS [training: 0.545217974991771 | validation: 0.5289059724260968]
	TIME [epoch: 9.52 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5743525611095495		[learning rate: 0.00013864]
	Learning Rate: 0.000138642
	LOSS [training: 0.5743525611095495 | validation: 0.4980472062778031]
	TIME [epoch: 9.53 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5434306140295102		[learning rate: 0.00013814]
	Learning Rate: 0.000138139
	LOSS [training: 0.5434306140295102 | validation: 0.46215077332151766]
	TIME [epoch: 9.54 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5280261862012225		[learning rate: 0.00013764]
	Learning Rate: 0.000137638
	LOSS [training: 0.5280261862012225 | validation: 0.4523492167833149]
	TIME [epoch: 9.53 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5380633746121505		[learning rate: 0.00013714]
	Learning Rate: 0.000137138
	LOSS [training: 0.5380633746121505 | validation: 0.4897791876248178]
	TIME [epoch: 9.53 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5307856702690454		[learning rate: 0.00013664]
	Learning Rate: 0.00013664
	LOSS [training: 0.5307856702690454 | validation: 0.4612001943808325]
	TIME [epoch: 9.55 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5092495887015756		[learning rate: 0.00013614]
	Learning Rate: 0.000136144
	LOSS [training: 0.5092495887015756 | validation: 0.4579458394086222]
	TIME [epoch: 9.53 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5304920380955197		[learning rate: 0.00013565]
	Learning Rate: 0.00013565
	LOSS [training: 0.5304920380955197 | validation: 0.43139333310286826]
	TIME [epoch: 9.53 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5388761476555471		[learning rate: 0.00013516]
	Learning Rate: 0.000135158
	LOSS [training: 0.5388761476555471 | validation: 0.4518343090159123]
	TIME [epoch: 9.52 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.52912140014473		[learning rate: 0.00013467]
	Learning Rate: 0.000134668
	LOSS [training: 0.52912140014473 | validation: 0.4622416815312404]
	TIME [epoch: 9.55 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5307641833731569		[learning rate: 0.00013418]
	Learning Rate: 0.000134179
	LOSS [training: 0.5307641833731569 | validation: 0.4740326514368071]
	TIME [epoch: 9.53 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5221560996340323		[learning rate: 0.00013369]
	Learning Rate: 0.000133692
	LOSS [training: 0.5221560996340323 | validation: 0.4475593122821863]
	TIME [epoch: 9.53 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5196729464750811		[learning rate: 0.00013321]
	Learning Rate: 0.000133207
	LOSS [training: 0.5196729464750811 | validation: 0.45341429640600633]
	TIME [epoch: 9.54 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5266726826689502		[learning rate: 0.00013272]
	Learning Rate: 0.000132723
	LOSS [training: 0.5266726826689502 | validation: 0.4334233990366295]
	TIME [epoch: 9.53 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5363174360394979		[learning rate: 0.00013224]
	Learning Rate: 0.000132242
	LOSS [training: 0.5363174360394979 | validation: 0.4301655853475327]
	TIME [epoch: 9.52 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5332525932574612		[learning rate: 0.00013176]
	Learning Rate: 0.000131762
	LOSS [training: 0.5332525932574612 | validation: 0.4501807224961043]
	TIME [epoch: 9.53 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5241009914153646		[learning rate: 0.00013128]
	Learning Rate: 0.000131284
	LOSS [training: 0.5241009914153646 | validation: 0.45508181629734906]
	TIME [epoch: 9.55 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5295094385478674		[learning rate: 0.00013081]
	Learning Rate: 0.000130807
	LOSS [training: 0.5295094385478674 | validation: 0.433697769396516]
	TIME [epoch: 9.53 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5390827785405062		[learning rate: 0.00013033]
	Learning Rate: 0.000130332
	LOSS [training: 0.5390827785405062 | validation: 0.4547479106050598]
	TIME [epoch: 9.53 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5297197166771269		[learning rate: 0.00012986]
	Learning Rate: 0.000129859
	LOSS [training: 0.5297197166771269 | validation: 0.4382642167153546]
	TIME [epoch: 9.54 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5255054210955037		[learning rate: 0.00012939]
	Learning Rate: 0.000129388
	LOSS [training: 0.5255054210955037 | validation: 0.4418784033948449]
	TIME [epoch: 9.52 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5297664074114965		[learning rate: 0.00012892]
	Learning Rate: 0.000128919
	LOSS [training: 0.5297664074114965 | validation: 0.44080841803735027]
	TIME [epoch: 9.53 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.537469152130057		[learning rate: 0.00012845]
	Learning Rate: 0.000128451
	LOSS [training: 0.537469152130057 | validation: 0.4516181365677563]
	TIME [epoch: 9.53 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5381017782166677		[learning rate: 0.00012798]
	Learning Rate: 0.000127985
	LOSS [training: 0.5381017782166677 | validation: 0.43726521971335075]
	TIME [epoch: 9.54 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5360673230438227		[learning rate: 0.00012752]
	Learning Rate: 0.00012752
	LOSS [training: 0.5360673230438227 | validation: 0.4222400032552613]
	TIME [epoch: 9.52 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5315658152672578		[learning rate: 0.00012706]
	Learning Rate: 0.000127057
	LOSS [training: 0.5315658152672578 | validation: 0.41881301844618607]
	TIME [epoch: 9.53 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5235366577229931		[learning rate: 0.0001266]
	Learning Rate: 0.000126596
	LOSS [training: 0.5235366577229931 | validation: 0.43286295256430973]
	TIME [epoch: 9.54 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5276479238867121		[learning rate: 0.00012614]
	Learning Rate: 0.000126137
	LOSS [training: 0.5276479238867121 | validation: 0.4331906168666492]
	TIME [epoch: 9.54 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5188212909565949		[learning rate: 0.00012568]
	Learning Rate: 0.000125679
	LOSS [training: 0.5188212909565949 | validation: 0.4523965920942017]
	TIME [epoch: 9.53 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5150580472851982		[learning rate: 0.00012522]
	Learning Rate: 0.000125223
	LOSS [training: 0.5150580472851982 | validation: 0.44509281817791574]
	TIME [epoch: 9.53 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5388821444666256		[learning rate: 0.00012477]
	Learning Rate: 0.000124769
	LOSS [training: 0.5388821444666256 | validation: 0.47214460306584416]
	TIME [epoch: 9.55 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5570036347765699		[learning rate: 0.00012432]
	Learning Rate: 0.000124316
	LOSS [training: 0.5570036347765699 | validation: 0.4864680942737658]
	TIME [epoch: 9.53 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5391565381538304		[learning rate: 0.00012386]
	Learning Rate: 0.000123865
	LOSS [training: 0.5391565381538304 | validation: 0.45721773942988203]
	TIME [epoch: 9.53 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5385548608708518		[learning rate: 0.00012342]
	Learning Rate: 0.000123415
	LOSS [training: 0.5385548608708518 | validation: 0.4750076960966061]
	TIME [epoch: 9.54 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5315651754353761		[learning rate: 0.00012297]
	Learning Rate: 0.000122967
	LOSS [training: 0.5315651754353761 | validation: 0.4464549358621616]
	TIME [epoch: 9.53 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5195050845576092		[learning rate: 0.00012252]
	Learning Rate: 0.000122521
	LOSS [training: 0.5195050845576092 | validation: 0.43441539398890555]
	TIME [epoch: 9.53 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5287825432916703		[learning rate: 0.00012208]
	Learning Rate: 0.000122076
	LOSS [training: 0.5287825432916703 | validation: 0.4540654195702832]
	TIME [epoch: 9.53 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5326870618839943		[learning rate: 0.00012163]
	Learning Rate: 0.000121633
	LOSS [training: 0.5326870618839943 | validation: 0.47199809080668576]
	TIME [epoch: 9.54 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5293724943661846		[learning rate: 0.00012119]
	Learning Rate: 0.000121192
	LOSS [training: 0.5293724943661846 | validation: 0.44320253278752464]
	TIME [epoch: 9.53 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5226851687515011		[learning rate: 0.00012075]
	Learning Rate: 0.000120752
	LOSS [training: 0.5226851687515011 | validation: 0.456027072161334]
	TIME [epoch: 9.52 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5222164687316531		[learning rate: 0.00012031]
	Learning Rate: 0.000120314
	LOSS [training: 0.5222164687316531 | validation: 0.4947026659611801]
	TIME [epoch: 9.55 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5200765444956186		[learning rate: 0.00011988]
	Learning Rate: 0.000119877
	LOSS [training: 0.5200765444956186 | validation: 0.47110067857168136]
	TIME [epoch: 9.52 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5283894246047668		[learning rate: 0.00011944]
	Learning Rate: 0.000119442
	LOSS [training: 0.5283894246047668 | validation: 0.47000592123119356]
	TIME [epoch: 9.53 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5219050327326378		[learning rate: 0.00011901]
	Learning Rate: 0.000119009
	LOSS [training: 0.5219050327326378 | validation: 0.461644259568608]
	TIME [epoch: 9.53 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5319444206614705		[learning rate: 0.00011858]
	Learning Rate: 0.000118577
	LOSS [training: 0.5319444206614705 | validation: 0.4587154570090805]
	TIME [epoch: 9.55 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5421749601963105		[learning rate: 0.00011815]
	Learning Rate: 0.000118147
	LOSS [training: 0.5421749601963105 | validation: 0.4524811967729462]
	TIME [epoch: 9.53 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5265802657486589		[learning rate: 0.00011772]
	Learning Rate: 0.000117718
	LOSS [training: 0.5265802657486589 | validation: 0.4508386466206741]
	TIME [epoch: 9.53 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5313619650940218		[learning rate: 0.00011729]
	Learning Rate: 0.000117291
	LOSS [training: 0.5313619650940218 | validation: 0.4570061745719359]
	TIME [epoch: 9.55 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5250462660143793		[learning rate: 0.00011686]
	Learning Rate: 0.000116865
	LOSS [training: 0.5250462660143793 | validation: 0.4873181609323716]
	TIME [epoch: 9.52 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.53293356565561		[learning rate: 0.00011644]
	Learning Rate: 0.000116441
	LOSS [training: 0.53293356565561 | validation: 0.4883255862680032]
	TIME [epoch: 9.53 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5342926429371451		[learning rate: 0.00011602]
	Learning Rate: 0.000116018
	LOSS [training: 0.5342926429371451 | validation: 0.4864130012997484]
	TIME [epoch: 9.55 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5499692059145452		[learning rate: 0.0001156]
	Learning Rate: 0.000115597
	LOSS [training: 0.5499692059145452 | validation: 0.5043375645389444]
	TIME [epoch: 9.54 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5378898232326979		[learning rate: 0.00011518]
	Learning Rate: 0.000115178
	LOSS [training: 0.5378898232326979 | validation: 0.5186141289701779]
	TIME [epoch: 9.52 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5484468063155366		[learning rate: 0.00011476]
	Learning Rate: 0.00011476
	LOSS [training: 0.5484468063155366 | validation: 0.5325472037854545]
	TIME [epoch: 9.52 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5509065379287632		[learning rate: 0.00011434]
	Learning Rate: 0.000114343
	LOSS [training: 0.5509065379287632 | validation: 0.43936925478732164]
	TIME [epoch: 9.54 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5254686326068845		[learning rate: 0.00011393]
	Learning Rate: 0.000113928
	LOSS [training: 0.5254686326068845 | validation: 0.4559904831774132]
	TIME [epoch: 9.53 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5298110253089175		[learning rate: 0.00011351]
	Learning Rate: 0.000113515
	LOSS [training: 0.5298110253089175 | validation: 0.4510717655447215]
	TIME [epoch: 9.52 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5244225304230591		[learning rate: 0.0001131]
	Learning Rate: 0.000113103
	LOSS [training: 0.5244225304230591 | validation: 0.470515415017571]
	TIME [epoch: 9.54 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5399107916104329		[learning rate: 0.00011269]
	Learning Rate: 0.000112692
	LOSS [training: 0.5399107916104329 | validation: 0.4776594443410199]
	TIME [epoch: 9.54 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5316475711021096		[learning rate: 0.00011228]
	Learning Rate: 0.000112283
	LOSS [training: 0.5316475711021096 | validation: 0.4443228745934729]
	TIME [epoch: 9.53 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5093041811728136		[learning rate: 0.00011188]
	Learning Rate: 0.000111876
	LOSS [training: 0.5093041811728136 | validation: 0.4359741831595288]
	TIME [epoch: 9.52 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5301416803385219		[learning rate: 0.00011147]
	Learning Rate: 0.00011147
	LOSS [training: 0.5301416803385219 | validation: 0.43735325971768035]
	TIME [epoch: 9.55 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5304825829660239		[learning rate: 0.00011107]
	Learning Rate: 0.000111065
	LOSS [training: 0.5304825829660239 | validation: 0.44405803921011827]
	TIME [epoch: 9.53 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5314075630668306		[learning rate: 0.00011066]
	Learning Rate: 0.000110662
	LOSS [training: 0.5314075630668306 | validation: 0.4769434029653331]
	TIME [epoch: 9.53 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5237223096987427		[learning rate: 0.00011026]
	Learning Rate: 0.000110261
	LOSS [training: 0.5237223096987427 | validation: 0.48032744420293677]
	TIME [epoch: 9.54 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.551697625072687		[learning rate: 0.00010986]
	Learning Rate: 0.000109861
	LOSS [training: 0.551697625072687 | validation: 0.49472209166856723]
	TIME [epoch: 9.53 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5223501566732269		[learning rate: 0.00010946]
	Learning Rate: 0.000109462
	LOSS [training: 0.5223501566732269 | validation: 0.46894285978123634]
	TIME [epoch: 9.52 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5305317773731952		[learning rate: 0.00010906]
	Learning Rate: 0.000109065
	LOSS [training: 0.5305317773731952 | validation: 0.4617071637986759]
	TIME [epoch: 9.53 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5204265316645362		[learning rate: 0.00010867]
	Learning Rate: 0.000108669
	LOSS [training: 0.5204265316645362 | validation: 0.49144541935345787]
	TIME [epoch: 9.55 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5331200496710086		[learning rate: 0.00010827]
	Learning Rate: 0.000108275
	LOSS [training: 0.5331200496710086 | validation: 0.4918128360909076]
	TIME [epoch: 9.53 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5435717202033945		[learning rate: 0.00010788]
	Learning Rate: 0.000107882
	LOSS [training: 0.5435717202033945 | validation: 0.5307740102816773]
	TIME [epoch: 9.52 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5630391791309075		[learning rate: 0.00010749]
	Learning Rate: 0.00010749
	LOSS [training: 0.5630391791309075 | validation: 0.5262220688501376]
	TIME [epoch: 9.54 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5451227778117194		[learning rate: 0.0001071]
	Learning Rate: 0.0001071
	LOSS [training: 0.5451227778117194 | validation: 0.5061996261051965]
	TIME [epoch: 9.53 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.522677153732169		[learning rate: 0.00010671]
	Learning Rate: 0.000106711
	LOSS [training: 0.522677153732169 | validation: 0.5161908701361992]
	TIME [epoch: 9.53 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5318727210159869		[learning rate: 0.00010632]
	Learning Rate: 0.000106324
	LOSS [training: 0.5318727210159869 | validation: 0.5022353335522859]
	TIME [epoch: 9.53 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5344795024032005		[learning rate: 0.00010594]
	Learning Rate: 0.000105938
	LOSS [training: 0.5344795024032005 | validation: 0.47279821279717726]
	TIME [epoch: 9.55 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5204350618467901		[learning rate: 0.00010555]
	Learning Rate: 0.000105554
	LOSS [training: 0.5204350618467901 | validation: 0.4653764906503089]
	TIME [epoch: 9.53 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5275279683075178		[learning rate: 0.00010517]
	Learning Rate: 0.000105171
	LOSS [training: 0.5275279683075178 | validation: 0.4816749932176588]
	TIME [epoch: 9.53 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5417383696856002		[learning rate: 0.00010479]
	Learning Rate: 0.000104789
	LOSS [training: 0.5417383696856002 | validation: 0.4750986576045254]
	TIME [epoch: 9.55 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5320765059647697		[learning rate: 0.00010441]
	Learning Rate: 0.000104409
	LOSS [training: 0.5320765059647697 | validation: 0.4426771444082322]
	TIME [epoch: 9.53 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5303881332720741		[learning rate: 0.00010403]
	Learning Rate: 0.00010403
	LOSS [training: 0.5303881332720741 | validation: 0.45241175080382856]
	TIME [epoch: 9.54 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5228227714083307		[learning rate: 0.00010365]
	Learning Rate: 0.000103652
	LOSS [training: 0.5228227714083307 | validation: 0.48159939321401035]
	TIME [epoch: 9.53 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5291271373156788		[learning rate: 0.00010328]
	Learning Rate: 0.000103276
	LOSS [training: 0.5291271373156788 | validation: 0.4847333454315893]
	TIME [epoch: 9.55 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.518829944558883		[learning rate: 0.0001029]
	Learning Rate: 0.000102901
	LOSS [training: 0.518829944558883 | validation: 0.47589504229498103]
	TIME [epoch: 9.52 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5307254087616814		[learning rate: 0.00010253]
	Learning Rate: 0.000102528
	LOSS [training: 0.5307254087616814 | validation: 0.4752182872873887]
	TIME [epoch: 9.53 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5198386327661081		[learning rate: 0.00010216]
	Learning Rate: 0.000102156
	LOSS [training: 0.5198386327661081 | validation: 0.4586011573115857]
	TIME [epoch: 9.54 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5187080973315492		[learning rate: 0.00010179]
	Learning Rate: 0.000101785
	LOSS [training: 0.5187080973315492 | validation: 0.4784726313176361]
	TIME [epoch: 9.52 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5178531188620867		[learning rate: 0.00010142]
	Learning Rate: 0.000101416
	LOSS [training: 0.5178531188620867 | validation: 0.4397317824213256]
	TIME [epoch: 9.53 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5215739973869692		[learning rate: 0.00010105]
	Learning Rate: 0.000101048
	LOSS [training: 0.5215739973869692 | validation: 0.456018122605442]
	TIME [epoch: 9.53 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5241676819939011		[learning rate: 0.00010068]
	Learning Rate: 0.000100681
	LOSS [training: 0.5241676819939011 | validation: 0.4609654384649911]
	TIME [epoch: 9.53 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5161749990069534		[learning rate: 0.00010032]
	Learning Rate: 0.000100316
	LOSS [training: 0.5161749990069534 | validation: 0.457692891455421]
	TIME [epoch: 9.52 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5288872667438362		[learning rate: 9.9952e-05]
	Learning Rate: 9.99515e-05
	LOSS [training: 0.5288872667438362 | validation: 0.455999936216909]
	TIME [epoch: 9.52 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5275503583530363		[learning rate: 9.9589e-05]
	Learning Rate: 9.95888e-05
	LOSS [training: 0.5275503583530363 | validation: 0.44628537817204966]
	TIME [epoch: 9.55 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5435551548927485		[learning rate: 9.9227e-05]
	Learning Rate: 9.92274e-05
	LOSS [training: 0.5435551548927485 | validation: 0.4491736552501719]
	TIME [epoch: 9.52 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5209350874165128		[learning rate: 9.8867e-05]
	Learning Rate: 9.88673e-05
	LOSS [training: 0.5209350874165128 | validation: 0.44337959590329684]
	TIME [epoch: 9.52 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5148129194220011		[learning rate: 9.8509e-05]
	Learning Rate: 9.85085e-05
	LOSS [training: 0.5148129194220011 | validation: 0.45218057888253316]
	TIME [epoch: 9.52 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5238992673036743		[learning rate: 9.8151e-05]
	Learning Rate: 9.8151e-05
	LOSS [training: 0.5238992673036743 | validation: 0.46539925323561837]
	TIME [epoch: 9.54 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5208007716382606		[learning rate: 9.7795e-05]
	Learning Rate: 9.77948e-05
	LOSS [training: 0.5208007716382606 | validation: 0.46229128420370175]
	TIME [epoch: 9.52 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5186214884566029		[learning rate: 9.744e-05]
	Learning Rate: 9.74399e-05
	LOSS [training: 0.5186214884566029 | validation: 0.4782220777906586]
	TIME [epoch: 9.52 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5257858637027357		[learning rate: 9.7086e-05]
	Learning Rate: 9.70863e-05
	LOSS [training: 0.5257858637027357 | validation: 0.4706894847311925]
	TIME [epoch: 9.55 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5162946960984147		[learning rate: 9.6734e-05]
	Learning Rate: 9.6734e-05
	LOSS [training: 0.5162946960984147 | validation: 0.4534375038503148]
	TIME [epoch: 9.53 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5204224310329784		[learning rate: 9.6383e-05]
	Learning Rate: 9.63829e-05
	LOSS [training: 0.5204224310329784 | validation: 0.4422699971126633]
	TIME [epoch: 9.52 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5257713420187029		[learning rate: 9.6033e-05]
	Learning Rate: 9.60331e-05
	LOSS [training: 0.5257713420187029 | validation: 0.4955977223381193]
	TIME [epoch: 9.53 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.536918876857716		[learning rate: 9.5685e-05]
	Learning Rate: 9.56846e-05
	LOSS [training: 0.536918876857716 | validation: 0.4859235472987023]
	TIME [epoch: 9.53 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5251001136478383		[learning rate: 9.5337e-05]
	Learning Rate: 9.53374e-05
	LOSS [training: 0.5251001136478383 | validation: 0.4673125005498535]
	TIME [epoch: 9.52 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5167118921173436		[learning rate: 9.4991e-05]
	Learning Rate: 9.49914e-05
	LOSS [training: 0.5167118921173436 | validation: 0.4625338259198995]
	TIME [epoch: 9.53 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5211043118402774		[learning rate: 9.4647e-05]
	Learning Rate: 9.46466e-05
	LOSS [training: 0.5211043118402774 | validation: 0.4559495397385647]
	TIME [epoch: 9.54 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5167968734358162		[learning rate: 9.4303e-05]
	Learning Rate: 9.43032e-05
	LOSS [training: 0.5167968734358162 | validation: 0.46250257582315263]
	TIME [epoch: 9.53 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5128898486023823		[learning rate: 9.3961e-05]
	Learning Rate: 9.39609e-05
	LOSS [training: 0.5128898486023823 | validation: 0.4335100916723124]
	TIME [epoch: 9.53 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5248356226235978		[learning rate: 9.362e-05]
	Learning Rate: 9.362e-05
	LOSS [training: 0.5248356226235978 | validation: 0.44106563556304046]
	TIME [epoch: 9.54 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5253417287520679		[learning rate: 9.328e-05]
	Learning Rate: 9.32802e-05
	LOSS [training: 0.5253417287520679 | validation: 0.4384898491358128]
	TIME [epoch: 9.53 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5153994582107624		[learning rate: 9.2942e-05]
	Learning Rate: 9.29417e-05
	LOSS [training: 0.5153994582107624 | validation: 0.47938349849208095]
	TIME [epoch: 9.52 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.528276985289263		[learning rate: 9.2604e-05]
	Learning Rate: 9.26044e-05
	LOSS [training: 0.528276985289263 | validation: 0.45966049955422916]
	TIME [epoch: 9.54 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5250290350622928		[learning rate: 9.2268e-05]
	Learning Rate: 9.22683e-05
	LOSS [training: 0.5250290350622928 | validation: 0.4516351363883628]
	TIME [epoch: 9.55 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5232196533292943		[learning rate: 9.1933e-05]
	Learning Rate: 9.19335e-05
	LOSS [training: 0.5232196533292943 | validation: 0.45585957276348843]
	TIME [epoch: 9.53 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.527518397206179		[learning rate: 9.16e-05]
	Learning Rate: 9.15998e-05
	LOSS [training: 0.527518397206179 | validation: 0.44436318855538354]
	TIME [epoch: 9.53 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5259402132213526		[learning rate: 9.1267e-05]
	Learning Rate: 9.12674e-05
	LOSS [training: 0.5259402132213526 | validation: 0.44756232141931807]
	TIME [epoch: 9.54 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5381491041498375		[learning rate: 9.0936e-05]
	Learning Rate: 9.09362e-05
	LOSS [training: 0.5381491041498375 | validation: 0.45764304421519564]
	TIME [epoch: 9.53 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5193517833991887		[learning rate: 9.0606e-05]
	Learning Rate: 9.06062e-05
	LOSS [training: 0.5193517833991887 | validation: 0.4282488782659262]
	TIME [epoch: 9.51 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5487295339166505		[learning rate: 9.0277e-05]
	Learning Rate: 9.02774e-05
	LOSS [training: 0.5487295339166505 | validation: 0.4384591110998824]
	TIME [epoch: 9.53 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5287456686268762		[learning rate: 8.995e-05]
	Learning Rate: 8.99498e-05
	LOSS [training: 0.5287456686268762 | validation: 0.4647562684067502]
	TIME [epoch: 9.55 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5300730281485037		[learning rate: 8.9623e-05]
	Learning Rate: 8.96233e-05
	LOSS [training: 0.5300730281485037 | validation: 0.4645520789344856]
	TIME [epoch: 9.53 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5247944273419349		[learning rate: 8.9298e-05]
	Learning Rate: 8.92981e-05
	LOSS [training: 0.5247944273419349 | validation: 0.4435408855005359]
	TIME [epoch: 9.53 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5257513467005575		[learning rate: 8.8974e-05]
	Learning Rate: 8.8974e-05
	LOSS [training: 0.5257513467005575 | validation: 0.4547737347932251]
	TIME [epoch: 9.54 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5240693088680634		[learning rate: 8.8651e-05]
	Learning Rate: 8.86511e-05
	LOSS [training: 0.5240693088680634 | validation: 0.4509272753676614]
	TIME [epoch: 9.53 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.537160327887584		[learning rate: 8.8329e-05]
	Learning Rate: 8.83294e-05
	LOSS [training: 0.537160327887584 | validation: 0.4479978170409072]
	TIME [epoch: 9.52 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.528593439911896		[learning rate: 8.8009e-05]
	Learning Rate: 8.80088e-05
	LOSS [training: 0.528593439911896 | validation: 0.46157474596294734]
	TIME [epoch: 9.53 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5246088966198227		[learning rate: 8.7689e-05]
	Learning Rate: 8.76895e-05
	LOSS [training: 0.5246088966198227 | validation: 0.4644863360591883]
	TIME [epoch: 9.56 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5304663248598681		[learning rate: 8.7371e-05]
	Learning Rate: 8.73712e-05
	LOSS [training: 0.5304663248598681 | validation: 0.4555111490900189]
	TIME [epoch: 9.52 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5132879215541268		[learning rate: 8.7054e-05]
	Learning Rate: 8.70542e-05
	LOSS [training: 0.5132879215541268 | validation: 0.4682045886805436]
	TIME [epoch: 9.53 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5286060513759782		[learning rate: 8.6738e-05]
	Learning Rate: 8.67382e-05
	LOSS [training: 0.5286060513759782 | validation: 0.44208033160963023]
	TIME [epoch: 9.55 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5073224837299843		[learning rate: 8.6423e-05]
	Learning Rate: 8.64235e-05
	LOSS [training: 0.5073224837299843 | validation: 0.4496902093159741]
	TIME [epoch: 9.52 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5190648990108192		[learning rate: 8.611e-05]
	Learning Rate: 8.61098e-05
	LOSS [training: 0.5190648990108192 | validation: 0.4415283640141907]
	TIME [epoch: 9.52 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5104713394249853		[learning rate: 8.5797e-05]
	Learning Rate: 8.57973e-05
	LOSS [training: 0.5104713394249853 | validation: 0.48600352106247663]
	TIME [epoch: 9.52 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5185379113781668		[learning rate: 8.5486e-05]
	Learning Rate: 8.54859e-05
	LOSS [training: 0.5185379113781668 | validation: 0.45926280451239737]
	TIME [epoch: 9.54 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5180729209165859		[learning rate: 8.5176e-05]
	Learning Rate: 8.51757e-05
	LOSS [training: 0.5180729209165859 | validation: 0.46417209699167816]
	TIME [epoch: 9.53 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5319072211166168		[learning rate: 8.4867e-05]
	Learning Rate: 8.48666e-05
	LOSS [training: 0.5319072211166168 | validation: 0.46582122667584924]
	TIME [epoch: 9.52 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5173810806904802		[learning rate: 8.4559e-05]
	Learning Rate: 8.45586e-05
	LOSS [training: 0.5173810806904802 | validation: 0.47416432550452103]
	TIME [epoch: 9.55 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5167692151888366		[learning rate: 8.4252e-05]
	Learning Rate: 8.42518e-05
	LOSS [training: 0.5167692151888366 | validation: 0.47476024611878415]
	TIME [epoch: 9.53 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5260093278522784		[learning rate: 8.3946e-05]
	Learning Rate: 8.3946e-05
	LOSS [training: 0.5260093278522784 | validation: 0.4482517189984591]
	TIME [epoch: 9.52 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5171475171042117		[learning rate: 8.3641e-05]
	Learning Rate: 8.36414e-05
	LOSS [training: 0.5171475171042117 | validation: 0.4614276898471454]
	TIME [epoch: 9.53 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.537862078499694		[learning rate: 8.3338e-05]
	Learning Rate: 8.33378e-05
	LOSS [training: 0.537862078499694 | validation: 0.4883855794874353]
	TIME [epoch: 9.54 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5304172647762792		[learning rate: 8.3035e-05]
	Learning Rate: 8.30354e-05
	LOSS [training: 0.5304172647762792 | validation: 0.4875711387645365]
	TIME [epoch: 9.53 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5199641480004284		[learning rate: 8.2734e-05]
	Learning Rate: 8.2734e-05
	LOSS [training: 0.5199641480004284 | validation: 0.4598185932736318]
	TIME [epoch: 9.52 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5237673803834574		[learning rate: 8.2434e-05]
	Learning Rate: 8.24338e-05
	LOSS [training: 0.5237673803834574 | validation: 0.46010457912718816]
	TIME [epoch: 9.54 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5193726283196869		[learning rate: 8.2135e-05]
	Learning Rate: 8.21346e-05
	LOSS [training: 0.5193726283196869 | validation: 0.4750702122955306]
	TIME [epoch: 9.53 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5236190798893036		[learning rate: 8.1837e-05]
	Learning Rate: 8.18366e-05
	LOSS [training: 0.5236190798893036 | validation: 0.4538029631424558]
	TIME [epoch: 9.53 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.536650916457134		[learning rate: 8.154e-05]
	Learning Rate: 8.15396e-05
	LOSS [training: 0.536650916457134 | validation: 0.45237352310696494]
	TIME [epoch: 9.53 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5243468815108783		[learning rate: 8.1244e-05]
	Learning Rate: 8.12437e-05
	LOSS [training: 0.5243468815108783 | validation: 0.46276693151842374]
	TIME [epoch: 9.54 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5316890127547281		[learning rate: 8.0949e-05]
	Learning Rate: 8.09488e-05
	LOSS [training: 0.5316890127547281 | validation: 0.4644798281219531]
	TIME [epoch: 9.53 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5183936905017144		[learning rate: 8.0655e-05]
	Learning Rate: 8.0655e-05
	LOSS [training: 0.5183936905017144 | validation: 0.45232764459452457]
	TIME [epoch: 9.53 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.52630380432738		[learning rate: 8.0362e-05]
	Learning Rate: 8.03623e-05
	LOSS [training: 0.52630380432738 | validation: 0.4368269463912817]
	TIME [epoch: 9.55 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5341280520358466		[learning rate: 8.0071e-05]
	Learning Rate: 8.00707e-05
	LOSS [training: 0.5341280520358466 | validation: 0.4445128631478892]
	TIME [epoch: 9.53 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5264887139131211		[learning rate: 7.978e-05]
	Learning Rate: 7.97801e-05
	LOSS [training: 0.5264887139131211 | validation: 0.4335118708760753]
	TIME [epoch: 9.53 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5184025542480235		[learning rate: 7.9491e-05]
	Learning Rate: 7.94906e-05
	LOSS [training: 0.5184025542480235 | validation: 0.44322411423861574]
	TIME [epoch: 9.53 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.51991366505451		[learning rate: 7.9202e-05]
	Learning Rate: 7.92021e-05
	LOSS [training: 0.51991366505451 | validation: 0.45501234421542974]
	TIME [epoch: 9.55 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5286676305143223		[learning rate: 7.8915e-05]
	Learning Rate: 7.89147e-05
	LOSS [training: 0.5286676305143223 | validation: 0.4568036678672891]
	TIME [epoch: 9.52 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5306744371592594		[learning rate: 7.8628e-05]
	Learning Rate: 7.86283e-05
	LOSS [training: 0.5306744371592594 | validation: 0.45874832148329026]
	TIME [epoch: 9.53 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5289576309790862		[learning rate: 7.8343e-05]
	Learning Rate: 7.8343e-05
	LOSS [training: 0.5289576309790862 | validation: 0.4338699108639182]
	TIME [epoch: 9.54 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5252006416151133		[learning rate: 7.8059e-05]
	Learning Rate: 7.80586e-05
	LOSS [training: 0.5252006416151133 | validation: 0.4593550332299755]
	TIME [epoch: 9.53 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5159527468861711		[learning rate: 7.7775e-05]
	Learning Rate: 7.77754e-05
	LOSS [training: 0.5159527468861711 | validation: 0.45765828428234]
	TIME [epoch: 9.52 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5181259826513264		[learning rate: 7.7493e-05]
	Learning Rate: 7.74931e-05
	LOSS [training: 0.5181259826513264 | validation: 0.47488789674174514]
	TIME [epoch: 9.54 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.508351473381725		[learning rate: 7.7212e-05]
	Learning Rate: 7.72119e-05
	LOSS [training: 0.508351473381725 | validation: 0.45245312392329357]
	TIME [epoch: 9.53 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5161994459591726		[learning rate: 7.6932e-05]
	Learning Rate: 7.69317e-05
	LOSS [training: 0.5161994459591726 | validation: 0.43592285827841826]
	TIME [epoch: 9.53 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.527858610784639		[learning rate: 7.6653e-05]
	Learning Rate: 7.66525e-05
	LOSS [training: 0.527858610784639 | validation: 0.44450806251621805]
	TIME [epoch: 9.53 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5230988081563922		[learning rate: 7.6374e-05]
	Learning Rate: 7.63743e-05
	LOSS [training: 0.5230988081563922 | validation: 0.4430307901141387]
	TIME [epoch: 9.55 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5224397685727962		[learning rate: 7.6097e-05]
	Learning Rate: 7.60972e-05
	LOSS [training: 0.5224397685727962 | validation: 0.45656781503190147]
	TIME [epoch: 9.52 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.513243664805252		[learning rate: 7.5821e-05]
	Learning Rate: 7.5821e-05
	LOSS [training: 0.513243664805252 | validation: 0.4536371615313868]
	TIME [epoch: 9.52 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5234058924835965		[learning rate: 7.5546e-05]
	Learning Rate: 7.55458e-05
	LOSS [training: 0.5234058924835965 | validation: 0.4529592277110645]
	TIME [epoch: 9.54 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.530790396318714		[learning rate: 7.5272e-05]
	Learning Rate: 7.52717e-05
	LOSS [training: 0.530790396318714 | validation: 0.45095513103712037]
	TIME [epoch: 9.53 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5246102609702662		[learning rate: 7.4999e-05]
	Learning Rate: 7.49985e-05
	LOSS [training: 0.5246102609702662 | validation: 0.45271062620535013]
	TIME [epoch: 9.51 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5227820897756815		[learning rate: 7.4726e-05]
	Learning Rate: 7.47263e-05
	LOSS [training: 0.5227820897756815 | validation: 0.469423201928244]
	TIME [epoch: 9.52 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5293466928199514		[learning rate: 7.4455e-05]
	Learning Rate: 7.44552e-05
	LOSS [training: 0.5293466928199514 | validation: 0.48595736207752444]
	TIME [epoch: 9.54 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5299389382421096		[learning rate: 7.4185e-05]
	Learning Rate: 7.4185e-05
	LOSS [training: 0.5299389382421096 | validation: 0.4857701795052718]
	TIME [epoch: 9.52 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5345346851067091		[learning rate: 7.3916e-05]
	Learning Rate: 7.39157e-05
	LOSS [training: 0.5345346851067091 | validation: 0.45710586295709366]
	TIME [epoch: 9.52 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5282854641435328		[learning rate: 7.3647e-05]
	Learning Rate: 7.36475e-05
	LOSS [training: 0.5282854641435328 | validation: 0.44167753459266534]
	TIME [epoch: 9.54 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5322342054461235		[learning rate: 7.338e-05]
	Learning Rate: 7.33802e-05
	LOSS [training: 0.5322342054461235 | validation: 0.4504412037006748]
	TIME [epoch: 9.54 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5272827503885619		[learning rate: 7.3114e-05]
	Learning Rate: 7.31139e-05
	LOSS [training: 0.5272827503885619 | validation: 0.45737439544352515]
	TIME [epoch: 9.52 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5270934491508601		[learning rate: 7.2849e-05]
	Learning Rate: 7.28486e-05
	LOSS [training: 0.5270934491508601 | validation: 0.44669731927909584]
	TIME [epoch: 9.53 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.537392848279777		[learning rate: 7.2584e-05]
	Learning Rate: 7.25842e-05
	LOSS [training: 0.537392848279777 | validation: 0.4631218498531955]
	TIME [epoch: 9.54 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5302139079378242		[learning rate: 7.2321e-05]
	Learning Rate: 7.23208e-05
	LOSS [training: 0.5302139079378242 | validation: 0.4582317748559778]
	TIME [epoch: 9.52 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5261319608079659		[learning rate: 7.2058e-05]
	Learning Rate: 7.20583e-05
	LOSS [training: 0.5261319608079659 | validation: 0.45634659294025853]
	TIME [epoch: 9.52 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.535420448871624		[learning rate: 7.1797e-05]
	Learning Rate: 7.17968e-05
	LOSS [training: 0.535420448871624 | validation: 0.4657251575464724]
	TIME [epoch: 9.53 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5347989541301962		[learning rate: 7.1536e-05]
	Learning Rate: 7.15363e-05
	LOSS [training: 0.5347989541301962 | validation: 0.46694733860316634]
	TIME [epoch: 9.53 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.51958397760269		[learning rate: 7.1277e-05]
	Learning Rate: 7.12767e-05
	LOSS [training: 0.51958397760269 | validation: 0.44420518052578006]
	TIME [epoch: 9.52 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5196369483021417		[learning rate: 7.1018e-05]
	Learning Rate: 7.1018e-05
	LOSS [training: 0.5196369483021417 | validation: 0.4485169095486585]
	TIME [epoch: 9.52 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5254591272351615		[learning rate: 7.076e-05]
	Learning Rate: 7.07603e-05
	LOSS [training: 0.5254591272351615 | validation: 0.4339753884632467]
	TIME [epoch: 9.55 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5340711938912874		[learning rate: 7.0503e-05]
	Learning Rate: 7.05035e-05
	LOSS [training: 0.5340711938912874 | validation: 0.4500910795797728]
	TIME [epoch: 9.52 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5210491913963747		[learning rate: 7.0248e-05]
	Learning Rate: 7.02476e-05
	LOSS [training: 0.5210491913963747 | validation: 0.46512294296414125]
	TIME [epoch: 9.52 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.526563043261042		[learning rate: 6.9993e-05]
	Learning Rate: 6.99927e-05
	LOSS [training: 0.526563043261042 | validation: 0.44517195063431403]
	TIME [epoch: 9.55 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5227562136401143		[learning rate: 6.9739e-05]
	Learning Rate: 6.97387e-05
	LOSS [training: 0.5227562136401143 | validation: 0.43544698774707]
	TIME [epoch: 9.53 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5252713389878487		[learning rate: 6.9486e-05]
	Learning Rate: 6.94856e-05
	LOSS [training: 0.5252713389878487 | validation: 0.44320204089132637]
	TIME [epoch: 9.51 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5248295013318061		[learning rate: 6.9233e-05]
	Learning Rate: 6.92334e-05
	LOSS [training: 0.5248295013318061 | validation: 0.44085975780088216]
	TIME [epoch: 9.52 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.526240815938551		[learning rate: 6.8982e-05]
	Learning Rate: 6.89822e-05
	LOSS [training: 0.526240815938551 | validation: 0.45495516291139804]
	TIME [epoch: 9.55 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5228511729857436		[learning rate: 6.8732e-05]
	Learning Rate: 6.87318e-05
	LOSS [training: 0.5228511729857436 | validation: 0.45173167027912203]
	TIME [epoch: 9.53 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5210779283718251		[learning rate: 6.8482e-05]
	Learning Rate: 6.84824e-05
	LOSS [training: 0.5210779283718251 | validation: 0.453978144600064]
	TIME [epoch: 9.53 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5229500933625395		[learning rate: 6.8234e-05]
	Learning Rate: 6.82339e-05
	LOSS [training: 0.5229500933625395 | validation: 0.4463541780548282]
	TIME [epoch: 9.54 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5323514403598464		[learning rate: 6.7986e-05]
	Learning Rate: 6.79862e-05
	LOSS [training: 0.5323514403598464 | validation: 0.44240070512702645]
	TIME [epoch: 9.52 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5204686913435411		[learning rate: 6.774e-05]
	Learning Rate: 6.77395e-05
	LOSS [training: 0.5204686913435411 | validation: 0.4533469543258842]
	TIME [epoch: 9.52 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5319670361472484		[learning rate: 6.7494e-05]
	Learning Rate: 6.74937e-05
	LOSS [training: 0.5319670361472484 | validation: 0.4537308203984204]
	TIME [epoch: 9.52 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5229786766443321		[learning rate: 6.7249e-05]
	Learning Rate: 6.72488e-05
	LOSS [training: 0.5229786766443321 | validation: 0.4564631573340452]
	TIME [epoch: 9.53 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5261128592383415		[learning rate: 6.7005e-05]
	Learning Rate: 6.70047e-05
	LOSS [training: 0.5261128592383415 | validation: 0.48926457762474307]
	TIME [epoch: 9.52 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5184029200767486		[learning rate: 6.6762e-05]
	Learning Rate: 6.67616e-05
	LOSS [training: 0.5184029200767486 | validation: 0.45035978082473216]
	TIME [epoch: 9.53 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5323682693638235		[learning rate: 6.6519e-05]
	Learning Rate: 6.65192e-05
	LOSS [training: 0.5323682693638235 | validation: 0.44137902427943654]
	TIME [epoch: 9.54 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.522760301675608		[learning rate: 6.6278e-05]
	Learning Rate: 6.62778e-05
	LOSS [training: 0.522760301675608 | validation: 0.4536305162433658]
	TIME [epoch: 9.52 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5350626019939986		[learning rate: 6.6037e-05]
	Learning Rate: 6.60373e-05
	LOSS [training: 0.5350626019939986 | validation: 0.44948185469818946]
	TIME [epoch: 9.51 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5254809812124224		[learning rate: 6.5798e-05]
	Learning Rate: 6.57977e-05
	LOSS [training: 0.5254809812124224 | validation: 0.4409797499217965]
	TIME [epoch: 9.53 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5242240380406454		[learning rate: 6.5559e-05]
	Learning Rate: 6.55589e-05
	LOSS [training: 0.5242240380406454 | validation: 0.4664165297761661]
	TIME [epoch: 9.54 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5297005728857918		[learning rate: 6.5321e-05]
	Learning Rate: 6.5321e-05
	LOSS [training: 0.5297005728857918 | validation: 0.46125950837706725]
	TIME [epoch: 9.52 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5280675574643021		[learning rate: 6.5084e-05]
	Learning Rate: 6.50839e-05
	LOSS [training: 0.5280675574643021 | validation: 0.4502245547602944]
	TIME [epoch: 9.52 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5423203119686326		[learning rate: 6.4848e-05]
	Learning Rate: 6.48477e-05
	LOSS [training: 0.5423203119686326 | validation: 0.44891888141368164]
	TIME [epoch: 9.54 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5171351437576288		[learning rate: 6.4612e-05]
	Learning Rate: 6.46124e-05
	LOSS [training: 0.5171351437576288 | validation: 0.4429410696891284]
	TIME [epoch: 9.52 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5196278127163094		[learning rate: 6.4378e-05]
	Learning Rate: 6.43779e-05
	LOSS [training: 0.5196278127163094 | validation: 0.4552847310106949]
	TIME [epoch: 9.52 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5296007978493293		[learning rate: 6.4144e-05]
	Learning Rate: 6.41443e-05
	LOSS [training: 0.5296007978493293 | validation: 0.4602593168111839]
	TIME [epoch: 9.53 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.528072839318712		[learning rate: 6.3911e-05]
	Learning Rate: 6.39115e-05
	LOSS [training: 0.528072839318712 | validation: 0.44934483205224995]
	TIME [epoch: 9.53 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5299495646250095		[learning rate: 6.368e-05]
	Learning Rate: 6.36795e-05
	LOSS [training: 0.5299495646250095 | validation: 0.449095520642328]
	TIME [epoch: 9.53 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5176936517036383		[learning rate: 6.3448e-05]
	Learning Rate: 6.34485e-05
	LOSS [training: 0.5176936517036383 | validation: 0.4460687748679586]
	TIME [epoch: 9.52 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5352563958126374		[learning rate: 6.3218e-05]
	Learning Rate: 6.32182e-05
	LOSS [training: 0.5352563958126374 | validation: 0.44461972622217644]
	TIME [epoch: 9.55 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.520911013042367		[learning rate: 6.2989e-05]
	Learning Rate: 6.29888e-05
	LOSS [training: 0.520911013042367 | validation: 0.42811053237714747]
	TIME [epoch: 9.52 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5219095933992336		[learning rate: 6.276e-05]
	Learning Rate: 6.27602e-05
	LOSS [training: 0.5219095933992336 | validation: 0.42715107637081157]
	TIME [epoch: 9.53 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5247013434204459		[learning rate: 6.2532e-05]
	Learning Rate: 6.25324e-05
	LOSS [training: 0.5247013434204459 | validation: 0.4458589184701513]
	TIME [epoch: 9.53 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5258418890269118		[learning rate: 6.2305e-05]
	Learning Rate: 6.23055e-05
	LOSS [training: 0.5258418890269118 | validation: 0.43348122368486314]
	TIME [epoch: 9.53 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5254313876216798		[learning rate: 6.2079e-05]
	Learning Rate: 6.20794e-05
	LOSS [training: 0.5254313876216798 | validation: 0.4258332733424222]
	TIME [epoch: 9.52 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.528926885581597		[learning rate: 6.1854e-05]
	Learning Rate: 6.18541e-05
	LOSS [training: 0.528926885581597 | validation: 0.4424111943158057]
	TIME [epoch: 9.52 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5256858889433135		[learning rate: 6.163e-05]
	Learning Rate: 6.16296e-05
	LOSS [training: 0.5256858889433135 | validation: 0.45158364412047264]
	TIME [epoch: 9.54 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5205019547972739		[learning rate: 6.1406e-05]
	Learning Rate: 6.1406e-05
	LOSS [training: 0.5205019547972739 | validation: 0.4557485714978274]
	TIME [epoch: 9.52 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5262931850326834		[learning rate: 6.1183e-05]
	Learning Rate: 6.11831e-05
	LOSS [training: 0.5262931850326834 | validation: 0.44852242751843047]
	TIME [epoch: 9.52 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5285479083555479		[learning rate: 6.0961e-05]
	Learning Rate: 6.09611e-05
	LOSS [training: 0.5285479083555479 | validation: 0.4397565462009604]
	TIME [epoch: 9.53 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5344592097930927		[learning rate: 6.074e-05]
	Learning Rate: 6.07399e-05
	LOSS [training: 0.5344592097930927 | validation: 0.4299103806418483]
	TIME [epoch: 9.53 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5286550610275527		[learning rate: 6.0519e-05]
	Learning Rate: 6.05194e-05
	LOSS [training: 0.5286550610275527 | validation: 0.4491820031686471]
	TIME [epoch: 9.52 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5143066308187192		[learning rate: 6.03e-05]
	Learning Rate: 6.02998e-05
	LOSS [training: 0.5143066308187192 | validation: 0.4516377651950691]
	TIME [epoch: 9.53 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5204598813902778		[learning rate: 6.0081e-05]
	Learning Rate: 6.0081e-05
	LOSS [training: 0.5204598813902778 | validation: 0.44518773714173276]
	TIME [epoch: 9.54 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5248822204069643		[learning rate: 5.9863e-05]
	Learning Rate: 5.98629e-05
	LOSS [training: 0.5248822204069643 | validation: 0.45114480550305347]
	TIME [epoch: 9.52 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5185431235758424		[learning rate: 5.9646e-05]
	Learning Rate: 5.96457e-05
	LOSS [training: 0.5185431235758424 | validation: 0.4487891285408644]
	TIME [epoch: 9.52 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5233081691578018		[learning rate: 5.9429e-05]
	Learning Rate: 5.94292e-05
	LOSS [training: 0.5233081691578018 | validation: 0.455899781416111]
	TIME [epoch: 9.54 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5266443696377281		[learning rate: 5.9214e-05]
	Learning Rate: 5.92136e-05
	LOSS [training: 0.5266443696377281 | validation: 0.44666947393050194]
	TIME [epoch: 9.52 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.526933509279164		[learning rate: 5.8999e-05]
	Learning Rate: 5.89987e-05
	LOSS [training: 0.526933509279164 | validation: 0.4336878496895455]
	TIME [epoch: 9.53 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5074858971999789		[learning rate: 5.8785e-05]
	Learning Rate: 5.87846e-05
	LOSS [training: 0.5074858971999789 | validation: 0.42719286152297725]
	TIME [epoch: 9.52 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5348451556950353		[learning rate: 5.8571e-05]
	Learning Rate: 5.85712e-05
	LOSS [training: 0.5348451556950353 | validation: 0.4570007186461252]
	TIME [epoch: 9.54 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5234850157149369		[learning rate: 5.8359e-05]
	Learning Rate: 5.83586e-05
	LOSS [training: 0.5234850157149369 | validation: 0.45048136427952246]
	TIME [epoch: 9.53 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5242802098949482		[learning rate: 5.8147e-05]
	Learning Rate: 5.81469e-05
	LOSS [training: 0.5242802098949482 | validation: 0.45409052274988093]
	TIME [epoch: 9.52 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5178529474108392		[learning rate: 5.7936e-05]
	Learning Rate: 5.79358e-05
	LOSS [training: 0.5178529474108392 | validation: 0.43404255799708763]
	TIME [epoch: 9.53 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5159378169550172		[learning rate: 5.7726e-05]
	Learning Rate: 5.77256e-05
	LOSS [training: 0.5159378169550172 | validation: 0.4456486897063618]
	TIME [epoch: 9.53 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5401749212056394		[learning rate: 5.7516e-05]
	Learning Rate: 5.75161e-05
	LOSS [training: 0.5401749212056394 | validation: 0.4529713019674614]
	TIME [epoch: 9.52 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.520416479409459		[learning rate: 5.7307e-05]
	Learning Rate: 5.73074e-05
	LOSS [training: 0.520416479409459 | validation: 0.4602353454730696]
	TIME [epoch: 9.52 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5221411807908727		[learning rate: 5.7099e-05]
	Learning Rate: 5.70994e-05
	LOSS [training: 0.5221411807908727 | validation: 0.45183010759562614]
	TIME [epoch: 9.54 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5279589968714249		[learning rate: 5.6892e-05]
	Learning Rate: 5.68922e-05
	LOSS [training: 0.5279589968714249 | validation: 0.4631509271553869]
	TIME [epoch: 9.53 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5154236350360077		[learning rate: 5.6686e-05]
	Learning Rate: 5.66857e-05
	LOSS [training: 0.5154236350360077 | validation: 0.4277299343295583]
	TIME [epoch: 9.52 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5201028422290328		[learning rate: 5.648e-05]
	Learning Rate: 5.648e-05
	LOSS [training: 0.5201028422290328 | validation: 0.45811933297075963]
	TIME [epoch: 9.55 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5128552038394427		[learning rate: 5.6275e-05]
	Learning Rate: 5.6275e-05
	LOSS [training: 0.5128552038394427 | validation: 0.4414351725585411]
	TIME [epoch: 9.53 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5284706673909845		[learning rate: 5.6071e-05]
	Learning Rate: 5.60708e-05
	LOSS [training: 0.5284706673909845 | validation: 0.43788580605257693]
	TIME [epoch: 9.53 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5219736632514577		[learning rate: 5.5867e-05]
	Learning Rate: 5.58673e-05
	LOSS [training: 0.5219736632514577 | validation: 0.45077518074107403]
	TIME [epoch: 9.54 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5286867451767749		[learning rate: 5.5665e-05]
	Learning Rate: 5.56646e-05
	LOSS [training: 0.5286867451767749 | validation: 0.45208466239728523]
	TIME [epoch: 9.54 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5217750263573542		[learning rate: 5.5463e-05]
	Learning Rate: 5.54626e-05
	LOSS [training: 0.5217750263573542 | validation: 0.45098586943864377]
	TIME [epoch: 9.53 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5267450871670118		[learning rate: 5.5261e-05]
	Learning Rate: 5.52613e-05
	LOSS [training: 0.5267450871670118 | validation: 0.449014600981976]
	TIME [epoch: 9.52 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5227917534765222		[learning rate: 5.5061e-05]
	Learning Rate: 5.50608e-05
	LOSS [training: 0.5227917534765222 | validation: 0.4429517414074613]
	TIME [epoch: 9.54 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5269063690562602		[learning rate: 5.4861e-05]
	Learning Rate: 5.48609e-05
	LOSS [training: 0.5269063690562602 | validation: 0.4727356637342435]
	TIME [epoch: 9.53 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5184671761001789		[learning rate: 5.4662e-05]
	Learning Rate: 5.46618e-05
	LOSS [training: 0.5184671761001789 | validation: 0.4654710683057486]
	TIME [epoch: 9.52 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5266248984606166		[learning rate: 5.4463e-05]
	Learning Rate: 5.44635e-05
	LOSS [training: 0.5266248984606166 | validation: 0.4549147402502526]
	TIME [epoch: 9.53 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5218529639978305		[learning rate: 5.4266e-05]
	Learning Rate: 5.42658e-05
	LOSS [training: 0.5218529639978305 | validation: 0.4623247657345931]
	TIME [epoch: 9.55 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5293475020817426		[learning rate: 5.4069e-05]
	Learning Rate: 5.40689e-05
	LOSS [training: 0.5293475020817426 | validation: 0.4822442394472013]
	TIME [epoch: 9.52 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5294703117101547		[learning rate: 5.3873e-05]
	Learning Rate: 5.38727e-05
	LOSS [training: 0.5294703117101547 | validation: 0.4474478146590915]
	TIME [epoch: 9.52 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5330478160800756		[learning rate: 5.3677e-05]
	Learning Rate: 5.36772e-05
	LOSS [training: 0.5330478160800756 | validation: 0.4650565033340331]
	TIME [epoch: 9.54 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5222516221688024		[learning rate: 5.3482e-05]
	Learning Rate: 5.34824e-05
	LOSS [training: 0.5222516221688024 | validation: 0.46251498078409525]
	TIME [epoch: 9.53 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5366840514847422		[learning rate: 5.3288e-05]
	Learning Rate: 5.32883e-05
	LOSS [training: 0.5366840514847422 | validation: 0.45036711366723825]
	TIME [epoch: 9.53 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5393902019229728		[learning rate: 5.3095e-05]
	Learning Rate: 5.30949e-05
	LOSS [training: 0.5393902019229728 | validation: 0.4588126435135622]
	TIME [epoch: 9.53 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5196334375082798		[learning rate: 5.2902e-05]
	Learning Rate: 5.29022e-05
	LOSS [training: 0.5196334375082798 | validation: 0.44836902882250573]
	TIME [epoch: 9.54 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.523049071456865		[learning rate: 5.271e-05]
	Learning Rate: 5.27102e-05
	LOSS [training: 0.523049071456865 | validation: 0.4480048465558268]
	TIME [epoch: 9.52 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5198258220880619		[learning rate: 5.2519e-05]
	Learning Rate: 5.25189e-05
	LOSS [training: 0.5198258220880619 | validation: 0.44480874461831277]
	TIME [epoch: 9.53 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5257368957792456		[learning rate: 5.2328e-05]
	Learning Rate: 5.23283e-05
	LOSS [training: 0.5257368957792456 | validation: 0.44501025306516917]
	TIME [epoch: 9.55 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5200517798884043		[learning rate: 5.2138e-05]
	Learning Rate: 5.21384e-05
	LOSS [training: 0.5200517798884043 | validation: 0.45004921640004014]
	TIME [epoch: 9.53 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5205015434782934		[learning rate: 5.1949e-05]
	Learning Rate: 5.19492e-05
	LOSS [training: 0.5205015434782934 | validation: 0.4626763943181266]
	TIME [epoch: 9.53 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5245221228423037		[learning rate: 5.1761e-05]
	Learning Rate: 5.17607e-05
	LOSS [training: 0.5245221228423037 | validation: 0.46250110295620245]
	TIME [epoch: 9.53 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5187425900298626		[learning rate: 5.1573e-05]
	Learning Rate: 5.15729e-05
	LOSS [training: 0.5187425900298626 | validation: 0.4730067363557583]
	TIME [epoch: 9.54 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5234336910727719		[learning rate: 5.1386e-05]
	Learning Rate: 5.13857e-05
	LOSS [training: 0.5234336910727719 | validation: 0.46867171868186924]
	TIME [epoch: 9.52 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5244054518274325		[learning rate: 5.1199e-05]
	Learning Rate: 5.11992e-05
	LOSS [training: 0.5244054518274325 | validation: 0.4518312576534258]
	TIME [epoch: 9.53 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5201402081698644		[learning rate: 5.1013e-05]
	Learning Rate: 5.10134e-05
	LOSS [training: 0.5201402081698644 | validation: 0.46783424976062743]
	TIME [epoch: 9.55 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5200832820355649		[learning rate: 5.0828e-05]
	Learning Rate: 5.08283e-05
	LOSS [training: 0.5200832820355649 | validation: 0.4498384074468382]
	TIME [epoch: 9.53 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5228834503612731		[learning rate: 5.0644e-05]
	Learning Rate: 5.06438e-05
	LOSS [training: 0.5228834503612731 | validation: 0.4828283833302285]
	TIME [epoch: 9.52 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5212431966036839		[learning rate: 5.046e-05]
	Learning Rate: 5.046e-05
	LOSS [training: 0.5212431966036839 | validation: 0.4427056923527339]
	TIME [epoch: 9.54 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5243317664229422		[learning rate: 5.0277e-05]
	Learning Rate: 5.02769e-05
	LOSS [training: 0.5243317664229422 | validation: 0.4522058032639695]
	TIME [epoch: 9.53 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5315071308747414		[learning rate: 5.0094e-05]
	Learning Rate: 5.00944e-05
	LOSS [training: 0.5315071308747414 | validation: 0.44327070797935547]
	TIME [epoch: 9.53 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5178299176571687		[learning rate: 4.9913e-05]
	Learning Rate: 4.99127e-05
	LOSS [training: 0.5178299176571687 | validation: 0.4454237238529498]
	TIME [epoch: 9.53 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5274422353456181		[learning rate: 4.9732e-05]
	Learning Rate: 4.97315e-05
	LOSS [training: 0.5274422353456181 | validation: 0.44290983093599]
	TIME [epoch: 9.55 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5198501016653184		[learning rate: 4.9551e-05]
	Learning Rate: 4.9551e-05
	LOSS [training: 0.5198501016653184 | validation: 0.4543189912217219]
	TIME [epoch: 9.52 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5345568019861446		[learning rate: 4.9371e-05]
	Learning Rate: 4.93712e-05
	LOSS [training: 0.5345568019861446 | validation: 0.46348740843950226]
	TIME [epoch: 9.52 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5208254233805131		[learning rate: 4.9192e-05]
	Learning Rate: 4.9192e-05
	LOSS [training: 0.5208254233805131 | validation: 0.4581630575991218]
	TIME [epoch: 9.54 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5187715873270988		[learning rate: 4.9014e-05]
	Learning Rate: 4.90135e-05
	LOSS [training: 0.5187715873270988 | validation: 0.44365073037372105]
	TIME [epoch: 9.53 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5183460947995054		[learning rate: 4.8836e-05]
	Learning Rate: 4.88356e-05
	LOSS [training: 0.5183460947995054 | validation: 0.4349554225715923]
	TIME [epoch: 9.52 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5279753727326467		[learning rate: 4.8658e-05]
	Learning Rate: 4.86584e-05
	LOSS [training: 0.5279753727326467 | validation: 0.4421037835104413]
	TIME [epoch: 9.53 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5273107767728145		[learning rate: 4.8482e-05]
	Learning Rate: 4.84818e-05
	LOSS [training: 0.5273107767728145 | validation: 0.43641209914793744]
	TIME [epoch: 9.54 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5214657538478945		[learning rate: 4.8306e-05]
	Learning Rate: 4.83059e-05
	LOSS [training: 0.5214657538478945 | validation: 0.45629674174012297]
	TIME [epoch: 9.52 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5201530954816385		[learning rate: 4.8131e-05]
	Learning Rate: 4.81306e-05
	LOSS [training: 0.5201530954816385 | validation: 0.4475357122436342]
	TIME [epoch: 9.52 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5269408479717981		[learning rate: 4.7956e-05]
	Learning Rate: 4.79559e-05
	LOSS [training: 0.5269408479717981 | validation: 0.4286251435930481]
	TIME [epoch: 9.54 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5245166245253863		[learning rate: 4.7782e-05]
	Learning Rate: 4.77819e-05
	LOSS [training: 0.5245166245253863 | validation: 0.44540407844770147]
	TIME [epoch: 9.53 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5274251925093181		[learning rate: 4.7608e-05]
	Learning Rate: 4.76085e-05
	LOSS [training: 0.5274251925093181 | validation: 0.45076286520875813]
	TIME [epoch: 9.52 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.517757383131756		[learning rate: 4.7436e-05]
	Learning Rate: 4.74357e-05
	LOSS [training: 0.517757383131756 | validation: 0.4494503313153206]
	TIME [epoch: 9.53 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5203740858729965		[learning rate: 4.7264e-05]
	Learning Rate: 4.72636e-05
	LOSS [training: 0.5203740858729965 | validation: 0.4342635527143986]
	TIME [epoch: 9.54 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.523887514716883		[learning rate: 4.7092e-05]
	Learning Rate: 4.7092e-05
	LOSS [training: 0.523887514716883 | validation: 0.4409021747385276]
	TIME [epoch: 9.52 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5164439551357064		[learning rate: 4.6921e-05]
	Learning Rate: 4.69211e-05
	LOSS [training: 0.5164439551357064 | validation: 0.4559458068505616]
	TIME [epoch: 9.53 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5223704793384345		[learning rate: 4.6751e-05]
	Learning Rate: 4.67508e-05
	LOSS [training: 0.5223704793384345 | validation: 0.4536156570253404]
	TIME [epoch: 9.55 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5306755873310157		[learning rate: 4.6581e-05]
	Learning Rate: 4.65812e-05
	LOSS [training: 0.5306755873310157 | validation: 0.46301406279236473]
	TIME [epoch: 9.55 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5367901632628564		[learning rate: 4.6412e-05]
	Learning Rate: 4.64121e-05
	LOSS [training: 0.5367901632628564 | validation: 0.46324706600278204]
	TIME [epoch: 9.53 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5221887830910324		[learning rate: 4.6244e-05]
	Learning Rate: 4.62437e-05
	LOSS [training: 0.5221887830910324 | validation: 0.4464768408220916]
	TIME [epoch: 9.52 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.521073403935704		[learning rate: 4.6076e-05]
	Learning Rate: 4.60759e-05
	LOSS [training: 0.521073403935704 | validation: 0.4686821653632765]
	TIME [epoch: 9.55 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5322304502549148		[learning rate: 4.5909e-05]
	Learning Rate: 4.59087e-05
	LOSS [training: 0.5322304502549148 | validation: 0.4329028502369371]
	TIME [epoch: 9.52 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5218355726291035		[learning rate: 4.5742e-05]
	Learning Rate: 4.57421e-05
	LOSS [training: 0.5218355726291035 | validation: 0.43881527053295877]
	TIME [epoch: 9.52 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5317816638190664		[learning rate: 4.5576e-05]
	Learning Rate: 4.55761e-05
	LOSS [training: 0.5317816638190664 | validation: 0.45499281541290737]
	TIME [epoch: 9.54 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5368606235491633		[learning rate: 4.5411e-05]
	Learning Rate: 4.54107e-05
	LOSS [training: 0.5368606235491633 | validation: 0.4712521963457074]
	TIME [epoch: 9.53 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5280202064109479		[learning rate: 4.5246e-05]
	Learning Rate: 4.52459e-05
	LOSS [training: 0.5280202064109479 | validation: 0.4765220586345788]
	TIME [epoch: 9.52 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5469847733448625		[learning rate: 4.5082e-05]
	Learning Rate: 4.50817e-05
	LOSS [training: 0.5469847733448625 | validation: 0.47018065573871637]
	TIME [epoch: 9.53 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5348589935065741		[learning rate: 4.4918e-05]
	Learning Rate: 4.49181e-05
	LOSS [training: 0.5348589935065741 | validation: 0.4674942445759139]
	TIME [epoch: 9.54 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.517754300507235		[learning rate: 4.4755e-05]
	Learning Rate: 4.47551e-05
	LOSS [training: 0.517754300507235 | validation: 0.4534180038452982]
	TIME [epoch: 9.51 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5143912964516755		[learning rate: 4.4593e-05]
	Learning Rate: 4.45926e-05
	LOSS [training: 0.5143912964516755 | validation: 0.4507514249066004]
	TIME [epoch: 9.53 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5218379108821696		[learning rate: 4.4431e-05]
	Learning Rate: 4.44308e-05
	LOSS [training: 0.5218379108821696 | validation: 0.46092192733017384]
	TIME [epoch: 9.54 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5385620050481182		[learning rate: 4.427e-05]
	Learning Rate: 4.42696e-05
	LOSS [training: 0.5385620050481182 | validation: 0.4690273914142054]
	TIME [epoch: 9.53 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5187440752357879		[learning rate: 4.4109e-05]
	Learning Rate: 4.41089e-05
	LOSS [training: 0.5187440752357879 | validation: 0.47517502675707224]
	TIME [epoch: 9.52 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5235432535332949		[learning rate: 4.3949e-05]
	Learning Rate: 4.39489e-05
	LOSS [training: 0.5235432535332949 | validation: 0.46366288319669957]
	TIME [epoch: 9.53 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5410548653891389		[learning rate: 4.3789e-05]
	Learning Rate: 4.37893e-05
	LOSS [training: 0.5410548653891389 | validation: 0.4620107930081828]
	TIME [epoch: 9.54 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5343813561743547		[learning rate: 4.363e-05]
	Learning Rate: 4.36304e-05
	LOSS [training: 0.5343813561743547 | validation: 0.46542528402749433]
	TIME [epoch: 9.53 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5253575393875283		[learning rate: 4.3472e-05]
	Learning Rate: 4.34721e-05
	LOSS [training: 0.5253575393875283 | validation: 0.46222400482835]
	TIME [epoch: 9.53 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5332740076886416		[learning rate: 4.3314e-05]
	Learning Rate: 4.33143e-05
	LOSS [training: 0.5332740076886416 | validation: 0.4762191196141421]
	TIME [epoch: 9.55 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5302267481923989		[learning rate: 4.3157e-05]
	Learning Rate: 4.31571e-05
	LOSS [training: 0.5302267481923989 | validation: 0.451270948522564]
	TIME [epoch: 9.53 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5204534232295799		[learning rate: 4.3001e-05]
	Learning Rate: 4.30005e-05
	LOSS [training: 0.5204534232295799 | validation: 0.4572602382643264]
	TIME [epoch: 9.52 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5297298922889098		[learning rate: 4.2844e-05]
	Learning Rate: 4.28445e-05
	LOSS [training: 0.5297298922889098 | validation: 0.45290632565852645]
	TIME [epoch: 9.53 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5271182925839087		[learning rate: 4.2689e-05]
	Learning Rate: 4.2689e-05
	LOSS [training: 0.5271182925839087 | validation: 0.4799097958230422]
	TIME [epoch: 9.55 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5306717248873185		[learning rate: 4.2534e-05]
	Learning Rate: 4.25341e-05
	LOSS [training: 0.5306717248873185 | validation: 0.45231517409855015]
	TIME [epoch: 9.52 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5264867605816244		[learning rate: 4.238e-05]
	Learning Rate: 4.23797e-05
	LOSS [training: 0.5264867605816244 | validation: 0.4622800621275009]
	TIME [epoch: 9.53 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5359774338978267		[learning rate: 4.2226e-05]
	Learning Rate: 4.22259e-05
	LOSS [training: 0.5359774338978267 | validation: 0.4568314108253051]
	TIME [epoch: 9.55 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5286533376786566		[learning rate: 4.2073e-05]
	Learning Rate: 4.20727e-05
	LOSS [training: 0.5286533376786566 | validation: 0.48828777792989814]
	TIME [epoch: 9.54 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5261570122256083		[learning rate: 4.192e-05]
	Learning Rate: 4.192e-05
	LOSS [training: 0.5261570122256083 | validation: 0.4893887056626348]
	TIME [epoch: 9.53 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5316767492202401		[learning rate: 4.1768e-05]
	Learning Rate: 4.17679e-05
	LOSS [training: 0.5316767492202401 | validation: 0.4503750683984291]
	TIME [epoch: 9.54 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.53001859996783		[learning rate: 4.1616e-05]
	Learning Rate: 4.16163e-05
	LOSS [training: 0.53001859996783 | validation: 0.46968730368492545]
	TIME [epoch: 9.54 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5262303881296282		[learning rate: 4.1465e-05]
	Learning Rate: 4.14652e-05
	LOSS [training: 0.5262303881296282 | validation: 0.45925468987014234]
	TIME [epoch: 9.52 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5196495990016949		[learning rate: 4.1315e-05]
	Learning Rate: 4.13148e-05
	LOSS [training: 0.5196495990016949 | validation: 0.4540620192288926]
	TIME [epoch: 9.53 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5275117192628971		[learning rate: 4.1165e-05]
	Learning Rate: 4.11648e-05
	LOSS [training: 0.5275117192628971 | validation: 0.4567737268402052]
	TIME [epoch: 9.55 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5223938041622105		[learning rate: 4.1015e-05]
	Learning Rate: 4.10154e-05
	LOSS [training: 0.5223938041622105 | validation: 0.4794247692638395]
	TIME [epoch: 9.53 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5315964436645523		[learning rate: 4.0867e-05]
	Learning Rate: 4.08666e-05
	LOSS [training: 0.5315964436645523 | validation: 0.4655984796484238]
	TIME [epoch: 9.52 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5208452694476244		[learning rate: 4.0718e-05]
	Learning Rate: 4.07183e-05
	LOSS [training: 0.5208452694476244 | validation: 0.43926453347101757]
	TIME [epoch: 9.54 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5260807096098825		[learning rate: 4.0571e-05]
	Learning Rate: 4.05705e-05
	LOSS [training: 0.5260807096098825 | validation: 0.4464449475426983]
	TIME [epoch: 9.53 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.518095096857232		[learning rate: 4.0423e-05]
	Learning Rate: 4.04233e-05
	LOSS [training: 0.518095096857232 | validation: 0.4499234183989546]
	TIME [epoch: 9.52 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5143339077703695		[learning rate: 4.0277e-05]
	Learning Rate: 4.02766e-05
	LOSS [training: 0.5143339077703695 | validation: 0.4419229753125358]
	TIME [epoch: 9.53 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5303005563289528		[learning rate: 4.013e-05]
	Learning Rate: 4.01304e-05
	LOSS [training: 0.5303005563289528 | validation: 0.4535911225641685]
	TIME [epoch: 9.55 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5241805207698649		[learning rate: 3.9985e-05]
	Learning Rate: 3.99848e-05
	LOSS [training: 0.5241805207698649 | validation: 0.46499684833250743]
	TIME [epoch: 9.53 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5200600776460851		[learning rate: 3.984e-05]
	Learning Rate: 3.98397e-05
	LOSS [training: 0.5200600776460851 | validation: 0.46058814027146583]
	TIME [epoch: 9.53 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5312648995617819		[learning rate: 3.9695e-05]
	Learning Rate: 3.96951e-05
	LOSS [training: 0.5312648995617819 | validation: 0.45759767426204234]
	TIME [epoch: 9.54 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5249598740160544		[learning rate: 3.9551e-05]
	Learning Rate: 3.9551e-05
	LOSS [training: 0.5249598740160544 | validation: 0.4464352708021578]
	TIME [epoch: 9.53 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5206356772634751		[learning rate: 3.9408e-05]
	Learning Rate: 3.94075e-05
	LOSS [training: 0.5206356772634751 | validation: 0.4414093290683195]
	TIME [epoch: 9.52 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5233225293848365		[learning rate: 3.9264e-05]
	Learning Rate: 3.92645e-05
	LOSS [training: 0.5233225293848365 | validation: 0.4557953261956438]
	TIME [epoch: 9.53 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5219919480087153		[learning rate: 3.9122e-05]
	Learning Rate: 3.9122e-05
	LOSS [training: 0.5219919480087153 | validation: 0.4552480427826501]
	TIME [epoch: 9.54 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5308434374066204		[learning rate: 3.898e-05]
	Learning Rate: 3.898e-05
	LOSS [training: 0.5308434374066204 | validation: 0.44610123500095106]
	TIME [epoch: 9.53 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5382383236070403		[learning rate: 3.8839e-05]
	Learning Rate: 3.88386e-05
	LOSS [training: 0.5382383236070403 | validation: 0.4440133805792559]
	TIME [epoch: 9.53 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5288371860111258		[learning rate: 3.8698e-05]
	Learning Rate: 3.86976e-05
	LOSS [training: 0.5288371860111258 | validation: 0.44612900126552363]
	TIME [epoch: 9.54 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5249440410970008		[learning rate: 3.8557e-05]
	Learning Rate: 3.85572e-05
	LOSS [training: 0.5249440410970008 | validation: 0.459952469897479]
	TIME [epoch: 9.53 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5288839008194126		[learning rate: 3.8417e-05]
	Learning Rate: 3.84173e-05
	LOSS [training: 0.5288839008194126 | validation: 0.45456268334852523]
	TIME [epoch: 9.53 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5242765757590953		[learning rate: 3.8278e-05]
	Learning Rate: 3.82778e-05
	LOSS [training: 0.5242765757590953 | validation: 0.45150374897006473]
	TIME [epoch: 9.53 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5374920444228248		[learning rate: 3.8139e-05]
	Learning Rate: 3.81389e-05
	LOSS [training: 0.5374920444228248 | validation: 0.44037476098354494]
	TIME [epoch: 9.55 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5248676466066493		[learning rate: 3.8001e-05]
	Learning Rate: 3.80005e-05
	LOSS [training: 0.5248676466066493 | validation: 0.4390967898055358]
	TIME [epoch: 9.53 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5234914927650441		[learning rate: 3.7863e-05]
	Learning Rate: 3.78626e-05
	LOSS [training: 0.5234914927650441 | validation: 0.4694640874671474]
	TIME [epoch: 9.52 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5196768452649376		[learning rate: 3.7725e-05]
	Learning Rate: 3.77252e-05
	LOSS [training: 0.5196768452649376 | validation: 0.46086393952909294]
	TIME [epoch: 9.54 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5198462374072118		[learning rate: 3.7588e-05]
	Learning Rate: 3.75883e-05
	LOSS [training: 0.5198462374072118 | validation: 0.44292314452598824]
	TIME [epoch: 9.53 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5219632185390282		[learning rate: 3.7452e-05]
	Learning Rate: 3.74519e-05
	LOSS [training: 0.5219632185390282 | validation: 0.46566843275957154]
	TIME [epoch: 9.53 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5195205242017631		[learning rate: 3.7316e-05]
	Learning Rate: 3.7316e-05
	LOSS [training: 0.5195205242017631 | validation: 0.4446175583763527]
	TIME [epoch: 9.53 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5275745790006158		[learning rate: 3.7181e-05]
	Learning Rate: 3.71805e-05
	LOSS [training: 0.5275745790006158 | validation: 0.45343781937933075]
	TIME [epoch: 9.55 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5337265011251302		[learning rate: 3.7046e-05]
	Learning Rate: 3.70456e-05
	LOSS [training: 0.5337265011251302 | validation: 0.4433863130569346]
	TIME [epoch: 9.51 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5219486564434298		[learning rate: 3.6911e-05]
	Learning Rate: 3.69112e-05
	LOSS [training: 0.5219486564434298 | validation: 0.4536188461529056]
	TIME [epoch: 9.52 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5290170552964473		[learning rate: 3.6777e-05]
	Learning Rate: 3.67772e-05
	LOSS [training: 0.5290170552964473 | validation: 0.4494611394315631]
	TIME [epoch: 9.54 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5223348354065458		[learning rate: 3.6644e-05]
	Learning Rate: 3.66438e-05
	LOSS [training: 0.5223348354065458 | validation: 0.4455122802723567]
	TIME [epoch: 9.53 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5198902102992715		[learning rate: 3.6511e-05]
	Learning Rate: 3.65108e-05
	LOSS [training: 0.5198902102992715 | validation: 0.44958869830140935]
	TIME [epoch: 9.52 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5176952820309608		[learning rate: 3.6378e-05]
	Learning Rate: 3.63783e-05
	LOSS [training: 0.5176952820309608 | validation: 0.44638053898851127]
	TIME [epoch: 9.53 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5279163329432875		[learning rate: 3.6246e-05]
	Learning Rate: 3.62463e-05
	LOSS [training: 0.5279163329432875 | validation: 0.47140347968997914]
	TIME [epoch: 9.54 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5332815646694085		[learning rate: 3.6115e-05]
	Learning Rate: 3.61147e-05
	LOSS [training: 0.5332815646694085 | validation: 0.4551477659748666]
	TIME [epoch: 9.53 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5181353151446545		[learning rate: 3.5984e-05]
	Learning Rate: 3.59837e-05
	LOSS [training: 0.5181353151446545 | validation: 0.45013028485163903]
	TIME [epoch: 9.53 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5143344527143061		[learning rate: 3.5853e-05]
	Learning Rate: 3.58531e-05
	LOSS [training: 0.5143344527143061 | validation: 0.44963329977272964]
	TIME [epoch: 9.54 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5275606849039793		[learning rate: 3.5723e-05]
	Learning Rate: 3.5723e-05
	LOSS [training: 0.5275606849039793 | validation: 0.4447179316557403]
	TIME [epoch: 9.52 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.520269972581994		[learning rate: 3.5593e-05]
	Learning Rate: 3.55933e-05
	LOSS [training: 0.520269972581994 | validation: 0.4305061706874104]
	TIME [epoch: 9.52 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5186375670799277		[learning rate: 3.5464e-05]
	Learning Rate: 3.54641e-05
	LOSS [training: 0.5186375670799277 | validation: 0.44365477414495097]
	TIME [epoch: 9.53 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5188942051283446		[learning rate: 3.5335e-05]
	Learning Rate: 3.53354e-05
	LOSS [training: 0.5188942051283446 | validation: 0.44411710855852393]
	TIME [epoch: 9.55 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5311903370351257		[learning rate: 3.5207e-05]
	Learning Rate: 3.52072e-05
	LOSS [training: 0.5311903370351257 | validation: 0.45114872830176994]
	TIME [epoch: 9.52 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5362864708578942		[learning rate: 3.5079e-05]
	Learning Rate: 3.50794e-05
	LOSS [training: 0.5362864708578942 | validation: 0.4543614765682609]
	TIME [epoch: 9.52 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5263909706607754		[learning rate: 3.4952e-05]
	Learning Rate: 3.49521e-05
	LOSS [training: 0.5263909706607754 | validation: 0.46458016262672114]
	TIME [epoch: 9.55 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5216795997787594		[learning rate: 3.4825e-05]
	Learning Rate: 3.48253e-05
	LOSS [training: 0.5216795997787594 | validation: 0.4632406614969953]
	TIME [epoch: 9.53 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.529664532973691		[learning rate: 3.4699e-05]
	Learning Rate: 3.46989e-05
	LOSS [training: 0.529664532973691 | validation: 0.47352808188454126]
	TIME [epoch: 9.52 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5245927287629406		[learning rate: 3.4573e-05]
	Learning Rate: 3.4573e-05
	LOSS [training: 0.5245927287629406 | validation: 0.4493945521440616]
	TIME [epoch: 9.53 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5226217377742642		[learning rate: 3.4448e-05]
	Learning Rate: 3.44475e-05
	LOSS [training: 0.5226217377742642 | validation: 0.46123835870611146]
	TIME [epoch: 9.54 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5220085409101772		[learning rate: 3.4323e-05]
	Learning Rate: 3.43225e-05
	LOSS [training: 0.5220085409101772 | validation: 0.4562400576136676]
	TIME [epoch: 9.53 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5319029943717579		[learning rate: 3.4198e-05]
	Learning Rate: 3.4198e-05
	LOSS [training: 0.5319029943717579 | validation: 0.4562619824097432]
	TIME [epoch: 9.53 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5195667650403917		[learning rate: 3.4074e-05]
	Learning Rate: 3.40738e-05
	LOSS [training: 0.5195667650403917 | validation: 0.45041055272088637]
	TIME [epoch: 9.55 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5261890107050059		[learning rate: 3.395e-05]
	Learning Rate: 3.39502e-05
	LOSS [training: 0.5261890107050059 | validation: 0.4425143135061557]
	TIME [epoch: 9.52 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5290234383012984		[learning rate: 3.3827e-05]
	Learning Rate: 3.3827e-05
	LOSS [training: 0.5290234383012984 | validation: 0.46673285883031596]
	TIME [epoch: 9.52 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5204563726992454		[learning rate: 3.3704e-05]
	Learning Rate: 3.37042e-05
	LOSS [training: 0.5204563726992454 | validation: 0.44005456822016853]
	TIME [epoch: 9.54 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5179802333767798		[learning rate: 3.3582e-05]
	Learning Rate: 3.35819e-05
	LOSS [training: 0.5179802333767798 | validation: 0.47354496760495596]
	TIME [epoch: 9.54 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5350752911680183		[learning rate: 3.346e-05]
	Learning Rate: 3.346e-05
	LOSS [training: 0.5350752911680183 | validation: 0.47179552068801345]
	TIME [epoch: 9.53 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5260533506548561		[learning rate: 3.3339e-05]
	Learning Rate: 3.33386e-05
	LOSS [training: 0.5260533506548561 | validation: 0.461793488896989]
	TIME [epoch: 9.52 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.516193427353967		[learning rate: 3.3218e-05]
	Learning Rate: 3.32176e-05
	LOSS [training: 0.516193427353967 | validation: 0.47825637824077705]
	TIME [epoch: 9.54 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.527612387442397		[learning rate: 3.3097e-05]
	Learning Rate: 3.30971e-05
	LOSS [training: 0.527612387442397 | validation: 0.4660219304223549]
	TIME [epoch: 9.53 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5205742669074244		[learning rate: 3.2977e-05]
	Learning Rate: 3.2977e-05
	LOSS [training: 0.5205742669074244 | validation: 0.47115393524380805]
	TIME [epoch: 9.52 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5233544601193195		[learning rate: 3.2857e-05]
	Learning Rate: 3.28573e-05
	LOSS [training: 0.5233544601193195 | validation: 0.45003401971096224]
	TIME [epoch: 9.55 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5294073815424076		[learning rate: 3.2738e-05]
	Learning Rate: 3.2738e-05
	LOSS [training: 0.5294073815424076 | validation: 0.4660602244424489]
	TIME [epoch: 9.53 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5313291909588999		[learning rate: 3.2619e-05]
	Learning Rate: 3.26192e-05
	LOSS [training: 0.5313291909588999 | validation: 0.45997643080795686]
	TIME [epoch: 9.52 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5229074919080506		[learning rate: 3.2501e-05]
	Learning Rate: 3.25009e-05
	LOSS [training: 0.5229074919080506 | validation: 0.4756620940627005]
	TIME [epoch: 9.53 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5217990209547697		[learning rate: 3.2383e-05]
	Learning Rate: 3.23829e-05
	LOSS [training: 0.5217990209547697 | validation: 0.4642701517498239]
	TIME [epoch: 9.54 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5238538649372882		[learning rate: 3.2265e-05]
	Learning Rate: 3.22654e-05
	LOSS [training: 0.5238538649372882 | validation: 0.46170036007644444]
	TIME [epoch: 9.53 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.533392127792694		[learning rate: 3.2148e-05]
	Learning Rate: 3.21483e-05
	LOSS [training: 0.533392127792694 | validation: 0.4515451807835146]
	TIME [epoch: 9.53 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5245433365293029		[learning rate: 3.2032e-05]
	Learning Rate: 3.20316e-05
	LOSS [training: 0.5245433365293029 | validation: 0.45569646421984317]
	TIME [epoch: 9.54 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5239525634193448		[learning rate: 3.1915e-05]
	Learning Rate: 3.19154e-05
	LOSS [training: 0.5239525634193448 | validation: 0.46755223643976435]
	TIME [epoch: 9.53 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5205115152252417		[learning rate: 3.18e-05]
	Learning Rate: 3.17996e-05
	LOSS [training: 0.5205115152252417 | validation: 0.44619053888530197]
	TIME [epoch: 9.52 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5177105826152048		[learning rate: 3.1684e-05]
	Learning Rate: 3.16842e-05
	LOSS [training: 0.5177105826152048 | validation: 0.477086336060342]
	TIME [epoch: 9.52 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5271372635460424		[learning rate: 3.1569e-05]
	Learning Rate: 3.15692e-05
	LOSS [training: 0.5271372635460424 | validation: 0.44576377364515984]
	TIME [epoch: 9.54 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5191619670820604		[learning rate: 3.1455e-05]
	Learning Rate: 3.14546e-05
	LOSS [training: 0.5191619670820604 | validation: 0.4529262289741414]
	TIME [epoch: 9.52 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.522666097951827		[learning rate: 3.134e-05]
	Learning Rate: 3.13405e-05
	LOSS [training: 0.522666097951827 | validation: 0.4491798815405903]
	TIME [epoch: 9.52 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5301918982064788		[learning rate: 3.1227e-05]
	Learning Rate: 3.12267e-05
	LOSS [training: 0.5301918982064788 | validation: 0.47107228467319573]
	TIME [epoch: 9.55 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5144829662514416		[learning rate: 3.1113e-05]
	Learning Rate: 3.11134e-05
	LOSS [training: 0.5144829662514416 | validation: 0.4748019062111149]
	TIME [epoch: 9.53 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5167317985750863		[learning rate: 3.1e-05]
	Learning Rate: 3.10005e-05
	LOSS [training: 0.5167317985750863 | validation: 0.4779492796959529]
	TIME [epoch: 9.52 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5186488267221452		[learning rate: 3.0888e-05]
	Learning Rate: 3.0888e-05
	LOSS [training: 0.5186488267221452 | validation: 0.4490327502319703]
	TIME [epoch: 9.53 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5293086890503664		[learning rate: 3.0776e-05]
	Learning Rate: 3.07759e-05
	LOSS [training: 0.5293086890503664 | validation: 0.4651344989239358]
	TIME [epoch: 9.54 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5172070452877143		[learning rate: 3.0664e-05]
	Learning Rate: 3.06642e-05
	LOSS [training: 0.5172070452877143 | validation: 0.457838142820458]
	TIME [epoch: 9.53 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5282896646284249		[learning rate: 3.0553e-05]
	Learning Rate: 3.05529e-05
	LOSS [training: 0.5282896646284249 | validation: 0.44973133798499243]
	TIME [epoch: 9.53 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5306186596229041		[learning rate: 3.0442e-05]
	Learning Rate: 3.0442e-05
	LOSS [training: 0.5306186596229041 | validation: 0.4323709556983472]
	TIME [epoch: 9.54 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5228457020517696		[learning rate: 3.0332e-05]
	Learning Rate: 3.03316e-05
	LOSS [training: 0.5228457020517696 | validation: 0.4427134042167763]
	TIME [epoch: 9.53 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5183482773473354		[learning rate: 3.0221e-05]
	Learning Rate: 3.02215e-05
	LOSS [training: 0.5183482773473354 | validation: 0.45514591712693003]
	TIME [epoch: 9.53 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5236557461298905		[learning rate: 3.0112e-05]
	Learning Rate: 3.01118e-05
	LOSS [training: 0.5236557461298905 | validation: 0.44613853351540966]
	TIME [epoch: 9.54 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5218618452856951		[learning rate: 3.0003e-05]
	Learning Rate: 3.00025e-05
	LOSS [training: 0.5218618452856951 | validation: 0.4590186551395938]
	TIME [epoch: 9.55 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.525395826876377		[learning rate: 2.9894e-05]
	Learning Rate: 2.98936e-05
	LOSS [training: 0.525395826876377 | validation: 0.45412392379882494]
	TIME [epoch: 9.53 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5290193087911004		[learning rate: 2.9785e-05]
	Learning Rate: 2.97852e-05
	LOSS [training: 0.5290193087911004 | validation: 0.45359486354048584]
	TIME [epoch: 9.52 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.520018104962934		[learning rate: 2.9677e-05]
	Learning Rate: 2.96771e-05
	LOSS [training: 0.520018104962934 | validation: 0.4680717810527076]
	TIME [epoch: 9.55 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5264662092637507		[learning rate: 2.9569e-05]
	Learning Rate: 2.95694e-05
	LOSS [training: 0.5264662092637507 | validation: 0.4567766948407123]
	TIME [epoch: 9.52 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5341381676424852		[learning rate: 2.9462e-05]
	Learning Rate: 2.94621e-05
	LOSS [training: 0.5341381676424852 | validation: 0.45123583845452536]
	TIME [epoch: 9.52 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5310009362090444		[learning rate: 2.9355e-05]
	Learning Rate: 2.93551e-05
	LOSS [training: 0.5310009362090444 | validation: 0.4646055422807044]
	TIME [epoch: 9.53 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5257289764695561		[learning rate: 2.9249e-05]
	Learning Rate: 2.92486e-05
	LOSS [training: 0.5257289764695561 | validation: 0.43222492556435954]
	TIME [epoch: 9.54 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.525892332860711		[learning rate: 2.9142e-05]
	Learning Rate: 2.91425e-05
	LOSS [training: 0.525892332860711 | validation: 0.4686399352110632]
	TIME [epoch: 9.53 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5323552830149556		[learning rate: 2.9037e-05]
	Learning Rate: 2.90367e-05
	LOSS [training: 0.5323552830149556 | validation: 0.4383983588757528]
	TIME [epoch: 9.52 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5120655952337838		[learning rate: 2.8931e-05]
	Learning Rate: 2.89313e-05
	LOSS [training: 0.5120655952337838 | validation: 0.4368802805400281]
	TIME [epoch: 9.54 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5057297302442291		[learning rate: 2.8826e-05]
	Learning Rate: 2.88263e-05
	LOSS [training: 0.5057297302442291 | validation: 0.45232494757568165]
	TIME [epoch: 9.53 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5095349329689796		[learning rate: 2.8722e-05]
	Learning Rate: 2.87217e-05
	LOSS [training: 0.5095349329689796 | validation: 0.4574250792396157]
	TIME [epoch: 9.52 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5279402105002642		[learning rate: 2.8617e-05]
	Learning Rate: 2.86175e-05
	LOSS [training: 0.5279402105002642 | validation: 0.4568984853577179]
	TIME [epoch: 9.52 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5193986601842134		[learning rate: 2.8514e-05]
	Learning Rate: 2.85136e-05
	LOSS [training: 0.5193986601842134 | validation: 0.4364258475273131]
	TIME [epoch: 9.55 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5267968886886343		[learning rate: 2.841e-05]
	Learning Rate: 2.84102e-05
	LOSS [training: 0.5267968886886343 | validation: 0.4502053782179675]
	TIME [epoch: 9.53 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5150621683268636		[learning rate: 2.8307e-05]
	Learning Rate: 2.83071e-05
	LOSS [training: 0.5150621683268636 | validation: 0.456228470484815]
	TIME [epoch: 9.53 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5304066741399869		[learning rate: 2.8204e-05]
	Learning Rate: 2.82043e-05
	LOSS [training: 0.5304066741399869 | validation: 0.4516905346996897]
	TIME [epoch: 9.54 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5291300627580153		[learning rate: 2.8102e-05]
	Learning Rate: 2.8102e-05
	LOSS [training: 0.5291300627580153 | validation: 0.462035854161495]
	TIME [epoch: 9.52 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5187694642873716		[learning rate: 2.8e-05]
	Learning Rate: 2.8e-05
	LOSS [training: 0.5187694642873716 | validation: 0.4701389627727077]
	TIME [epoch: 9.52 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5238140995068215		[learning rate: 2.7898e-05]
	Learning Rate: 2.78984e-05
	LOSS [training: 0.5238140995068215 | validation: 0.44565265662266995]
	TIME [epoch: 9.54 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5193936368176377		[learning rate: 2.7797e-05]
	Learning Rate: 2.77971e-05
	LOSS [training: 0.5193936368176377 | validation: 0.44714719127491065]
	TIME [epoch: 9.53 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5346486626748306		[learning rate: 2.7696e-05]
	Learning Rate: 2.76963e-05
	LOSS [training: 0.5346486626748306 | validation: 0.4676933234603813]
	TIME [epoch: 9.53 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5353874818053851		[learning rate: 2.7596e-05]
	Learning Rate: 2.75957e-05
	LOSS [training: 0.5353874818053851 | validation: 0.45396954842775034]
	TIME [epoch: 9.53 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.519781586361181		[learning rate: 2.7496e-05]
	Learning Rate: 2.74956e-05
	LOSS [training: 0.519781586361181 | validation: 0.4570347968205695]
	TIME [epoch: 9.56 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5182062012787088		[learning rate: 2.7396e-05]
	Learning Rate: 2.73958e-05
	LOSS [training: 0.5182062012787088 | validation: 0.44238653361200486]
	TIME [epoch: 9.52 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5263332789388567		[learning rate: 2.7296e-05]
	Learning Rate: 2.72964e-05
	LOSS [training: 0.5263332789388567 | validation: 0.4436417937187774]
	TIME [epoch: 9.53 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5279010709962512		[learning rate: 2.7197e-05]
	Learning Rate: 2.71973e-05
	LOSS [training: 0.5279010709962512 | validation: 0.44914362190332496]
	TIME [epoch: 9.54 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5219243269786316		[learning rate: 2.7099e-05]
	Learning Rate: 2.70986e-05
	LOSS [training: 0.5219243269786316 | validation: 0.4477657137396461]
	TIME [epoch: 9.53 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5259603218851906		[learning rate: 2.7e-05]
	Learning Rate: 2.70003e-05
	LOSS [training: 0.5259603218851906 | validation: 0.45828070373472196]
	TIME [epoch: 9.53 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5168932902559863		[learning rate: 2.6902e-05]
	Learning Rate: 2.69023e-05
	LOSS [training: 0.5168932902559863 | validation: 0.4714661404994554]
	TIME [epoch: 9.52 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.520776133611637		[learning rate: 2.6805e-05]
	Learning Rate: 2.68047e-05
	LOSS [training: 0.520776133611637 | validation: 0.450485439759237]
	TIME [epoch: 9.55 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5134773959449546		[learning rate: 2.6707e-05]
	Learning Rate: 2.67074e-05
	LOSS [training: 0.5134773959449546 | validation: 0.4502135229569423]
	TIME [epoch: 9.53 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5230260829874943		[learning rate: 2.661e-05]
	Learning Rate: 2.66105e-05
	LOSS [training: 0.5230260829874943 | validation: 0.4307279308113847]
	TIME [epoch: 9.52 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5144161340982005		[learning rate: 2.6514e-05]
	Learning Rate: 2.65139e-05
	LOSS [training: 0.5144161340982005 | validation: 0.44046858117569315]
	TIME [epoch: 9.54 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5283532852242881		[learning rate: 2.6418e-05]
	Learning Rate: 2.64177e-05
	LOSS [training: 0.5283532852242881 | validation: 0.4486203417940004]
	TIME [epoch: 9.53 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5275048230815409		[learning rate: 2.6322e-05]
	Learning Rate: 2.63218e-05
	LOSS [training: 0.5275048230815409 | validation: 0.4510297120476045]
	TIME [epoch: 9.52 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5344432328481015		[learning rate: 2.6226e-05]
	Learning Rate: 2.62263e-05
	LOSS [training: 0.5344432328481015 | validation: 0.4384598037242125]
	TIME [epoch: 9.52 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5346976472897716		[learning rate: 2.6131e-05]
	Learning Rate: 2.61311e-05
	LOSS [training: 0.5346976472897716 | validation: 0.4516802078897316]
	TIME [epoch: 9.54 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.513971696309866		[learning rate: 2.6036e-05]
	Learning Rate: 2.60363e-05
	LOSS [training: 0.513971696309866 | validation: 0.4732165437311291]
	TIME [epoch: 9.52 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5175989568810933		[learning rate: 2.5942e-05]
	Learning Rate: 2.59418e-05
	LOSS [training: 0.5175989568810933 | validation: 0.4394263887607696]
	TIME [epoch: 9.52 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5164603725614549		[learning rate: 2.5848e-05]
	Learning Rate: 2.58477e-05
	LOSS [training: 0.5164603725614549 | validation: 0.44651716286237814]
	TIME [epoch: 9.54 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5260675006163791		[learning rate: 2.5754e-05]
	Learning Rate: 2.57539e-05
	LOSS [training: 0.5260675006163791 | validation: 0.4646040963120437]
	TIME [epoch: 9.52 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5134648489555638		[learning rate: 2.566e-05]
	Learning Rate: 2.56604e-05
	LOSS [training: 0.5134648489555638 | validation: 0.4399425808558681]
	TIME [epoch: 9.52 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.523248838610631		[learning rate: 2.5567e-05]
	Learning Rate: 2.55673e-05
	LOSS [training: 0.523248838610631 | validation: 0.453669070117486]
	TIME [epoch: 9.55 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5140849830882698		[learning rate: 2.5474e-05]
	Learning Rate: 2.54745e-05
	LOSS [training: 0.5140849830882698 | validation: 0.4503639601266911]
	TIME [epoch: 9.55 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5094155520118234		[learning rate: 2.5382e-05]
	Learning Rate: 2.5382e-05
	LOSS [training: 0.5094155520118234 | validation: 0.44523880610543715]
	TIME [epoch: 9.52 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5113880233234165		[learning rate: 2.529e-05]
	Learning Rate: 2.52899e-05
	LOSS [training: 0.5113880233234165 | validation: 0.4429071492631796]
	TIME [epoch: 9.51 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5298865427465206		[learning rate: 2.5198e-05]
	Learning Rate: 2.51981e-05
	LOSS [training: 0.5298865427465206 | validation: 0.46200422388468054]
	TIME [epoch: 9.54 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5166736808122478		[learning rate: 2.5107e-05]
	Learning Rate: 2.51067e-05
	LOSS [training: 0.5166736808122478 | validation: 0.45218089214068047]
	TIME [epoch: 9.52 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5255035788787971		[learning rate: 2.5016e-05]
	Learning Rate: 2.50156e-05
	LOSS [training: 0.5255035788787971 | validation: 0.46089235090275266]
	TIME [epoch: 9.52 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5180290006533477		[learning rate: 2.4925e-05]
	Learning Rate: 2.49248e-05
	LOSS [training: 0.5180290006533477 | validation: 0.4580317720979704]
	TIME [epoch: 9.52 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5246525805373912		[learning rate: 2.4834e-05]
	Learning Rate: 2.48343e-05
	LOSS [training: 0.5246525805373912 | validation: 0.4363618853162738]
	TIME [epoch: 9.54 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5227137413582349		[learning rate: 2.4744e-05]
	Learning Rate: 2.47442e-05
	LOSS [training: 0.5227137413582349 | validation: 0.45238582024136575]
	TIME [epoch: 9.52 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5254331399260599		[learning rate: 2.4654e-05]
	Learning Rate: 2.46544e-05
	LOSS [training: 0.5254331399260599 | validation: 0.4431073571042509]
	TIME [epoch: 9.52 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5214660430973377		[learning rate: 2.4565e-05]
	Learning Rate: 2.45649e-05
	LOSS [training: 0.5214660430973377 | validation: 0.4415895592793227]
	TIME [epoch: 9.54 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5284604746539375		[learning rate: 2.4476e-05]
	Learning Rate: 2.44758e-05
	LOSS [training: 0.5284604746539375 | validation: 0.4377094615829436]
	TIME [epoch: 9.53 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5193318884557818		[learning rate: 2.4387e-05]
	Learning Rate: 2.4387e-05
	LOSS [training: 0.5193318884557818 | validation: 0.4574239645028489]
	TIME [epoch: 9.52 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5327913859796409		[learning rate: 2.4298e-05]
	Learning Rate: 2.42985e-05
	LOSS [training: 0.5327913859796409 | validation: 0.4587509617010575]
	TIME [epoch: 9.53 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5292146904342903		[learning rate: 2.421e-05]
	Learning Rate: 2.42103e-05
	LOSS [training: 0.5292146904342903 | validation: 0.4546638085601677]
	TIME [epoch: 9.54 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5273387726053205		[learning rate: 2.4122e-05]
	Learning Rate: 2.41224e-05
	LOSS [training: 0.5273387726053205 | validation: 0.4485350244699728]
	TIME [epoch: 9.53 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5322023419602628		[learning rate: 2.4035e-05]
	Learning Rate: 2.40349e-05
	LOSS [training: 0.5322023419602628 | validation: 0.46864494099677667]
	TIME [epoch: 9.52 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5238134205280327		[learning rate: 2.3948e-05]
	Learning Rate: 2.39477e-05
	LOSS [training: 0.5238134205280327 | validation: 0.48459780308744344]
	TIME [epoch: 9.54 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5224044417728184		[learning rate: 2.3861e-05]
	Learning Rate: 2.38608e-05
	LOSS [training: 0.5224044417728184 | validation: 0.4840741167139996]
	TIME [epoch: 9.53 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.53073214730041		[learning rate: 2.3774e-05]
	Learning Rate: 2.37742e-05
	LOSS [training: 0.53073214730041 | validation: 0.47138116001321967]
	TIME [epoch: 9.53 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5216529380122953		[learning rate: 2.3688e-05]
	Learning Rate: 2.36879e-05
	LOSS [training: 0.5216529380122953 | validation: 0.47049994231951764]
	TIME [epoch: 9.52 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5156664397411463		[learning rate: 2.3602e-05]
	Learning Rate: 2.36019e-05
	LOSS [training: 0.5156664397411463 | validation: 0.4671080237776131]
	TIME [epoch: 9.54 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5285241406197031		[learning rate: 2.3516e-05]
	Learning Rate: 2.35163e-05
	LOSS [training: 0.5285241406197031 | validation: 0.48155116305914486]
	TIME [epoch: 9.53 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5354788946059059		[learning rate: 2.3431e-05]
	Learning Rate: 2.34309e-05
	LOSS [training: 0.5354788946059059 | validation: 0.4565692185864274]
	TIME [epoch: 9.53 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5252957307705132		[learning rate: 2.3346e-05]
	Learning Rate: 2.33459e-05
	LOSS [training: 0.5252957307705132 | validation: 0.4773798054630591]
	TIME [epoch: 9.54 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5169190325523767		[learning rate: 2.3261e-05]
	Learning Rate: 2.32612e-05
	LOSS [training: 0.5169190325523767 | validation: 0.4771733047999532]
	TIME [epoch: 9.53 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5349081785505175		[learning rate: 2.3177e-05]
	Learning Rate: 2.31768e-05
	LOSS [training: 0.5349081785505175 | validation: 0.44575408596390986]
	TIME [epoch: 9.52 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5258555998986589		[learning rate: 2.3093e-05]
	Learning Rate: 2.30926e-05
	LOSS [training: 0.5258555998986589 | validation: 0.4571769870316814]
	TIME [epoch: 9.54 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5232910414246429		[learning rate: 2.3009e-05]
	Learning Rate: 2.30088e-05
	LOSS [training: 0.5232910414246429 | validation: 0.45108016575074034]
	TIME [epoch: 9.53 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5134905469578785		[learning rate: 2.2925e-05]
	Learning Rate: 2.29253e-05
	LOSS [training: 0.5134905469578785 | validation: 0.4690366276081923]
	TIME [epoch: 9.52 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5203436694559246		[learning rate: 2.2842e-05]
	Learning Rate: 2.28421e-05
	LOSS [training: 0.5203436694559246 | validation: 0.45372313267993475]
	TIME [epoch: 9.53 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5305952401070326		[learning rate: 2.2759e-05]
	Learning Rate: 2.27592e-05
	LOSS [training: 0.5305952401070326 | validation: 0.4493592901952709]
	TIME [epoch: 9.55 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5199044690814404		[learning rate: 2.2677e-05]
	Learning Rate: 2.26767e-05
	LOSS [training: 0.5199044690814404 | validation: 0.4621197208398378]
	TIME [epoch: 9.52 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5320689397705378		[learning rate: 2.2594e-05]
	Learning Rate: 2.25944e-05
	LOSS [training: 0.5320689397705378 | validation: 0.47209829749308946]
	TIME [epoch: 9.53 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5197889656227794		[learning rate: 2.2512e-05]
	Learning Rate: 2.25124e-05
	LOSS [training: 0.5197889656227794 | validation: 0.4652046588793371]
	TIME [epoch: 9.54 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5251103527973322		[learning rate: 2.2431e-05]
	Learning Rate: 2.24307e-05
	LOSS [training: 0.5251103527973322 | validation: 0.45283482500918193]
	TIME [epoch: 9.54 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5124435673218339		[learning rate: 2.2349e-05]
	Learning Rate: 2.23493e-05
	LOSS [training: 0.5124435673218339 | validation: 0.4654981669530641]
	TIME [epoch: 9.53 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5242167543031515		[learning rate: 2.2268e-05]
	Learning Rate: 2.22682e-05
	LOSS [training: 0.5242167543031515 | validation: 0.46270291193745666]
	TIME [epoch: 9.53 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5228244263158205		[learning rate: 2.2187e-05]
	Learning Rate: 2.21873e-05
	LOSS [training: 0.5228244263158205 | validation: 0.45840435219769005]
	TIME [epoch: 9.55 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5273620289870771		[learning rate: 2.2107e-05]
	Learning Rate: 2.21068e-05
	LOSS [training: 0.5273620289870771 | validation: 0.4578697403348471]
	TIME [epoch: 9.53 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5178054706134103		[learning rate: 2.2027e-05]
	Learning Rate: 2.20266e-05
	LOSS [training: 0.5178054706134103 | validation: 0.45863063971652845]
	TIME [epoch: 9.53 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5248564540227558		[learning rate: 2.1947e-05]
	Learning Rate: 2.19467e-05
	LOSS [training: 0.5248564540227558 | validation: 0.4569845744009834]
	TIME [epoch: 9.54 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5276535885087373		[learning rate: 2.1867e-05]
	Learning Rate: 2.1867e-05
	LOSS [training: 0.5276535885087373 | validation: 0.45089814648403953]
	TIME [epoch: 9.53 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5181330475714153		[learning rate: 2.1788e-05]
	Learning Rate: 2.17877e-05
	LOSS [training: 0.5181330475714153 | validation: 0.46086697829845535]
	TIME [epoch: 9.53 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5155499926078353		[learning rate: 2.1709e-05]
	Learning Rate: 2.17086e-05
	LOSS [training: 0.5155499926078353 | validation: 0.4466054973765904]
	TIME [epoch: 9.53 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5338818314032685		[learning rate: 2.163e-05]
	Learning Rate: 2.16298e-05
	LOSS [training: 0.5338818314032685 | validation: 0.45220145412674373]
	TIME [epoch: 9.54 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5218402521450703		[learning rate: 2.1551e-05]
	Learning Rate: 2.15513e-05
	LOSS [training: 0.5218402521450703 | validation: 0.4538352440941913]
	TIME [epoch: 9.53 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5193327437609923		[learning rate: 2.1473e-05]
	Learning Rate: 2.14731e-05
	LOSS [training: 0.5193327437609923 | validation: 0.4466073605679668]
	TIME [epoch: 9.53 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5214984193948731		[learning rate: 2.1395e-05]
	Learning Rate: 2.13952e-05
	LOSS [training: 0.5214984193948731 | validation: 0.45874295164422424]
	TIME [epoch: 9.54 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5207052076095564		[learning rate: 2.1318e-05]
	Learning Rate: 2.13175e-05
	LOSS [training: 0.5207052076095564 | validation: 0.4370858473391275]
	TIME [epoch: 9.53 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5064239839699713		[learning rate: 2.124e-05]
	Learning Rate: 2.12402e-05
	LOSS [training: 0.5064239839699713 | validation: 0.45924035696183596]
	TIME [epoch: 9.52 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5239084798980325		[learning rate: 2.1163e-05]
	Learning Rate: 2.11631e-05
	LOSS [training: 0.5239084798980325 | validation: 0.4399969053442368]
	TIME [epoch: 9.52 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5121537341315787		[learning rate: 2.1086e-05]
	Learning Rate: 2.10863e-05
	LOSS [training: 0.5121537341315787 | validation: 0.45251571587208644]
	TIME [epoch: 9.54 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5306288213234627		[learning rate: 2.101e-05]
	Learning Rate: 2.10098e-05
	LOSS [training: 0.5306288213234627 | validation: 0.44570784415074605]
	TIME [epoch: 9.53 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5288126114298993		[learning rate: 2.0934e-05]
	Learning Rate: 2.09335e-05
	LOSS [training: 0.5288126114298993 | validation: 0.44532087315916186]
	TIME [epoch: 9.52 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5289265634693526		[learning rate: 2.0858e-05]
	Learning Rate: 2.08575e-05
	LOSS [training: 0.5289265634693526 | validation: 0.468413511520195]
	TIME [epoch: 9.55 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5093966805661249		[learning rate: 2.0782e-05]
	Learning Rate: 2.07819e-05
	LOSS [training: 0.5093966805661249 | validation: 0.44970979752968276]
	TIME [epoch: 9.54 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5211245646096632		[learning rate: 2.0706e-05]
	Learning Rate: 2.07064e-05
	LOSS [training: 0.5211245646096632 | validation: 0.46771749015115377]
	TIME [epoch: 9.53 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5172287624318057		[learning rate: 2.0631e-05]
	Learning Rate: 2.06313e-05
	LOSS [training: 0.5172287624318057 | validation: 0.4454130118966172]
	TIME [epoch: 9.53 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5254974838739968		[learning rate: 2.0556e-05]
	Learning Rate: 2.05564e-05
	LOSS [training: 0.5254974838739968 | validation: 0.46162495542310583]
	TIME [epoch: 9.55 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5168726244468924		[learning rate: 2.0482e-05]
	Learning Rate: 2.04818e-05
	LOSS [training: 0.5168726244468924 | validation: 0.4636000694053131]
	TIME [epoch: 9.53 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.535309927000735		[learning rate: 2.0407e-05]
	Learning Rate: 2.04075e-05
	LOSS [training: 0.535309927000735 | validation: 0.4458499208315693]
	TIME [epoch: 9.52 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5231128997109487		[learning rate: 2.0333e-05]
	Learning Rate: 2.03334e-05
	LOSS [training: 0.5231128997109487 | validation: 0.4536406547455345]
	TIME [epoch: 9.55 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5312158898980469		[learning rate: 2.026e-05]
	Learning Rate: 2.02596e-05
	LOSS [training: 0.5312158898980469 | validation: 0.45400638061848037]
	TIME [epoch: 9.54 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5154928689889572		[learning rate: 2.0186e-05]
	Learning Rate: 2.01861e-05
	LOSS [training: 0.5154928689889572 | validation: 0.46108515702608743]
	TIME [epoch: 9.53 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5255101591901389		[learning rate: 2.0113e-05]
	Learning Rate: 2.01129e-05
	LOSS [training: 0.5255101591901389 | validation: 0.46495000318931395]
	TIME [epoch: 9.54 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5303450236328968		[learning rate: 2.004e-05]
	Learning Rate: 2.00399e-05
	LOSS [training: 0.5303450236328968 | validation: 0.4705454088974777]
	TIME [epoch: 9.55 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5303620755912415		[learning rate: 1.9967e-05]
	Learning Rate: 1.99671e-05
	LOSS [training: 0.5303620755912415 | validation: 0.45784700078076623]
	TIME [epoch: 9.53 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5174070698416449		[learning rate: 1.9895e-05]
	Learning Rate: 1.98947e-05
	LOSS [training: 0.5174070698416449 | validation: 0.4710365134088814]
	TIME [epoch: 9.53 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5293762497850375		[learning rate: 1.9822e-05]
	Learning Rate: 1.98225e-05
	LOSS [training: 0.5293762497850375 | validation: 0.44246999423395367]
	TIME [epoch: 9.55 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5320944274669623		[learning rate: 1.9751e-05]
	Learning Rate: 1.97505e-05
	LOSS [training: 0.5320944274669623 | validation: 0.4594045600926792]
	TIME [epoch: 9.53 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5199848761407517		[learning rate: 1.9679e-05]
	Learning Rate: 1.96789e-05
	LOSS [training: 0.5199848761407517 | validation: 0.4738404332264042]
	TIME [epoch: 9.53 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5245562919182924		[learning rate: 1.9607e-05]
	Learning Rate: 1.96074e-05
	LOSS [training: 0.5245562919182924 | validation: 0.45631209170638165]
	TIME [epoch: 9.53 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5179118463991816		[learning rate: 1.9536e-05]
	Learning Rate: 1.95363e-05
	LOSS [training: 0.5179118463991816 | validation: 0.47209005236022433]
	TIME [epoch: 9.55 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5301311415648471		[learning rate: 1.9465e-05]
	Learning Rate: 1.94654e-05
	LOSS [training: 0.5301311415648471 | validation: 0.45691187016840235]
	TIME [epoch: 9.53 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.518604723293108		[learning rate: 1.9395e-05]
	Learning Rate: 1.93948e-05
	LOSS [training: 0.518604723293108 | validation: 0.45802561784904317]
	TIME [epoch: 9.52 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5220240027033001		[learning rate: 1.9324e-05]
	Learning Rate: 1.93244e-05
	LOSS [training: 0.5220240027033001 | validation: 0.42676180453599244]
	TIME [epoch: 9.55 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.531479751562111		[learning rate: 1.9254e-05]
	Learning Rate: 1.92542e-05
	LOSS [training: 0.531479751562111 | validation: 0.4711053881684732]
	TIME [epoch: 9.52 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5304687729492997		[learning rate: 1.9184e-05]
	Learning Rate: 1.91844e-05
	LOSS [training: 0.5304687729492997 | validation: 0.4463901429853337]
	TIME [epoch: 9.53 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5220790160043045		[learning rate: 1.9115e-05]
	Learning Rate: 1.91147e-05
	LOSS [training: 0.5220790160043045 | validation: 0.44876079364236887]
	TIME [epoch: 9.54 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5214343626238067		[learning rate: 1.9045e-05]
	Learning Rate: 1.90454e-05
	LOSS [training: 0.5214343626238067 | validation: 0.4505973821577341]
	TIME [epoch: 9.54 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5255538680435631		[learning rate: 1.8976e-05]
	Learning Rate: 1.89763e-05
	LOSS [training: 0.5255538680435631 | validation: 0.46309575893512595]
	TIME [epoch: 9.52 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.532590673357572		[learning rate: 1.8907e-05]
	Learning Rate: 1.89074e-05
	LOSS [training: 0.532590673357572 | validation: 0.47264705258525525]
	TIME [epoch: 9.53 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5166719395277843		[learning rate: 1.8839e-05]
	Learning Rate: 1.88388e-05
	LOSS [training: 0.5166719395277843 | validation: 0.4538384580700728]
	TIME [epoch: 9.55 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5444854323676251		[learning rate: 1.877e-05]
	Learning Rate: 1.87704e-05
	LOSS [training: 0.5444854323676251 | validation: 0.4592666004161181]
	TIME [epoch: 9.53 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5268180689320496		[learning rate: 1.8702e-05]
	Learning Rate: 1.87023e-05
	LOSS [training: 0.5268180689320496 | validation: 0.4447200499330329]
	TIME [epoch: 9.53 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5226882211995526		[learning rate: 1.8634e-05]
	Learning Rate: 1.86344e-05
	LOSS [training: 0.5226882211995526 | validation: 0.46271120769652757]
	TIME [epoch: 9.53 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5218902256875629		[learning rate: 1.8567e-05]
	Learning Rate: 1.85668e-05
	LOSS [training: 0.5218902256875629 | validation: 0.4540324730934553]
	TIME [epoch: 9.54 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5172462090361123		[learning rate: 1.8499e-05]
	Learning Rate: 1.84994e-05
	LOSS [training: 0.5172462090361123 | validation: 0.4644190364244606]
	TIME [epoch: 9.52 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5204272034153729		[learning rate: 1.8432e-05]
	Learning Rate: 1.84323e-05
	LOSS [training: 0.5204272034153729 | validation: 0.4514003576117696]
	TIME [epoch: 9.53 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.512960212263197		[learning rate: 1.8365e-05]
	Learning Rate: 1.83654e-05
	LOSS [training: 0.512960212263197 | validation: 0.4473825806043521]
	TIME [epoch: 9.55 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5198928484339999		[learning rate: 1.8299e-05]
	Learning Rate: 1.82987e-05
	LOSS [training: 0.5198928484339999 | validation: 0.4368834792364237]
	TIME [epoch: 9.53 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5194638978488733		[learning rate: 1.8232e-05]
	Learning Rate: 1.82323e-05
	LOSS [training: 0.5194638978488733 | validation: 0.4683243510631445]
	TIME [epoch: 9.53 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5166834309282358		[learning rate: 1.8166e-05]
	Learning Rate: 1.81662e-05
	LOSS [training: 0.5166834309282358 | validation: 0.4309742791047447]
	TIME [epoch: 9.54 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5320356549250079		[learning rate: 1.81e-05]
	Learning Rate: 1.81002e-05
	LOSS [training: 0.5320356549250079 | validation: 0.4728791940276844]
	TIME [epoch: 9.53 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.518660675194965		[learning rate: 1.8035e-05]
	Learning Rate: 1.80346e-05
	LOSS [training: 0.518660675194965 | validation: 0.4635002864113446]
	TIME [epoch: 9.54 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5206003518242698		[learning rate: 1.7969e-05]
	Learning Rate: 1.79691e-05
	LOSS [training: 0.5206003518242698 | validation: 0.4413194561790678]
	TIME [epoch: 9.53 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5212492971284008		[learning rate: 1.7904e-05]
	Learning Rate: 1.79039e-05
	LOSS [training: 0.5212492971284008 | validation: 0.4407657020548406]
	TIME [epoch: 9.55 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5221792778000165		[learning rate: 1.7839e-05]
	Learning Rate: 1.78389e-05
	LOSS [training: 0.5221792778000165 | validation: 0.44636922174469834]
	TIME [epoch: 9.53 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5217277964932185		[learning rate: 1.7774e-05]
	Learning Rate: 1.77742e-05
	LOSS [training: 0.5217277964932185 | validation: 0.43606133259842295]
	TIME [epoch: 9.52 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5165279986609264		[learning rate: 1.771e-05]
	Learning Rate: 1.77097e-05
	LOSS [training: 0.5165279986609264 | validation: 0.4275307317010658]
	TIME [epoch: 9.55 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.524587956356176		[learning rate: 1.7645e-05]
	Learning Rate: 1.76454e-05
	LOSS [training: 0.524587956356176 | validation: 0.4473811192065314]
	TIME [epoch: 9.53 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5180917349563985		[learning rate: 1.7581e-05]
	Learning Rate: 1.75814e-05
	LOSS [training: 0.5180917349563985 | validation: 0.4553694071602212]
	TIME [epoch: 9.53 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5202695238523811		[learning rate: 1.7518e-05]
	Learning Rate: 1.75176e-05
	LOSS [training: 0.5202695238523811 | validation: 0.452226244709304]
	TIME [epoch: 9.53 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5112572715727253		[learning rate: 1.7454e-05]
	Learning Rate: 1.7454e-05
	LOSS [training: 0.5112572715727253 | validation: 0.4449743411390417]
	TIME [epoch: 9.55 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5196771582791663		[learning rate: 1.7391e-05]
	Learning Rate: 1.73907e-05
	LOSS [training: 0.5196771582791663 | validation: 0.43829662731452823]
	TIME [epoch: 9.53 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.528366889901854		[learning rate: 1.7328e-05]
	Learning Rate: 1.73275e-05
	LOSS [training: 0.528366889901854 | validation: 0.469947164321651]
	TIME [epoch: 9.52 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5089887167734293		[learning rate: 1.7265e-05]
	Learning Rate: 1.72647e-05
	LOSS [training: 0.5089887167734293 | validation: 0.45325335153070234]
	TIME [epoch: 9.54 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5242382168902411		[learning rate: 1.7202e-05]
	Learning Rate: 1.7202e-05
	LOSS [training: 0.5242382168902411 | validation: 0.44468068295239804]
	TIME [epoch: 9.53 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5239452399890366		[learning rate: 1.714e-05]
	Learning Rate: 1.71396e-05
	LOSS [training: 0.5239452399890366 | validation: 0.45824323834852315]
	TIME [epoch: 9.53 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.526534694932819		[learning rate: 1.7077e-05]
	Learning Rate: 1.70774e-05
	LOSS [training: 0.526534694932819 | validation: 0.4280227488095508]
	TIME [epoch: 9.53 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5204146245159575		[learning rate: 1.7015e-05]
	Learning Rate: 1.70154e-05
	LOSS [training: 0.5204146245159575 | validation: 0.46370677926640697]
	TIME [epoch: 9.54 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5315723414439437		[learning rate: 1.6954e-05]
	Learning Rate: 1.69537e-05
	LOSS [training: 0.5315723414439437 | validation: 0.4706874919296012]
	TIME [epoch: 9.53 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5177370703181816		[learning rate: 1.6892e-05]
	Learning Rate: 1.68921e-05
	LOSS [training: 0.5177370703181816 | validation: 0.44890673925685554]
	TIME [epoch: 9.52 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.510805406632295		[learning rate: 1.6831e-05]
	Learning Rate: 1.68308e-05
	LOSS [training: 0.510805406632295 | validation: 0.462686318593617]
	TIME [epoch: 9.55 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5130255398402177		[learning rate: 1.677e-05]
	Learning Rate: 1.67697e-05
	LOSS [training: 0.5130255398402177 | validation: 0.42792934337288957]
	TIME [epoch: 9.54 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5351416359468365		[learning rate: 1.6709e-05]
	Learning Rate: 1.67089e-05
	LOSS [training: 0.5351416359468365 | validation: 0.4552471896747314]
	TIME [epoch: 9.53 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5040434591713168		[learning rate: 1.6648e-05]
	Learning Rate: 1.66482e-05
	LOSS [training: 0.5040434591713168 | validation: 0.4530616448904719]
	TIME [epoch: 9.53 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5178651720657201		[learning rate: 1.6588e-05]
	Learning Rate: 1.65878e-05
	LOSS [training: 0.5178651720657201 | validation: 0.44579008400744563]
	TIME [epoch: 9.55 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5293249904688611		[learning rate: 1.6528e-05]
	Learning Rate: 1.65276e-05
	LOSS [training: 0.5293249904688611 | validation: 0.4351060445405102]
	TIME [epoch: 9.53 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5083687145032718		[learning rate: 1.6468e-05]
	Learning Rate: 1.64677e-05
	LOSS [training: 0.5083687145032718 | validation: 0.43083217383764466]
	TIME [epoch: 9.52 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5259077035507407		[learning rate: 1.6408e-05]
	Learning Rate: 1.64079e-05
	LOSS [training: 0.5259077035507407 | validation: 0.4474317991554982]
	TIME [epoch: 9.55 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5139539183924249		[learning rate: 1.6348e-05]
	Learning Rate: 1.63483e-05
	LOSS [training: 0.5139539183924249 | validation: 0.44841429431703744]
	TIME [epoch: 9.52 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5243959683820022		[learning rate: 1.6289e-05]
	Learning Rate: 1.6289e-05
	LOSS [training: 0.5243959683820022 | validation: 0.4599860666684951]
	TIME [epoch: 9.52 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5172451815074228		[learning rate: 1.623e-05]
	Learning Rate: 1.62299e-05
	LOSS [training: 0.5172451815074228 | validation: 0.43919531983943155]
	TIME [epoch: 9.53 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5302060431043523		[learning rate: 1.6171e-05]
	Learning Rate: 1.6171e-05
	LOSS [training: 0.5302060431043523 | validation: 0.45844826721443005]
	TIME [epoch: 9.55 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5270152936793807		[learning rate: 1.6112e-05]
	Learning Rate: 1.61123e-05
	LOSS [training: 0.5270152936793807 | validation: 0.4724876404764002]
	TIME [epoch: 9.52 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5262774963813361		[learning rate: 1.6054e-05]
	Learning Rate: 1.60538e-05
	LOSS [training: 0.5262774963813361 | validation: 0.44678473230342014]
	TIME [epoch: 9.52 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5178340994023711		[learning rate: 1.5996e-05]
	Learning Rate: 1.59956e-05
	LOSS [training: 0.5178340994023711 | validation: 0.42403843550504083]
	TIME [epoch: 9.55 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5170610229452954		[learning rate: 1.5938e-05]
	Learning Rate: 1.59375e-05
	LOSS [training: 0.5170610229452954 | validation: 0.47337716824575865]
	TIME [epoch: 9.53 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5173463154284338		[learning rate: 1.588e-05]
	Learning Rate: 1.58797e-05
	LOSS [training: 0.5173463154284338 | validation: 0.4410692783977238]
	TIME [epoch: 9.52 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5321554141248368		[learning rate: 1.5822e-05]
	Learning Rate: 1.58221e-05
	LOSS [training: 0.5321554141248368 | validation: 0.45432728528066607]
	TIME [epoch: 9.54 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5233635875805561		[learning rate: 1.5765e-05]
	Learning Rate: 1.57647e-05
	LOSS [training: 0.5233635875805561 | validation: 0.4488361085378712]
	TIME [epoch: 9.53 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5299487839288206		[learning rate: 1.5707e-05]
	Learning Rate: 1.57074e-05
	LOSS [training: 0.5299487839288206 | validation: 0.43984058296839407]
	TIME [epoch: 9.52 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5235796917972817		[learning rate: 1.565e-05]
	Learning Rate: 1.56504e-05
	LOSS [training: 0.5235796917972817 | validation: 0.4563383242416471]
	TIME [epoch: 9.52 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5135709313269722		[learning rate: 1.5594e-05]
	Learning Rate: 1.55936e-05
	LOSS [training: 0.5135709313269722 | validation: 0.4690112414413288]
	TIME [epoch: 9.55 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5220778704150957		[learning rate: 1.5537e-05]
	Learning Rate: 1.5537e-05
	LOSS [training: 0.5220778704150957 | validation: 0.4532582043214522]
	TIME [epoch: 9.53 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5323660066290082		[learning rate: 1.5481e-05]
	Learning Rate: 1.54807e-05
	LOSS [training: 0.5323660066290082 | validation: 0.4430114621972063]
	TIME [epoch: 9.53 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5217986826771233		[learning rate: 1.5424e-05]
	Learning Rate: 1.54245e-05
	LOSS [training: 0.5217986826771233 | validation: 0.4450028303506185]
	TIME [epoch: 9.54 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5227649314044929		[learning rate: 1.5369e-05]
	Learning Rate: 1.53685e-05
	LOSS [training: 0.5227649314044929 | validation: 0.45545151425511454]
	TIME [epoch: 9.54 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5201807020070147		[learning rate: 1.5313e-05]
	Learning Rate: 1.53127e-05
	LOSS [training: 0.5201807020070147 | validation: 0.440450338678005]
	TIME [epoch: 9.53 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5176286755342778		[learning rate: 1.5257e-05]
	Learning Rate: 1.52572e-05
	LOSS [training: 0.5176286755342778 | validation: 0.44679309234555425]
	TIME [epoch: 9.53 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5225696417476159		[learning rate: 1.5202e-05]
	Learning Rate: 1.52018e-05
	LOSS [training: 0.5225696417476159 | validation: 0.4272211211308411]
	TIME [epoch: 9.55 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.530211370728787		[learning rate: 1.5147e-05]
	Learning Rate: 1.51466e-05
	LOSS [training: 0.530211370728787 | validation: 0.4464031293169255]
	TIME [epoch: 9.53 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5159336841806221		[learning rate: 1.5092e-05]
	Learning Rate: 1.50917e-05
	LOSS [training: 0.5159336841806221 | validation: 0.45106109460765076]
	TIME [epoch: 9.52 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5205783890527116		[learning rate: 1.5037e-05]
	Learning Rate: 1.50369e-05
	LOSS [training: 0.5205783890527116 | validation: 0.44508248836468073]
	TIME [epoch: 9.55 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5190367503499191		[learning rate: 1.4982e-05]
	Learning Rate: 1.49823e-05
	LOSS [training: 0.5190367503499191 | validation: 0.4477755738403452]
	TIME [epoch: 9.52 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5200272213734001		[learning rate: 1.4928e-05]
	Learning Rate: 1.49279e-05
	LOSS [training: 0.5200272213734001 | validation: 0.45983586878892657]
	TIME [epoch: 9.53 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5280445224620015		[learning rate: 1.4874e-05]
	Learning Rate: 1.48738e-05
	LOSS [training: 0.5280445224620015 | validation: 0.4604562822161949]
	TIME [epoch: 9.52 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5210611750342451		[learning rate: 1.482e-05]
	Learning Rate: 1.48198e-05
	LOSS [training: 0.5210611750342451 | validation: 0.45107095026295235]
	TIME [epoch: 9.55 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5259837190745571		[learning rate: 1.4766e-05]
	Learning Rate: 1.4766e-05
	LOSS [training: 0.5259837190745571 | validation: 0.46997858244750423]
	TIME [epoch: 9.52 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5241824010142039		[learning rate: 1.4712e-05]
	Learning Rate: 1.47124e-05
	LOSS [training: 0.5241824010142039 | validation: 0.4536380754761754]
	TIME [epoch: 9.53 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5202120075158013		[learning rate: 1.4659e-05]
	Learning Rate: 1.4659e-05
	LOSS [training: 0.5202120075158013 | validation: 0.4582810609043415]
	TIME [epoch: 9.54 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5263731774130939		[learning rate: 1.4606e-05]
	Learning Rate: 1.46058e-05
	LOSS [training: 0.5263731774130939 | validation: 0.45274035645666916]
	TIME [epoch: 9.54 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5174944762970879		[learning rate: 1.4553e-05]
	Learning Rate: 1.45528e-05
	LOSS [training: 0.5174944762970879 | validation: 0.44585248896438856]
	TIME [epoch: 9.53 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5244359660750638		[learning rate: 1.45e-05]
	Learning Rate: 1.45e-05
	LOSS [training: 0.5244359660750638 | validation: 0.4565150459911429]
	TIME [epoch: 9.53 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5193691066531161		[learning rate: 1.4447e-05]
	Learning Rate: 1.44474e-05
	LOSS [training: 0.5193691066531161 | validation: 0.4269032215319692]
	TIME [epoch: 9.56 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5225675811477389		[learning rate: 1.4395e-05]
	Learning Rate: 1.4395e-05
	LOSS [training: 0.5225675811477389 | validation: 0.4469626012485264]
	TIME [epoch: 9.52 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.515582343862698		[learning rate: 1.4343e-05]
	Learning Rate: 1.43427e-05
	LOSS [training: 0.515582343862698 | validation: 0.45492081137768636]
	TIME [epoch: 9.53 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5227571867266226		[learning rate: 1.4291e-05]
	Learning Rate: 1.42907e-05
	LOSS [training: 0.5227571867266226 | validation: 0.43456402210987405]
	TIME [epoch: 9.54 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.517725644990434		[learning rate: 1.4239e-05]
	Learning Rate: 1.42388e-05
	LOSS [training: 0.517725644990434 | validation: 0.4492359394049236]
	TIME [epoch: 9.53 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5341746044249015		[learning rate: 1.4187e-05]
	Learning Rate: 1.41871e-05
	LOSS [training: 0.5341746044249015 | validation: 0.4346653515032636]
	TIME [epoch: 9.53 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5132184513399312		[learning rate: 1.4136e-05]
	Learning Rate: 1.41357e-05
	LOSS [training: 0.5132184513399312 | validation: 0.4490604698312906]
	TIME [epoch: 9.53 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5276654060765303		[learning rate: 1.4084e-05]
	Learning Rate: 1.40844e-05
	LOSS [training: 0.5276654060765303 | validation: 0.4368838043911427]
	TIME [epoch: 9.54 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5205978124062036		[learning rate: 1.4033e-05]
	Learning Rate: 1.40332e-05
	LOSS [training: 0.5205978124062036 | validation: 0.45108202576989287]
	TIME [epoch: 9.52 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5178347992482729		[learning rate: 1.3982e-05]
	Learning Rate: 1.39823e-05
	LOSS [training: 0.5178347992482729 | validation: 0.4450629270160883]
	TIME [epoch: 9.53 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5147925297249112		[learning rate: 1.3932e-05]
	Learning Rate: 1.39316e-05
	LOSS [training: 0.5147925297249112 | validation: 0.43597064034198524]
	TIME [epoch: 9.55 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.523596461027761		[learning rate: 1.3881e-05]
	Learning Rate: 1.3881e-05
	LOSS [training: 0.523596461027761 | validation: 0.4594581179844478]
	TIME [epoch: 9.53 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5228370405209692		[learning rate: 1.3831e-05]
	Learning Rate: 1.38306e-05
	LOSS [training: 0.5228370405209692 | validation: 0.45946877196197805]
	TIME [epoch: 9.53 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5305522513376794		[learning rate: 1.378e-05]
	Learning Rate: 1.37804e-05
	LOSS [training: 0.5305522513376794 | validation: 0.44965840014359415]
	TIME [epoch: 9.53 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5156466241871416		[learning rate: 1.373e-05]
	Learning Rate: 1.37304e-05
	LOSS [training: 0.5156466241871416 | validation: 0.4365928988167013]
	TIME [epoch: 9.55 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5250922419005584		[learning rate: 1.3681e-05]
	Learning Rate: 1.36806e-05
	LOSS [training: 0.5250922419005584 | validation: 0.4360927660205329]
	TIME [epoch: 9.53 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.518483241642594		[learning rate: 1.3631e-05]
	Learning Rate: 1.3631e-05
	LOSS [training: 0.518483241642594 | validation: 0.44271233389397757]
	TIME [epoch: 9.53 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5272632061704031		[learning rate: 1.3581e-05]
	Learning Rate: 1.35815e-05
	LOSS [training: 0.5272632061704031 | validation: 0.4374582485631799]
	TIME [epoch: 9.55 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5127939293026612		[learning rate: 1.3532e-05]
	Learning Rate: 1.35322e-05
	LOSS [training: 0.5127939293026612 | validation: 0.43668606178606295]
	TIME [epoch: 9.53 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5363813011680787		[learning rate: 1.3483e-05]
	Learning Rate: 1.34831e-05
	LOSS [training: 0.5363813011680787 | validation: 0.4313297796189839]
	TIME [epoch: 9.52 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.529635891466566		[learning rate: 1.3434e-05]
	Learning Rate: 1.34342e-05
	LOSS [training: 0.529635891466566 | validation: 0.4520207953501639]
	TIME [epoch: 9.53 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5322614572470717		[learning rate: 1.3385e-05]
	Learning Rate: 1.33854e-05
	LOSS [training: 0.5322614572470717 | validation: 0.4477944183511172]
	TIME [epoch: 9.54 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5245877618483332		[learning rate: 1.3337e-05]
	Learning Rate: 1.33368e-05
	LOSS [training: 0.5245877618483332 | validation: 0.4336676618920906]
	TIME [epoch: 9.53 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5217450506513419		[learning rate: 1.3288e-05]
	Learning Rate: 1.32884e-05
	LOSS [training: 0.5217450506513419 | validation: 0.44876454616135053]
	TIME [epoch: 9.52 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5261589740336456		[learning rate: 1.324e-05]
	Learning Rate: 1.32402e-05
	LOSS [training: 0.5261589740336456 | validation: 0.4525877186817405]
	TIME [epoch: 9.55 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5173786354605943		[learning rate: 1.3192e-05]
	Learning Rate: 1.31922e-05
	LOSS [training: 0.5173786354605943 | validation: 0.43979229946823345]
	TIME [epoch: 9.52 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5108483487109805		[learning rate: 1.3144e-05]
	Learning Rate: 1.31443e-05
	LOSS [training: 0.5108483487109805 | validation: 0.446011013930076]
	TIME [epoch: 9.53 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5139936622268797		[learning rate: 1.3097e-05]
	Learning Rate: 1.30966e-05
	LOSS [training: 0.5139936622268797 | validation: 0.4319706622776121]
	TIME [epoch: 9.54 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5243545691064774		[learning rate: 1.3049e-05]
	Learning Rate: 1.30491e-05
	LOSS [training: 0.5243545691064774 | validation: 0.4475245373579324]
	TIME [epoch: 9.54 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5314617799933059		[learning rate: 1.3002e-05]
	Learning Rate: 1.30017e-05
	LOSS [training: 0.5314617799933059 | validation: 0.4467832348224099]
	TIME [epoch: 9.53 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.520038847589864		[learning rate: 1.2955e-05]
	Learning Rate: 1.29545e-05
	LOSS [training: 0.520038847589864 | validation: 0.45593475690902935]
	TIME [epoch: 9.53 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5179086405908744		[learning rate: 1.2907e-05]
	Learning Rate: 1.29075e-05
	LOSS [training: 0.5179086405908744 | validation: 0.45313516784661345]
	TIME [epoch: 9.55 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5237570025388171		[learning rate: 1.2861e-05]
	Learning Rate: 1.28607e-05
	LOSS [training: 0.5237570025388171 | validation: 0.44777289924420643]
	TIME [epoch: 9.53 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5245652688477362		[learning rate: 1.2814e-05]
	Learning Rate: 1.2814e-05
	LOSS [training: 0.5245652688477362 | validation: 0.45931268866159713]
	TIME [epoch: 9.53 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5232978302900293		[learning rate: 1.2767e-05]
	Learning Rate: 1.27675e-05
	LOSS [training: 0.5232978302900293 | validation: 0.44729363703130565]
	TIME [epoch: 9.54 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5302336714341065		[learning rate: 1.2721e-05]
	Learning Rate: 1.27212e-05
	LOSS [training: 0.5302336714341065 | validation: 0.4457818260354842]
	TIME [epoch: 9.53 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5163603162164094		[learning rate: 1.2675e-05]
	Learning Rate: 1.2675e-05
	LOSS [training: 0.5163603162164094 | validation: 0.45382190514824494]
	TIME [epoch: 9.53 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5224393243021844		[learning rate: 1.2629e-05]
	Learning Rate: 1.2629e-05
	LOSS [training: 0.5224393243021844 | validation: 0.440680036970398]
	TIME [epoch: 9.53 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5136668250249754		[learning rate: 1.2583e-05]
	Learning Rate: 1.25832e-05
	LOSS [training: 0.5136668250249754 | validation: 0.44140327981509186]
	TIME [epoch: 9.54 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5273895925410177		[learning rate: 1.2537e-05]
	Learning Rate: 1.25375e-05
	LOSS [training: 0.5273895925410177 | validation: 0.4514058221695018]
	TIME [epoch: 9.53 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5283247229438784		[learning rate: 1.2492e-05]
	Learning Rate: 1.2492e-05
	LOSS [training: 0.5283247229438784 | validation: 0.44001997554918504]
	TIME [epoch: 9.52 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5186835574362961		[learning rate: 1.2447e-05]
	Learning Rate: 1.24467e-05
	LOSS [training: 0.5186835574362961 | validation: 0.44543881243108807]
	TIME [epoch: 9.55 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5280366643753126		[learning rate: 1.2401e-05]
	Learning Rate: 1.24015e-05
	LOSS [training: 0.5280366643753126 | validation: 0.4505887636739567]
	TIME [epoch: 9.53 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5318904722616599		[learning rate: 1.2356e-05]
	Learning Rate: 1.23565e-05
	LOSS [training: 0.5318904722616599 | validation: 0.42596124709728356]
	TIME [epoch: 9.53 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5123326757301608		[learning rate: 1.2312e-05]
	Learning Rate: 1.23116e-05
	LOSS [training: 0.5123326757301608 | validation: 0.43421401210076]
	TIME [epoch: 9.53 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5170044835956019		[learning rate: 1.2267e-05]
	Learning Rate: 1.2267e-05
	LOSS [training: 0.5170044835956019 | validation: 0.4274706161841834]
	TIME [epoch: 9.55 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5203910985256062		[learning rate: 1.2222e-05]
	Learning Rate: 1.22224e-05
	LOSS [training: 0.5203910985256062 | validation: 0.4352135117146169]
	TIME [epoch: 9.53 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5225663946524148		[learning rate: 1.2178e-05]
	Learning Rate: 1.21781e-05
	LOSS [training: 0.5225663946524148 | validation: 0.4426046954037128]
	TIME [epoch: 9.53 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5215289514313779		[learning rate: 1.2134e-05]
	Learning Rate: 1.21339e-05
	LOSS [training: 0.5215289514313779 | validation: 0.4526989546232858]
	TIME [epoch: 9.55 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5177994864603687		[learning rate: 1.209e-05]
	Learning Rate: 1.20899e-05
	LOSS [training: 0.5177994864603687 | validation: 0.43448023254159474]
	TIME [epoch: 9.53 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5097329452522694		[learning rate: 1.2046e-05]
	Learning Rate: 1.2046e-05
	LOSS [training: 0.5097329452522694 | validation: 0.455220464305873]
	TIME [epoch: 9.53 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5357327989798499		[learning rate: 1.2002e-05]
	Learning Rate: 1.20023e-05
	LOSS [training: 0.5357327989798499 | validation: 0.44110312676250363]
	TIME [epoch: 9.53 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5312166466111599		[learning rate: 1.1959e-05]
	Learning Rate: 1.19587e-05
	LOSS [training: 0.5312166466111599 | validation: 0.4653538623257431]
	TIME [epoch: 9.55 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5230799546264846		[learning rate: 1.1915e-05]
	Learning Rate: 1.19153e-05
	LOSS [training: 0.5230799546264846 | validation: 0.4416319372840428]
	TIME [epoch: 9.52 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5194798650718233		[learning rate: 1.1872e-05]
	Learning Rate: 1.18721e-05
	LOSS [training: 0.5194798650718233 | validation: 0.4374503463768975]
	TIME [epoch: 9.53 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5349607021023399		[learning rate: 1.1829e-05]
	Learning Rate: 1.1829e-05
	LOSS [training: 0.5349607021023399 | validation: 0.4320743253874126]
	TIME [epoch: 9.54 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5171416884553858		[learning rate: 1.1786e-05]
	Learning Rate: 1.17861e-05
	LOSS [training: 0.5171416884553858 | validation: 0.4488631292834898]
	TIME [epoch: 9.53 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5275331795556425		[learning rate: 1.1743e-05]
	Learning Rate: 1.17433e-05
	LOSS [training: 0.5275331795556425 | validation: 0.4474897395100453]
	TIME [epoch: 9.53 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.523903431345498		[learning rate: 1.1701e-05]
	Learning Rate: 1.17007e-05
	LOSS [training: 0.523903431345498 | validation: 0.45316465749083606]
	TIME [epoch: 9.53 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5287708843256492		[learning rate: 1.1658e-05]
	Learning Rate: 1.16582e-05
	LOSS [training: 0.5287708843256492 | validation: 0.4451507076262904]
	TIME [epoch: 9.55 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5205048435083641		[learning rate: 1.1616e-05]
	Learning Rate: 1.16159e-05
	LOSS [training: 0.5205048435083641 | validation: 0.45162775965167407]
	TIME [epoch: 9.52 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5293101522892483		[learning rate: 1.1574e-05]
	Learning Rate: 1.15737e-05
	LOSS [training: 0.5293101522892483 | validation: 0.45254525817810826]
	TIME [epoch: 9.53 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5161356163131308		[learning rate: 1.1532e-05]
	Learning Rate: 1.15317e-05
	LOSS [training: 0.5161356163131308 | validation: 0.45212328316973327]
	TIME [epoch: 9.55 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5314550617865382		[learning rate: 1.149e-05]
	Learning Rate: 1.14899e-05
	LOSS [training: 0.5314550617865382 | validation: 0.4684260088623542]
	TIME [epoch: 9.53 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5152305240793572		[learning rate: 1.1448e-05]
	Learning Rate: 1.14482e-05
	LOSS [training: 0.5152305240793572 | validation: 0.449850361134958]
	TIME [epoch: 9.53 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5228330539070488		[learning rate: 1.1407e-05]
	Learning Rate: 1.14066e-05
	LOSS [training: 0.5228330539070488 | validation: 0.44767241926081563]
	TIME [epoch: 9.53 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5167635875405783		[learning rate: 1.1365e-05]
	Learning Rate: 1.13652e-05
	LOSS [training: 0.5167635875405783 | validation: 0.4546940780774322]
	TIME [epoch: 9.54 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5208924186904696		[learning rate: 1.1324e-05]
	Learning Rate: 1.1324e-05
	LOSS [training: 0.5208924186904696 | validation: 0.43845132058062464]
	TIME [epoch: 9.53 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5130394924721979		[learning rate: 1.1283e-05]
	Learning Rate: 1.12829e-05
	LOSS [training: 0.5130394924721979 | validation: 0.4661786130808711]
	TIME [epoch: 9.52 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5087164119152805		[learning rate: 1.1242e-05]
	Learning Rate: 1.1242e-05
	LOSS [training: 0.5087164119152805 | validation: 0.4539978160903097]
	TIME [epoch: 9.55 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5211240292055754		[learning rate: 1.1201e-05]
	Learning Rate: 1.12012e-05
	LOSS [training: 0.5211240292055754 | validation: 0.4760634777415011]
	TIME [epoch: 9.52 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.527020926032056		[learning rate: 1.1161e-05]
	Learning Rate: 1.11605e-05
	LOSS [training: 0.527020926032056 | validation: 0.46459916506947396]
	TIME [epoch: 9.54 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5335799986973819		[learning rate: 1.112e-05]
	Learning Rate: 1.112e-05
	LOSS [training: 0.5335799986973819 | validation: 0.43933350464581344]
	TIME [epoch: 9.53 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5283306100200987		[learning rate: 1.108e-05]
	Learning Rate: 1.10797e-05
	LOSS [training: 0.5283306100200987 | validation: 0.4591034003263535]
	TIME [epoch: 9.54 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5288783281223838		[learning rate: 1.1039e-05]
	Learning Rate: 1.10394e-05
	LOSS [training: 0.5288783281223838 | validation: 0.45091791233593087]
	TIME [epoch: 9.52 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5207405913970892		[learning rate: 1.0999e-05]
	Learning Rate: 1.09994e-05
	LOSS [training: 0.5207405913970892 | validation: 0.4540825666853765]
	TIME [epoch: 9.52 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5227178809483173		[learning rate: 1.0959e-05]
	Learning Rate: 1.09595e-05
	LOSS [training: 0.5227178809483173 | validation: 0.4751720394963009]
	TIME [epoch: 9.54 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5231918849443635		[learning rate: 1.092e-05]
	Learning Rate: 1.09197e-05
	LOSS [training: 0.5231918849443635 | validation: 0.436335294212918]
	TIME [epoch: 9.51 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5178051892771529		[learning rate: 1.088e-05]
	Learning Rate: 1.08801e-05
	LOSS [training: 0.5178051892771529 | validation: 0.44938251380764355]
	TIME [epoch: 9.53 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5218819314813363		[learning rate: 1.0841e-05]
	Learning Rate: 1.08406e-05
	LOSS [training: 0.5218819314813363 | validation: 0.44485514642755597]
	TIME [epoch: 9.54 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5217688007516508		[learning rate: 1.0801e-05]
	Learning Rate: 1.08012e-05
	LOSS [training: 0.5217688007516508 | validation: 0.45535270595990474]
	TIME [epoch: 9.53 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5277292783269225		[learning rate: 1.0762e-05]
	Learning Rate: 1.0762e-05
	LOSS [training: 0.5277292783269225 | validation: 0.4417932879305384]
	TIME [epoch: 9.51 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5135770265877416		[learning rate: 1.0723e-05]
	Learning Rate: 1.0723e-05
	LOSS [training: 0.5135770265877416 | validation: 0.46158640545659796]
	TIME [epoch: 9.53 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5178559143332756		[learning rate: 1.0684e-05]
	Learning Rate: 1.06841e-05
	LOSS [training: 0.5178559143332756 | validation: 0.4604482558962738]
	TIME [epoch: 9.54 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5206880137959954		[learning rate: 1.0645e-05]
	Learning Rate: 1.06453e-05
	LOSS [training: 0.5206880137959954 | validation: 0.4394875742288541]
	TIME [epoch: 9.52 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5220642161055167		[learning rate: 1.0607e-05]
	Learning Rate: 1.06067e-05
	LOSS [training: 0.5220642161055167 | validation: 0.4480313596679439]
	TIME [epoch: 9.53 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5074202509492943		[learning rate: 1.0568e-05]
	Learning Rate: 1.05682e-05
	LOSS [training: 0.5074202509492943 | validation: 0.435232456267051]
	TIME [epoch: 9.55 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5173734687778604		[learning rate: 1.053e-05]
	Learning Rate: 1.05298e-05
	LOSS [training: 0.5173734687778604 | validation: 0.4378572566630178]
	TIME [epoch: 9.53 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5180135064477753		[learning rate: 1.0492e-05]
	Learning Rate: 1.04916e-05
	LOSS [training: 0.5180135064477753 | validation: 0.45264504536203193]
	TIME [epoch: 9.52 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.513551827266928		[learning rate: 1.0454e-05]
	Learning Rate: 1.04535e-05
	LOSS [training: 0.513551827266928 | validation: 0.4331553381651127]
	TIME [epoch: 9.52 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5154754947856588		[learning rate: 1.0416e-05]
	Learning Rate: 1.04156e-05
	LOSS [training: 0.5154754947856588 | validation: 0.43182962120445156]
	TIME [epoch: 9.54 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5195948750260544		[learning rate: 1.0378e-05]
	Learning Rate: 1.03778e-05
	LOSS [training: 0.5195948750260544 | validation: 0.4406653692112491]
	TIME [epoch: 9.52 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5137059399541165		[learning rate: 1.034e-05]
	Learning Rate: 1.03401e-05
	LOSS [training: 0.5137059399541165 | validation: 0.44814565560554775]
	TIME [epoch: 9.52 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5109265112684798		[learning rate: 1.0303e-05]
	Learning Rate: 1.03026e-05
	LOSS [training: 0.5109265112684798 | validation: 0.46291357009856143]
	TIME [epoch: 9.54 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5143892389403604		[learning rate: 1.0265e-05]
	Learning Rate: 1.02652e-05
	LOSS [training: 0.5143892389403604 | validation: 0.4299273785665547]
	TIME [epoch: 9.53 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5235431790423858		[learning rate: 1.0228e-05]
	Learning Rate: 1.0228e-05
	LOSS [training: 0.5235431790423858 | validation: 0.4448041448619526]
	TIME [epoch: 9.52 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5203639862253582		[learning rate: 1.0191e-05]
	Learning Rate: 1.01909e-05
	LOSS [training: 0.5203639862253582 | validation: 0.44853136054495635]
	TIME [epoch: 9.51 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5272707515449977		[learning rate: 1.0154e-05]
	Learning Rate: 1.01539e-05
	LOSS [training: 0.5272707515449977 | validation: 0.4575642819517997]
	TIME [epoch: 9.55 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5308161646446835		[learning rate: 1.0117e-05]
	Learning Rate: 1.0117e-05
	LOSS [training: 0.5308161646446835 | validation: 0.45973079392159394]
	TIME [epoch: 9.52 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5125718447646969		[learning rate: 1.008e-05]
	Learning Rate: 1.00803e-05
	LOSS [training: 0.5125718447646969 | validation: 0.44444134450725836]
	TIME [epoch: 9.51 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5220788716379463		[learning rate: 1.0044e-05]
	Learning Rate: 1.00437e-05
	LOSS [training: 0.5220788716379463 | validation: 0.4484219262798693]
	TIME [epoch: 9.54 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5234574769084149		[learning rate: 1.0007e-05]
	Learning Rate: 1.00073e-05
	LOSS [training: 0.5234574769084149 | validation: 0.45243810039686266]
	TIME [epoch: 9.53 sec]
Finished training in 19228.300 seconds.
