Args:
Namespace(name='model_tr_study205', outdir='out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1', training_data='data/transition_rate_studies/tr_study205/tr_study205_training/r1', validation_data='data/transition_rate_studies/tr_study205/tr_study205_validation/r1', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.075, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=100, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 767518268

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 5/5] avg loss: 13.565543270717598		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 13.565543270717598 | validation: 14.15191985340055]
	TIME [epoch: 78.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 5/5] avg loss: 14.098407016495523		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 14.098407016495523 | validation: 13.537341658046735]
	TIME [epoch: 9.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 5/5] avg loss: 13.08305223841684		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 13.08305223841684 | validation: 11.576234336198445]
	TIME [epoch: 9.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 5/5] avg loss: 11.624400811759159		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.624400811759159 | validation: 9.187901457140947]
	TIME [epoch: 9.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 5/5] avg loss: 12.001915800126202		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 12.001915800126202 | validation: 11.80458432220825]
	TIME [epoch: 9.46 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 5/5] avg loss: 10.321900595665856		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.321900595665856 | validation: 8.793961566983851]
	TIME [epoch: 9.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.584031687305417		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.584031687305417 | validation: 10.501989784375958]
	TIME [epoch: 9.49 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.49328351421349		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.49328351421349 | validation: 9.321001548035376]
	TIME [epoch: 9.5 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.468619643701109		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.468619643701109 | validation: 9.236054041269302]
	TIME [epoch: 9.46 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.093602889165158		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.093602889165158 | validation: 4.803546923367518]
	TIME [epoch: 9.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.58159891918116		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.58159891918116 | validation: 9.977010609339068]
	TIME [epoch: 9.49 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.458438687218967		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.458438687218967 | validation: 8.677231816333743]
	TIME [epoch: 9.46 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.615895669093371		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.615895669093371 | validation: 8.942046862046684]
	TIME [epoch: 9.46 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.55769542009957		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.55769542009957 | validation: 10.281199728398354]
	TIME [epoch: 9.48 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.566340863893295		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.566340863893295 | validation: 6.2543923098109335]
	TIME [epoch: 9.47 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.403945834811134		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.403945834811134 | validation: 8.446582493598235]
	TIME [epoch: 9.46 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.88905963549208		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.88905963549208 | validation: 7.862416377718257]
	TIME [epoch: 9.46 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.183781372351097		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.183781372351097 | validation: 9.662535737042795]
	TIME [epoch: 9.47 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.205519220350235		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.205519220350235 | validation: 7.411167350419009]
	TIME [epoch: 9.46 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.4449926705517795		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.4449926705517795 | validation: 8.943437009364963]
	TIME [epoch: 9.45 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.430620430626123		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.430620430626123 | validation: 9.659213206785825]
	TIME [epoch: 9.46 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.563325605688764		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.563325605688764 | validation: 7.154962223526764]
	TIME [epoch: 9.47 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.496158948108952		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.496158948108952 | validation: 6.762999333284398]
	TIME [epoch: 9.45 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.125699025187005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.125699025187005 | validation: 7.4584275914582605]
	TIME [epoch: 9.45 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.605606621068733		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.605606621068733 | validation: 7.632443145337926]
	TIME [epoch: 9.45 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.6693639887766665		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.6693639887766665 | validation: 5.60278780619019]
	TIME [epoch: 9.48 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.742259883670395		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.742259883670395 | validation: 9.646026508276032]
	TIME [epoch: 9.45 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.587432001333646		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.587432001333646 | validation: 7.8847577000354105]
	TIME [epoch: 9.46 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.932688020261128		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.932688020261128 | validation: 8.152501512182816]
	TIME [epoch: 9.44 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.205389978731118		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.205389978731118 | validation: 7.053848542353648]
	TIME [epoch: 9.48 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.360291581310691		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.360291581310691 | validation: 3.2979848576748267]
	TIME [epoch: 9.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.19354866749335		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.19354866749335 | validation: 6.433405938032766]
	TIME [epoch: 9.45 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.182095146218186		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.182095146218186 | validation: 3.526017459470205]
	TIME [epoch: 9.46 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.712318172998858		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.712318172998858 | validation: 9.201217620366123]
	TIME [epoch: 9.48 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.684508744322173		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.684508744322173 | validation: 6.438776912980618]
	TIME [epoch: 9.45 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.965734552620979		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.965734552620979 | validation: 6.452186029934754]
	TIME [epoch: 9.45 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.378669757614288		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.378669757614288 | validation: 5.803975329245941]
	TIME [epoch: 9.46 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.622993065070352		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.622993065070352 | validation: 3.7201237891678454]
	TIME [epoch: 9.47 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.213365154820704		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.213365154820704 | validation: 5.457715417183649]
	TIME [epoch: 9.45 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.370047209990306		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.370047209990306 | validation: 4.531742907892407]
	TIME [epoch: 9.44 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.244338261766301		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.244338261766301 | validation: 5.505315090806449]
	TIME [epoch: 9.47 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.315178013846076		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.315178013846076 | validation: 3.8067901348762976]
	TIME [epoch: 9.49 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.983226296558486		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.983226296558486 | validation: 5.713006878232199]
	TIME [epoch: 9.46 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.35293674217115		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.35293674217115 | validation: 4.18690289619838]
	TIME [epoch: 9.46 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.017368503389344		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.017368503389344 | validation: 5.251063318314023]
	TIME [epoch: 9.48 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.127945053758898		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.127945053758898 | validation: 4.835918076200073]
	TIME [epoch: 9.47 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.069106327435156		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.069106327435156 | validation: 4.612115439358517]
	TIME [epoch: 9.46 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.058343199008581		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.058343199008581 | validation: 5.12209825757496]
	TIME [epoch: 9.45 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.959366452252505		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.959366452252505 | validation: 4.9924548942226785]
	TIME [epoch: 9.49 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.106000468103747		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.106000468103747 | validation: 4.675876516150886]
	TIME [epoch: 9.47 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.066788919094837		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.066788919094837 | validation: 4.428745395640106]
	TIME [epoch: 9.46 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.997072013164344		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.997072013164344 | validation: 4.634270626747542]
	TIME [epoch: 9.46 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.014596666541193		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.014596666541193 | validation: 4.341896677717019]
	TIME [epoch: 9.48 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.882307648603403		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.882307648603403 | validation: 4.760058500748622]
	TIME [epoch: 9.45 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.9020237970529505		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.9020237970529505 | validation: 5.175928507853302]
	TIME [epoch: 9.49 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.068351657220876		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.068351657220876 | validation: 3.793793015185355]
	TIME [epoch: 9.47 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.831367515336598		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.831367515336598 | validation: 5.063552271185015]
	TIME [epoch: 9.48 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.922428666318272		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.922428666318272 | validation: 4.484733934694328]
	TIME [epoch: 9.46 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.796205399064666		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.796205399064666 | validation: 4.795950805792276]
	TIME [epoch: 9.46 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.892803301469274		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.892803301469274 | validation: 4.203829247506014]
	TIME [epoch: 9.46 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.859987651504149		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.859987651504149 | validation: 4.344433405393828]
	TIME [epoch: 9.49 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.77480256923592		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.77480256923592 | validation: 4.970808441683777]
	TIME [epoch: 9.45 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.907487011881394		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.907487011881394 | validation: 5.260431008172518]
	TIME [epoch: 9.47 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.879919684445752		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.879919684445752 | validation: 3.9284343282114866]
	TIME [epoch: 9.49 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.721404776610768		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.721404776610768 | validation: 4.738238883322622]
	TIME [epoch: 9.45 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.745565704542533		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.745565704542533 | validation: 4.094186538564525]
	TIME [epoch: 9.46 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.840588781212077		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.840588781212077 | validation: 3.706795599774839]
	TIME [epoch: 9.46 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.483964056296135		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.483964056296135 | validation: 5.115179082399586]
	TIME [epoch: 9.47 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.816431670366507		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.816431670366507 | validation: 4.351232905933451]
	TIME [epoch: 9.46 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.674038775233725		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.674038775233725 | validation: 4.606734154117207]
	TIME [epoch: 9.45 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.590415799047654		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.590415799047654 | validation: 4.238494637673629]
	TIME [epoch: 9.46 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.68279729553979		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.68279729553979 | validation: 4.626808076105972]
	TIME [epoch: 9.49 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.569697495009406		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.569697495009406 | validation: 4.722633258616288]
	TIME [epoch: 9.46 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.693077692624073		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.693077692624073 | validation: 3.7763266107145825]
	TIME [epoch: 9.45 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.5366282048497215		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.5366282048497215 | validation: 4.7872447861759975]
	TIME [epoch: 9.45 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.519843732596415		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.519843732596415 | validation: 4.350200741932124]
	TIME [epoch: 9.48 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.537558511201847		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.537558511201847 | validation: 4.030571262174358]
	TIME [epoch: 9.46 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.4948694409303585		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.4948694409303585 | validation: 4.554140720564603]
	TIME [epoch: 9.44 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.764814826261751		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.764814826261751 | validation: 2.864307285609635]
	TIME [epoch: 9.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.337308515811477		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.337308515811477 | validation: 5.0939103850913785]
	TIME [epoch: 9.47 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.652164792509241		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.652164792509241 | validation: 3.866562755086891]
	TIME [epoch: 9.45 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.469749901011617		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.469749901011617 | validation: 4.462946794227667]
	TIME [epoch: 9.45 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.543310644894455		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.543310644894455 | validation: 3.72289851256371]
	TIME [epoch: 9.48 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.373145220205379		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.373145220205379 | validation: 4.167263663683384]
	TIME [epoch: 9.46 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.539781918074236		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.539781918074236 | validation: 3.8028846169869435]
	TIME [epoch: 9.45 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.294315377736459		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.294315377736459 | validation: 3.8676323576985867]
	TIME [epoch: 9.45 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.394228134414179		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.394228134414179 | validation: 3.9122885436474166]
	TIME [epoch: 9.48 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.405617531909246		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.405617531909246 | validation: 3.7655235121503985]
	TIME [epoch: 9.46 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.36184760762808		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.36184760762808 | validation: 3.965314378564256]
	TIME [epoch: 9.45 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.370375552058947		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.370375552058947 | validation: 4.108668557311349]
	TIME [epoch: 9.45 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.315654203354269		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.315654203354269 | validation: 3.7972350431522175]
	TIME [epoch: 9.48 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.255870334580087		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.255870334580087 | validation: 3.917037679935901]
	TIME [epoch: 9.45 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.42549921448931		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.42549921448931 | validation: 3.4174952600597375]
	TIME [epoch: 9.45 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.5876422879209455		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.5876422879209455 | validation: 5.967456666848224]
	TIME [epoch: 9.45 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.299536097560962		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.299536097560962 | validation: 4.92413996449196]
	TIME [epoch: 9.48 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.621938343166155		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.621938343166155 | validation: 4.0677982292971375]
	TIME [epoch: 9.45 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.515106643724904		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.515106643724904 | validation: 5.0926321350349335]
	TIME [epoch: 9.45 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.260922373219772		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.260922373219772 | validation: 4.403580942899229]
	TIME [epoch: 9.46 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.509239582471212		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.509239582471212 | validation: 3.802831243090136]
	TIME [epoch: 9.47 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.319782925838252		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.319782925838252 | validation: 4.176195044566494]
	TIME [epoch: 9.45 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.2644203051924086		[learning rate: 0.009971]
	Learning Rate: 0.00997096
	LOSS [training: 4.2644203051924086 | validation: 3.9710200655359214]
	TIME [epoch: 9.45 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.201842954156855		[learning rate: 0.0099348]
	Learning Rate: 0.00993477
	LOSS [training: 4.201842954156855 | validation: 3.4573791655085095]
	TIME [epoch: 9.46 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.164635178096625		[learning rate: 0.0098987]
	Learning Rate: 0.00989872
	LOSS [training: 4.164635178096625 | validation: 3.4793146334003424]
	TIME [epoch: 9.47 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.181046792815475		[learning rate: 0.0098628]
	Learning Rate: 0.00986279
	LOSS [training: 4.181046792815475 | validation: 4.367016816272228]
	TIME [epoch: 9.45 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.146403841680789		[learning rate: 0.009827]
	Learning Rate: 0.009827
	LOSS [training: 4.146403841680789 | validation: 3.6241152095526514]
	TIME [epoch: 9.45 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.068210406010872		[learning rate: 0.0097913]
	Learning Rate: 0.00979134
	LOSS [training: 4.068210406010872 | validation: 3.991972077297824]
	TIME [epoch: 9.48 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.05673631691807		[learning rate: 0.0097558]
	Learning Rate: 0.00975581
	LOSS [training: 4.05673631691807 | validation: 3.958964872582684]
	TIME [epoch: 9.46 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.118179476959288		[learning rate: 0.0097204]
	Learning Rate: 0.0097204
	LOSS [training: 4.118179476959288 | validation: 4.232150312475191]
	TIME [epoch: 9.45 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.158105224951083		[learning rate: 0.0096851]
	Learning Rate: 0.00968513
	LOSS [training: 4.158105224951083 | validation: 3.942375121869682]
	TIME [epoch: 9.45 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.032108181465502		[learning rate: 0.00965]
	Learning Rate: 0.00964998
	LOSS [training: 4.032108181465502 | validation: 3.5681184006025837]
	TIME [epoch: 9.48 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.875716912276828		[learning rate: 0.009615]
	Learning Rate: 0.00961496
	LOSS [training: 3.875716912276828 | validation: 3.6629565510981523]
	TIME [epoch: 9.46 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.045377399084314		[learning rate: 0.0095801]
	Learning Rate: 0.00958006
	LOSS [training: 4.045377399084314 | validation: 3.970303103580728]
	TIME [epoch: 9.45 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.093308495544995		[learning rate: 0.0095453]
	Learning Rate: 0.0095453
	LOSS [training: 4.093308495544995 | validation: 3.2548567209881787]
	TIME [epoch: 9.45 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.892401561816702		[learning rate: 0.0095107]
	Learning Rate: 0.00951066
	LOSS [training: 3.892401561816702 | validation: 3.714116032491267]
	TIME [epoch: 9.48 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.895498700060274		[learning rate: 0.0094761]
	Learning Rate: 0.00947614
	LOSS [training: 3.895498700060274 | validation: 3.3619824262507856]
	TIME [epoch: 9.45 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9140811774300195		[learning rate: 0.0094418]
	Learning Rate: 0.00944175
	LOSS [training: 3.9140811774300195 | validation: 3.4761915391282225]
	TIME [epoch: 9.46 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.8651192382719337		[learning rate: 0.0094075]
	Learning Rate: 0.00940749
	LOSS [training: 3.8651192382719337 | validation: 2.9293621726767096]
	TIME [epoch: 9.45 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.8169605432827196		[learning rate: 0.0093733]
	Learning Rate: 0.00937335
	LOSS [training: 3.8169605432827196 | validation: 3.8750263210220086]
	TIME [epoch: 9.48 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.824274228662253		[learning rate: 0.0093393]
	Learning Rate: 0.00933933
	LOSS [training: 3.824274228662253 | validation: 3.8058637071200225]
	TIME [epoch: 9.45 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9918356356846885		[learning rate: 0.0093054]
	Learning Rate: 0.00930544
	LOSS [training: 3.9918356356846885 | validation: 3.4924558478253367]
	TIME [epoch: 9.45 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.7391229557787895		[learning rate: 0.0092717]
	Learning Rate: 0.00927167
	LOSS [training: 3.7391229557787895 | validation: 3.6455902484052674]
	TIME [epoch: 9.46 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.8743838241903545		[learning rate: 0.009238]
	Learning Rate: 0.00923802
	LOSS [training: 3.8743838241903545 | validation: 3.7105198609260293]
	TIME [epoch: 9.47 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.759437103117107		[learning rate: 0.0092045]
	Learning Rate: 0.0092045
	LOSS [training: 3.759437103117107 | validation: 3.813426137208125]
	TIME [epoch: 9.46 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.7700322696859465		[learning rate: 0.0091711]
	Learning Rate: 0.00917109
	LOSS [training: 3.7700322696859465 | validation: 3.553043154413206]
	TIME [epoch: 9.45 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.70181801170827		[learning rate: 0.0091378]
	Learning Rate: 0.00913781
	LOSS [training: 3.70181801170827 | validation: 3.14333162268063]
	TIME [epoch: 9.47 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.769953947419509		[learning rate: 0.0091046]
	Learning Rate: 0.00910465
	LOSS [training: 3.769953947419509 | validation: 3.184379005908413]
	TIME [epoch: 9.46 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.459336983226143		[learning rate: 0.0090716]
	Learning Rate: 0.00907161
	LOSS [training: 3.459336983226143 | validation: 3.193075462569402]
	TIME [epoch: 9.45 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.8954329439417785		[learning rate: 0.0090387]
	Learning Rate: 0.00903868
	LOSS [training: 3.8954329439417785 | validation: 2.6538091586964208]
	TIME [epoch: 9.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_128.pth
	Model improved!!!
EPOCH 129/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.671726656301245		[learning rate: 0.0090059]
	Learning Rate: 0.00900588
	LOSS [training: 3.671726656301245 | validation: 3.634431478570602]
	TIME [epoch: 9.48 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.754171267652032		[learning rate: 0.0089732]
	Learning Rate: 0.0089732
	LOSS [training: 3.754171267652032 | validation: 3.101400445638203]
	TIME [epoch: 9.46 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6774558461885873		[learning rate: 0.0089406]
	Learning Rate: 0.00894064
	LOSS [training: 3.6774558461885873 | validation: 3.431777272750229]
	TIME [epoch: 9.46 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.7460739468696773		[learning rate: 0.0089082]
	Learning Rate: 0.00890819
	LOSS [training: 3.7460739468696773 | validation: 5.406093232798622]
	TIME [epoch: 9.46 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.972708136724808		[learning rate: 0.0088759]
	Learning Rate: 0.00887586
	LOSS [training: 4.972708136724808 | validation: 4.515522196347534]
	TIME [epoch: 9.49 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.249316490479761		[learning rate: 0.0088437]
	Learning Rate: 0.00884365
	LOSS [training: 4.249316490479761 | validation: 3.60040554471732]
	TIME [epoch: 9.46 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.807589346435519		[learning rate: 0.0088116]
	Learning Rate: 0.00881156
	LOSS [training: 3.807589346435519 | validation: 3.0037511447552436]
	TIME [epoch: 9.45 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.5943289458569376		[learning rate: 0.0087796]
	Learning Rate: 0.00877958
	LOSS [training: 3.5943289458569376 | validation: 3.0390863386344997]
	TIME [epoch: 9.46 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.645806973053508		[learning rate: 0.0087477]
	Learning Rate: 0.00874772
	LOSS [training: 3.645806973053508 | validation: 2.9489299478740203]
	TIME [epoch: 9.49 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.5372179057530753		[learning rate: 0.008716]
	Learning Rate: 0.00871597
	LOSS [training: 3.5372179057530753 | validation: 3.037174497422776]
	TIME [epoch: 9.46 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4536253289307943		[learning rate: 0.0086843]
	Learning Rate: 0.00868434
	LOSS [training: 3.4536253289307943 | validation: 3.141097004937467]
	TIME [epoch: 9.45 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.5455956082354754		[learning rate: 0.0086528]
	Learning Rate: 0.00865282
	LOSS [training: 3.5455956082354754 | validation: 3.2798335228805935]
	TIME [epoch: 9.46 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4130511317049868		[learning rate: 0.0086214]
	Learning Rate: 0.00862142
	LOSS [training: 3.4130511317049868 | validation: 4.403214197458723]
	TIME [epoch: 9.48 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6525627066354063		[learning rate: 0.0085901]
	Learning Rate: 0.00859013
	LOSS [training: 3.6525627066354063 | validation: 3.0135577348533484]
	TIME [epoch: 9.45 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6198099904483536		[learning rate: 0.008559]
	Learning Rate: 0.00855896
	LOSS [training: 3.6198099904483536 | validation: 2.591935132286736]
	TIME [epoch: 9.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_143.pth
	Model improved!!!
EPOCH 144/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.323686423638867		[learning rate: 0.0085279]
	Learning Rate: 0.0085279
	LOSS [training: 3.323686423638867 | validation: 2.8983277903108298]
	TIME [epoch: 9.49 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.485305249127736		[learning rate: 0.008497]
	Learning Rate: 0.00849695
	LOSS [training: 3.485305249127736 | validation: 3.3073615795828273]
	TIME [epoch: 9.48 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4974055024387183		[learning rate: 0.0084661]
	Learning Rate: 0.00846612
	LOSS [training: 3.4974055024387183 | validation: 3.257463622057886]
	TIME [epoch: 9.47 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4930097969626717		[learning rate: 0.0084354]
	Learning Rate: 0.00843539
	LOSS [training: 3.4930097969626717 | validation: 3.2635281730947496]
	TIME [epoch: 9.46 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.5208053563646837		[learning rate: 0.0084048]
	Learning Rate: 0.00840478
	LOSS [training: 3.5208053563646837 | validation: 2.992799122427349]
	TIME [epoch: 9.48 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.5400500404828916		[learning rate: 0.0083743]
	Learning Rate: 0.00837428
	LOSS [training: 3.5400500404828916 | validation: 2.5777699984182005]
	TIME [epoch: 9.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_149.pth
	Model improved!!!
EPOCH 150/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6182056070204545		[learning rate: 0.0083439]
	Learning Rate: 0.00834389
	LOSS [training: 3.6182056070204545 | validation: 2.4606651616384103]
	TIME [epoch: 9.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_150.pth
	Model improved!!!
EPOCH 151/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.367791422572638		[learning rate: 0.0083136]
	Learning Rate: 0.00831361
	LOSS [training: 3.367791422572638 | validation: 3.3204409984393615]
	TIME [epoch: 9.46 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4502198775936663		[learning rate: 0.0082834]
	Learning Rate: 0.00828344
	LOSS [training: 3.4502198775936663 | validation: 3.527459513732268]
	TIME [epoch: 9.48 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.467474529226761		[learning rate: 0.0082534]
	Learning Rate: 0.00825338
	LOSS [training: 3.467474529226761 | validation: 3.299314920315045]
	TIME [epoch: 9.45 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3279349366228255		[learning rate: 0.0082234]
	Learning Rate: 0.00822342
	LOSS [training: 3.3279349366228255 | validation: 2.4311928063016315]
	TIME [epoch: 9.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_154.pth
	Model improved!!!
EPOCH 155/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.35475685150696		[learning rate: 0.0081936]
	Learning Rate: 0.00819358
	LOSS [training: 3.35475685150696 | validation: 3.4542040227706066]
	TIME [epoch: 9.44 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4390044325222093		[learning rate: 0.0081638]
	Learning Rate: 0.00816384
	LOSS [training: 3.4390044325222093 | validation: 2.981561414273133]
	TIME [epoch: 9.48 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2737898527738167		[learning rate: 0.0081342]
	Learning Rate: 0.00813422
	LOSS [training: 3.2737898527738167 | validation: 3.77762438084147]
	TIME [epoch: 9.47 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.5479203145312956		[learning rate: 0.0081047]
	Learning Rate: 0.0081047
	LOSS [training: 3.5479203145312956 | validation: 3.3025562445783954]
	TIME [epoch: 9.46 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.37182691443666		[learning rate: 0.0080753]
	Learning Rate: 0.00807529
	LOSS [training: 3.37182691443666 | validation: 3.1906693547748546]
	TIME [epoch: 9.48 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.379252454286756		[learning rate: 0.008046]
	Learning Rate: 0.00804598
	LOSS [training: 3.379252454286756 | validation: 2.829582853270623]
	TIME [epoch: 9.48 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2273799243635715		[learning rate: 0.0080168]
	Learning Rate: 0.00801678
	LOSS [training: 3.2273799243635715 | validation: 2.3945848508927656]
	TIME [epoch: 9.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_161.pth
	Model improved!!!
EPOCH 162/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1521768773658025		[learning rate: 0.0079877]
	Learning Rate: 0.00798769
	LOSS [training: 3.1521768773658025 | validation: 3.404671100396122]
	TIME [epoch: 9.45 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4357163404325903		[learning rate: 0.0079587]
	Learning Rate: 0.0079587
	LOSS [training: 3.4357163404325903 | validation: 2.4491352296211226]
	TIME [epoch: 9.46 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2684560665611757		[learning rate: 0.0079298]
	Learning Rate: 0.00792982
	LOSS [training: 3.2684560665611757 | validation: 2.5383101833847146]
	TIME [epoch: 9.46 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.279284402623321		[learning rate: 0.007901]
	Learning Rate: 0.00790104
	LOSS [training: 3.279284402623321 | validation: 2.5470342355369766]
	TIME [epoch: 9.44 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.175334343926063		[learning rate: 0.0078724]
	Learning Rate: 0.00787237
	LOSS [training: 3.175334343926063 | validation: 3.110706470113417]
	TIME [epoch: 9.44 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2391078636544206		[learning rate: 0.0078438]
	Learning Rate: 0.0078438
	LOSS [training: 3.2391078636544206 | validation: 2.646979696047271]
	TIME [epoch: 9.47 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0614985248442967		[learning rate: 0.0078153]
	Learning Rate: 0.00781533
	LOSS [training: 3.0614985248442967 | validation: 3.685575394653828]
	TIME [epoch: 9.45 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2081639998977094		[learning rate: 0.007787]
	Learning Rate: 0.00778697
	LOSS [training: 3.2081639998977094 | validation: 3.4719127829670082]
	TIME [epoch: 9.44 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.25174448466075		[learning rate: 0.0077587]
	Learning Rate: 0.00775871
	LOSS [training: 3.25174448466075 | validation: 2.57026215447351]
	TIME [epoch: 9.45 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.132516381889876		[learning rate: 0.0077306]
	Learning Rate: 0.00773055
	LOSS [training: 3.132516381889876 | validation: 3.7684574618242412]
	TIME [epoch: 9.47 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3941491047280343		[learning rate: 0.0077025]
	Learning Rate: 0.0077025
	LOSS [training: 3.3941491047280343 | validation: 3.434397832171768]
	TIME [epoch: 9.44 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3968276591989364		[learning rate: 0.0076745]
	Learning Rate: 0.00767455
	LOSS [training: 3.3968276591989364 | validation: 2.314240281075655]
	TIME [epoch: 9.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_173.pth
	Model improved!!!
EPOCH 174/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1440703003452235		[learning rate: 0.0076467]
	Learning Rate: 0.00764669
	LOSS [training: 3.1440703003452235 | validation: 2.6252609718515267]
	TIME [epoch: 9.45 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.131023684378845		[learning rate: 0.0076189]
	Learning Rate: 0.00761894
	LOSS [training: 3.131023684378845 | validation: 2.932054057681845]
	TIME [epoch: 9.47 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1311468646562743		[learning rate: 0.0075913]
	Learning Rate: 0.00759129
	LOSS [training: 3.1311468646562743 | validation: 2.7899388223829713]
	TIME [epoch: 9.44 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4735658526437247		[learning rate: 0.0075637]
	Learning Rate: 0.00756374
	LOSS [training: 3.4735658526437247 | validation: 5.233479499749121]
	TIME [epoch: 9.44 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.227341648436396		[learning rate: 0.0075363]
	Learning Rate: 0.00753629
	LOSS [training: 4.227341648436396 | validation: 2.7642536266176263]
	TIME [epoch: 9.45 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.507293328034195		[learning rate: 0.0075089]
	Learning Rate: 0.00750895
	LOSS [training: 3.507293328034195 | validation: 4.553608366838922]
	TIME [epoch: 9.46 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.612159456261805		[learning rate: 0.0074817]
	Learning Rate: 0.00748169
	LOSS [training: 3.612159456261805 | validation: 2.3194404493098126]
	TIME [epoch: 9.44 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1067476324583523		[learning rate: 0.0074545]
	Learning Rate: 0.00745454
	LOSS [training: 3.1067476324583523 | validation: 2.6313796604855986]
	TIME [epoch: 9.44 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.152966160500181		[learning rate: 0.0074275]
	Learning Rate: 0.00742749
	LOSS [training: 3.152966160500181 | validation: 2.7459266178597512]
	TIME [epoch: 9.46 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.188292779308405		[learning rate: 0.0074005]
	Learning Rate: 0.00740054
	LOSS [training: 3.188292779308405 | validation: 2.2777853666013046]
	TIME [epoch: 9.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_183.pth
	Model improved!!!
EPOCH 184/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0986854735958613		[learning rate: 0.0073737]
	Learning Rate: 0.00737368
	LOSS [training: 3.0986854735958613 | validation: 2.362416857151792]
	TIME [epoch: 9.45 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.089749876124899		[learning rate: 0.0073469]
	Learning Rate: 0.00734692
	LOSS [training: 3.089749876124899 | validation: 2.716777944663162]
	TIME [epoch: 9.44 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.106027768535567		[learning rate: 0.0073203]
	Learning Rate: 0.00732026
	LOSS [training: 3.106027768535567 | validation: 3.2589465260649626]
	TIME [epoch: 9.46 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0566220132864172		[learning rate: 0.0072937]
	Learning Rate: 0.00729369
	LOSS [training: 3.0566220132864172 | validation: 2.9962549962359084]
	TIME [epoch: 9.45 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.396017649832568		[learning rate: 0.0072672]
	Learning Rate: 0.00726722
	LOSS [training: 3.396017649832568 | validation: 2.1829348978546035]
	TIME [epoch: 9.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_188.pth
	Model improved!!!
EPOCH 189/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0632148129826495		[learning rate: 0.0072408]
	Learning Rate: 0.00724085
	LOSS [training: 3.0632148129826495 | validation: 2.292289011937351]
	TIME [epoch: 9.45 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.085191910829936		[learning rate: 0.0072146]
	Learning Rate: 0.00721457
	LOSS [training: 3.085191910829936 | validation: 2.3205420607283247]
	TIME [epoch: 9.47 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.084671936378266		[learning rate: 0.0071884]
	Learning Rate: 0.00718839
	LOSS [training: 3.084671936378266 | validation: 2.5420042737001896]
	TIME [epoch: 9.44 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.045766754981961		[learning rate: 0.0071623]
	Learning Rate: 0.0071623
	LOSS [training: 3.045766754981961 | validation: 2.970096640196234]
	TIME [epoch: 9.44 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1487323312628623		[learning rate: 0.0071363]
	Learning Rate: 0.00713631
	LOSS [training: 3.1487323312628623 | validation: 3.728046777795172]
	TIME [epoch: 9.44 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2968054252647625		[learning rate: 0.0071104]
	Learning Rate: 0.00711041
	LOSS [training: 3.2968054252647625 | validation: 2.784555019635038]
	TIME [epoch: 9.46 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.011826491582812		[learning rate: 0.0070846]
	Learning Rate: 0.00708461
	LOSS [training: 3.011826491582812 | validation: 2.918683693020787]
	TIME [epoch: 9.44 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0470462407936276		[learning rate: 0.0070589]
	Learning Rate: 0.0070589
	LOSS [training: 3.0470462407936276 | validation: 2.3150537524320876]
	TIME [epoch: 9.44 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9451251448097104		[learning rate: 0.0070333]
	Learning Rate: 0.00703328
	LOSS [training: 2.9451251448097104 | validation: 3.2570753197754927]
	TIME [epoch: 9.45 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4393945895623146		[learning rate: 0.0070078]
	Learning Rate: 0.00700776
	LOSS [training: 3.4393945895623146 | validation: 4.992523869257676]
	TIME [epoch: 9.46 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.8328954665627593		[learning rate: 0.0069823]
	Learning Rate: 0.00698232
	LOSS [training: 3.8328954665627593 | validation: 2.7831245795576196]
	TIME [epoch: 9.44 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.061590957867883		[learning rate: 0.006957]
	Learning Rate: 0.00695698
	LOSS [training: 3.061590957867883 | validation: 3.758901505463074]
	TIME [epoch: 9.43 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1930008769247276		[learning rate: 0.0069317]
	Learning Rate: 0.00693174
	LOSS [training: 3.1930008769247276 | validation: 2.4244070792240353]
	TIME [epoch: 9.45 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0217440140977603		[learning rate: 0.0069066]
	Learning Rate: 0.00690658
	LOSS [training: 3.0217440140977603 | validation: 2.4913024580108054]
	TIME [epoch: 9.45 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9142712992384325		[learning rate: 0.0068815]
	Learning Rate: 0.00688152
	LOSS [training: 2.9142712992384325 | validation: 2.754396892309302]
	TIME [epoch: 9.44 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.262036096138202		[learning rate: 0.0068565]
	Learning Rate: 0.00685654
	LOSS [training: 3.262036096138202 | validation: 2.1526244885312504]
	TIME [epoch: 9.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_204.pth
	Model improved!!!
EPOCH 205/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.95911996716512		[learning rate: 0.0068317]
	Learning Rate: 0.00683166
	LOSS [training: 2.95911996716512 | validation: 2.6743669560073977]
	TIME [epoch: 9.47 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9527139734502983		[learning rate: 0.0068069]
	Learning Rate: 0.00680687
	LOSS [training: 2.9527139734502983 | validation: 2.4604724357503267]
	TIME [epoch: 9.45 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.981060956610495		[learning rate: 0.0067822]
	Learning Rate: 0.00678217
	LOSS [training: 2.981060956610495 | validation: 2.4654843467922363]
	TIME [epoch: 9.45 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2126257525201836		[learning rate: 0.0067576]
	Learning Rate: 0.00675755
	LOSS [training: 3.2126257525201836 | validation: 2.1964604119865743]
	TIME [epoch: 9.44 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0913664715136364		[learning rate: 0.006733]
	Learning Rate: 0.00673303
	LOSS [training: 3.0913664715136364 | validation: 2.22846443299156]
	TIME [epoch: 9.47 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9156336470298587		[learning rate: 0.0067086]
	Learning Rate: 0.00670859
	LOSS [training: 2.9156336470298587 | validation: 3.575815677101046]
	TIME [epoch: 9.45 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1060084171029865		[learning rate: 0.0066842]
	Learning Rate: 0.00668425
	LOSS [training: 3.1060084171029865 | validation: 2.7395950110056324]
	TIME [epoch: 9.44 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.261570515406395		[learning rate: 0.00666]
	Learning Rate: 0.00665999
	LOSS [training: 3.261570515406395 | validation: 2.2131860318754804]
	TIME [epoch: 9.44 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.921477999071117		[learning rate: 0.0066358]
	Learning Rate: 0.00663582
	LOSS [training: 2.921477999071117 | validation: 2.370476114718684]
	TIME [epoch: 9.47 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9403941375996476		[learning rate: 0.0066117]
	Learning Rate: 0.00661174
	LOSS [training: 2.9403941375996476 | validation: 2.8040266223781805]
	TIME [epoch: 9.44 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9000368942040806		[learning rate: 0.0065877]
	Learning Rate: 0.00658775
	LOSS [training: 2.9000368942040806 | validation: 2.44776889623366]
	TIME [epoch: 9.44 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0579785134670496		[learning rate: 0.0065638]
	Learning Rate: 0.00656384
	LOSS [training: 3.0579785134670496 | validation: 2.2068914934457102]
	TIME [epoch: 9.44 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.036246914458723		[learning rate: 0.00654]
	Learning Rate: 0.00654002
	LOSS [training: 3.036246914458723 | validation: 2.5808681709531003]
	TIME [epoch: 9.46 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.789247395068135		[learning rate: 0.0065163]
	Learning Rate: 0.00651628
	LOSS [training: 2.789247395068135 | validation: 2.5773771353984434]
	TIME [epoch: 9.44 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.85058001425956		[learning rate: 0.0064926]
	Learning Rate: 0.00649264
	LOSS [training: 2.85058001425956 | validation: 3.2541752726917976]
	TIME [epoch: 9.44 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.078420491275303		[learning rate: 0.0064691]
	Learning Rate: 0.00646907
	LOSS [training: 3.078420491275303 | validation: 2.104997090225668]
	TIME [epoch: 9.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_220.pth
	Model improved!!!
EPOCH 221/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0182833395898085		[learning rate: 0.0064456]
	Learning Rate: 0.0064456
	LOSS [training: 3.0182833395898085 | validation: 2.803083404067187]
	TIME [epoch: 9.47 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.972440473571322		[learning rate: 0.0064222]
	Learning Rate: 0.00642221
	LOSS [training: 2.972440473571322 | validation: 2.5293142287886217]
	TIME [epoch: 9.45 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9437456433825337		[learning rate: 0.0063989]
	Learning Rate: 0.0063989
	LOSS [training: 2.9437456433825337 | validation: 2.8873974987971844]
	TIME [epoch: 9.44 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0457554805433653		[learning rate: 0.0063757]
	Learning Rate: 0.00637568
	LOSS [training: 3.0457554805433653 | validation: 2.2680959078580454]
	TIME [epoch: 9.45 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2357187424057288		[learning rate: 0.0063525]
	Learning Rate: 0.00635254
	LOSS [training: 3.2357187424057288 | validation: 2.9066873579948176]
	TIME [epoch: 9.44 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9507382901285704		[learning rate: 0.0063295]
	Learning Rate: 0.00632949
	LOSS [training: 2.9507382901285704 | validation: 2.316629330380299]
	TIME [epoch: 9.44 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.935673214581328		[learning rate: 0.0063065]
	Learning Rate: 0.00630652
	LOSS [training: 2.935673214581328 | validation: 2.3589566618850286]
	TIME [epoch: 9.44 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.905418444721931		[learning rate: 0.0062836]
	Learning Rate: 0.00628363
	LOSS [training: 2.905418444721931 | validation: 2.6211073142176953]
	TIME [epoch: 9.46 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9150344726843285		[learning rate: 0.0062608]
	Learning Rate: 0.00626082
	LOSS [training: 2.9150344726843285 | validation: 2.6187868134313574]
	TIME [epoch: 9.45 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0455592368143103		[learning rate: 0.0062381]
	Learning Rate: 0.0062381
	LOSS [training: 3.0455592368143103 | validation: 2.260415481232012]
	TIME [epoch: 9.44 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9083445828399026		[learning rate: 0.0062155]
	Learning Rate: 0.00621547
	LOSS [training: 2.9083445828399026 | validation: 2.5296678034981976]
	TIME [epoch: 9.44 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8451859682265535		[learning rate: 0.0061929]
	Learning Rate: 0.00619291
	LOSS [training: 2.8451859682265535 | validation: 2.255611367698896]
	TIME [epoch: 9.47 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.806764984468871		[learning rate: 0.0061704]
	Learning Rate: 0.00617043
	LOSS [training: 2.806764984468871 | validation: 2.1941841486954146]
	TIME [epoch: 9.44 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.927692647709146		[learning rate: 0.006148]
	Learning Rate: 0.00614804
	LOSS [training: 2.927692647709146 | validation: 2.740171972634117]
	TIME [epoch: 9.44 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.952183124690014		[learning rate: 0.0061257]
	Learning Rate: 0.00612573
	LOSS [training: 2.952183124690014 | validation: 2.9282203207234323]
	TIME [epoch: 9.44 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.87250845356658		[learning rate: 0.0061035]
	Learning Rate: 0.0061035
	LOSS [training: 2.87250845356658 | validation: 2.412351124949488]
	TIME [epoch: 9.47 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.922516833418218		[learning rate: 0.0060814]
	Learning Rate: 0.00608135
	LOSS [training: 2.922516833418218 | validation: 2.224229790528225]
	TIME [epoch: 9.44 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.70302172139433		[learning rate: 0.0060593]
	Learning Rate: 0.00605928
	LOSS [training: 2.70302172139433 | validation: 2.585754375539309]
	TIME [epoch: 9.44 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.939608963045193		[learning rate: 0.0060373]
	Learning Rate: 0.00603729
	LOSS [training: 2.939608963045193 | validation: 2.419615692635433]
	TIME [epoch: 9.45 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9837125648512126		[learning rate: 0.0060154]
	Learning Rate: 0.00601538
	LOSS [training: 2.9837125648512126 | validation: 2.4802530778934333]
	TIME [epoch: 9.46 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.067780932584843		[learning rate: 0.0059936]
	Learning Rate: 0.00599355
	LOSS [training: 3.067780932584843 | validation: 3.278297757013271]
	TIME [epoch: 9.45 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.129093501791666		[learning rate: 0.0059718]
	Learning Rate: 0.0059718
	LOSS [training: 3.129093501791666 | validation: 2.2583434668784337]
	TIME [epoch: 9.44 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.833705073240565		[learning rate: 0.0059501]
	Learning Rate: 0.00595013
	LOSS [training: 2.833705073240565 | validation: 2.4466427648517133]
	TIME [epoch: 9.46 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.751925070670171		[learning rate: 0.0059285]
	Learning Rate: 0.00592853
	LOSS [training: 2.751925070670171 | validation: 2.238029663946856]
	TIME [epoch: 9.45 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.994921594789857		[learning rate: 0.005907]
	Learning Rate: 0.00590702
	LOSS [training: 2.994921594789857 | validation: 2.333181994644884]
	TIME [epoch: 9.45 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.787134650723449		[learning rate: 0.0058856]
	Learning Rate: 0.00588558
	LOSS [training: 2.787134650723449 | validation: 2.2554957594456853]
	TIME [epoch: 9.44 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8823404271600728		[learning rate: 0.0058642]
	Learning Rate: 0.00586422
	LOSS [training: 2.8823404271600728 | validation: 2.4298822134989155]
	TIME [epoch: 9.47 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8593013087547536		[learning rate: 0.0058429]
	Learning Rate: 0.00584294
	LOSS [training: 2.8593013087547536 | validation: 2.385230029040902]
	TIME [epoch: 9.44 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.841653148046543		[learning rate: 0.0058217]
	Learning Rate: 0.00582174
	LOSS [training: 2.841653148046543 | validation: 2.313220225279705]
	TIME [epoch: 9.44 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.755635681299774		[learning rate: 0.0058006]
	Learning Rate: 0.00580061
	LOSS [training: 2.755635681299774 | validation: 2.2928437205578645]
	TIME [epoch: 9.44 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.766910302280897		[learning rate: 0.0057796]
	Learning Rate: 0.00577956
	LOSS [training: 2.766910302280897 | validation: 2.725470987768255]
	TIME [epoch: 9.47 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7567323624191618		[learning rate: 0.0057586]
	Learning Rate: 0.00575859
	LOSS [training: 2.7567323624191618 | validation: 3.2081833780406357]
	TIME [epoch: 9.44 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.891085574873344		[learning rate: 0.0057377]
	Learning Rate: 0.00573769
	LOSS [training: 2.891085574873344 | validation: 2.1521318537042506]
	TIME [epoch: 9.45 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0129590523106544		[learning rate: 0.0057169]
	Learning Rate: 0.00571686
	LOSS [training: 3.0129590523106544 | validation: 2.503656301786473]
	TIME [epoch: 9.44 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2956581974903636		[learning rate: 0.0056961]
	Learning Rate: 0.00569612
	LOSS [training: 3.2956581974903636 | validation: 3.5325376708709264]
	TIME [epoch: 9.47 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.112816185728571		[learning rate: 0.0056754]
	Learning Rate: 0.00567545
	LOSS [training: 3.112816185728571 | validation: 2.244221939284013]
	TIME [epoch: 9.44 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.789867158014444		[learning rate: 0.0056548]
	Learning Rate: 0.00565485
	LOSS [training: 2.789867158014444 | validation: 2.26405543028759]
	TIME [epoch: 9.44 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.766610632899482		[learning rate: 0.0056343]
	Learning Rate: 0.00563433
	LOSS [training: 2.766610632899482 | validation: 2.1375816162156402]
	TIME [epoch: 9.45 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.666829951855685		[learning rate: 0.0056139]
	Learning Rate: 0.00561388
	LOSS [training: 2.666829951855685 | validation: 3.1084639872083346]
	TIME [epoch: 9.47 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8288451496044518		[learning rate: 0.0055935]
	Learning Rate: 0.00559351
	LOSS [training: 2.8288451496044518 | validation: 2.7298259529370017]
	TIME [epoch: 9.45 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.851679787268499		[learning rate: 0.0055732]
	Learning Rate: 0.00557321
	LOSS [training: 2.851679787268499 | validation: 3.6390662818385797]
	TIME [epoch: 9.45 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.089780527076201		[learning rate: 0.005553]
	Learning Rate: 0.00555298
	LOSS [training: 3.089780527076201 | validation: 2.170008355036856]
	TIME [epoch: 9.45 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.825477989089362		[learning rate: 0.0055328]
	Learning Rate: 0.00553283
	LOSS [training: 2.825477989089362 | validation: 2.1371258659572634]
	TIME [epoch: 9.45 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.840975514391034		[learning rate: 0.0055128]
	Learning Rate: 0.00551275
	LOSS [training: 2.840975514391034 | validation: 2.306671498571905]
	TIME [epoch: 9.44 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.731518726536624		[learning rate: 0.0054927]
	Learning Rate: 0.00549274
	LOSS [training: 2.731518726536624 | validation: 2.2994749804171755]
	TIME [epoch: 9.44 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.94935386406981		[learning rate: 0.0054728]
	Learning Rate: 0.00547281
	LOSS [training: 2.94935386406981 | validation: 2.443182087970817]
	TIME [epoch: 9.46 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9015322036446705		[learning rate: 0.005453]
	Learning Rate: 0.00545295
	LOSS [training: 2.9015322036446705 | validation: 2.2592009456281223]
	TIME [epoch: 9.45 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7468244062297886		[learning rate: 0.0054332]
	Learning Rate: 0.00543316
	LOSS [training: 2.7468244062297886 | validation: 2.4185559857853054]
	TIME [epoch: 9.44 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.784856217305509		[learning rate: 0.0054134]
	Learning Rate: 0.00541344
	LOSS [training: 2.784856217305509 | validation: 2.3194320279435385]
	TIME [epoch: 9.44 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7414245351954007		[learning rate: 0.0053938]
	Learning Rate: 0.0053938
	LOSS [training: 2.7414245351954007 | validation: 2.4522846293767704]
	TIME [epoch: 9.46 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8194151507505234		[learning rate: 0.0053742]
	Learning Rate: 0.00537422
	LOSS [training: 2.8194151507505234 | validation: 2.9379814931644934]
	TIME [epoch: 9.44 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8254561019805373		[learning rate: 0.0053547]
	Learning Rate: 0.00535472
	LOSS [training: 2.8254561019805373 | validation: 2.400521080158345]
	TIME [epoch: 9.44 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.791964212528009		[learning rate: 0.0053353]
	Learning Rate: 0.00533529
	LOSS [training: 2.791964212528009 | validation: 2.4481314873657563]
	TIME [epoch: 9.44 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7960101629412057		[learning rate: 0.0053159]
	Learning Rate: 0.00531593
	LOSS [training: 2.7960101629412057 | validation: 2.619427864364474]
	TIME [epoch: 9.46 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.708977226009618		[learning rate: 0.0052966]
	Learning Rate: 0.00529663
	LOSS [training: 2.708977226009618 | validation: 2.5252794295786907]
	TIME [epoch: 9.45 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8653033927843885		[learning rate: 0.0052774]
	Learning Rate: 0.00527741
	LOSS [training: 2.8653033927843885 | validation: 2.1717459961177132]
	TIME [epoch: 9.44 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.679916024380396		[learning rate: 0.0052583]
	Learning Rate: 0.00525826
	LOSS [training: 2.679916024380396 | validation: 2.5649185584050636]
	TIME [epoch: 9.44 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.741260768248772		[learning rate: 0.0052392]
	Learning Rate: 0.00523918
	LOSS [training: 2.741260768248772 | validation: 2.5748746676549352]
	TIME [epoch: 9.46 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7637544685824795		[learning rate: 0.0052202]
	Learning Rate: 0.00522017
	LOSS [training: 2.7637544685824795 | validation: 2.658495515505517]
	TIME [epoch: 9.44 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.912515478693907		[learning rate: 0.0052012]
	Learning Rate: 0.00520122
	LOSS [training: 2.912515478693907 | validation: 3.775639544274725]
	TIME [epoch: 9.44 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.104319848590598		[learning rate: 0.0051823]
	Learning Rate: 0.00518234
	LOSS [training: 3.104319848590598 | validation: 2.130138448530947]
	TIME [epoch: 9.44 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.739706047651919		[learning rate: 0.0051635]
	Learning Rate: 0.00516354
	LOSS [training: 2.739706047651919 | validation: 2.9645536949101152]
	TIME [epoch: 9.47 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.753688392679478		[learning rate: 0.0051448]
	Learning Rate: 0.0051448
	LOSS [training: 2.753688392679478 | validation: 2.266798268371189]
	TIME [epoch: 9.44 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.771875776616986		[learning rate: 0.0051261]
	Learning Rate: 0.00512613
	LOSS [training: 2.771875776616986 | validation: 2.1064433673765577]
	TIME [epoch: 9.44 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.740282991238438		[learning rate: 0.0051075]
	Learning Rate: 0.00510753
	LOSS [training: 2.740282991238438 | validation: 2.138013142978826]
	TIME [epoch: 9.45 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.674119096710139		[learning rate: 0.005089]
	Learning Rate: 0.00508899
	LOSS [training: 2.674119096710139 | validation: 2.222761732314725]
	TIME [epoch: 9.46 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.695315233820806		[learning rate: 0.0050705]
	Learning Rate: 0.00507052
	LOSS [training: 2.695315233820806 | validation: 2.2448798557939273]
	TIME [epoch: 9.44 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7440579634036646		[learning rate: 0.0050521]
	Learning Rate: 0.00505212
	LOSS [training: 2.7440579634036646 | validation: 2.1135054514060934]
	TIME [epoch: 9.44 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.586733834173356		[learning rate: 0.0050338]
	Learning Rate: 0.00503379
	LOSS [training: 2.586733834173356 | validation: 2.1897099040358023]
	TIME [epoch: 9.46 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.731289517230615		[learning rate: 0.0050155]
	Learning Rate: 0.00501552
	LOSS [training: 2.731289517230615 | validation: 3.2528366501576205]
	TIME [epoch: 9.45 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.924392708599445		[learning rate: 0.0049973]
	Learning Rate: 0.00499732
	LOSS [training: 2.924392708599445 | validation: 2.4959805550323213]
	TIME [epoch: 9.44 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.886097640795596		[learning rate: 0.0049792]
	Learning Rate: 0.00497918
	LOSS [training: 2.886097640795596 | validation: 2.1152440463461764]
	TIME [epoch: 9.43 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6416102048352643		[learning rate: 0.0049611]
	Learning Rate: 0.00496111
	LOSS [training: 2.6416102048352643 | validation: 2.4126269147128947]
	TIME [epoch: 9.46 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9783635786810896		[learning rate: 0.0049431]
	Learning Rate: 0.00494311
	LOSS [training: 2.9783635786810896 | validation: 2.1442447524162156]
	TIME [epoch: 9.44 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.755916090558025		[learning rate: 0.0049252]
	Learning Rate: 0.00492517
	LOSS [training: 2.755916090558025 | validation: 2.223489747034161]
	TIME [epoch: 9.44 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8002899037420135		[learning rate: 0.0049073]
	Learning Rate: 0.00490729
	LOSS [training: 2.8002899037420135 | validation: 2.1126638016382655]
	TIME [epoch: 9.44 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.710817902583698		[learning rate: 0.0048895]
	Learning Rate: 0.00488948
	LOSS [training: 2.710817902583698 | validation: 2.3520484902304113]
	TIME [epoch: 9.46 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6785091708637707		[learning rate: 0.0048717]
	Learning Rate: 0.00487174
	LOSS [training: 2.6785091708637707 | validation: 2.1985768153855223]
	TIME [epoch: 9.44 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6088668920166693		[learning rate: 0.0048541]
	Learning Rate: 0.00485406
	LOSS [training: 2.6088668920166693 | validation: 3.1961486665120002]
	TIME [epoch: 9.44 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.927610176072383		[learning rate: 0.0048364]
	Learning Rate: 0.00483645
	LOSS [training: 2.927610176072383 | validation: 2.088812719725218]
	TIME [epoch: 9.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_300.pth
	Model improved!!!
EPOCH 301/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.752654673415438		[learning rate: 0.0048189]
	Learning Rate: 0.00481889
	LOSS [training: 2.752654673415438 | validation: 2.83523918411106]
	TIME [epoch: 9.48 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.842795496015083		[learning rate: 0.0048014]
	Learning Rate: 0.00480141
	LOSS [training: 2.842795496015083 | validation: 2.0399120036177196]
	TIME [epoch: 9.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_302.pth
	Model improved!!!
EPOCH 303/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.694065335715082		[learning rate: 0.004784]
	Learning Rate: 0.00478398
	LOSS [training: 2.694065335715082 | validation: 2.774248979000205]
	TIME [epoch: 9.45 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.917755059809285		[learning rate: 0.0047666]
	Learning Rate: 0.00476662
	LOSS [training: 2.917755059809285 | validation: 2.3356356619321286]
	TIME [epoch: 9.47 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.883784354376877		[learning rate: 0.0047493]
	Learning Rate: 0.00474932
	LOSS [training: 2.883784354376877 | validation: 2.312696029587229]
	TIME [epoch: 9.47 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1298179859496393		[learning rate: 0.0047321]
	Learning Rate: 0.00473209
	LOSS [training: 3.1298179859496393 | validation: 2.5584954616318636]
	TIME [epoch: 9.46 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7200400495609642		[learning rate: 0.0047149]
	Learning Rate: 0.00471491
	LOSS [training: 2.7200400495609642 | validation: 2.250753712171812]
	TIME [epoch: 9.45 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5796474099951086		[learning rate: 0.0046978]
	Learning Rate: 0.0046978
	LOSS [training: 2.5796474099951086 | validation: 2.31538111163234]
	TIME [epoch: 9.48 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.646447836827545		[learning rate: 0.0046808]
	Learning Rate: 0.00468075
	LOSS [training: 2.646447836827545 | validation: 2.1731363089081412]
	TIME [epoch: 9.46 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5779648487786777		[learning rate: 0.0046638]
	Learning Rate: 0.00466377
	LOSS [training: 2.5779648487786777 | validation: 2.736324109568808]
	TIME [epoch: 9.46 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7119618372191687		[learning rate: 0.0046468]
	Learning Rate: 0.00464684
	LOSS [training: 2.7119618372191687 | validation: 2.3506348555177943]
	TIME [epoch: 9.45 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5985446875026597		[learning rate: 0.00463]
	Learning Rate: 0.00462998
	LOSS [training: 2.5985446875026597 | validation: 2.0093214790556853]
	TIME [epoch: 9.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_312.pth
	Model improved!!!
EPOCH 313/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6435973720736823		[learning rate: 0.0046132]
	Learning Rate: 0.00461318
	LOSS [training: 2.6435973720736823 | validation: 2.0746486140974363]
	TIME [epoch: 9.45 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.570763594879404		[learning rate: 0.0045964]
	Learning Rate: 0.00459643
	LOSS [training: 2.570763594879404 | validation: 2.1557963775310505]
	TIME [epoch: 9.45 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.613624141808082		[learning rate: 0.0045798]
	Learning Rate: 0.00457975
	LOSS [training: 2.613624141808082 | validation: 2.290586635594071]
	TIME [epoch: 9.45 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5949139630068108		[learning rate: 0.0045631]
	Learning Rate: 0.00456313
	LOSS [training: 2.5949139630068108 | validation: 2.2640465568675467]
	TIME [epoch: 9.47 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.641375979555565		[learning rate: 0.0045466]
	Learning Rate: 0.00454657
	LOSS [training: 2.641375979555565 | validation: 2.041980441465179]
	TIME [epoch: 9.45 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.624108179935026		[learning rate: 0.0045301]
	Learning Rate: 0.00453007
	LOSS [training: 2.624108179935026 | validation: 2.1310033550278225]
	TIME [epoch: 9.45 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.640859270489177		[learning rate: 0.0045136]
	Learning Rate: 0.00451363
	LOSS [training: 2.640859270489177 | validation: 2.24705769344398]
	TIME [epoch: 9.45 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6710286204480567		[learning rate: 0.0044973]
	Learning Rate: 0.00449725
	LOSS [training: 2.6710286204480567 | validation: 2.2546807788586096]
	TIME [epoch: 9.47 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.62220808162309		[learning rate: 0.0044809]
	Learning Rate: 0.00448093
	LOSS [training: 2.62220808162309 | validation: 2.08973297060952]
	TIME [epoch: 9.45 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.608399986482312		[learning rate: 0.0044647]
	Learning Rate: 0.00446467
	LOSS [training: 2.608399986482312 | validation: 2.0517084690146805]
	TIME [epoch: 9.44 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6142667084054816		[learning rate: 0.0044485]
	Learning Rate: 0.00444847
	LOSS [training: 2.6142667084054816 | validation: 2.2049772680646305]
	TIME [epoch: 9.45 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.699436961634718		[learning rate: 0.0044323]
	Learning Rate: 0.00443232
	LOSS [training: 2.699436961634718 | validation: 2.1884328232644363]
	TIME [epoch: 9.46 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7216049026263134		[learning rate: 0.0044162]
	Learning Rate: 0.00441624
	LOSS [training: 2.7216049026263134 | validation: 2.1129545482110332]
	TIME [epoch: 9.45 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6351077646723446		[learning rate: 0.0044002]
	Learning Rate: 0.00440021
	LOSS [training: 2.6351077646723446 | validation: 2.2908374438049304]
	TIME [epoch: 9.44 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.556840693646599		[learning rate: 0.0043842]
	Learning Rate: 0.00438424
	LOSS [training: 2.556840693646599 | validation: 2.0341874833272446]
	TIME [epoch: 9.46 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6878853799750426		[learning rate: 0.0043683]
	Learning Rate: 0.00436833
	LOSS [training: 2.6878853799750426 | validation: 2.3701821006487194]
	TIME [epoch: 9.45 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.540855148388726		[learning rate: 0.0043525]
	Learning Rate: 0.00435248
	LOSS [training: 2.540855148388726 | validation: 2.0084123029478884]
	TIME [epoch: 9.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_329.pth
	Model improved!!!
EPOCH 330/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5776466524083252		[learning rate: 0.0043367]
	Learning Rate: 0.00433668
	LOSS [training: 2.5776466524083252 | validation: 2.191656245568753]
	TIME [epoch: 9.44 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5780827632793915		[learning rate: 0.0043209]
	Learning Rate: 0.00432095
	LOSS [training: 2.5780827632793915 | validation: 2.507627462656411]
	TIME [epoch: 9.47 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6112327720793003		[learning rate: 0.0043053]
	Learning Rate: 0.00430527
	LOSS [training: 2.6112327720793003 | validation: 2.1232047665201907]
	TIME [epoch: 9.45 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5839251906961347		[learning rate: 0.0042896]
	Learning Rate: 0.00428964
	LOSS [training: 2.5839251906961347 | validation: 2.266875017517462]
	TIME [epoch: 9.45 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.586245166083465		[learning rate: 0.0042741]
	Learning Rate: 0.00427407
	LOSS [training: 2.586245166083465 | validation: 2.26739221169682]
	TIME [epoch: 9.44 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.611290654938973		[learning rate: 0.0042586]
	Learning Rate: 0.00425856
	LOSS [training: 2.611290654938973 | validation: 2.0718422353142945]
	TIME [epoch: 9.47 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5578761985905567		[learning rate: 0.0042431]
	Learning Rate: 0.00424311
	LOSS [training: 2.5578761985905567 | validation: 2.1194224207018557]
	TIME [epoch: 9.44 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.599987792024233		[learning rate: 0.0042277]
	Learning Rate: 0.00422771
	LOSS [training: 2.599987792024233 | validation: 2.0417144969769065]
	TIME [epoch: 9.44 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.573105266830608		[learning rate: 0.0042124]
	Learning Rate: 0.00421237
	LOSS [training: 2.573105266830608 | validation: 2.10601100668267]
	TIME [epoch: 9.44 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5280928594016743		[learning rate: 0.0041971]
	Learning Rate: 0.00419708
	LOSS [training: 2.5280928594016743 | validation: 2.0966648336644584]
	TIME [epoch: 9.47 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.636802191518109		[learning rate: 0.0041818]
	Learning Rate: 0.00418185
	LOSS [training: 2.636802191518109 | validation: 1.9945104574562447]
	TIME [epoch: 9.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_340.pth
	Model improved!!!
EPOCH 341/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5629655191097975		[learning rate: 0.0041667]
	Learning Rate: 0.00416667
	LOSS [training: 2.5629655191097975 | validation: 2.5719335128224374]
	TIME [epoch: 9.44 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7866464509123143		[learning rate: 0.0041516]
	Learning Rate: 0.00415155
	LOSS [training: 2.7866464509123143 | validation: 2.2953573549015114]
	TIME [epoch: 9.45 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5369479202162326		[learning rate: 0.0041365]
	Learning Rate: 0.00413649
	LOSS [training: 2.5369479202162326 | validation: 2.482435266152284]
	TIME [epoch: 9.46 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6245319903704383		[learning rate: 0.0041215]
	Learning Rate: 0.00412147
	LOSS [training: 2.6245319903704383 | validation: 2.4563028955913886]
	TIME [epoch: 9.44 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.85640046517504		[learning rate: 0.0041065]
	Learning Rate: 0.00410652
	LOSS [training: 2.85640046517504 | validation: 2.011008434952573]
	TIME [epoch: 9.44 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7391034804927537		[learning rate: 0.0040916]
	Learning Rate: 0.00409161
	LOSS [training: 2.7391034804927537 | validation: 2.0669188024780194]
	TIME [epoch: 9.46 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.692301400542889		[learning rate: 0.0040768]
	Learning Rate: 0.00407677
	LOSS [training: 2.692301400542889 | validation: 2.335067467513149]
	TIME [epoch: 9.44 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5413390328412677		[learning rate: 0.004062]
	Learning Rate: 0.00406197
	LOSS [training: 2.5413390328412677 | validation: 3.042359976124773]
	TIME [epoch: 9.44 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8253735089412526		[learning rate: 0.0040472]
	Learning Rate: 0.00404723
	LOSS [training: 2.8253735089412526 | validation: 2.3519155478669904]
	TIME [epoch: 9.44 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6417358118735335		[learning rate: 0.0040325]
	Learning Rate: 0.00403254
	LOSS [training: 2.6417358118735335 | validation: 2.063856137513556]
	TIME [epoch: 9.46 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.505107094252575		[learning rate: 0.0040179]
	Learning Rate: 0.00401791
	LOSS [training: 2.505107094252575 | validation: 2.710123789045209]
	TIME [epoch: 9.45 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.677503739827877		[learning rate: 0.0040033]
	Learning Rate: 0.00400333
	LOSS [training: 2.677503739827877 | validation: 2.2120828470228115]
	TIME [epoch: 9.44 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5415439658140024		[learning rate: 0.0039888]
	Learning Rate: 0.0039888
	LOSS [training: 2.5415439658140024 | validation: 1.9904157580522133]
	TIME [epoch: 9.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_353.pth
	Model improved!!!
EPOCH 354/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6138710865990733		[learning rate: 0.0039743]
	Learning Rate: 0.00397432
	LOSS [training: 2.6138710865990733 | validation: 1.9938684080500337]
	TIME [epoch: 9.46 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5237148230377		[learning rate: 0.0039599]
	Learning Rate: 0.0039599
	LOSS [training: 2.5237148230377 | validation: 2.139307328716003]
	TIME [epoch: 9.44 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.561062336522924		[learning rate: 0.0039455]
	Learning Rate: 0.00394553
	LOSS [training: 2.561062336522924 | validation: 2.510854402781843]
	TIME [epoch: 9.44 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.589647281734639		[learning rate: 0.0039312]
	Learning Rate: 0.00393121
	LOSS [training: 2.589647281734639 | validation: 2.245981569895395]
	TIME [epoch: 9.44 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6008166767957164		[learning rate: 0.0039169]
	Learning Rate: 0.00391694
	LOSS [training: 2.6008166767957164 | validation: 2.0228952069967936]
	TIME [epoch: 9.46 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5559946878493562		[learning rate: 0.0039027]
	Learning Rate: 0.00390273
	LOSS [training: 2.5559946878493562 | validation: 2.1795247560280537]
	TIME [epoch: 9.44 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.565244492078417		[learning rate: 0.0038886]
	Learning Rate: 0.00388857
	LOSS [training: 2.565244492078417 | validation: 2.0451499823080934]
	TIME [epoch: 9.44 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.714539131526716		[learning rate: 0.0038745]
	Learning Rate: 0.00387445
	LOSS [training: 2.714539131526716 | validation: 2.2103563457928908]
	TIME [epoch: 9.44 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5390557899438133		[learning rate: 0.0038604]
	Learning Rate: 0.00386039
	LOSS [training: 2.5390557899438133 | validation: 2.11342154433927]
	TIME [epoch: 9.46 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7381707029957374		[learning rate: 0.0038464]
	Learning Rate: 0.00384638
	LOSS [training: 2.7381707029957374 | validation: 2.271873468058408]
	TIME [epoch: 9.44 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.584810300907541		[learning rate: 0.0038324]
	Learning Rate: 0.00383242
	LOSS [training: 2.584810300907541 | validation: 2.5422010912403388]
	TIME [epoch: 9.44 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.785544834927034		[learning rate: 0.0038185]
	Learning Rate: 0.00381852
	LOSS [training: 2.785544834927034 | validation: 2.1773994667408267]
	TIME [epoch: 9.45 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5539070831188044		[learning rate: 0.0038047]
	Learning Rate: 0.00380466
	LOSS [training: 2.5539070831188044 | validation: 2.1578076244163604]
	TIME [epoch: 9.46 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5672121113789492		[learning rate: 0.0037909]
	Learning Rate: 0.00379085
	LOSS [training: 2.5672121113789492 | validation: 2.1587432597881473]
	TIME [epoch: 9.44 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.516020207951527		[learning rate: 0.0037771]
	Learning Rate: 0.00377709
	LOSS [training: 2.516020207951527 | validation: 2.413402160259981]
	TIME [epoch: 9.44 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6555243836023275		[learning rate: 0.0037634]
	Learning Rate: 0.00376339
	LOSS [training: 2.6555243836023275 | validation: 2.101360607325885]
	TIME [epoch: 9.46 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.531096215009378		[learning rate: 0.0037497]
	Learning Rate: 0.00374973
	LOSS [training: 2.531096215009378 | validation: 1.993561882764148]
	TIME [epoch: 9.44 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.61157714215746		[learning rate: 0.0037361]
	Learning Rate: 0.00373612
	LOSS [training: 2.61157714215746 | validation: 2.2272492890998876]
	TIME [epoch: 9.44 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.565661345375368		[learning rate: 0.0037226]
	Learning Rate: 0.00372256
	LOSS [training: 2.565661345375368 | validation: 2.332052271880975]
	TIME [epoch: 9.43 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5316162090524648		[learning rate: 0.0037091]
	Learning Rate: 0.00370905
	LOSS [training: 2.5316162090524648 | validation: 2.0822936619503025]
	TIME [epoch: 9.46 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4662169866532944		[learning rate: 0.0036956]
	Learning Rate: 0.00369559
	LOSS [training: 2.4662169866532944 | validation: 2.6167714478561455]
	TIME [epoch: 9.44 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6319271072557204		[learning rate: 0.0036822]
	Learning Rate: 0.00368218
	LOSS [training: 2.6319271072557204 | validation: 2.069264145292929]
	TIME [epoch: 9.44 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5269156900713865		[learning rate: 0.0036688]
	Learning Rate: 0.00366882
	LOSS [training: 2.5269156900713865 | validation: 2.300503782408213]
	TIME [epoch: 9.44 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5762806410173567		[learning rate: 0.0036555]
	Learning Rate: 0.0036555
	LOSS [training: 2.5762806410173567 | validation: 2.0766863988872486]
	TIME [epoch: 9.46 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.491637536530403		[learning rate: 0.0036422]
	Learning Rate: 0.00364224
	LOSS [training: 2.491637536530403 | validation: 2.151296860972434]
	TIME [epoch: 9.44 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5547067504326515		[learning rate: 0.003629]
	Learning Rate: 0.00362902
	LOSS [training: 2.5547067504326515 | validation: 2.222952029081323]
	TIME [epoch: 9.44 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.525760017646263		[learning rate: 0.0036159]
	Learning Rate: 0.00361585
	LOSS [training: 2.525760017646263 | validation: 1.995428430959584]
	TIME [epoch: 9.44 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.518271646701283		[learning rate: 0.0036027]
	Learning Rate: 0.00360273
	LOSS [training: 2.518271646701283 | validation: 2.13516623709957]
	TIME [epoch: 9.47 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.577686610900412		[learning rate: 0.0035897]
	Learning Rate: 0.00358965
	LOSS [training: 2.577686610900412 | validation: 2.4463870117796254]
	TIME [epoch: 9.44 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.687355706248101		[learning rate: 0.0035766]
	Learning Rate: 0.00357663
	LOSS [training: 2.687355706248101 | validation: 2.043617432354791]
	TIME [epoch: 9.44 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.561846384103469		[learning rate: 0.0035636]
	Learning Rate: 0.00356365
	LOSS [training: 2.561846384103469 | validation: 2.1906046359449696]
	TIME [epoch: 9.44 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.565866879823141		[learning rate: 0.0035507]
	Learning Rate: 0.00355072
	LOSS [training: 2.565866879823141 | validation: 2.0707834961182394]
	TIME [epoch: 9.46 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.494573235926357		[learning rate: 0.0035378]
	Learning Rate: 0.00353783
	LOSS [training: 2.494573235926357 | validation: 2.030131503818767]
	TIME [epoch: 9.44 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5207591363103896		[learning rate: 0.003525]
	Learning Rate: 0.00352499
	LOSS [training: 2.5207591363103896 | validation: 1.9811524486385363]
	TIME [epoch: 9.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_387.pth
	Model improved!!!
EPOCH 388/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.461634349604355		[learning rate: 0.0035122]
	Learning Rate: 0.0035122
	LOSS [training: 2.461634349604355 | validation: 2.178640467887957]
	TIME [epoch: 9.45 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5104652068949935		[learning rate: 0.0034995]
	Learning Rate: 0.00349945
	LOSS [training: 2.5104652068949935 | validation: 2.009700658194469]
	TIME [epoch: 9.44 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5754087127556384		[learning rate: 0.0034868]
	Learning Rate: 0.00348675
	LOSS [training: 2.5754087127556384 | validation: 2.079967921671693]
	TIME [epoch: 9.44 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5602879707720687		[learning rate: 0.0034741]
	Learning Rate: 0.0034741
	LOSS [training: 2.5602879707720687 | validation: 2.060295198308444]
	TIME [epoch: 9.44 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.570469562472573		[learning rate: 0.0034615]
	Learning Rate: 0.00346149
	LOSS [training: 2.570469562472573 | validation: 2.131048736833889]
	TIME [epoch: 9.46 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5721297220762773		[learning rate: 0.0034489]
	Learning Rate: 0.00344893
	LOSS [training: 2.5721297220762773 | validation: 2.055515137578518]
	TIME [epoch: 9.44 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5661409205941514		[learning rate: 0.0034364]
	Learning Rate: 0.00343641
	LOSS [training: 2.5661409205941514 | validation: 2.0044065991592666]
	TIME [epoch: 9.43 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4609360479755313		[learning rate: 0.0034239]
	Learning Rate: 0.00342394
	LOSS [training: 2.4609360479755313 | validation: 2.196977775015755]
	TIME [epoch: 9.44 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5534583004268994		[learning rate: 0.0034115]
	Learning Rate: 0.00341152
	LOSS [training: 2.5534583004268994 | validation: 2.1410222163056822]
	TIME [epoch: 9.45 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.487185595983189		[learning rate: 0.0033991]
	Learning Rate: 0.00339914
	LOSS [training: 2.487185595983189 | validation: 2.075304102785349]
	TIME [epoch: 9.44 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.615110120131532		[learning rate: 0.0033868]
	Learning Rate: 0.0033868
	LOSS [training: 2.615110120131532 | validation: 2.11312653368283]
	TIME [epoch: 9.43 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.697821449356886		[learning rate: 0.0033745]
	Learning Rate: 0.00337451
	LOSS [training: 2.697821449356886 | validation: 2.2603430796436395]
	TIME [epoch: 9.44 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.712814359535025		[learning rate: 0.0033623]
	Learning Rate: 0.00336226
	LOSS [training: 2.712814359535025 | validation: 1.9991114587923084]
	TIME [epoch: 9.46 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.624803051800382		[learning rate: 0.0033501]
	Learning Rate: 0.00335006
	LOSS [training: 2.624803051800382 | validation: 2.0331253133366496]
	TIME [epoch: 9.44 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5230597366300804		[learning rate: 0.0033379]
	Learning Rate: 0.0033379
	LOSS [training: 2.5230597366300804 | validation: 2.0044093222122497]
	TIME [epoch: 9.43 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.563036758220396		[learning rate: 0.0033258]
	Learning Rate: 0.00332579
	LOSS [training: 2.563036758220396 | validation: 2.0958730768609373]
	TIME [epoch: 9.44 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.666140223076869		[learning rate: 0.0033137]
	Learning Rate: 0.00331372
	LOSS [training: 2.666140223076869 | validation: 1.9967860113343177]
	TIME [epoch: 9.46 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4522984407925064		[learning rate: 0.0033017]
	Learning Rate: 0.00330169
	LOSS [training: 2.4522984407925064 | validation: 2.0099358397039726]
	TIME [epoch: 9.44 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6569126504843803		[learning rate: 0.0032897]
	Learning Rate: 0.00328971
	LOSS [training: 2.6569126504843803 | validation: 2.545950007568623]
	TIME [epoch: 9.44 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6849983582354167		[learning rate: 0.0032778]
	Learning Rate: 0.00327777
	LOSS [training: 2.6849983582354167 | validation: 2.1684088171733387]
	TIME [epoch: 9.44 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5428346458671798		[learning rate: 0.0032659]
	Learning Rate: 0.00326588
	LOSS [training: 2.5428346458671798 | validation: 2.0519026206798143]
	TIME [epoch: 9.45 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5596336069249666		[learning rate: 0.003254]
	Learning Rate: 0.00325403
	LOSS [training: 2.5596336069249666 | validation: 1.9896605010847261]
	TIME [epoch: 9.44 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5439806819447464		[learning rate: 0.0032422]
	Learning Rate: 0.00324222
	LOSS [training: 2.5439806819447464 | validation: 2.006471587511909]
	TIME [epoch: 9.43 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4801370998725836		[learning rate: 0.0032305]
	Learning Rate: 0.00323045
	LOSS [training: 2.4801370998725836 | validation: 1.9984937636661653]
	TIME [epoch: 9.46 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5336684346675		[learning rate: 0.0032187]
	Learning Rate: 0.00321873
	LOSS [training: 2.5336684346675 | validation: 1.9789202103437509]
	TIME [epoch: 9.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_412.pth
	Model improved!!!
EPOCH 413/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6712118299358627		[learning rate: 0.003207]
	Learning Rate: 0.00320705
	LOSS [training: 2.6712118299358627 | validation: 2.263223528335516]
	TIME [epoch: 9.44 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6431305593989562		[learning rate: 0.0031954]
	Learning Rate: 0.00319541
	LOSS [training: 2.6431305593989562 | validation: 2.254076754329436]
	TIME [epoch: 9.44 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4608508545759262		[learning rate: 0.0031838]
	Learning Rate: 0.00318381
	LOSS [training: 2.4608508545759262 | validation: 2.0194524297553524]
	TIME [epoch: 9.46 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4232143233282506		[learning rate: 0.0031723]
	Learning Rate: 0.00317226
	LOSS [training: 2.4232143233282506 | validation: 2.363572773311116]
	TIME [epoch: 9.44 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.659778254130581		[learning rate: 0.0031607]
	Learning Rate: 0.00316075
	LOSS [training: 2.659778254130581 | validation: 2.363215330736728]
	TIME [epoch: 9.44 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.705711358310429		[learning rate: 0.0031493]
	Learning Rate: 0.00314927
	LOSS [training: 2.705711358310429 | validation: 2.3326125625698713]
	TIME [epoch: 9.44 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.546330449133131		[learning rate: 0.0031378]
	Learning Rate: 0.00313785
	LOSS [training: 2.546330449133131 | validation: 2.366712504991399]
	TIME [epoch: 9.46 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.506439872121263		[learning rate: 0.0031265]
	Learning Rate: 0.00312646
	LOSS [training: 2.506439872121263 | validation: 1.9989469033899776]
	TIME [epoch: 9.43 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5065965525600524		[learning rate: 0.0031151]
	Learning Rate: 0.00311511
	LOSS [training: 2.5065965525600524 | validation: 1.9967228751533106]
	TIME [epoch: 9.44 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4639231180451704		[learning rate: 0.0031038]
	Learning Rate: 0.00310381
	LOSS [training: 2.4639231180451704 | validation: 2.0048542491983783]
	TIME [epoch: 9.43 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.53149982996715		[learning rate: 0.0030925]
	Learning Rate: 0.00309254
	LOSS [training: 2.53149982996715 | validation: 2.0134221643122157]
	TIME [epoch: 9.46 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.514329752246952		[learning rate: 0.0030813]
	Learning Rate: 0.00308132
	LOSS [training: 2.514329752246952 | validation: 1.954707219019257]
	TIME [epoch: 9.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_424.pth
	Model improved!!!
EPOCH 425/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.426609109419843		[learning rate: 0.0030701]
	Learning Rate: 0.00307014
	LOSS [training: 2.426609109419843 | validation: 2.0095918340585546]
	TIME [epoch: 9.45 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5775130280387337		[learning rate: 0.003059]
	Learning Rate: 0.003059
	LOSS [training: 2.5775130280387337 | validation: 2.2034061278793873]
	TIME [epoch: 9.45 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.491752518660175		[learning rate: 0.0030479]
	Learning Rate: 0.0030479
	LOSS [training: 2.491752518660175 | validation: 2.1942357013241]
	TIME [epoch: 9.46 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4487708713851744		[learning rate: 0.0030368]
	Learning Rate: 0.00303683
	LOSS [training: 2.4487708713851744 | validation: 2.0484132007932483]
	TIME [epoch: 9.44 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5730333547925044		[learning rate: 0.0030258]
	Learning Rate: 0.00302581
	LOSS [training: 2.5730333547925044 | validation: 2.011643159077161]
	TIME [epoch: 9.44 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5119072587528493		[learning rate: 0.0030148]
	Learning Rate: 0.00301483
	LOSS [training: 2.5119072587528493 | validation: 2.010912449773218]
	TIME [epoch: 9.45 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5745772545309538		[learning rate: 0.0030039]
	Learning Rate: 0.00300389
	LOSS [training: 2.5745772545309538 | validation: 2.0772938234427465]
	TIME [epoch: 9.45 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.530330155091532		[learning rate: 0.002993]
	Learning Rate: 0.00299299
	LOSS [training: 2.530330155091532 | validation: 2.0201352244896755]
	TIME [epoch: 9.44 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4410511535588393		[learning rate: 0.0029821]
	Learning Rate: 0.00298213
	LOSS [training: 2.4410511535588393 | validation: 2.41348284725716]
	TIME [epoch: 9.44 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.652656361222638		[learning rate: 0.0029713]
	Learning Rate: 0.00297131
	LOSS [training: 2.652656361222638 | validation: 2.215306742248151]
	TIME [epoch: 9.46 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5316650443507536		[learning rate: 0.0029605]
	Learning Rate: 0.00296052
	LOSS [training: 2.5316650443507536 | validation: 2.5310231063159763]
	TIME [epoch: 9.44 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5822156720588247		[learning rate: 0.0029498]
	Learning Rate: 0.00294978
	LOSS [training: 2.5822156720588247 | validation: 2.26535844741156]
	TIME [epoch: 9.44 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5798448049636606		[learning rate: 0.0029391]
	Learning Rate: 0.00293907
	LOSS [training: 2.5798448049636606 | validation: 2.0517053040617723]
	TIME [epoch: 9.44 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5142247082428506		[learning rate: 0.0029284]
	Learning Rate: 0.00292841
	LOSS [training: 2.5142247082428506 | validation: 2.1299918121235346]
	TIME [epoch: 9.47 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.468454306268685		[learning rate: 0.0029178]
	Learning Rate: 0.00291778
	LOSS [training: 2.468454306268685 | validation: 2.1462284515710155]
	TIME [epoch: 9.45 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.499964084526242		[learning rate: 0.0029072]
	Learning Rate: 0.00290719
	LOSS [training: 2.499964084526242 | validation: 2.331297114592268]
	TIME [epoch: 9.44 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.610556920166437		[learning rate: 0.0028966]
	Learning Rate: 0.00289664
	LOSS [training: 2.610556920166437 | validation: 2.004885166885167]
	TIME [epoch: 9.44 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.512601029707314		[learning rate: 0.0028861]
	Learning Rate: 0.00288613
	LOSS [training: 2.512601029707314 | validation: 2.095642810390196]
	TIME [epoch: 9.46 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.572242144636792		[learning rate: 0.0028757]
	Learning Rate: 0.00287566
	LOSS [training: 2.572242144636792 | validation: 2.255951241789007]
	TIME [epoch: 9.44 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4435852016645527		[learning rate: 0.0028652]
	Learning Rate: 0.00286522
	LOSS [training: 2.4435852016645527 | validation: 2.032327957754517]
	TIME [epoch: 9.44 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4489713497322385		[learning rate: 0.0028548]
	Learning Rate: 0.00285482
	LOSS [training: 2.4489713497322385 | validation: 2.0856669581712293]
	TIME [epoch: 9.44 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4755086904635055		[learning rate: 0.0028445]
	Learning Rate: 0.00284446
	LOSS [training: 2.4755086904635055 | validation: 2.1252247205209818]
	TIME [epoch: 9.47 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5206308038378498		[learning rate: 0.0028341]
	Learning Rate: 0.00283414
	LOSS [training: 2.5206308038378498 | validation: 1.9992357985050226]
	TIME [epoch: 9.44 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6163129821745357		[learning rate: 0.0028239]
	Learning Rate: 0.00282385
	LOSS [training: 2.6163129821745357 | validation: 2.3053410290378613]
	TIME [epoch: 9.44 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.520813304758645		[learning rate: 0.0028136]
	Learning Rate: 0.00281361
	LOSS [training: 2.520813304758645 | validation: 2.1175373468347183]
	TIME [epoch: 9.45 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6138502068992526		[learning rate: 0.0028034]
	Learning Rate: 0.00280339
	LOSS [training: 2.6138502068992526 | validation: 2.1105348100480223]
	TIME [epoch: 9.46 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4175290735488235		[learning rate: 0.0027932]
	Learning Rate: 0.00279322
	LOSS [training: 2.4175290735488235 | validation: 2.1820871485898166]
	TIME [epoch: 9.44 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.44061347320297		[learning rate: 0.0027831]
	Learning Rate: 0.00278308
	LOSS [training: 2.44061347320297 | validation: 2.0640409795667534]
	TIME [epoch: 9.43 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4800299344516845		[learning rate: 0.002773]
	Learning Rate: 0.00277298
	LOSS [training: 2.4800299344516845 | validation: 2.057723067430302]
	TIME [epoch: 9.46 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4383904702896357		[learning rate: 0.0027629]
	Learning Rate: 0.00276292
	LOSS [training: 2.4383904702896357 | validation: 2.0530072252067986]
	TIME [epoch: 9.45 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.459364559405286		[learning rate: 0.0027529]
	Learning Rate: 0.00275289
	LOSS [training: 2.459364559405286 | validation: 2.011968563903468]
	TIME [epoch: 9.44 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4689443330575243		[learning rate: 0.0027429]
	Learning Rate: 0.0027429
	LOSS [training: 2.4689443330575243 | validation: 2.113105046456613]
	TIME [epoch: 9.44 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.510629102822242		[learning rate: 0.0027329]
	Learning Rate: 0.00273295
	LOSS [training: 2.510629102822242 | validation: 2.003946510532637]
	TIME [epoch: 9.46 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4768047727104663		[learning rate: 0.002723]
	Learning Rate: 0.00272303
	LOSS [training: 2.4768047727104663 | validation: 2.0823988612463977]
	TIME [epoch: 9.44 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4915448043590773		[learning rate: 0.0027131]
	Learning Rate: 0.00271315
	LOSS [training: 2.4915448043590773 | validation: 2.0498904529309017]
	TIME [epoch: 9.44 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.454659953756628		[learning rate: 0.0027033]
	Learning Rate: 0.0027033
	LOSS [training: 2.454659953756628 | validation: 2.0162415952768824]
	TIME [epoch: 9.44 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.528504519198553		[learning rate: 0.0026935]
	Learning Rate: 0.00269349
	LOSS [training: 2.528504519198553 | validation: 2.2467501975482493]
	TIME [epoch: 9.46 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.452546461482079		[learning rate: 0.0026837]
	Learning Rate: 0.00268372
	LOSS [training: 2.452546461482079 | validation: 2.066264721292422]
	TIME [epoch: 9.44 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.257465168746337		[learning rate: 0.002674]
	Learning Rate: 0.00267398
	LOSS [training: 2.257465168746337 | validation: 2.006282152253961]
	TIME [epoch: 9.44 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.262604564514338		[learning rate: 0.0026643]
	Learning Rate: 0.00266427
	LOSS [training: 2.262604564514338 | validation: 2.0679198471030555]
	TIME [epoch: 9.44 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1377348865264425		[learning rate: 0.0026546]
	Learning Rate: 0.00265461
	LOSS [training: 2.1377348865264425 | validation: 1.931854959335429]
	TIME [epoch: 9.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_465.pth
	Model improved!!!
EPOCH 466/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.288244977196251		[learning rate: 0.002645]
	Learning Rate: 0.00264497
	LOSS [training: 2.288244977196251 | validation: 1.8071160599461713]
	TIME [epoch: 9.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_466.pth
	Model improved!!!
EPOCH 467/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.025934432126395		[learning rate: 0.0026354]
	Learning Rate: 0.00263537
	LOSS [training: 2.025934432126395 | validation: 2.1332548335273294]
	TIME [epoch: 9.44 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.899628114249356		[learning rate: 0.0026258]
	Learning Rate: 0.00262581
	LOSS [training: 1.899628114249356 | validation: 1.5490563656533494]
	TIME [epoch: 9.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_468.pth
	Model improved!!!
EPOCH 469/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5689133821326036		[learning rate: 0.0026163]
	Learning Rate: 0.00261628
	LOSS [training: 1.5689133821326036 | validation: 1.8257786447656879]
	TIME [epoch: 9.46 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3297848701113817		[learning rate: 0.0026068]
	Learning Rate: 0.00260679
	LOSS [training: 1.3297848701113817 | validation: 1.6096999590760677]
	TIME [epoch: 9.44 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.403417153004296		[learning rate: 0.0025973]
	Learning Rate: 0.00259733
	LOSS [training: 1.403417153004296 | validation: 1.9710282429550603]
	TIME [epoch: 9.44 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3098760658530897		[learning rate: 0.0025879]
	Learning Rate: 0.0025879
	LOSS [training: 1.3098760658530897 | validation: 1.7170091983900775]
	TIME [epoch: 9.46 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2330085702341194		[learning rate: 0.0025785]
	Learning Rate: 0.00257851
	LOSS [training: 1.2330085702341194 | validation: 1.4828891455796633]
	TIME [epoch: 9.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_473.pth
	Model improved!!!
EPOCH 474/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1739037245239548		[learning rate: 0.0025691]
	Learning Rate: 0.00256915
	LOSS [training: 1.1739037245239548 | validation: 1.3865787459839312]
	TIME [epoch: 9.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_474.pth
	Model improved!!!
EPOCH 475/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2081102725673722		[learning rate: 0.0025598]
	Learning Rate: 0.00255983
	LOSS [training: 1.2081102725673722 | validation: 1.463790180043047]
	TIME [epoch: 9.45 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.151310080493274		[learning rate: 0.0025505]
	Learning Rate: 0.00255054
	LOSS [training: 1.151310080493274 | validation: 1.4085810386967959]
	TIME [epoch: 9.47 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3051397744332167		[learning rate: 0.0025413]
	Learning Rate: 0.00254128
	LOSS [training: 1.3051397744332167 | validation: 1.44815450220549]
	TIME [epoch: 9.45 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1893163426425006		[learning rate: 0.0025321]
	Learning Rate: 0.00253206
	LOSS [training: 1.1893163426425006 | validation: 1.4402178880827332]
	TIME [epoch: 9.45 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0829771342115155		[learning rate: 0.0025229]
	Learning Rate: 0.00252287
	LOSS [training: 1.0829771342115155 | validation: 1.4273175178865327]
	TIME [epoch: 9.45 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1665440235574285		[learning rate: 0.0025137]
	Learning Rate: 0.00251371
	LOSS [training: 1.1665440235574285 | validation: 1.4854537191429102]
	TIME [epoch: 9.47 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.16978168538922		[learning rate: 0.0025046]
	Learning Rate: 0.00250459
	LOSS [training: 1.16978168538922 | validation: 2.438581346013357]
	TIME [epoch: 9.45 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6544065688318348		[learning rate: 0.0024955]
	Learning Rate: 0.0024955
	LOSS [training: 1.6544065688318348 | validation: 1.4238787065208647]
	TIME [epoch: 9.45 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0840408206701202		[learning rate: 0.0024864]
	Learning Rate: 0.00248645
	LOSS [training: 1.0840408206701202 | validation: 1.4253909732636683]
	TIME [epoch: 9.45 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0453737503426965		[learning rate: 0.0024774]
	Learning Rate: 0.00247742
	LOSS [training: 1.0453737503426965 | validation: 1.4497463000626574]
	TIME [epoch: 9.47 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0998522572631722		[learning rate: 0.0024684]
	Learning Rate: 0.00246843
	LOSS [training: 1.0998522572631722 | validation: 1.3666210370667549]
	TIME [epoch: 9.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_485.pth
	Model improved!!!
EPOCH 486/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1133890846234409		[learning rate: 0.0024595]
	Learning Rate: 0.00245947
	LOSS [training: 1.1133890846234409 | validation: 2.150807046457083]
	TIME [epoch: 9.45 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.390716526420111		[learning rate: 0.0024505]
	Learning Rate: 0.00245055
	LOSS [training: 1.390716526420111 | validation: 1.3491373437133103]
	TIME [epoch: 9.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_487.pth
	Model improved!!!
EPOCH 488/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1368919450799426		[learning rate: 0.0024417]
	Learning Rate: 0.00244165
	LOSS [training: 1.1368919450799426 | validation: 1.404170502535698]
	TIME [epoch: 9.45 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.094833776995866		[learning rate: 0.0024328]
	Learning Rate: 0.00243279
	LOSS [training: 1.094833776995866 | validation: 1.4117563048606006]
	TIME [epoch: 9.44 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1028472057583505		[learning rate: 0.002424]
	Learning Rate: 0.00242396
	LOSS [training: 1.1028472057583505 | validation: 1.2949454763703108]
	TIME [epoch: 9.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_490.pth
	Model improved!!!
EPOCH 491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.971690413621553		[learning rate: 0.0024152]
	Learning Rate: 0.00241517
	LOSS [training: 0.971690413621553 | validation: 1.3182533319764327]
	TIME [epoch: 9.47 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0060122279115227		[learning rate: 0.0024064]
	Learning Rate: 0.0024064
	LOSS [training: 1.0060122279115227 | validation: 1.3420567801356378]
	TIME [epoch: 9.45 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2339611959513639		[learning rate: 0.0023977]
	Learning Rate: 0.00239767
	LOSS [training: 1.2339611959513639 | validation: 1.619698639668278]
	TIME [epoch: 9.45 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0344110612976096		[learning rate: 0.002389]
	Learning Rate: 0.00238897
	LOSS [training: 1.0344110612976096 | validation: 1.3305797567805229]
	TIME [epoch: 9.45 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9984633175397581		[learning rate: 0.0023803]
	Learning Rate: 0.0023803
	LOSS [training: 0.9984633175397581 | validation: 1.302686485502913]
	TIME [epoch: 9.47 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1308522624074029		[learning rate: 0.0023717]
	Learning Rate: 0.00237166
	LOSS [training: 1.1308522624074029 | validation: 1.3364759202075558]
	TIME [epoch: 9.44 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9417924061823122		[learning rate: 0.0023631]
	Learning Rate: 0.00236305
	LOSS [training: 0.9417924061823122 | validation: 1.2744033043973184]
	TIME [epoch: 9.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_497.pth
	Model improved!!!
EPOCH 498/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.044635200841426		[learning rate: 0.0023545]
	Learning Rate: 0.00235448
	LOSS [training: 1.044635200841426 | validation: 1.2862976173147116]
	TIME [epoch: 9.45 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9786068932643405		[learning rate: 0.0023459]
	Learning Rate: 0.00234593
	LOSS [training: 0.9786068932643405 | validation: 1.2702190431966116]
	TIME [epoch: 9.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_499.pth
	Model improved!!!
EPOCH 500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9390891648496449		[learning rate: 0.0023374]
	Learning Rate: 0.00233742
	LOSS [training: 0.9390891648496449 | validation: 1.3600925907801062]
	TIME [epoch: 9.44 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.034784030273137		[learning rate: 0.0023289]
	Learning Rate: 0.00232894
	LOSS [training: 1.034784030273137 | validation: 1.2871564646647482]
	TIME [epoch: 9.44 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0668160716164568		[learning rate: 0.0023205]
	Learning Rate: 0.00232049
	LOSS [training: 1.0668160716164568 | validation: 1.3754242470160774]
	TIME [epoch: 9.45 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0291038670605324		[learning rate: 0.0023121]
	Learning Rate: 0.00231206
	LOSS [training: 1.0291038670605324 | validation: 1.6543895148295087]
	TIME [epoch: 9.46 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1111876239055938		[learning rate: 0.0023037]
	Learning Rate: 0.00230367
	LOSS [training: 1.1111876239055938 | validation: 1.2260106058167548]
	TIME [epoch: 9.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_504.pth
	Model improved!!!
EPOCH 505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9129101808306386		[learning rate: 0.0022953]
	Learning Rate: 0.00229531
	LOSS [training: 0.9129101808306386 | validation: 1.5908432554019567]
	TIME [epoch: 9.44 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0929034853641084		[learning rate: 0.002287]
	Learning Rate: 0.00228698
	LOSS [training: 1.0929034853641084 | validation: 1.2843575794408053]
	TIME [epoch: 9.46 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9994680295251379		[learning rate: 0.0022787]
	Learning Rate: 0.00227868
	LOSS [training: 0.9994680295251379 | validation: 1.2804613923394712]
	TIME [epoch: 9.45 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0164306765484519		[learning rate: 0.0022704]
	Learning Rate: 0.00227042
	LOSS [training: 1.0164306765484519 | validation: 1.489275261274392]
	TIME [epoch: 9.44 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.10167581112974		[learning rate: 0.0022622]
	Learning Rate: 0.00226218
	LOSS [training: 1.10167581112974 | validation: 1.4993022410854744]
	TIME [epoch: 9.44 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0600780983027591		[learning rate: 0.002254]
	Learning Rate: 0.00225397
	LOSS [training: 1.0600780983027591 | validation: 1.2177075636438384]
	TIME [epoch: 9.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_510.pth
	Model improved!!!
EPOCH 511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9722391207359291		[learning rate: 0.0022458]
	Learning Rate: 0.00224579
	LOSS [training: 0.9722391207359291 | validation: 1.3154047033831584]
	TIME [epoch: 9.45 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9216609211539231		[learning rate: 0.0022376]
	Learning Rate: 0.00223764
	LOSS [training: 0.9216609211539231 | validation: 1.1557261439756321]
	TIME [epoch: 9.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_512.pth
	Model improved!!!
EPOCH 513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9054056293211226		[learning rate: 0.0022295]
	Learning Rate: 0.00222952
	LOSS [training: 0.9054056293211226 | validation: 1.3289153339901572]
	TIME [epoch: 9.44 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9345983004029123		[learning rate: 0.0022214]
	Learning Rate: 0.00222142
	LOSS [training: 0.9345983004029123 | validation: 1.3594329121290922]
	TIME [epoch: 9.47 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9286416686993583		[learning rate: 0.0022134]
	Learning Rate: 0.00221336
	LOSS [training: 0.9286416686993583 | validation: 1.238922478175565]
	TIME [epoch: 9.44 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8862295742736432		[learning rate: 0.0022053]
	Learning Rate: 0.00220533
	LOSS [training: 0.8862295742736432 | validation: 1.3386377921465868]
	TIME [epoch: 9.44 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0285696271479363		[learning rate: 0.0021973]
	Learning Rate: 0.00219733
	LOSS [training: 1.0285696271479363 | validation: 1.413856275119436]
	TIME [epoch: 9.44 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9218642961694468		[learning rate: 0.0021894]
	Learning Rate: 0.00218935
	LOSS [training: 0.9218642961694468 | validation: 1.1476811747251754]
	TIME [epoch: 9.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_518.pth
	Model improved!!!
EPOCH 519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8643382740607729		[learning rate: 0.0021814]
	Learning Rate: 0.00218141
	LOSS [training: 0.8643382740607729 | validation: 1.2377486640768305]
	TIME [epoch: 9.44 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9026098452084674		[learning rate: 0.0021735]
	Learning Rate: 0.00217349
	LOSS [training: 0.9026098452084674 | validation: 1.4216103406428782]
	TIME [epoch: 9.44 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0156179368070681		[learning rate: 0.0021656]
	Learning Rate: 0.0021656
	LOSS [training: 1.0156179368070681 | validation: 1.2083078051652665]
	TIME [epoch: 9.45 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8470630456136113		[learning rate: 0.0021577]
	Learning Rate: 0.00215774
	LOSS [training: 0.8470630456136113 | validation: 1.1495342467198586]
	TIME [epoch: 9.44 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8416085444197104		[learning rate: 0.0021499]
	Learning Rate: 0.00214991
	LOSS [training: 0.8416085444197104 | validation: 1.3194707933330971]
	TIME [epoch: 9.43 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9382208549109391		[learning rate: 0.0021421]
	Learning Rate: 0.00214211
	LOSS [training: 0.9382208549109391 | validation: 1.2258254808924018]
	TIME [epoch: 9.44 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9295220649588936		[learning rate: 0.0021343]
	Learning Rate: 0.00213434
	LOSS [training: 0.9295220649588936 | validation: 1.163352564410719]
	TIME [epoch: 9.45 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.838208909083136		[learning rate: 0.0021266]
	Learning Rate: 0.00212659
	LOSS [training: 0.838208909083136 | validation: 1.182397338450318]
	TIME [epoch: 9.44 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9343647550626499		[learning rate: 0.0021189]
	Learning Rate: 0.00211887
	LOSS [training: 0.9343647550626499 | validation: 1.4324586113538533]
	TIME [epoch: 9.43 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9050976073536228		[learning rate: 0.0021112]
	Learning Rate: 0.00211119
	LOSS [training: 0.9050976073536228 | validation: 1.1397974679342286]
	TIME [epoch: 9.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_528.pth
	Model improved!!!
EPOCH 529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8984985268190817		[learning rate: 0.0021035]
	Learning Rate: 0.00210352
	LOSS [training: 0.8984985268190817 | validation: 1.1539497782633927]
	TIME [epoch: 9.46 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8161884911069363		[learning rate: 0.0020959]
	Learning Rate: 0.00209589
	LOSS [training: 0.8161884911069363 | validation: 1.1349961161313715]
	TIME [epoch: 9.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_530.pth
	Model improved!!!
EPOCH 531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9551992118940389		[learning rate: 0.0020883]
	Learning Rate: 0.00208828
	LOSS [training: 0.9551992118940389 | validation: 1.148086850864207]
	TIME [epoch: 9.45 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8787130846100112		[learning rate: 0.0020807]
	Learning Rate: 0.00208071
	LOSS [training: 0.8787130846100112 | validation: 1.1346159464109846]
	TIME [epoch: 9.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_532.pth
	Model improved!!!
EPOCH 533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9055721384792077		[learning rate: 0.0020732]
	Learning Rate: 0.00207315
	LOSS [training: 0.9055721384792077 | validation: 1.064177684508151]
	TIME [epoch: 9.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_533.pth
	Model improved!!!
EPOCH 534/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0588239635312235		[learning rate: 0.0020656]
	Learning Rate: 0.00206563
	LOSS [training: 1.0588239635312235 | validation: 1.2052108786840032]
	TIME [epoch: 9.45 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8557099948739889		[learning rate: 0.0020581]
	Learning Rate: 0.00205813
	LOSS [training: 0.8557099948739889 | validation: 1.396552487851411]
	TIME [epoch: 9.45 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9454273514521903		[learning rate: 0.0020507]
	Learning Rate: 0.00205067
	LOSS [training: 0.9454273514521903 | validation: 1.1816293677186025]
	TIME [epoch: 9.45 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9814110795002167		[learning rate: 0.0020432]
	Learning Rate: 0.00204322
	LOSS [training: 0.9814110795002167 | validation: 1.1180796301485172]
	TIME [epoch: 9.46 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.845523329368147		[learning rate: 0.0020358]
	Learning Rate: 0.00203581
	LOSS [training: 0.845523329368147 | validation: 1.0759126200430962]
	TIME [epoch: 9.45 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8763944506004675		[learning rate: 0.0020284]
	Learning Rate: 0.00202842
	LOSS [training: 0.8763944506004675 | validation: 1.2530279509989806]
	TIME [epoch: 9.45 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9241843154130656		[learning rate: 0.0020211]
	Learning Rate: 0.00202106
	LOSS [training: 0.9241843154130656 | validation: 1.1411347884174579]
	TIME [epoch: 9.46 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9472612940082138		[learning rate: 0.0020137]
	Learning Rate: 0.00201372
	LOSS [training: 0.9472612940082138 | validation: 1.1954867399010054]
	TIME [epoch: 9.44 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8188690087676294		[learning rate: 0.0020064]
	Learning Rate: 0.00200642
	LOSS [training: 0.8188690087676294 | validation: 1.1750616378279835]
	TIME [epoch: 9.44 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8176002132450062		[learning rate: 0.0019991]
	Learning Rate: 0.00199913
	LOSS [training: 0.8176002132450062 | validation: 1.1238451582878208]
	TIME [epoch: 9.44 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8734809862048113		[learning rate: 0.0019919]
	Learning Rate: 0.00199188
	LOSS [training: 0.8734809862048113 | validation: 1.0135009913478759]
	TIME [epoch: 9.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_544.pth
	Model improved!!!
EPOCH 545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7993983456204297		[learning rate: 0.0019847]
	Learning Rate: 0.00198465
	LOSS [training: 0.7993983456204297 | validation: 1.2723960016655258]
	TIME [epoch: 9.45 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9735519000151116		[learning rate: 0.0019774]
	Learning Rate: 0.00197745
	LOSS [training: 0.9735519000151116 | validation: 1.0799159058515693]
	TIME [epoch: 9.45 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8772456801445317		[learning rate: 0.0019703]
	Learning Rate: 0.00197027
	LOSS [training: 0.8772456801445317 | validation: 1.2474093980604704]
	TIME [epoch: 9.44 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7889110870509842		[learning rate: 0.0019631]
	Learning Rate: 0.00196312
	LOSS [training: 0.7889110870509842 | validation: 1.1356533332957672]
	TIME [epoch: 9.47 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8604871711380282		[learning rate: 0.001956]
	Learning Rate: 0.001956
	LOSS [training: 0.8604871711380282 | validation: 1.08499179591349]
	TIME [epoch: 9.45 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7788792468682568		[learning rate: 0.0019489]
	Learning Rate: 0.0019489
	LOSS [training: 0.7788792468682568 | validation: 1.4376058757112042]
	TIME [epoch: 9.44 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.011414345378363		[learning rate: 0.0019418]
	Learning Rate: 0.00194183
	LOSS [training: 1.011414345378363 | validation: 1.1638158552622104]
	TIME [epoch: 9.45 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8783516769747985		[learning rate: 0.0019348]
	Learning Rate: 0.00193478
	LOSS [training: 0.8783516769747985 | validation: 1.0824383192922002]
	TIME [epoch: 9.47 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8364287771977313		[learning rate: 0.0019278]
	Learning Rate: 0.00192776
	LOSS [training: 0.8364287771977313 | validation: 1.068778389067833]
	TIME [epoch: 9.45 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8044987051073772		[learning rate: 0.0019208]
	Learning Rate: 0.00192076
	LOSS [training: 0.8044987051073772 | validation: 1.1946750077680977]
	TIME [epoch: 9.45 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9033055871988536		[learning rate: 0.0019138]
	Learning Rate: 0.00191379
	LOSS [training: 0.9033055871988536 | validation: 1.1934007905896449]
	TIME [epoch: 9.45 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8789553274083005		[learning rate: 0.0019068]
	Learning Rate: 0.00190685
	LOSS [training: 0.8789553274083005 | validation: 1.0909090166428346]
	TIME [epoch: 9.46 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7683723382817665		[learning rate: 0.0018999]
	Learning Rate: 0.00189993
	LOSS [training: 0.7683723382817665 | validation: 1.25667715938407]
	TIME [epoch: 9.44 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9295884679090521		[learning rate: 0.001893]
	Learning Rate: 0.00189303
	LOSS [training: 0.9295884679090521 | validation: 0.9920834673654304]
	TIME [epoch: 9.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_558.pth
	Model improved!!!
EPOCH 559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7445110691414893		[learning rate: 0.0018862]
	Learning Rate: 0.00188616
	LOSS [training: 0.7445110691414893 | validation: 1.1214368583569472]
	TIME [epoch: 9.46 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7903201948484933		[learning rate: 0.0018793]
	Learning Rate: 0.00187932
	LOSS [training: 0.7903201948484933 | validation: 0.9761844765140789]
	TIME [epoch: 9.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_560.pth
	Model improved!!!
EPOCH 561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9398311888514052		[learning rate: 0.0018725]
	Learning Rate: 0.0018725
	LOSS [training: 0.9398311888514052 | validation: 1.0681111640899656]
	TIME [epoch: 9.44 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.983938404829745		[learning rate: 0.0018657]
	Learning Rate: 0.0018657
	LOSS [training: 0.983938404829745 | validation: 1.1832947498082296]
	TIME [epoch: 9.44 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8590217166487883		[learning rate: 0.0018589]
	Learning Rate: 0.00185893
	LOSS [training: 0.8590217166487883 | validation: 1.0751078337093782]
	TIME [epoch: 9.46 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7894211576163507		[learning rate: 0.0018522]
	Learning Rate: 0.00185218
	LOSS [training: 0.7894211576163507 | validation: 1.0390297017238834]
	TIME [epoch: 9.45 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8252085124345128		[learning rate: 0.0018455]
	Learning Rate: 0.00184546
	LOSS [training: 0.8252085124345128 | validation: 1.1714632181275153]
	TIME [epoch: 9.44 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8260520208192561		[learning rate: 0.0018388]
	Learning Rate: 0.00183877
	LOSS [training: 0.8260520208192561 | validation: 1.0795891185864794]
	TIME [epoch: 9.44 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8260322790059424		[learning rate: 0.0018321]
	Learning Rate: 0.00183209
	LOSS [training: 0.8260322790059424 | validation: 1.0861381622837196]
	TIME [epoch: 9.46 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7950910761889071		[learning rate: 0.0018254]
	Learning Rate: 0.00182544
	LOSS [training: 0.7950910761889071 | validation: 1.0067939748506083]
	TIME [epoch: 9.44 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9380039925576377		[learning rate: 0.0018188]
	Learning Rate: 0.00181882
	LOSS [training: 0.9380039925576377 | validation: 1.3184341166365072]
	TIME [epoch: 9.44 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8422275622464168		[learning rate: 0.0018122]
	Learning Rate: 0.00181222
	LOSS [training: 0.8422275622464168 | validation: 0.997064448782958]
	TIME [epoch: 9.44 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7395940667093838		[learning rate: 0.0018056]
	Learning Rate: 0.00180564
	LOSS [training: 0.7395940667093838 | validation: 0.991801889778688]
	TIME [epoch: 9.46 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7669276740788747		[learning rate: 0.0017991]
	Learning Rate: 0.00179909
	LOSS [training: 0.7669276740788747 | validation: 1.0492339553461754]
	TIME [epoch: 9.44 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8429470020341666		[learning rate: 0.0017926]
	Learning Rate: 0.00179256
	LOSS [training: 0.8429470020341666 | validation: 1.01437600691356]
	TIME [epoch: 9.44 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.790302113886875		[learning rate: 0.0017861]
	Learning Rate: 0.00178605
	LOSS [training: 0.790302113886875 | validation: 1.0749191118848203]
	TIME [epoch: 9.45 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7512380857913035		[learning rate: 0.0017796]
	Learning Rate: 0.00177957
	LOSS [training: 0.7512380857913035 | validation: 1.067304428565937]
	TIME [epoch: 9.46 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8118559882411394		[learning rate: 0.0017731]
	Learning Rate: 0.00177311
	LOSS [training: 0.8118559882411394 | validation: 1.0563513864314011]
	TIME [epoch: 9.44 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8393234747503417		[learning rate: 0.0017667]
	Learning Rate: 0.00176668
	LOSS [training: 0.8393234747503417 | validation: 1.0913811885373623]
	TIME [epoch: 9.44 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7758005089796507		[learning rate: 0.0017603]
	Learning Rate: 0.00176027
	LOSS [training: 0.7758005089796507 | validation: 1.0720402818964756]
	TIME [epoch: 9.46 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8206974319169416		[learning rate: 0.0017539]
	Learning Rate: 0.00175388
	LOSS [training: 0.8206974319169416 | validation: 0.9742679524481321]
	TIME [epoch: 9.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_579.pth
	Model improved!!!
EPOCH 580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7697050303826939		[learning rate: 0.0017475]
	Learning Rate: 0.00174752
	LOSS [training: 0.7697050303826939 | validation: 0.9513121082713346]
	TIME [epoch: 9.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_580.pth
	Model improved!!!
EPOCH 581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.778651657718569		[learning rate: 0.0017412]
	Learning Rate: 0.00174117
	LOSS [training: 0.778651657718569 | validation: 1.1682208928442859]
	TIME [epoch: 9.44 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8502692030223866		[learning rate: 0.0017349]
	Learning Rate: 0.00173486
	LOSS [training: 0.8502692030223866 | validation: 1.2963419591003855]
	TIME [epoch: 9.46 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.845262508162741		[learning rate: 0.0017286]
	Learning Rate: 0.00172856
	LOSS [training: 0.845262508162741 | validation: 1.0755744493405006]
	TIME [epoch: 9.44 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7951457635597236		[learning rate: 0.0017223]
	Learning Rate: 0.00172229
	LOSS [training: 0.7951457635597236 | validation: 0.9378288560950284]
	TIME [epoch: 9.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_584.pth
	Model improved!!!
EPOCH 585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7678039913130589		[learning rate: 0.001716]
	Learning Rate: 0.00171604
	LOSS [training: 0.7678039913130589 | validation: 1.0260817144958048]
	TIME [epoch: 9.44 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7404252515130044		[learning rate: 0.0017098]
	Learning Rate: 0.00170981
	LOSS [training: 0.7404252515130044 | validation: 0.9929163933488796]
	TIME [epoch: 9.46 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7457609940980435		[learning rate: 0.0017036]
	Learning Rate: 0.0017036
	LOSS [training: 0.7457609940980435 | validation: 1.0527397205896565]
	TIME [epoch: 9.44 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8183864655896812		[learning rate: 0.0016974]
	Learning Rate: 0.00169742
	LOSS [training: 0.8183864655896812 | validation: 1.1570452299038791]
	TIME [epoch: 9.44 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7934614972234437		[learning rate: 0.0016913]
	Learning Rate: 0.00169126
	LOSS [training: 0.7934614972234437 | validation: 1.1013613474992587]
	TIME [epoch: 9.44 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7765801685208905		[learning rate: 0.0016851]
	Learning Rate: 0.00168512
	LOSS [training: 0.7765801685208905 | validation: 0.9925449704890953]
	TIME [epoch: 9.46 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7475912641366722		[learning rate: 0.001679]
	Learning Rate: 0.00167901
	LOSS [training: 0.7475912641366722 | validation: 1.0182331340995092]
	TIME [epoch: 9.44 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8334491992723215		[learning rate: 0.0016729]
	Learning Rate: 0.00167291
	LOSS [training: 0.8334491992723215 | validation: 0.9664387844394036]
	TIME [epoch: 9.43 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7608569704018017		[learning rate: 0.0016668]
	Learning Rate: 0.00166684
	LOSS [training: 0.7608569704018017 | validation: 1.0127233715508472]
	TIME [epoch: 9.44 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.775501373152205		[learning rate: 0.0016608]
	Learning Rate: 0.00166079
	LOSS [training: 0.775501373152205 | validation: 0.9815954518155746]
	TIME [epoch: 9.45 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7729334208432357		[learning rate: 0.0016548]
	Learning Rate: 0.00165477
	LOSS [training: 0.7729334208432357 | validation: 1.0054764492914232]
	TIME [epoch: 9.43 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8203921385807702		[learning rate: 0.0016488]
	Learning Rate: 0.00164876
	LOSS [training: 0.8203921385807702 | validation: 1.328770729773522]
	TIME [epoch: 9.43 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8763442269928792		[learning rate: 0.0016428]
	Learning Rate: 0.00164278
	LOSS [training: 0.8763442269928792 | validation: 1.0427521579028252]
	TIME [epoch: 9.45 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7449718598611167		[learning rate: 0.0016368]
	Learning Rate: 0.00163682
	LOSS [training: 0.7449718598611167 | validation: 0.9276495973049569]
	TIME [epoch: 9.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_598.pth
	Model improved!!!
EPOCH 599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7467355857634981		[learning rate: 0.0016309]
	Learning Rate: 0.00163088
	LOSS [training: 0.7467355857634981 | validation: 0.917309370345235]
	TIME [epoch: 9.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_599.pth
	Model improved!!!
EPOCH 600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7732677272596791		[learning rate: 0.001625]
	Learning Rate: 0.00162496
	LOSS [training: 0.7732677272596791 | validation: 0.991750982470079]
	TIME [epoch: 9.44 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7847767617177426		[learning rate: 0.0016191]
	Learning Rate: 0.00161906
	LOSS [training: 0.7847767617177426 | validation: 0.9250313788368498]
	TIME [epoch: 9.46 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.771052852641761		[learning rate: 0.0016132]
	Learning Rate: 0.00161319
	LOSS [training: 0.771052852641761 | validation: 0.9332005316407379]
	TIME [epoch: 9.45 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7930446063116028		[learning rate: 0.0016073]
	Learning Rate: 0.00160733
	LOSS [training: 0.7930446063116028 | validation: 1.0041476360935804]
	TIME [epoch: 9.44 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.87964363144531		[learning rate: 0.0016015]
	Learning Rate: 0.0016015
	LOSS [training: 0.87964363144531 | validation: 0.9828949674656547]
	TIME [epoch: 9.44 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8303702662165919		[learning rate: 0.0015957]
	Learning Rate: 0.00159569
	LOSS [training: 0.8303702662165919 | validation: 0.956371660912358]
	TIME [epoch: 9.46 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7409866836001112		[learning rate: 0.0015899]
	Learning Rate: 0.00158989
	LOSS [training: 0.7409866836001112 | validation: 1.276779248113007]
	TIME [epoch: 9.44 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8236891156851115		[learning rate: 0.0015841]
	Learning Rate: 0.00158413
	LOSS [training: 0.8236891156851115 | validation: 1.0604295091756701]
	TIME [epoch: 9.44 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7414255412888889		[learning rate: 0.0015784]
	Learning Rate: 0.00157838
	LOSS [training: 0.7414255412888889 | validation: 0.9319250610043482]
	TIME [epoch: 9.44 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7541028350617024		[learning rate: 0.0015726]
	Learning Rate: 0.00157265
	LOSS [training: 0.7541028350617024 | validation: 0.9360530172137602]
	TIME [epoch: 9.46 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7317951661252942		[learning rate: 0.0015669]
	Learning Rate: 0.00156694
	LOSS [training: 0.7317951661252942 | validation: 0.927456890979671]
	TIME [epoch: 9.44 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6856467946122169		[learning rate: 0.0015613]
	Learning Rate: 0.00156125
	LOSS [training: 0.6856467946122169 | validation: 0.9848543018687945]
	TIME [epoch: 9.44 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7790494809555053		[learning rate: 0.0015556]
	Learning Rate: 0.00155559
	LOSS [training: 0.7790494809555053 | validation: 1.1360623174631004]
	TIME [epoch: 9.44 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7403646651298028		[learning rate: 0.0015499]
	Learning Rate: 0.00154994
	LOSS [training: 0.7403646651298028 | validation: 0.9501149973358491]
	TIME [epoch: 9.45 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7645712248506713		[learning rate: 0.0015443]
	Learning Rate: 0.00154432
	LOSS [training: 0.7645712248506713 | validation: 0.9398827385499459]
	TIME [epoch: 9.45 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9017533141211305		[learning rate: 0.0015387]
	Learning Rate: 0.00153871
	LOSS [training: 0.9017533141211305 | validation: 0.9140817645533295]
	TIME [epoch: 9.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_615.pth
	Model improved!!!
EPOCH 616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7331171328417021		[learning rate: 0.0015331]
	Learning Rate: 0.00153313
	LOSS [training: 0.7331171328417021 | validation: 1.105896511366374]
	TIME [epoch: 9.46 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7042420523790908		[learning rate: 0.0015276]
	Learning Rate: 0.00152757
	LOSS [training: 0.7042420523790908 | validation: 1.0431197934596192]
	TIME [epoch: 9.44 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8497840936477973		[learning rate: 0.001522]
	Learning Rate: 0.00152202
	LOSS [training: 0.8497840936477973 | validation: 0.873582664400436]
	TIME [epoch: 9.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_618.pth
	Model improved!!!
EPOCH 619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.698904859194247		[learning rate: 0.0015165]
	Learning Rate: 0.0015165
	LOSS [training: 0.698904859194247 | validation: 0.8978556556609408]
	TIME [epoch: 9.45 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7019166917099403		[learning rate: 0.001511]
	Learning Rate: 0.001511
	LOSS [training: 0.7019166917099403 | validation: 0.9009459773809428]
	TIME [epoch: 9.46 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7936345944301455		[learning rate: 0.0015055]
	Learning Rate: 0.00150551
	LOSS [training: 0.7936345944301455 | validation: 1.0116253556210757]
	TIME [epoch: 9.44 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.752380809366497		[learning rate: 0.0015]
	Learning Rate: 0.00150005
	LOSS [training: 0.752380809366497 | validation: 0.925220987950854]
	TIME [epoch: 9.43 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7502639640237045		[learning rate: 0.0014946]
	Learning Rate: 0.0014946
	LOSS [training: 0.7502639640237045 | validation: 0.9479549909610354]
	TIME [epoch: 9.44 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7490586080261495		[learning rate: 0.0014892]
	Learning Rate: 0.00148918
	LOSS [training: 0.7490586080261495 | validation: 1.001994881812825]
	TIME [epoch: 9.46 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7318969401166515		[learning rate: 0.0014838]
	Learning Rate: 0.00148378
	LOSS [training: 0.7318969401166515 | validation: 0.9384613892530255]
	TIME [epoch: 9.44 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7873674576170385		[learning rate: 0.0014784]
	Learning Rate: 0.00147839
	LOSS [training: 0.7873674576170385 | validation: 0.9579323042526177]
	TIME [epoch: 9.44 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7274652361941897		[learning rate: 0.001473]
	Learning Rate: 0.00147303
	LOSS [training: 0.7274652361941897 | validation: 0.9013102810620859]
	TIME [epoch: 9.44 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7423440052534781		[learning rate: 0.0014677]
	Learning Rate: 0.00146768
	LOSS [training: 0.7423440052534781 | validation: 1.0137788801407512]
	TIME [epoch: 9.46 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7553135113910994		[learning rate: 0.0014624]
	Learning Rate: 0.00146235
	LOSS [training: 0.7553135113910994 | validation: 1.2002982924488423]
	TIME [epoch: 9.44 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8042108217521108		[learning rate: 0.001457]
	Learning Rate: 0.00145705
	LOSS [training: 0.8042108217521108 | validation: 0.9570035498113977]
	TIME [epoch: 9.43 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.697029603800037		[learning rate: 0.0014518]
	Learning Rate: 0.00145176
	LOSS [training: 0.697029603800037 | validation: 0.9358433886682157]
	TIME [epoch: 9.44 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7084726581492085		[learning rate: 0.0014465]
	Learning Rate: 0.00144649
	LOSS [training: 0.7084726581492085 | validation: 1.010892974133042]
	TIME [epoch: 9.78 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7248772682537755		[learning rate: 0.0014412]
	Learning Rate: 0.00144124
	LOSS [training: 0.7248772682537755 | validation: 0.9022318847842261]
	TIME [epoch: 9.45 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6867265188906108		[learning rate: 0.001436]
	Learning Rate: 0.00143601
	LOSS [training: 0.6867265188906108 | validation: 0.9284832832047529]
	TIME [epoch: 9.44 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7398790610044793		[learning rate: 0.0014308]
	Learning Rate: 0.0014308
	LOSS [training: 0.7398790610044793 | validation: 1.017624113676534]
	TIME [epoch: 9.46 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7236485351573692		[learning rate: 0.0014256]
	Learning Rate: 0.00142561
	LOSS [training: 0.7236485351573692 | validation: 0.9354712491367835]
	TIME [epoch: 9.46 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6865440377378516		[learning rate: 0.0014204]
	Learning Rate: 0.00142043
	LOSS [training: 0.6865440377378516 | validation: 1.121547043752983]
	TIME [epoch: 9.45 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.759455146553953		[learning rate: 0.0014153]
	Learning Rate: 0.00141528
	LOSS [training: 0.759455146553953 | validation: 0.8954760243863663]
	TIME [epoch: 9.45 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7015687865365594		[learning rate: 0.0014101]
	Learning Rate: 0.00141014
	LOSS [training: 0.7015687865365594 | validation: 1.0191698791093764]
	TIME [epoch: 9.47 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6994616063323859		[learning rate: 0.001405]
	Learning Rate: 0.00140503
	LOSS [training: 0.6994616063323859 | validation: 1.0243731295816318]
	TIME [epoch: 9.45 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7202164053534946		[learning rate: 0.0013999]
	Learning Rate: 0.00139993
	LOSS [training: 0.7202164053534946 | validation: 0.8681392586372944]
	TIME [epoch: 9.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_641.pth
	Model improved!!!
EPOCH 642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6698878578948945		[learning rate: 0.0013948]
	Learning Rate: 0.00139485
	LOSS [training: 0.6698878578948945 | validation: 0.8999386400731968]
	TIME [epoch: 9.45 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.716483960220067		[learning rate: 0.0013898]
	Learning Rate: 0.00138978
	LOSS [training: 0.716483960220067 | validation: 1.0376844240092833]
	TIME [epoch: 9.47 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6943742697458044		[learning rate: 0.0013847]
	Learning Rate: 0.00138474
	LOSS [training: 0.6943742697458044 | validation: 0.8776495527539823]
	TIME [epoch: 9.44 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6747497549129637		[learning rate: 0.0013797]
	Learning Rate: 0.00137972
	LOSS [training: 0.6747497549129637 | validation: 0.9019357886927187]
	TIME [epoch: 9.44 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6707190592549134		[learning rate: 0.0013747]
	Learning Rate: 0.00137471
	LOSS [training: 0.6707190592549134 | validation: 0.8053034892406615]
	TIME [epoch: 9.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_646.pth
	Model improved!!!
EPOCH 647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7663332487415768		[learning rate: 0.0013697]
	Learning Rate: 0.00136972
	LOSS [training: 0.7663332487415768 | validation: 0.924174707668623]
	TIME [epoch: 9.46 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6457244284034653		[learning rate: 0.0013647]
	Learning Rate: 0.00136475
	LOSS [training: 0.6457244284034653 | validation: 0.8913393189956921]
	TIME [epoch: 9.44 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6818232419012784		[learning rate: 0.0013598]
	Learning Rate: 0.0013598
	LOSS [training: 0.6818232419012784 | validation: 0.9333239586156755]
	TIME [epoch: 9.44 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7002613779076148		[learning rate: 0.0013549]
	Learning Rate: 0.00135486
	LOSS [training: 0.7002613779076148 | validation: 0.857254652492251]
	TIME [epoch: 9.45 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6583945774478039		[learning rate: 0.0013499]
	Learning Rate: 0.00134994
	LOSS [training: 0.6583945774478039 | validation: 0.9516934724428208]
	TIME [epoch: 9.46 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6613592883959866		[learning rate: 0.001345]
	Learning Rate: 0.00134505
	LOSS [training: 0.6613592883959866 | validation: 0.8632896957940145]
	TIME [epoch: 9.45 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.70700571714654		[learning rate: 0.0013402]
	Learning Rate: 0.00134016
	LOSS [training: 0.70700571714654 | validation: 0.7977701873654759]
	TIME [epoch: 9.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_653.pth
	Model improved!!!
EPOCH 654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6595829181053954		[learning rate: 0.0013353]
	Learning Rate: 0.0013353
	LOSS [training: 0.6595829181053954 | validation: 0.876331763574852]
	TIME [epoch: 9.46 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6615309573685322		[learning rate: 0.0013305]
	Learning Rate: 0.00133045
	LOSS [training: 0.6615309573685322 | validation: 0.8872872288156328]
	TIME [epoch: 9.45 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7043721069372347		[learning rate: 0.0013256]
	Learning Rate: 0.00132563
	LOSS [training: 0.7043721069372347 | validation: 0.8575273188727188]
	TIME [epoch: 9.44 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0119846137303292		[learning rate: 0.0013208]
	Learning Rate: 0.00132082
	LOSS [training: 1.0119846137303292 | validation: 1.0342304428045344]
	TIME [epoch: 9.44 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9545482445031628		[learning rate: 0.001316]
	Learning Rate: 0.00131602
	LOSS [training: 0.9545482445031628 | validation: 0.8730413450458043]
	TIME [epoch: 9.47 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6806194559269253		[learning rate: 0.0013112]
	Learning Rate: 0.00131125
	LOSS [training: 0.6806194559269253 | validation: 0.8777025016407354]
	TIME [epoch: 9.45 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6459336888718014		[learning rate: 0.0013065]
	Learning Rate: 0.00130649
	LOSS [training: 0.6459336888718014 | validation: 0.8727890909102256]
	TIME [epoch: 9.44 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6015161009413602		[learning rate: 0.0013017]
	Learning Rate: 0.00130175
	LOSS [training: 0.6015161009413602 | validation: 0.8755846464796139]
	TIME [epoch: 9.45 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6811782415417384		[learning rate: 0.001297]
	Learning Rate: 0.00129702
	LOSS [training: 0.6811782415417384 | validation: 0.8652082087664212]
	TIME [epoch: 9.46 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6943108724781204		[learning rate: 0.0012923]
	Learning Rate: 0.00129232
	LOSS [training: 0.6943108724781204 | validation: 0.8753883275847342]
	TIME [epoch: 9.44 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6412694488031145		[learning rate: 0.0012876]
	Learning Rate: 0.00128763
	LOSS [training: 0.6412694488031145 | validation: 0.8446064422143275]
	TIME [epoch: 9.45 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6481687703013994		[learning rate: 0.001283]
	Learning Rate: 0.00128295
	LOSS [training: 0.6481687703013994 | validation: 0.8442061153296235]
	TIME [epoch: 9.44 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6332767127894618		[learning rate: 0.0012783]
	Learning Rate: 0.0012783
	LOSS [training: 0.6332767127894618 | validation: 0.9161412802720611]
	TIME [epoch: 9.47 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7210615625378788		[learning rate: 0.0012737]
	Learning Rate: 0.00127366
	LOSS [training: 0.7210615625378788 | validation: 1.1153639637018404]
	TIME [epoch: 9.45 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8286745056365451		[learning rate: 0.001269]
	Learning Rate: 0.00126904
	LOSS [training: 0.8286745056365451 | validation: 0.9827261318020092]
	TIME [epoch: 9.44 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.74133895852428		[learning rate: 0.0012644]
	Learning Rate: 0.00126443
	LOSS [training: 0.74133895852428 | validation: 0.8937078551497553]
	TIME [epoch: 9.45 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6846856060707274		[learning rate: 0.0012598]
	Learning Rate: 0.00125984
	LOSS [training: 0.6846856060707274 | validation: 0.830995996184013]
	TIME [epoch: 9.46 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6536698448580458		[learning rate: 0.0012553]
	Learning Rate: 0.00125527
	LOSS [training: 0.6536698448580458 | validation: 0.777424536241594]
	TIME [epoch: 9.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_671.pth
	Model improved!!!
EPOCH 672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6495116889936672		[learning rate: 0.0012507]
	Learning Rate: 0.00125071
	LOSS [training: 0.6495116889936672 | validation: 0.7882693434323188]
	TIME [epoch: 9.44 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6268136522299987		[learning rate: 0.0012462]
	Learning Rate: 0.00124617
	LOSS [training: 0.6268136522299987 | validation: 0.7824669468925132]
	TIME [epoch: 9.45 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6263242221612988		[learning rate: 0.0012417]
	Learning Rate: 0.00124165
	LOSS [training: 0.6263242221612988 | validation: 0.8363702954886401]
	TIME [epoch: 9.44 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6748303559105427		[learning rate: 0.0012371]
	Learning Rate: 0.00123715
	LOSS [training: 0.6748303559105427 | validation: 0.9173563520073998]
	TIME [epoch: 9.44 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6316292596219693		[learning rate: 0.0012327]
	Learning Rate: 0.00123266
	LOSS [training: 0.6316292596219693 | validation: 0.8453060314129789]
	TIME [epoch: 9.43 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6338830006323891		[learning rate: 0.0012282]
	Learning Rate: 0.00122818
	LOSS [training: 0.6338830006323891 | validation: 0.8946601387746006]
	TIME [epoch: 9.46 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6950635523576796		[learning rate: 0.0012237]
	Learning Rate: 0.00122373
	LOSS [training: 0.6950635523576796 | validation: 0.9635005137409173]
	TIME [epoch: 9.44 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6674589938858653		[learning rate: 0.0012193]
	Learning Rate: 0.00121929
	LOSS [training: 0.6674589938858653 | validation: 0.8584781170358214]
	TIME [epoch: 9.44 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6639268931135728		[learning rate: 0.0012149]
	Learning Rate: 0.00121486
	LOSS [training: 0.6639268931135728 | validation: 0.8760008525505457]
	TIME [epoch: 9.44 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6727211123328143		[learning rate: 0.0012105]
	Learning Rate: 0.00121045
	LOSS [training: 0.6727211123328143 | validation: 0.8524660963697998]
	TIME [epoch: 9.46 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7920239759817577		[learning rate: 0.0012061]
	Learning Rate: 0.00120606
	LOSS [training: 0.7920239759817577 | validation: 0.9374759468209303]
	TIME [epoch: 9.44 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6647284834279212		[learning rate: 0.0012017]
	Learning Rate: 0.00120168
	LOSS [training: 0.6647284834279212 | validation: 0.7147183953817614]
	TIME [epoch: 9.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_683.pth
	Model improved!!!
EPOCH 684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6025076576171304		[learning rate: 0.0011973]
	Learning Rate: 0.00119732
	LOSS [training: 0.6025076576171304 | validation: 0.9391034746457446]
	TIME [epoch: 9.44 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.625178059436924		[learning rate: 0.001193]
	Learning Rate: 0.00119298
	LOSS [training: 0.625178059436924 | validation: 0.8404988156724591]
	TIME [epoch: 9.46 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6277925801942088		[learning rate: 0.0011886]
	Learning Rate: 0.00118865
	LOSS [training: 0.6277925801942088 | validation: 0.7691879692493845]
	TIME [epoch: 9.44 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6123479143860335		[learning rate: 0.0011843]
	Learning Rate: 0.00118433
	LOSS [training: 0.6123479143860335 | validation: 0.8139053324397783]
	TIME [epoch: 9.44 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.755920713001778		[learning rate: 0.00118]
	Learning Rate: 0.00118003
	LOSS [training: 0.755920713001778 | validation: 0.8397765199043863]
	TIME [epoch: 9.44 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6063143345305659		[learning rate: 0.0011758]
	Learning Rate: 0.00117575
	LOSS [training: 0.6063143345305659 | validation: 0.9247796523103038]
	TIME [epoch: 9.45 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6716843211601704		[learning rate: 0.0011715]
	Learning Rate: 0.00117149
	LOSS [training: 0.6716843211601704 | validation: 0.8449913204166188]
	TIME [epoch: 9.43 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6236730872303144		[learning rate: 0.0011672]
	Learning Rate: 0.00116723
	LOSS [training: 0.6236730872303144 | validation: 0.8159113323887707]
	TIME [epoch: 9.44 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7188254976730097		[learning rate: 0.001163]
	Learning Rate: 0.001163
	LOSS [training: 0.7188254976730097 | validation: 0.8332494848809642]
	TIME [epoch: 9.45 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6480155213233909		[learning rate: 0.0011588]
	Learning Rate: 0.00115878
	LOSS [training: 0.6480155213233909 | validation: 0.9072974136565998]
	TIME [epoch: 9.44 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6065159505319042		[learning rate: 0.0011546]
	Learning Rate: 0.00115457
	LOSS [training: 0.6065159505319042 | validation: 0.7376444478327571]
	TIME [epoch: 9.44 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6024211741188366		[learning rate: 0.0011504]
	Learning Rate: 0.00115038
	LOSS [training: 0.6024211741188366 | validation: 0.7692974935577992]
	TIME [epoch: 9.43 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6310062065353503		[learning rate: 0.0011462]
	Learning Rate: 0.00114621
	LOSS [training: 0.6310062065353503 | validation: 0.7615583257199015]
	TIME [epoch: 9.46 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5995399240902638		[learning rate: 0.001142]
	Learning Rate: 0.00114205
	LOSS [training: 0.5995399240902638 | validation: 0.8104612468461946]
	TIME [epoch: 9.44 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6439147434506971		[learning rate: 0.0011379]
	Learning Rate: 0.0011379
	LOSS [training: 0.6439147434506971 | validation: 0.8935702911925719]
	TIME [epoch: 9.43 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6372090534844694		[learning rate: 0.0011338]
	Learning Rate: 0.00113377
	LOSS [training: 0.6372090534844694 | validation: 0.7684629716166089]
	TIME [epoch: 9.44 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6117015730641959		[learning rate: 0.0011297]
	Learning Rate: 0.00112966
	LOSS [training: 0.6117015730641959 | validation: 0.7400816307799396]
	TIME [epoch: 9.46 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5950882165684447		[learning rate: 0.0011256]
	Learning Rate: 0.00112556
	LOSS [training: 0.5950882165684447 | validation: 0.7725711473175397]
	TIME [epoch: 9.44 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.586806473012812		[learning rate: 0.0011215]
	Learning Rate: 0.00112147
	LOSS [training: 0.586806473012812 | validation: 0.7477715328291444]
	TIME [epoch: 9.44 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6555766817215548		[learning rate: 0.0011174]
	Learning Rate: 0.0011174
	LOSS [training: 0.6555766817215548 | validation: 0.7515037224845788]
	TIME [epoch: 9.44 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5958423146716756		[learning rate: 0.0011133]
	Learning Rate: 0.00111335
	LOSS [training: 0.5958423146716756 | validation: 0.8002546419317358]
	TIME [epoch: 9.46 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6559333533051133		[learning rate: 0.0011093]
	Learning Rate: 0.00110931
	LOSS [training: 0.6559333533051133 | validation: 0.8235346962296699]
	TIME [epoch: 9.43 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.648403157784798		[learning rate: 0.0011053]
	Learning Rate: 0.00110528
	LOSS [training: 0.648403157784798 | validation: 0.8559561691879595]
	TIME [epoch: 9.44 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6584945954856204		[learning rate: 0.0011013]
	Learning Rate: 0.00110127
	LOSS [training: 0.6584945954856204 | validation: 0.7485866789819955]
	TIME [epoch: 9.43 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5963070860314192		[learning rate: 0.0010973]
	Learning Rate: 0.00109728
	LOSS [training: 0.5963070860314192 | validation: 0.7476594078509939]
	TIME [epoch: 9.45 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6413120568786334		[learning rate: 0.0010933]
	Learning Rate: 0.00109329
	LOSS [training: 0.6413120568786334 | validation: 0.9040338073332046]
	TIME [epoch: 9.43 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6197390077540466		[learning rate: 0.0010893]
	Learning Rate: 0.00108933
	LOSS [training: 0.6197390077540466 | validation: 0.8366864777892761]
	TIME [epoch: 9.43 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5924583950243256		[learning rate: 0.0010854]
	Learning Rate: 0.00108537
	LOSS [training: 0.5924583950243256 | validation: 0.8538127861338208]
	TIME [epoch: 9.44 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6133625629475745		[learning rate: 0.0010814]
	Learning Rate: 0.00108143
	LOSS [training: 0.6133625629475745 | validation: 0.7128508138267364]
	TIME [epoch: 9.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_712.pth
	Model improved!!!
EPOCH 713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5746247262741749		[learning rate: 0.0010775]
	Learning Rate: 0.00107751
	LOSS [training: 0.5746247262741749 | validation: 0.8035701857456479]
	TIME [epoch: 9.43 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6411117119462059		[learning rate: 0.0010736]
	Learning Rate: 0.0010736
	LOSS [training: 0.6411117119462059 | validation: 0.6851362304284018]
	TIME [epoch: 9.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_714.pth
	Model improved!!!
EPOCH 715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6376778049471706		[learning rate: 0.0010697]
	Learning Rate: 0.0010697
	LOSS [training: 0.6376778049471706 | validation: 0.7115257544057468]
	TIME [epoch: 9.46 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6412180914472705		[learning rate: 0.0010658]
	Learning Rate: 0.00106582
	LOSS [training: 0.6412180914472705 | validation: 0.7360025726085029]
	TIME [epoch: 9.44 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6215930511286052		[learning rate: 0.001062]
	Learning Rate: 0.00106195
	LOSS [training: 0.6215930511286052 | validation: 0.751949175745842]
	TIME [epoch: 9.44 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6253908689423162		[learning rate: 0.0010581]
	Learning Rate: 0.0010581
	LOSS [training: 0.6253908689423162 | validation: 0.7681600292257728]
	TIME [epoch: 9.44 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6482433593762241		[learning rate: 0.0010543]
	Learning Rate: 0.00105426
	LOSS [training: 0.6482433593762241 | validation: 0.6753794298480332]
	TIME [epoch: 9.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_719.pth
	Model improved!!!
EPOCH 720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5943101103969567		[learning rate: 0.0010504]
	Learning Rate: 0.00105043
	LOSS [training: 0.5943101103969567 | validation: 0.7774261843396859]
	TIME [epoch: 9.43 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5843280150269827		[learning rate: 0.0010466]
	Learning Rate: 0.00104662
	LOSS [training: 0.5843280150269827 | validation: 0.8277897886461503]
	TIME [epoch: 9.44 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5917863616535253		[learning rate: 0.0010428]
	Learning Rate: 0.00104282
	LOSS [training: 0.5917863616535253 | validation: 0.8670465114055252]
	TIME [epoch: 9.43 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6404170596328781		[learning rate: 0.001039]
	Learning Rate: 0.00103904
	LOSS [training: 0.6404170596328781 | validation: 0.8256337662406645]
	TIME [epoch: 9.45 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6096282631383719		[learning rate: 0.0010353]
	Learning Rate: 0.00103527
	LOSS [training: 0.6096282631383719 | validation: 0.6983054287458245]
	TIME [epoch: 9.43 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6195133722908174		[learning rate: 0.0010315]
	Learning Rate: 0.00103151
	LOSS [training: 0.6195133722908174 | validation: 0.800241359054036]
	TIME [epoch: 9.43 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.569304337142045		[learning rate: 0.0010278]
	Learning Rate: 0.00102777
	LOSS [training: 0.569304337142045 | validation: 0.7603203489143335]
	TIME [epoch: 9.43 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5975132979615969		[learning rate: 0.001024]
	Learning Rate: 0.00102404
	LOSS [training: 0.5975132979615969 | validation: 0.7397012074187539]
	TIME [epoch: 9.46 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5847439152648904		[learning rate: 0.0010203]
	Learning Rate: 0.00102032
	LOSS [training: 0.5847439152648904 | validation: 0.7244161073701255]
	TIME [epoch: 9.43 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5967242200021446		[learning rate: 0.0010166]
	Learning Rate: 0.00101662
	LOSS [training: 0.5967242200021446 | validation: 0.691777769434633]
	TIME [epoch: 9.43 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6172701921569266		[learning rate: 0.0010129]
	Learning Rate: 0.00101293
	LOSS [training: 0.6172701921569266 | validation: 0.7569437278378932]
	TIME [epoch: 9.44 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6349392726262664		[learning rate: 0.0010093]
	Learning Rate: 0.00100925
	LOSS [training: 0.6349392726262664 | validation: 0.6538575519739246]
	TIME [epoch: 9.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_731.pth
	Model improved!!!
EPOCH 732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5897476950137348		[learning rate: 0.0010056]
	Learning Rate: 0.00100559
	LOSS [training: 0.5897476950137348 | validation: 0.7384055919150887]
	TIME [epoch: 9.44 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6244732222519922		[learning rate: 0.0010019]
	Learning Rate: 0.00100194
	LOSS [training: 0.6244732222519922 | validation: 0.689684264783425]
	TIME [epoch: 9.44 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5675451395370847		[learning rate: 0.0009983]
	Learning Rate: 0.000998305
	LOSS [training: 0.5675451395370847 | validation: 0.6940885808785067]
	TIME [epoch: 9.46 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5814643263686257		[learning rate: 0.00099468]
	Learning Rate: 0.000994682
	LOSS [training: 0.5814643263686257 | validation: 0.780150365297248]
	TIME [epoch: 9.44 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6378609396251959		[learning rate: 0.00099107]
	Learning Rate: 0.000991072
	LOSS [training: 0.6378609396251959 | validation: 0.647242063492635]
	TIME [epoch: 9.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_736.pth
	Model improved!!!
EPOCH 737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5701960255197724		[learning rate: 0.00098748]
	Learning Rate: 0.000987475
	LOSS [training: 0.5701960255197724 | validation: 0.7768448441321385]
	TIME [epoch: 9.44 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5999644838247755		[learning rate: 0.00098389]
	Learning Rate: 0.000983892
	LOSS [training: 0.5999644838247755 | validation: 0.6939422540459278]
	TIME [epoch: 9.46 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.562754431322207		[learning rate: 0.00098032]
	Learning Rate: 0.000980321
	LOSS [training: 0.562754431322207 | validation: 0.7388582670020339]
	TIME [epoch: 9.44 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5765053377929742		[learning rate: 0.00097676]
	Learning Rate: 0.000976764
	LOSS [training: 0.5765053377929742 | validation: 0.6788545510839487]
	TIME [epoch: 9.44 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6279617039240062		[learning rate: 0.00097322]
	Learning Rate: 0.000973219
	LOSS [training: 0.6279617039240062 | validation: 0.707633512651436]
	TIME [epoch: 9.44 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.564528345903226		[learning rate: 0.00096969]
	Learning Rate: 0.000969687
	LOSS [training: 0.564528345903226 | validation: 0.6366373263268256]
	TIME [epoch: 9.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_742.pth
	Model improved!!!
EPOCH 743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5642803704429654		[learning rate: 0.00096617]
	Learning Rate: 0.000966168
	LOSS [training: 0.5642803704429654 | validation: 0.6622119271158678]
	TIME [epoch: 9.44 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.586780363944609		[learning rate: 0.00096266]
	Learning Rate: 0.000962662
	LOSS [training: 0.586780363944609 | validation: 0.7056836074909929]
	TIME [epoch: 9.43 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5500173220525962		[learning rate: 0.00095917]
	Learning Rate: 0.000959168
	LOSS [training: 0.5500173220525962 | validation: 0.6553917516506721]
	TIME [epoch: 9.44 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5563722023537673		[learning rate: 0.00095569]
	Learning Rate: 0.000955687
	LOSS [training: 0.5563722023537673 | validation: 0.6835911201565716]
	TIME [epoch: 9.46 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5960932405199592		[learning rate: 0.00095222]
	Learning Rate: 0.000952219
	LOSS [training: 0.5960932405199592 | validation: 0.6401853189489843]
	TIME [epoch: 9.44 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6123027865084497		[learning rate: 0.00094876]
	Learning Rate: 0.000948763
	LOSS [training: 0.6123027865084497 | validation: 0.6704509551979474]
	TIME [epoch: 9.44 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5779154855895		[learning rate: 0.00094532]
	Learning Rate: 0.00094532
	LOSS [training: 0.5779154855895 | validation: 0.7879294063593975]
	TIME [epoch: 9.44 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6148113923337153		[learning rate: 0.00094189]
	Learning Rate: 0.000941889
	LOSS [training: 0.6148113923337153 | validation: 0.6949694045229708]
	TIME [epoch: 9.45 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.582442234712033		[learning rate: 0.00093847]
	Learning Rate: 0.000938471
	LOSS [training: 0.582442234712033 | validation: 0.6988028717822194]
	TIME [epoch: 9.44 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5632844437170836		[learning rate: 0.00093507]
	Learning Rate: 0.000935066
	LOSS [training: 0.5632844437170836 | validation: 0.6498853602420505]
	TIME [epoch: 9.44 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5888058837420861		[learning rate: 0.00093167]
	Learning Rate: 0.000931672
	LOSS [training: 0.5888058837420861 | validation: 0.6417403810027846]
	TIME [epoch: 9.46 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5259777218470558		[learning rate: 0.00092829]
	Learning Rate: 0.000928291
	LOSS [training: 0.5259777218470558 | validation: 0.6205065990743988]
	TIME [epoch: 9.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_754.pth
	Model improved!!!
EPOCH 755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5807898176666181		[learning rate: 0.00092492]
	Learning Rate: 0.000924922
	LOSS [training: 0.5807898176666181 | validation: 0.7356353936966805]
	TIME [epoch: 9.44 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5756150580607186		[learning rate: 0.00092157]
	Learning Rate: 0.000921566
	LOSS [training: 0.5756150580607186 | validation: 0.7520503773722206]
	TIME [epoch: 9.44 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5664003271289861		[learning rate: 0.00091822]
	Learning Rate: 0.000918221
	LOSS [training: 0.5664003271289861 | validation: 0.6670019202851505]
	TIME [epoch: 9.46 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5385927821466794		[learning rate: 0.00091489]
	Learning Rate: 0.000914889
	LOSS [training: 0.5385927821466794 | validation: 0.5997374014255672]
	TIME [epoch: 9.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_758.pth
	Model improved!!!
EPOCH 759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5876855032563142		[learning rate: 0.00091157]
	Learning Rate: 0.000911569
	LOSS [training: 0.5876855032563142 | validation: 0.7399876549611885]
	TIME [epoch: 9.44 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5653248537565851		[learning rate: 0.00090826]
	Learning Rate: 0.000908261
	LOSS [training: 0.5653248537565851 | validation: 0.6437156946970722]
	TIME [epoch: 9.44 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.58247366380385		[learning rate: 0.00090496]
	Learning Rate: 0.000904965
	LOSS [training: 0.58247366380385 | validation: 0.7175904444642154]
	TIME [epoch: 9.46 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5919689337503213		[learning rate: 0.00090168]
	Learning Rate: 0.00090168
	LOSS [training: 0.5919689337503213 | validation: 0.6261747761297827]
	TIME [epoch: 9.44 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5575330032886876		[learning rate: 0.00089841]
	Learning Rate: 0.000898408
	LOSS [training: 0.5575330032886876 | validation: 0.6927656231260235]
	TIME [epoch: 9.44 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.605839536037178		[learning rate: 0.00089515]
	Learning Rate: 0.000895148
	LOSS [training: 0.605839536037178 | validation: 0.6652748302374331]
	TIME [epoch: 9.45 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5277676087549898		[learning rate: 0.0008919]
	Learning Rate: 0.000891899
	LOSS [training: 0.5277676087549898 | validation: 0.7609762043380707]
	TIME [epoch: 9.45 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5624114051635608		[learning rate: 0.00088866]
	Learning Rate: 0.000888663
	LOSS [training: 0.5624114051635608 | validation: 0.6816119448766152]
	TIME [epoch: 9.44 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5315241124013446		[learning rate: 0.00088544]
	Learning Rate: 0.000885438
	LOSS [training: 0.5315241124013446 | validation: 0.6389531600776256]
	TIME [epoch: 9.44 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5826383804545365		[learning rate: 0.00088222]
	Learning Rate: 0.000882224
	LOSS [training: 0.5826383804545365 | validation: 0.6188025434990719]
	TIME [epoch: 9.45 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.542768723654558		[learning rate: 0.00087902]
	Learning Rate: 0.000879022
	LOSS [training: 0.542768723654558 | validation: 0.6902479356447503]
	TIME [epoch: 9.45 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5404856890189925		[learning rate: 0.00087583]
	Learning Rate: 0.000875833
	LOSS [training: 0.5404856890189925 | validation: 0.7153282165113413]
	TIME [epoch: 9.44 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5448170043759883		[learning rate: 0.00087265]
	Learning Rate: 0.000872654
	LOSS [training: 0.5448170043759883 | validation: 0.6606946628832483]
	TIME [epoch: 9.44 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5686108053017642		[learning rate: 0.00086949]
	Learning Rate: 0.000869487
	LOSS [training: 0.5686108053017642 | validation: 0.6611145388356633]
	TIME [epoch: 9.46 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5535534413658276		[learning rate: 0.00086633]
	Learning Rate: 0.000866332
	LOSS [training: 0.5535534413658276 | validation: 0.6314761768674461]
	TIME [epoch: 9.44 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5370678879504835		[learning rate: 0.00086319]
	Learning Rate: 0.000863188
	LOSS [training: 0.5370678879504835 | validation: 0.5983177813485162]
	TIME [epoch: 9.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_774.pth
	Model improved!!!
EPOCH 775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5742930827793169		[learning rate: 0.00086006]
	Learning Rate: 0.000860055
	LOSS [training: 0.5742930827793169 | validation: 0.8367933824990353]
	TIME [epoch: 9.44 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5600617430377229		[learning rate: 0.00085693]
	Learning Rate: 0.000856934
	LOSS [training: 0.5600617430377229 | validation: 0.7432481721366966]
	TIME [epoch: 9.46 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6055926380916209		[learning rate: 0.00085382]
	Learning Rate: 0.000853824
	LOSS [training: 0.6055926380916209 | validation: 0.6256343248926458]
	TIME [epoch: 9.44 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5392612801592702		[learning rate: 0.00085073]
	Learning Rate: 0.000850726
	LOSS [training: 0.5392612801592702 | validation: 0.6926887742561445]
	TIME [epoch: 9.44 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5948280643024331		[learning rate: 0.00084764]
	Learning Rate: 0.000847638
	LOSS [training: 0.5948280643024331 | validation: 0.6568519068906425]
	TIME [epoch: 9.44 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5204154665753057		[learning rate: 0.00084456]
	Learning Rate: 0.000844562
	LOSS [training: 0.5204154665753057 | validation: 0.6233433079748484]
	TIME [epoch: 9.46 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5461731801958496		[learning rate: 0.0008415]
	Learning Rate: 0.000841497
	LOSS [training: 0.5461731801958496 | validation: 0.7281009732941089]
	TIME [epoch: 9.44 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5818532368163185		[learning rate: 0.00083844]
	Learning Rate: 0.000838443
	LOSS [training: 0.5818532368163185 | validation: 0.6794204781088816]
	TIME [epoch: 9.44 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5093980839516388		[learning rate: 0.0008354]
	Learning Rate: 0.000835401
	LOSS [training: 0.5093980839516388 | validation: 0.6297420982480708]
	TIME [epoch: 9.44 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.566180102559054		[learning rate: 0.00083237]
	Learning Rate: 0.000832369
	LOSS [training: 0.566180102559054 | validation: 0.634146108891571]
	TIME [epoch: 9.47 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5411867954745859		[learning rate: 0.00082935]
	Learning Rate: 0.000829348
	LOSS [training: 0.5411867954745859 | validation: 0.6354336350139691]
	TIME [epoch: 9.44 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5218424818020696		[learning rate: 0.00082634]
	Learning Rate: 0.000826338
	LOSS [training: 0.5218424818020696 | validation: 0.7476950391205813]
	TIME [epoch: 9.44 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.556915999153978		[learning rate: 0.00082334]
	Learning Rate: 0.00082334
	LOSS [training: 0.556915999153978 | validation: 0.5998968863169146]
	TIME [epoch: 9.44 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5665912329036654		[learning rate: 0.00082035]
	Learning Rate: 0.000820352
	LOSS [training: 0.5665912329036654 | validation: 0.6815335833545696]
	TIME [epoch: 9.46 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5498874473900595		[learning rate: 0.00081737]
	Learning Rate: 0.000817375
	LOSS [training: 0.5498874473900595 | validation: 0.6291017363456577]
	TIME [epoch: 9.44 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5555244612392986		[learning rate: 0.00081441]
	Learning Rate: 0.000814408
	LOSS [training: 0.5555244612392986 | validation: 0.5907814025701289]
	TIME [epoch: 9.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_790.pth
	Model improved!!!
EPOCH 791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5293913758206321		[learning rate: 0.00081145]
	Learning Rate: 0.000811453
	LOSS [training: 0.5293913758206321 | validation: 0.5946799993878148]
	TIME [epoch: 9.46 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5356596445974462		[learning rate: 0.00080851]
	Learning Rate: 0.000808508
	LOSS [training: 0.5356596445974462 | validation: 0.6556502597280338]
	TIME [epoch: 9.45 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5545428758543328		[learning rate: 0.00080557]
	Learning Rate: 0.000805574
	LOSS [training: 0.5545428758543328 | validation: 0.625609739446464]
	TIME [epoch: 9.44 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5277323336359911		[learning rate: 0.00080265]
	Learning Rate: 0.00080265
	LOSS [training: 0.5277323336359911 | validation: 0.6434386599538489]
	TIME [epoch: 9.43 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5698704027202001		[learning rate: 0.00079974]
	Learning Rate: 0.000799737
	LOSS [training: 0.5698704027202001 | validation: 0.638035306555924]
	TIME [epoch: 9.46 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5550264082651544		[learning rate: 0.00079684]
	Learning Rate: 0.000796835
	LOSS [training: 0.5550264082651544 | validation: 0.668766004560086]
	TIME [epoch: 9.44 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5392159640792632		[learning rate: 0.00079394]
	Learning Rate: 0.000793943
	LOSS [training: 0.5392159640792632 | validation: 0.5631420726640866]
	TIME [epoch: 9.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_797.pth
	Model improved!!!
EPOCH 798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5174633031292506		[learning rate: 0.00079106]
	Learning Rate: 0.000791062
	LOSS [training: 0.5174633031292506 | validation: 0.6580802635031552]
	TIME [epoch: 9.44 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.525731431516979		[learning rate: 0.00078819]
	Learning Rate: 0.000788191
	LOSS [training: 0.525731431516979 | validation: 0.6281419976140385]
	TIME [epoch: 9.46 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5169284375818415		[learning rate: 0.00078533]
	Learning Rate: 0.000785331
	LOSS [training: 0.5169284375818415 | validation: 0.6589406697370578]
	TIME [epoch: 9.44 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5437135162953124		[learning rate: 0.00078248]
	Learning Rate: 0.000782481
	LOSS [training: 0.5437135162953124 | validation: 0.7898111379522712]
	TIME [epoch: 9.44 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6429646229106265		[learning rate: 0.00077964]
	Learning Rate: 0.000779641
	LOSS [training: 0.6429646229106265 | validation: 0.6615170075390183]
	TIME [epoch: 9.44 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5407772302826096		[learning rate: 0.00077681]
	Learning Rate: 0.000776812
	LOSS [training: 0.5407772302826096 | validation: 0.6505341153675359]
	TIME [epoch: 9.47 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5191855181528592		[learning rate: 0.00077399]
	Learning Rate: 0.000773993
	LOSS [training: 0.5191855181528592 | validation: 0.6832076245279626]
	TIME [epoch: 9.44 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5194095063744248		[learning rate: 0.00077118]
	Learning Rate: 0.000771184
	LOSS [training: 0.5194095063744248 | validation: 0.6546163522608592]
	TIME [epoch: 9.44 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4931022277668543		[learning rate: 0.00076839]
	Learning Rate: 0.000768385
	LOSS [training: 0.4931022277668543 | validation: 0.6167328206166258]
	TIME [epoch: 9.44 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5372565136043029		[learning rate: 0.0007656]
	Learning Rate: 0.000765597
	LOSS [training: 0.5372565136043029 | validation: 0.5799135800956383]
	TIME [epoch: 9.45 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5285930771346029		[learning rate: 0.00076282]
	Learning Rate: 0.000762818
	LOSS [training: 0.5285930771346029 | validation: 0.6074905996677196]
	TIME [epoch: 9.44 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5202530906274628		[learning rate: 0.00076005]
	Learning Rate: 0.00076005
	LOSS [training: 0.5202530906274628 | validation: 0.7205761981327521]
	TIME [epoch: 9.44 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5170597561759924		[learning rate: 0.00075729]
	Learning Rate: 0.000757292
	LOSS [training: 0.5170597561759924 | validation: 0.5927477204447397]
	TIME [epoch: 9.46 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5245443893368706		[learning rate: 0.00075454]
	Learning Rate: 0.000754543
	LOSS [training: 0.5245443893368706 | validation: 0.5629410584840301]
	TIME [epoch: 9.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_811.pth
	Model improved!!!
EPOCH 812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5265660692351759		[learning rate: 0.00075181]
	Learning Rate: 0.000751805
	LOSS [training: 0.5265660692351759 | validation: 0.5864794290896534]
	TIME [epoch: 9.43 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5085334978745515		[learning rate: 0.00074908]
	Learning Rate: 0.000749077
	LOSS [training: 0.5085334978745515 | validation: 0.6445066703182787]
	TIME [epoch: 9.44 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.51676822460601		[learning rate: 0.00074636]
	Learning Rate: 0.000746358
	LOSS [training: 0.51676822460601 | validation: 0.6125874329463307]
	TIME [epoch: 9.46 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5072261649296036		[learning rate: 0.00074365]
	Learning Rate: 0.00074365
	LOSS [training: 0.5072261649296036 | validation: 0.5960860706122112]
	TIME [epoch: 9.43 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4921558061842502		[learning rate: 0.00074095]
	Learning Rate: 0.000740951
	LOSS [training: 0.4921558061842502 | validation: 0.5823440878982334]
	TIME [epoch: 9.44 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5276028397430842		[learning rate: 0.00073826]
	Learning Rate: 0.000738262
	LOSS [training: 0.5276028397430842 | validation: 0.6806039997095197]
	TIME [epoch: 9.43 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5547036887882225		[learning rate: 0.00073558]
	Learning Rate: 0.000735583
	LOSS [training: 0.5547036887882225 | validation: 0.5572050686318538]
	TIME [epoch: 9.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_818.pth
	Model improved!!!
EPOCH 819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5437042322549263		[learning rate: 0.00073291]
	Learning Rate: 0.000732913
	LOSS [training: 0.5437042322549263 | validation: 0.6564772278977171]
	TIME [epoch: 9.43 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5314140372205379		[learning rate: 0.00073025]
	Learning Rate: 0.000730254
	LOSS [training: 0.5314140372205379 | validation: 0.6447792683823061]
	TIME [epoch: 9.43 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5614734594272633		[learning rate: 0.0007276]
	Learning Rate: 0.000727603
	LOSS [training: 0.5614734594272633 | validation: 0.6491282259413707]
	TIME [epoch: 9.44 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5214507244909894		[learning rate: 0.00072496]
	Learning Rate: 0.000724963
	LOSS [training: 0.5214507244909894 | validation: 0.6125428514338535]
	TIME [epoch: 9.46 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5086510792780328		[learning rate: 0.00072233]
	Learning Rate: 0.000722332
	LOSS [training: 0.5086510792780328 | validation: 0.6755204671307038]
	TIME [epoch: 9.43 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5291469913271225		[learning rate: 0.00071971]
	Learning Rate: 0.000719711
	LOSS [training: 0.5291469913271225 | validation: 0.5296203715409549]
	TIME [epoch: 9.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_824.pth
	Model improved!!!
EPOCH 825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5073093829622797		[learning rate: 0.0007171]
	Learning Rate: 0.000717099
	LOSS [training: 0.5073093829622797 | validation: 0.6129499374097448]
	TIME [epoch: 9.44 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5636037875771747		[learning rate: 0.0007145]
	Learning Rate: 0.000714496
	LOSS [training: 0.5636037875771747 | validation: 0.5835589951312524]
	TIME [epoch: 9.45 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5069755425962921		[learning rate: 0.0007119]
	Learning Rate: 0.000711903
	LOSS [training: 0.5069755425962921 | validation: 0.5889674241165294]
	TIME [epoch: 9.44 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5049386029316734		[learning rate: 0.00070932]
	Learning Rate: 0.00070932
	LOSS [training: 0.5049386029316734 | validation: 0.56996598917266]
	TIME [epoch: 9.44 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5295062473517727		[learning rate: 0.00070675]
	Learning Rate: 0.000706746
	LOSS [training: 0.5295062473517727 | validation: 0.5785507143066388]
	TIME [epoch: 9.45 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4854874105777004		[learning rate: 0.00070418]
	Learning Rate: 0.000704181
	LOSS [training: 0.4854874105777004 | validation: 0.5389675545728742]
	TIME [epoch: 9.44 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.507726211235781		[learning rate: 0.00070163]
	Learning Rate: 0.000701625
	LOSS [training: 0.507726211235781 | validation: 0.5694176142779154]
	TIME [epoch: 9.43 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5256891424587227		[learning rate: 0.00069908]
	Learning Rate: 0.000699079
	LOSS [training: 0.5256891424587227 | validation: 0.5470675055405446]
	TIME [epoch: 9.43 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5246733708508893		[learning rate: 0.00069654]
	Learning Rate: 0.000696542
	LOSS [training: 0.5246733708508893 | validation: 0.600908223878868]
	TIME [epoch: 9.45 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4882192658713239		[learning rate: 0.00069401]
	Learning Rate: 0.000694014
	LOSS [training: 0.4882192658713239 | validation: 0.6070022616980575]
	TIME [epoch: 9.44 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49559086456213636		[learning rate: 0.0006915]
	Learning Rate: 0.000691496
	LOSS [training: 0.49559086456213636 | validation: 0.5554599948170816]
	TIME [epoch: 9.43 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4814754375660969		[learning rate: 0.00068899]
	Learning Rate: 0.000688986
	LOSS [training: 0.4814754375660969 | validation: 0.6648672446995343]
	TIME [epoch: 9.43 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4990716707090068		[learning rate: 0.00068649]
	Learning Rate: 0.000686486
	LOSS [training: 0.4990716707090068 | validation: 0.5789238500632726]
	TIME [epoch: 9.46 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5110528531587748		[learning rate: 0.00068399]
	Learning Rate: 0.000683994
	LOSS [training: 0.5110528531587748 | validation: 0.631553783190655]
	TIME [epoch: 9.43 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48990250917062933		[learning rate: 0.00068151]
	Learning Rate: 0.000681512
	LOSS [training: 0.48990250917062933 | validation: 0.5649659504652048]
	TIME [epoch: 9.43 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5189438425252659		[learning rate: 0.00067904]
	Learning Rate: 0.000679039
	LOSS [training: 0.5189438425252659 | validation: 0.6082373833811102]
	TIME [epoch: 9.43 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5011287407760082		[learning rate: 0.00067657]
	Learning Rate: 0.000676575
	LOSS [training: 0.5011287407760082 | validation: 0.5483128680791447]
	TIME [epoch: 9.45 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5231685652475534		[learning rate: 0.00067412]
	Learning Rate: 0.00067412
	LOSS [training: 0.5231685652475534 | validation: 0.577620365864133]
	TIME [epoch: 9.43 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.508054609593592		[learning rate: 0.00067167]
	Learning Rate: 0.000671673
	LOSS [training: 0.508054609593592 | validation: 0.6160374966319679]
	TIME [epoch: 9.44 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5003227541579531		[learning rate: 0.00066924]
	Learning Rate: 0.000669235
	LOSS [training: 0.5003227541579531 | validation: 0.5977534707973335]
	TIME [epoch: 9.44 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5230293026014281		[learning rate: 0.00066681]
	Learning Rate: 0.000666807
	LOSS [training: 0.5230293026014281 | validation: 0.6701375961139311]
	TIME [epoch: 9.45 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5343614961760782		[learning rate: 0.00066439]
	Learning Rate: 0.000664387
	LOSS [training: 0.5343614961760782 | validation: 0.6189643010561244]
	TIME [epoch: 9.44 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4910392826997018		[learning rate: 0.00066198]
	Learning Rate: 0.000661976
	LOSS [training: 0.4910392826997018 | validation: 0.5428702610328563]
	TIME [epoch: 9.43 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49741386187251013		[learning rate: 0.00065957]
	Learning Rate: 0.000659573
	LOSS [training: 0.49741386187251013 | validation: 0.6514126083222809]
	TIME [epoch: 9.45 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4977358339943538		[learning rate: 0.00065718]
	Learning Rate: 0.00065718
	LOSS [training: 0.4977358339943538 | validation: 0.6159274187503099]
	TIME [epoch: 9.44 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5416347106993695		[learning rate: 0.00065479]
	Learning Rate: 0.000654795
	LOSS [training: 0.5416347106993695 | validation: 0.5920691542216551]
	TIME [epoch: 9.44 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5086721279568881		[learning rate: 0.00065242]
	Learning Rate: 0.000652419
	LOSS [training: 0.5086721279568881 | validation: 0.5777154656002076]
	TIME [epoch: 9.43 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5023197137150281		[learning rate: 0.00065005]
	Learning Rate: 0.000650051
	LOSS [training: 0.5023197137150281 | validation: 0.5715258748033125]
	TIME [epoch: 9.46 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5007139408319107		[learning rate: 0.00064769]
	Learning Rate: 0.000647692
	LOSS [training: 0.5007139408319107 | validation: 0.5693436136486859]
	TIME [epoch: 9.44 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4773199689748381		[learning rate: 0.00064534]
	Learning Rate: 0.000645341
	LOSS [training: 0.4773199689748381 | validation: 0.580900620294949]
	TIME [epoch: 9.43 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5124827915547014		[learning rate: 0.000643]
	Learning Rate: 0.000642999
	LOSS [training: 0.5124827915547014 | validation: 0.5910253374489385]
	TIME [epoch: 9.44 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5005400269608664		[learning rate: 0.00064067]
	Learning Rate: 0.000640666
	LOSS [training: 0.5005400269608664 | validation: 0.5883317123915796]
	TIME [epoch: 9.46 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4827588464823373		[learning rate: 0.00063834]
	Learning Rate: 0.000638341
	LOSS [training: 0.4827588464823373 | validation: 0.5450058549581115]
	TIME [epoch: 9.44 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4967654313039029		[learning rate: 0.00063602]
	Learning Rate: 0.000636024
	LOSS [training: 0.4967654313039029 | validation: 0.6034665934213885]
	TIME [epoch: 9.43 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5285545021617428		[learning rate: 0.00063372]
	Learning Rate: 0.000633716
	LOSS [training: 0.5285545021617428 | validation: 0.697865005051566]
	TIME [epoch: 9.44 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5776178057429316		[learning rate: 0.00063142]
	Learning Rate: 0.000631416
	LOSS [training: 0.5776178057429316 | validation: 0.6592433197626554]
	TIME [epoch: 9.46 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5120953488669009		[learning rate: 0.00062912]
	Learning Rate: 0.000629125
	LOSS [training: 0.5120953488669009 | validation: 0.5290496455385609]
	TIME [epoch: 9.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_861.pth
	Model improved!!!
EPOCH 862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5163588314953678		[learning rate: 0.00062684]
	Learning Rate: 0.000626842
	LOSS [training: 0.5163588314953678 | validation: 0.6411204206338192]
	TIME [epoch: 9.44 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5707920902492474		[learning rate: 0.00062457]
	Learning Rate: 0.000624567
	LOSS [training: 0.5707920902492474 | validation: 0.5253868624957568]
	TIME [epoch: 9.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_863.pth
	Model improved!!!
EPOCH 864/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5069743322640595		[learning rate: 0.0006223]
	Learning Rate: 0.0006223
	LOSS [training: 0.5069743322640595 | validation: 0.6568370283173448]
	TIME [epoch: 9.46 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4782500830489201		[learning rate: 0.00062004]
	Learning Rate: 0.000620042
	LOSS [training: 0.4782500830489201 | validation: 0.5561071863900251]
	TIME [epoch: 9.43 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5671294702999132		[learning rate: 0.00061779]
	Learning Rate: 0.000617792
	LOSS [training: 0.5671294702999132 | validation: 0.6242303190089304]
	TIME [epoch: 9.44 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5077970859639561		[learning rate: 0.00061555]
	Learning Rate: 0.00061555
	LOSS [training: 0.5077970859639561 | validation: 0.5168353012023763]
	TIME [epoch: 9.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_867.pth
	Model improved!!!
EPOCH 868/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5174889501938776		[learning rate: 0.00061332]
	Learning Rate: 0.000613316
	LOSS [training: 0.5174889501938776 | validation: 0.5590053481996359]
	TIME [epoch: 9.45 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5530352478696818		[learning rate: 0.00061109]
	Learning Rate: 0.00061109
	LOSS [training: 0.5530352478696818 | validation: 0.5825832792311881]
	TIME [epoch: 9.43 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49892564764447184		[learning rate: 0.00060887]
	Learning Rate: 0.000608872
	LOSS [training: 0.49892564764447184 | validation: 0.6149014191490416]
	TIME [epoch: 9.44 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5389502644612119		[learning rate: 0.00060666]
	Learning Rate: 0.000606663
	LOSS [training: 0.5389502644612119 | validation: 0.6052983057897473]
	TIME [epoch: 9.45 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5048703529435861		[learning rate: 0.00060446]
	Learning Rate: 0.000604461
	LOSS [training: 0.5048703529435861 | validation: 0.619597895082059]
	TIME [epoch: 9.43 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5150533239117965		[learning rate: 0.00060227]
	Learning Rate: 0.000602268
	LOSS [training: 0.5150533239117965 | validation: 0.7583285279308227]
	TIME [epoch: 9.43 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5225856449253178		[learning rate: 0.00060008]
	Learning Rate: 0.000600082
	LOSS [training: 0.5225856449253178 | validation: 0.5897433968360524]
	TIME [epoch: 9.43 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4804809892473626		[learning rate: 0.0005979]
	Learning Rate: 0.000597904
	LOSS [training: 0.4804809892473626 | validation: 0.5929749714000385]
	TIME [epoch: 9.46 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5062986932559286		[learning rate: 0.00059573]
	Learning Rate: 0.000595734
	LOSS [training: 0.5062986932559286 | validation: 0.6090283574330857]
	TIME [epoch: 9.44 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4626455171636126		[learning rate: 0.00059357]
	Learning Rate: 0.000593572
	LOSS [training: 0.4626455171636126 | validation: 0.5238661275170726]
	TIME [epoch: 9.43 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5213538114504946		[learning rate: 0.00059142]
	Learning Rate: 0.000591418
	LOSS [training: 0.5213538114504946 | validation: 0.6226294573341714]
	TIME [epoch: 9.44 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5166881617654792		[learning rate: 0.00058927]
	Learning Rate: 0.000589272
	LOSS [training: 0.5166881617654792 | validation: 0.5876868632681456]
	TIME [epoch: 9.46 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5452951138711872		[learning rate: 0.00058713]
	Learning Rate: 0.000587133
	LOSS [training: 0.5452951138711872 | validation: 0.6186776081381028]
	TIME [epoch: 9.44 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5252968962130564		[learning rate: 0.000585]
	Learning Rate: 0.000585003
	LOSS [training: 0.5252968962130564 | validation: 0.5194040074913652]
	TIME [epoch: 9.43 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4929504665071425		[learning rate: 0.00058288]
	Learning Rate: 0.00058288
	LOSS [training: 0.4929504665071425 | validation: 0.6027611012535923]
	TIME [epoch: 9.44 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47556870755502256		[learning rate: 0.00058076]
	Learning Rate: 0.000580764
	LOSS [training: 0.47556870755502256 | validation: 0.6054537208287846]
	TIME [epoch: 9.46 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.493425064022653		[learning rate: 0.00057866]
	Learning Rate: 0.000578657
	LOSS [training: 0.493425064022653 | validation: 0.5715650634809041]
	TIME [epoch: 9.43 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5147460557846725		[learning rate: 0.00057656]
	Learning Rate: 0.000576557
	LOSS [training: 0.5147460557846725 | validation: 0.5036681857539151]
	TIME [epoch: 9.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_885.pth
	Model improved!!!
EPOCH 886/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5448821448134394		[learning rate: 0.00057446]
	Learning Rate: 0.000574465
	LOSS [training: 0.5448821448134394 | validation: 0.6046660218742563]
	TIME [epoch: 9.44 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5220394347437696		[learning rate: 0.00057238]
	Learning Rate: 0.00057238
	LOSS [training: 0.5220394347437696 | validation: 0.5710150170447261]
	TIME [epoch: 9.45 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4864427902315027		[learning rate: 0.0005703]
	Learning Rate: 0.000570303
	LOSS [training: 0.4864427902315027 | validation: 0.5047192088949765]
	TIME [epoch: 9.44 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4788298998337484		[learning rate: 0.00056823]
	Learning Rate: 0.000568233
	LOSS [training: 0.4788298998337484 | validation: 0.5325723581060932]
	TIME [epoch: 9.43 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47798088844328007		[learning rate: 0.00056617]
	Learning Rate: 0.000566171
	LOSS [training: 0.47798088844328007 | validation: 0.5603446975075395]
	TIME [epoch: 9.45 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4717666036723679		[learning rate: 0.00056412]
	Learning Rate: 0.000564116
	LOSS [training: 0.4717666036723679 | validation: 0.574369054957742]
	TIME [epoch: 9.44 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4817118510217041		[learning rate: 0.00056207]
	Learning Rate: 0.000562069
	LOSS [training: 0.4817118510217041 | validation: 0.5558028883327877]
	TIME [epoch: 9.44 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4643570958311212		[learning rate: 0.00056003]
	Learning Rate: 0.000560029
	LOSS [training: 0.4643570958311212 | validation: 0.5014642398321886]
	TIME [epoch: 9.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_893.pth
	Model improved!!!
EPOCH 894/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4850851331594992		[learning rate: 0.000558]
	Learning Rate: 0.000557997
	LOSS [training: 0.4850851331594992 | validation: 0.5845166133216764]
	TIME [epoch: 9.46 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4939430760444187		[learning rate: 0.00055597]
	Learning Rate: 0.000555972
	LOSS [training: 0.4939430760444187 | validation: 0.6688938751654588]
	TIME [epoch: 9.44 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5087551527434406		[learning rate: 0.00055395]
	Learning Rate: 0.000553954
	LOSS [training: 0.5087551527434406 | validation: 0.6180444884489759]
	TIME [epoch: 9.44 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.491068128267953		[learning rate: 0.00055194]
	Learning Rate: 0.000551944
	LOSS [training: 0.491068128267953 | validation: 0.5194267899232178]
	TIME [epoch: 9.44 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4936433772076539		[learning rate: 0.00054994]
	Learning Rate: 0.000549941
	LOSS [training: 0.4936433772076539 | validation: 0.5638958209068354]
	TIME [epoch: 9.47 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47517066674996544		[learning rate: 0.00054794]
	Learning Rate: 0.000547945
	LOSS [training: 0.47517066674996544 | validation: 0.5321931946041546]
	TIME [epoch: 9.44 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4807463970062419		[learning rate: 0.00054596]
	Learning Rate: 0.000545956
	LOSS [training: 0.4807463970062419 | validation: 0.47689211310645024]
	TIME [epoch: 9.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_900.pth
	Model improved!!!
EPOCH 901/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.472654198300161		[learning rate: 0.00054397]
	Learning Rate: 0.000543975
	LOSS [training: 0.472654198300161 | validation: 0.5230000792737668]
	TIME [epoch: 9.45 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4818633203534334		[learning rate: 0.000542]
	Learning Rate: 0.000542001
	LOSS [training: 0.4818633203534334 | validation: 0.5285501586291936]
	TIME [epoch: 9.45 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46712829318726756		[learning rate: 0.00054003]
	Learning Rate: 0.000540034
	LOSS [training: 0.46712829318726756 | validation: 0.5873482152410372]
	TIME [epoch: 9.44 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49064245299836473		[learning rate: 0.00053807]
	Learning Rate: 0.000538074
	LOSS [training: 0.49064245299836473 | validation: 0.5027010277004981]
	TIME [epoch: 9.44 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4752600268812951		[learning rate: 0.00053612]
	Learning Rate: 0.000536121
	LOSS [training: 0.4752600268812951 | validation: 0.6384609098704529]
	TIME [epoch: 9.45 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4700718616690958		[learning rate: 0.00053418]
	Learning Rate: 0.000534176
	LOSS [training: 0.4700718616690958 | validation: 0.5487938373217791]
	TIME [epoch: 9.45 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49390544378445833		[learning rate: 0.00053224]
	Learning Rate: 0.000532237
	LOSS [training: 0.49390544378445833 | validation: 0.5084162593311581]
	TIME [epoch: 9.44 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47342103060911384		[learning rate: 0.00053031]
	Learning Rate: 0.000530306
	LOSS [training: 0.47342103060911384 | validation: 0.558736264357475]
	TIME [epoch: 9.44 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48125250894602206		[learning rate: 0.00052838]
	Learning Rate: 0.000528381
	LOSS [training: 0.48125250894602206 | validation: 0.5477963344189095]
	TIME [epoch: 9.46 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4893005586764561		[learning rate: 0.00052646]
	Learning Rate: 0.000526464
	LOSS [training: 0.4893005586764561 | validation: 0.5401918533124659]
	TIME [epoch: 9.45 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47269868893851646		[learning rate: 0.00052455]
	Learning Rate: 0.000524553
	LOSS [training: 0.47269868893851646 | validation: 0.4828430900663112]
	TIME [epoch: 9.44 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48811347118662046		[learning rate: 0.00052265]
	Learning Rate: 0.000522649
	LOSS [training: 0.48811347118662046 | validation: 0.5748342791748212]
	TIME [epoch: 9.44 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5305381744826989		[learning rate: 0.00052075]
	Learning Rate: 0.000520753
	LOSS [training: 0.5305381744826989 | validation: 0.563917349857479]
	TIME [epoch: 9.46 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47930065879520656		[learning rate: 0.00051886]
	Learning Rate: 0.000518863
	LOSS [training: 0.47930065879520656 | validation: 0.6383269694513889]
	TIME [epoch: 9.45 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5395349614566035		[learning rate: 0.00051698]
	Learning Rate: 0.00051698
	LOSS [training: 0.5395349614566035 | validation: 0.6203289581676228]
	TIME [epoch: 9.44 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5095638654215436		[learning rate: 0.0005151]
	Learning Rate: 0.000515104
	LOSS [training: 0.5095638654215436 | validation: 0.5042842500852251]
	TIME [epoch: 9.44 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45370550641301993		[learning rate: 0.00051323]
	Learning Rate: 0.000513235
	LOSS [training: 0.45370550641301993 | validation: 0.6159255014974033]
	TIME [epoch: 9.47 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49724054697660575		[learning rate: 0.00051137]
	Learning Rate: 0.000511372
	LOSS [training: 0.49724054697660575 | validation: 0.5087863796377967]
	TIME [epoch: 9.44 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47803092381501466		[learning rate: 0.00050952]
	Learning Rate: 0.000509516
	LOSS [training: 0.47803092381501466 | validation: 0.5971426273090924]
	TIME [epoch: 9.44 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4970349313491303		[learning rate: 0.00050767]
	Learning Rate: 0.000507667
	LOSS [training: 0.4970349313491303 | validation: 0.6559453783755532]
	TIME [epoch: 9.44 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4883221521009773		[learning rate: 0.00050582]
	Learning Rate: 0.000505825
	LOSS [training: 0.4883221521009773 | validation: 0.5020731111210269]
	TIME [epoch: 9.46 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46754312891482747		[learning rate: 0.00050399]
	Learning Rate: 0.000503989
	LOSS [training: 0.46754312891482747 | validation: 0.5894797420910017]
	TIME [epoch: 9.45 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4530863192522208		[learning rate: 0.00050216]
	Learning Rate: 0.00050216
	LOSS [training: 0.4530863192522208 | validation: 0.5353155881145145]
	TIME [epoch: 9.44 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48515680759953195		[learning rate: 0.00050034]
	Learning Rate: 0.000500338
	LOSS [training: 0.48515680759953195 | validation: 0.5676115608137987]
	TIME [epoch: 9.45 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4840360506195931		[learning rate: 0.00049852]
	Learning Rate: 0.000498522
	LOSS [training: 0.4840360506195931 | validation: 0.5952772447777338]
	TIME [epoch: 9.46 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48604184133129336		[learning rate: 0.00049671]
	Learning Rate: 0.000496713
	LOSS [training: 0.48604184133129336 | validation: 0.60733326555999]
	TIME [epoch: 9.44 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5257190201247359		[learning rate: 0.00049491]
	Learning Rate: 0.00049491
	LOSS [training: 0.5257190201247359 | validation: 0.5794264758203694]
	TIME [epoch: 9.44 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5121520348237848		[learning rate: 0.00049311]
	Learning Rate: 0.000493114
	LOSS [training: 0.5121520348237848 | validation: 0.5715308652644903]
	TIME [epoch: 9.46 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49282321834719695		[learning rate: 0.00049132]
	Learning Rate: 0.000491325
	LOSS [training: 0.49282321834719695 | validation: 0.5929531542136576]
	TIME [epoch: 9.45 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46234480710635645		[learning rate: 0.00048954]
	Learning Rate: 0.000489542
	LOSS [training: 0.46234480710635645 | validation: 0.6114211078584456]
	TIME [epoch: 9.45 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4985901824614592		[learning rate: 0.00048776]
	Learning Rate: 0.000487765
	LOSS [training: 0.4985901824614592 | validation: 0.5129951330432019]
	TIME [epoch: 9.44 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47804809439235585		[learning rate: 0.00048599]
	Learning Rate: 0.000485995
	LOSS [training: 0.47804809439235585 | validation: 0.4964678035942865]
	TIME [epoch: 9.46 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4968698781829829		[learning rate: 0.00048423]
	Learning Rate: 0.000484231
	LOSS [training: 0.4968698781829829 | validation: 0.5112659545370656]
	TIME [epoch: 9.44 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4662847504451134		[learning rate: 0.00048247]
	Learning Rate: 0.000482474
	LOSS [training: 0.4662847504451134 | validation: 0.5453902933624393]
	TIME [epoch: 9.44 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4653052895134119		[learning rate: 0.00048072]
	Learning Rate: 0.000480723
	LOSS [training: 0.4653052895134119 | validation: 0.5495621935506888]
	TIME [epoch: 9.44 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4949517220565073		[learning rate: 0.00047898]
	Learning Rate: 0.000478978
	LOSS [training: 0.4949517220565073 | validation: 0.5496164765755033]
	TIME [epoch: 9.46 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4568460912284699		[learning rate: 0.00047724]
	Learning Rate: 0.00047724
	LOSS [training: 0.4568460912284699 | validation: 0.5508523079842885]
	TIME [epoch: 9.44 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4870700596679455		[learning rate: 0.00047551]
	Learning Rate: 0.000475508
	LOSS [training: 0.4870700596679455 | validation: 0.5972116627727436]
	TIME [epoch: 9.44 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5170390587409923		[learning rate: 0.00047378]
	Learning Rate: 0.000473782
	LOSS [training: 0.5170390587409923 | validation: 0.5972284687614439]
	TIME [epoch: 9.44 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4781297378085242		[learning rate: 0.00047206]
	Learning Rate: 0.000472063
	LOSS [training: 0.4781297378085242 | validation: 0.5645391307625981]
	TIME [epoch: 9.46 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46465569112524163		[learning rate: 0.00047035]
	Learning Rate: 0.00047035
	LOSS [training: 0.46465569112524163 | validation: 0.5998725564812789]
	TIME [epoch: 9.44 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4770668162615844		[learning rate: 0.00046864]
	Learning Rate: 0.000468643
	LOSS [training: 0.4770668162615844 | validation: 0.6059122335604792]
	TIME [epoch: 9.44 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46770438724525193		[learning rate: 0.00046694]
	Learning Rate: 0.000466942
	LOSS [training: 0.46770438724525193 | validation: 0.49219811448035333]
	TIME [epoch: 9.44 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45520799052632127		[learning rate: 0.00046525]
	Learning Rate: 0.000465248
	LOSS [training: 0.45520799052632127 | validation: 0.5241126617526536]
	TIME [epoch: 9.46 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48167939055813436		[learning rate: 0.00046356]
	Learning Rate: 0.000463559
	LOSS [training: 0.48167939055813436 | validation: 0.56568799345406]
	TIME [epoch: 9.44 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48867156947718		[learning rate: 0.00046188]
	Learning Rate: 0.000461877
	LOSS [training: 0.48867156947718 | validation: 0.48263458727108943]
	TIME [epoch: 9.44 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46891864435721703		[learning rate: 0.0004602]
	Learning Rate: 0.000460201
	LOSS [training: 0.46891864435721703 | validation: 0.5315911382544785]
	TIME [epoch: 9.44 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4761497053810054		[learning rate: 0.00045853]
	Learning Rate: 0.000458531
	LOSS [training: 0.4761497053810054 | validation: 0.5656792309613016]
	TIME [epoch: 9.46 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4791020414791502		[learning rate: 0.00045687]
	Learning Rate: 0.000456867
	LOSS [training: 0.4791020414791502 | validation: 0.524006116838242]
	TIME [epoch: 9.44 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5018172780324681		[learning rate: 0.00045521]
	Learning Rate: 0.000455209
	LOSS [training: 0.5018172780324681 | validation: 0.5291479324457941]
	TIME [epoch: 9.44 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4601845067789741		[learning rate: 0.00045356]
	Learning Rate: 0.000453557
	LOSS [training: 0.4601845067789741 | validation: 0.5321811439339669]
	TIME [epoch: 9.46 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4702373650373127		[learning rate: 0.00045191]
	Learning Rate: 0.000451911
	LOSS [training: 0.4702373650373127 | validation: 0.5284512668215641]
	TIME [epoch: 9.44 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4941602758156943		[learning rate: 0.00045027]
	Learning Rate: 0.000450271
	LOSS [training: 0.4941602758156943 | validation: 0.6330442904202194]
	TIME [epoch: 9.44 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4769276754864517		[learning rate: 0.00044864]
	Learning Rate: 0.000448637
	LOSS [training: 0.4769276754864517 | validation: 0.5581633579730206]
	TIME [epoch: 9.44 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4588642320518714		[learning rate: 0.00044701]
	Learning Rate: 0.000447009
	LOSS [training: 0.4588642320518714 | validation: 0.5707375601056065]
	TIME [epoch: 9.46 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4849741965394453		[learning rate: 0.00044539]
	Learning Rate: 0.000445386
	LOSS [training: 0.4849741965394453 | validation: 0.5817126405531756]
	TIME [epoch: 9.44 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46756842335927057		[learning rate: 0.00044377]
	Learning Rate: 0.00044377
	LOSS [training: 0.46756842335927057 | validation: 0.5150010875786911]
	TIME [epoch: 9.44 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4665178535471268		[learning rate: 0.00044216]
	Learning Rate: 0.00044216
	LOSS [training: 0.4665178535471268 | validation: 0.5190473547442818]
	TIME [epoch: 9.44 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4644358971129817		[learning rate: 0.00044055]
	Learning Rate: 0.000440555
	LOSS [training: 0.4644358971129817 | validation: 0.49788500607101127]
	TIME [epoch: 9.46 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5110361105664322		[learning rate: 0.00043896]
	Learning Rate: 0.000438956
	LOSS [training: 0.5110361105664322 | validation: 0.5466820747930664]
	TIME [epoch: 9.44 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48440933691909505		[learning rate: 0.00043736]
	Learning Rate: 0.000437363
	LOSS [training: 0.48440933691909505 | validation: 0.5326209025708617]
	TIME [epoch: 9.44 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4938005802998274		[learning rate: 0.00043578]
	Learning Rate: 0.000435776
	LOSS [training: 0.4938005802998274 | validation: 0.5799622116748135]
	TIME [epoch: 9.44 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49569338021711895		[learning rate: 0.00043419]
	Learning Rate: 0.000434194
	LOSS [training: 0.49569338021711895 | validation: 0.5292929605489727]
	TIME [epoch: 9.46 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4784259228247681		[learning rate: 0.00043262]
	Learning Rate: 0.000432619
	LOSS [training: 0.4784259228247681 | validation: 0.5755334158202494]
	TIME [epoch: 9.44 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47946023703965057		[learning rate: 0.00043105]
	Learning Rate: 0.000431049
	LOSS [training: 0.47946023703965057 | validation: 0.6236809640874746]
	TIME [epoch: 9.44 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4730084382145088		[learning rate: 0.00042948]
	Learning Rate: 0.000429484
	LOSS [training: 0.4730084382145088 | validation: 0.5664070131175513]
	TIME [epoch: 9.44 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44802787116148524		[learning rate: 0.00042793]
	Learning Rate: 0.000427926
	LOSS [training: 0.44802787116148524 | validation: 0.5199218996600773]
	TIME [epoch: 9.46 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48033700353444564		[learning rate: 0.00042637]
	Learning Rate: 0.000426373
	LOSS [training: 0.48033700353444564 | validation: 0.49721574418760184]
	TIME [epoch: 9.45 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47241726334993556		[learning rate: 0.00042483]
	Learning Rate: 0.000424825
	LOSS [training: 0.47241726334993556 | validation: 0.6453447927870635]
	TIME [epoch: 9.44 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4539509364280955		[learning rate: 0.00042328]
	Learning Rate: 0.000423284
	LOSS [training: 0.4539509364280955 | validation: 0.4869084942078066]
	TIME [epoch: 9.46 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5115089608546899		[learning rate: 0.00042175]
	Learning Rate: 0.000421748
	LOSS [training: 0.5115089608546899 | validation: 0.5556274670565321]
	TIME [epoch: 9.44 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47874923500880123		[learning rate: 0.00042022]
	Learning Rate: 0.000420217
	LOSS [training: 0.47874923500880123 | validation: 0.5546645630573268]
	TIME [epoch: 9.44 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47144465097376853		[learning rate: 0.00041869]
	Learning Rate: 0.000418692
	LOSS [training: 0.47144465097376853 | validation: 0.5103733305673093]
	TIME [epoch: 9.44 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.493147848836779		[learning rate: 0.00041717]
	Learning Rate: 0.000417173
	LOSS [training: 0.493147848836779 | validation: 0.5948670866798788]
	TIME [epoch: 9.46 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4950660050821418		[learning rate: 0.00041566]
	Learning Rate: 0.000415659
	LOSS [training: 0.4950660050821418 | validation: 0.5300420309386518]
	TIME [epoch: 9.45 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46706204572816984		[learning rate: 0.00041415]
	Learning Rate: 0.00041415
	LOSS [training: 0.46706204572816984 | validation: 0.5316301253634862]
	TIME [epoch: 9.44 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44169898657875706		[learning rate: 0.00041265]
	Learning Rate: 0.000412647
	LOSS [training: 0.44169898657875706 | validation: 0.5451109264995005]
	TIME [epoch: 9.44 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4995082877670183		[learning rate: 0.00041115]
	Learning Rate: 0.00041115
	LOSS [training: 0.4995082877670183 | validation: 0.5007953067933183]
	TIME [epoch: 9.46 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.471477557528073		[learning rate: 0.00040966]
	Learning Rate: 0.000409658
	LOSS [training: 0.471477557528073 | validation: 0.5300509868976707]
	TIME [epoch: 9.44 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47153274843187587		[learning rate: 0.00040817]
	Learning Rate: 0.000408171
	LOSS [training: 0.47153274843187587 | validation: 0.5523838054875175]
	TIME [epoch: 9.44 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4766436154014538		[learning rate: 0.00040669]
	Learning Rate: 0.00040669
	LOSS [training: 0.4766436154014538 | validation: 0.5614643312309576]
	TIME [epoch: 9.44 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47555819924321624		[learning rate: 0.00040521]
	Learning Rate: 0.000405214
	LOSS [training: 0.47555819924321624 | validation: 0.561723214823637]
	TIME [epoch: 9.46 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4681734835341699		[learning rate: 0.00040374]
	Learning Rate: 0.000403743
	LOSS [training: 0.4681734835341699 | validation: 0.5455303077909984]
	TIME [epoch: 9.44 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4562585920816617		[learning rate: 0.00040228]
	Learning Rate: 0.000402278
	LOSS [training: 0.4562585920816617 | validation: 0.4943724831062081]
	TIME [epoch: 9.44 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46258611433763425		[learning rate: 0.00040082]
	Learning Rate: 0.000400818
	LOSS [training: 0.46258611433763425 | validation: 0.5283235638131093]
	TIME [epoch: 9.44 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45889603886457647		[learning rate: 0.00039936]
	Learning Rate: 0.000399364
	LOSS [training: 0.45889603886457647 | validation: 0.524952719218687]
	TIME [epoch: 9.46 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4575358070265135		[learning rate: 0.00039791]
	Learning Rate: 0.000397914
	LOSS [training: 0.4575358070265135 | validation: 0.5290627619688038]
	TIME [epoch: 9.44 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4744141603480877		[learning rate: 0.00039647]
	Learning Rate: 0.00039647
	LOSS [training: 0.4744141603480877 | validation: 0.5113586547299231]
	TIME [epoch: 9.44 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.489141286712967		[learning rate: 0.00039503]
	Learning Rate: 0.000395031
	LOSS [training: 0.489141286712967 | validation: 0.5330316541450839]
	TIME [epoch: 9.45 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4453992555447597		[learning rate: 0.0003936]
	Learning Rate: 0.000393598
	LOSS [training: 0.4453992555447597 | validation: 0.491527430866708]
	TIME [epoch: 9.46 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46581432625179		[learning rate: 0.00039217]
	Learning Rate: 0.000392169
	LOSS [training: 0.46581432625179 | validation: 0.5668136627670319]
	TIME [epoch: 9.44 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45091046092504605		[learning rate: 0.00039075]
	Learning Rate: 0.000390746
	LOSS [training: 0.45091046092504605 | validation: 0.515215903333543]
	TIME [epoch: 9.44 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4410422731074677		[learning rate: 0.00038933]
	Learning Rate: 0.000389328
	LOSS [training: 0.4410422731074677 | validation: 0.6061424150374035]
	TIME [epoch: 9.46 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47672207895004215		[learning rate: 0.00038792]
	Learning Rate: 0.000387915
	LOSS [training: 0.47672207895004215 | validation: 0.5246221870739177]
	TIME [epoch: 9.45 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46972451488060674		[learning rate: 0.00038651]
	Learning Rate: 0.000386508
	LOSS [training: 0.46972451488060674 | validation: 0.5253242260673574]
	TIME [epoch: 9.44 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4534718320364262		[learning rate: 0.0003851]
	Learning Rate: 0.000385105
	LOSS [training: 0.4534718320364262 | validation: 0.5348663840374348]
	TIME [epoch: 9.44 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44696302126411763		[learning rate: 0.00038371]
	Learning Rate: 0.000383707
	LOSS [training: 0.44696302126411763 | validation: 0.47605425867238993]
	TIME [epoch: 9.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_997.pth
	Model improved!!!
EPOCH 998/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4598287331405018		[learning rate: 0.00038231]
	Learning Rate: 0.000382315
	LOSS [training: 0.4598287331405018 | validation: 0.6154023143822863]
	TIME [epoch: 9.44 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4389550584302201		[learning rate: 0.00038093]
	Learning Rate: 0.000380927
	LOSS [training: 0.4389550584302201 | validation: 0.4748261954988965]
	TIME [epoch: 9.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_999.pth
	Model improved!!!
EPOCH 1000/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4603511282918952		[learning rate: 0.00037954]
	Learning Rate: 0.000379545
	LOSS [training: 0.4603511282918952 | validation: 0.5554292047687996]
	TIME [epoch: 9.44 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47164380413622603		[learning rate: 0.00037817]
	Learning Rate: 0.000378167
	LOSS [training: 0.47164380413622603 | validation: 0.5562809936643741]
	TIME [epoch: 9.46 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44894637838016715		[learning rate: 0.0003768]
	Learning Rate: 0.000376795
	LOSS [training: 0.44894637838016715 | validation: 0.47745500422150744]
	TIME [epoch: 9.43 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44208743298607367		[learning rate: 0.00037543]
	Learning Rate: 0.000375428
	LOSS [training: 0.44208743298607367 | validation: 0.5263777140485111]
	TIME [epoch: 9.43 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4461899990279548		[learning rate: 0.00037407]
	Learning Rate: 0.000374065
	LOSS [training: 0.4461899990279548 | validation: 0.5214188169580479]
	TIME [epoch: 9.44 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44636241771033963		[learning rate: 0.00037271]
	Learning Rate: 0.000372708
	LOSS [training: 0.44636241771033963 | validation: 0.5438869830802241]
	TIME [epoch: 9.45 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4551798658682043		[learning rate: 0.00037136]
	Learning Rate: 0.000371355
	LOSS [training: 0.4551798658682043 | validation: 0.4780307631773355]
	TIME [epoch: 9.43 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4600279302301285		[learning rate: 0.00037001]
	Learning Rate: 0.000370008
	LOSS [training: 0.4600279302301285 | validation: 0.5308205702811876]
	TIME [epoch: 9.43 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4659733062630299		[learning rate: 0.00036866]
	Learning Rate: 0.000368665
	LOSS [training: 0.4659733062630299 | validation: 0.5556173164618174]
	TIME [epoch: 9.44 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4484164281918188		[learning rate: 0.00036733]
	Learning Rate: 0.000367327
	LOSS [training: 0.4484164281918188 | validation: 0.5661963081554495]
	TIME [epoch: 9.45 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47102460627104925		[learning rate: 0.00036599]
	Learning Rate: 0.000365994
	LOSS [training: 0.47102460627104925 | validation: 0.5440658055366454]
	TIME [epoch: 9.44 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4442754197461645		[learning rate: 0.00036467]
	Learning Rate: 0.000364666
	LOSS [training: 0.4442754197461645 | validation: 0.4634940248556518]
	TIME [epoch: 9.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_1011.pth
	Model improved!!!
EPOCH 1012/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46143712330891357		[learning rate: 0.00036334]
	Learning Rate: 0.000363342
	LOSS [training: 0.46143712330891357 | validation: 0.5034508991311598]
	TIME [epoch: 9.46 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.453813014256922		[learning rate: 0.00036202]
	Learning Rate: 0.000362024
	LOSS [training: 0.453813014256922 | validation: 0.5072612518739374]
	TIME [epoch: 9.44 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4439892190788566		[learning rate: 0.00036071]
	Learning Rate: 0.00036071
	LOSS [training: 0.4439892190788566 | validation: 0.5371319646876094]
	TIME [epoch: 9.44 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4663611540074428		[learning rate: 0.0003594]
	Learning Rate: 0.000359401
	LOSS [training: 0.4663611540074428 | validation: 0.5404541640963385]
	TIME [epoch: 9.44 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4592754617441218		[learning rate: 0.0003581]
	Learning Rate: 0.000358096
	LOSS [training: 0.4592754617441218 | validation: 0.5215224355242621]
	TIME [epoch: 9.46 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4814864106427983		[learning rate: 0.0003568]
	Learning Rate: 0.000356797
	LOSS [training: 0.4814864106427983 | validation: 0.48386033113293736]
	TIME [epoch: 9.44 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4477636142510761		[learning rate: 0.0003555]
	Learning Rate: 0.000355502
	LOSS [training: 0.4477636142510761 | validation: 0.5084410210643673]
	TIME [epoch: 9.44 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47145743108257365		[learning rate: 0.00035421]
	Learning Rate: 0.000354212
	LOSS [training: 0.47145743108257365 | validation: 0.5619147029269507]
	TIME [epoch: 9.43 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4478727722161402		[learning rate: 0.00035293]
	Learning Rate: 0.000352926
	LOSS [training: 0.4478727722161402 | validation: 0.535857191861466]
	TIME [epoch: 9.45 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4671344797225159		[learning rate: 0.00035165]
	Learning Rate: 0.000351646
	LOSS [training: 0.4671344797225159 | validation: 0.5292688360186751]
	TIME [epoch: 9.43 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4428241033400043		[learning rate: 0.00035037]
	Learning Rate: 0.00035037
	LOSS [training: 0.4428241033400043 | validation: 0.5104019075206903]
	TIME [epoch: 9.44 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.460778247441395		[learning rate: 0.0003491]
	Learning Rate: 0.000349098
	LOSS [training: 0.460778247441395 | validation: 0.5873487199338598]
	TIME [epoch: 9.43 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43702029282099525		[learning rate: 0.00034783]
	Learning Rate: 0.000347831
	LOSS [training: 0.43702029282099525 | validation: 0.5147659313965549]
	TIME [epoch: 9.45 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4557269587199528		[learning rate: 0.00034657]
	Learning Rate: 0.000346569
	LOSS [training: 0.4557269587199528 | validation: 0.49718613142280477]
	TIME [epoch: 9.43 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4511991341132199		[learning rate: 0.00034531]
	Learning Rate: 0.000345311
	LOSS [training: 0.4511991341132199 | validation: 0.5092812957259453]
	TIME [epoch: 9.43 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4667334366477217		[learning rate: 0.00034406]
	Learning Rate: 0.000344058
	LOSS [training: 0.4667334366477217 | validation: 0.5221252080145234]
	TIME [epoch: 9.44 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45154499343000687		[learning rate: 0.00034281]
	Learning Rate: 0.000342809
	LOSS [training: 0.45154499343000687 | validation: 0.5480095048880359]
	TIME [epoch: 9.44 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44935397101817154		[learning rate: 0.00034157]
	Learning Rate: 0.000341565
	LOSS [training: 0.44935397101817154 | validation: 0.5254636473165405]
	TIME [epoch: 9.43 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4513706375834642		[learning rate: 0.00034033]
	Learning Rate: 0.000340326
	LOSS [training: 0.4513706375834642 | validation: 0.567650308065989]
	TIME [epoch: 9.43 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47770702480650645		[learning rate: 0.00033909]
	Learning Rate: 0.000339091
	LOSS [training: 0.47770702480650645 | validation: 0.47230913765101334]
	TIME [epoch: 9.45 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4646406539925339		[learning rate: 0.00033786]
	Learning Rate: 0.00033786
	LOSS [training: 0.4646406539925339 | validation: 0.4990719979836071]
	TIME [epoch: 9.44 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4612691242261787		[learning rate: 0.00033663]
	Learning Rate: 0.000336634
	LOSS [training: 0.4612691242261787 | validation: 0.463603683515653]
	TIME [epoch: 9.43 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.455703000602118		[learning rate: 0.00033541]
	Learning Rate: 0.000335412
	LOSS [training: 0.455703000602118 | validation: 0.5639727510401111]
	TIME [epoch: 9.43 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47347918692993957		[learning rate: 0.0003342]
	Learning Rate: 0.000334195
	LOSS [training: 0.47347918692993957 | validation: 0.4850728009454848]
	TIME [epoch: 9.45 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45573510369841264		[learning rate: 0.00033298]
	Learning Rate: 0.000332982
	LOSS [training: 0.45573510369841264 | validation: 0.5111620860642258]
	TIME [epoch: 9.44 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4264425261079424		[learning rate: 0.00033177]
	Learning Rate: 0.000331774
	LOSS [training: 0.4264425261079424 | validation: 0.4999507823052817]
	TIME [epoch: 9.43 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44105220397665923		[learning rate: 0.00033057]
	Learning Rate: 0.00033057
	LOSS [training: 0.44105220397665923 | validation: 0.5090987936748937]
	TIME [epoch: 9.43 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44130210315590707		[learning rate: 0.00032937]
	Learning Rate: 0.00032937
	LOSS [training: 0.44130210315590707 | validation: 0.472100465709098]
	TIME [epoch: 9.46 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4571069170774778		[learning rate: 0.00032817]
	Learning Rate: 0.000328175
	LOSS [training: 0.4571069170774778 | validation: 0.5345651805600344]
	TIME [epoch: 9.44 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4388658850601018		[learning rate: 0.00032698]
	Learning Rate: 0.000326984
	LOSS [training: 0.4388658850601018 | validation: 0.5257040026251599]
	TIME [epoch: 9.43 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4583871055408582		[learning rate: 0.0003258]
	Learning Rate: 0.000325797
	LOSS [training: 0.4583871055408582 | validation: 0.49474628133691056]
	TIME [epoch: 9.44 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4667675686810169		[learning rate: 0.00032461]
	Learning Rate: 0.000324615
	LOSS [training: 0.4667675686810169 | validation: 0.5275719745612856]
	TIME [epoch: 9.46 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44842144405649575		[learning rate: 0.00032344]
	Learning Rate: 0.000323437
	LOSS [training: 0.44842144405649575 | validation: 0.5395808609569156]
	TIME [epoch: 9.44 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4808883911430276		[learning rate: 0.00032226]
	Learning Rate: 0.000322263
	LOSS [training: 0.4808883911430276 | validation: 0.5399490437359014]
	TIME [epoch: 9.43 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43480329509803683		[learning rate: 0.00032109]
	Learning Rate: 0.000321094
	LOSS [training: 0.43480329509803683 | validation: 0.5435075637994412]
	TIME [epoch: 9.43 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46754959121480716		[learning rate: 0.00031993]
	Learning Rate: 0.000319928
	LOSS [training: 0.46754959121480716 | validation: 0.5261229317392045]
	TIME [epoch: 9.46 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45526957784034716		[learning rate: 0.00031877]
	Learning Rate: 0.000318767
	LOSS [training: 0.45526957784034716 | validation: 0.4387565486966391]
	TIME [epoch: 9.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_1048.pth
	Model improved!!!
EPOCH 1049/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4541905317268021		[learning rate: 0.00031761]
	Learning Rate: 0.000317611
	LOSS [training: 0.4541905317268021 | validation: 0.4920467216886906]
	TIME [epoch: 9.43 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4770333720966099		[learning rate: 0.00031646]
	Learning Rate: 0.000316458
	LOSS [training: 0.4770333720966099 | validation: 0.4902038868564159]
	TIME [epoch: 9.44 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4417461876055545		[learning rate: 0.00031531]
	Learning Rate: 0.000315309
	LOSS [training: 0.4417461876055545 | validation: 0.5480322137521431]
	TIME [epoch: 9.45 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4541270804029325		[learning rate: 0.00031417]
	Learning Rate: 0.000314165
	LOSS [training: 0.4541270804029325 | validation: 0.49008678107239806]
	TIME [epoch: 9.43 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4404911178004989		[learning rate: 0.00031302]
	Learning Rate: 0.000313025
	LOSS [training: 0.4404911178004989 | validation: 0.5436852986543553]
	TIME [epoch: 9.44 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4524149403807532		[learning rate: 0.00031189]
	Learning Rate: 0.000311889
	LOSS [training: 0.4524149403807532 | validation: 0.5054728514651311]
	TIME [epoch: 9.45 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45105658127858045		[learning rate: 0.00031076]
	Learning Rate: 0.000310757
	LOSS [training: 0.45105658127858045 | validation: 0.472874077694878]
	TIME [epoch: 9.44 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46441966303034976		[learning rate: 0.00030963]
	Learning Rate: 0.000309629
	LOSS [training: 0.46441966303034976 | validation: 0.6053830331349778]
	TIME [epoch: 9.43 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45468579262938996		[learning rate: 0.00030851]
	Learning Rate: 0.000308506
	LOSS [training: 0.45468579262938996 | validation: 0.5773429685181202]
	TIME [epoch: 9.43 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4568322205827551		[learning rate: 0.00030739]
	Learning Rate: 0.000307386
	LOSS [training: 0.4568322205827551 | validation: 0.5196597635089001]
	TIME [epoch: 9.45 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4453188870864718		[learning rate: 0.00030627]
	Learning Rate: 0.000306271
	LOSS [training: 0.4453188870864718 | validation: 0.49667065070869953]
	TIME [epoch: 9.44 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4379781019695361		[learning rate: 0.00030516]
	Learning Rate: 0.000305159
	LOSS [training: 0.4379781019695361 | validation: 0.4936401645746616]
	TIME [epoch: 9.43 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44837984527476493		[learning rate: 0.00030405]
	Learning Rate: 0.000304052
	LOSS [training: 0.44837984527476493 | validation: 0.6574687550178879]
	TIME [epoch: 9.43 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45842470097676563		[learning rate: 0.00030295]
	Learning Rate: 0.000302948
	LOSS [training: 0.45842470097676563 | validation: 0.5109602617626529]
	TIME [epoch: 9.46 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45259431528220206		[learning rate: 0.00030185]
	Learning Rate: 0.000301849
	LOSS [training: 0.45259431528220206 | validation: 0.47066582680885277]
	TIME [epoch: 9.43 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4400759379621599		[learning rate: 0.00030075]
	Learning Rate: 0.000300753
	LOSS [training: 0.4400759379621599 | validation: 0.5052186750516264]
	TIME [epoch: 9.43 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4466998140517687		[learning rate: 0.00029966]
	Learning Rate: 0.000299662
	LOSS [training: 0.4466998140517687 | validation: 0.4679044436929607]
	TIME [epoch: 9.43 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4375746788786479		[learning rate: 0.00029857]
	Learning Rate: 0.000298574
	LOSS [training: 0.4375746788786479 | validation: 0.4978420270055655]
	TIME [epoch: 9.46 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43393172296301524		[learning rate: 0.00029749]
	Learning Rate: 0.000297491
	LOSS [training: 0.43393172296301524 | validation: 0.47916623847951156]
	TIME [epoch: 9.43 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4583068041813007		[learning rate: 0.00029641]
	Learning Rate: 0.000296411
	LOSS [training: 0.4583068041813007 | validation: 0.5064180614259034]
	TIME [epoch: 9.43 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4444035851100484		[learning rate: 0.00029534]
	Learning Rate: 0.000295336
	LOSS [training: 0.4444035851100484 | validation: 0.5248552185986424]
	TIME [epoch: 9.44 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4459185475969182		[learning rate: 0.00029426]
	Learning Rate: 0.000294264
	LOSS [training: 0.4459185475969182 | validation: 0.44589549943900963]
	TIME [epoch: 9.45 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44360890336852615		[learning rate: 0.0002932]
	Learning Rate: 0.000293196
	LOSS [training: 0.44360890336852615 | validation: 0.4661880666096372]
	TIME [epoch: 9.43 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44181579733567145		[learning rate: 0.00029213]
	Learning Rate: 0.000292132
	LOSS [training: 0.44181579733567145 | validation: 0.48550217229644815]
	TIME [epoch: 9.43 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4620615492083804		[learning rate: 0.00029107]
	Learning Rate: 0.000291072
	LOSS [training: 0.4620615492083804 | validation: 0.5082537693949837]
	TIME [epoch: 9.45 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44371985851031964		[learning rate: 0.00029002]
	Learning Rate: 0.000290015
	LOSS [training: 0.44371985851031964 | validation: 0.46966804330065004]
	TIME [epoch: 9.44 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45455796703077256		[learning rate: 0.00028896]
	Learning Rate: 0.000288963
	LOSS [training: 0.45455796703077256 | validation: 0.5315674833921898]
	TIME [epoch: 9.44 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4359522454725992		[learning rate: 0.00028791]
	Learning Rate: 0.000287914
	LOSS [training: 0.4359522454725992 | validation: 0.4765907913977819]
	TIME [epoch: 9.43 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4270439925394589		[learning rate: 0.00028687]
	Learning Rate: 0.000286869
	LOSS [training: 0.4270439925394589 | validation: 0.48165183975865933]
	TIME [epoch: 9.45 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44656450680990745		[learning rate: 0.00028583]
	Learning Rate: 0.000285828
	LOSS [training: 0.44656450680990745 | validation: 0.4672011522702331]
	TIME [epoch: 9.44 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4307036290625577		[learning rate: 0.00028479]
	Learning Rate: 0.000284791
	LOSS [training: 0.4307036290625577 | validation: 0.5088349339193176]
	TIME [epoch: 9.44 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.423947878077667		[learning rate: 0.00028376]
	Learning Rate: 0.000283758
	LOSS [training: 0.423947878077667 | validation: 0.5034733789373559]
	TIME [epoch: 9.43 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4534899026838515		[learning rate: 0.00028273]
	Learning Rate: 0.000282728
	LOSS [training: 0.4534899026838515 | validation: 0.4319777454910988]
	TIME [epoch: 9.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_1081.pth
	Model improved!!!
EPOCH 1082/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4353144355646451		[learning rate: 0.0002817]
	Learning Rate: 0.000281702
	LOSS [training: 0.4353144355646451 | validation: 0.5245503645491817]
	TIME [epoch: 9.43 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4610517531317372		[learning rate: 0.00028068]
	Learning Rate: 0.000280679
	LOSS [training: 0.4610517531317372 | validation: 0.5200272550338662]
	TIME [epoch: 9.43 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45760124379789263		[learning rate: 0.00027966]
	Learning Rate: 0.000279661
	LOSS [training: 0.45760124379789263 | validation: 0.4833266214545269]
	TIME [epoch: 9.43 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4383287976376808		[learning rate: 0.00027865]
	Learning Rate: 0.000278646
	LOSS [training: 0.4383287976376808 | validation: 0.5058289212802807]
	TIME [epoch: 9.46 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44309716135689825		[learning rate: 0.00027763]
	Learning Rate: 0.000277635
	LOSS [training: 0.44309716135689825 | validation: 0.4627193844581971]
	TIME [epoch: 9.43 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43180401094583987		[learning rate: 0.00027663]
	Learning Rate: 0.000276627
	LOSS [training: 0.43180401094583987 | validation: 0.47111548897679567]
	TIME [epoch: 9.43 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4293341978494256		[learning rate: 0.00027562]
	Learning Rate: 0.000275623
	LOSS [training: 0.4293341978494256 | validation: 0.4369403857913815]
	TIME [epoch: 9.43 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43516000087899054		[learning rate: 0.00027462]
	Learning Rate: 0.000274623
	LOSS [training: 0.43516000087899054 | validation: 0.5721356524025302]
	TIME [epoch: 9.45 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44368241797375935		[learning rate: 0.00027363]
	Learning Rate: 0.000273626
	LOSS [training: 0.44368241797375935 | validation: 0.5244921750674737]
	TIME [epoch: 9.43 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45720926644912196		[learning rate: 0.00027263]
	Learning Rate: 0.000272633
	LOSS [training: 0.45720926644912196 | validation: 0.506414325039699]
	TIME [epoch: 9.43 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4580936359663907		[learning rate: 0.00027164]
	Learning Rate: 0.000271644
	LOSS [training: 0.4580936359663907 | validation: 0.5148594763167222]
	TIME [epoch: 9.44 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44401499844775955		[learning rate: 0.00027066]
	Learning Rate: 0.000270658
	LOSS [training: 0.44401499844775955 | validation: 0.539955400060319]
	TIME [epoch: 9.45 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4523144006222107		[learning rate: 0.00026968]
	Learning Rate: 0.000269676
	LOSS [training: 0.4523144006222107 | validation: 0.5284849746548878]
	TIME [epoch: 9.43 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42141256553981765		[learning rate: 0.0002687]
	Learning Rate: 0.000268697
	LOSS [training: 0.42141256553981765 | validation: 0.4613955159703232]
	TIME [epoch: 9.43 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4348014080274815		[learning rate: 0.00026772]
	Learning Rate: 0.000267722
	LOSS [training: 0.4348014080274815 | validation: 0.4705487834340154]
	TIME [epoch: 9.45 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4438954474712785		[learning rate: 0.00026675]
	Learning Rate: 0.000266751
	LOSS [training: 0.4438954474712785 | validation: 0.5011697001043811]
	TIME [epoch: 9.44 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42599004205217667		[learning rate: 0.00026578]
	Learning Rate: 0.000265782
	LOSS [training: 0.42599004205217667 | validation: 0.48131299844538256]
	TIME [epoch: 9.43 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44301812151726494		[learning rate: 0.00026482]
	Learning Rate: 0.000264818
	LOSS [training: 0.44301812151726494 | validation: 0.4773028729488919]
	TIME [epoch: 9.43 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43206688720929726		[learning rate: 0.00026386]
	Learning Rate: 0.000263857
	LOSS [training: 0.43206688720929726 | validation: 0.5196116799677667]
	TIME [epoch: 9.46 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44076282774177145		[learning rate: 0.0002629]
	Learning Rate: 0.000262899
	LOSS [training: 0.44076282774177145 | validation: 0.4632892563002334]
	TIME [epoch: 9.43 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43416106327523973		[learning rate: 0.00026195]
	Learning Rate: 0.000261945
	LOSS [training: 0.43416106327523973 | validation: 0.43054956528538624]
	TIME [epoch: 9.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_1102.pth
	Model improved!!!
EPOCH 1103/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44415619935370765		[learning rate: 0.00026099]
	Learning Rate: 0.000260995
	LOSS [training: 0.44415619935370765 | validation: 0.4720596557641863]
	TIME [epoch: 9.44 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42496690327576037		[learning rate: 0.00026005]
	Learning Rate: 0.000260047
	LOSS [training: 0.42496690327576037 | validation: 0.43612554653920355]
	TIME [epoch: 9.45 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45997512233205456		[learning rate: 0.0002591]
	Learning Rate: 0.000259104
	LOSS [training: 0.45997512233205456 | validation: 0.487273009224061]
	TIME [epoch: 9.43 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4559182982302417		[learning rate: 0.00025816]
	Learning Rate: 0.000258163
	LOSS [training: 0.4559182982302417 | validation: 0.5257598689176192]
	TIME [epoch: 9.43 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42097684594479257		[learning rate: 0.00025723]
	Learning Rate: 0.000257227
	LOSS [training: 0.42097684594479257 | validation: 0.5318987306584934]
	TIME [epoch: 9.43 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4325901673715743		[learning rate: 0.00025629]
	Learning Rate: 0.000256293
	LOSS [training: 0.4325901673715743 | validation: 0.5755647601660009]
	TIME [epoch: 9.46 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4511112743971566		[learning rate: 0.00025536]
	Learning Rate: 0.000255363
	LOSS [training: 0.4511112743971566 | validation: 0.44091661565557155]
	TIME [epoch: 9.43 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43689736960642656		[learning rate: 0.00025444]
	Learning Rate: 0.000254436
	LOSS [training: 0.43689736960642656 | validation: 0.4891798021128033]
	TIME [epoch: 9.43 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41982526660676484		[learning rate: 0.00025351]
	Learning Rate: 0.000253513
	LOSS [training: 0.41982526660676484 | validation: 0.48707316163303943]
	TIME [epoch: 9.44 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4240848651408097		[learning rate: 0.00025259]
	Learning Rate: 0.000252593
	LOSS [training: 0.4240848651408097 | validation: 0.5196359096191643]
	TIME [epoch: 9.45 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41422822383785834		[learning rate: 0.00025168]
	Learning Rate: 0.000251676
	LOSS [training: 0.41422822383785834 | validation: 0.4492218585641551]
	TIME [epoch: 9.43 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43641563533488653		[learning rate: 0.00025076]
	Learning Rate: 0.000250763
	LOSS [training: 0.43641563533488653 | validation: 0.4403592042020803]
	TIME [epoch: 9.43 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43224682267274356		[learning rate: 0.00024985]
	Learning Rate: 0.000249853
	LOSS [training: 0.43224682267274356 | validation: 0.48212851016175395]
	TIME [epoch: 9.45 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44865292889456565		[learning rate: 0.00024895]
	Learning Rate: 0.000248946
	LOSS [training: 0.44865292889456565 | validation: 0.5470171399982497]
	TIME [epoch: 9.44 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4578994356169		[learning rate: 0.00024804]
	Learning Rate: 0.000248043
	LOSS [training: 0.4578994356169 | validation: 0.49687755310682175]
	TIME [epoch: 9.43 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4352067965478893		[learning rate: 0.00024714]
	Learning Rate: 0.000247142
	LOSS [training: 0.4352067965478893 | validation: 0.47502057579779144]
	TIME [epoch: 9.43 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4610726192666049		[learning rate: 0.00024625]
	Learning Rate: 0.000246246
	LOSS [training: 0.4610726192666049 | validation: 0.45669812628163214]
	TIME [epoch: 9.45 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44808191595080976		[learning rate: 0.00024535]
	Learning Rate: 0.000245352
	LOSS [training: 0.44808191595080976 | validation: 0.43074966659981995]
	TIME [epoch: 9.43 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45112538137114455		[learning rate: 0.00024446]
	Learning Rate: 0.000244462
	LOSS [training: 0.45112538137114455 | validation: 0.5183898193705996]
	TIME [epoch: 9.43 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44779596292834467		[learning rate: 0.00024357]
	Learning Rate: 0.000243574
	LOSS [training: 0.44779596292834467 | validation: 0.4924856702427385]
	TIME [epoch: 9.43 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46584561272106206		[learning rate: 0.00024269]
	Learning Rate: 0.00024269
	LOSS [training: 0.46584561272106206 | validation: 0.4610966050961139]
	TIME [epoch: 9.46 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4329055020022768		[learning rate: 0.00024181]
	Learning Rate: 0.00024181
	LOSS [training: 0.4329055020022768 | validation: 0.4811083555939088]
	TIME [epoch: 9.43 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43434631450413796		[learning rate: 0.00024093]
	Learning Rate: 0.000240932
	LOSS [training: 0.43434631450413796 | validation: 0.4658865932996805]
	TIME [epoch: 9.43 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4366821960113376		[learning rate: 0.00024006]
	Learning Rate: 0.000240058
	LOSS [training: 0.4366821960113376 | validation: 0.521980132857032]
	TIME [epoch: 9.43 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44234191359415326		[learning rate: 0.00023919]
	Learning Rate: 0.000239187
	LOSS [training: 0.44234191359415326 | validation: 0.4785106429480499]
	TIME [epoch: 9.45 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4285181812122933		[learning rate: 0.00023832]
	Learning Rate: 0.000238319
	LOSS [training: 0.4285181812122933 | validation: 0.5208640112234413]
	TIME [epoch: 9.43 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44466510283178995		[learning rate: 0.00023745]
	Learning Rate: 0.000237454
	LOSS [training: 0.44466510283178995 | validation: 0.4786724913310441]
	TIME [epoch: 9.43 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46291142086965376		[learning rate: 0.00023659]
	Learning Rate: 0.000236592
	LOSS [training: 0.46291142086965376 | validation: 0.4531113273025858]
	TIME [epoch: 9.46 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45392453913304187		[learning rate: 0.00023573]
	Learning Rate: 0.000235733
	LOSS [training: 0.45392453913304187 | validation: 0.4979650599179084]
	TIME [epoch: 9.46 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4366790450971651		[learning rate: 0.00023488]
	Learning Rate: 0.000234878
	LOSS [training: 0.4366790450971651 | validation: 0.48923024524598613]
	TIME [epoch: 9.43 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43232892612647456		[learning rate: 0.00023403]
	Learning Rate: 0.000234026
	LOSS [training: 0.43232892612647456 | validation: 0.4525789183269228]
	TIME [epoch: 9.43 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43511698590023223		[learning rate: 0.00023318]
	Learning Rate: 0.000233176
	LOSS [training: 0.43511698590023223 | validation: 0.48812930320222464]
	TIME [epoch: 9.44 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44119569559958816		[learning rate: 0.00023233]
	Learning Rate: 0.00023233
	LOSS [training: 0.44119569559958816 | validation: 0.4535422219234981]
	TIME [epoch: 9.45 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4222237974283972		[learning rate: 0.00023149]
	Learning Rate: 0.000231487
	LOSS [training: 0.4222237974283972 | validation: 0.5467547997116067]
	TIME [epoch: 9.43 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4216381374781387		[learning rate: 0.00023065]
	Learning Rate: 0.000230647
	LOSS [training: 0.4216381374781387 | validation: 0.5095152838190877]
	TIME [epoch: 9.43 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4276162987905515		[learning rate: 0.00022981]
	Learning Rate: 0.00022981
	LOSS [training: 0.4276162987905515 | validation: 0.4855559213327466]
	TIME [epoch: 9.45 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45002010922226343		[learning rate: 0.00022898]
	Learning Rate: 0.000228976
	LOSS [training: 0.45002010922226343 | validation: 0.53185650258094]
	TIME [epoch: 9.44 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43287589155127015		[learning rate: 0.00022814]
	Learning Rate: 0.000228145
	LOSS [training: 0.43287589155127015 | validation: 0.5079084562325621]
	TIME [epoch: 9.43 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42034721729841956		[learning rate: 0.00022732]
	Learning Rate: 0.000227317
	LOSS [training: 0.42034721729841956 | validation: 0.4670960556686803]
	TIME [epoch: 9.43 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43953712393803557		[learning rate: 0.00022649]
	Learning Rate: 0.000226492
	LOSS [training: 0.43953712393803557 | validation: 0.5169253351657322]
	TIME [epoch: 9.45 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4276560543384614		[learning rate: 0.00022567]
	Learning Rate: 0.00022567
	LOSS [training: 0.4276560543384614 | validation: 0.46648984508419133]
	TIME [epoch: 9.43 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4221176086376917		[learning rate: 0.00022485]
	Learning Rate: 0.000224851
	LOSS [training: 0.4221176086376917 | validation: 0.5105404785546506]
	TIME [epoch: 9.43 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4441224034904449		[learning rate: 0.00022403]
	Learning Rate: 0.000224035
	LOSS [training: 0.4441224034904449 | validation: 0.4873545275455565]
	TIME [epoch: 9.43 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4268330608069242		[learning rate: 0.00022322]
	Learning Rate: 0.000223222
	LOSS [training: 0.4268330608069242 | validation: 0.4814912381238534]
	TIME [epoch: 9.45 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44603168184813163		[learning rate: 0.00022241]
	Learning Rate: 0.000222412
	LOSS [training: 0.44603168184813163 | validation: 0.48556794084656046]
	TIME [epoch: 9.43 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4444613236504746		[learning rate: 0.0002216]
	Learning Rate: 0.000221605
	LOSS [training: 0.4444613236504746 | validation: 0.4135597064076025]
	TIME [epoch: 9.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_1148.pth
	Model improved!!!
EPOCH 1149/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44393871718804256		[learning rate: 0.0002208]
	Learning Rate: 0.0002208
	LOSS [training: 0.44393871718804256 | validation: 0.4972965848654897]
	TIME [epoch: 9.46 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43280758934649777		[learning rate: 0.00022]
	Learning Rate: 0.000219999
	LOSS [training: 0.43280758934649777 | validation: 0.5075427737626895]
	TIME [epoch: 9.45 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4383062410750229		[learning rate: 0.0002192]
	Learning Rate: 0.000219201
	LOSS [training: 0.4383062410750229 | validation: 0.4524431263427976]
	TIME [epoch: 9.43 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43519543788094606		[learning rate: 0.00021841]
	Learning Rate: 0.000218405
	LOSS [training: 0.43519543788094606 | validation: 0.4785903869702139]
	TIME [epoch: 9.44 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.440087507423533		[learning rate: 0.00021761]
	Learning Rate: 0.000217613
	LOSS [training: 0.440087507423533 | validation: 0.5018708714322991]
	TIME [epoch: 9.44 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4441074872724885		[learning rate: 0.00021682]
	Learning Rate: 0.000216823
	LOSS [training: 0.4441074872724885 | validation: 0.4688919419528773]
	TIME [epoch: 9.45 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4277621639392638		[learning rate: 0.00021604]
	Learning Rate: 0.000216036
	LOSS [training: 0.4277621639392638 | validation: 0.4849170580962303]
	TIME [epoch: 9.43 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42540612250001975		[learning rate: 0.00021525]
	Learning Rate: 0.000215252
	LOSS [training: 0.42540612250001975 | validation: 0.46799771237884286]
	TIME [epoch: 9.43 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4229812339749894		[learning rate: 0.00021447]
	Learning Rate: 0.000214471
	LOSS [training: 0.4229812339749894 | validation: 0.4586716599006688]
	TIME [epoch: 9.45 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4194930403967184		[learning rate: 0.00021369]
	Learning Rate: 0.000213693
	LOSS [training: 0.4194930403967184 | validation: 0.45769927618158235]
	TIME [epoch: 9.44 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42157845880340405		[learning rate: 0.00021292]
	Learning Rate: 0.000212917
	LOSS [training: 0.42157845880340405 | validation: 0.4846170468132736]
	TIME [epoch: 9.43 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4289088922488687		[learning rate: 0.00021214]
	Learning Rate: 0.000212144
	LOSS [training: 0.4289088922488687 | validation: 0.4556577021897239]
	TIME [epoch: 9.43 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43106528207386574		[learning rate: 0.00021137]
	Learning Rate: 0.000211375
	LOSS [training: 0.43106528207386574 | validation: 0.48499288911482635]
	TIME [epoch: 9.45 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45668822189455655		[learning rate: 0.00021061]
	Learning Rate: 0.000210607
	LOSS [training: 0.45668822189455655 | validation: 0.47805448283873136]
	TIME [epoch: 9.43 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4356690634794841		[learning rate: 0.00020984]
	Learning Rate: 0.000209843
	LOSS [training: 0.4356690634794841 | validation: 0.5036520843668275]
	TIME [epoch: 9.43 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41515612563161924		[learning rate: 0.00020908]
	Learning Rate: 0.000209082
	LOSS [training: 0.41515612563161924 | validation: 0.507214230159581]
	TIME [epoch: 9.42 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48089949718465624		[learning rate: 0.00020832]
	Learning Rate: 0.000208323
	LOSS [training: 0.48089949718465624 | validation: 0.6083877425210268]
	TIME [epoch: 9.45 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45710985847213437		[learning rate: 0.00020757]
	Learning Rate: 0.000207567
	LOSS [training: 0.45710985847213437 | validation: 0.5180691557998048]
	TIME [epoch: 9.43 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43139642189757643		[learning rate: 0.00020681]
	Learning Rate: 0.000206814
	LOSS [training: 0.43139642189757643 | validation: 0.4721350295708859]
	TIME [epoch: 9.43 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43231614121117723		[learning rate: 0.00020606]
	Learning Rate: 0.000206063
	LOSS [training: 0.43231614121117723 | validation: 0.4525047187874449]
	TIME [epoch: 9.43 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4335967626749896		[learning rate: 0.00020532]
	Learning Rate: 0.000205315
	LOSS [training: 0.4335967626749896 | validation: 0.4982933772866886]
	TIME [epoch: 9.45 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42770946268047777		[learning rate: 0.00020457]
	Learning Rate: 0.00020457
	LOSS [training: 0.42770946268047777 | validation: 0.5026710412425963]
	TIME [epoch: 9.43 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43717329479741174		[learning rate: 0.00020383]
	Learning Rate: 0.000203828
	LOSS [training: 0.43717329479741174 | validation: 0.4826317406264734]
	TIME [epoch: 9.43 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4338394274897438		[learning rate: 0.00020309]
	Learning Rate: 0.000203088
	LOSS [training: 0.4338394274897438 | validation: 0.45735320873272195]
	TIME [epoch: 9.43 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4246932256142541		[learning rate: 0.00020235]
	Learning Rate: 0.000202351
	LOSS [training: 0.4246932256142541 | validation: 0.4435820193681832]
	TIME [epoch: 9.45 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41167576590389343		[learning rate: 0.00020162]
	Learning Rate: 0.000201617
	LOSS [training: 0.41167576590389343 | validation: 0.42782462308841984]
	TIME [epoch: 9.43 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42226174268317446		[learning rate: 0.00020088]
	Learning Rate: 0.000200885
	LOSS [training: 0.42226174268317446 | validation: 0.5084534842353665]
	TIME [epoch: 9.43 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43294714178304716		[learning rate: 0.00020016]
	Learning Rate: 0.000200156
	LOSS [training: 0.43294714178304716 | validation: 0.48192648963866924]
	TIME [epoch: 9.44 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41389567669795363		[learning rate: 0.00019943]
	Learning Rate: 0.00019943
	LOSS [training: 0.41389567669795363 | validation: 0.5132943671067691]
	TIME [epoch: 9.45 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4117607198039108		[learning rate: 0.00019871]
	Learning Rate: 0.000198706
	LOSS [training: 0.4117607198039108 | validation: 0.44820571465266057]
	TIME [epoch: 9.43 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4574923164199756		[learning rate: 0.00019798]
	Learning Rate: 0.000197985
	LOSS [training: 0.4574923164199756 | validation: 0.48056279777611133]
	TIME [epoch: 9.43 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43276495729964815		[learning rate: 0.00019727]
	Learning Rate: 0.000197266
	LOSS [training: 0.43276495729964815 | validation: 0.4783231246415233]
	TIME [epoch: 9.45 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43189206192437546		[learning rate: 0.00019655]
	Learning Rate: 0.00019655
	LOSS [training: 0.43189206192437546 | validation: 0.462190859888687]
	TIME [epoch: 9.44 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44775581903042816		[learning rate: 0.00019584]
	Learning Rate: 0.000195837
	LOSS [training: 0.44775581903042816 | validation: 0.5252585708626115]
	TIME [epoch: 9.43 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4225052518547113		[learning rate: 0.00019513]
	Learning Rate: 0.000195126
	LOSS [training: 0.4225052518547113 | validation: 0.4583422539098674]
	TIME [epoch: 9.43 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41528485190326414		[learning rate: 0.00019442]
	Learning Rate: 0.000194418
	LOSS [training: 0.41528485190326414 | validation: 0.4312591128373539]
	TIME [epoch: 9.45 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4405544333951411		[learning rate: 0.00019371]
	Learning Rate: 0.000193713
	LOSS [training: 0.4405544333951411 | validation: 0.4873765442749696]
	TIME [epoch: 9.43 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4335682012719281		[learning rate: 0.00019301]
	Learning Rate: 0.00019301
	LOSS [training: 0.4335682012719281 | validation: 0.46982119622297164]
	TIME [epoch: 9.43 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43446409692703963		[learning rate: 0.00019231]
	Learning Rate: 0.000192309
	LOSS [training: 0.43446409692703963 | validation: 0.45103985516986933]
	TIME [epoch: 9.43 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4263036903109273		[learning rate: 0.00019161]
	Learning Rate: 0.000191611
	LOSS [training: 0.4263036903109273 | validation: 0.5267777824560091]
	TIME [epoch: 9.45 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41477559855422086		[learning rate: 0.00019092]
	Learning Rate: 0.000190916
	LOSS [training: 0.41477559855422086 | validation: 0.46535273618065065]
	TIME [epoch: 9.43 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41620437634559104		[learning rate: 0.00019022]
	Learning Rate: 0.000190223
	LOSS [training: 0.41620437634559104 | validation: 0.5051810677753938]
	TIME [epoch: 9.43 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4202786677827848		[learning rate: 0.00018953]
	Learning Rate: 0.000189533
	LOSS [training: 0.4202786677827848 | validation: 0.4441420713206495]
	TIME [epoch: 9.43 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42875590050558066		[learning rate: 0.00018884]
	Learning Rate: 0.000188845
	LOSS [training: 0.42875590050558066 | validation: 0.5139696838012584]
	TIME [epoch: 9.46 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4229054063769654		[learning rate: 0.00018816]
	Learning Rate: 0.00018816
	LOSS [training: 0.4229054063769654 | validation: 0.4388970235832646]
	TIME [epoch: 9.43 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40610462296772043		[learning rate: 0.00018748]
	Learning Rate: 0.000187477
	LOSS [training: 0.40610462296772043 | validation: 0.4510302347859451]
	TIME [epoch: 9.43 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.419536629677156		[learning rate: 0.0001868]
	Learning Rate: 0.000186796
	LOSS [training: 0.419536629677156 | validation: 0.5119671591331282]
	TIME [epoch: 9.44 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4139588278168015		[learning rate: 0.00018612]
	Learning Rate: 0.000186119
	LOSS [training: 0.4139588278168015 | validation: 0.44688700285293137]
	TIME [epoch: 9.45 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4388404625100658		[learning rate: 0.00018544]
	Learning Rate: 0.000185443
	LOSS [training: 0.4388404625100658 | validation: 0.49488152890203924]
	TIME [epoch: 9.43 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42335373964336026		[learning rate: 0.00018477]
	Learning Rate: 0.00018477
	LOSS [training: 0.42335373964336026 | validation: 0.49834669237170304]
	TIME [epoch: 9.43 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4272356810257225		[learning rate: 0.0001841]
	Learning Rate: 0.000184099
	LOSS [training: 0.4272356810257225 | validation: 0.4776851989743568]
	TIME [epoch: 9.45 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41348852925362073		[learning rate: 0.00018343]
	Learning Rate: 0.000183431
	LOSS [training: 0.41348852925362073 | validation: 0.4761511585756988]
	TIME [epoch: 9.44 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4072488909745375		[learning rate: 0.00018277]
	Learning Rate: 0.000182766
	LOSS [training: 0.4072488909745375 | validation: 0.49608506302815825]
	TIME [epoch: 9.43 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40911858304882065		[learning rate: 0.0001821]
	Learning Rate: 0.000182102
	LOSS [training: 0.40911858304882065 | validation: 0.4514711630875261]
	TIME [epoch: 9.43 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4318724107322189		[learning rate: 0.00018144]
	Learning Rate: 0.000181442
	LOSS [training: 0.4318724107322189 | validation: 0.46459452760068476]
	TIME [epoch: 9.45 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4147760399015679		[learning rate: 0.00018078]
	Learning Rate: 0.000180783
	LOSS [training: 0.4147760399015679 | validation: 0.4590557669592319]
	TIME [epoch: 9.43 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41543790506731726		[learning rate: 0.00018013]
	Learning Rate: 0.000180127
	LOSS [training: 0.41543790506731726 | validation: 0.48419779773497085]
	TIME [epoch: 9.43 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4252981693876923		[learning rate: 0.00017947]
	Learning Rate: 0.000179473
	LOSS [training: 0.4252981693876923 | validation: 0.41975874705674093]
	TIME [epoch: 9.43 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4288886726953966		[learning rate: 0.00017882]
	Learning Rate: 0.000178822
	LOSS [training: 0.4288886726953966 | validation: 0.4575493186930326]
	TIME [epoch: 9.45 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41790089257544594		[learning rate: 0.00017817]
	Learning Rate: 0.000178173
	LOSS [training: 0.41790089257544594 | validation: 0.45878621647111656]
	TIME [epoch: 9.44 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41848205187955223		[learning rate: 0.00017753]
	Learning Rate: 0.000177526
	LOSS [training: 0.41848205187955223 | validation: 0.4653317685398599]
	TIME [epoch: 9.43 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42514794091875235		[learning rate: 0.00017688]
	Learning Rate: 0.000176882
	LOSS [training: 0.42514794091875235 | validation: 0.45040486075841585]
	TIME [epoch: 9.43 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4329739126500912		[learning rate: 0.00017624]
	Learning Rate: 0.00017624
	LOSS [training: 0.4329739126500912 | validation: 0.4891048163707275]
	TIME [epoch: 9.46 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41264574773255813		[learning rate: 0.0001756]
	Learning Rate: 0.000175601
	LOSS [training: 0.41264574773255813 | validation: 0.4910345603651989]
	TIME [epoch: 9.43 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4359214608386052		[learning rate: 0.00017496]
	Learning Rate: 0.000174964
	LOSS [training: 0.4359214608386052 | validation: 0.4687776036246262]
	TIME [epoch: 9.43 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40950133195691485		[learning rate: 0.00017433]
	Learning Rate: 0.000174329
	LOSS [training: 0.40950133195691485 | validation: 0.4333960834244677]
	TIME [epoch: 9.43 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4290826903098813		[learning rate: 0.0001737]
	Learning Rate: 0.000173696
	LOSS [training: 0.4290826903098813 | validation: 0.4946833986269739]
	TIME [epoch: 9.46 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4124812506877741		[learning rate: 0.00017307]
	Learning Rate: 0.000173066
	LOSS [training: 0.4124812506877741 | validation: 0.44747925157192103]
	TIME [epoch: 9.43 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4203711784505887		[learning rate: 0.00017244]
	Learning Rate: 0.000172437
	LOSS [training: 0.4203711784505887 | validation: 0.47923650551353236]
	TIME [epoch: 9.43 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42221475885017784		[learning rate: 0.00017181]
	Learning Rate: 0.000171812
	LOSS [training: 0.42221475885017784 | validation: 0.47941956426058574]
	TIME [epoch: 9.43 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4100927690635129		[learning rate: 0.00017119]
	Learning Rate: 0.000171188
	LOSS [training: 0.4100927690635129 | validation: 0.45465002419581274]
	TIME [epoch: 9.45 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41683532171515136		[learning rate: 0.00017057]
	Learning Rate: 0.000170567
	LOSS [training: 0.41683532171515136 | validation: 0.4521532378736305]
	TIME [epoch: 9.43 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4103839326493617		[learning rate: 0.00016995]
	Learning Rate: 0.000169948
	LOSS [training: 0.4103839326493617 | validation: 0.4730027791946496]
	TIME [epoch: 9.43 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42021111756183416		[learning rate: 0.00016933]
	Learning Rate: 0.000169331
	LOSS [training: 0.42021111756183416 | validation: 0.4259705565346924]
	TIME [epoch: 9.45 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41581918113872174		[learning rate: 0.00016872]
	Learning Rate: 0.000168717
	LOSS [training: 0.41581918113872174 | validation: 0.508925458877007]
	TIME [epoch: 9.44 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41631188795556984		[learning rate: 0.0001681]
	Learning Rate: 0.000168104
	LOSS [training: 0.41631188795556984 | validation: 0.45592473208203904]
	TIME [epoch: 9.43 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4269626046835168		[learning rate: 0.00016749]
	Learning Rate: 0.000167494
	LOSS [training: 0.4269626046835168 | validation: 0.46100115127093305]
	TIME [epoch: 9.43 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4206938610458981		[learning rate: 0.00016689]
	Learning Rate: 0.000166886
	LOSS [training: 0.4206938610458981 | validation: 0.4736389584582261]
	TIME [epoch: 9.45 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.436747071210846		[learning rate: 0.00016628]
	Learning Rate: 0.000166281
	LOSS [training: 0.436747071210846 | validation: 0.42797230847477225]
	TIME [epoch: 9.44 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.414591202286135		[learning rate: 0.00016568]
	Learning Rate: 0.000165677
	LOSS [training: 0.414591202286135 | validation: 0.488071105097436]
	TIME [epoch: 9.43 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4241410866398224		[learning rate: 0.00016508]
	Learning Rate: 0.000165076
	LOSS [training: 0.4241410866398224 | validation: 0.5717084794491579]
	TIME [epoch: 9.43 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43700975948202336		[learning rate: 0.00016448]
	Learning Rate: 0.000164477
	LOSS [training: 0.43700975948202336 | validation: 0.47139008612828437]
	TIME [epoch: 9.46 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44921698123204834		[learning rate: 0.00016388]
	Learning Rate: 0.00016388
	LOSS [training: 0.44921698123204834 | validation: 0.5510994853987965]
	TIME [epoch: 9.44 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43971258395243273		[learning rate: 0.00016329]
	Learning Rate: 0.000163285
	LOSS [training: 0.43971258395243273 | validation: 0.5008254406386871]
	TIME [epoch: 9.43 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41923596858075135		[learning rate: 0.00016269]
	Learning Rate: 0.000162693
	LOSS [training: 0.41923596858075135 | validation: 0.48645808939706897]
	TIME [epoch: 9.43 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.457567892148		[learning rate: 0.0001621]
	Learning Rate: 0.000162102
	LOSS [training: 0.457567892148 | validation: 0.5240689243819304]
	TIME [epoch: 9.46 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4162347155173018		[learning rate: 0.00016151]
	Learning Rate: 0.000161514
	LOSS [training: 0.4162347155173018 | validation: 0.4847440004813149]
	TIME [epoch: 9.43 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4263821535237102		[learning rate: 0.00016093]
	Learning Rate: 0.000160928
	LOSS [training: 0.4263821535237102 | validation: 0.5021657605995249]
	TIME [epoch: 9.43 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42100642653007225		[learning rate: 0.00016034]
	Learning Rate: 0.000160344
	LOSS [training: 0.42100642653007225 | validation: 0.5119658552968922]
	TIME [epoch: 9.43 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4191307111148578		[learning rate: 0.00015976]
	Learning Rate: 0.000159762
	LOSS [training: 0.4191307111148578 | validation: 0.476956212365764]
	TIME [epoch: 9.45 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4083111605681983		[learning rate: 0.00015918]
	Learning Rate: 0.000159182
	LOSS [training: 0.4083111605681983 | validation: 0.4545198761197648]
	TIME [epoch: 9.43 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4278244184094211		[learning rate: 0.0001586]
	Learning Rate: 0.000158605
	LOSS [training: 0.4278244184094211 | validation: 0.5179068001642775]
	TIME [epoch: 9.43 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42272694708352543		[learning rate: 0.00015803]
	Learning Rate: 0.000158029
	LOSS [training: 0.42272694708352543 | validation: 0.49225018069053783]
	TIME [epoch: 9.44 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.416926335024064		[learning rate: 0.00015746]
	Learning Rate: 0.000157456
	LOSS [training: 0.416926335024064 | validation: 0.44824492139081956]
	TIME [epoch: 9.45 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4354526708518847		[learning rate: 0.00015688]
	Learning Rate: 0.000156884
	LOSS [training: 0.4354526708518847 | validation: 0.49278021077831013]
	TIME [epoch: 9.43 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40694619747711813		[learning rate: 0.00015631]
	Learning Rate: 0.000156315
	LOSS [training: 0.40694619747711813 | validation: 0.46561413139068925]
	TIME [epoch: 9.43 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41224039684789604		[learning rate: 0.00015575]
	Learning Rate: 0.000155748
	LOSS [training: 0.41224039684789604 | validation: 0.46328451782346675]
	TIME [epoch: 9.45 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4334258017585963		[learning rate: 0.00015518]
	Learning Rate: 0.000155182
	LOSS [training: 0.4334258017585963 | validation: 0.46919033638426494]
	TIME [epoch: 9.44 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42999753374964766		[learning rate: 0.00015462]
	Learning Rate: 0.000154619
	LOSS [training: 0.42999753374964766 | validation: 0.5201039410926991]
	TIME [epoch: 9.43 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4150874872491556		[learning rate: 0.00015406]
	Learning Rate: 0.000154058
	LOSS [training: 0.4150874872491556 | validation: 0.4184482132455658]
	TIME [epoch: 9.43 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.407614424362427		[learning rate: 0.0001535]
	Learning Rate: 0.000153499
	LOSS [training: 0.407614424362427 | validation: 0.4719721017988384]
	TIME [epoch: 9.45 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41634177117403814		[learning rate: 0.00015294]
	Learning Rate: 0.000152942
	LOSS [training: 0.41634177117403814 | validation: 0.4764182644580921]
	TIME [epoch: 9.43 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4181403326113055		[learning rate: 0.00015239]
	Learning Rate: 0.000152387
	LOSS [training: 0.4181403326113055 | validation: 0.43940459996339776]
	TIME [epoch: 9.43 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4333069586409751		[learning rate: 0.00015183]
	Learning Rate: 0.000151834
	LOSS [training: 0.4333069586409751 | validation: 0.4441047767134003]
	TIME [epoch: 9.43 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4198531165105267		[learning rate: 0.00015128]
	Learning Rate: 0.000151283
	LOSS [training: 0.4198531165105267 | validation: 0.49685423102294707]
	TIME [epoch: 9.46 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40890315960770307		[learning rate: 0.00015073]
	Learning Rate: 0.000150734
	LOSS [training: 0.40890315960770307 | validation: 0.5026280531944944]
	TIME [epoch: 9.43 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4121601383157186		[learning rate: 0.00015019]
	Learning Rate: 0.000150187
	LOSS [training: 0.4121601383157186 | validation: 0.5107836377721691]
	TIME [epoch: 9.43 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4125350385739065		[learning rate: 0.00014964]
	Learning Rate: 0.000149642
	LOSS [training: 0.4125350385739065 | validation: 0.4680318469238335]
	TIME [epoch: 9.43 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4176985709712605		[learning rate: 0.0001491]
	Learning Rate: 0.000149099
	LOSS [training: 0.4176985709712605 | validation: 0.46255368340426956]
	TIME [epoch: 9.45 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4048328882647801		[learning rate: 0.00014856]
	Learning Rate: 0.000148558
	LOSS [training: 0.4048328882647801 | validation: 0.4665412911477857]
	TIME [epoch: 9.43 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.423385204383802		[learning rate: 0.00014802]
	Learning Rate: 0.000148018
	LOSS [training: 0.423385204383802 | validation: 0.5080611761244845]
	TIME [epoch: 9.43 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4153008041788497		[learning rate: 0.00014748]
	Learning Rate: 0.000147481
	LOSS [training: 0.4153008041788497 | validation: 0.43418358806470886]
	TIME [epoch: 9.44 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3922451410130142		[learning rate: 0.00014695]
	Learning Rate: 0.000146946
	LOSS [training: 0.3922451410130142 | validation: 0.4789948593256854]
	TIME [epoch: 9.45 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4170658380975305		[learning rate: 0.00014641]
	Learning Rate: 0.000146413
	LOSS [training: 0.4170658380975305 | validation: 0.42897647913361747]
	TIME [epoch: 9.43 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40745029982317105		[learning rate: 0.00014588]
	Learning Rate: 0.000145881
	LOSS [training: 0.40745029982317105 | validation: 0.46648582280674233]
	TIME [epoch: 9.43 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.403812550398131		[learning rate: 0.00014535]
	Learning Rate: 0.000145352
	LOSS [training: 0.403812550398131 | validation: 0.4463874604579296]
	TIME [epoch: 9.45 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4317921065942064		[learning rate: 0.00014482]
	Learning Rate: 0.000144825
	LOSS [training: 0.4317921065942064 | validation: 0.48504505020655325]
	TIME [epoch: 9.44 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41743635287888364		[learning rate: 0.0001443]
	Learning Rate: 0.000144299
	LOSS [training: 0.41743635287888364 | validation: 0.45570609308095456]
	TIME [epoch: 9.43 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42655822236414237		[learning rate: 0.00014378]
	Learning Rate: 0.000143775
	LOSS [training: 0.42655822236414237 | validation: 0.5204027788878299]
	TIME [epoch: 9.43 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39889400919784296		[learning rate: 0.00014325]
	Learning Rate: 0.000143253
	LOSS [training: 0.39889400919784296 | validation: 0.44722916757850006]
	TIME [epoch: 9.45 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4181593165173977		[learning rate: 0.00014273]
	Learning Rate: 0.000142734
	LOSS [training: 0.4181593165173977 | validation: 0.492760376625599]
	TIME [epoch: 9.44 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41726978290388395		[learning rate: 0.00014222]
	Learning Rate: 0.000142216
	LOSS [training: 0.41726978290388395 | validation: 0.4780406723070162]
	TIME [epoch: 9.43 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41584684295370894		[learning rate: 0.0001417]
	Learning Rate: 0.0001417
	LOSS [training: 0.41584684295370894 | validation: 0.4519691352612594]
	TIME [epoch: 9.43 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41528020266965726		[learning rate: 0.00014119]
	Learning Rate: 0.000141185
	LOSS [training: 0.41528020266965726 | validation: 0.43710774588312995]
	TIME [epoch: 9.45 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.428555500514774		[learning rate: 0.00014067]
	Learning Rate: 0.000140673
	LOSS [training: 0.428555500514774 | validation: 0.4679427092044287]
	TIME [epoch: 9.43 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3967405048571197		[learning rate: 0.00014016]
	Learning Rate: 0.000140162
	LOSS [training: 0.3967405048571197 | validation: 0.4659342256345271]
	TIME [epoch: 9.43 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41540054835633067		[learning rate: 0.00013965]
	Learning Rate: 0.000139654
	LOSS [training: 0.41540054835633067 | validation: 0.46337151988688874]
	TIME [epoch: 9.43 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4150075153564707		[learning rate: 0.00013915]
	Learning Rate: 0.000139147
	LOSS [training: 0.4150075153564707 | validation: 0.4182867994345172]
	TIME [epoch: 9.45 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4226516762389072		[learning rate: 0.00013864]
	Learning Rate: 0.000138642
	LOSS [training: 0.4226516762389072 | validation: 0.43551220507953825]
	TIME [epoch: 9.43 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41003205846849633		[learning rate: 0.00013814]
	Learning Rate: 0.000138139
	LOSS [training: 0.41003205846849633 | validation: 0.4525215577633007]
	TIME [epoch: 9.43 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4024104871117009		[learning rate: 0.00013764]
	Learning Rate: 0.000137638
	LOSS [training: 0.4024104871117009 | validation: 0.4367748589123927]
	TIME [epoch: 9.43 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4212133701066921		[learning rate: 0.00013714]
	Learning Rate: 0.000137138
	LOSS [training: 0.4212133701066921 | validation: 0.47335570510799946]
	TIME [epoch: 9.45 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43319777063689757		[learning rate: 0.00013664]
	Learning Rate: 0.00013664
	LOSS [training: 0.43319777063689757 | validation: 0.4587503390498325]
	TIME [epoch: 9.43 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4059442291715928		[learning rate: 0.00013614]
	Learning Rate: 0.000136144
	LOSS [training: 0.4059442291715928 | validation: 0.4625331489388158]
	TIME [epoch: 9.43 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3990902933667237		[learning rate: 0.00013565]
	Learning Rate: 0.00013565
	LOSS [training: 0.3990902933667237 | validation: 0.536032034688466]
	TIME [epoch: 9.44 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4249057685964887		[learning rate: 0.00013516]
	Learning Rate: 0.000135158
	LOSS [training: 0.4249057685964887 | validation: 0.42978296130487553]
	TIME [epoch: 9.45 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4036623391791088		[learning rate: 0.00013467]
	Learning Rate: 0.000134668
	LOSS [training: 0.4036623391791088 | validation: 0.4491140075481874]
	TIME [epoch: 9.43 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4052303593916024		[learning rate: 0.00013418]
	Learning Rate: 0.000134179
	LOSS [training: 0.4052303593916024 | validation: 0.4435169938273486]
	TIME [epoch: 9.43 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42009385692585755		[learning rate: 0.00013369]
	Learning Rate: 0.000133692
	LOSS [training: 0.42009385692585755 | validation: 0.4458741877935812]
	TIME [epoch: 9.44 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41446854793625604		[learning rate: 0.00013321]
	Learning Rate: 0.000133207
	LOSS [training: 0.41446854793625604 | validation: 0.4437589908147688]
	TIME [epoch: 9.44 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41555611670309733		[learning rate: 0.00013272]
	Learning Rate: 0.000132723
	LOSS [training: 0.41555611670309733 | validation: 0.49881563050987154]
	TIME [epoch: 9.43 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4105015982411661		[learning rate: 0.00013224]
	Learning Rate: 0.000132242
	LOSS [training: 0.4105015982411661 | validation: 0.47985627494770855]
	TIME [epoch: 9.43 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4104469957468229		[learning rate: 0.00013176]
	Learning Rate: 0.000131762
	LOSS [training: 0.4104469957468229 | validation: 0.43123095552772517]
	TIME [epoch: 9.45 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41372592620140464		[learning rate: 0.00013128]
	Learning Rate: 0.000131284
	LOSS [training: 0.41372592620140464 | validation: 0.5385447222375376]
	TIME [epoch: 9.44 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39558015667047697		[learning rate: 0.00013081]
	Learning Rate: 0.000130807
	LOSS [training: 0.39558015667047697 | validation: 0.5301814746135365]
	TIME [epoch: 9.43 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42092234672440576		[learning rate: 0.00013033]
	Learning Rate: 0.000130332
	LOSS [training: 0.42092234672440576 | validation: 0.4658420611013478]
	TIME [epoch: 9.43 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41680808318213913		[learning rate: 0.00012986]
	Learning Rate: 0.000129859
	LOSS [training: 0.41680808318213913 | validation: 0.5051593042542573]
	TIME [epoch: 9.45 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41839803879594256		[learning rate: 0.00012939]
	Learning Rate: 0.000129388
	LOSS [training: 0.41839803879594256 | validation: 0.45009625398171876]
	TIME [epoch: 9.43 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43803387516841924		[learning rate: 0.00012892]
	Learning Rate: 0.000128919
	LOSS [training: 0.43803387516841924 | validation: 0.48657761311738207]
	TIME [epoch: 9.43 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4191371330394575		[learning rate: 0.00012845]
	Learning Rate: 0.000128451
	LOSS [training: 0.4191371330394575 | validation: 0.48117432215791317]
	TIME [epoch: 9.42 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40908260025630394		[learning rate: 0.00012798]
	Learning Rate: 0.000127985
	LOSS [training: 0.40908260025630394 | validation: 0.49404887963592337]
	TIME [epoch: 9.45 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4123445413449753		[learning rate: 0.00012752]
	Learning Rate: 0.00012752
	LOSS [training: 0.4123445413449753 | validation: 0.4907125541253782]
	TIME [epoch: 9.42 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4076904777307798		[learning rate: 0.00012706]
	Learning Rate: 0.000127057
	LOSS [training: 0.4076904777307798 | validation: 0.46503441680949736]
	TIME [epoch: 9.43 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40784663649801345		[learning rate: 0.0001266]
	Learning Rate: 0.000126596
	LOSS [training: 0.40784663649801345 | validation: 0.4764460582796096]
	TIME [epoch: 9.43 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40537338039285026		[learning rate: 0.00012614]
	Learning Rate: 0.000126137
	LOSS [training: 0.40537338039285026 | validation: 0.475767034738201]
	TIME [epoch: 9.45 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41062134057548105		[learning rate: 0.00012568]
	Learning Rate: 0.000125679
	LOSS [training: 0.41062134057548105 | validation: 0.5102905471141557]
	TIME [epoch: 9.42 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43199006990332733		[learning rate: 0.00012522]
	Learning Rate: 0.000125223
	LOSS [training: 0.43199006990332733 | validation: 0.5279915946699287]
	TIME [epoch: 9.43 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4000705993162025		[learning rate: 0.00012477]
	Learning Rate: 0.000124769
	LOSS [training: 0.4000705993162025 | validation: 0.48231900677676864]
	TIME [epoch: 9.44 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40958483249901556		[learning rate: 0.00012432]
	Learning Rate: 0.000124316
	LOSS [training: 0.40958483249901556 | validation: 0.4763196713883495]
	TIME [epoch: 9.44 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.404062444881249		[learning rate: 0.00012386]
	Learning Rate: 0.000123865
	LOSS [training: 0.404062444881249 | validation: 0.45283494675212754]
	TIME [epoch: 9.43 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4059641183893213		[learning rate: 0.00012342]
	Learning Rate: 0.000123415
	LOSS [training: 0.4059641183893213 | validation: 0.4448917780657986]
	TIME [epoch: 9.43 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40308257469126174		[learning rate: 0.00012297]
	Learning Rate: 0.000122967
	LOSS [training: 0.40308257469126174 | validation: 0.41887783518116595]
	TIME [epoch: 9.45 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4120561329679802		[learning rate: 0.00012252]
	Learning Rate: 0.000122521
	LOSS [training: 0.4120561329679802 | validation: 0.4598384021716217]
	TIME [epoch: 9.43 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41426562233407127		[learning rate: 0.00012208]
	Learning Rate: 0.000122076
	LOSS [training: 0.41426562233407127 | validation: 0.4536648132461552]
	TIME [epoch: 9.43 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40100927649704454		[learning rate: 0.00012163]
	Learning Rate: 0.000121633
	LOSS [training: 0.40100927649704454 | validation: 0.49224003689154444]
	TIME [epoch: 9.43 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4348769353033801		[learning rate: 0.00012119]
	Learning Rate: 0.000121192
	LOSS [training: 0.4348769353033801 | validation: 0.5151823985276225]
	TIME [epoch: 9.45 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4068286409413096		[learning rate: 0.00012075]
	Learning Rate: 0.000120752
	LOSS [training: 0.4068286409413096 | validation: 0.5021847746043524]
	TIME [epoch: 9.43 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4289447933196591		[learning rate: 0.00012031]
	Learning Rate: 0.000120314
	LOSS [training: 0.4289447933196591 | validation: 0.4681957371130644]
	TIME [epoch: 9.43 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4268863584061431		[learning rate: 0.00011988]
	Learning Rate: 0.000119877
	LOSS [training: 0.4268863584061431 | validation: 0.4369811552335128]
	TIME [epoch: 9.43 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4313886134374739		[learning rate: 0.00011944]
	Learning Rate: 0.000119442
	LOSS [training: 0.4313886134374739 | validation: 0.4609211735310115]
	TIME [epoch: 9.45 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.408978493397227		[learning rate: 0.00011901]
	Learning Rate: 0.000119009
	LOSS [training: 0.408978493397227 | validation: 0.5016144101491822]
	TIME [epoch: 9.44 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39563526927452064		[learning rate: 0.00011858]
	Learning Rate: 0.000118577
	LOSS [training: 0.39563526927452064 | validation: 0.4782770538383826]
	TIME [epoch: 9.43 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.405085018509849		[learning rate: 0.00011815]
	Learning Rate: 0.000118147
	LOSS [training: 0.405085018509849 | validation: 0.43324700799762583]
	TIME [epoch: 9.43 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40883549021362064		[learning rate: 0.00011772]
	Learning Rate: 0.000117718
	LOSS [training: 0.40883549021362064 | validation: 0.482198420200742]
	TIME [epoch: 9.45 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4251543597521866		[learning rate: 0.00011729]
	Learning Rate: 0.000117291
	LOSS [training: 0.4251543597521866 | validation: 0.4649439894077544]
	TIME [epoch: 9.44 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40715320154841866		[learning rate: 0.00011686]
	Learning Rate: 0.000116865
	LOSS [training: 0.40715320154841866 | validation: 0.4514428166402045]
	TIME [epoch: 9.43 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41360459945170414		[learning rate: 0.00011644]
	Learning Rate: 0.000116441
	LOSS [training: 0.41360459945170414 | validation: 0.48350338482430133]
	TIME [epoch: 9.44 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4194217689217387		[learning rate: 0.00011602]
	Learning Rate: 0.000116018
	LOSS [training: 0.4194217689217387 | validation: 0.4387625883051256]
	TIME [epoch: 9.44 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3929737888469673		[learning rate: 0.0001156]
	Learning Rate: 0.000115597
	LOSS [training: 0.3929737888469673 | validation: 0.4387593865973195]
	TIME [epoch: 9.43 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39912082838318613		[learning rate: 0.00011518]
	Learning Rate: 0.000115178
	LOSS [training: 0.39912082838318613 | validation: 0.4342298447107338]
	TIME [epoch: 9.43 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4155726804196374		[learning rate: 0.00011476]
	Learning Rate: 0.00011476
	LOSS [training: 0.4155726804196374 | validation: 0.41739128070240145]
	TIME [epoch: 9.45 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41935138773336345		[learning rate: 0.00011434]
	Learning Rate: 0.000114343
	LOSS [training: 0.41935138773336345 | validation: 0.42342732042157094]
	TIME [epoch: 9.43 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4249274074624931		[learning rate: 0.00011393]
	Learning Rate: 0.000113928
	LOSS [training: 0.4249274074624931 | validation: 0.49176649956540003]
	TIME [epoch: 9.44 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40482125536520586		[learning rate: 0.00011351]
	Learning Rate: 0.000113515
	LOSS [training: 0.40482125536520586 | validation: 0.4270438087084223]
	TIME [epoch: 9.43 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4183777603519954		[learning rate: 0.0001131]
	Learning Rate: 0.000113103
	LOSS [training: 0.4183777603519954 | validation: 0.47579613942463894]
	TIME [epoch: 9.45 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40206314618277955		[learning rate: 0.00011269]
	Learning Rate: 0.000112692
	LOSS [training: 0.40206314618277955 | validation: 0.45453044383196256]
	TIME [epoch: 9.44 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4151521294653304		[learning rate: 0.00011228]
	Learning Rate: 0.000112283
	LOSS [training: 0.4151521294653304 | validation: 0.4380999980003394]
	TIME [epoch: 9.43 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42068212127409793		[learning rate: 0.00011188]
	Learning Rate: 0.000111876
	LOSS [training: 0.42068212127409793 | validation: 0.47443397903469825]
	TIME [epoch: 9.43 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4207640091568418		[learning rate: 0.00011147]
	Learning Rate: 0.00011147
	LOSS [training: 0.4207640091568418 | validation: 0.4810885948015552]
	TIME [epoch: 9.45 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40921882249804237		[learning rate: 0.00011107]
	Learning Rate: 0.000111065
	LOSS [training: 0.40921882249804237 | validation: 0.4621782152340431]
	TIME [epoch: 9.43 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4118630316696906		[learning rate: 0.00011066]
	Learning Rate: 0.000110662
	LOSS [training: 0.4118630316696906 | validation: 0.44608804569316735]
	TIME [epoch: 9.43 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4015338259262335		[learning rate: 0.00011026]
	Learning Rate: 0.000110261
	LOSS [training: 0.4015338259262335 | validation: 0.45781552322845204]
	TIME [epoch: 9.43 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4086889517043552		[learning rate: 0.00010986]
	Learning Rate: 0.000109861
	LOSS [training: 0.4086889517043552 | validation: 0.44106974945034105]
	TIME [epoch: 9.45 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4092825651959622		[learning rate: 0.00010946]
	Learning Rate: 0.000109462
	LOSS [training: 0.4092825651959622 | validation: 0.42987145963151563]
	TIME [epoch: 9.43 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41181116228572623		[learning rate: 0.00010906]
	Learning Rate: 0.000109065
	LOSS [training: 0.41181116228572623 | validation: 0.4448628083292937]
	TIME [epoch: 9.43 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4048364600597748		[learning rate: 0.00010867]
	Learning Rate: 0.000108669
	LOSS [training: 0.4048364600597748 | validation: 0.45608192545390663]
	TIME [epoch: 9.43 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39870972778346825		[learning rate: 0.00010827]
	Learning Rate: 0.000108275
	LOSS [training: 0.39870972778346825 | validation: 0.46123889016852515]
	TIME [epoch: 9.46 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41205102255296		[learning rate: 0.00010788]
	Learning Rate: 0.000107882
	LOSS [training: 0.41205102255296 | validation: 0.4929986568481462]
	TIME [epoch: 9.43 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41692045486276574		[learning rate: 0.00010749]
	Learning Rate: 0.00010749
	LOSS [training: 0.41692045486276574 | validation: 0.47870837897771695]
	TIME [epoch: 9.43 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4046862044566457		[learning rate: 0.0001071]
	Learning Rate: 0.0001071
	LOSS [training: 0.4046862044566457 | validation: 0.3976527152222056]
	TIME [epoch: 9.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_1348.pth
	Model improved!!!
EPOCH 1349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40483435698582004		[learning rate: 0.00010671]
	Learning Rate: 0.000106711
	LOSS [training: 0.40483435698582004 | validation: 0.5009649284662298]
	TIME [epoch: 9.45 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4153002974113186		[learning rate: 0.00010632]
	Learning Rate: 0.000106324
	LOSS [training: 0.4153002974113186 | validation: 0.4386859753325213]
	TIME [epoch: 9.43 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39711161490724295		[learning rate: 0.00010594]
	Learning Rate: 0.000105938
	LOSS [training: 0.39711161490724295 | validation: 0.5293224099006095]
	TIME [epoch: 9.43 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4139943155956873		[learning rate: 0.00010555]
	Learning Rate: 0.000105554
	LOSS [training: 0.4139943155956873 | validation: 0.4134323362563569]
	TIME [epoch: 9.46 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41042862995912427		[learning rate: 0.00010517]
	Learning Rate: 0.000105171
	LOSS [training: 0.41042862995912427 | validation: 0.48776038816287054]
	TIME [epoch: 9.44 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4044473573190871		[learning rate: 0.00010479]
	Learning Rate: 0.000104789
	LOSS [training: 0.4044473573190871 | validation: 0.462565897683808]
	TIME [epoch: 9.44 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41430561212201794		[learning rate: 0.00010441]
	Learning Rate: 0.000104409
	LOSS [training: 0.41430561212201794 | validation: 0.41373392016694327]
	TIME [epoch: 9.43 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4048634143073754		[learning rate: 0.00010403]
	Learning Rate: 0.00010403
	LOSS [training: 0.4048634143073754 | validation: 0.5050663692112911]
	TIME [epoch: 9.45 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4108001247630447		[learning rate: 0.00010365]
	Learning Rate: 0.000103652
	LOSS [training: 0.4108001247630447 | validation: 0.444569011211687]
	TIME [epoch: 9.43 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4268890513947948		[learning rate: 0.00010328]
	Learning Rate: 0.000103276
	LOSS [training: 0.4268890513947948 | validation: 0.4263035716566404]
	TIME [epoch: 9.43 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41546715476708984		[learning rate: 0.0001029]
	Learning Rate: 0.000102901
	LOSS [training: 0.41546715476708984 | validation: 0.4247058513545591]
	TIME [epoch: 9.44 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4005012697900767		[learning rate: 0.00010253]
	Learning Rate: 0.000102528
	LOSS [training: 0.4005012697900767 | validation: 0.4429754105715894]
	TIME [epoch: 9.46 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40406064974615685		[learning rate: 0.00010216]
	Learning Rate: 0.000102156
	LOSS [training: 0.40406064974615685 | validation: 0.4967433607986245]
	TIME [epoch: 9.43 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4115854507319888		[learning rate: 0.00010179]
	Learning Rate: 0.000101785
	LOSS [training: 0.4115854507319888 | validation: 0.44664981900680106]
	TIME [epoch: 9.44 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40754368441577393		[learning rate: 0.00010142]
	Learning Rate: 0.000101416
	LOSS [training: 0.40754368441577393 | validation: 0.4322865189937894]
	TIME [epoch: 9.43 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40445901866226397		[learning rate: 0.00010105]
	Learning Rate: 0.000101048
	LOSS [training: 0.40445901866226397 | validation: 0.46406584873216555]
	TIME [epoch: 9.46 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41427624749550124		[learning rate: 0.00010068]
	Learning Rate: 0.000100681
	LOSS [training: 0.41427624749550124 | validation: 0.4707333932290857]
	TIME [epoch: 9.44 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4154889568160732		[learning rate: 0.00010032]
	Learning Rate: 0.000100316
	LOSS [training: 0.4154889568160732 | validation: 0.446256714968783]
	TIME [epoch: 9.43 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40115686488522206		[learning rate: 9.9952e-05]
	Learning Rate: 9.99515e-05
	LOSS [training: 0.40115686488522206 | validation: 0.45449295728188593]
	TIME [epoch: 9.46 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3977690873662091		[learning rate: 9.9589e-05]
	Learning Rate: 9.95888e-05
	LOSS [training: 0.3977690873662091 | validation: 0.4542579040137323]
	TIME [epoch: 9.45 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4006724246726561		[learning rate: 9.9227e-05]
	Learning Rate: 9.92274e-05
	LOSS [training: 0.4006724246726561 | validation: 0.49812801096432474]
	TIME [epoch: 9.43 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4007468725971476		[learning rate: 9.8867e-05]
	Learning Rate: 9.88673e-05
	LOSS [training: 0.4007468725971476 | validation: 0.47799668060129125]
	TIME [epoch: 9.45 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41621281427317725		[learning rate: 9.8509e-05]
	Learning Rate: 9.85085e-05
	LOSS [training: 0.41621281427317725 | validation: 0.46321833981154587]
	TIME [epoch: 9.45 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4071462096649953		[learning rate: 9.8151e-05]
	Learning Rate: 9.8151e-05
	LOSS [training: 0.4071462096649953 | validation: 0.47794356196899646]
	TIME [epoch: 9.44 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42012619008193075		[learning rate: 9.7795e-05]
	Learning Rate: 9.77948e-05
	LOSS [training: 0.42012619008193075 | validation: 0.42310030713401936]
	TIME [epoch: 9.44 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4140081965956129		[learning rate: 9.744e-05]
	Learning Rate: 9.74399e-05
	LOSS [training: 0.4140081965956129 | validation: 0.42553055687300173]
	TIME [epoch: 9.44 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4061551030405677		[learning rate: 9.7086e-05]
	Learning Rate: 9.70863e-05
	LOSS [training: 0.4061551030405677 | validation: 0.42510304059571924]
	TIME [epoch: 9.46 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40657807842411386		[learning rate: 9.6734e-05]
	Learning Rate: 9.6734e-05
	LOSS [training: 0.40657807842411386 | validation: 0.4299249860316347]
	TIME [epoch: 9.44 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3928718926501739		[learning rate: 9.6383e-05]
	Learning Rate: 9.63829e-05
	LOSS [training: 0.3928718926501739 | validation: 0.43732829754780234]
	TIME [epoch: 9.44 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4196790607631928		[learning rate: 9.6033e-05]
	Learning Rate: 9.60331e-05
	LOSS [training: 0.4196790607631928 | validation: 0.44163365768380713]
	TIME [epoch: 9.43 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3876454778526228		[learning rate: 9.5685e-05]
	Learning Rate: 9.56846e-05
	LOSS [training: 0.3876454778526228 | validation: 0.48015539083920794]
	TIME [epoch: 9.46 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4087637430871224		[learning rate: 9.5337e-05]
	Learning Rate: 9.53374e-05
	LOSS [training: 0.4087637430871224 | validation: 0.47185301578928773]
	TIME [epoch: 9.44 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4167222845009791		[learning rate: 9.4991e-05]
	Learning Rate: 9.49914e-05
	LOSS [training: 0.4167222845009791 | validation: 0.46274717728236825]
	TIME [epoch: 9.43 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40409161514452097		[learning rate: 9.4647e-05]
	Learning Rate: 9.46466e-05
	LOSS [training: 0.40409161514452097 | validation: 0.4625902015098595]
	TIME [epoch: 9.44 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39933123066363896		[learning rate: 9.4303e-05]
	Learning Rate: 9.43032e-05
	LOSS [training: 0.39933123066363896 | validation: 0.49421004855114675]
	TIME [epoch: 9.46 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4038270106112035		[learning rate: 9.3961e-05]
	Learning Rate: 9.39609e-05
	LOSS [training: 0.4038270106112035 | validation: 0.4057640096069829]
	TIME [epoch: 9.43 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4084379094409464		[learning rate: 9.362e-05]
	Learning Rate: 9.362e-05
	LOSS [training: 0.4084379094409464 | validation: 0.44446929327097723]
	TIME [epoch: 9.43 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43019385122675413		[learning rate: 9.328e-05]
	Learning Rate: 9.32802e-05
	LOSS [training: 0.43019385122675413 | validation: 0.5189130216267259]
	TIME [epoch: 9.43 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39906846277901875		[learning rate: 9.2942e-05]
	Learning Rate: 9.29417e-05
	LOSS [training: 0.39906846277901875 | validation: 0.46817471945670774]
	TIME [epoch: 9.46 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3970008057670746		[learning rate: 9.2604e-05]
	Learning Rate: 9.26044e-05
	LOSS [training: 0.3970008057670746 | validation: 0.44712714417416055]
	TIME [epoch: 9.43 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40086406066420277		[learning rate: 9.2268e-05]
	Learning Rate: 9.22683e-05
	LOSS [training: 0.40086406066420277 | validation: 0.48672588824507906]
	TIME [epoch: 9.44 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4039791080832485		[learning rate: 9.1933e-05]
	Learning Rate: 9.19335e-05
	LOSS [training: 0.4039791080832485 | validation: 0.4809190350380951]
	TIME [epoch: 9.45 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4138574667772358		[learning rate: 9.16e-05]
	Learning Rate: 9.15998e-05
	LOSS [training: 0.4138574667772358 | validation: 0.4231688513574725]
	TIME [epoch: 9.46 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42167719397620207		[learning rate: 9.1267e-05]
	Learning Rate: 9.12674e-05
	LOSS [training: 0.42167719397620207 | validation: 0.4648870939757921]
	TIME [epoch: 9.44 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4069647527697131		[learning rate: 9.0936e-05]
	Learning Rate: 9.09362e-05
	LOSS [training: 0.4069647527697131 | validation: 0.45945892702279567]
	TIME [epoch: 9.44 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3941538017115195		[learning rate: 9.0606e-05]
	Learning Rate: 9.06062e-05
	LOSS [training: 0.3941538017115195 | validation: 0.5143213150233052]
	TIME [epoch: 9.46 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41223203709004874		[learning rate: 9.0277e-05]
	Learning Rate: 9.02774e-05
	LOSS [training: 0.41223203709004874 | validation: 0.4523495117476328]
	TIME [epoch: 9.45 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4060720318194734		[learning rate: 8.995e-05]
	Learning Rate: 8.99498e-05
	LOSS [training: 0.4060720318194734 | validation: 0.43379729061166294]
	TIME [epoch: 9.44 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38944651751581594		[learning rate: 8.9623e-05]
	Learning Rate: 8.96233e-05
	LOSS [training: 0.38944651751581594 | validation: 0.4506290652311995]
	TIME [epoch: 9.45 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4212411153233718		[learning rate: 8.9298e-05]
	Learning Rate: 8.92981e-05
	LOSS [training: 0.4212411153233718 | validation: 0.48873697700568336]
	TIME [epoch: 9.46 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42545965353133236		[learning rate: 8.8974e-05]
	Learning Rate: 8.8974e-05
	LOSS [training: 0.42545965353133236 | validation: 0.49690888258499083]
	TIME [epoch: 9.44 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4141607509081002		[learning rate: 8.8651e-05]
	Learning Rate: 8.86511e-05
	LOSS [training: 0.4141607509081002 | validation: 0.4597086407581387]
	TIME [epoch: 9.44 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.401757488569248		[learning rate: 8.8329e-05]
	Learning Rate: 8.83294e-05
	LOSS [training: 0.401757488569248 | validation: 0.4321205583957626]
	TIME [epoch: 9.44 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40172164001565747		[learning rate: 8.8009e-05]
	Learning Rate: 8.80088e-05
	LOSS [training: 0.40172164001565747 | validation: 0.4566240661131259]
	TIME [epoch: 9.45 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40997765318803914		[learning rate: 8.7689e-05]
	Learning Rate: 8.76895e-05
	LOSS [training: 0.40997765318803914 | validation: 0.4386739554208691]
	TIME [epoch: 9.44 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4062406920351931		[learning rate: 8.7371e-05]
	Learning Rate: 8.73712e-05
	LOSS [training: 0.4062406920351931 | validation: 0.4999633130345628]
	TIME [epoch: 9.44 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42358695752114206		[learning rate: 8.7054e-05]
	Learning Rate: 8.70542e-05
	LOSS [training: 0.42358695752114206 | validation: 0.49097277309246695]
	TIME [epoch: 9.44 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40364444300788993		[learning rate: 8.6738e-05]
	Learning Rate: 8.67382e-05
	LOSS [training: 0.40364444300788993 | validation: 0.4803193164071011]
	TIME [epoch: 9.46 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41116253011087317		[learning rate: 8.6423e-05]
	Learning Rate: 8.64235e-05
	LOSS [training: 0.41116253011087317 | validation: 0.40613171820850286]
	TIME [epoch: 9.44 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3960306762637482		[learning rate: 8.611e-05]
	Learning Rate: 8.61098e-05
	LOSS [training: 0.3960306762637482 | validation: 0.40920521749216493]
	TIME [epoch: 9.44 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4022639912174325		[learning rate: 8.5797e-05]
	Learning Rate: 8.57973e-05
	LOSS [training: 0.4022639912174325 | validation: 0.4246768652235048]
	TIME [epoch: 9.44 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4054914121732395		[learning rate: 8.5486e-05]
	Learning Rate: 8.54859e-05
	LOSS [training: 0.4054914121732395 | validation: 0.4608372609330101]
	TIME [epoch: 9.44 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4046856069262126		[learning rate: 8.5176e-05]
	Learning Rate: 8.51757e-05
	LOSS [training: 0.4046856069262126 | validation: 0.427301199551534]
	TIME [epoch: 9.43 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4076311762223007		[learning rate: 8.4867e-05]
	Learning Rate: 8.48666e-05
	LOSS [training: 0.4076311762223007 | validation: 0.4836295217888801]
	TIME [epoch: 9.43 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39887657043546143		[learning rate: 8.4559e-05]
	Learning Rate: 8.45586e-05
	LOSS [training: 0.39887657043546143 | validation: 0.4289432704582099]
	TIME [epoch: 9.45 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.405825662753752		[learning rate: 8.4252e-05]
	Learning Rate: 8.42518e-05
	LOSS [training: 0.405825662753752 | validation: 0.4829314604293941]
	TIME [epoch: 9.45 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4061687520919481		[learning rate: 8.3946e-05]
	Learning Rate: 8.3946e-05
	LOSS [training: 0.4061687520919481 | validation: 0.4546573157436445]
	TIME [epoch: 9.45 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40004791659588107		[learning rate: 8.3641e-05]
	Learning Rate: 8.36414e-05
	LOSS [training: 0.40004791659588107 | validation: 0.4811180138597954]
	TIME [epoch: 9.44 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.394308626630283		[learning rate: 8.3338e-05]
	Learning Rate: 8.33378e-05
	LOSS [training: 0.394308626630283 | validation: 0.4166489087761701]
	TIME [epoch: 9.47 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4034460834371035		[learning rate: 8.3035e-05]
	Learning Rate: 8.30354e-05
	LOSS [training: 0.4034460834371035 | validation: 0.41473170569038076]
	TIME [epoch: 9.45 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40702379976613623		[learning rate: 8.2734e-05]
	Learning Rate: 8.2734e-05
	LOSS [training: 0.40702379976613623 | validation: 0.41860397007021277]
	TIME [epoch: 9.45 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42349859425700265		[learning rate: 8.2434e-05]
	Learning Rate: 8.24338e-05
	LOSS [training: 0.42349859425700265 | validation: 0.4396700125365496]
	TIME [epoch: 9.45 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4115123957761564		[learning rate: 8.2135e-05]
	Learning Rate: 8.21346e-05
	LOSS [training: 0.4115123957761564 | validation: 0.5229467249500128]
	TIME [epoch: 9.47 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4203525176161416		[learning rate: 8.1837e-05]
	Learning Rate: 8.18366e-05
	LOSS [training: 0.4203525176161416 | validation: 0.5179250625345595]
	TIME [epoch: 9.45 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4077470730507331		[learning rate: 8.154e-05]
	Learning Rate: 8.15396e-05
	LOSS [training: 0.4077470730507331 | validation: 0.4200590796000884]
	TIME [epoch: 9.45 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40090146457662135		[learning rate: 8.1244e-05]
	Learning Rate: 8.12437e-05
	LOSS [training: 0.40090146457662135 | validation: 0.4213929934603425]
	TIME [epoch: 9.44 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40668840346647783		[learning rate: 8.0949e-05]
	Learning Rate: 8.09488e-05
	LOSS [training: 0.40668840346647783 | validation: 0.4401301575311362]
	TIME [epoch: 9.47 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41149760609605435		[learning rate: 8.0655e-05]
	Learning Rate: 8.0655e-05
	LOSS [training: 0.41149760609605435 | validation: 0.4639063742236432]
	TIME [epoch: 9.44 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4134344491164862		[learning rate: 8.0362e-05]
	Learning Rate: 8.03623e-05
	LOSS [training: 0.4134344491164862 | validation: 0.426573405240944]
	TIME [epoch: 9.45 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43018076236444436		[learning rate: 8.0071e-05]
	Learning Rate: 8.00707e-05
	LOSS [training: 0.43018076236444436 | validation: 0.4428098473910146]
	TIME [epoch: 9.44 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41022394296474146		[learning rate: 7.978e-05]
	Learning Rate: 7.97801e-05
	LOSS [training: 0.41022394296474146 | validation: 0.47241929247625125]
	TIME [epoch: 9.46 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42288092603082494		[learning rate: 7.9491e-05]
	Learning Rate: 7.94906e-05
	LOSS [training: 0.42288092603082494 | validation: 0.46987119641168756]
	TIME [epoch: 9.43 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.420577980301276		[learning rate: 7.9202e-05]
	Learning Rate: 7.92021e-05
	LOSS [training: 0.420577980301276 | validation: 0.45972597886655436]
	TIME [epoch: 9.42 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41167463556074724		[learning rate: 7.8915e-05]
	Learning Rate: 7.89147e-05
	LOSS [training: 0.41167463556074724 | validation: 0.4735898570805054]
	TIME [epoch: 9.43 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4313787502781081		[learning rate: 7.8628e-05]
	Learning Rate: 7.86283e-05
	LOSS [training: 0.4313787502781081 | validation: 0.44563403698126747]
	TIME [epoch: 9.44 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40361991523844887		[learning rate: 7.8343e-05]
	Learning Rate: 7.8343e-05
	LOSS [training: 0.40361991523844887 | validation: 0.48657058027889255]
	TIME [epoch: 9.43 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4036571735453517		[learning rate: 7.8059e-05]
	Learning Rate: 7.80586e-05
	LOSS [training: 0.4036571735453517 | validation: 0.45647299487407256]
	TIME [epoch: 9.43 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3909859044807382		[learning rate: 7.7775e-05]
	Learning Rate: 7.77754e-05
	LOSS [training: 0.3909859044807382 | validation: 0.4465100134802195]
	TIME [epoch: 9.44 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4200408832322676		[learning rate: 7.7493e-05]
	Learning Rate: 7.74931e-05
	LOSS [training: 0.4200408832322676 | validation: 0.44719548737694303]
	TIME [epoch: 9.43 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41625728488745023		[learning rate: 7.7212e-05]
	Learning Rate: 7.72119e-05
	LOSS [training: 0.41625728488745023 | validation: 0.43418530552770873]
	TIME [epoch: 9.43 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4106840140050621		[learning rate: 7.6932e-05]
	Learning Rate: 7.69317e-05
	LOSS [training: 0.4106840140050621 | validation: 0.4472392768816296]
	TIME [epoch: 9.43 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4134113833896268		[learning rate: 7.6653e-05]
	Learning Rate: 7.66525e-05
	LOSS [training: 0.4134113833896268 | validation: 0.45793016982225]
	TIME [epoch: 9.45 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40269751943845933		[learning rate: 7.6374e-05]
	Learning Rate: 7.63743e-05
	LOSS [training: 0.40269751943845933 | validation: 0.4819689267892029]
	TIME [epoch: 9.44 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.404353893127667		[learning rate: 7.6097e-05]
	Learning Rate: 7.60972e-05
	LOSS [training: 0.404353893127667 | validation: 0.44473493198971575]
	TIME [epoch: 9.43 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3941711042156161		[learning rate: 7.5821e-05]
	Learning Rate: 7.5821e-05
	LOSS [training: 0.3941711042156161 | validation: 0.460543348482094]
	TIME [epoch: 9.43 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39120567319371025		[learning rate: 7.5546e-05]
	Learning Rate: 7.55458e-05
	LOSS [training: 0.39120567319371025 | validation: 0.4072687270618562]
	TIME [epoch: 9.47 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40159404928465464		[learning rate: 7.5272e-05]
	Learning Rate: 7.52717e-05
	LOSS [training: 0.40159404928465464 | validation: 0.46619620335084094]
	TIME [epoch: 9.43 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4055929674093555		[learning rate: 7.4999e-05]
	Learning Rate: 7.49985e-05
	LOSS [training: 0.4055929674093555 | validation: 0.4135995519990334]
	TIME [epoch: 9.43 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4011256581038104		[learning rate: 7.4726e-05]
	Learning Rate: 7.47263e-05
	LOSS [training: 0.4011256581038104 | validation: 0.4564424052674495]
	TIME [epoch: 9.43 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3961891656709196		[learning rate: 7.4455e-05]
	Learning Rate: 7.44552e-05
	LOSS [training: 0.3961891656709196 | validation: 0.4413446298441606]
	TIME [epoch: 9.45 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4038082173884624		[learning rate: 7.4185e-05]
	Learning Rate: 7.4185e-05
	LOSS [training: 0.4038082173884624 | validation: 0.46898544819838267]
	TIME [epoch: 9.43 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4033700746619247		[learning rate: 7.3916e-05]
	Learning Rate: 7.39157e-05
	LOSS [training: 0.4033700746619247 | validation: 0.47258385717006535]
	TIME [epoch: 9.43 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3872071829725482		[learning rate: 7.3647e-05]
	Learning Rate: 7.36475e-05
	LOSS [training: 0.3872071829725482 | validation: 0.46180807037029015]
	TIME [epoch: 9.43 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41235398400826784		[learning rate: 7.338e-05]
	Learning Rate: 7.33802e-05
	LOSS [training: 0.41235398400826784 | validation: 0.5309226250657162]
	TIME [epoch: 9.45 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4277963814129066		[learning rate: 7.3114e-05]
	Learning Rate: 7.31139e-05
	LOSS [training: 0.4277963814129066 | validation: 0.4235951999422896]
	TIME [epoch: 9.43 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4030694281405238		[learning rate: 7.2849e-05]
	Learning Rate: 7.28486e-05
	LOSS [training: 0.4030694281405238 | validation: 0.41624318791794634]
	TIME [epoch: 9.43 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40267068687857044		[learning rate: 7.2584e-05]
	Learning Rate: 7.25842e-05
	LOSS [training: 0.40267068687857044 | validation: 0.46571198239707273]
	TIME [epoch: 9.45 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40395758946967303		[learning rate: 7.2321e-05]
	Learning Rate: 7.23208e-05
	LOSS [training: 0.40395758946967303 | validation: 0.4313361130814083]
	TIME [epoch: 9.43 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39751476318670714		[learning rate: 7.2058e-05]
	Learning Rate: 7.20583e-05
	LOSS [training: 0.39751476318670714 | validation: 0.46361498350461594]
	TIME [epoch: 9.43 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39256597125785986		[learning rate: 7.1797e-05]
	Learning Rate: 7.17968e-05
	LOSS [training: 0.39256597125785986 | validation: 0.44512523641597695]
	TIME [epoch: 9.43 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3950931087644107		[learning rate: 7.1536e-05]
	Learning Rate: 7.15363e-05
	LOSS [training: 0.3950931087644107 | validation: 0.4520923588078569]
	TIME [epoch: 9.45 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40199504880657777		[learning rate: 7.1277e-05]
	Learning Rate: 7.12767e-05
	LOSS [training: 0.40199504880657777 | validation: 0.45431175442793525]
	TIME [epoch: 9.43 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40036326483450874		[learning rate: 7.1018e-05]
	Learning Rate: 7.1018e-05
	LOSS [training: 0.40036326483450874 | validation: 0.4964592045151752]
	TIME [epoch: 9.43 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4105536408607738		[learning rate: 7.076e-05]
	Learning Rate: 7.07603e-05
	LOSS [training: 0.4105536408607738 | validation: 0.4831196130627213]
	TIME [epoch: 9.43 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40697550049315084		[learning rate: 7.0503e-05]
	Learning Rate: 7.05035e-05
	LOSS [training: 0.40697550049315084 | validation: 0.4236937730497944]
	TIME [epoch: 9.45 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4163618254079717		[learning rate: 7.0248e-05]
	Learning Rate: 7.02476e-05
	LOSS [training: 0.4163618254079717 | validation: 0.48132302073042765]
	TIME [epoch: 9.43 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3921674183439218		[learning rate: 6.9993e-05]
	Learning Rate: 6.99927e-05
	LOSS [training: 0.3921674183439218 | validation: 0.47148159996566746]
	TIME [epoch: 9.43 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41848892892714584		[learning rate: 6.9739e-05]
	Learning Rate: 6.97387e-05
	LOSS [training: 0.41848892892714584 | validation: 0.40396585623947434]
	TIME [epoch: 9.43 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4048622356553585		[learning rate: 6.9486e-05]
	Learning Rate: 6.94856e-05
	LOSS [training: 0.4048622356553585 | validation: 0.48930194036943364]
	TIME [epoch: 9.45 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.408664455837468		[learning rate: 6.9233e-05]
	Learning Rate: 6.92334e-05
	LOSS [training: 0.408664455837468 | validation: 0.43713485386750306]
	TIME [epoch: 9.43 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41287423132633505		[learning rate: 6.8982e-05]
	Learning Rate: 6.89822e-05
	LOSS [training: 0.41287423132633505 | validation: 0.4499725382203144]
	TIME [epoch: 9.43 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3962446534717983		[learning rate: 6.8732e-05]
	Learning Rate: 6.87318e-05
	LOSS [training: 0.3962446534717983 | validation: 0.4366596010147168]
	TIME [epoch: 9.43 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39876676625749535		[learning rate: 6.8482e-05]
	Learning Rate: 6.84824e-05
	LOSS [training: 0.39876676625749535 | validation: 0.47005902670098765]
	TIME [epoch: 9.45 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4035726958976296		[learning rate: 6.8234e-05]
	Learning Rate: 6.82339e-05
	LOSS [training: 0.4035726958976296 | validation: 0.44615000553466855]
	TIME [epoch: 9.43 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41028830545381717		[learning rate: 6.7986e-05]
	Learning Rate: 6.79862e-05
	LOSS [training: 0.41028830545381717 | validation: 0.44537892366687404]
	TIME [epoch: 9.43 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.413262438733371		[learning rate: 6.774e-05]
	Learning Rate: 6.77395e-05
	LOSS [training: 0.413262438733371 | validation: 0.413114326496015]
	TIME [epoch: 9.44 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4112003403095933		[learning rate: 6.7494e-05]
	Learning Rate: 6.74937e-05
	LOSS [training: 0.4112003403095933 | validation: 0.4449586719744709]
	TIME [epoch: 9.45 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3959504668519327		[learning rate: 6.7249e-05]
	Learning Rate: 6.72488e-05
	LOSS [training: 0.3959504668519327 | validation: 0.4615330156053401]
	TIME [epoch: 9.43 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4091876356466929		[learning rate: 6.7005e-05]
	Learning Rate: 6.70047e-05
	LOSS [training: 0.4091876356466929 | validation: 0.47343490599271365]
	TIME [epoch: 9.43 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3965300419128606		[learning rate: 6.6762e-05]
	Learning Rate: 6.67616e-05
	LOSS [training: 0.3965300419128606 | validation: 0.5171048283199999]
	TIME [epoch: 9.44 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4113796565323038		[learning rate: 6.6519e-05]
	Learning Rate: 6.65192e-05
	LOSS [training: 0.4113796565323038 | validation: 0.44527159289282237]
	TIME [epoch: 9.44 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40458823014839923		[learning rate: 6.6278e-05]
	Learning Rate: 6.62778e-05
	LOSS [training: 0.40458823014839923 | validation: 0.4705018072555078]
	TIME [epoch: 9.43 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41112956371596343		[learning rate: 6.6037e-05]
	Learning Rate: 6.60373e-05
	LOSS [training: 0.41112956371596343 | validation: 0.4303926497665026]
	TIME [epoch: 9.43 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4178430354251182		[learning rate: 6.5798e-05]
	Learning Rate: 6.57977e-05
	LOSS [training: 0.4178430354251182 | validation: 0.4312268742425198]
	TIME [epoch: 9.45 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4014302912489132		[learning rate: 6.5559e-05]
	Learning Rate: 6.55589e-05
	LOSS [training: 0.4014302912489132 | validation: 0.4397444368128252]
	TIME [epoch: 9.43 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39450035443860204		[learning rate: 6.5321e-05]
	Learning Rate: 6.5321e-05
	LOSS [training: 0.39450035443860204 | validation: 0.4840927815691084]
	TIME [epoch: 9.43 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4309356934832948		[learning rate: 6.5084e-05]
	Learning Rate: 6.50839e-05
	LOSS [training: 0.4309356934832948 | validation: 0.48403835662691125]
	TIME [epoch: 9.43 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4018240729369264		[learning rate: 6.4848e-05]
	Learning Rate: 6.48477e-05
	LOSS [training: 0.4018240729369264 | validation: 0.47050038492996976]
	TIME [epoch: 9.46 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4024763145731711		[learning rate: 6.4612e-05]
	Learning Rate: 6.46124e-05
	LOSS [training: 0.4024763145731711 | validation: 0.4042580055439217]
	TIME [epoch: 9.43 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4057131327150693		[learning rate: 6.4378e-05]
	Learning Rate: 6.43779e-05
	LOSS [training: 0.4057131327150693 | validation: 0.4344614330016544]
	TIME [epoch: 9.43 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3887631137266201		[learning rate: 6.4144e-05]
	Learning Rate: 6.41443e-05
	LOSS [training: 0.3887631137266201 | validation: 0.4343698716819533]
	TIME [epoch: 9.43 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4035125479077134		[learning rate: 6.3911e-05]
	Learning Rate: 6.39115e-05
	LOSS [training: 0.4035125479077134 | validation: 0.4139606163162729]
	TIME [epoch: 9.46 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39066593138811073		[learning rate: 6.368e-05]
	Learning Rate: 6.36795e-05
	LOSS [training: 0.39066593138811073 | validation: 0.4426267751064472]
	TIME [epoch: 9.44 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4022249785348304		[learning rate: 6.3448e-05]
	Learning Rate: 6.34485e-05
	LOSS [training: 0.4022249785348304 | validation: 0.48745459579649614]
	TIME [epoch: 9.43 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40060144379489887		[learning rate: 6.3218e-05]
	Learning Rate: 6.32182e-05
	LOSS [training: 0.40060144379489887 | validation: 0.5006125146883845]
	TIME [epoch: 9.43 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3924395696036872		[learning rate: 6.2989e-05]
	Learning Rate: 6.29888e-05
	LOSS [training: 0.3924395696036872 | validation: 0.43245540339572913]
	TIME [epoch: 9.46 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39472308337788553		[learning rate: 6.276e-05]
	Learning Rate: 6.27602e-05
	LOSS [training: 0.39472308337788553 | validation: 0.49711553257109004]
	TIME [epoch: 9.44 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4021183210106084		[learning rate: 6.2532e-05]
	Learning Rate: 6.25324e-05
	LOSS [training: 0.4021183210106084 | validation: 0.44127062175725373]
	TIME [epoch: 9.44 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40572887928827256		[learning rate: 6.2305e-05]
	Learning Rate: 6.23055e-05
	LOSS [training: 0.40572887928827256 | validation: 0.45897586721463945]
	TIME [epoch: 9.45 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3954151888956171		[learning rate: 6.2079e-05]
	Learning Rate: 6.20794e-05
	LOSS [training: 0.3954151888956171 | validation: 0.40334042224225924]
	TIME [epoch: 9.47 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4058774568542793		[learning rate: 6.1854e-05]
	Learning Rate: 6.18541e-05
	LOSS [training: 0.4058774568542793 | validation: 0.4718962074272705]
	TIME [epoch: 9.45 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40532231696964505		[learning rate: 6.163e-05]
	Learning Rate: 6.16296e-05
	LOSS [training: 0.40532231696964505 | validation: 0.41298299494315177]
	TIME [epoch: 9.44 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3989800936277296		[learning rate: 6.1406e-05]
	Learning Rate: 6.1406e-05
	LOSS [training: 0.3989800936277296 | validation: 0.4768984273147207]
	TIME [epoch: 9.47 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40707370157141903		[learning rate: 6.1183e-05]
	Learning Rate: 6.11831e-05
	LOSS [training: 0.40707370157141903 | validation: 0.5160695808911081]
	TIME [epoch: 9.45 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41586946342858794		[learning rate: 6.0961e-05]
	Learning Rate: 6.09611e-05
	LOSS [training: 0.41586946342858794 | validation: 0.5178398446387436]
	TIME [epoch: 9.45 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40006732413634827		[learning rate: 6.074e-05]
	Learning Rate: 6.07399e-05
	LOSS [training: 0.40006732413634827 | validation: 0.4372697438813919]
	TIME [epoch: 9.45 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4033855847932659		[learning rate: 6.0519e-05]
	Learning Rate: 6.05194e-05
	LOSS [training: 0.4033855847932659 | validation: 0.483767170308565]
	TIME [epoch: 9.46 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3928517206975826		[learning rate: 6.03e-05]
	Learning Rate: 6.02998e-05
	LOSS [training: 0.3928517206975826 | validation: 0.4313531907756294]
	TIME [epoch: 9.45 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3885441330245935		[learning rate: 6.0081e-05]
	Learning Rate: 6.0081e-05
	LOSS [training: 0.3885441330245935 | validation: 0.44757252014617244]
	TIME [epoch: 9.44 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4030890162392565		[learning rate: 5.9863e-05]
	Learning Rate: 5.98629e-05
	LOSS [training: 0.4030890162392565 | validation: 0.4582701539751995]
	TIME [epoch: 9.45 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4023942961240835		[learning rate: 5.9646e-05]
	Learning Rate: 5.96457e-05
	LOSS [training: 0.4023942961240835 | validation: 0.4744045423549402]
	TIME [epoch: 9.47 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3839811867028386		[learning rate: 5.9429e-05]
	Learning Rate: 5.94292e-05
	LOSS [training: 0.3839811867028386 | validation: 0.4240976872336822]
	TIME [epoch: 9.45 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3949827625132423		[learning rate: 5.9214e-05]
	Learning Rate: 5.92136e-05
	LOSS [training: 0.3949827625132423 | validation: 0.41897098479482736]
	TIME [epoch: 9.44 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39581674117253424		[learning rate: 5.8999e-05]
	Learning Rate: 5.89987e-05
	LOSS [training: 0.39581674117253424 | validation: 0.39765997584271445]
	TIME [epoch: 9.44 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40464209799820267		[learning rate: 5.8785e-05]
	Learning Rate: 5.87846e-05
	LOSS [training: 0.40464209799820267 | validation: 0.4770272297902832]
	TIME [epoch: 9.47 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3871233284000604		[learning rate: 5.8571e-05]
	Learning Rate: 5.85712e-05
	LOSS [training: 0.3871233284000604 | validation: 0.4785577131370873]
	TIME [epoch: 9.45 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4168921781036007		[learning rate: 5.8359e-05]
	Learning Rate: 5.83586e-05
	LOSS [training: 0.4168921781036007 | validation: 0.42873527163838987]
	TIME [epoch: 9.45 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4003630736678816		[learning rate: 5.8147e-05]
	Learning Rate: 5.81469e-05
	LOSS [training: 0.4003630736678816 | validation: 0.42769636848466164]
	TIME [epoch: 9.45 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3937591656659312		[learning rate: 5.7936e-05]
	Learning Rate: 5.79358e-05
	LOSS [training: 0.3937591656659312 | validation: 0.45868072424604295]
	TIME [epoch: 9.47 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4044813910312122		[learning rate: 5.7726e-05]
	Learning Rate: 5.77256e-05
	LOSS [training: 0.4044813910312122 | validation: 0.41518382739604137]
	TIME [epoch: 9.45 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.407028623809237		[learning rate: 5.7516e-05]
	Learning Rate: 5.75161e-05
	LOSS [training: 0.407028623809237 | validation: 0.4696711014627716]
	TIME [epoch: 9.44 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40154132060227515		[learning rate: 5.7307e-05]
	Learning Rate: 5.73074e-05
	LOSS [training: 0.40154132060227515 | validation: 0.4210924517836891]
	TIME [epoch: 9.46 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39053683832341374		[learning rate: 5.7099e-05]
	Learning Rate: 5.70994e-05
	LOSS [training: 0.39053683832341374 | validation: 0.41025848255117175]
	TIME [epoch: 9.45 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39938758682755465		[learning rate: 5.6892e-05]
	Learning Rate: 5.68922e-05
	LOSS [training: 0.39938758682755465 | validation: 0.4868559251977691]
	TIME [epoch: 9.45 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3966496136873473		[learning rate: 5.6686e-05]
	Learning Rate: 5.66857e-05
	LOSS [training: 0.3966496136873473 | validation: 0.4746054608241168]
	TIME [epoch: 9.44 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39394830640460776		[learning rate: 5.648e-05]
	Learning Rate: 5.648e-05
	LOSS [training: 0.39394830640460776 | validation: 0.39714758615870355]
	TIME [epoch: 9.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_1524.pth
	Model improved!!!
EPOCH 1525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39703527908939573		[learning rate: 5.6275e-05]
	Learning Rate: 5.6275e-05
	LOSS [training: 0.39703527908939573 | validation: 0.47218193094933114]
	TIME [epoch: 9.43 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4243678182685812		[learning rate: 5.6071e-05]
	Learning Rate: 5.60708e-05
	LOSS [training: 0.4243678182685812 | validation: 0.44315645456656655]
	TIME [epoch: 9.43 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4124953841001724		[learning rate: 5.5867e-05]
	Learning Rate: 5.58673e-05
	LOSS [training: 0.4124953841001724 | validation: 0.4589069211126284]
	TIME [epoch: 9.43 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40628424278836234		[learning rate: 5.5665e-05]
	Learning Rate: 5.56646e-05
	LOSS [training: 0.40628424278836234 | validation: 0.42928842524106586]
	TIME [epoch: 9.45 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3925196619475755		[learning rate: 5.5463e-05]
	Learning Rate: 5.54626e-05
	LOSS [training: 0.3925196619475755 | validation: 0.4573858525907133]
	TIME [epoch: 9.43 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3882175123148338		[learning rate: 5.5261e-05]
	Learning Rate: 5.52613e-05
	LOSS [training: 0.3882175123148338 | validation: 0.4344918529922072]
	TIME [epoch: 9.43 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39218139972091876		[learning rate: 5.5061e-05]
	Learning Rate: 5.50608e-05
	LOSS [training: 0.39218139972091876 | validation: 0.4511598825801956]
	TIME [epoch: 9.43 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38727492444346967		[learning rate: 5.4861e-05]
	Learning Rate: 5.48609e-05
	LOSS [training: 0.38727492444346967 | validation: 0.4397754740628176]
	TIME [epoch: 9.45 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3946805204460749		[learning rate: 5.4662e-05]
	Learning Rate: 5.46618e-05
	LOSS [training: 0.3946805204460749 | validation: 0.4594886870846996]
	TIME [epoch: 9.43 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40084099722647615		[learning rate: 5.4463e-05]
	Learning Rate: 5.44635e-05
	LOSS [training: 0.40084099722647615 | validation: 0.5014974099271305]
	TIME [epoch: 9.43 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3982359899018852		[learning rate: 5.4266e-05]
	Learning Rate: 5.42658e-05
	LOSS [training: 0.3982359899018852 | validation: 0.47013721831565547]
	TIME [epoch: 9.43 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40158805233563005		[learning rate: 5.4069e-05]
	Learning Rate: 5.40689e-05
	LOSS [training: 0.40158805233563005 | validation: 0.49693554639647775]
	TIME [epoch: 9.44 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.389323039768268		[learning rate: 5.3873e-05]
	Learning Rate: 5.38727e-05
	LOSS [training: 0.389323039768268 | validation: 0.49469646496344577]
	TIME [epoch: 9.43 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38940260902300877		[learning rate: 5.3677e-05]
	Learning Rate: 5.36772e-05
	LOSS [training: 0.38940260902300877 | validation: 0.4504318976139662]
	TIME [epoch: 9.43 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39922176509273005		[learning rate: 5.3482e-05]
	Learning Rate: 5.34824e-05
	LOSS [training: 0.39922176509273005 | validation: 0.45738521451642244]
	TIME [epoch: 9.45 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3920757628267086		[learning rate: 5.3288e-05]
	Learning Rate: 5.32883e-05
	LOSS [training: 0.3920757628267086 | validation: 0.4748736098371403]
	TIME [epoch: 9.44 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39710411456425015		[learning rate: 5.3095e-05]
	Learning Rate: 5.30949e-05
	LOSS [training: 0.39710411456425015 | validation: 0.4694190675659993]
	TIME [epoch: 9.43 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4069630899788851		[learning rate: 5.2902e-05]
	Learning Rate: 5.29022e-05
	LOSS [training: 0.4069630899788851 | validation: 0.4268285374674701]
	TIME [epoch: 9.43 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.390415869610596		[learning rate: 5.271e-05]
	Learning Rate: 5.27102e-05
	LOSS [training: 0.390415869610596 | validation: 0.4576577031528578]
	TIME [epoch: 9.45 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.415768939838275		[learning rate: 5.2519e-05]
	Learning Rate: 5.25189e-05
	LOSS [training: 0.415768939838275 | validation: 0.4386509028506649]
	TIME [epoch: 9.43 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4069511067727033		[learning rate: 5.2328e-05]
	Learning Rate: 5.23283e-05
	LOSS [training: 0.4069511067727033 | validation: 0.42518836586953185]
	TIME [epoch: 9.43 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40268669043627525		[learning rate: 5.2138e-05]
	Learning Rate: 5.21384e-05
	LOSS [training: 0.40268669043627525 | validation: 0.4002305368844927]
	TIME [epoch: 9.43 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4216452599688987		[learning rate: 5.1949e-05]
	Learning Rate: 5.19492e-05
	LOSS [training: 0.4216452599688987 | validation: 0.40575304819083435]
	TIME [epoch: 9.45 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38923328128343027		[learning rate: 5.1761e-05]
	Learning Rate: 5.17607e-05
	LOSS [training: 0.38923328128343027 | validation: 0.4518961947934645]
	TIME [epoch: 9.43 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4012007728097883		[learning rate: 5.1573e-05]
	Learning Rate: 5.15729e-05
	LOSS [training: 0.4012007728097883 | validation: 0.4661314525655634]
	TIME [epoch: 9.43 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40251750476777365		[learning rate: 5.1386e-05]
	Learning Rate: 5.13857e-05
	LOSS [training: 0.40251750476777365 | validation: 0.4750652700240412]
	TIME [epoch: 9.43 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42417365058110573		[learning rate: 5.1199e-05]
	Learning Rate: 5.11992e-05
	LOSS [training: 0.42417365058110573 | validation: 0.4194744641776032]
	TIME [epoch: 9.45 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4012150420147428		[learning rate: 5.1013e-05]
	Learning Rate: 5.10134e-05
	LOSS [training: 0.4012150420147428 | validation: 0.46142208424843684]
	TIME [epoch: 9.43 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40021822173033117		[learning rate: 5.0828e-05]
	Learning Rate: 5.08283e-05
	LOSS [training: 0.40021822173033117 | validation: 0.4907407821614019]
	TIME [epoch: 9.43 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3987555043213541		[learning rate: 5.0644e-05]
	Learning Rate: 5.06438e-05
	LOSS [training: 0.3987555043213541 | validation: 0.43954896943000954]
	TIME [epoch: 9.43 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4024982166269271		[learning rate: 5.046e-05]
	Learning Rate: 5.046e-05
	LOSS [training: 0.4024982166269271 | validation: 0.4272877487852432]
	TIME [epoch: 9.45 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3990285308745182		[learning rate: 5.0277e-05]
	Learning Rate: 5.02769e-05
	LOSS [training: 0.3990285308745182 | validation: 0.43414006818605044]
	TIME [epoch: 9.43 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3938183273204642		[learning rate: 5.0094e-05]
	Learning Rate: 5.00944e-05
	LOSS [training: 0.3938183273204642 | validation: 0.4793549103207755]
	TIME [epoch: 9.43 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39703220291344554		[learning rate: 4.9913e-05]
	Learning Rate: 4.99127e-05
	LOSS [training: 0.39703220291344554 | validation: 0.39634773589660055]
	TIME [epoch: 9.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_1558.pth
	Model improved!!!
EPOCH 1559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3988750015622101		[learning rate: 4.9732e-05]
	Learning Rate: 4.97315e-05
	LOSS [training: 0.3988750015622101 | validation: 0.41721508982501365]
	TIME [epoch: 9.46 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41723745933358325		[learning rate: 4.9551e-05]
	Learning Rate: 4.9551e-05
	LOSS [training: 0.41723745933358325 | validation: 0.4632203917655187]
	TIME [epoch: 9.44 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3947466113200632		[learning rate: 4.9371e-05]
	Learning Rate: 4.93712e-05
	LOSS [training: 0.3947466113200632 | validation: 0.4199267527843151]
	TIME [epoch: 9.44 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4006241686013808		[learning rate: 4.9192e-05]
	Learning Rate: 4.9192e-05
	LOSS [training: 0.4006241686013808 | validation: 0.4168371163222598]
	TIME [epoch: 9.46 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39629076067796365		[learning rate: 4.9014e-05]
	Learning Rate: 4.90135e-05
	LOSS [training: 0.39629076067796365 | validation: 0.5076416431426454]
	TIME [epoch: 9.44 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3872857060522159		[learning rate: 4.8836e-05]
	Learning Rate: 4.88356e-05
	LOSS [training: 0.3872857060522159 | validation: 0.48150357565712354]
	TIME [epoch: 9.44 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3937566738312782		[learning rate: 4.8658e-05]
	Learning Rate: 4.86584e-05
	LOSS [training: 0.3937566738312782 | validation: 0.40907372588752594]
	TIME [epoch: 9.44 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3956469638614756		[learning rate: 4.8482e-05]
	Learning Rate: 4.84818e-05
	LOSS [training: 0.3956469638614756 | validation: 0.4123921683615356]
	TIME [epoch: 9.46 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41268894357907654		[learning rate: 4.8306e-05]
	Learning Rate: 4.83059e-05
	LOSS [training: 0.41268894357907654 | validation: 0.45091399650440805]
	TIME [epoch: 9.44 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4088034079272106		[learning rate: 4.8131e-05]
	Learning Rate: 4.81306e-05
	LOSS [training: 0.4088034079272106 | validation: 0.41305458104608833]
	TIME [epoch: 9.44 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39586865420764566		[learning rate: 4.7956e-05]
	Learning Rate: 4.79559e-05
	LOSS [training: 0.39586865420764566 | validation: 0.45746461097507296]
	TIME [epoch: 9.44 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3950763561450711		[learning rate: 4.7782e-05]
	Learning Rate: 4.77819e-05
	LOSS [training: 0.3950763561450711 | validation: 0.44870721901277827]
	TIME [epoch: 9.46 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3984941432304348		[learning rate: 4.7608e-05]
	Learning Rate: 4.76085e-05
	LOSS [training: 0.3984941432304348 | validation: 0.4558022565486236]
	TIME [epoch: 9.44 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39289540137028583		[learning rate: 4.7436e-05]
	Learning Rate: 4.74357e-05
	LOSS [training: 0.39289540137028583 | validation: 0.42432820990692516]
	TIME [epoch: 9.44 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.397619705738373		[learning rate: 4.7264e-05]
	Learning Rate: 4.72636e-05
	LOSS [training: 0.397619705738373 | validation: 0.40954462141452164]
	TIME [epoch: 9.44 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40162506699979206		[learning rate: 4.7092e-05]
	Learning Rate: 4.7092e-05
	LOSS [training: 0.40162506699979206 | validation: 0.507512772262366]
	TIME [epoch: 9.46 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40086749793194026		[learning rate: 4.6921e-05]
	Learning Rate: 4.69211e-05
	LOSS [training: 0.40086749793194026 | validation: 0.4625598374298923]
	TIME [epoch: 9.43 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.392648592757751		[learning rate: 4.6751e-05]
	Learning Rate: 4.67508e-05
	LOSS [training: 0.392648592757751 | validation: 0.4946809467350234]
	TIME [epoch: 9.44 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3954190117386248		[learning rate: 4.6581e-05]
	Learning Rate: 4.65812e-05
	LOSS [training: 0.3954190117386248 | validation: 0.4082202040407559]
	TIME [epoch: 9.44 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42384310266306047		[learning rate: 4.6412e-05]
	Learning Rate: 4.64121e-05
	LOSS [training: 0.42384310266306047 | validation: 0.4459504205367817]
	TIME [epoch: 9.45 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40752985848910095		[learning rate: 4.6244e-05]
	Learning Rate: 4.62437e-05
	LOSS [training: 0.40752985848910095 | validation: 0.38614076110410955]
	TIME [epoch: 9.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_1579.pth
	Model improved!!!
EPOCH 1580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4112145148387339		[learning rate: 4.6076e-05]
	Learning Rate: 4.60759e-05
	LOSS [training: 0.4112145148387339 | validation: 0.4216654374366924]
	TIME [epoch: 9.45 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37928601357322145		[learning rate: 4.5909e-05]
	Learning Rate: 4.59087e-05
	LOSS [training: 0.37928601357322145 | validation: 0.45335264887005494]
	TIME [epoch: 9.47 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3985045101048855		[learning rate: 4.5742e-05]
	Learning Rate: 4.57421e-05
	LOSS [training: 0.3985045101048855 | validation: 0.49331335399960424]
	TIME [epoch: 9.45 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38948394851985246		[learning rate: 4.5576e-05]
	Learning Rate: 4.55761e-05
	LOSS [training: 0.38948394851985246 | validation: 0.4327276778621551]
	TIME [epoch: 9.44 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39532466610678296		[learning rate: 4.5411e-05]
	Learning Rate: 4.54107e-05
	LOSS [training: 0.39532466610678296 | validation: 0.48555342136073154]
	TIME [epoch: 9.45 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39399952142148287		[learning rate: 4.5246e-05]
	Learning Rate: 4.52459e-05
	LOSS [training: 0.39399952142148287 | validation: 0.4627717847406639]
	TIME [epoch: 9.47 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.386715425000198		[learning rate: 4.5082e-05]
	Learning Rate: 4.50817e-05
	LOSS [training: 0.386715425000198 | validation: 0.4970018228984676]
	TIME [epoch: 9.45 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39835992306640156		[learning rate: 4.4918e-05]
	Learning Rate: 4.49181e-05
	LOSS [training: 0.39835992306640156 | validation: 0.4287917316440711]
	TIME [epoch: 9.45 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3978495233987448		[learning rate: 4.4755e-05]
	Learning Rate: 4.47551e-05
	LOSS [training: 0.3978495233987448 | validation: 0.5007885616206132]
	TIME [epoch: 9.45 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4048531247739594		[learning rate: 4.4593e-05]
	Learning Rate: 4.45926e-05
	LOSS [training: 0.4048531247739594 | validation: 0.46364051559140607]
	TIME [epoch: 9.47 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39252807749003965		[learning rate: 4.4431e-05]
	Learning Rate: 4.44308e-05
	LOSS [training: 0.39252807749003965 | validation: 0.41419429294693916]
	TIME [epoch: 9.45 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39751603038262273		[learning rate: 4.427e-05]
	Learning Rate: 4.42696e-05
	LOSS [training: 0.39751603038262273 | validation: 0.4514995666458637]
	TIME [epoch: 9.45 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39367512252588965		[learning rate: 4.4109e-05]
	Learning Rate: 4.41089e-05
	LOSS [training: 0.39367512252588965 | validation: 0.42502403462450744]
	TIME [epoch: 9.45 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39125854449064734		[learning rate: 4.3949e-05]
	Learning Rate: 4.39489e-05
	LOSS [training: 0.39125854449064734 | validation: 0.41795647890229276]
	TIME [epoch: 9.47 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3969175289226493		[learning rate: 4.3789e-05]
	Learning Rate: 4.37893e-05
	LOSS [training: 0.3969175289226493 | validation: 0.44088915359026215]
	TIME [epoch: 9.45 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38915341611419174		[learning rate: 4.363e-05]
	Learning Rate: 4.36304e-05
	LOSS [training: 0.38915341611419174 | validation: 0.4472296015225075]
	TIME [epoch: 9.45 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.413944489763851		[learning rate: 4.3472e-05]
	Learning Rate: 4.34721e-05
	LOSS [training: 0.413944489763851 | validation: 0.41234011731534126]
	TIME [epoch: 9.46 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3980586630354233		[learning rate: 4.3314e-05]
	Learning Rate: 4.33143e-05
	LOSS [training: 0.3980586630354233 | validation: 0.4385281053649092]
	TIME [epoch: 9.46 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3894881335190041		[learning rate: 4.3157e-05]
	Learning Rate: 4.31571e-05
	LOSS [training: 0.3894881335190041 | validation: 0.4603623980365329]
	TIME [epoch: 9.45 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40057800201519456		[learning rate: 4.3001e-05]
	Learning Rate: 4.30005e-05
	LOSS [training: 0.40057800201519456 | validation: 0.4787547369753785]
	TIME [epoch: 9.45 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3959596994043106		[learning rate: 4.2844e-05]
	Learning Rate: 4.28445e-05
	LOSS [training: 0.3959596994043106 | validation: 0.4305617912599793]
	TIME [epoch: 9.47 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38702018359141716		[learning rate: 4.2689e-05]
	Learning Rate: 4.2689e-05
	LOSS [training: 0.38702018359141716 | validation: 0.429999941367154]
	TIME [epoch: 9.45 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39585971894722083		[learning rate: 4.2534e-05]
	Learning Rate: 4.25341e-05
	LOSS [training: 0.39585971894722083 | validation: 0.42175774647625125]
	TIME [epoch: 9.45 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4113723397723364		[learning rate: 4.238e-05]
	Learning Rate: 4.23797e-05
	LOSS [training: 0.4113723397723364 | validation: 0.43177950897487805]
	TIME [epoch: 9.45 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3941282246397635		[learning rate: 4.2226e-05]
	Learning Rate: 4.22259e-05
	LOSS [training: 0.3941282246397635 | validation: 0.4490888179041471]
	TIME [epoch: 9.47 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3901903995668757		[learning rate: 4.2073e-05]
	Learning Rate: 4.20727e-05
	LOSS [training: 0.3901903995668757 | validation: 0.4374565174980407]
	TIME [epoch: 9.45 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4079571778358684		[learning rate: 4.192e-05]
	Learning Rate: 4.192e-05
	LOSS [training: 0.4079571778358684 | validation: 0.43943741222166227]
	TIME [epoch: 9.45 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3911325013730805		[learning rate: 4.1768e-05]
	Learning Rate: 4.17679e-05
	LOSS [training: 0.3911325013730805 | validation: 0.4565029970089728]
	TIME [epoch: 9.45 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4245045906472769		[learning rate: 4.1616e-05]
	Learning Rate: 4.16163e-05
	LOSS [training: 0.4245045906472769 | validation: 0.48069118679014744]
	TIME [epoch: 9.47 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3955804759199479		[learning rate: 4.1465e-05]
	Learning Rate: 4.14652e-05
	LOSS [training: 0.3955804759199479 | validation: 0.39128081549753263]
	TIME [epoch: 9.45 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38763560146377163		[learning rate: 4.1315e-05]
	Learning Rate: 4.13148e-05
	LOSS [training: 0.38763560146377163 | validation: 0.42859453755048227]
	TIME [epoch: 9.45 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39090309282198393		[learning rate: 4.1165e-05]
	Learning Rate: 4.11648e-05
	LOSS [training: 0.39090309282198393 | validation: 0.44159906891097633]
	TIME [epoch: 9.45 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3957823115644799		[learning rate: 4.1015e-05]
	Learning Rate: 4.10154e-05
	LOSS [training: 0.3957823115644799 | validation: 0.41368380605732924]
	TIME [epoch: 9.47 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39448342075452736		[learning rate: 4.0867e-05]
	Learning Rate: 4.08666e-05
	LOSS [training: 0.39448342075452736 | validation: 0.4501744490297565]
	TIME [epoch: 9.45 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4060618240794499		[learning rate: 4.0718e-05]
	Learning Rate: 4.07183e-05
	LOSS [training: 0.4060618240794499 | validation: 0.40027835609058576]
	TIME [epoch: 9.45 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40208157001908784		[learning rate: 4.0571e-05]
	Learning Rate: 4.05705e-05
	LOSS [training: 0.40208157001908784 | validation: 0.41268649867001905]
	TIME [epoch: 9.46 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4020197992389858		[learning rate: 4.0423e-05]
	Learning Rate: 4.04233e-05
	LOSS [training: 0.4020197992389858 | validation: 0.433636972425042]
	TIME [epoch: 9.47 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3976003563567928		[learning rate: 4.0277e-05]
	Learning Rate: 4.02766e-05
	LOSS [training: 0.3976003563567928 | validation: 0.42102172158878987]
	TIME [epoch: 9.45 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39329034745478814		[learning rate: 4.013e-05]
	Learning Rate: 4.01304e-05
	LOSS [training: 0.39329034745478814 | validation: 0.4077300532211486]
	TIME [epoch: 9.45 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3882768340707966		[learning rate: 3.9985e-05]
	Learning Rate: 3.99848e-05
	LOSS [training: 0.3882768340707966 | validation: 0.37829669463339843]
	TIME [epoch: 9.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_1619.pth
	Model improved!!!
EPOCH 1620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3994098033537462		[learning rate: 3.984e-05]
	Learning Rate: 3.98397e-05
	LOSS [training: 0.3994098033537462 | validation: 0.45169029582361997]
	TIME [epoch: 9.46 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4155734141545281		[learning rate: 3.9695e-05]
	Learning Rate: 3.96951e-05
	LOSS [training: 0.4155734141545281 | validation: 0.4105943074661728]
	TIME [epoch: 9.45 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4020399932215718		[learning rate: 3.9551e-05]
	Learning Rate: 3.9551e-05
	LOSS [training: 0.4020399932215718 | validation: 0.4371354855660405]
	TIME [epoch: 9.45 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40504641771385375		[learning rate: 3.9408e-05]
	Learning Rate: 3.94075e-05
	LOSS [training: 0.40504641771385375 | validation: 0.41177915453260894]
	TIME [epoch: 9.47 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3885387709197512		[learning rate: 3.9264e-05]
	Learning Rate: 3.92645e-05
	LOSS [training: 0.3885387709197512 | validation: 0.40596420961738344]
	TIME [epoch: 9.45 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41186396219514376		[learning rate: 3.9122e-05]
	Learning Rate: 3.9122e-05
	LOSS [training: 0.41186396219514376 | validation: 0.41599430164545936]
	TIME [epoch: 9.45 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3815150437607947		[learning rate: 3.898e-05]
	Learning Rate: 3.898e-05
	LOSS [training: 0.3815150437607947 | validation: 0.4160142708525993]
	TIME [epoch: 9.45 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3970489058299485		[learning rate: 3.8839e-05]
	Learning Rate: 3.88386e-05
	LOSS [training: 0.3970489058299485 | validation: 0.49957949417166986]
	TIME [epoch: 9.47 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3899394980684744		[learning rate: 3.8698e-05]
	Learning Rate: 3.86976e-05
	LOSS [training: 0.3899394980684744 | validation: 0.5151232263600074]
	TIME [epoch: 9.45 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4051385272144878		[learning rate: 3.8557e-05]
	Learning Rate: 3.85572e-05
	LOSS [training: 0.4051385272144878 | validation: 0.41837813698237747]
	TIME [epoch: 9.45 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41643728628477356		[learning rate: 3.8417e-05]
	Learning Rate: 3.84173e-05
	LOSS [training: 0.41643728628477356 | validation: 0.43731551560437815]
	TIME [epoch: 9.45 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40710005789534154		[learning rate: 3.8278e-05]
	Learning Rate: 3.82778e-05
	LOSS [training: 0.40710005789534154 | validation: 0.4353020339517258]
	TIME [epoch: 9.47 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3991433828057104		[learning rate: 3.8139e-05]
	Learning Rate: 3.81389e-05
	LOSS [training: 0.3991433828057104 | validation: 0.39299866520620336]
	TIME [epoch: 9.45 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39794745518458297		[learning rate: 3.8001e-05]
	Learning Rate: 3.80005e-05
	LOSS [training: 0.39794745518458297 | validation: 0.4577908285370728]
	TIME [epoch: 9.45 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40396886045255487		[learning rate: 3.7863e-05]
	Learning Rate: 3.78626e-05
	LOSS [training: 0.40396886045255487 | validation: 0.43985303023480643]
	TIME [epoch: 9.45 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39616961502349224		[learning rate: 3.7725e-05]
	Learning Rate: 3.77252e-05
	LOSS [training: 0.39616961502349224 | validation: 0.4950138031988422]
	TIME [epoch: 9.47 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3949254457358578		[learning rate: 3.7588e-05]
	Learning Rate: 3.75883e-05
	LOSS [training: 0.3949254457358578 | validation: 0.45548904138346175]
	TIME [epoch: 9.45 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40268131211055425		[learning rate: 3.7452e-05]
	Learning Rate: 3.74519e-05
	LOSS [training: 0.40268131211055425 | validation: 0.4563616006782024]
	TIME [epoch: 9.45 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40275085975647434		[learning rate: 3.7316e-05]
	Learning Rate: 3.7316e-05
	LOSS [training: 0.40275085975647434 | validation: 0.42644671438385273]
	TIME [epoch: 9.46 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3930060433368655		[learning rate: 3.7181e-05]
	Learning Rate: 3.71805e-05
	LOSS [training: 0.3930060433368655 | validation: 0.40756424933236174]
	TIME [epoch: 9.45 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40172256250842314		[learning rate: 3.7046e-05]
	Learning Rate: 3.70456e-05
	LOSS [training: 0.40172256250842314 | validation: 0.4174694782592887]
	TIME [epoch: 9.45 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3846639911217704		[learning rate: 3.6911e-05]
	Learning Rate: 3.69112e-05
	LOSS [training: 0.3846639911217704 | validation: 0.45399270053613444]
	TIME [epoch: 9.45 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38248856287442284		[learning rate: 3.6777e-05]
	Learning Rate: 3.67772e-05
	LOSS [training: 0.38248856287442284 | validation: 0.48496988623376225]
	TIME [epoch: 9.47 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3915282040756598		[learning rate: 3.6644e-05]
	Learning Rate: 3.66438e-05
	LOSS [training: 0.3915282040756598 | validation: 0.4479689936622446]
	TIME [epoch: 9.45 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3914374853458683		[learning rate: 3.6511e-05]
	Learning Rate: 3.65108e-05
	LOSS [training: 0.3914374853458683 | validation: 0.4059820520001566]
	TIME [epoch: 9.45 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39816905353381565		[learning rate: 3.6378e-05]
	Learning Rate: 3.63783e-05
	LOSS [training: 0.39816905353381565 | validation: 0.47266645151911557]
	TIME [epoch: 9.45 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3986393843779615		[learning rate: 3.6246e-05]
	Learning Rate: 3.62463e-05
	LOSS [training: 0.3986393843779615 | validation: 0.49683994189054886]
	TIME [epoch: 9.47 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3937912515879324		[learning rate: 3.6115e-05]
	Learning Rate: 3.61147e-05
	LOSS [training: 0.3937912515879324 | validation: 0.4775409554426932]
	TIME [epoch: 9.46 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4015012886271216		[learning rate: 3.5984e-05]
	Learning Rate: 3.59837e-05
	LOSS [training: 0.4015012886271216 | validation: 0.42975280872591953]
	TIME [epoch: 9.45 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39322068155406625		[learning rate: 3.5853e-05]
	Learning Rate: 3.58531e-05
	LOSS [training: 0.39322068155406625 | validation: 0.4396703392030935]
	TIME [epoch: 9.45 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3917026001252383		[learning rate: 3.5723e-05]
	Learning Rate: 3.5723e-05
	LOSS [training: 0.3917026001252383 | validation: 0.40870311051378994]
	TIME [epoch: 9.48 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39428915913592794		[learning rate: 3.5593e-05]
	Learning Rate: 3.55933e-05
	LOSS [training: 0.39428915913592794 | validation: 0.46487922497491185]
	TIME [epoch: 9.45 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4142862701445891		[learning rate: 3.5464e-05]
	Learning Rate: 3.54641e-05
	LOSS [training: 0.4142862701445891 | validation: 0.4236685764031104]
	TIME [epoch: 9.45 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39877614800642935		[learning rate: 3.5335e-05]
	Learning Rate: 3.53354e-05
	LOSS [training: 0.39877614800642935 | validation: 0.40450395845142645]
	TIME [epoch: 9.45 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3857516523431258		[learning rate: 3.5207e-05]
	Learning Rate: 3.52072e-05
	LOSS [training: 0.3857516523431258 | validation: 0.4212920685483767]
	TIME [epoch: 9.48 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3864805258629353		[learning rate: 3.5079e-05]
	Learning Rate: 3.50794e-05
	LOSS [training: 0.3864805258629353 | validation: 0.4163667142387186]
	TIME [epoch: 9.45 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4139146090829368		[learning rate: 3.4952e-05]
	Learning Rate: 3.49521e-05
	LOSS [training: 0.4139146090829368 | validation: 0.41786758004075497]
	TIME [epoch: 9.45 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4031825201569165		[learning rate: 3.4825e-05]
	Learning Rate: 3.48253e-05
	LOSS [training: 0.4031825201569165 | validation: 0.45460700136154847]
	TIME [epoch: 9.46 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4058886148888653		[learning rate: 3.4699e-05]
	Learning Rate: 3.46989e-05
	LOSS [training: 0.4058886148888653 | validation: 0.44156162860471043]
	TIME [epoch: 9.47 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39749564002407484		[learning rate: 3.4573e-05]
	Learning Rate: 3.4573e-05
	LOSS [training: 0.39749564002407484 | validation: 0.4306805626176042]
	TIME [epoch: 9.45 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3861298032541708		[learning rate: 3.4448e-05]
	Learning Rate: 3.44475e-05
	LOSS [training: 0.3861298032541708 | validation: 0.43792759115574564]
	TIME [epoch: 9.45 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40080474888675666		[learning rate: 3.4323e-05]
	Learning Rate: 3.43225e-05
	LOSS [training: 0.40080474888675666 | validation: 0.42792345533353543]
	TIME [epoch: 9.47 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3880722164756937		[learning rate: 3.4198e-05]
	Learning Rate: 3.4198e-05
	LOSS [training: 0.3880722164756937 | validation: 0.4353668289307639]
	TIME [epoch: 9.45 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3918499366037301		[learning rate: 3.4074e-05]
	Learning Rate: 3.40738e-05
	LOSS [training: 0.3918499366037301 | validation: 0.4781258912091226]
	TIME [epoch: 9.45 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40271160616819746		[learning rate: 3.395e-05]
	Learning Rate: 3.39502e-05
	LOSS [training: 0.40271160616819746 | validation: 0.43882478952728377]
	TIME [epoch: 9.45 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3882763212735551		[learning rate: 3.3827e-05]
	Learning Rate: 3.3827e-05
	LOSS [training: 0.3882763212735551 | validation: 0.44803222013267785]
	TIME [epoch: 9.47 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3943361386030878		[learning rate: 3.3704e-05]
	Learning Rate: 3.37042e-05
	LOSS [training: 0.3943361386030878 | validation: 0.43914202829681726]
	TIME [epoch: 9.45 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40879520451268725		[learning rate: 3.3582e-05]
	Learning Rate: 3.35819e-05
	LOSS [training: 0.40879520451268725 | validation: 0.44305161017445316]
	TIME [epoch: 9.45 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4037856305910637		[learning rate: 3.346e-05]
	Learning Rate: 3.346e-05
	LOSS [training: 0.4037856305910637 | validation: 0.4868627039836892]
	TIME [epoch: 9.45 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3946678978891314		[learning rate: 3.3339e-05]
	Learning Rate: 3.33386e-05
	LOSS [training: 0.3946678978891314 | validation: 0.49689753759086186]
	TIME [epoch: 9.48 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38794808570195594		[learning rate: 3.3218e-05]
	Learning Rate: 3.32176e-05
	LOSS [training: 0.38794808570195594 | validation: 0.3915212486401231]
	TIME [epoch: 9.45 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3958591529909538		[learning rate: 3.3097e-05]
	Learning Rate: 3.30971e-05
	LOSS [training: 0.3958591529909538 | validation: 0.40905821619580934]
	TIME [epoch: 9.45 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.417934453906167		[learning rate: 3.2977e-05]
	Learning Rate: 3.2977e-05
	LOSS [training: 0.417934453906167 | validation: 0.3875612343506488]
	TIME [epoch: 9.45 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39944828588469433		[learning rate: 3.2857e-05]
	Learning Rate: 3.28573e-05
	LOSS [training: 0.39944828588469433 | validation: 0.41952234449696224]
	TIME [epoch: 9.47 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3990727832545413		[learning rate: 3.2738e-05]
	Learning Rate: 3.2738e-05
	LOSS [training: 0.3990727832545413 | validation: 0.4680564133240093]
	TIME [epoch: 9.45 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39586184484796305		[learning rate: 3.2619e-05]
	Learning Rate: 3.26192e-05
	LOSS [training: 0.39586184484796305 | validation: 0.4189009317213055]
	TIME [epoch: 9.45 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4005553949882499		[learning rate: 3.2501e-05]
	Learning Rate: 3.25009e-05
	LOSS [training: 0.4005553949882499 | validation: 0.42970998113136183]
	TIME [epoch: 9.46 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40111942572585846		[learning rate: 3.2383e-05]
	Learning Rate: 3.23829e-05
	LOSS [training: 0.40111942572585846 | validation: 0.4310533380539262]
	TIME [epoch: 9.46 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3867159885085656		[learning rate: 3.2265e-05]
	Learning Rate: 3.22654e-05
	LOSS [training: 0.3867159885085656 | validation: 0.4299761850764615]
	TIME [epoch: 9.45 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3948405182669279		[learning rate: 3.2148e-05]
	Learning Rate: 3.21483e-05
	LOSS [training: 0.3948405182669279 | validation: 0.4182399193763717]
	TIME [epoch: 9.45 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40686947901808646		[learning rate: 3.2032e-05]
	Learning Rate: 3.20316e-05
	LOSS [training: 0.40686947901808646 | validation: 0.4118498257086247]
	TIME [epoch: 9.47 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3907707973654452		[learning rate: 3.1915e-05]
	Learning Rate: 3.19154e-05
	LOSS [training: 0.3907707973654452 | validation: 0.46480457414561527]
	TIME [epoch: 9.45 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39792849475634806		[learning rate: 3.18e-05]
	Learning Rate: 3.17996e-05
	LOSS [training: 0.39792849475634806 | validation: 0.46948599305117117]
	TIME [epoch: 9.45 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40325498136007737		[learning rate: 3.1684e-05]
	Learning Rate: 3.16842e-05
	LOSS [training: 0.40325498136007737 | validation: 0.46432594969868746]
	TIME [epoch: 9.45 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39387990649639715		[learning rate: 3.1569e-05]
	Learning Rate: 3.15692e-05
	LOSS [training: 0.39387990649639715 | validation: 0.41333301467123934]
	TIME [epoch: 9.47 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4040064142816301		[learning rate: 3.1455e-05]
	Learning Rate: 3.14546e-05
	LOSS [training: 0.4040064142816301 | validation: 0.42238498654822015]
	TIME [epoch: 9.45 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4007740605411376		[learning rate: 3.134e-05]
	Learning Rate: 3.13405e-05
	LOSS [training: 0.4007740605411376 | validation: 0.5072245660587309]
	TIME [epoch: 9.45 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3964602440522886		[learning rate: 3.1227e-05]
	Learning Rate: 3.12267e-05
	LOSS [training: 0.3964602440522886 | validation: 0.4095649076462488]
	TIME [epoch: 9.45 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38490999265089454		[learning rate: 3.1113e-05]
	Learning Rate: 3.11134e-05
	LOSS [training: 0.38490999265089454 | validation: 0.4673186700416541]
	TIME [epoch: 9.47 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3929639463009743		[learning rate: 3.1e-05]
	Learning Rate: 3.10005e-05
	LOSS [training: 0.3929639463009743 | validation: 0.43540427776543694]
	TIME [epoch: 9.45 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40647404274702925		[learning rate: 3.0888e-05]
	Learning Rate: 3.0888e-05
	LOSS [training: 0.40647404274702925 | validation: 0.421469847608749]
	TIME [epoch: 9.45 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3968873352699568		[learning rate: 3.0776e-05]
	Learning Rate: 3.07759e-05
	LOSS [training: 0.3968873352699568 | validation: 0.49416927437302277]
	TIME [epoch: 9.45 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39780434099501927		[learning rate: 3.0664e-05]
	Learning Rate: 3.06642e-05
	LOSS [training: 0.39780434099501927 | validation: 0.4751076941737881]
	TIME [epoch: 9.47 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4015554268021031		[learning rate: 3.0553e-05]
	Learning Rate: 3.05529e-05
	LOSS [training: 0.4015554268021031 | validation: 0.4356570496913866]
	TIME [epoch: 9.45 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4022352581965597		[learning rate: 3.0442e-05]
	Learning Rate: 3.0442e-05
	LOSS [training: 0.4022352581965597 | validation: 0.41575623489431723]
	TIME [epoch: 9.45 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39145445736398776		[learning rate: 3.0332e-05]
	Learning Rate: 3.03316e-05
	LOSS [training: 0.39145445736398776 | validation: 0.43240593540631117]
	TIME [epoch: 9.46 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3993206811515211		[learning rate: 3.0221e-05]
	Learning Rate: 3.02215e-05
	LOSS [training: 0.3993206811515211 | validation: 0.4417644120948235]
	TIME [epoch: 9.46 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39153690282449627		[learning rate: 3.0112e-05]
	Learning Rate: 3.01118e-05
	LOSS [training: 0.39153690282449627 | validation: 0.4801144493262731]
	TIME [epoch: 9.45 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4007430625800247		[learning rate: 3.0003e-05]
	Learning Rate: 3.00025e-05
	LOSS [training: 0.4007430625800247 | validation: 0.4450447724268372]
	TIME [epoch: 9.45 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40148772420375656		[learning rate: 2.9894e-05]
	Learning Rate: 2.98936e-05
	LOSS [training: 0.40148772420375656 | validation: 0.4035209616188993]
	TIME [epoch: 9.46 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40597406851661066		[learning rate: 2.9785e-05]
	Learning Rate: 2.97852e-05
	LOSS [training: 0.40597406851661066 | validation: 0.45042472858716565]
	TIME [epoch: 9.45 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3970419498801031		[learning rate: 2.9677e-05]
	Learning Rate: 2.96771e-05
	LOSS [training: 0.3970419498801031 | validation: 0.45021090050748214]
	TIME [epoch: 9.45 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38834047153222484		[learning rate: 2.9569e-05]
	Learning Rate: 2.95694e-05
	LOSS [training: 0.38834047153222484 | validation: 0.41424818825918136]
	TIME [epoch: 9.45 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39648809010426855		[learning rate: 2.9462e-05]
	Learning Rate: 2.94621e-05
	LOSS [training: 0.39648809010426855 | validation: 0.45700568206635384]
	TIME [epoch: 9.47 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4018429553134002		[learning rate: 2.9355e-05]
	Learning Rate: 2.93551e-05
	LOSS [training: 0.4018429553134002 | validation: 0.4574094242635507]
	TIME [epoch: 9.45 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4117849177068519		[learning rate: 2.9249e-05]
	Learning Rate: 2.92486e-05
	LOSS [training: 0.4117849177068519 | validation: 0.3997094893245376]
	TIME [epoch: 9.45 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3983803039615849		[learning rate: 2.9142e-05]
	Learning Rate: 2.91425e-05
	LOSS [training: 0.3983803039615849 | validation: 0.4036055443980166]
	TIME [epoch: 9.45 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38913773441309013		[learning rate: 2.9037e-05]
	Learning Rate: 2.90367e-05
	LOSS [training: 0.38913773441309013 | validation: 0.4070763356386229]
	TIME [epoch: 9.47 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39678416735942557		[learning rate: 2.8931e-05]
	Learning Rate: 2.89313e-05
	LOSS [training: 0.39678416735942557 | validation: 0.40802904596650685]
	TIME [epoch: 9.45 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4005554784845457		[learning rate: 2.8826e-05]
	Learning Rate: 2.88263e-05
	LOSS [training: 0.4005554784845457 | validation: 0.4551443059090643]
	TIME [epoch: 9.45 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3898141972951768		[learning rate: 2.8722e-05]
	Learning Rate: 2.87217e-05
	LOSS [training: 0.3898141972951768 | validation: 0.4614698851902422]
	TIME [epoch: 9.45 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4007126651590234		[learning rate: 2.8617e-05]
	Learning Rate: 2.86175e-05
	LOSS [training: 0.4007126651590234 | validation: 0.4183529084203953]
	TIME [epoch: 9.47 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3903222565990676		[learning rate: 2.8514e-05]
	Learning Rate: 2.85136e-05
	LOSS [training: 0.3903222565990676 | validation: 0.4134332507526017]
	TIME [epoch: 9.45 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3845959037337247		[learning rate: 2.841e-05]
	Learning Rate: 2.84102e-05
	LOSS [training: 0.3845959037337247 | validation: 0.419495581355651]
	TIME [epoch: 9.45 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39132838388572794		[learning rate: 2.8307e-05]
	Learning Rate: 2.83071e-05
	LOSS [training: 0.39132838388572794 | validation: 0.39617842770649164]
	TIME [epoch: 9.45 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3862266807442756		[learning rate: 2.8204e-05]
	Learning Rate: 2.82043e-05
	LOSS [training: 0.3862266807442756 | validation: 0.40012583059001267]
	TIME [epoch: 9.47 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39654903208596476		[learning rate: 2.8102e-05]
	Learning Rate: 2.8102e-05
	LOSS [training: 0.39654903208596476 | validation: 0.4308342755443924]
	TIME [epoch: 9.45 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.390656133381073		[learning rate: 2.8e-05]
	Learning Rate: 2.8e-05
	LOSS [training: 0.390656133381073 | validation: 0.4414950253376959]
	TIME [epoch: 9.45 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3997358616164465		[learning rate: 2.7898e-05]
	Learning Rate: 2.78984e-05
	LOSS [training: 0.3997358616164465 | validation: 0.44142190760508015]
	TIME [epoch: 9.45 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3860642345439146		[learning rate: 2.7797e-05]
	Learning Rate: 2.77971e-05
	LOSS [training: 0.3860642345439146 | validation: 0.4464957902278256]
	TIME [epoch: 9.47 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39148682791852657		[learning rate: 2.7696e-05]
	Learning Rate: 2.76963e-05
	LOSS [training: 0.39148682791852657 | validation: 0.4207503108857382]
	TIME [epoch: 9.45 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39092328108974217		[learning rate: 2.7596e-05]
	Learning Rate: 2.75957e-05
	LOSS [training: 0.39092328108974217 | validation: 0.454934879623815]
	TIME [epoch: 9.45 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3975689084750804		[learning rate: 2.7496e-05]
	Learning Rate: 2.74956e-05
	LOSS [training: 0.3975689084750804 | validation: 0.4293645050250538]
	TIME [epoch: 9.47 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4041245787436588		[learning rate: 2.7396e-05]
	Learning Rate: 2.73958e-05
	LOSS [training: 0.4041245787436588 | validation: 0.4340804017189396]
	TIME [epoch: 9.45 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4003435017826386		[learning rate: 2.7296e-05]
	Learning Rate: 2.72964e-05
	LOSS [training: 0.4003435017826386 | validation: 0.40065212480980306]
	TIME [epoch: 9.45 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3958922720346061		[learning rate: 2.7197e-05]
	Learning Rate: 2.71973e-05
	LOSS [training: 0.3958922720346061 | validation: 0.4168745785060316]
	TIME [epoch: 9.45 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39897443359984885		[learning rate: 2.7099e-05]
	Learning Rate: 2.70986e-05
	LOSS [training: 0.39897443359984885 | validation: 0.4142828938307175]
	TIME [epoch: 9.47 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41103786054793956		[learning rate: 2.7e-05]
	Learning Rate: 2.70003e-05
	LOSS [training: 0.41103786054793956 | validation: 0.4070213784697826]
	TIME [epoch: 9.45 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40311820028385237		[learning rate: 2.6902e-05]
	Learning Rate: 2.69023e-05
	LOSS [training: 0.40311820028385237 | validation: 0.46131932117095015]
	TIME [epoch: 9.44 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3914626162843421		[learning rate: 2.6805e-05]
	Learning Rate: 2.68047e-05
	LOSS [training: 0.3914626162843421 | validation: 0.4437658965635444]
	TIME [epoch: 9.44 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40577493499893097		[learning rate: 2.6707e-05]
	Learning Rate: 2.67074e-05
	LOSS [training: 0.40577493499893097 | validation: 0.4876281143445152]
	TIME [epoch: 9.47 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39327658962706247		[learning rate: 2.661e-05]
	Learning Rate: 2.66105e-05
	LOSS [training: 0.39327658962706247 | validation: 0.4805286942963479]
	TIME [epoch: 9.45 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.392648373462369		[learning rate: 2.6514e-05]
	Learning Rate: 2.65139e-05
	LOSS [training: 0.392648373462369 | validation: 0.4471963449050377]
	TIME [epoch: 9.45 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.412405384102808		[learning rate: 2.6418e-05]
	Learning Rate: 2.64177e-05
	LOSS [training: 0.412405384102808 | validation: 0.4007532284458595]
	TIME [epoch: 9.44 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37703244589670826		[learning rate: 2.6322e-05]
	Learning Rate: 2.63218e-05
	LOSS [training: 0.37703244589670826 | validation: 0.45719250577138326]
	TIME [epoch: 9.47 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39740908820541804		[learning rate: 2.6226e-05]
	Learning Rate: 2.62263e-05
	LOSS [training: 0.39740908820541804 | validation: 0.4528469004658712]
	TIME [epoch: 9.45 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4163531293952576		[learning rate: 2.6131e-05]
	Learning Rate: 2.61311e-05
	LOSS [training: 0.4163531293952576 | validation: 0.41932207211979994]
	TIME [epoch: 9.45 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41883466291355564		[learning rate: 2.6036e-05]
	Learning Rate: 2.60363e-05
	LOSS [training: 0.41883466291355564 | validation: 0.4020589563611357]
	TIME [epoch: 9.45 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3956192087052032		[learning rate: 2.5942e-05]
	Learning Rate: 2.59418e-05
	LOSS [training: 0.3956192087052032 | validation: 0.43380062479698067]
	TIME [epoch: 9.46 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4035309697717101		[learning rate: 2.5848e-05]
	Learning Rate: 2.58477e-05
	LOSS [training: 0.4035309697717101 | validation: 0.431393767804332]
	TIME [epoch: 9.45 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3988619601157246		[learning rate: 2.5754e-05]
	Learning Rate: 2.57539e-05
	LOSS [training: 0.3988619601157246 | validation: 0.45175026762698695]
	TIME [epoch: 9.45 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39183569772912935		[learning rate: 2.566e-05]
	Learning Rate: 2.56604e-05
	LOSS [training: 0.39183569772912935 | validation: 0.44138350922679]
	TIME [epoch: 9.46 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.404544213408077		[learning rate: 2.5567e-05]
	Learning Rate: 2.55673e-05
	LOSS [training: 0.404544213408077 | validation: 0.4156939256851966]
	TIME [epoch: 9.45 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3895270242704244		[learning rate: 2.5474e-05]
	Learning Rate: 2.54745e-05
	LOSS [training: 0.3895270242704244 | validation: 0.4414494901618716]
	TIME [epoch: 9.45 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39036575215181396		[learning rate: 2.5382e-05]
	Learning Rate: 2.5382e-05
	LOSS [training: 0.39036575215181396 | validation: 0.4764291631303066]
	TIME [epoch: 9.45 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3871925668705881		[learning rate: 2.529e-05]
	Learning Rate: 2.52899e-05
	LOSS [training: 0.3871925668705881 | validation: 0.4548797100182509]
	TIME [epoch: 9.46 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39401522461166305		[learning rate: 2.5198e-05]
	Learning Rate: 2.51981e-05
	LOSS [training: 0.39401522461166305 | validation: 0.4589279590463457]
	TIME [epoch: 9.45 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3962828424844149		[learning rate: 2.5107e-05]
	Learning Rate: 2.51067e-05
	LOSS [training: 0.3962828424844149 | validation: 0.4108188045785161]
	TIME [epoch: 9.44 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4041904847291319		[learning rate: 2.5016e-05]
	Learning Rate: 2.50156e-05
	LOSS [training: 0.4041904847291319 | validation: 0.40913576449620725]
	TIME [epoch: 9.44 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4021664239345082		[learning rate: 2.4925e-05]
	Learning Rate: 2.49248e-05
	LOSS [training: 0.4021664239345082 | validation: 0.4597252058979161]
	TIME [epoch: 9.47 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39745937630226014		[learning rate: 2.4834e-05]
	Learning Rate: 2.48343e-05
	LOSS [training: 0.39745937630226014 | validation: 0.47709406405711696]
	TIME [epoch: 9.45 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40000532218733814		[learning rate: 2.4744e-05]
	Learning Rate: 2.47442e-05
	LOSS [training: 0.40000532218733814 | validation: 0.43129805456694925]
	TIME [epoch: 9.44 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38992856916421853		[learning rate: 2.4654e-05]
	Learning Rate: 2.46544e-05
	LOSS [training: 0.38992856916421853 | validation: 0.40117449982312]
	TIME [epoch: 9.44 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.398236572553598		[learning rate: 2.4565e-05]
	Learning Rate: 2.45649e-05
	LOSS [training: 0.398236572553598 | validation: 0.42247525566640165]
	TIME [epoch: 9.46 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41310648174179826		[learning rate: 2.4476e-05]
	Learning Rate: 2.44758e-05
	LOSS [training: 0.41310648174179826 | validation: 0.4476731241037484]
	TIME [epoch: 9.44 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39680209821281703		[learning rate: 2.4387e-05]
	Learning Rate: 2.4387e-05
	LOSS [training: 0.39680209821281703 | validation: 0.46408582820853767]
	TIME [epoch: 9.44 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.384878320161801		[learning rate: 2.4298e-05]
	Learning Rate: 2.42985e-05
	LOSS [training: 0.384878320161801 | validation: 0.4529186362906809]
	TIME [epoch: 9.45 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39062074958623916		[learning rate: 2.421e-05]
	Learning Rate: 2.42103e-05
	LOSS [training: 0.39062074958623916 | validation: 0.4129440715678813]
	TIME [epoch: 9.46 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4064868957005636		[learning rate: 2.4122e-05]
	Learning Rate: 2.41224e-05
	LOSS [training: 0.4064868957005636 | validation: 0.40576146062051877]
	TIME [epoch: 9.45 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3935690319738455		[learning rate: 2.4035e-05]
	Learning Rate: 2.40349e-05
	LOSS [training: 0.3935690319738455 | validation: 0.4718912100140408]
	TIME [epoch: 9.45 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.390882838177174		[learning rate: 2.3948e-05]
	Learning Rate: 2.39477e-05
	LOSS [training: 0.390882838177174 | validation: 0.4770763290246006]
	TIME [epoch: 9.46 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4006652936174751		[learning rate: 2.3861e-05]
	Learning Rate: 2.38608e-05
	LOSS [training: 0.4006652936174751 | validation: 0.40395674731227715]
	TIME [epoch: 9.45 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40626042756224817		[learning rate: 2.3774e-05]
	Learning Rate: 2.37742e-05
	LOSS [training: 0.40626042756224817 | validation: 0.42245099420865373]
	TIME [epoch: 9.45 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37605101535211455		[learning rate: 2.3688e-05]
	Learning Rate: 2.36879e-05
	LOSS [training: 0.37605101535211455 | validation: 0.4292814685693277]
	TIME [epoch: 9.44 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3963711953725308		[learning rate: 2.3602e-05]
	Learning Rate: 2.36019e-05
	LOSS [training: 0.3963711953725308 | validation: 0.4459178052535486]
	TIME [epoch: 9.46 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39398002690653816		[learning rate: 2.3516e-05]
	Learning Rate: 2.35163e-05
	LOSS [training: 0.39398002690653816 | validation: 0.38461270913108975]
	TIME [epoch: 9.45 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3893374226846104		[learning rate: 2.3431e-05]
	Learning Rate: 2.34309e-05
	LOSS [training: 0.3893374226846104 | validation: 0.47356077241713]
	TIME [epoch: 9.44 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3913985494266914		[learning rate: 2.3346e-05]
	Learning Rate: 2.33459e-05
	LOSS [training: 0.3913985494266914 | validation: 0.4157609570431723]
	TIME [epoch: 9.44 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3883112866874505		[learning rate: 2.3261e-05]
	Learning Rate: 2.32612e-05
	LOSS [training: 0.3883112866874505 | validation: 0.40573438265803974]
	TIME [epoch: 9.46 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3951244103811634		[learning rate: 2.3177e-05]
	Learning Rate: 2.31768e-05
	LOSS [training: 0.3951244103811634 | validation: 0.43814897211259124]
	TIME [epoch: 9.44 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3859647223590809		[learning rate: 2.3093e-05]
	Learning Rate: 2.30926e-05
	LOSS [training: 0.3859647223590809 | validation: 0.41890528632879853]
	TIME [epoch: 9.44 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38571702580733674		[learning rate: 2.3009e-05]
	Learning Rate: 2.30088e-05
	LOSS [training: 0.38571702580733674 | validation: 0.44463450226927254]
	TIME [epoch: 9.44 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39776711652484054		[learning rate: 2.2925e-05]
	Learning Rate: 2.29253e-05
	LOSS [training: 0.39776711652484054 | validation: 0.4579059833213786]
	TIME [epoch: 9.47 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39045177756663846		[learning rate: 2.2842e-05]
	Learning Rate: 2.28421e-05
	LOSS [training: 0.39045177756663846 | validation: 0.44279514998419783]
	TIME [epoch: 9.44 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3968850367373871		[learning rate: 2.2759e-05]
	Learning Rate: 2.27592e-05
	LOSS [training: 0.3968850367373871 | validation: 0.4438878660132477]
	TIME [epoch: 9.44 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4017350316262084		[learning rate: 2.2677e-05]
	Learning Rate: 2.26767e-05
	LOSS [training: 0.4017350316262084 | validation: 0.38960944277200027]
	TIME [epoch: 9.44 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39847283853657345		[learning rate: 2.2594e-05]
	Learning Rate: 2.25944e-05
	LOSS [training: 0.39847283853657345 | validation: 0.39959989958711795]
	TIME [epoch: 9.47 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4066512429416905		[learning rate: 2.2512e-05]
	Learning Rate: 2.25124e-05
	LOSS [training: 0.4066512429416905 | validation: 0.4537368854350066]
	TIME [epoch: 9.44 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3956679202308746		[learning rate: 2.2431e-05]
	Learning Rate: 2.24307e-05
	LOSS [training: 0.3956679202308746 | validation: 0.4349175348817693]
	TIME [epoch: 9.44 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3897172034422051		[learning rate: 2.2349e-05]
	Learning Rate: 2.23493e-05
	LOSS [training: 0.3897172034422051 | validation: 0.45123780135759634]
	TIME [epoch: 9.45 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38483641663712664		[learning rate: 2.2268e-05]
	Learning Rate: 2.22682e-05
	LOSS [training: 0.38483641663712664 | validation: 0.4336354844363918]
	TIME [epoch: 9.46 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3882392725534759		[learning rate: 2.2187e-05]
	Learning Rate: 2.21873e-05
	LOSS [training: 0.3882392725534759 | validation: 0.43507235286040996]
	TIME [epoch: 9.45 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3986009207361622		[learning rate: 2.2107e-05]
	Learning Rate: 2.21068e-05
	LOSS [training: 0.3986009207361622 | validation: 0.43859030890347755]
	TIME [epoch: 9.44 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3916347252674609		[learning rate: 2.2027e-05]
	Learning Rate: 2.20266e-05
	LOSS [training: 0.3916347252674609 | validation: 0.4350419167955756]
	TIME [epoch: 9.46 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40950845105553135		[learning rate: 2.1947e-05]
	Learning Rate: 2.19467e-05
	LOSS [training: 0.40950845105553135 | validation: 0.4875662149680386]
	TIME [epoch: 9.44 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3952198863634095		[learning rate: 2.1867e-05]
	Learning Rate: 2.1867e-05
	LOSS [training: 0.3952198863634095 | validation: 0.41793322173088177]
	TIME [epoch: 9.44 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4007324597040314		[learning rate: 2.1788e-05]
	Learning Rate: 2.17877e-05
	LOSS [training: 0.4007324597040314 | validation: 0.44731323347869134]
	TIME [epoch: 9.44 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4060349703323364		[learning rate: 2.1709e-05]
	Learning Rate: 2.17086e-05
	LOSS [training: 0.4060349703323364 | validation: 0.40887787214406457]
	TIME [epoch: 9.46 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3972356529136046		[learning rate: 2.163e-05]
	Learning Rate: 2.16298e-05
	LOSS [training: 0.3972356529136046 | validation: 0.4381761547812451]
	TIME [epoch: 9.45 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39069117342639836		[learning rate: 2.1551e-05]
	Learning Rate: 2.15513e-05
	LOSS [training: 0.39069117342639836 | validation: 0.4649768563761471]
	TIME [epoch: 9.44 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40163516456292525		[learning rate: 2.1473e-05]
	Learning Rate: 2.14731e-05
	LOSS [training: 0.40163516456292525 | validation: 0.44578777478973935]
	TIME [epoch: 9.44 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3998448616129833		[learning rate: 2.1395e-05]
	Learning Rate: 2.13952e-05
	LOSS [training: 0.3998448616129833 | validation: 0.41144185125746485]
	TIME [epoch: 9.47 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40481355958902865		[learning rate: 2.1318e-05]
	Learning Rate: 2.13175e-05
	LOSS [training: 0.40481355958902865 | validation: 0.4368517301289468]
	TIME [epoch: 9.44 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3949844155509684		[learning rate: 2.124e-05]
	Learning Rate: 2.12402e-05
	LOSS [training: 0.3949844155509684 | validation: 0.4252114643910512]
	TIME [epoch: 9.44 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3763853566266401		[learning rate: 2.1163e-05]
	Learning Rate: 2.11631e-05
	LOSS [training: 0.3763853566266401 | validation: 0.4287602585077338]
	TIME [epoch: 9.44 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.399738339342823		[learning rate: 2.1086e-05]
	Learning Rate: 2.10863e-05
	LOSS [training: 0.399738339342823 | validation: 0.41517130008435243]
	TIME [epoch: 9.47 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3843398098440625		[learning rate: 2.101e-05]
	Learning Rate: 2.10098e-05
	LOSS [training: 0.3843398098440625 | validation: 0.5041464987858794]
	TIME [epoch: 9.44 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3872831515094449		[learning rate: 2.0934e-05]
	Learning Rate: 2.09335e-05
	LOSS [training: 0.3872831515094449 | validation: 0.457862295168256]
	TIME [epoch: 9.44 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40497190108783016		[learning rate: 2.0858e-05]
	Learning Rate: 2.08575e-05
	LOSS [training: 0.40497190108783016 | validation: 0.3930141131286834]
	TIME [epoch: 9.45 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38876049826440223		[learning rate: 2.0782e-05]
	Learning Rate: 2.07819e-05
	LOSS [training: 0.38876049826440223 | validation: 0.45141046554612557]
	TIME [epoch: 9.46 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39690260607433725		[learning rate: 2.0706e-05]
	Learning Rate: 2.07064e-05
	LOSS [training: 0.39690260607433725 | validation: 0.43604825840305894]
	TIME [epoch: 9.44 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38733514421787396		[learning rate: 2.0631e-05]
	Learning Rate: 2.06313e-05
	LOSS [training: 0.38733514421787396 | validation: 0.43924985344555195]
	TIME [epoch: 9.45 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3988310828928718		[learning rate: 2.0556e-05]
	Learning Rate: 2.05564e-05
	LOSS [training: 0.3988310828928718 | validation: 0.4608223621203454]
	TIME [epoch: 9.46 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4124016006613022		[learning rate: 2.0482e-05]
	Learning Rate: 2.04818e-05
	LOSS [training: 0.4124016006613022 | validation: 0.441417965715858]
	TIME [epoch: 9.45 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3900245886158194		[learning rate: 2.0407e-05]
	Learning Rate: 2.04075e-05
	LOSS [training: 0.3900245886158194 | validation: 0.470951022403368]
	TIME [epoch: 9.45 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3906023137369582		[learning rate: 2.0333e-05]
	Learning Rate: 2.03334e-05
	LOSS [training: 0.3906023137369582 | validation: 0.4290741901296258]
	TIME [epoch: 9.44 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4050030485398077		[learning rate: 2.026e-05]
	Learning Rate: 2.02596e-05
	LOSS [training: 0.4050030485398077 | validation: 0.43065971722208335]
	TIME [epoch: 9.46 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3969600371272695		[learning rate: 2.0186e-05]
	Learning Rate: 2.01861e-05
	LOSS [training: 0.3969600371272695 | validation: 0.48337762418429775]
	TIME [epoch: 9.45 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38740699866402506		[learning rate: 2.0113e-05]
	Learning Rate: 2.01129e-05
	LOSS [training: 0.38740699866402506 | validation: 0.4462238912326729]
	TIME [epoch: 9.44 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3814127280109004		[learning rate: 2.004e-05]
	Learning Rate: 2.00399e-05
	LOSS [training: 0.3814127280109004 | validation: 0.4049988303410678]
	TIME [epoch: 9.44 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3869719948396127		[learning rate: 1.9967e-05]
	Learning Rate: 1.99671e-05
	LOSS [training: 0.3869719948396127 | validation: 0.3985208863780939]
	TIME [epoch: 9.47 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3949472723856982		[learning rate: 1.9895e-05]
	Learning Rate: 1.98947e-05
	LOSS [training: 0.3949472723856982 | validation: 0.41366322455158766]
	TIME [epoch: 9.44 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3863320618911112		[learning rate: 1.9822e-05]
	Learning Rate: 1.98225e-05
	LOSS [training: 0.3863320618911112 | validation: 0.4096769874085882]
	TIME [epoch: 9.44 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3943005833357384		[learning rate: 1.9751e-05]
	Learning Rate: 1.97505e-05
	LOSS [training: 0.3943005833357384 | validation: 0.4347776521633051]
	TIME [epoch: 9.44 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.398429242044853		[learning rate: 1.9679e-05]
	Learning Rate: 1.96789e-05
	LOSS [training: 0.398429242044853 | validation: 0.44718036874083367]
	TIME [epoch: 9.46 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3994223904721296		[learning rate: 1.9607e-05]
	Learning Rate: 1.96074e-05
	LOSS [training: 0.3994223904721296 | validation: 0.4186069651563171]
	TIME [epoch: 9.45 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3950866359580062		[learning rate: 1.9536e-05]
	Learning Rate: 1.95363e-05
	LOSS [training: 0.3950866359580062 | validation: 0.4364677267711812]
	TIME [epoch: 9.44 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3904111624280721		[learning rate: 1.9465e-05]
	Learning Rate: 1.94654e-05
	LOSS [training: 0.3904111624280721 | validation: 0.44909421933976346]
	TIME [epoch: 9.45 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39061377074484016		[learning rate: 1.9395e-05]
	Learning Rate: 1.93948e-05
	LOSS [training: 0.39061377074484016 | validation: 0.35468452721313126]
	TIME [epoch: 9.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r1_20240219_235153/states/model_tr_study205_1818.pth
	Model improved!!!
EPOCH 1819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3894084259890696		[learning rate: 1.9324e-05]
	Learning Rate: 1.93244e-05
	LOSS [training: 0.3894084259890696 | validation: 0.4376237844532693]
	TIME [epoch: 9.45 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38202612554232857		[learning rate: 1.9254e-05]
	Learning Rate: 1.92542e-05
	LOSS [training: 0.38202612554232857 | validation: 0.4188844655719667]
	TIME [epoch: 9.44 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38952233052655266		[learning rate: 1.9184e-05]
	Learning Rate: 1.91844e-05
	LOSS [training: 0.38952233052655266 | validation: 0.39195693673077214]
	TIME [epoch: 9.46 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3885629318744321		[learning rate: 1.9115e-05]
	Learning Rate: 1.91147e-05
	LOSS [training: 0.3885629318744321 | validation: 0.39385663966986756]
	TIME [epoch: 9.45 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3847902180255086		[learning rate: 1.9045e-05]
	Learning Rate: 1.90454e-05
	LOSS [training: 0.3847902180255086 | validation: 0.4803411331521153]
	TIME [epoch: 9.44 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3845630419698077		[learning rate: 1.8976e-05]
	Learning Rate: 1.89763e-05
	LOSS [training: 0.3845630419698077 | validation: 0.4147767911786339]
	TIME [epoch: 9.43 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3993672155510267		[learning rate: 1.8907e-05]
	Learning Rate: 1.89074e-05
	LOSS [training: 0.3993672155510267 | validation: 0.43476420550467454]
	TIME [epoch: 9.46 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40539003802536105		[learning rate: 1.8839e-05]
	Learning Rate: 1.88388e-05
	LOSS [training: 0.40539003802536105 | validation: 0.4407151514653232]
	TIME [epoch: 9.44 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3835703808559301		[learning rate: 1.877e-05]
	Learning Rate: 1.87704e-05
	LOSS [training: 0.3835703808559301 | validation: 0.3950048070048749]
	TIME [epoch: 9.44 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38730332640322085		[learning rate: 1.8702e-05]
	Learning Rate: 1.87023e-05
	LOSS [training: 0.38730332640322085 | validation: 0.48679417044057816]
	TIME [epoch: 9.44 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39440390984796386		[learning rate: 1.8634e-05]
	Learning Rate: 1.86344e-05
	LOSS [training: 0.39440390984796386 | validation: 0.4011860015267837]
	TIME [epoch: 9.46 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40029120004490276		[learning rate: 1.8567e-05]
	Learning Rate: 1.85668e-05
	LOSS [training: 0.40029120004490276 | validation: 0.49002352146328065]
	TIME [epoch: 9.44 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3832052207232858		[learning rate: 1.8499e-05]
	Learning Rate: 1.84994e-05
	LOSS [training: 0.3832052207232858 | validation: 0.3875732085260156]
	TIME [epoch: 9.44 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3841735221644048		[learning rate: 1.8432e-05]
	Learning Rate: 1.84323e-05
	LOSS [training: 0.3841735221644048 | validation: 0.4204368240316309]
	TIME [epoch: 9.44 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39680137371366897		[learning rate: 1.8365e-05]
	Learning Rate: 1.83654e-05
	LOSS [training: 0.39680137371366897 | validation: 0.4460444365251106]
	TIME [epoch: 9.46 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39481781018151774		[learning rate: 1.8299e-05]
	Learning Rate: 1.82987e-05
	LOSS [training: 0.39481781018151774 | validation: 0.40867817057571026]
	TIME [epoch: 9.44 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3931086730219827		[learning rate: 1.8232e-05]
	Learning Rate: 1.82323e-05
	LOSS [training: 0.3931086730219827 | validation: 0.47213031884630297]
	TIME [epoch: 9.44 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41112122584706706		[learning rate: 1.8166e-05]
	Learning Rate: 1.81662e-05
	LOSS [training: 0.41112122584706706 | validation: 0.48202191466824096]
	TIME [epoch: 9.44 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3882962198092802		[learning rate: 1.81e-05]
	Learning Rate: 1.81002e-05
	LOSS [training: 0.3882962198092802 | validation: 0.4558337343273766]
	TIME [epoch: 9.46 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39597449141904834		[learning rate: 1.8035e-05]
	Learning Rate: 1.80346e-05
	LOSS [training: 0.39597449141904834 | validation: 0.403444079511855]
	TIME [epoch: 9.44 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38197830363564433		[learning rate: 1.7969e-05]
	Learning Rate: 1.79691e-05
	LOSS [training: 0.38197830363564433 | validation: 0.46660077412307815]
	TIME [epoch: 9.44 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3931905681491695		[learning rate: 1.7904e-05]
	Learning Rate: 1.79039e-05
	LOSS [training: 0.3931905681491695 | validation: 0.46612205776581334]
	TIME [epoch: 9.45 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3830096215764446		[learning rate: 1.7839e-05]
	Learning Rate: 1.78389e-05
	LOSS [training: 0.3830096215764446 | validation: 0.4819751108208196]
	TIME [epoch: 9.45 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3934361536920846		[learning rate: 1.7774e-05]
	Learning Rate: 1.77742e-05
	LOSS [training: 0.3934361536920846 | validation: 0.46293002352881785]
	TIME [epoch: 9.44 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38220306195315057		[learning rate: 1.771e-05]
	Learning Rate: 1.77097e-05
	LOSS [training: 0.38220306195315057 | validation: 0.4063719983068472]
	TIME [epoch: 9.43 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41533840613090023		[learning rate: 1.7645e-05]
	Learning Rate: 1.76454e-05
	LOSS [training: 0.41533840613090023 | validation: 0.37314387334525395]
	TIME [epoch: 9.45 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4034463016403994		[learning rate: 1.7581e-05]
	Learning Rate: 1.75814e-05
	LOSS [training: 0.4034463016403994 | validation: 0.38767214643832787]
	TIME [epoch: 9.44 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38956401911891136		[learning rate: 1.7518e-05]
	Learning Rate: 1.75176e-05
	LOSS [training: 0.38956401911891136 | validation: 0.4586509234627917]
	TIME [epoch: 9.43 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39639864439779837		[learning rate: 1.7454e-05]
	Learning Rate: 1.7454e-05
	LOSS [training: 0.39639864439779837 | validation: 0.40952882103406524]
	TIME [epoch: 9.44 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38772935188312324		[learning rate: 1.7391e-05]
	Learning Rate: 1.73907e-05
	LOSS [training: 0.38772935188312324 | validation: 0.43961781813240836]
	TIME [epoch: 9.46 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3857419570394514		[learning rate: 1.7328e-05]
	Learning Rate: 1.73275e-05
	LOSS [training: 0.3857419570394514 | validation: 0.4136706994933138]
	TIME [epoch: 9.44 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3954388896597739		[learning rate: 1.7265e-05]
	Learning Rate: 1.72647e-05
	LOSS [training: 0.3954388896597739 | validation: 0.488583958093177]
	TIME [epoch: 9.44 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40112423216580684		[learning rate: 1.7202e-05]
	Learning Rate: 1.7202e-05
	LOSS [training: 0.40112423216580684 | validation: 0.407508275888512]
	TIME [epoch: 9.44 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3938448040646881		[learning rate: 1.714e-05]
	Learning Rate: 1.71396e-05
	LOSS [training: 0.3938448040646881 | validation: 0.46944705182175234]
	TIME [epoch: 9.46 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38795270945351595		[learning rate: 1.7077e-05]
	Learning Rate: 1.70774e-05
	LOSS [training: 0.38795270945351595 | validation: 0.42309841911380935]
	TIME [epoch: 9.44 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39598716571375414		[learning rate: 1.7015e-05]
	Learning Rate: 1.70154e-05
	LOSS [training: 0.39598716571375414 | validation: 0.39002281157474]
	TIME [epoch: 9.44 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4028983248455681		[learning rate: 1.6954e-05]
	Learning Rate: 1.69537e-05
	LOSS [training: 0.4028983248455681 | validation: 0.39121869017340777]
	TIME [epoch: 9.44 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.392599746549826		[learning rate: 1.6892e-05]
	Learning Rate: 1.68921e-05
	LOSS [training: 0.392599746549826 | validation: 0.4550193044585354]
	TIME [epoch: 9.46 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3888619170373998		[learning rate: 1.6831e-05]
	Learning Rate: 1.68308e-05
	LOSS [training: 0.3888619170373998 | validation: 0.45079902959625545]
	TIME [epoch: 9.44 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3992300377828706		[learning rate: 1.677e-05]
	Learning Rate: 1.67697e-05
	LOSS [training: 0.3992300377828706 | validation: 0.44047511011687135]
	TIME [epoch: 9.44 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38537054755170186		[learning rate: 1.6709e-05]
	Learning Rate: 1.67089e-05
	LOSS [training: 0.38537054755170186 | validation: 0.3978519590715689]
	TIME [epoch: 9.45 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40449033915308574		[learning rate: 1.6648e-05]
	Learning Rate: 1.66482e-05
	LOSS [training: 0.40449033915308574 | validation: 0.4211031093820908]
	TIME [epoch: 9.45 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4037009354729628		[learning rate: 1.6588e-05]
	Learning Rate: 1.65878e-05
	LOSS [training: 0.4037009354729628 | validation: 0.38138550212115746]
	TIME [epoch: 9.44 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3972088549875073		[learning rate: 1.6528e-05]
	Learning Rate: 1.65276e-05
	LOSS [training: 0.3972088549875073 | validation: 0.41869028718797957]
	TIME [epoch: 9.44 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38718120036588		[learning rate: 1.6468e-05]
	Learning Rate: 1.64677e-05
	LOSS [training: 0.38718120036588 | validation: 0.47869370147680024]
	TIME [epoch: 9.45 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4036102391435682		[learning rate: 1.6408e-05]
	Learning Rate: 1.64079e-05
	LOSS [training: 0.4036102391435682 | validation: 0.380882203761867]
	TIME [epoch: 9.45 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40349535889931853		[learning rate: 1.6348e-05]
	Learning Rate: 1.63483e-05
	LOSS [training: 0.40349535889931853 | validation: 0.4893421981177244]
	TIME [epoch: 9.44 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4080314280402818		[learning rate: 1.6289e-05]
	Learning Rate: 1.6289e-05
	LOSS [training: 0.4080314280402818 | validation: 0.43667773016942624]
	TIME [epoch: 9.44 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41124301155231197		[learning rate: 1.623e-05]
	Learning Rate: 1.62299e-05
	LOSS [training: 0.41124301155231197 | validation: 0.46907313254967464]
	TIME [epoch: 9.46 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3883481899091428		[learning rate: 1.6171e-05]
	Learning Rate: 1.6171e-05
	LOSS [training: 0.3883481899091428 | validation: 0.47622516972095524]
	TIME [epoch: 9.44 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38907862005477967		[learning rate: 1.6112e-05]
	Learning Rate: 1.61123e-05
	LOSS [training: 0.38907862005477967 | validation: 0.4278074908109551]
	TIME [epoch: 9.44 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38470371095748		[learning rate: 1.6054e-05]
	Learning Rate: 1.60538e-05
	LOSS [training: 0.38470371095748 | validation: 0.4362152292487663]
	TIME [epoch: 9.44 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3839071276355545		[learning rate: 1.5996e-05]
	Learning Rate: 1.59956e-05
	LOSS [training: 0.3839071276355545 | validation: 0.46062793956297526]
	TIME [epoch: 9.46 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3889307482198364		[learning rate: 1.5938e-05]
	Learning Rate: 1.59375e-05
	LOSS [training: 0.3889307482198364 | validation: 0.44343241264176025]
	TIME [epoch: 9.44 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38758519718431805		[learning rate: 1.588e-05]
	Learning Rate: 1.58797e-05
	LOSS [training: 0.38758519718431805 | validation: 0.4809785309258961]
	TIME [epoch: 9.44 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3841539819641636		[learning rate: 1.5822e-05]
	Learning Rate: 1.58221e-05
	LOSS [training: 0.3841539819641636 | validation: 0.4648528649119522]
	TIME [epoch: 9.44 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3894044472966923		[learning rate: 1.5765e-05]
	Learning Rate: 1.57647e-05
	LOSS [training: 0.3894044472966923 | validation: 0.447251692280799]
	TIME [epoch: 9.47 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4005643920999592		[learning rate: 1.5707e-05]
	Learning Rate: 1.57074e-05
	LOSS [training: 0.4005643920999592 | validation: 0.45948007549767234]
	TIME [epoch: 9.44 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38817145030132466		[learning rate: 1.565e-05]
	Learning Rate: 1.56504e-05
	LOSS [training: 0.38817145030132466 | validation: 0.4059413807441958]
	TIME [epoch: 9.44 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37863979132917447		[learning rate: 1.5594e-05]
	Learning Rate: 1.55936e-05
	LOSS [training: 0.37863979132917447 | validation: 0.45631945825334996]
	TIME [epoch: 9.45 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38941274252904345		[learning rate: 1.5537e-05]
	Learning Rate: 1.5537e-05
	LOSS [training: 0.38941274252904345 | validation: 0.45457503527782395]
	TIME [epoch: 9.46 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3810796857145277		[learning rate: 1.5481e-05]
	Learning Rate: 1.54807e-05
	LOSS [training: 0.3810796857145277 | validation: 0.4003384267212994]
	TIME [epoch: 9.44 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39372890420581236		[learning rate: 1.5424e-05]
	Learning Rate: 1.54245e-05
	LOSS [training: 0.39372890420581236 | validation: 0.4447819073608389]
	TIME [epoch: 9.44 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4189515796963696		[learning rate: 1.5369e-05]
	Learning Rate: 1.53685e-05
	LOSS [training: 0.4189515796963696 | validation: 0.37920451764845964]
	TIME [epoch: 9.46 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38742057804547575		[learning rate: 1.5313e-05]
	Learning Rate: 1.53127e-05
	LOSS [training: 0.38742057804547575 | validation: 0.4068170100157272]
	TIME [epoch: 9.45 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3905775448714961		[learning rate: 1.5257e-05]
	Learning Rate: 1.52572e-05
	LOSS [training: 0.3905775448714961 | validation: 0.4284764635164832]
	TIME [epoch: 9.44 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3977976380044129		[learning rate: 1.5202e-05]
	Learning Rate: 1.52018e-05
	LOSS [training: 0.3977976380044129 | validation: 0.41203706864309314]
	TIME [epoch: 9.45 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3907890977249054		[learning rate: 1.5147e-05]
	Learning Rate: 1.51466e-05
	LOSS [training: 0.3907890977249054 | validation: 0.41201469074376207]
	TIME [epoch: 9.46 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3828662854868085		[learning rate: 1.5092e-05]
	Learning Rate: 1.50917e-05
	LOSS [training: 0.3828662854868085 | validation: 0.44359465415956545]
	TIME [epoch: 9.44 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39830764566877264		[learning rate: 1.5037e-05]
	Learning Rate: 1.50369e-05
	LOSS [training: 0.39830764566877264 | validation: 0.3934862218896566]
	TIME [epoch: 9.44 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3948650774729928		[learning rate: 1.4982e-05]
	Learning Rate: 1.49823e-05
	LOSS [training: 0.3948650774729928 | validation: 0.4235500296696178]
	TIME [epoch: 9.44 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3845101022467739		[learning rate: 1.4928e-05]
	Learning Rate: 1.49279e-05
	LOSS [training: 0.3845101022467739 | validation: 0.4317606602836132]
	TIME [epoch: 9.46 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3920155793991432		[learning rate: 1.4874e-05]
	Learning Rate: 1.48738e-05
	LOSS [training: 0.3920155793991432 | validation: 0.45644829967305167]
	TIME [epoch: 9.44 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38559625512446083		[learning rate: 1.482e-05]
	Learning Rate: 1.48198e-05
	LOSS [training: 0.38559625512446083 | validation: 0.4241580531252053]
	TIME [epoch: 9.44 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3919170613885769		[learning rate: 1.4766e-05]
	Learning Rate: 1.4766e-05
	LOSS [training: 0.3919170613885769 | validation: 0.4469212364452194]
	TIME [epoch: 9.44 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38320443067410015		[learning rate: 1.4712e-05]
	Learning Rate: 1.47124e-05
	LOSS [training: 0.38320443067410015 | validation: 0.48152101927090274]
	TIME [epoch: 9.46 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3888275107579124		[learning rate: 1.4659e-05]
	Learning Rate: 1.4659e-05
	LOSS [training: 0.3888275107579124 | validation: 0.38905304730376133]
	TIME [epoch: 9.44 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40302858484263765		[learning rate: 1.4606e-05]
	Learning Rate: 1.46058e-05
	LOSS [training: 0.40302858484263765 | validation: 0.5104539796775578]
	TIME [epoch: 9.44 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3934090759342661		[learning rate: 1.4553e-05]
	Learning Rate: 1.45528e-05
	LOSS [training: 0.3934090759342661 | validation: 0.4903350482953125]
	TIME [epoch: 9.44 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3855490312189294		[learning rate: 1.45e-05]
	Learning Rate: 1.45e-05
	LOSS [training: 0.3855490312189294 | validation: 0.40410595402743044]
	TIME [epoch: 9.46 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3898537971054888		[learning rate: 1.4447e-05]
	Learning Rate: 1.44474e-05
	LOSS [training: 0.3898537971054888 | validation: 0.44025450646218967]
	TIME [epoch: 9.44 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39106258858792525		[learning rate: 1.4395e-05]
	Learning Rate: 1.4395e-05
	LOSS [training: 0.39106258858792525 | validation: 0.43532010969911095]
	TIME [epoch: 9.44 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39887488911375996		[learning rate: 1.4343e-05]
	Learning Rate: 1.43427e-05
	LOSS [training: 0.39887488911375996 | validation: 0.4303125306090905]
	TIME [epoch: 9.44 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40429890901650606		[learning rate: 1.4291e-05]
	Learning Rate: 1.42907e-05
	LOSS [training: 0.40429890901650606 | validation: 0.40148168484348723]
	TIME [epoch: 9.45 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3992379113403036		[learning rate: 1.4239e-05]
	Learning Rate: 1.42388e-05
	LOSS [training: 0.3992379113403036 | validation: 0.4384259093319889]
	TIME [epoch: 9.44 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39745192309607663		[learning rate: 1.4187e-05]
	Learning Rate: 1.41871e-05
	LOSS [training: 0.39745192309607663 | validation: 0.42475736850463586]
	TIME [epoch: 9.44 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39195817577892306		[learning rate: 1.4136e-05]
	Learning Rate: 1.41357e-05
	LOSS [training: 0.39195817577892306 | validation: 0.39132803249715314]
	TIME [epoch: 9.46 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3800171050346718		[learning rate: 1.4084e-05]
	Learning Rate: 1.40844e-05
	LOSS [training: 0.3800171050346718 | validation: 0.426594015818162]
	TIME [epoch: 9.44 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38748414746129456		[learning rate: 1.4033e-05]
	Learning Rate: 1.40332e-05
	LOSS [training: 0.38748414746129456 | validation: 0.40797457523066516]
	TIME [epoch: 9.44 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4068081870043788		[learning rate: 1.3982e-05]
	Learning Rate: 1.39823e-05
	LOSS [training: 0.4068081870043788 | validation: 0.3953992089821391]
	TIME [epoch: 9.44 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40256055818358466		[learning rate: 1.3932e-05]
	Learning Rate: 1.39316e-05
	LOSS [training: 0.40256055818358466 | validation: 0.4171334420854887]
	TIME [epoch: 9.46 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3868397623775756		[learning rate: 1.3881e-05]
	Learning Rate: 1.3881e-05
	LOSS [training: 0.3868397623775756 | validation: 0.48611605806200237]
	TIME [epoch: 9.44 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39690971195051084		[learning rate: 1.3831e-05]
	Learning Rate: 1.38306e-05
	LOSS [training: 0.39690971195051084 | validation: 0.4238886306431468]
	TIME [epoch: 9.44 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.391582915384601		[learning rate: 1.378e-05]
	Learning Rate: 1.37804e-05
	LOSS [training: 0.391582915384601 | validation: 0.4022690534059886]
	TIME [epoch: 9.44 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3791608010098856		[learning rate: 1.373e-05]
	Learning Rate: 1.37304e-05
	LOSS [training: 0.3791608010098856 | validation: 0.467996379628825]
	TIME [epoch: 9.46 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38491645196349966		[learning rate: 1.3681e-05]
	Learning Rate: 1.36806e-05
	LOSS [training: 0.38491645196349966 | validation: 0.39423363409777495]
	TIME [epoch: 9.44 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38167736694619797		[learning rate: 1.3631e-05]
	Learning Rate: 1.3631e-05
	LOSS [training: 0.38167736694619797 | validation: 0.42526958667415293]
	TIME [epoch: 9.44 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3844098586418182		[learning rate: 1.3581e-05]
	Learning Rate: 1.35815e-05
	LOSS [training: 0.3844098586418182 | validation: 0.4379612998192408]
	TIME [epoch: 9.44 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3998891628691739		[learning rate: 1.3532e-05]
	Learning Rate: 1.35322e-05
	LOSS [training: 0.3998891628691739 | validation: 0.43708717412324155]
	TIME [epoch: 9.46 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3877520193550252		[learning rate: 1.3483e-05]
	Learning Rate: 1.34831e-05
	LOSS [training: 0.3877520193550252 | validation: 0.4117945700042342]
	TIME [epoch: 9.44 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3892331074178045		[learning rate: 1.3434e-05]
	Learning Rate: 1.34342e-05
	LOSS [training: 0.3892331074178045 | validation: 0.4143872773666233]
	TIME [epoch: 9.44 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3900095762439895		[learning rate: 1.3385e-05]
	Learning Rate: 1.33854e-05
	LOSS [training: 0.3900095762439895 | validation: 0.444672186563553]
	TIME [epoch: 9.45 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3931592308413041		[learning rate: 1.3337e-05]
	Learning Rate: 1.33368e-05
	LOSS [training: 0.3931592308413041 | validation: 0.46296702388706606]
	TIME [epoch: 9.46 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37351763735612814		[learning rate: 1.3288e-05]
	Learning Rate: 1.32884e-05
	LOSS [training: 0.37351763735612814 | validation: 0.42041765066165354]
	TIME [epoch: 9.44 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3925017237027056		[learning rate: 1.324e-05]
	Learning Rate: 1.32402e-05
	LOSS [training: 0.3925017237027056 | validation: 0.446197251777119]
	TIME [epoch: 9.44 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3826205700803643		[learning rate: 1.3192e-05]
	Learning Rate: 1.31922e-05
	LOSS [training: 0.3826205700803643 | validation: 0.37017066990754316]
	TIME [epoch: 9.46 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38946081820984163		[learning rate: 1.3144e-05]
	Learning Rate: 1.31443e-05
	LOSS [training: 0.38946081820984163 | validation: 0.4279949714274105]
	TIME [epoch: 9.45 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4015332821686329		[learning rate: 1.3097e-05]
	Learning Rate: 1.30966e-05
	LOSS [training: 0.4015332821686329 | validation: 0.4218941651935137]
	TIME [epoch: 9.44 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.396766072981676		[learning rate: 1.3049e-05]
	Learning Rate: 1.30491e-05
	LOSS [training: 0.396766072981676 | validation: 0.45770329866016973]
	TIME [epoch: 9.44 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.381166411502449		[learning rate: 1.3002e-05]
	Learning Rate: 1.30017e-05
	LOSS [training: 0.381166411502449 | validation: 0.4483258838816693]
	TIME [epoch: 9.46 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38643748371195197		[learning rate: 1.2955e-05]
	Learning Rate: 1.29545e-05
	LOSS [training: 0.38643748371195197 | validation: 0.3984493819343624]
	TIME [epoch: 9.44 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37947263355650235		[learning rate: 1.2907e-05]
	Learning Rate: 1.29075e-05
	LOSS [training: 0.37947263355650235 | validation: 0.4508985588422023]
	TIME [epoch: 9.44 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.392701155327717		[learning rate: 1.2861e-05]
	Learning Rate: 1.28607e-05
	LOSS [training: 0.392701155327717 | validation: 0.42669206947956395]
	TIME [epoch: 9.44 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3939503679127707		[learning rate: 1.2814e-05]
	Learning Rate: 1.2814e-05
	LOSS [training: 0.3939503679127707 | validation: 0.4411251303538232]
	TIME [epoch: 9.46 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4031342990981237		[learning rate: 1.2767e-05]
	Learning Rate: 1.27675e-05
	LOSS [training: 0.4031342990981237 | validation: 0.41723067743610104]
	TIME [epoch: 9.44 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.384719794310772		[learning rate: 1.2721e-05]
	Learning Rate: 1.27212e-05
	LOSS [training: 0.384719794310772 | validation: 0.3928830729814733]
	TIME [epoch: 9.43 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37926188048879006		[learning rate: 1.2675e-05]
	Learning Rate: 1.2675e-05
	LOSS [training: 0.37926188048879006 | validation: 0.4498318459430165]
	TIME [epoch: 9.44 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3728769479679849		[learning rate: 1.2629e-05]
	Learning Rate: 1.2629e-05
	LOSS [training: 0.3728769479679849 | validation: 0.4515251252173995]
	TIME [epoch: 9.46 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39470982005245797		[learning rate: 1.2583e-05]
	Learning Rate: 1.25832e-05
	LOSS [training: 0.39470982005245797 | validation: 0.41234328684534033]
	TIME [epoch: 9.44 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38858558630946377		[learning rate: 1.2537e-05]
	Learning Rate: 1.25375e-05
	LOSS [training: 0.38858558630946377 | validation: 0.40804378198181346]
	TIME [epoch: 9.44 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39070123893718256		[learning rate: 1.2492e-05]
	Learning Rate: 1.2492e-05
	LOSS [training: 0.39070123893718256 | validation: 0.42520861644975955]
	TIME [epoch: 9.44 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3878864285227313		[learning rate: 1.2447e-05]
	Learning Rate: 1.24467e-05
	LOSS [training: 0.3878864285227313 | validation: 0.46160416530659953]
	TIME [epoch: 9.46 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39093097483679645		[learning rate: 1.2401e-05]
	Learning Rate: 1.24015e-05
	LOSS [training: 0.39093097483679645 | validation: 0.4615076443842845]
	TIME [epoch: 9.44 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3872749639227558		[learning rate: 1.2356e-05]
	Learning Rate: 1.23565e-05
	LOSS [training: 0.3872749639227558 | validation: 0.4430430457072803]
	TIME [epoch: 9.43 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3936928983983602		[learning rate: 1.2312e-05]
	Learning Rate: 1.23116e-05
	LOSS [training: 0.3936928983983602 | validation: 0.5152258764612695]
	TIME [epoch: 9.46 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40310650409		[learning rate: 1.2267e-05]
	Learning Rate: 1.2267e-05
	LOSS [training: 0.40310650409 | validation: 0.4201457927882157]
	TIME [epoch: 9.45 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38372018838591426		[learning rate: 1.2222e-05]
	Learning Rate: 1.22224e-05
	LOSS [training: 0.38372018838591426 | validation: 0.4066272861355303]
	TIME [epoch: 9.44 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3998525941886267		[learning rate: 1.2178e-05]
	Learning Rate: 1.21781e-05
	LOSS [training: 0.3998525941886267 | validation: 0.42125513171779894]
	TIME [epoch: 9.44 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39711414262718375		[learning rate: 1.2134e-05]
	Learning Rate: 1.21339e-05
	LOSS [training: 0.39711414262718375 | validation: 0.45088717087720426]
	TIME [epoch: 9.45 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38777112696922444		[learning rate: 1.209e-05]
	Learning Rate: 1.20899e-05
	LOSS [training: 0.38777112696922444 | validation: 0.38614723722002325]
	TIME [epoch: 9.44 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39506703820609546		[learning rate: 1.2046e-05]
	Learning Rate: 1.2046e-05
	LOSS [training: 0.39506703820609546 | validation: 0.3953240247409335]
	TIME [epoch: 9.44 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4078981918623395		[learning rate: 1.2002e-05]
	Learning Rate: 1.20023e-05
	LOSS [training: 0.4078981918623395 | validation: 0.4290973924575255]
	TIME [epoch: 9.44 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38194264238700554		[learning rate: 1.1959e-05]
	Learning Rate: 1.19587e-05
	LOSS [training: 0.38194264238700554 | validation: 0.4510484114146327]
	TIME [epoch: 9.46 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3977228657241539		[learning rate: 1.1915e-05]
	Learning Rate: 1.19153e-05
	LOSS [training: 0.3977228657241539 | validation: 0.46755912772015523]
	TIME [epoch: 9.44 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40487063255349864		[learning rate: 1.1872e-05]
	Learning Rate: 1.18721e-05
	LOSS [training: 0.40487063255349864 | validation: 0.4259882243315332]
	TIME [epoch: 9.44 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3739022644983204		[learning rate: 1.1829e-05]
	Learning Rate: 1.1829e-05
	LOSS [training: 0.3739022644983204 | validation: 0.45411392426793756]
	TIME [epoch: 9.44 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39352557407377187		[learning rate: 1.1786e-05]
	Learning Rate: 1.17861e-05
	LOSS [training: 0.39352557407377187 | validation: 0.39966952958780044]
	TIME [epoch: 9.46 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39309799733711503		[learning rate: 1.1743e-05]
	Learning Rate: 1.17433e-05
	LOSS [training: 0.39309799733711503 | validation: 0.3965632389726762]
	TIME [epoch: 9.44 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3765592301507801		[learning rate: 1.1701e-05]
	Learning Rate: 1.17007e-05
	LOSS [training: 0.3765592301507801 | validation: 0.4202214196275834]
	TIME [epoch: 9.44 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4007350355643612		[learning rate: 1.1658e-05]
	Learning Rate: 1.16582e-05
	LOSS [training: 0.4007350355643612 | validation: 0.41061672832823265]
	TIME [epoch: 9.44 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40308016111614486		[learning rate: 1.1616e-05]
	Learning Rate: 1.16159e-05
	LOSS [training: 0.40308016111614486 | validation: 0.39453635635423856]
	TIME [epoch: 9.46 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3826502301790805		[learning rate: 1.1574e-05]
	Learning Rate: 1.15737e-05
	LOSS [training: 0.3826502301790805 | validation: 0.3866813054052841]
	TIME [epoch: 9.44 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38952026784474014		[learning rate: 1.1532e-05]
	Learning Rate: 1.15317e-05
	LOSS [training: 0.38952026784474014 | validation: 0.4354059268654873]
	TIME [epoch: 9.43 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38891603885909776		[learning rate: 1.149e-05]
	Learning Rate: 1.14899e-05
	LOSS [training: 0.38891603885909776 | validation: 0.4532692708920038]
	TIME [epoch: 9.44 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3821990177154023		[learning rate: 1.1448e-05]
	Learning Rate: 1.14482e-05
	LOSS [training: 0.3821990177154023 | validation: 0.47019626607182113]
	TIME [epoch: 9.45 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3912633324715639		[learning rate: 1.1407e-05]
	Learning Rate: 1.14066e-05
	LOSS [training: 0.3912633324715639 | validation: 0.4327514793686901]
	TIME [epoch: 9.44 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3936714499257654		[learning rate: 1.1365e-05]
	Learning Rate: 1.13652e-05
	LOSS [training: 0.3936714499257654 | validation: 0.39879418225971663]
	TIME [epoch: 9.44 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38083256055313097		[learning rate: 1.1324e-05]
	Learning Rate: 1.1324e-05
	LOSS [training: 0.38083256055313097 | validation: 0.4732657815850466]
	TIME [epoch: 9.45 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40049328899190684		[learning rate: 1.1283e-05]
	Learning Rate: 1.12829e-05
	LOSS [training: 0.40049328899190684 | validation: 0.3852441078578403]
	TIME [epoch: 9.45 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3893065451831316		[learning rate: 1.1242e-05]
	Learning Rate: 1.1242e-05
	LOSS [training: 0.3893065451831316 | validation: 0.4256747692591324]
	TIME [epoch: 9.44 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38680552247464633		[learning rate: 1.1201e-05]
	Learning Rate: 1.12012e-05
	LOSS [training: 0.38680552247464633 | validation: 0.4187824024578367]
	TIME [epoch: 9.44 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39217837355057317		[learning rate: 1.1161e-05]
	Learning Rate: 1.11605e-05
	LOSS [training: 0.39217837355057317 | validation: 0.38970869667543456]
	TIME [epoch: 9.46 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38084254624685826		[learning rate: 1.112e-05]
	Learning Rate: 1.112e-05
	LOSS [training: 0.38084254624685826 | validation: 0.42144581270442955]
	TIME [epoch: 9.44 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3896525925540797		[learning rate: 1.108e-05]
	Learning Rate: 1.10797e-05
	LOSS [training: 0.3896525925540797 | validation: 0.4344371453997784]
	TIME [epoch: 9.44 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3927951455625497		[learning rate: 1.1039e-05]
	Learning Rate: 1.10394e-05
	LOSS [training: 0.3927951455625497 | validation: 0.40504228626547173]
	TIME [epoch: 9.44 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38628709511111026		[learning rate: 1.0999e-05]
	Learning Rate: 1.09994e-05
	LOSS [training: 0.38628709511111026 | validation: 0.39184155669599485]
	TIME [epoch: 9.46 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3853489004653919		[learning rate: 1.0959e-05]
	Learning Rate: 1.09595e-05
	LOSS [training: 0.3853489004653919 | validation: 0.4445309645585431]
	TIME [epoch: 9.44 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38981058105850896		[learning rate: 1.092e-05]
	Learning Rate: 1.09197e-05
	LOSS [training: 0.38981058105850896 | validation: 0.4040179571235716]
	TIME [epoch: 9.44 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3864775117001196		[learning rate: 1.088e-05]
	Learning Rate: 1.08801e-05
	LOSS [training: 0.3864775117001196 | validation: 0.4779218690081675]
	TIME [epoch: 9.44 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39856175197681665		[learning rate: 1.0841e-05]
	Learning Rate: 1.08406e-05
	LOSS [training: 0.39856175197681665 | validation: 0.41538302530478194]
	TIME [epoch: 9.46 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40166509347408724		[learning rate: 1.0801e-05]
	Learning Rate: 1.08012e-05
	LOSS [training: 0.40166509347408724 | validation: 0.47287262125861346]
	TIME [epoch: 9.44 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40342841382091577		[learning rate: 1.0762e-05]
	Learning Rate: 1.0762e-05
	LOSS [training: 0.40342841382091577 | validation: 0.4397930288776311]
	TIME [epoch: 9.43 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38301665093583004		[learning rate: 1.0723e-05]
	Learning Rate: 1.0723e-05
	LOSS [training: 0.38301665093583004 | validation: 0.45848152336520287]
	TIME [epoch: 9.45 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3995508870002128		[learning rate: 1.0684e-05]
	Learning Rate: 1.06841e-05
	LOSS [training: 0.3995508870002128 | validation: 0.45904056413377914]
	TIME [epoch: 9.45 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3781125672538507		[learning rate: 1.0645e-05]
	Learning Rate: 1.06453e-05
	LOSS [training: 0.3781125672538507 | validation: 0.4161716113094178]
	TIME [epoch: 9.44 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39401347582759416		[learning rate: 1.0607e-05]
	Learning Rate: 1.06067e-05
	LOSS [training: 0.39401347582759416 | validation: 0.41654503678697735]
	TIME [epoch: 9.44 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40667167569879803		[learning rate: 1.0568e-05]
	Learning Rate: 1.05682e-05
	LOSS [training: 0.40667167569879803 | validation: 0.42640912411702503]
	TIME [epoch: 9.46 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39062460640566216		[learning rate: 1.053e-05]
	Learning Rate: 1.05298e-05
	LOSS [training: 0.39062460640566216 | validation: 0.4196485279864856]
	TIME [epoch: 9.45 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38640574937719		[learning rate: 1.0492e-05]
	Learning Rate: 1.04916e-05
	LOSS [training: 0.38640574937719 | validation: 0.4625558939690059]
	TIME [epoch: 9.44 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4070321076580564		[learning rate: 1.0454e-05]
	Learning Rate: 1.04535e-05
	LOSS [training: 0.4070321076580564 | validation: 0.46530254446952596]
	TIME [epoch: 9.43 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3862348362619362		[learning rate: 1.0416e-05]
	Learning Rate: 1.04156e-05
	LOSS [training: 0.3862348362619362 | validation: 0.39232657522378434]
	TIME [epoch: 9.46 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39727579083207354		[learning rate: 1.0378e-05]
	Learning Rate: 1.03778e-05
	LOSS [training: 0.39727579083207354 | validation: 0.409368079843679]
	TIME [epoch: 9.44 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39426552637269424		[learning rate: 1.034e-05]
	Learning Rate: 1.03401e-05
	LOSS [training: 0.39426552637269424 | validation: 0.4125460744499152]
	TIME [epoch: 9.44 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.381211108570067		[learning rate: 1.0303e-05]
	Learning Rate: 1.03026e-05
	LOSS [training: 0.381211108570067 | validation: 0.41886771244942594]
	TIME [epoch: 9.44 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.374248289573721		[learning rate: 1.0265e-05]
	Learning Rate: 1.02652e-05
	LOSS [training: 0.374248289573721 | validation: 0.42628793894853856]
	TIME [epoch: 9.47 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38452254605408853		[learning rate: 1.0228e-05]
	Learning Rate: 1.0228e-05
	LOSS [training: 0.38452254605408853 | validation: 0.4070743180322669]
	TIME [epoch: 9.47 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40696500255805185		[learning rate: 1.0191e-05]
	Learning Rate: 1.01909e-05
	LOSS [training: 0.40696500255805185 | validation: 0.4283569217068541]
	TIME [epoch: 9.44 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3808787320264332		[learning rate: 1.0154e-05]
	Learning Rate: 1.01539e-05
	LOSS [training: 0.3808787320264332 | validation: 0.4332597694095263]
	TIME [epoch: 9.44 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3820854601054259		[learning rate: 1.0117e-05]
	Learning Rate: 1.0117e-05
	LOSS [training: 0.3820854601054259 | validation: 0.42184360491031386]
	TIME [epoch: 9.46 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3866369555505435		[learning rate: 1.008e-05]
	Learning Rate: 1.00803e-05
	LOSS [training: 0.3866369555505435 | validation: 0.4904041962161796]
	TIME [epoch: 9.44 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38138288901610873		[learning rate: 1.0044e-05]
	Learning Rate: 1.00437e-05
	LOSS [training: 0.38138288901610873 | validation: 0.42515895313376434]
	TIME [epoch: 9.44 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3882149111770784		[learning rate: 1.0007e-05]
	Learning Rate: 1.00073e-05
	LOSS [training: 0.3882149111770784 | validation: 0.4536626256961884]
	TIME [epoch: 9.44 sec]
Finished training in 19080.766 seconds.
