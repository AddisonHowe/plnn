Args:
Namespace(name='model_tr_study205', outdir='out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2', training_data='data/transition_rate_studies/tr_study205/tr_study205_training/r2', validation_data='data/transition_rate_studies/tr_study205/tr_study205_validation/r2', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.075, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=100, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1061410384

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 5/5] avg loss: 12.0459610540568		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 12.0459610540568 | validation: 11.944530649177281]
	TIME [epoch: 79.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 5/5] avg loss: 11.459870997098285		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.459870997098285 | validation: 10.822737964906493]
	TIME [epoch: 9.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 5/5] avg loss: 11.20268041915845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.20268041915845 | validation: 12.560233036303943]
	TIME [epoch: 9.54 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 5/5] avg loss: 12.24344257332962		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 12.24344257332962 | validation: 11.580085672196846]
	TIME [epoch: 9.54 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 5/5] avg loss: 11.245087269087424		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.245087269087424 | validation: 11.157144847691013]
	TIME [epoch: 9.53 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 5/5] avg loss: 10.890961352214706		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.890961352214706 | validation: 11.230291189998661]
	TIME [epoch: 9.53 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 5/5] avg loss: 11.563787479995147		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.563787479995147 | validation: 11.865432509086586]
	TIME [epoch: 9.56 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 5/5] avg loss: 11.224532948313058		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.224532948313058 | validation: 11.021037071251053]
	TIME [epoch: 9.53 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 5/5] avg loss: 10.615683819133956		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.615683819133956 | validation: 10.031078470203346]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 5/5] avg loss: 10.064699345992173		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.064699345992173 | validation: 9.718380956311947]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.38990014545728		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.38990014545728 | validation: 9.99471604977363]
	TIME [epoch: 9.54 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.931782858454113		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.931782858454113 | validation: 7.204499361310414]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.575359745549626		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.575359745549626 | validation: 7.505767386823975]
	TIME [epoch: 9.54 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.37250083361576		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.37250083361576 | validation: 5.785416113411327]
	TIME [epoch: 9.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.411735255660166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.411735255660166 | validation: 6.696526508209479]
	TIME [epoch: 9.53 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.649646726995317		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.649646726995317 | validation: 8.824620596104541]
	TIME [epoch: 9.53 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.70001817256332		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.70001817256332 | validation: 5.927645891754727]
	TIME [epoch: 9.55 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.094719060903154		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.094719060903154 | validation: 5.61524043513976]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.9873527209272055		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.9873527209272055 | validation: 5.170049394322018]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.66325545062421		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.66325545062421 | validation: 6.1404536685960505]
	TIME [epoch: 9.55 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.396199304378212		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.396199304378212 | validation: 5.220833193869663]
	TIME [epoch: 9.53 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.4384260969785485		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.4384260969785485 | validation: 5.467153396754051]
	TIME [epoch: 9.53 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.350269244473128		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.350269244473128 | validation: 5.328288032361987]
	TIME [epoch: 9.53 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.162869142503922		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.162869142503922 | validation: 5.540429957923891]
	TIME [epoch: 9.55 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.255340173115954		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.255340173115954 | validation: 5.672964288501704]
	TIME [epoch: 9.52 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.161648768662699		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.161648768662699 | validation: 5.285821752605275]
	TIME [epoch: 9.53 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.042497350812718		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.042497350812718 | validation: 6.427529780662805]
	TIME [epoch: 9.55 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.104807922242109		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.104807922242109 | validation: 5.61300441479275]
	TIME [epoch: 9.54 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.2628398460709995		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.2628398460709995 | validation: 5.737825512570096]
	TIME [epoch: 9.53 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.468661650611245		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.468661650611245 | validation: 6.252822806233991]
	TIME [epoch: 9.53 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.23304635804845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.23304635804845 | validation: 5.611824763150278]
	TIME [epoch: 9.56 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.27485667922726		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.27485667922726 | validation: 5.102749628880134]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.038480575292966		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.038480575292966 | validation: 5.347336554795162]
	TIME [epoch: 9.54 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.945696240756619		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.945696240756619 | validation: 5.825874711234383]
	TIME [epoch: 9.55 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.87284853137971		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.87284853137971 | validation: 5.5905127396235414]
	TIME [epoch: 9.54 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.9502782945819455		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.9502782945819455 | validation: 6.1484390452826]
	TIME [epoch: 9.52 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.97742389187617		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.97742389187617 | validation: 5.2120611705651365]
	TIME [epoch: 9.53 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.8385863983595145		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.8385863983595145 | validation: 5.872992434848438]
	TIME [epoch: 9.56 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.807698430515617		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.807698430515617 | validation: 5.294711161362123]
	TIME [epoch: 9.53 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.965688791044204		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.965688791044204 | validation: 5.247642360392042]
	TIME [epoch: 9.54 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.9677869773677115		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.9677869773677115 | validation: 5.495530141403735]
	TIME [epoch: 9.55 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.768108657718986		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.768108657718986 | validation: 5.508701553266596]
	TIME [epoch: 9.57 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.543950212527015		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.543950212527015 | validation: 4.758500645748562]
	TIME [epoch: 9.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.662573275732369		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.662573275732369 | validation: 5.099346363470605]
	TIME [epoch: 9.54 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.66303095014811		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.66303095014811 | validation: 5.30235683053739]
	TIME [epoch: 9.56 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.574860140734414		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.574860140734414 | validation: 4.308123767427885]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.607586815817858		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.607586815817858 | validation: 4.623882381005256]
	TIME [epoch: 9.55 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.467848807468027		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.467848807468027 | validation: 5.041961120764021]
	TIME [epoch: 9.57 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.588918149635249		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.588918149635249 | validation: 5.2560442858803595]
	TIME [epoch: 9.52 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.423611484840818		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.423611484840818 | validation: 4.377991769205569]
	TIME [epoch: 9.55 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.337512170781946		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.337512170781946 | validation: 4.495142182605715]
	TIME [epoch: 9.56 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.1936567334288135		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.1936567334288135 | validation: 4.422263950704387]
	TIME [epoch: 9.54 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.343304001874575		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.343304001874575 | validation: 5.00308279252413]
	TIME [epoch: 9.53 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.401960419690531		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.401960419690531 | validation: 4.2133140302054155]
	TIME [epoch: 9.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.170412960602905		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.170412960602905 | validation: 5.213187453212628]
	TIME [epoch: 9.57 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.208447016530193		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.208447016530193 | validation: 4.36094040101997]
	TIME [epoch: 9.54 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.148276679707798		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.148276679707798 | validation: 4.29047760894493]
	TIME [epoch: 9.54 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.12018475405918		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.12018475405918 | validation: 5.85770865693894]
	TIME [epoch: 9.54 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.160344112891698		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.160344112891698 | validation: 3.9328672103930185]
	TIME [epoch: 9.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.943593519203754		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.943593519203754 | validation: 4.941896980691398]
	TIME [epoch: 9.54 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.003663676426982		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.003663676426982 | validation: 3.8939283847621113]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.972171830838735		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.972171830838735 | validation: 4.4168410107724165]
	TIME [epoch: 9.56 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9370492547324742		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9370492547324742 | validation: 4.123339605182023]
	TIME [epoch: 9.54 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.808190121423169		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.808190121423169 | validation: 5.315784934381589]
	TIME [epoch: 9.54 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.8838949689927924		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8838949689927924 | validation: 3.8979027990437043]
	TIME [epoch: 9.55 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.680370820555088		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.680370820555088 | validation: 4.534949461312491]
	TIME [epoch: 9.54 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.803681178218239		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.803681178218239 | validation: 5.00965762733166]
	TIME [epoch: 9.53 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.865383751032019		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.865383751032019 | validation: 4.48090964925713]
	TIME [epoch: 9.54 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.8211894046242287		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8211894046242287 | validation: 4.209754530068093]
	TIME [epoch: 9.55 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.805647217400859		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.805647217400859 | validation: 5.7735187756923345]
	TIME [epoch: 9.53 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.8537904689165305		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.8537904689165305 | validation: 4.46065553475402]
	TIME [epoch: 9.53 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.164422485419043		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.164422485419043 | validation: 4.079114223095381]
	TIME [epoch: 9.56 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.807559501745716		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.807559501745716 | validation: 3.938732083382536]
	TIME [epoch: 9.53 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.914048689356375		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.914048689356375 | validation: 3.701404416714482]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_74.pth
	Model improved!!!
EPOCH 75/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.61057381842029		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.61057381842029 | validation: 4.189592796766158]
	TIME [epoch: 9.54 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.7026550846370534		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7026550846370534 | validation: 3.8022958053791207]
	TIME [epoch: 9.56 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.398753337894752		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.398753337894752 | validation: 4.515027499377933]
	TIME [epoch: 9.53 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.7765357787247402		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7765357787247402 | validation: 4.170218747378483]
	TIME [epoch: 9.54 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.514840980919984		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.514840980919984 | validation: 3.7415940969479515]
	TIME [epoch: 9.54 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6457498201814347		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6457498201814347 | validation: 4.12814584850888]
	TIME [epoch: 9.53 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3504572377495796		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3504572377495796 | validation: 4.7342595959095926]
	TIME [epoch: 9.52 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6151708625397134		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6151708625397134 | validation: 4.1655606522409]
	TIME [epoch: 9.54 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.5104138810681214		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5104138810681214 | validation: 3.667715961224548]
	TIME [epoch: 9.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_83.pth
	Model improved!!!
EPOCH 84/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.603828932590679		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.603828932590679 | validation: 3.93988017309036]
	TIME [epoch: 9.54 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3903733793359727		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3903733793359727 | validation: 3.7062485368130034]
	TIME [epoch: 9.53 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.328093378877232		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.328093378877232 | validation: 4.155541363380237]
	TIME [epoch: 9.56 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4856941039307285		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4856941039307285 | validation: 3.487981132844677]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_87.pth
	Model improved!!!
EPOCH 88/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.425211383090576		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.425211383090576 | validation: 4.076547264454408]
	TIME [epoch: 9.52 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.439430027604667		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.439430027604667 | validation: 3.6398249043084765]
	TIME [epoch: 9.53 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3657161649093177		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3657161649093177 | validation: 3.783210151067245]
	TIME [epoch: 9.53 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.474669554852452		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.474669554852452 | validation: 5.0839944441592175]
	TIME [epoch: 9.52 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.659219681063996		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.659219681063996 | validation: 4.097172612889798]
	TIME [epoch: 9.53 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3269097013915827		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3269097013915827 | validation: 3.3872479610043134]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_93.pth
	Model improved!!!
EPOCH 94/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.402429117391759		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.402429117391759 | validation: 4.001890902269972]
	TIME [epoch: 9.54 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4214979884270265		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4214979884270265 | validation: 3.7430037144175414]
	TIME [epoch: 9.53 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2325487658484904		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2325487658484904 | validation: 4.083214547990757]
	TIME [epoch: 9.53 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.381281501369944		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.381281501369944 | validation: 3.3638991152145263]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1910480014814078		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1910480014814078 | validation: 4.194302457671629]
	TIME [epoch: 9.5 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.309763202132136		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.309763202132136 | validation: 3.635853446755914]
	TIME [epoch: 9.51 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.312672779320825		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.312672779320825 | validation: 3.7404302552136777]
	TIME [epoch: 9.54 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3455664379178502		[learning rate: 0.009971]
	Learning Rate: 0.00997096
	LOSS [training: 3.3455664379178502 | validation: 3.6322038775062153]
	TIME [epoch: 9.5 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2257430321267813		[learning rate: 0.0099348]
	Learning Rate: 0.00993477
	LOSS [training: 3.2257430321267813 | validation: 3.7105765027246482]
	TIME [epoch: 9.51 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.27819755605542		[learning rate: 0.0098987]
	Learning Rate: 0.00989872
	LOSS [training: 3.27819755605542 | validation: 3.874965824418581]
	TIME [epoch: 9.52 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.531688771583358		[learning rate: 0.0098628]
	Learning Rate: 0.00986279
	LOSS [training: 3.531688771583358 | validation: 3.3195625950579943]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_104.pth
	Model improved!!!
EPOCH 105/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.550264576436798		[learning rate: 0.009827]
	Learning Rate: 0.009827
	LOSS [training: 3.550264576436798 | validation: 5.575358069499838]
	TIME [epoch: 9.53 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.631342977832737		[learning rate: 0.0097913]
	Learning Rate: 0.00979134
	LOSS [training: 4.631342977832737 | validation: 3.6899477444413695]
	TIME [epoch: 9.54 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.014374146669774		[learning rate: 0.0097558]
	Learning Rate: 0.00975581
	LOSS [training: 4.014374146669774 | validation: 5.530732679456015]
	TIME [epoch: 9.56 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.0741418150525694		[learning rate: 0.0097204]
	Learning Rate: 0.0097204
	LOSS [training: 4.0741418150525694 | validation: 3.649032178656421]
	TIME [epoch: 9.54 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3048130009704217		[learning rate: 0.0096851]
	Learning Rate: 0.00968513
	LOSS [training: 3.3048130009704217 | validation: 3.6658037276043327]
	TIME [epoch: 9.54 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.416598318141213		[learning rate: 0.00965]
	Learning Rate: 0.00964998
	LOSS [training: 3.416598318141213 | validation: 3.606784386171861]
	TIME [epoch: 9.56 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2745568402549177		[learning rate: 0.009615]
	Learning Rate: 0.00961496
	LOSS [training: 3.2745568402549177 | validation: 3.6283906227297154]
	TIME [epoch: 9.54 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4001022375274417		[learning rate: 0.0095801]
	Learning Rate: 0.00958006
	LOSS [training: 3.4001022375274417 | validation: 3.752365442382883]
	TIME [epoch: 9.54 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0356667504861363		[learning rate: 0.0095453]
	Learning Rate: 0.0095453
	LOSS [training: 3.0356667504861363 | validation: 3.3829225269208303]
	TIME [epoch: 9.54 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1222470682769314		[learning rate: 0.0095107]
	Learning Rate: 0.00951066
	LOSS [training: 3.1222470682769314 | validation: 4.438391494658957]
	TIME [epoch: 9.56 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4698824602207368		[learning rate: 0.0094761]
	Learning Rate: 0.00947614
	LOSS [training: 3.4698824602207368 | validation: 3.2590680177982545]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_115.pth
	Model improved!!!
EPOCH 116/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3333990981876065		[learning rate: 0.0094418]
	Learning Rate: 0.00944175
	LOSS [training: 3.3333990981876065 | validation: 4.247554609005871]
	TIME [epoch: 9.53 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.147214200447776		[learning rate: 0.0094075]
	Learning Rate: 0.00940749
	LOSS [training: 3.147214200447776 | validation: 3.3706198802278555]
	TIME [epoch: 9.55 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.468429099654469		[learning rate: 0.0093733]
	Learning Rate: 0.00937335
	LOSS [training: 3.468429099654469 | validation: 3.690562892087876]
	TIME [epoch: 9.54 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0268523222017505		[learning rate: 0.0093393]
	Learning Rate: 0.00933933
	LOSS [training: 3.0268523222017505 | validation: 3.321372948241446]
	TIME [epoch: 9.53 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.081435853404777		[learning rate: 0.0093054]
	Learning Rate: 0.00930544
	LOSS [training: 3.081435853404777 | validation: 3.218272946914815]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_120.pth
	Model improved!!!
EPOCH 121/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.966859332956113		[learning rate: 0.0092717]
	Learning Rate: 0.00927167
	LOSS [training: 2.966859332956113 | validation: 3.645429942372086]
	TIME [epoch: 9.55 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.942145516649739		[learning rate: 0.009238]
	Learning Rate: 0.00923802
	LOSS [training: 2.942145516649739 | validation: 3.291589391868062]
	TIME [epoch: 9.54 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0333616065924986		[learning rate: 0.0092045]
	Learning Rate: 0.0092045
	LOSS [training: 3.0333616065924986 | validation: 3.696874746675274]
	TIME [epoch: 9.53 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.930280304593148		[learning rate: 0.0091711]
	Learning Rate: 0.00917109
	LOSS [training: 2.930280304593148 | validation: 3.356675419866976]
	TIME [epoch: 9.55 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.973862853692678		[learning rate: 0.0091378]
	Learning Rate: 0.00913781
	LOSS [training: 2.973862853692678 | validation: 3.9882665512016264]
	TIME [epoch: 9.53 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.943957355351073		[learning rate: 0.0091046]
	Learning Rate: 0.00910465
	LOSS [training: 2.943957355351073 | validation: 3.561767642174613]
	TIME [epoch: 9.53 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8736431003513037		[learning rate: 0.0090716]
	Learning Rate: 0.00907161
	LOSS [training: 2.8736431003513037 | validation: 3.577519694832485]
	TIME [epoch: 9.55 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.985269749919234		[learning rate: 0.0090387]
	Learning Rate: 0.00903868
	LOSS [training: 2.985269749919234 | validation: 3.2039219022727288]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_128.pth
	Model improved!!!
EPOCH 129/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7308764237315915		[learning rate: 0.0090059]
	Learning Rate: 0.00900588
	LOSS [training: 2.7308764237315915 | validation: 3.6390991764883727]
	TIME [epoch: 9.54 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9090529993674226		[learning rate: 0.0089732]
	Learning Rate: 0.0089732
	LOSS [training: 2.9090529993674226 | validation: 3.8730352182858487]
	TIME [epoch: 9.52 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.983467728519067		[learning rate: 0.0089406]
	Learning Rate: 0.00894064
	LOSS [training: 2.983467728519067 | validation: 3.140073787735844]
	TIME [epoch: 9.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_131.pth
	Model improved!!!
EPOCH 132/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7547733046612892		[learning rate: 0.0089082]
	Learning Rate: 0.00890819
	LOSS [training: 2.7547733046612892 | validation: 3.148098869941068]
	TIME [epoch: 9.53 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8047614265403498		[learning rate: 0.0088759]
	Learning Rate: 0.00887586
	LOSS [training: 2.8047614265403498 | validation: 3.053281006992802]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_133.pth
	Model improved!!!
EPOCH 134/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.745870384341791		[learning rate: 0.0088437]
	Learning Rate: 0.00884365
	LOSS [training: 2.745870384341791 | validation: 3.408413077122916]
	TIME [epoch: 9.54 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.705146510002716		[learning rate: 0.0088116]
	Learning Rate: 0.00881156
	LOSS [training: 2.705146510002716 | validation: 3.3327453747714424]
	TIME [epoch: 9.52 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0017053662199786		[learning rate: 0.0087796]
	Learning Rate: 0.00877958
	LOSS [training: 3.0017053662199786 | validation: 2.971658354608495]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_136.pth
	Model improved!!!
EPOCH 137/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9471695392241295		[learning rate: 0.0087477]
	Learning Rate: 0.00874772
	LOSS [training: 2.9471695392241295 | validation: 2.8996816129293426]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_137.pth
	Model improved!!!
EPOCH 138/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.849214127272133		[learning rate: 0.008716]
	Learning Rate: 0.00871597
	LOSS [training: 2.849214127272133 | validation: 3.080831651917732]
	TIME [epoch: 9.54 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7577249580970182		[learning rate: 0.0086843]
	Learning Rate: 0.00868434
	LOSS [training: 2.7577249580970182 | validation: 3.9959890467605095]
	TIME [epoch: 9.53 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.358423788899297		[learning rate: 0.0086528]
	Learning Rate: 0.00865282
	LOSS [training: 3.358423788899297 | validation: 2.978518678399437]
	TIME [epoch: 9.52 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1143424647724975		[learning rate: 0.0086214]
	Learning Rate: 0.00862142
	LOSS [training: 3.1143424647724975 | validation: 4.3579635570212885]
	TIME [epoch: 9.55 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8684840495788		[learning rate: 0.0085901]
	Learning Rate: 0.00859013
	LOSS [training: 2.8684840495788 | validation: 3.656817332539038]
	TIME [epoch: 9.52 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0122971865141777		[learning rate: 0.008559]
	Learning Rate: 0.00855896
	LOSS [training: 3.0122971865141777 | validation: 2.999707683678805]
	TIME [epoch: 9.53 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.709065222632715		[learning rate: 0.0085279]
	Learning Rate: 0.0085279
	LOSS [training: 2.709065222632715 | validation: 2.903130677576944]
	TIME [epoch: 9.53 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.697554033653045		[learning rate: 0.008497]
	Learning Rate: 0.00849695
	LOSS [training: 2.697554033653045 | validation: 3.6484781445616092]
	TIME [epoch: 9.54 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.735604693885082		[learning rate: 0.0084661]
	Learning Rate: 0.00846612
	LOSS [training: 2.735604693885082 | validation: 2.912232464058469]
	TIME [epoch: 9.52 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6342552659215754		[learning rate: 0.0084354]
	Learning Rate: 0.00843539
	LOSS [training: 2.6342552659215754 | validation: 3.092811461187601]
	TIME [epoch: 9.52 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.730167089744385		[learning rate: 0.0084048]
	Learning Rate: 0.00840478
	LOSS [training: 2.730167089744385 | validation: 2.954442217106654]
	TIME [epoch: 9.53 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6104544080975174		[learning rate: 0.0083743]
	Learning Rate: 0.00837428
	LOSS [training: 2.6104544080975174 | validation: 3.08467470843598]
	TIME [epoch: 9.52 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5120077447355387		[learning rate: 0.0083439]
	Learning Rate: 0.00834389
	LOSS [training: 2.5120077447355387 | validation: 3.276688730996607]
	TIME [epoch: 9.52 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6935132895393963		[learning rate: 0.0083136]
	Learning Rate: 0.00831361
	LOSS [training: 2.6935132895393963 | validation: 2.988771974402258]
	TIME [epoch: 9.52 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.732617034814056		[learning rate: 0.0082834]
	Learning Rate: 0.00828344
	LOSS [training: 2.732617034814056 | validation: 2.9119030472692486]
	TIME [epoch: 9.55 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.692343807713901		[learning rate: 0.0082534]
	Learning Rate: 0.00825338
	LOSS [training: 2.692343807713901 | validation: 2.7572808667606763]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_153.pth
	Model improved!!!
EPOCH 154/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.530566594610417		[learning rate: 0.0082234]
	Learning Rate: 0.00822342
	LOSS [training: 2.530566594610417 | validation: 2.7415109467468994]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_154.pth
	Model improved!!!
EPOCH 155/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.348596237751947		[learning rate: 0.0081936]
	Learning Rate: 0.00819358
	LOSS [training: 2.348596237751947 | validation: 2.6980958335690084]
	TIME [epoch: 9.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_155.pth
	Model improved!!!
EPOCH 156/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.029779525834649		[learning rate: 0.0081638]
	Learning Rate: 0.00816384
	LOSS [training: 2.029779525834649 | validation: 2.9519903152053986]
	TIME [epoch: 9.51 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3266235238587765		[learning rate: 0.0081342]
	Learning Rate: 0.00813422
	LOSS [training: 2.3266235238587765 | validation: 2.4854160432071697]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_157.pth
	Model improved!!!
EPOCH 158/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.051008515861592		[learning rate: 0.0081047]
	Learning Rate: 0.0081047
	LOSS [training: 2.051008515861592 | validation: 2.3332739331314993]
	TIME [epoch: 9.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_158.pth
	Model improved!!!
EPOCH 159/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.278280822869875		[learning rate: 0.0080753]
	Learning Rate: 0.00807529
	LOSS [training: 2.278280822869875 | validation: 2.1592384554496973]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_159.pth
	Model improved!!!
EPOCH 160/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.130306722811428		[learning rate: 0.008046]
	Learning Rate: 0.00804598
	LOSS [training: 2.130306722811428 | validation: 2.8212823748697726]
	TIME [epoch: 9.53 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.130239149205321		[learning rate: 0.0080168]
	Learning Rate: 0.00801678
	LOSS [training: 2.130239149205321 | validation: 2.565903639917607]
	TIME [epoch: 9.53 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.059859125888954		[learning rate: 0.0079877]
	Learning Rate: 0.00798769
	LOSS [training: 2.059859125888954 | validation: 2.0427288201754004]
	TIME [epoch: 9.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_162.pth
	Model improved!!!
EPOCH 163/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0129552412636875		[learning rate: 0.0079587]
	Learning Rate: 0.0079587
	LOSS [training: 2.0129552412636875 | validation: 2.1224545109702926]
	TIME [epoch: 9.52 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9475554681537244		[learning rate: 0.0079298]
	Learning Rate: 0.00792982
	LOSS [training: 1.9475554681537244 | validation: 2.468751817168502]
	TIME [epoch: 9.52 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9456338140508755		[learning rate: 0.007901]
	Learning Rate: 0.00790104
	LOSS [training: 1.9456338140508755 | validation: 2.767852893179029]
	TIME [epoch: 9.55 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0550704689784722		[learning rate: 0.0078724]
	Learning Rate: 0.00787237
	LOSS [training: 2.0550704689784722 | validation: 2.8554152011503584]
	TIME [epoch: 9.52 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.006382144252451		[learning rate: 0.0078438]
	Learning Rate: 0.0078438
	LOSS [training: 2.006382144252451 | validation: 2.3189404823225135]
	TIME [epoch: 9.52 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.936447511636787		[learning rate: 0.0078153]
	Learning Rate: 0.00781533
	LOSS [training: 1.936447511636787 | validation: 2.3494754844829155]
	TIME [epoch: 9.53 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.938915174794565		[learning rate: 0.007787]
	Learning Rate: 0.00778697
	LOSS [training: 1.938915174794565 | validation: 2.092921918525188]
	TIME [epoch: 9.54 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7419524076136923		[learning rate: 0.0077587]
	Learning Rate: 0.00775871
	LOSS [training: 1.7419524076136923 | validation: 2.201584411351914]
	TIME [epoch: 9.52 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.987656153093414		[learning rate: 0.0077306]
	Learning Rate: 0.00773055
	LOSS [training: 1.987656153093414 | validation: 2.2522280393897165]
	TIME [epoch: 9.52 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.903312773411654		[learning rate: 0.0077025]
	Learning Rate: 0.0077025
	LOSS [training: 1.903312773411654 | validation: 2.2530987701662255]
	TIME [epoch: 9.54 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1077498252212434		[learning rate: 0.0076745]
	Learning Rate: 0.00767455
	LOSS [training: 2.1077498252212434 | validation: 1.8781984206211104]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_173.pth
	Model improved!!!
EPOCH 174/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8126505114657523		[learning rate: 0.0076467]
	Learning Rate: 0.00764669
	LOSS [training: 1.8126505114657523 | validation: 2.065955749041992]
	TIME [epoch: 9.53 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7691960765625225		[learning rate: 0.0076189]
	Learning Rate: 0.00761894
	LOSS [training: 1.7691960765625225 | validation: 2.5056012666022376]
	TIME [epoch: 9.54 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9116291034465847		[learning rate: 0.0075913]
	Learning Rate: 0.00759129
	LOSS [training: 1.9116291034465847 | validation: 2.0868713040654923]
	TIME [epoch: 9.53 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7246019990889274		[learning rate: 0.0075637]
	Learning Rate: 0.00756374
	LOSS [training: 1.7246019990889274 | validation: 2.1218747709483576]
	TIME [epoch: 9.52 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7504361961842725		[learning rate: 0.0075363]
	Learning Rate: 0.00753629
	LOSS [training: 1.7504361961842725 | validation: 2.0177817176034525]
	TIME [epoch: 9.52 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.808168685484355		[learning rate: 0.0075089]
	Learning Rate: 0.00750895
	LOSS [training: 1.808168685484355 | validation: 2.3362044954040724]
	TIME [epoch: 9.54 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8442528728174161		[learning rate: 0.0074817]
	Learning Rate: 0.00748169
	LOSS [training: 1.8442528728174161 | validation: 2.3699097244164786]
	TIME [epoch: 9.52 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7802802852456487		[learning rate: 0.0074545]
	Learning Rate: 0.00745454
	LOSS [training: 1.7802802852456487 | validation: 2.6990843499913173]
	TIME [epoch: 9.52 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9183936949695983		[learning rate: 0.0074275]
	Learning Rate: 0.00742749
	LOSS [training: 1.9183936949695983 | validation: 2.186819563946863]
	TIME [epoch: 9.54 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0231642971333628		[learning rate: 0.0074005]
	Learning Rate: 0.00740054
	LOSS [training: 2.0231642971333628 | validation: 2.1686242960734488]
	TIME [epoch: 9.53 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0622602716298903		[learning rate: 0.0073737]
	Learning Rate: 0.00737368
	LOSS [training: 2.0622602716298903 | validation: 2.2281410761306204]
	TIME [epoch: 9.52 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6490571046130829		[learning rate: 0.0073469]
	Learning Rate: 0.00734692
	LOSS [training: 1.6490571046130829 | validation: 1.9424264502778]
	TIME [epoch: 9.52 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7448924363287588		[learning rate: 0.0073203]
	Learning Rate: 0.00732026
	LOSS [training: 1.7448924363287588 | validation: 1.983475434778324]
	TIME [epoch: 9.54 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.743302472931563		[learning rate: 0.0072937]
	Learning Rate: 0.00729369
	LOSS [training: 1.743302472931563 | validation: 1.9728809966924268]
	TIME [epoch: 9.53 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8425814427190363		[learning rate: 0.0072672]
	Learning Rate: 0.00726722
	LOSS [training: 1.8425814427190363 | validation: 2.4928896112990024]
	TIME [epoch: 9.52 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8481160533884737		[learning rate: 0.0072408]
	Learning Rate: 0.00724085
	LOSS [training: 1.8481160533884737 | validation: 1.9400840584888321]
	TIME [epoch: 9.53 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8733847327106006		[learning rate: 0.0072146]
	Learning Rate: 0.00721457
	LOSS [training: 1.8733847327106006 | validation: 1.9576495960935723]
	TIME [epoch: 9.52 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6286765910254672		[learning rate: 0.0071884]
	Learning Rate: 0.00718839
	LOSS [training: 1.6286765910254672 | validation: 2.090843931839266]
	TIME [epoch: 9.52 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4898340013287874		[learning rate: 0.0071623]
	Learning Rate: 0.0071623
	LOSS [training: 2.4898340013287874 | validation: 2.780338021185218]
	TIME [epoch: 9.52 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0275834819862975		[learning rate: 0.0071363]
	Learning Rate: 0.00713631
	LOSS [training: 2.0275834819862975 | validation: 1.9695524978030494]
	TIME [epoch: 9.55 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0610036225881077		[learning rate: 0.0071104]
	Learning Rate: 0.00711041
	LOSS [training: 2.0610036225881077 | validation: 3.418094544817974]
	TIME [epoch: 9.52 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9923582238569602		[learning rate: 0.0070846]
	Learning Rate: 0.00708461
	LOSS [training: 1.9923582238569602 | validation: 2.0445804048313154]
	TIME [epoch: 9.52 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.62479067177842		[learning rate: 0.0070589]
	Learning Rate: 0.0070589
	LOSS [training: 1.62479067177842 | validation: 2.1296968504017757]
	TIME [epoch: 9.54 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6912105211168384		[learning rate: 0.0070333]
	Learning Rate: 0.00703328
	LOSS [training: 1.6912105211168384 | validation: 2.0023629088371155]
	TIME [epoch: 9.52 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6975848959195505		[learning rate: 0.0070078]
	Learning Rate: 0.00700776
	LOSS [training: 1.6975848959195505 | validation: 1.8247870802059816]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_198.pth
	Model improved!!!
EPOCH 199/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6448451337979506		[learning rate: 0.0069823]
	Learning Rate: 0.00698232
	LOSS [training: 1.6448451337979506 | validation: 2.073223782594695]
	TIME [epoch: 9.52 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6282218488955333		[learning rate: 0.006957]
	Learning Rate: 0.00695698
	LOSS [training: 1.6282218488955333 | validation: 2.0302968154331453]
	TIME [epoch: 9.53 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5665534548787858		[learning rate: 0.0069317]
	Learning Rate: 0.00693174
	LOSS [training: 1.5665534548787858 | validation: 2.7967133862273905]
	TIME [epoch: 9.51 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7749067909384852		[learning rate: 0.0069066]
	Learning Rate: 0.00690658
	LOSS [training: 1.7749067909384852 | validation: 2.088137236210719]
	TIME [epoch: 9.51 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5779438942131618		[learning rate: 0.0068815]
	Learning Rate: 0.00688152
	LOSS [training: 1.5779438942131618 | validation: 2.5443440809197795]
	TIME [epoch: 9.53 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.942027778211394		[learning rate: 0.0068565]
	Learning Rate: 0.00685654
	LOSS [training: 1.942027778211394 | validation: 3.544652654059539]
	TIME [epoch: 9.51 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3160006332500602		[learning rate: 0.0068317]
	Learning Rate: 0.00683166
	LOSS [training: 2.3160006332500602 | validation: 2.092209153858871]
	TIME [epoch: 9.51 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7659733293492166		[learning rate: 0.0068069]
	Learning Rate: 0.00680687
	LOSS [training: 1.7659733293492166 | validation: 2.118970080594215]
	TIME [epoch: 9.52 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.601947793788162		[learning rate: 0.0067822]
	Learning Rate: 0.00678217
	LOSS [training: 1.601947793788162 | validation: 2.0183713204579043]
	TIME [epoch: 9.54 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8757229616252211		[learning rate: 0.0067576]
	Learning Rate: 0.00675755
	LOSS [training: 1.8757229616252211 | validation: 2.1065527980762644]
	TIME [epoch: 9.51 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5814505229925504		[learning rate: 0.006733]
	Learning Rate: 0.00673303
	LOSS [training: 1.5814505229925504 | validation: 1.6750472298624146]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_209.pth
	Model improved!!!
EPOCH 210/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5666599314390575		[learning rate: 0.0067086]
	Learning Rate: 0.00670859
	LOSS [training: 1.5666599314390575 | validation: 1.8699286384004858]
	TIME [epoch: 9.54 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6983655891337779		[learning rate: 0.0066842]
	Learning Rate: 0.00668425
	LOSS [training: 1.6983655891337779 | validation: 1.7548405622734933]
	TIME [epoch: 9.52 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5579407786002077		[learning rate: 0.00666]
	Learning Rate: 0.00665999
	LOSS [training: 1.5579407786002077 | validation: 2.1765812614381113]
	TIME [epoch: 9.51 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6123276344509239		[learning rate: 0.0066358]
	Learning Rate: 0.00663582
	LOSS [training: 1.6123276344509239 | validation: 2.025676578804876]
	TIME [epoch: 9.52 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6280367720208389		[learning rate: 0.0066117]
	Learning Rate: 0.00661174
	LOSS [training: 1.6280367720208389 | validation: 1.9444619512671992]
	TIME [epoch: 9.53 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5508436580028366		[learning rate: 0.0065877]
	Learning Rate: 0.00658775
	LOSS [training: 1.5508436580028366 | validation: 2.376504064670858]
	TIME [epoch: 9.51 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.312562684679508		[learning rate: 0.0065638]
	Learning Rate: 0.00656384
	LOSS [training: 2.312562684679508 | validation: 2.268965529300102]
	TIME [epoch: 9.51 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6788226157510455		[learning rate: 0.00654]
	Learning Rate: 0.00654002
	LOSS [training: 1.6788226157510455 | validation: 1.9331993915597343]
	TIME [epoch: 9.54 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4698616257268349		[learning rate: 0.0065163]
	Learning Rate: 0.00651628
	LOSS [training: 1.4698616257268349 | validation: 2.2691337199906316]
	TIME [epoch: 9.51 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5480683771661623		[learning rate: 0.0064926]
	Learning Rate: 0.00649264
	LOSS [training: 1.5480683771661623 | validation: 1.6929733074324043]
	TIME [epoch: 9.51 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4290170135489026		[learning rate: 0.0064691]
	Learning Rate: 0.00646907
	LOSS [training: 1.4290170135489026 | validation: 2.1354750461275978]
	TIME [epoch: 9.52 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.634335187735666		[learning rate: 0.0064456]
	Learning Rate: 0.0064456
	LOSS [training: 1.634335187735666 | validation: 1.5677686877781678]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_221.pth
	Model improved!!!
EPOCH 222/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.895153080937067		[learning rate: 0.0064222]
	Learning Rate: 0.00642221
	LOSS [training: 1.895153080937067 | validation: 2.52755095851574]
	TIME [epoch: 9.51 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.726116737800727		[learning rate: 0.0063989]
	Learning Rate: 0.0063989
	LOSS [training: 1.726116737800727 | validation: 1.7007027701855588]
	TIME [epoch: 9.51 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.335303778251426		[learning rate: 0.0063757]
	Learning Rate: 0.00637568
	LOSS [training: 1.335303778251426 | validation: 1.7740441469573298]
	TIME [epoch: 9.53 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6480644307386416		[learning rate: 0.0063525]
	Learning Rate: 0.00635254
	LOSS [training: 1.6480644307386416 | validation: 4.775819683899075]
	TIME [epoch: 9.51 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.467820433247371		[learning rate: 0.0063295]
	Learning Rate: 0.00632949
	LOSS [training: 2.467820433247371 | validation: 1.6479119748245274]
	TIME [epoch: 9.5 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.446456848459492		[learning rate: 0.0063065]
	Learning Rate: 0.00630652
	LOSS [training: 1.446456848459492 | validation: 1.7100352957779432]
	TIME [epoch: 9.52 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3505699633803618		[learning rate: 0.0062836]
	Learning Rate: 0.00628363
	LOSS [training: 1.3505699633803618 | validation: 1.6241023361200917]
	TIME [epoch: 9.52 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9252431016203277		[learning rate: 0.0062608]
	Learning Rate: 0.00626082
	LOSS [training: 1.9252431016203277 | validation: 2.15384676255053]
	TIME [epoch: 9.51 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5028600513370578		[learning rate: 0.0062381]
	Learning Rate: 0.0062381
	LOSS [training: 1.5028600513370578 | validation: 1.66794776632591]
	TIME [epoch: 9.5 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5281867172053523		[learning rate: 0.0062155]
	Learning Rate: 0.00621547
	LOSS [training: 1.5281867172053523 | validation: 1.9052497017666719]
	TIME [epoch: 9.54 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4331251227478066		[learning rate: 0.0061929]
	Learning Rate: 0.00619291
	LOSS [training: 1.4331251227478066 | validation: 1.8833984871453542]
	TIME [epoch: 9.51 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3403659720972665		[learning rate: 0.0061704]
	Learning Rate: 0.00617043
	LOSS [training: 1.3403659720972665 | validation: 1.8456667550722756]
	TIME [epoch: 9.51 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4050599417849146		[learning rate: 0.006148]
	Learning Rate: 0.00614804
	LOSS [training: 1.4050599417849146 | validation: 1.9937680759014516]
	TIME [epoch: 9.52 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3966698875812724		[learning rate: 0.0061257]
	Learning Rate: 0.00612573
	LOSS [training: 1.3966698875812724 | validation: 2.0750040720937903]
	TIME [epoch: 9.52 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5400968652560567		[learning rate: 0.0061035]
	Learning Rate: 0.0061035
	LOSS [training: 1.5400968652560567 | validation: 1.645932947587243]
	TIME [epoch: 9.51 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5608959253875598		[learning rate: 0.0060814]
	Learning Rate: 0.00608135
	LOSS [training: 1.5608959253875598 | validation: 1.9411297621614705]
	TIME [epoch: 9.51 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.697567900057053		[learning rate: 0.0060593]
	Learning Rate: 0.00605928
	LOSS [training: 1.697567900057053 | validation: 1.8123417639177553]
	TIME [epoch: 9.53 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9305612132881127		[learning rate: 0.0060373]
	Learning Rate: 0.00603729
	LOSS [training: 1.9305612132881127 | validation: 2.84666105870936]
	TIME [epoch: 9.51 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8454614778822038		[learning rate: 0.0060154]
	Learning Rate: 0.00601538
	LOSS [training: 1.8454614778822038 | validation: 1.7060446057475718]
	TIME [epoch: 9.51 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7563109465129974		[learning rate: 0.0059936]
	Learning Rate: 0.00599355
	LOSS [training: 1.7563109465129974 | validation: 1.8063476756558832]
	TIME [epoch: 9.53 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3457373434485875		[learning rate: 0.0059718]
	Learning Rate: 0.0059718
	LOSS [training: 1.3457373434485875 | validation: 1.507532841730545]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_242.pth
	Model improved!!!
EPOCH 243/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5593248303649705		[learning rate: 0.0059501]
	Learning Rate: 0.00595013
	LOSS [training: 1.5593248303649705 | validation: 1.6914227936868427]
	TIME [epoch: 9.52 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3166420212154322		[learning rate: 0.0059285]
	Learning Rate: 0.00592853
	LOSS [training: 1.3166420212154322 | validation: 1.8792549834891572]
	TIME [epoch: 9.53 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4235137472386215		[learning rate: 0.005907]
	Learning Rate: 0.00590702
	LOSS [training: 1.4235137472386215 | validation: 1.994555906152668]
	TIME [epoch: 9.54 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5017131132211778		[learning rate: 0.0058856]
	Learning Rate: 0.00588558
	LOSS [training: 1.5017131132211778 | validation: 1.5963855800237157]
	TIME [epoch: 9.51 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3668809403834585		[learning rate: 0.0058642]
	Learning Rate: 0.00586422
	LOSS [training: 1.3668809403834585 | validation: 1.559422858183729]
	TIME [epoch: 9.52 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4030031880580702		[learning rate: 0.0058429]
	Learning Rate: 0.00584294
	LOSS [training: 1.4030031880580702 | validation: 1.6529299348074136]
	TIME [epoch: 9.54 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2810140952267972		[learning rate: 0.0058217]
	Learning Rate: 0.00582174
	LOSS [training: 1.2810140952267972 | validation: 1.689392376473144]
	TIME [epoch: 9.53 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4110434513593755		[learning rate: 0.0058006]
	Learning Rate: 0.00580061
	LOSS [training: 1.4110434513593755 | validation: 1.6282737919025547]
	TIME [epoch: 9.52 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2294041507595785		[learning rate: 0.0057796]
	Learning Rate: 0.00577956
	LOSS [training: 1.2294041507595785 | validation: 1.530951399456444]
	TIME [epoch: 9.52 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4071770416973206		[learning rate: 0.0057586]
	Learning Rate: 0.00575859
	LOSS [training: 1.4071770416973206 | validation: 1.63850522278153]
	TIME [epoch: 9.54 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3275579661506556		[learning rate: 0.0057377]
	Learning Rate: 0.00573769
	LOSS [training: 1.3275579661506556 | validation: 1.6031484613673106]
	TIME [epoch: 9.51 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4481625091174128		[learning rate: 0.0057169]
	Learning Rate: 0.00571686
	LOSS [training: 1.4481625091174128 | validation: 1.5409962438071183]
	TIME [epoch: 9.53 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2958378327892432		[learning rate: 0.0056961]
	Learning Rate: 0.00569612
	LOSS [training: 1.2958378327892432 | validation: 1.6827080734996096]
	TIME [epoch: 9.53 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.209840541756677		[learning rate: 0.0056754]
	Learning Rate: 0.00567545
	LOSS [training: 1.209840541756677 | validation: 1.829920127922249]
	TIME [epoch: 9.52 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2981001245777581		[learning rate: 0.0056548]
	Learning Rate: 0.00565485
	LOSS [training: 1.2981001245777581 | validation: 1.5462041325350566]
	TIME [epoch: 9.51 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2675393768668852		[learning rate: 0.0056343]
	Learning Rate: 0.00563433
	LOSS [training: 1.2675393768668852 | validation: 2.2182587975022843]
	TIME [epoch: 9.51 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4514140435394454		[learning rate: 0.0056139]
	Learning Rate: 0.00561388
	LOSS [training: 1.4514140435394454 | validation: 1.4369126044412894]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_259.pth
	Model improved!!!
EPOCH 260/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.930354690721855		[learning rate: 0.0055935]
	Learning Rate: 0.00559351
	LOSS [training: 1.930354690721855 | validation: 1.9328892365201973]
	TIME [epoch: 9.53 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2963216531796988		[learning rate: 0.0055732]
	Learning Rate: 0.00557321
	LOSS [training: 1.2963216531796988 | validation: 1.95219529306723]
	TIME [epoch: 9.52 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2185196105281513		[learning rate: 0.005553]
	Learning Rate: 0.00555298
	LOSS [training: 1.2185196105281513 | validation: 1.8641967570021643]
	TIME [epoch: 9.53 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3039432404692797		[learning rate: 0.0055328]
	Learning Rate: 0.00553283
	LOSS [training: 1.3039432404692797 | validation: 2.3072277149441502]
	TIME [epoch: 9.5 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4241717967792142		[learning rate: 0.0055128]
	Learning Rate: 0.00551275
	LOSS [training: 1.4241717967792142 | validation: 1.8001645691777335]
	TIME [epoch: 9.5 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.305405110750042		[learning rate: 0.0054927]
	Learning Rate: 0.00549274
	LOSS [training: 1.305405110750042 | validation: 1.846176336148962]
	TIME [epoch: 9.51 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3548281479184745		[learning rate: 0.0054728]
	Learning Rate: 0.00547281
	LOSS [training: 1.3548281479184745 | validation: 2.4760529334165113]
	TIME [epoch: 9.51 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3888414333657981		[learning rate: 0.005453]
	Learning Rate: 0.00545295
	LOSS [training: 1.3888414333657981 | validation: 1.9667311065468587]
	TIME [epoch: 9.5 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3755925186235196		[learning rate: 0.0054332]
	Learning Rate: 0.00543316
	LOSS [training: 1.3755925186235196 | validation: 1.936379287401412]
	TIME [epoch: 9.51 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2673216735533885		[learning rate: 0.0054134]
	Learning Rate: 0.00541344
	LOSS [training: 1.2673216735533885 | validation: 1.4937044085387083]
	TIME [epoch: 9.52 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1890111239275813		[learning rate: 0.0053938]
	Learning Rate: 0.0053938
	LOSS [training: 1.1890111239275813 | validation: 1.3454140922070064]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_270.pth
	Model improved!!!
EPOCH 271/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8408325992884194		[learning rate: 0.0053742]
	Learning Rate: 0.00537422
	LOSS [training: 1.8408325992884194 | validation: 2.165610448553621]
	TIME [epoch: 9.54 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7544244057601794		[learning rate: 0.0053547]
	Learning Rate: 0.00535472
	LOSS [training: 1.7544244057601794 | validation: 1.5942600832625666]
	TIME [epoch: 9.53 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5355662497424665		[learning rate: 0.0053353]
	Learning Rate: 0.00533529
	LOSS [training: 1.5355662497424665 | validation: 1.9884255922202188]
	TIME [epoch: 9.52 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6027254942405817		[learning rate: 0.0053159]
	Learning Rate: 0.00531593
	LOSS [training: 1.6027254942405817 | validation: 1.5233335139083302]
	TIME [epoch: 9.51 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.393737485226385		[learning rate: 0.0052966]
	Learning Rate: 0.00529663
	LOSS [training: 1.393737485226385 | validation: 2.189636182649464]
	TIME [epoch: 9.5 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3717825185532528		[learning rate: 0.0052774]
	Learning Rate: 0.00527741
	LOSS [training: 1.3717825185532528 | validation: 1.4492696471813913]
	TIME [epoch: 9.53 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1980223375020382		[learning rate: 0.0052583]
	Learning Rate: 0.00525826
	LOSS [training: 1.1980223375020382 | validation: 1.6224579107745225]
	TIME [epoch: 9.51 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6157254324401549		[learning rate: 0.0052392]
	Learning Rate: 0.00523918
	LOSS [training: 1.6157254324401549 | validation: 1.6289807486709225]
	TIME [epoch: 9.51 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6919500578227389		[learning rate: 0.0052202]
	Learning Rate: 0.00522017
	LOSS [training: 1.6919500578227389 | validation: 1.9258913549479628]
	TIME [epoch: 9.52 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4707206895025469		[learning rate: 0.0052012]
	Learning Rate: 0.00520122
	LOSS [training: 1.4707206895025469 | validation: 1.5539892396748156]
	TIME [epoch: 9.53 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.305585407001447		[learning rate: 0.0051823]
	Learning Rate: 0.00518234
	LOSS [training: 1.305585407001447 | validation: 1.5015841946855102]
	TIME [epoch: 9.52 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.347233314574122		[learning rate: 0.0051635]
	Learning Rate: 0.00516354
	LOSS [training: 1.347233314574122 | validation: 7.42688631316711]
	TIME [epoch: 9.52 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7220496677272377		[learning rate: 0.0051448]
	Learning Rate: 0.0051448
	LOSS [training: 2.7220496677272377 | validation: 1.5902557213766984]
	TIME [epoch: 9.54 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.187372032337176		[learning rate: 0.0051261]
	Learning Rate: 0.00512613
	LOSS [training: 1.187372032337176 | validation: 1.8589327526294397]
	TIME [epoch: 9.51 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1896002251112958		[learning rate: 0.0051075]
	Learning Rate: 0.00510753
	LOSS [training: 1.1896002251112958 | validation: 1.5868111650781953]
	TIME [epoch: 9.51 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.272292672508899		[learning rate: 0.005089]
	Learning Rate: 0.00508899
	LOSS [training: 1.272292672508899 | validation: 1.746756036956898]
	TIME [epoch: 9.53 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3250978994749443		[learning rate: 0.0050705]
	Learning Rate: 0.00507052
	LOSS [training: 1.3250978994749443 | validation: 4.572633680182104]
	TIME [epoch: 9.51 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3850290921866044		[learning rate: 0.0050521]
	Learning Rate: 0.00505212
	LOSS [training: 2.3850290921866044 | validation: 1.9000905308927487]
	TIME [epoch: 9.52 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.38280439687521		[learning rate: 0.0050338]
	Learning Rate: 0.00503379
	LOSS [training: 1.38280439687521 | validation: 2.5073308898296096]
	TIME [epoch: 9.5 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6741818100960952		[learning rate: 0.0050155]
	Learning Rate: 0.00501552
	LOSS [training: 1.6741818100960952 | validation: 1.5179920114731118]
	TIME [epoch: 9.53 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3704716095891223		[learning rate: 0.0049973]
	Learning Rate: 0.00499732
	LOSS [training: 1.3704716095891223 | validation: 1.4237708682237626]
	TIME [epoch: 9.51 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2256016734238862		[learning rate: 0.0049792]
	Learning Rate: 0.00497918
	LOSS [training: 1.2256016734238862 | validation: 1.520577841379886]
	TIME [epoch: 9.51 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4950307884061036		[learning rate: 0.0049611]
	Learning Rate: 0.00496111
	LOSS [training: 1.4950307884061036 | validation: 2.0383216626052736]
	TIME [epoch: 9.52 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5617629741231789		[learning rate: 0.0049431]
	Learning Rate: 0.00494311
	LOSS [training: 1.5617629741231789 | validation: 1.466288900374571]
	TIME [epoch: 9.52 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4087749118604662		[learning rate: 0.0049252]
	Learning Rate: 0.00492517
	LOSS [training: 1.4087749118604662 | validation: 2.320798186749945]
	TIME [epoch: 9.51 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4307213569807569		[learning rate: 0.0049073]
	Learning Rate: 0.00490729
	LOSS [training: 1.4307213569807569 | validation: 1.8204563874056043]
	TIME [epoch: 9.5 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2719575125068485		[learning rate: 0.0048895]
	Learning Rate: 0.00488948
	LOSS [training: 1.2719575125068485 | validation: 2.2397322556497223]
	TIME [epoch: 9.53 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.442005164760572		[learning rate: 0.0048717]
	Learning Rate: 0.00487174
	LOSS [training: 1.442005164760572 | validation: 1.7225703859278805]
	TIME [epoch: 9.52 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1990297255096702		[learning rate: 0.0048541]
	Learning Rate: 0.00485406
	LOSS [training: 1.1990297255096702 | validation: 2.1873895281599305]
	TIME [epoch: 9.52 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7020753604229142		[learning rate: 0.0048364]
	Learning Rate: 0.00483645
	LOSS [training: 1.7020753604229142 | validation: 1.8178641826971813]
	TIME [epoch: 9.52 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2213554296837674		[learning rate: 0.0048189]
	Learning Rate: 0.00481889
	LOSS [training: 1.2213554296837674 | validation: 1.4675923641577793]
	TIME [epoch: 9.53 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7650511901430934		[learning rate: 0.0048014]
	Learning Rate: 0.00480141
	LOSS [training: 1.7650511901430934 | validation: 2.149126913472418]
	TIME [epoch: 9.51 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5032729444349666		[learning rate: 0.004784]
	Learning Rate: 0.00478398
	LOSS [training: 1.5032729444349666 | validation: 10.681775141966845]
	TIME [epoch: 9.52 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.728361349400812		[learning rate: 0.0047666]
	Learning Rate: 0.00476662
	LOSS [training: 5.728361349400812 | validation: 2.179904800121887]
	TIME [epoch: 9.53 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2879589104869864		[learning rate: 0.0047493]
	Learning Rate: 0.00474932
	LOSS [training: 1.2879589104869864 | validation: 1.4949417080631042]
	TIME [epoch: 9.51 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1741806593726336		[learning rate: 0.0047321]
	Learning Rate: 0.00473209
	LOSS [training: 1.1741806593726336 | validation: 1.6477350860637188]
	TIME [epoch: 9.52 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1575726813744107		[learning rate: 0.0047149]
	Learning Rate: 0.00471491
	LOSS [training: 1.1575726813744107 | validation: 2.2064466005700574]
	TIME [epoch: 9.54 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3326947034566627		[learning rate: 0.0046978]
	Learning Rate: 0.0046978
	LOSS [training: 1.3326947034566627 | validation: 1.6900924864410678]
	TIME [epoch: 9.52 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.141471056221773		[learning rate: 0.0046808]
	Learning Rate: 0.00468075
	LOSS [training: 1.141471056221773 | validation: 1.725998302251862]
	TIME [epoch: 9.52 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2672967051008128		[learning rate: 0.0046638]
	Learning Rate: 0.00466377
	LOSS [training: 1.2672967051008128 | validation: 1.5173021463014615]
	TIME [epoch: 9.52 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5303610221759736		[learning rate: 0.0046468]
	Learning Rate: 0.00464684
	LOSS [training: 1.5303610221759736 | validation: 2.285788131260802]
	TIME [epoch: 9.53 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5297389422984258		[learning rate: 0.00463]
	Learning Rate: 0.00462998
	LOSS [training: 1.5297389422984258 | validation: 1.5956533252237788]
	TIME [epoch: 9.52 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2461972256651128		[learning rate: 0.0046132]
	Learning Rate: 0.00461318
	LOSS [training: 1.2461972256651128 | validation: 1.4945356673321208]
	TIME [epoch: 9.52 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1067074699298138		[learning rate: 0.0045964]
	Learning Rate: 0.00459643
	LOSS [training: 1.1067074699298138 | validation: 1.4866327978131568]
	TIME [epoch: 9.54 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1565884162277282		[learning rate: 0.0045798]
	Learning Rate: 0.00457975
	LOSS [training: 1.1565884162277282 | validation: 2.756918891215232]
	TIME [epoch: 9.51 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5155698205520745		[learning rate: 0.0045631]
	Learning Rate: 0.00456313
	LOSS [training: 1.5155698205520745 | validation: 1.83089777008986]
	TIME [epoch: 9.51 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1575318697412205		[learning rate: 0.0045466]
	Learning Rate: 0.00454657
	LOSS [training: 1.1575318697412205 | validation: 1.5039887860649859]
	TIME [epoch: 9.51 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1592286803345102		[learning rate: 0.0045301]
	Learning Rate: 0.00453007
	LOSS [training: 1.1592286803345102 | validation: 1.6083131280986451]
	TIME [epoch: 9.54 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3249684127938948		[learning rate: 0.0045136]
	Learning Rate: 0.00451363
	LOSS [training: 1.3249684127938948 | validation: 5.137015473924428]
	TIME [epoch: 9.52 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.651294127106101		[learning rate: 0.0044973]
	Learning Rate: 0.00449725
	LOSS [training: 2.651294127106101 | validation: 1.828662176559491]
	TIME [epoch: 9.51 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1692060475282289		[learning rate: 0.0044809]
	Learning Rate: 0.00448093
	LOSS [training: 1.1692060475282289 | validation: 1.4326531645942664]
	TIME [epoch: 9.52 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3260469305184497		[learning rate: 0.0044647]
	Learning Rate: 0.00446467
	LOSS [training: 1.3260469305184497 | validation: 1.7081219018655214]
	TIME [epoch: 9.52 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.503561152186165		[learning rate: 0.0044485]
	Learning Rate: 0.00444847
	LOSS [training: 1.503561152186165 | validation: 1.583274403554577]
	TIME [epoch: 9.52 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2733223490155408		[learning rate: 0.0044323]
	Learning Rate: 0.00443232
	LOSS [training: 1.2733223490155408 | validation: 2.259499401407751]
	TIME [epoch: 9.5 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.412631666615106		[learning rate: 0.0044162]
	Learning Rate: 0.00441624
	LOSS [training: 1.412631666615106 | validation: 1.5038781903980842]
	TIME [epoch: 9.54 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.626623101406017		[learning rate: 0.0044002]
	Learning Rate: 0.00440021
	LOSS [training: 1.626623101406017 | validation: 1.7907272697654362]
	TIME [epoch: 9.51 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.138813564084113		[learning rate: 0.0043842]
	Learning Rate: 0.00438424
	LOSS [training: 1.138813564084113 | validation: 1.7390153697236088]
	TIME [epoch: 9.52 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2352643435242965		[learning rate: 0.0043683]
	Learning Rate: 0.00436833
	LOSS [training: 1.2352643435242965 | validation: 1.8181901127017457]
	TIME [epoch: 9.54 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1784794397139373		[learning rate: 0.0043525]
	Learning Rate: 0.00435248
	LOSS [training: 1.1784794397139373 | validation: 1.4152314671241488]
	TIME [epoch: 9.52 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.664030474767745		[learning rate: 0.0043367]
	Learning Rate: 0.00433668
	LOSS [training: 1.664030474767745 | validation: 1.7115023862539982]
	TIME [epoch: 9.52 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3433891612596658		[learning rate: 0.0043209]
	Learning Rate: 0.00432095
	LOSS [training: 1.3433891612596658 | validation: 1.6833993017113411]
	TIME [epoch: 9.51 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5405187960972402		[learning rate: 0.0043053]
	Learning Rate: 0.00430527
	LOSS [training: 1.5405187960972402 | validation: 2.9359086137190338]
	TIME [epoch: 9.55 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7994314232230129		[learning rate: 0.0042896]
	Learning Rate: 0.00428964
	LOSS [training: 1.7994314232230129 | validation: 1.903996964797711]
	TIME [epoch: 9.51 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2687688567463697		[learning rate: 0.0042741]
	Learning Rate: 0.00427407
	LOSS [training: 1.2687688567463697 | validation: 1.8306803622187757]
	TIME [epoch: 9.51 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.272439320774028		[learning rate: 0.0042586]
	Learning Rate: 0.00425856
	LOSS [training: 1.272439320774028 | validation: 1.5864951286557858]
	TIME [epoch: 9.54 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3916378417530317		[learning rate: 0.0042431]
	Learning Rate: 0.00424311
	LOSS [training: 1.3916378417530317 | validation: 1.4412051767912675]
	TIME [epoch: 9.51 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1586192269968016		[learning rate: 0.0042277]
	Learning Rate: 0.00422771
	LOSS [training: 1.1586192269968016 | validation: 1.5674013167960295]
	TIME [epoch: 9.52 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2898130352199406		[learning rate: 0.0042124]
	Learning Rate: 0.00421237
	LOSS [training: 1.2898130352199406 | validation: 1.524915104238465]
	TIME [epoch: 9.52 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1976560487206096		[learning rate: 0.0041971]
	Learning Rate: 0.00419708
	LOSS [training: 1.1976560487206096 | validation: 1.5036188708076583]
	TIME [epoch: 9.53 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.216309998916063		[learning rate: 0.0041818]
	Learning Rate: 0.00418185
	LOSS [training: 1.216309998916063 | validation: 1.5264023911471787]
	TIME [epoch: 9.51 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1701517080995534		[learning rate: 0.0041667]
	Learning Rate: 0.00416667
	LOSS [training: 1.1701517080995534 | validation: 1.6732641762503857]
	TIME [epoch: 9.5 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.135719827558916		[learning rate: 0.0041516]
	Learning Rate: 0.00415155
	LOSS [training: 1.135719827558916 | validation: 1.6124476279953495]
	TIME [epoch: 9.54 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2246563354685027		[learning rate: 0.0041365]
	Learning Rate: 0.00413649
	LOSS [training: 1.2246563354685027 | validation: 1.4512554484304834]
	TIME [epoch: 9.53 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4154505710840863		[learning rate: 0.0041215]
	Learning Rate: 0.00412147
	LOSS [training: 1.4154505710840863 | validation: 2.359286894884237]
	TIME [epoch: 9.52 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.7913840068962985		[learning rate: 0.0041065]
	Learning Rate: 0.00410652
	LOSS [training: 6.7913840068962985 | validation: 1.4764358567402553]
	TIME [epoch: 9.53 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.142500074456872		[learning rate: 0.0040916]
	Learning Rate: 0.00409161
	LOSS [training: 1.142500074456872 | validation: 1.5254439693873962]
	TIME [epoch: 9.53 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3930889260637653		[learning rate: 0.0040768]
	Learning Rate: 0.00407677
	LOSS [training: 1.3930889260637653 | validation: 1.9228984602394708]
	TIME [epoch: 9.5 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2989829523881646		[learning rate: 0.004062]
	Learning Rate: 0.00406197
	LOSS [training: 1.2989829523881646 | validation: 1.3740119107971354]
	TIME [epoch: 9.51 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0919512774578117		[learning rate: 0.0040472]
	Learning Rate: 0.00404723
	LOSS [training: 1.0919512774578117 | validation: 1.5392546029408403]
	TIME [epoch: 9.54 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0831304613343267		[learning rate: 0.0040325]
	Learning Rate: 0.00403254
	LOSS [training: 1.0831304613343267 | validation: 1.4046022511841563]
	TIME [epoch: 9.52 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.065311896858947		[learning rate: 0.0040179]
	Learning Rate: 0.00401791
	LOSS [training: 1.065311896858947 | validation: 1.6059472940798514]
	TIME [epoch: 9.52 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.119443553955233		[learning rate: 0.0040033]
	Learning Rate: 0.00400333
	LOSS [training: 1.119443553955233 | validation: 1.9277201818281557]
	TIME [epoch: 9.53 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.13869960277895		[learning rate: 0.0039888]
	Learning Rate: 0.0039888
	LOSS [training: 1.13869960277895 | validation: 1.3002574740976485]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_353.pth
	Model improved!!!
EPOCH 354/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3837563697522153		[learning rate: 0.0039743]
	Learning Rate: 0.00397432
	LOSS [training: 1.3837563697522153 | validation: 1.7417222138609294]
	TIME [epoch: 9.53 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2990257579389035		[learning rate: 0.0039599]
	Learning Rate: 0.0039599
	LOSS [training: 1.2990257579389035 | validation: 1.4281970954108034]
	TIME [epoch: 9.53 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1107696397798947		[learning rate: 0.0039455]
	Learning Rate: 0.00394553
	LOSS [training: 1.1107696397798947 | validation: 1.475346319499913]
	TIME [epoch: 9.54 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.092365898276305		[learning rate: 0.0039312]
	Learning Rate: 0.00393121
	LOSS [training: 1.092365898276305 | validation: 1.410855712084635]
	TIME [epoch: 9.54 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1526995850629997		[learning rate: 0.0039169]
	Learning Rate: 0.00391694
	LOSS [training: 1.1526995850629997 | validation: 1.6135348163515968]
	TIME [epoch: 9.54 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1155096341930304		[learning rate: 0.0039027]
	Learning Rate: 0.00390273
	LOSS [training: 1.1155096341930304 | validation: 1.5733302858790563]
	TIME [epoch: 9.53 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1431491455152591		[learning rate: 0.0038886]
	Learning Rate: 0.00388857
	LOSS [training: 1.1431491455152591 | validation: 2.101744062418933]
	TIME [epoch: 9.52 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.330445468944816		[learning rate: 0.0038745]
	Learning Rate: 0.00387445
	LOSS [training: 1.330445468944816 | validation: 1.663188288985221]
	TIME [epoch: 9.52 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1916773148480415		[learning rate: 0.0038604]
	Learning Rate: 0.00386039
	LOSS [training: 1.1916773148480415 | validation: 1.4897962850554285]
	TIME [epoch: 9.52 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1280523255417958		[learning rate: 0.0038464]
	Learning Rate: 0.00384638
	LOSS [training: 1.1280523255417958 | validation: 1.9508427004071498]
	TIME [epoch: 9.54 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2767533573635528		[learning rate: 0.0038324]
	Learning Rate: 0.00383242
	LOSS [training: 1.2767533573635528 | validation: 1.5828100728407024]
	TIME [epoch: 9.52 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1119514630793952		[learning rate: 0.0038185]
	Learning Rate: 0.00381852
	LOSS [training: 1.1119514630793952 | validation: 1.5649921363520838]
	TIME [epoch: 9.53 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2121288682025546		[learning rate: 0.0038047]
	Learning Rate: 0.00380466
	LOSS [training: 1.2121288682025546 | validation: 1.430331744101115]
	TIME [epoch: 9.54 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1476181102237248		[learning rate: 0.0037909]
	Learning Rate: 0.00379085
	LOSS [training: 1.1476181102237248 | validation: 1.4335644983303217]
	TIME [epoch: 9.53 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0855631587339496		[learning rate: 0.0037771]
	Learning Rate: 0.00377709
	LOSS [training: 1.0855631587339496 | validation: 1.4217215640410865]
	TIME [epoch: 9.53 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.085789697243466		[learning rate: 0.0037634]
	Learning Rate: 0.00376339
	LOSS [training: 1.085789697243466 | validation: 1.560999363286044]
	TIME [epoch: 9.52 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1171934286836698		[learning rate: 0.0037497]
	Learning Rate: 0.00374973
	LOSS [training: 1.1171934286836698 | validation: 1.4505938265788296]
	TIME [epoch: 9.54 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.100758791288634		[learning rate: 0.0037361]
	Learning Rate: 0.00373612
	LOSS [training: 1.100758791288634 | validation: 1.4298530775948246]
	TIME [epoch: 9.52 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.225222754625514		[learning rate: 0.0037226]
	Learning Rate: 0.00372256
	LOSS [training: 1.225222754625514 | validation: 1.9223237888059135]
	TIME [epoch: 9.52 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1695234253630387		[learning rate: 0.0037091]
	Learning Rate: 0.00370905
	LOSS [training: 1.1695234253630387 | validation: 1.5196429305831365]
	TIME [epoch: 9.55 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1254463442022775		[learning rate: 0.0036956]
	Learning Rate: 0.00369559
	LOSS [training: 1.1254463442022775 | validation: 2.1168102579390182]
	TIME [epoch: 9.53 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2926276262683276		[learning rate: 0.0036822]
	Learning Rate: 0.00368218
	LOSS [training: 1.2926276262683276 | validation: 1.4634264374012553]
	TIME [epoch: 9.53 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.069647672686636		[learning rate: 0.0036688]
	Learning Rate: 0.00366882
	LOSS [training: 1.069647672686636 | validation: 1.555164597273306]
	TIME [epoch: 9.52 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.113823916903646		[learning rate: 0.0036555]
	Learning Rate: 0.0036555
	LOSS [training: 1.113823916903646 | validation: 1.5314591475551178]
	TIME [epoch: 9.55 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2637017417609024		[learning rate: 0.0036422]
	Learning Rate: 0.00364224
	LOSS [training: 1.2637017417609024 | validation: 1.4563784927154375]
	TIME [epoch: 9.53 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.18596140607844		[learning rate: 0.003629]
	Learning Rate: 0.00362902
	LOSS [training: 1.18596140607844 | validation: 1.5454917238051196]
	TIME [epoch: 9.52 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3003492963505685		[learning rate: 0.0036159]
	Learning Rate: 0.00361585
	LOSS [training: 1.3003492963505685 | validation: 1.773019039347285]
	TIME [epoch: 9.55 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.214371079756426		[learning rate: 0.0036027]
	Learning Rate: 0.00360273
	LOSS [training: 1.214371079756426 | validation: 1.6287021725005864]
	TIME [epoch: 9.52 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.141605814823492		[learning rate: 0.0035897]
	Learning Rate: 0.00358965
	LOSS [training: 1.141605814823492 | validation: 1.5684771797320372]
	TIME [epoch: 9.53 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1259545924238188		[learning rate: 0.0035766]
	Learning Rate: 0.00357663
	LOSS [training: 1.1259545924238188 | validation: 1.4829413833161278]
	TIME [epoch: 9.53 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4433086991715587		[learning rate: 0.0035636]
	Learning Rate: 0.00356365
	LOSS [training: 1.4433086991715587 | validation: 1.3800392162787052]
	TIME [epoch: 9.54 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9818270706215035		[learning rate: 0.0035507]
	Learning Rate: 0.00355072
	LOSS [training: 0.9818270706215035 | validation: 1.6232825701903466]
	TIME [epoch: 9.52 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.166044482540613		[learning rate: 0.0035378]
	Learning Rate: 0.00353783
	LOSS [training: 1.166044482540613 | validation: 1.7183360219295747]
	TIME [epoch: 9.52 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.077247551155343		[learning rate: 0.003525]
	Learning Rate: 0.00352499
	LOSS [training: 1.077247551155343 | validation: 1.8904635015951332]
	TIME [epoch: 9.54 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2788372225206532		[learning rate: 0.0035122]
	Learning Rate: 0.0035122
	LOSS [training: 1.2788372225206532 | validation: 1.5595808948592873]
	TIME [epoch: 9.53 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2189617222836886		[learning rate: 0.0034995]
	Learning Rate: 0.00349945
	LOSS [training: 1.2189617222836886 | validation: 1.462410675230422]
	TIME [epoch: 9.52 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3016677278007265		[learning rate: 0.0034868]
	Learning Rate: 0.00348675
	LOSS [training: 1.3016677278007265 | validation: 1.7215987726557287]
	TIME [epoch: 9.51 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1502769148807424		[learning rate: 0.0034741]
	Learning Rate: 0.0034741
	LOSS [training: 1.1502769148807424 | validation: 1.4763067977369269]
	TIME [epoch: 9.54 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1238262849049936		[learning rate: 0.0034615]
	Learning Rate: 0.00346149
	LOSS [training: 1.1238262849049936 | validation: 1.6180367436076706]
	TIME [epoch: 9.51 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3134681899003993		[learning rate: 0.0034489]
	Learning Rate: 0.00344893
	LOSS [training: 1.3134681899003993 | validation: 1.6187959703992107]
	TIME [epoch: 9.52 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0371375300713725		[learning rate: 0.0034364]
	Learning Rate: 0.00343641
	LOSS [training: 1.0371375300713725 | validation: 1.593623829881031]
	TIME [epoch: 9.53 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1295080822837393		[learning rate: 0.0034239]
	Learning Rate: 0.00342394
	LOSS [training: 1.1295080822837393 | validation: 1.4294776676553136]
	TIME [epoch: 9.52 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2442800166609307		[learning rate: 0.0034115]
	Learning Rate: 0.00341152
	LOSS [training: 1.2442800166609307 | validation: 1.3523474160922442]
	TIME [epoch: 9.52 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0117633223280211		[learning rate: 0.0033991]
	Learning Rate: 0.00339914
	LOSS [training: 1.0117633223280211 | validation: 1.4561449524289276]
	TIME [epoch: 9.52 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0699634367882784		[learning rate: 0.0033868]
	Learning Rate: 0.0033868
	LOSS [training: 1.0699634367882784 | validation: 1.3217998238856372]
	TIME [epoch: 9.54 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0489414592870603		[learning rate: 0.0033745]
	Learning Rate: 0.00337451
	LOSS [training: 1.0489414592870603 | validation: 1.3448750644246548]
	TIME [epoch: 9.53 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0775392106102744		[learning rate: 0.0033623]
	Learning Rate: 0.00336226
	LOSS [training: 1.0775392106102744 | validation: 1.4435147577870961]
	TIME [epoch: 9.53 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9931150186936761		[learning rate: 0.0033501]
	Learning Rate: 0.00335006
	LOSS [training: 0.9931150186936761 | validation: 1.4807880272402594]
	TIME [epoch: 9.54 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1176448678125737		[learning rate: 0.0033379]
	Learning Rate: 0.0033379
	LOSS [training: 1.1176448678125737 | validation: 1.3878986259831627]
	TIME [epoch: 9.53 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2564307107005255		[learning rate: 0.0033258]
	Learning Rate: 0.00332579
	LOSS [training: 1.2564307107005255 | validation: 1.5527669660006536]
	TIME [epoch: 9.52 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1225322952138124		[learning rate: 0.0033137]
	Learning Rate: 0.00331372
	LOSS [training: 1.1225322952138124 | validation: 1.2914956512309947]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_404.pth
	Model improved!!!
EPOCH 405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9923931294834272		[learning rate: 0.0033017]
	Learning Rate: 0.00330169
	LOSS [training: 0.9923931294834272 | validation: 1.561932281326741]
	TIME [epoch: 9.55 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.046281287305874		[learning rate: 0.0032897]
	Learning Rate: 0.00328971
	LOSS [training: 1.046281287305874 | validation: 1.5539937862876751]
	TIME [epoch: 9.52 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0106572728116991		[learning rate: 0.0032778]
	Learning Rate: 0.00327777
	LOSS [training: 1.0106572728116991 | validation: 1.500494176159744]
	TIME [epoch: 9.53 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0633794789082238		[learning rate: 0.0032659]
	Learning Rate: 0.00326588
	LOSS [training: 1.0633794789082238 | validation: 1.529014755014099]
	TIME [epoch: 9.54 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9452676899297991		[learning rate: 0.003254]
	Learning Rate: 0.00325403
	LOSS [training: 0.9452676899297991 | validation: 2.066021067454644]
	TIME [epoch: 9.52 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2314201443514605		[learning rate: 0.0032422]
	Learning Rate: 0.00324222
	LOSS [training: 1.2314201443514605 | validation: 1.3947069770686358]
	TIME [epoch: 9.52 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0067997940129392		[learning rate: 0.0032305]
	Learning Rate: 0.00323045
	LOSS [training: 1.0067997940129392 | validation: 1.4456227672517765]
	TIME [epoch: 9.53 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9758912795179772		[learning rate: 0.0032187]
	Learning Rate: 0.00321873
	LOSS [training: 0.9758912795179772 | validation: 1.5882283560391137]
	TIME [epoch: 9.53 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2961197959548518		[learning rate: 0.003207]
	Learning Rate: 0.00320705
	LOSS [training: 1.2961197959548518 | validation: 1.6770404548801567]
	TIME [epoch: 9.52 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0388592576287508		[learning rate: 0.0031954]
	Learning Rate: 0.00319541
	LOSS [training: 1.0388592576287508 | validation: 1.639703533687046]
	TIME [epoch: 9.53 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0825131896700788		[learning rate: 0.0031838]
	Learning Rate: 0.00318381
	LOSS [training: 1.0825131896700788 | validation: 1.547556240810482]
	TIME [epoch: 9.54 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9766785755123696		[learning rate: 0.0031723]
	Learning Rate: 0.00317226
	LOSS [training: 0.9766785755123696 | validation: 1.402551393275337]
	TIME [epoch: 9.52 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0435780951838232		[learning rate: 0.0031607]
	Learning Rate: 0.00316075
	LOSS [training: 1.0435780951838232 | validation: 1.4339362454640026]
	TIME [epoch: 9.53 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9955366147863984		[learning rate: 0.0031493]
	Learning Rate: 0.00314927
	LOSS [training: 0.9955366147863984 | validation: 1.4530466801498683]
	TIME [epoch: 9.53 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1095192102351759		[learning rate: 0.0031378]
	Learning Rate: 0.00313785
	LOSS [training: 1.1095192102351759 | validation: 1.5190101233393676]
	TIME [epoch: 9.54 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0128162555320108		[learning rate: 0.0031265]
	Learning Rate: 0.00312646
	LOSS [training: 1.0128162555320108 | validation: 1.4658629543025894]
	TIME [epoch: 9.54 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9914251047713665		[learning rate: 0.0031151]
	Learning Rate: 0.00311511
	LOSS [training: 0.9914251047713665 | validation: 1.4799850790923506]
	TIME [epoch: 9.54 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0010060717841431		[learning rate: 0.0031038]
	Learning Rate: 0.00310381
	LOSS [training: 1.0010060717841431 | validation: 1.5409587749795295]
	TIME [epoch: 9.55 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0110668512555463		[learning rate: 0.0030925]
	Learning Rate: 0.00309254
	LOSS [training: 1.0110668512555463 | validation: 1.3209709690882756]
	TIME [epoch: 9.51 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.036610594277182		[learning rate: 0.0030813]
	Learning Rate: 0.00308132
	LOSS [training: 1.036610594277182 | validation: 1.4979581337498358]
	TIME [epoch: 9.52 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0245517872217624		[learning rate: 0.0030701]
	Learning Rate: 0.00307014
	LOSS [training: 1.0245517872217624 | validation: 1.4963108233065436]
	TIME [epoch: 9.54 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0722657322612879		[learning rate: 0.003059]
	Learning Rate: 0.003059
	LOSS [training: 1.0722657322612879 | validation: 1.8031704945250493]
	TIME [epoch: 9.53 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.120548773735762		[learning rate: 0.0030479]
	Learning Rate: 0.0030479
	LOSS [training: 1.120548773735762 | validation: 1.7480011657010572]
	TIME [epoch: 9.53 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0543594329166832		[learning rate: 0.0030368]
	Learning Rate: 0.00303683
	LOSS [training: 1.0543594329166832 | validation: 1.395531064326798]
	TIME [epoch: 9.53 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.093641137474171		[learning rate: 0.0030258]
	Learning Rate: 0.00302581
	LOSS [training: 1.093641137474171 | validation: 1.8017058234925032]
	TIME [epoch: 9.56 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1123629045961319		[learning rate: 0.0030148]
	Learning Rate: 0.00301483
	LOSS [training: 1.1123629045961319 | validation: 1.508048441732838]
	TIME [epoch: 9.52 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1763421245987815		[learning rate: 0.0030039]
	Learning Rate: 0.00300389
	LOSS [training: 1.1763421245987815 | validation: 1.4801321922740323]
	TIME [epoch: 9.53 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.976609500658524		[learning rate: 0.002993]
	Learning Rate: 0.00299299
	LOSS [training: 0.976609500658524 | validation: 1.515491959357394]
	TIME [epoch: 9.54 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0029479540623552		[learning rate: 0.0029821]
	Learning Rate: 0.00298213
	LOSS [training: 1.0029479540623552 | validation: 1.3303216130136315]
	TIME [epoch: 9.54 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8923425835630482		[learning rate: 0.0029713]
	Learning Rate: 0.00297131
	LOSS [training: 0.8923425835630482 | validation: 1.383278007296903]
	TIME [epoch: 9.52 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9910390833734555		[learning rate: 0.0029605]
	Learning Rate: 0.00296052
	LOSS [training: 0.9910390833734555 | validation: 1.4319176330901229]
	TIME [epoch: 9.53 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0001468918830014		[learning rate: 0.0029498]
	Learning Rate: 0.00294978
	LOSS [training: 1.0001468918830014 | validation: 1.4014296893171598]
	TIME [epoch: 9.55 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0492225873360612		[learning rate: 0.0029391]
	Learning Rate: 0.00293907
	LOSS [training: 1.0492225873360612 | validation: 1.5206076260159478]
	TIME [epoch: 9.54 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0518676844403285		[learning rate: 0.0029284]
	Learning Rate: 0.00292841
	LOSS [training: 1.0518676844403285 | validation: 1.4596470867937488]
	TIME [epoch: 9.53 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.01526465550046		[learning rate: 0.0029178]
	Learning Rate: 0.00291778
	LOSS [training: 1.01526465550046 | validation: 1.4846059538163077]
	TIME [epoch: 9.54 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9675735748817635		[learning rate: 0.0029072]
	Learning Rate: 0.00290719
	LOSS [training: 0.9675735748817635 | validation: 1.7780447514760047]
	TIME [epoch: 9.53 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.141470828996314		[learning rate: 0.0028966]
	Learning Rate: 0.00289664
	LOSS [training: 1.141470828996314 | validation: 1.405090598042416]
	TIME [epoch: 9.53 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9420674314420252		[learning rate: 0.0028861]
	Learning Rate: 0.00288613
	LOSS [training: 0.9420674314420252 | validation: 1.3747084334514748]
	TIME [epoch: 9.52 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3860471678023276		[learning rate: 0.0028757]
	Learning Rate: 0.00287566
	LOSS [training: 1.3860471678023276 | validation: 1.4618482347289687]
	TIME [epoch: 9.55 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0593714068136504		[learning rate: 0.0028652]
	Learning Rate: 0.00286522
	LOSS [training: 1.0593714068136504 | validation: 1.708478601384483]
	TIME [epoch: 9.53 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1177319337478853		[learning rate: 0.0028548]
	Learning Rate: 0.00285482
	LOSS [training: 1.1177319337478853 | validation: 5.015270634542586]
	TIME [epoch: 9.53 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9646483780055484		[learning rate: 0.0028445]
	Learning Rate: 0.00284446
	LOSS [training: 1.9646483780055484 | validation: 1.4023069504024652]
	TIME [epoch: 9.55 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0648749713733614		[learning rate: 0.0028341]
	Learning Rate: 0.00283414
	LOSS [training: 1.0648749713733614 | validation: 1.3954391352468014]
	TIME [epoch: 9.54 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7860310013000995		[learning rate: 0.0028239]
	Learning Rate: 0.00282385
	LOSS [training: 1.7860310013000995 | validation: 1.279906971285191]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_448.pth
	Model improved!!!
EPOCH 449/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2166961427916596		[learning rate: 0.0028136]
	Learning Rate: 0.00281361
	LOSS [training: 1.2166961427916596 | validation: 1.4223918846840105]
	TIME [epoch: 9.52 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9309133183154181		[learning rate: 0.0028034]
	Learning Rate: 0.00280339
	LOSS [training: 0.9309133183154181 | validation: 1.3198072532939233]
	TIME [epoch: 9.54 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9049157413725787		[learning rate: 0.0027932]
	Learning Rate: 0.00279322
	LOSS [training: 0.9049157413725787 | validation: 1.3762022739611763]
	TIME [epoch: 9.84 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9851147635332872		[learning rate: 0.0027831]
	Learning Rate: 0.00278308
	LOSS [training: 0.9851147635332872 | validation: 1.2309522999787752]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_452.pth
	Model improved!!!
EPOCH 453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9563315273718258		[learning rate: 0.002773]
	Learning Rate: 0.00277298
	LOSS [training: 0.9563315273718258 | validation: 1.2886923341304215]
	TIME [epoch: 9.56 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1471439074862262		[learning rate: 0.0027629]
	Learning Rate: 0.00276292
	LOSS [training: 1.1471439074862262 | validation: 1.6562892878744722]
	TIME [epoch: 9.54 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0409083613890586		[learning rate: 0.0027529]
	Learning Rate: 0.00275289
	LOSS [training: 1.0409083613890586 | validation: 1.42633345045458]
	TIME [epoch: 9.54 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.90544195595917		[learning rate: 0.0027429]
	Learning Rate: 0.0027429
	LOSS [training: 0.90544195595917 | validation: 1.6165047909252146]
	TIME [epoch: 9.55 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1274205915545044		[learning rate: 0.0027329]
	Learning Rate: 0.00273295
	LOSS [training: 1.1274205915545044 | validation: 1.566129730636747]
	TIME [epoch: 9.56 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2140918234327398		[learning rate: 0.002723]
	Learning Rate: 0.00272303
	LOSS [training: 1.2140918234327398 | validation: 1.512740087589375]
	TIME [epoch: 9.54 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9156325489954108		[learning rate: 0.0027131]
	Learning Rate: 0.00271315
	LOSS [training: 0.9156325489954108 | validation: 1.6861392652900589]
	TIME [epoch: 9.54 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.021055394748745		[learning rate: 0.0027033]
	Learning Rate: 0.0027033
	LOSS [training: 1.021055394748745 | validation: 1.33359560245706]
	TIME [epoch: 9.56 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9315557688598191		[learning rate: 0.0026935]
	Learning Rate: 0.00269349
	LOSS [training: 0.9315557688598191 | validation: 1.538888331346381]
	TIME [epoch: 9.54 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4732304308384858		[learning rate: 0.0026837]
	Learning Rate: 0.00268372
	LOSS [training: 1.4732304308384858 | validation: 1.3466072422278246]
	TIME [epoch: 9.54 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9203696881044097		[learning rate: 0.002674]
	Learning Rate: 0.00267398
	LOSS [training: 0.9203696881044097 | validation: 1.3771403462158651]
	TIME [epoch: 9.55 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9457809511589866		[learning rate: 0.0026643]
	Learning Rate: 0.00266427
	LOSS [training: 0.9457809511589866 | validation: 3.392063568803002]
	TIME [epoch: 9.55 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.663823511897207		[learning rate: 0.0026546]
	Learning Rate: 0.00265461
	LOSS [training: 1.663823511897207 | validation: 1.4358441087218052]
	TIME [epoch: 9.55 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0117069758866832		[learning rate: 0.002645]
	Learning Rate: 0.00264497
	LOSS [training: 1.0117069758866832 | validation: 1.4899497573066702]
	TIME [epoch: 9.54 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0017299226940568		[learning rate: 0.0026354]
	Learning Rate: 0.00263537
	LOSS [training: 1.0017299226940568 | validation: 1.3564858930910169]
	TIME [epoch: 9.56 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9202525420702494		[learning rate: 0.0026258]
	Learning Rate: 0.00262581
	LOSS [training: 0.9202525420702494 | validation: 1.5080052317404398]
	TIME [epoch: 9.54 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8618534425360975		[learning rate: 0.0026163]
	Learning Rate: 0.00261628
	LOSS [training: 0.8618534425360975 | validation: 1.4735732222267817]
	TIME [epoch: 9.54 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9048565416199296		[learning rate: 0.0026068]
	Learning Rate: 0.00260679
	LOSS [training: 0.9048565416199296 | validation: 1.2685134531325704]
	TIME [epoch: 9.56 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9832588019414811		[learning rate: 0.0025973]
	Learning Rate: 0.00259733
	LOSS [training: 0.9832588019414811 | validation: 1.632171548800198]
	TIME [epoch: 9.55 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9875207063380925		[learning rate: 0.0025879]
	Learning Rate: 0.0025879
	LOSS [training: 0.9875207063380925 | validation: 1.9652956798220669]
	TIME [epoch: 9.54 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0397532572567463		[learning rate: 0.0025785]
	Learning Rate: 0.00257851
	LOSS [training: 1.0397532572567463 | validation: 1.4409728822324683]
	TIME [epoch: 9.54 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9665058026279981		[learning rate: 0.0025691]
	Learning Rate: 0.00256915
	LOSS [training: 0.9665058026279981 | validation: 1.3514895959686806]
	TIME [epoch: 9.56 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8754816849504664		[learning rate: 0.0025598]
	Learning Rate: 0.00255983
	LOSS [training: 0.8754816849504664 | validation: 1.6394856120415326]
	TIME [epoch: 9.54 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9755301292739105		[learning rate: 0.0025505]
	Learning Rate: 0.00255054
	LOSS [training: 0.9755301292739105 | validation: 1.4016653386481717]
	TIME [epoch: 9.53 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.003448198401226		[learning rate: 0.0025413]
	Learning Rate: 0.00254128
	LOSS [training: 1.003448198401226 | validation: 1.6054583253694574]
	TIME [epoch: 9.56 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9433613439119336		[learning rate: 0.0025321]
	Learning Rate: 0.00253206
	LOSS [training: 0.9433613439119336 | validation: 1.303852179535056]
	TIME [epoch: 9.54 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9477852415775466		[learning rate: 0.0025229]
	Learning Rate: 0.00252287
	LOSS [training: 0.9477852415775466 | validation: 1.3416978592076305]
	TIME [epoch: 9.54 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9483452444531549		[learning rate: 0.0025137]
	Learning Rate: 0.00251371
	LOSS [training: 0.9483452444531549 | validation: 1.4686172561142434]
	TIME [epoch: 9.54 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9123025337500416		[learning rate: 0.0025046]
	Learning Rate: 0.00250459
	LOSS [training: 0.9123025337500416 | validation: 1.238652913434693]
	TIME [epoch: 9.56 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9239796083888445		[learning rate: 0.0024955]
	Learning Rate: 0.0024955
	LOSS [training: 0.9239796083888445 | validation: 1.290839269451601]
	TIME [epoch: 9.55 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.929581550846545		[learning rate: 0.0024864]
	Learning Rate: 0.00248645
	LOSS [training: 0.929581550846545 | validation: 1.314506942938413]
	TIME [epoch: 9.54 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8597612534904077		[learning rate: 0.0024774]
	Learning Rate: 0.00247742
	LOSS [training: 0.8597612534904077 | validation: 1.4478164111794092]
	TIME [epoch: 9.56 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0113107527711727		[learning rate: 0.0024684]
	Learning Rate: 0.00246843
	LOSS [training: 1.0113107527711727 | validation: 1.6129898501969107]
	TIME [epoch: 9.54 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9067346340377609		[learning rate: 0.0024595]
	Learning Rate: 0.00245947
	LOSS [training: 0.9067346340377609 | validation: 1.804223375233258]
	TIME [epoch: 9.54 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0252498323225772		[learning rate: 0.0024505]
	Learning Rate: 0.00245055
	LOSS [training: 1.0252498323225772 | validation: 1.3103067089707074]
	TIME [epoch: 9.53 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9007182747934749		[learning rate: 0.0024417]
	Learning Rate: 0.00244165
	LOSS [training: 0.9007182747934749 | validation: 1.275580347939945]
	TIME [epoch: 9.56 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.857502998588453		[learning rate: 0.0024328]
	Learning Rate: 0.00243279
	LOSS [training: 0.857502998588453 | validation: 1.427144835159587]
	TIME [epoch: 9.54 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9568656190286191		[learning rate: 0.002424]
	Learning Rate: 0.00242396
	LOSS [training: 0.9568656190286191 | validation: 1.4631355361594656]
	TIME [epoch: 9.54 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9269631535672497		[learning rate: 0.0024152]
	Learning Rate: 0.00241517
	LOSS [training: 0.9269631535672497 | validation: 1.5332874748533534]
	TIME [epoch: 9.56 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9530417485988044		[learning rate: 0.0024064]
	Learning Rate: 0.0024064
	LOSS [training: 0.9530417485988044 | validation: 1.5472224909181547]
	TIME [epoch: 9.54 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9153830862417888		[learning rate: 0.0023977]
	Learning Rate: 0.00239767
	LOSS [training: 0.9153830862417888 | validation: 1.5770079033666569]
	TIME [epoch: 9.53 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0580146224429314		[learning rate: 0.002389]
	Learning Rate: 0.00238897
	LOSS [training: 1.0580146224429314 | validation: 1.4383448953702236]
	TIME [epoch: 9.54 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9250096725507693		[learning rate: 0.0023803]
	Learning Rate: 0.0023803
	LOSS [training: 0.9250096725507693 | validation: 1.4040134199124168]
	TIME [epoch: 9.56 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9495157846382284		[learning rate: 0.0023717]
	Learning Rate: 0.00237166
	LOSS [training: 0.9495157846382284 | validation: 1.3289942536262844]
	TIME [epoch: 9.54 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9379202621484127		[learning rate: 0.0023631]
	Learning Rate: 0.00236305
	LOSS [training: 0.9379202621484127 | validation: 1.4195150866500046]
	TIME [epoch: 9.53 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9220497261210916		[learning rate: 0.0023545]
	Learning Rate: 0.00235448
	LOSS [training: 0.9220497261210916 | validation: 1.4197237483622285]
	TIME [epoch: 9.56 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9970615453845552		[learning rate: 0.0023459]
	Learning Rate: 0.00234593
	LOSS [training: 0.9970615453845552 | validation: 1.448663646946437]
	TIME [epoch: 9.54 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0054762603864371		[learning rate: 0.0023374]
	Learning Rate: 0.00233742
	LOSS [training: 1.0054762603864371 | validation: 1.5403503732005246]
	TIME [epoch: 9.54 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.015440023780655		[learning rate: 0.0023289]
	Learning Rate: 0.00232894
	LOSS [training: 1.015440023780655 | validation: 1.5212936620144277]
	TIME [epoch: 9.54 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9367471542863111		[learning rate: 0.0023205]
	Learning Rate: 0.00232049
	LOSS [training: 0.9367471542863111 | validation: 1.3554037216758554]
	TIME [epoch: 9.55 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.053549566510126		[learning rate: 0.0023121]
	Learning Rate: 0.00231206
	LOSS [training: 1.053549566510126 | validation: 1.3828506812089938]
	TIME [epoch: 9.54 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9240912799532989		[learning rate: 0.0023037]
	Learning Rate: 0.00230367
	LOSS [training: 0.9240912799532989 | validation: 1.3235931744004494]
	TIME [epoch: 9.54 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.918762438589319		[learning rate: 0.0022953]
	Learning Rate: 0.00229531
	LOSS [training: 0.918762438589319 | validation: 1.612174681989464]
	TIME [epoch: 9.55 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9769815022021803		[learning rate: 0.002287]
	Learning Rate: 0.00228698
	LOSS [training: 0.9769815022021803 | validation: 1.4778763114370868]
	TIME [epoch: 9.54 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9217377085745827		[learning rate: 0.0022787]
	Learning Rate: 0.00227868
	LOSS [training: 0.9217377085745827 | validation: 1.2685723610221737]
	TIME [epoch: 9.54 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9147824402925192		[learning rate: 0.0022704]
	Learning Rate: 0.00227042
	LOSS [training: 0.9147824402925192 | validation: 1.2950824883084624]
	TIME [epoch: 9.55 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8920122177052991		[learning rate: 0.0022622]
	Learning Rate: 0.00226218
	LOSS [training: 0.8920122177052991 | validation: 1.4461066568594911]
	TIME [epoch: 9.55 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.067503273352155		[learning rate: 0.002254]
	Learning Rate: 0.00225397
	LOSS [training: 1.067503273352155 | validation: 1.3306752311670118]
	TIME [epoch: 9.54 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9520660658248208		[learning rate: 0.0022458]
	Learning Rate: 0.00224579
	LOSS [training: 0.9520660658248208 | validation: 1.3102918203223568]
	TIME [epoch: 9.53 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8593428110666725		[learning rate: 0.0022376]
	Learning Rate: 0.00223764
	LOSS [training: 0.8593428110666725 | validation: 1.295208601814377]
	TIME [epoch: 9.55 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8424623745484865		[learning rate: 0.0022295]
	Learning Rate: 0.00222952
	LOSS [training: 0.8424623745484865 | validation: 1.4741523873543616]
	TIME [epoch: 9.54 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9352182376014951		[learning rate: 0.0022214]
	Learning Rate: 0.00222142
	LOSS [training: 0.9352182376014951 | validation: 1.3375732511359733]
	TIME [epoch: 9.53 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8608544305813475		[learning rate: 0.0022134]
	Learning Rate: 0.00221336
	LOSS [training: 0.8608544305813475 | validation: 1.1506380698636058]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_515.pth
	Model improved!!!
EPOCH 516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8628773484535349		[learning rate: 0.0022053]
	Learning Rate: 0.00220533
	LOSS [training: 0.8628773484535349 | validation: 1.2934436101914377]
	TIME [epoch: 9.55 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.887644680626661		[learning rate: 0.0021973]
	Learning Rate: 0.00219733
	LOSS [training: 0.887644680626661 | validation: 1.3512663818052313]
	TIME [epoch: 9.53 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9469755276736891		[learning rate: 0.0021894]
	Learning Rate: 0.00218935
	LOSS [training: 0.9469755276736891 | validation: 1.3153239686579912]
	TIME [epoch: 9.53 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9323837619554045		[learning rate: 0.0021814]
	Learning Rate: 0.00218141
	LOSS [training: 0.9323837619554045 | validation: 1.3193758223351824]
	TIME [epoch: 9.56 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8833992960159689		[learning rate: 0.0021735]
	Learning Rate: 0.00217349
	LOSS [training: 0.8833992960159689 | validation: 1.5529008947260285]
	TIME [epoch: 9.54 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9074487994138876		[learning rate: 0.0021656]
	Learning Rate: 0.0021656
	LOSS [training: 0.9074487994138876 | validation: 1.5524792883460632]
	TIME [epoch: 9.54 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.971002372963423		[learning rate: 0.0021577]
	Learning Rate: 0.00215774
	LOSS [training: 0.971002372963423 | validation: 1.2369413554755744]
	TIME [epoch: 9.55 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8340979038489614		[learning rate: 0.0021499]
	Learning Rate: 0.00214991
	LOSS [training: 0.8340979038489614 | validation: 1.1927283928170358]
	TIME [epoch: 9.54 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.883858620641562		[learning rate: 0.0021421]
	Learning Rate: 0.00214211
	LOSS [training: 0.883858620641562 | validation: 1.2232898633819698]
	TIME [epoch: 9.53 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8695797889900658		[learning rate: 0.0021343]
	Learning Rate: 0.00213434
	LOSS [training: 0.8695797889900658 | validation: 1.3383107422357796]
	TIME [epoch: 9.53 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8634201774658539		[learning rate: 0.0021266]
	Learning Rate: 0.00212659
	LOSS [training: 0.8634201774658539 | validation: 1.2839544105142648]
	TIME [epoch: 9.56 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8552332673485508		[learning rate: 0.0021189]
	Learning Rate: 0.00211887
	LOSS [training: 0.8552332673485508 | validation: 1.3734296409321038]
	TIME [epoch: 9.53 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8971286225678394		[learning rate: 0.0021112]
	Learning Rate: 0.00211119
	LOSS [training: 0.8971286225678394 | validation: 1.3667481888989388]
	TIME [epoch: 9.53 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8492948733323841		[learning rate: 0.0021035]
	Learning Rate: 0.00210352
	LOSS [training: 0.8492948733323841 | validation: 1.303571337434978]
	TIME [epoch: 9.55 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9710984050475238		[learning rate: 0.0020959]
	Learning Rate: 0.00209589
	LOSS [training: 0.9710984050475238 | validation: 1.2410312968347088]
	TIME [epoch: 9.54 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8356861116805492		[learning rate: 0.0020883]
	Learning Rate: 0.00208828
	LOSS [training: 0.8356861116805492 | validation: 1.2939825404344851]
	TIME [epoch: 9.53 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8085788986448451		[learning rate: 0.0020807]
	Learning Rate: 0.00208071
	LOSS [training: 0.8085788986448451 | validation: 1.173827634895315]
	TIME [epoch: 9.53 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8459543328548536		[learning rate: 0.0020732]
	Learning Rate: 0.00207315
	LOSS [training: 0.8459543328548536 | validation: 1.2949043516903023]
	TIME [epoch: 9.56 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8401913067196232		[learning rate: 0.0020656]
	Learning Rate: 0.00206563
	LOSS [training: 0.8401913067196232 | validation: 1.35599804976905]
	TIME [epoch: 9.55 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.939886180135707		[learning rate: 0.0020581]
	Learning Rate: 0.00205813
	LOSS [training: 0.939886180135707 | validation: 1.3117971008972655]
	TIME [epoch: 9.55 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8990846155993211		[learning rate: 0.0020507]
	Learning Rate: 0.00205067
	LOSS [training: 0.8990846155993211 | validation: 1.2950312067953187]
	TIME [epoch: 9.56 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9694100030668533		[learning rate: 0.0020432]
	Learning Rate: 0.00204322
	LOSS [training: 0.9694100030668533 | validation: 1.228592037980299]
	TIME [epoch: 9.55 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8456461980108539		[learning rate: 0.0020358]
	Learning Rate: 0.00203581
	LOSS [training: 0.8456461980108539 | validation: 1.20128527952526]
	TIME [epoch: 9.54 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9144599304796566		[learning rate: 0.0020284]
	Learning Rate: 0.00202842
	LOSS [training: 0.9144599304796566 | validation: 1.5397964692160742]
	TIME [epoch: 9.55 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9161954529817997		[learning rate: 0.0020211]
	Learning Rate: 0.00202106
	LOSS [training: 0.9161954529817997 | validation: 1.4754528193309069]
	TIME [epoch: 9.57 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9052638891186688		[learning rate: 0.0020137]
	Learning Rate: 0.00201372
	LOSS [training: 0.9052638891186688 | validation: 1.649708169076827]
	TIME [epoch: 9.54 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9392099854486572		[learning rate: 0.0020064]
	Learning Rate: 0.00200642
	LOSS [training: 0.9392099854486572 | validation: 1.1844320543906646]
	TIME [epoch: 9.54 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8307133136725213		[learning rate: 0.0019991]
	Learning Rate: 0.00199913
	LOSS [training: 0.8307133136725213 | validation: 1.2799227208017308]
	TIME [epoch: 9.56 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8549749913537923		[learning rate: 0.0019919]
	Learning Rate: 0.00199188
	LOSS [training: 0.8549749913537923 | validation: 1.3575708527324541]
	TIME [epoch: 9.55 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9017034291381048		[learning rate: 0.0019847]
	Learning Rate: 0.00198465
	LOSS [training: 0.9017034291381048 | validation: 1.2466316560200823]
	TIME [epoch: 9.55 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8611434866615089		[learning rate: 0.0019774]
	Learning Rate: 0.00197745
	LOSS [training: 0.8611434866615089 | validation: 1.3253670590746225]
	TIME [epoch: 9.55 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7831175707086582		[learning rate: 0.0019703]
	Learning Rate: 0.00197027
	LOSS [training: 0.7831175707086582 | validation: 1.2861908533465922]
	TIME [epoch: 9.56 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8294925991099754		[learning rate: 0.0019631]
	Learning Rate: 0.00196312
	LOSS [training: 0.8294925991099754 | validation: 1.4538396057435716]
	TIME [epoch: 9.54 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9131760566412856		[learning rate: 0.001956]
	Learning Rate: 0.001956
	LOSS [training: 0.9131760566412856 | validation: 1.1551788424871117]
	TIME [epoch: 9.54 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8028860932731801		[learning rate: 0.0019489]
	Learning Rate: 0.0019489
	LOSS [training: 0.8028860932731801 | validation: 1.500954330767963]
	TIME [epoch: 9.57 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.932394881305321		[learning rate: 0.0019418]
	Learning Rate: 0.00194183
	LOSS [training: 0.932394881305321 | validation: 1.2121925276847927]
	TIME [epoch: 9.56 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8348640687059843		[learning rate: 0.0019348]
	Learning Rate: 0.00193478
	LOSS [training: 0.8348640687059843 | validation: 1.3511467929410412]
	TIME [epoch: 9.55 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8468456306776566		[learning rate: 0.0019278]
	Learning Rate: 0.00192776
	LOSS [training: 0.8468456306776566 | validation: 1.2572524973987795]
	TIME [epoch: 9.55 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.908867125316146		[learning rate: 0.0019208]
	Learning Rate: 0.00192076
	LOSS [training: 0.908867125316146 | validation: 1.3548347880056377]
	TIME [epoch: 9.56 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.795922925153959		[learning rate: 0.0019138]
	Learning Rate: 0.00191379
	LOSS [training: 0.795922925153959 | validation: 1.3640616831100294]
	TIME [epoch: 9.55 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8490663950239931		[learning rate: 0.0019068]
	Learning Rate: 0.00190685
	LOSS [training: 0.8490663950239931 | validation: 1.2044779269051955]
	TIME [epoch: 9.54 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8091817705362774		[learning rate: 0.0018999]
	Learning Rate: 0.00189993
	LOSS [training: 0.8091817705362774 | validation: 1.2427844472693914]
	TIME [epoch: 9.57 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8596421178435406		[learning rate: 0.001893]
	Learning Rate: 0.00189303
	LOSS [training: 0.8596421178435406 | validation: 1.2444170114327782]
	TIME [epoch: 9.54 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8314081320310922		[learning rate: 0.0018862]
	Learning Rate: 0.00188616
	LOSS [training: 0.8314081320310922 | validation: 1.1728974494112288]
	TIME [epoch: 9.54 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8496246362081697		[learning rate: 0.0018793]
	Learning Rate: 0.00187932
	LOSS [training: 0.8496246362081697 | validation: 1.3206641450303847]
	TIME [epoch: 9.55 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8689133708965668		[learning rate: 0.0018725]
	Learning Rate: 0.0018725
	LOSS [training: 0.8689133708965668 | validation: 1.180962881472872]
	TIME [epoch: 9.56 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8127193580193263		[learning rate: 0.0018657]
	Learning Rate: 0.0018657
	LOSS [training: 0.8127193580193263 | validation: 1.2648654930631957]
	TIME [epoch: 9.55 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8613239773895323		[learning rate: 0.0018589]
	Learning Rate: 0.00185893
	LOSS [training: 0.8613239773895323 | validation: 1.1648047955935303]
	TIME [epoch: 9.54 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7988599875646353		[learning rate: 0.0018522]
	Learning Rate: 0.00185218
	LOSS [training: 0.7988599875646353 | validation: 1.24021714187113]
	TIME [epoch: 9.57 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1309080659280286		[learning rate: 0.0018455]
	Learning Rate: 0.00184546
	LOSS [training: 1.1309080659280286 | validation: 1.32194140699733]
	TIME [epoch: 9.54 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8058285559818892		[learning rate: 0.0018388]
	Learning Rate: 0.00183877
	LOSS [training: 0.8058285559818892 | validation: 1.2980965660909944]
	TIME [epoch: 9.53 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8714143018112935		[learning rate: 0.0018321]
	Learning Rate: 0.00183209
	LOSS [training: 0.8714143018112935 | validation: 1.3627423792873254]
	TIME [epoch: 9.55 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8551384274940477		[learning rate: 0.0018254]
	Learning Rate: 0.00182544
	LOSS [training: 0.8551384274940477 | validation: 1.1081643343934875]
	TIME [epoch: 9.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_568.pth
	Model improved!!!
EPOCH 569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8603522391993611		[learning rate: 0.0018188]
	Learning Rate: 0.00181882
	LOSS [training: 0.8603522391993611 | validation: 1.494317464540715]
	TIME [epoch: 9.53 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.847618526898839		[learning rate: 0.0018122]
	Learning Rate: 0.00181222
	LOSS [training: 0.847618526898839 | validation: 1.1739712382151235]
	TIME [epoch: 9.53 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8208956095029689		[learning rate: 0.0018056]
	Learning Rate: 0.00180564
	LOSS [training: 0.8208956095029689 | validation: 1.193166959053145]
	TIME [epoch: 9.55 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7553939572060244		[learning rate: 0.0017991]
	Learning Rate: 0.00179909
	LOSS [training: 0.7553939572060244 | validation: 1.51435176487904]
	TIME [epoch: 9.53 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8703569161147223		[learning rate: 0.0017926]
	Learning Rate: 0.00179256
	LOSS [training: 0.8703569161147223 | validation: 1.1876667749208334]
	TIME [epoch: 9.53 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8053658088198177		[learning rate: 0.0017861]
	Learning Rate: 0.00178605
	LOSS [training: 0.8053658088198177 | validation: 1.3027562551107605]
	TIME [epoch: 9.54 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8016379103966462		[learning rate: 0.0017796]
	Learning Rate: 0.00177957
	LOSS [training: 0.8016379103966462 | validation: 1.2510675469365837]
	TIME [epoch: 9.54 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8184754332099011		[learning rate: 0.0017731]
	Learning Rate: 0.00177311
	LOSS [training: 0.8184754332099011 | validation: 1.0762862063614385]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_576.pth
	Model improved!!!
EPOCH 577/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0020389763658137		[learning rate: 0.0017667]
	Learning Rate: 0.00176668
	LOSS [training: 1.0020389763658137 | validation: 1.6972228582003481]
	TIME [epoch: 9.52 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0135698716644863		[learning rate: 0.0017603]
	Learning Rate: 0.00176027
	LOSS [training: 1.0135698716644863 | validation: 1.2241075558977093]
	TIME [epoch: 9.54 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7961762428106042		[learning rate: 0.0017539]
	Learning Rate: 0.00175388
	LOSS [training: 0.7961762428106042 | validation: 1.0762126378935164]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_579.pth
	Model improved!!!
EPOCH 580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8367300740508613		[learning rate: 0.0017475]
	Learning Rate: 0.00174752
	LOSS [training: 0.8367300740508613 | validation: 1.1026262331232746]
	TIME [epoch: 9.53 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8492440424260757		[learning rate: 0.0017412]
	Learning Rate: 0.00174117
	LOSS [training: 0.8492440424260757 | validation: 1.1951772095645203]
	TIME [epoch: 9.55 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8088397482890362		[learning rate: 0.0017349]
	Learning Rate: 0.00173486
	LOSS [training: 0.8088397482890362 | validation: 1.3156999691651283]
	TIME [epoch: 9.54 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8771333394813128		[learning rate: 0.0017286]
	Learning Rate: 0.00172856
	LOSS [training: 0.8771333394813128 | validation: 1.0657093969142581]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_583.pth
	Model improved!!!
EPOCH 584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7840839508332362		[learning rate: 0.0017223]
	Learning Rate: 0.00172229
	LOSS [training: 0.7840839508332362 | validation: 1.032302108989428]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_584.pth
	Model improved!!!
EPOCH 585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7989462883179196		[learning rate: 0.001716]
	Learning Rate: 0.00171604
	LOSS [training: 0.7989462883179196 | validation: 1.0150687640111444]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_585.pth
	Model improved!!!
EPOCH 586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7872629393657695		[learning rate: 0.0017098]
	Learning Rate: 0.00170981
	LOSS [training: 0.7872629393657695 | validation: 0.9794196197317251]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_586.pth
	Model improved!!!
EPOCH 587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7522154085165291		[learning rate: 0.0017036]
	Learning Rate: 0.0017036
	LOSS [training: 0.7522154085165291 | validation: 0.979336666882175]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_587.pth
	Model improved!!!
EPOCH 588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7466073026741463		[learning rate: 0.0016974]
	Learning Rate: 0.00169742
	LOSS [training: 0.7466073026741463 | validation: 0.9684741816039094]
	TIME [epoch: 9.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_588.pth
	Model improved!!!
EPOCH 589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8021807574473735		[learning rate: 0.0016913]
	Learning Rate: 0.00169126
	LOSS [training: 0.8021807574473735 | validation: 1.0236198790172413]
	TIME [epoch: 9.53 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7305893103706321		[learning rate: 0.0016851]
	Learning Rate: 0.00168512
	LOSS [training: 0.7305893103706321 | validation: 0.9232339897624795]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_590.pth
	Model improved!!!
EPOCH 591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7433821303251501		[learning rate: 0.001679]
	Learning Rate: 0.00167901
	LOSS [training: 0.7433821303251501 | validation: 0.9375898511247911]
	TIME [epoch: 9.56 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8059912308446154		[learning rate: 0.0016729]
	Learning Rate: 0.00167291
	LOSS [training: 0.8059912308446154 | validation: 1.0123932837688767]
	TIME [epoch: 9.55 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.757120392506596		[learning rate: 0.0016668]
	Learning Rate: 0.00166684
	LOSS [training: 0.757120392506596 | validation: 1.3207409998436317]
	TIME [epoch: 9.54 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8926833814955538		[learning rate: 0.0016608]
	Learning Rate: 0.00166079
	LOSS [training: 0.8926833814955538 | validation: 1.0674813318168859]
	TIME [epoch: 9.54 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7386835361786943		[learning rate: 0.0016548]
	Learning Rate: 0.00165477
	LOSS [training: 0.7386835361786943 | validation: 0.9533596883140095]
	TIME [epoch: 9.55 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6882806313627157		[learning rate: 0.0016488]
	Learning Rate: 0.00164876
	LOSS [training: 0.6882806313627157 | validation: 0.9956279548554736]
	TIME [epoch: 9.54 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6794300726270988		[learning rate: 0.0016428]
	Learning Rate: 0.00164278
	LOSS [training: 0.6794300726270988 | validation: 0.9884245027537404]
	TIME [epoch: 9.54 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7457220498058064		[learning rate: 0.0016368]
	Learning Rate: 0.00163682
	LOSS [training: 0.7457220498058064 | validation: 1.050398411109636]
	TIME [epoch: 9.56 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7425248677020099		[learning rate: 0.0016309]
	Learning Rate: 0.00163088
	LOSS [training: 0.7425248677020099 | validation: 0.8894663846002638]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_599.pth
	Model improved!!!
EPOCH 600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6781862061586998		[learning rate: 0.001625]
	Learning Rate: 0.00162496
	LOSS [training: 0.6781862061586998 | validation: 0.8540766667279467]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_600.pth
	Model improved!!!
EPOCH 601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7578486310486718		[learning rate: 0.0016191]
	Learning Rate: 0.00161906
	LOSS [training: 0.7578486310486718 | validation: 0.9637369385660438]
	TIME [epoch: 9.54 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6791015198486348		[learning rate: 0.0016132]
	Learning Rate: 0.00161319
	LOSS [training: 0.6791015198486348 | validation: 0.9339722135420744]
	TIME [epoch: 9.55 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7045335579229395		[learning rate: 0.0016073]
	Learning Rate: 0.00160733
	LOSS [training: 0.7045335579229395 | validation: 0.9740577638698125]
	TIME [epoch: 9.54 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7076234717113693		[learning rate: 0.0016015]
	Learning Rate: 0.0016015
	LOSS [training: 0.7076234717113693 | validation: 0.9220282450894319]
	TIME [epoch: 9.54 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7107797131745723		[learning rate: 0.0015957]
	Learning Rate: 0.00159569
	LOSS [training: 0.7107797131745723 | validation: 0.8929772905794193]
	TIME [epoch: 9.56 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6734041504533053		[learning rate: 0.0015899]
	Learning Rate: 0.00158989
	LOSS [training: 0.6734041504533053 | validation: 0.8056681573231126]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_606.pth
	Model improved!!!
EPOCH 607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6564450351534377		[learning rate: 0.0015841]
	Learning Rate: 0.00158413
	LOSS [training: 0.6564450351534377 | validation: 0.8444487434893339]
	TIME [epoch: 9.53 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6451887106138529		[learning rate: 0.0015784]
	Learning Rate: 0.00157838
	LOSS [training: 0.6451887106138529 | validation: 0.8305912314690949]
	TIME [epoch: 9.54 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6776167606969349		[learning rate: 0.0015726]
	Learning Rate: 0.00157265
	LOSS [training: 0.6776167606969349 | validation: 0.9077932848702063]
	TIME [epoch: 9.54 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6993247163064689		[learning rate: 0.0015669]
	Learning Rate: 0.00156694
	LOSS [training: 0.6993247163064689 | validation: 0.9026822981735555]
	TIME [epoch: 9.54 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6165329015155617		[learning rate: 0.0015613]
	Learning Rate: 0.00156125
	LOSS [training: 0.6165329015155617 | validation: 0.8658067229319499]
	TIME [epoch: 9.53 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6382797420051547		[learning rate: 0.0015556]
	Learning Rate: 0.00155559
	LOSS [training: 0.6382797420051547 | validation: 0.8610632209102782]
	TIME [epoch: 9.54 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6636733425322159		[learning rate: 0.0015499]
	Learning Rate: 0.00154994
	LOSS [training: 0.6636733425322159 | validation: 0.8815193075308605]
	TIME [epoch: 9.53 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.762639494853534		[learning rate: 0.0015443]
	Learning Rate: 0.00154432
	LOSS [training: 0.762639494853534 | validation: 0.9939020203980309]
	TIME [epoch: 9.53 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6885592483631138		[learning rate: 0.0015387]
	Learning Rate: 0.00153871
	LOSS [training: 0.6885592483631138 | validation: 1.0240541412498199]
	TIME [epoch: 9.54 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7136980292894841		[learning rate: 0.0015331]
	Learning Rate: 0.00153313
	LOSS [training: 0.7136980292894841 | validation: 0.935661789323265]
	TIME [epoch: 9.53 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6473296465912439		[learning rate: 0.0015276]
	Learning Rate: 0.00152757
	LOSS [training: 0.6473296465912439 | validation: 0.852477599890437]
	TIME [epoch: 9.52 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6410487878395614		[learning rate: 0.001522]
	Learning Rate: 0.00152202
	LOSS [training: 0.6410487878395614 | validation: 0.8981991106749289]
	TIME [epoch: 9.52 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7087847729470378		[learning rate: 0.0015165]
	Learning Rate: 0.0015165
	LOSS [training: 0.7087847729470378 | validation: 1.0084132987257177]
	TIME [epoch: 9.55 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6899224846342124		[learning rate: 0.001511]
	Learning Rate: 0.001511
	LOSS [training: 0.6899224846342124 | validation: 0.8909660183701251]
	TIME [epoch: 9.53 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6040487758266174		[learning rate: 0.0015055]
	Learning Rate: 0.00150551
	LOSS [training: 0.6040487758266174 | validation: 0.8841533362100091]
	TIME [epoch: 9.53 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.675763696115869		[learning rate: 0.0015]
	Learning Rate: 0.00150005
	LOSS [training: 0.675763696115869 | validation: 0.9043014690095271]
	TIME [epoch: 9.54 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6624789171823726		[learning rate: 0.0014946]
	Learning Rate: 0.0014946
	LOSS [training: 0.6624789171823726 | validation: 0.8401580253657506]
	TIME [epoch: 9.53 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6812103758149949		[learning rate: 0.0014892]
	Learning Rate: 0.00148918
	LOSS [training: 0.6812103758149949 | validation: 0.8931445483785467]
	TIME [epoch: 9.52 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6671209041760868		[learning rate: 0.0014838]
	Learning Rate: 0.00148378
	LOSS [training: 0.6671209041760868 | validation: 0.8987878087402009]
	TIME [epoch: 9.52 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7148226958913871		[learning rate: 0.0014784]
	Learning Rate: 0.00147839
	LOSS [training: 0.7148226958913871 | validation: 0.8816307585188059]
	TIME [epoch: 9.55 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7510724736365844		[learning rate: 0.001473]
	Learning Rate: 0.00147303
	LOSS [training: 0.7510724736365844 | validation: 0.9254164593325822]
	TIME [epoch: 9.53 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7532898419453545		[learning rate: 0.0014677]
	Learning Rate: 0.00146768
	LOSS [training: 0.7532898419453545 | validation: 1.007849461062858]
	TIME [epoch: 9.53 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6894421308759819		[learning rate: 0.0014624]
	Learning Rate: 0.00146235
	LOSS [training: 0.6894421308759819 | validation: 0.9339368781200452]
	TIME [epoch: 9.54 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6501624460972181		[learning rate: 0.001457]
	Learning Rate: 0.00145705
	LOSS [training: 0.6501624460972181 | validation: 0.9978270712230756]
	TIME [epoch: 9.53 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7154488150302398		[learning rate: 0.0014518]
	Learning Rate: 0.00145176
	LOSS [training: 0.7154488150302398 | validation: 0.9379738782891542]
	TIME [epoch: 9.53 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6821244598139111		[learning rate: 0.0014465]
	Learning Rate: 0.00144649
	LOSS [training: 0.6821244598139111 | validation: 0.8770121094779628]
	TIME [epoch: 9.53 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6797115836090939		[learning rate: 0.0014412]
	Learning Rate: 0.00144124
	LOSS [training: 0.6797115836090939 | validation: 0.884345944444944]
	TIME [epoch: 9.55 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6510613542435391		[learning rate: 0.001436]
	Learning Rate: 0.00143601
	LOSS [training: 0.6510613542435391 | validation: 0.8201952520618381]
	TIME [epoch: 9.53 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6483625351134854		[learning rate: 0.0014308]
	Learning Rate: 0.0014308
	LOSS [training: 0.6483625351134854 | validation: 0.9039687563061441]
	TIME [epoch: 9.52 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6805907427287364		[learning rate: 0.0014256]
	Learning Rate: 0.00142561
	LOSS [training: 0.6805907427287364 | validation: 0.8422793102339609]
	TIME [epoch: 9.54 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6700630228987855		[learning rate: 0.0014204]
	Learning Rate: 0.00142043
	LOSS [training: 0.6700630228987855 | validation: 0.9111307003371748]
	TIME [epoch: 9.53 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6379704592311735		[learning rate: 0.0014153]
	Learning Rate: 0.00141528
	LOSS [training: 0.6379704592311735 | validation: 0.9730264681732586]
	TIME [epoch: 9.53 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6556890892737834		[learning rate: 0.0014101]
	Learning Rate: 0.00141014
	LOSS [training: 0.6556890892737834 | validation: 0.9711561115355896]
	TIME [epoch: 9.53 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7203802249095229		[learning rate: 0.001405]
	Learning Rate: 0.00140503
	LOSS [training: 0.7203802249095229 | validation: 0.8857223975523116]
	TIME [epoch: 9.55 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6622346615142682		[learning rate: 0.0013999]
	Learning Rate: 0.00139993
	LOSS [training: 0.6622346615142682 | validation: 0.9500799261740064]
	TIME [epoch: 9.53 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.662837155338317		[learning rate: 0.0013948]
	Learning Rate: 0.00139485
	LOSS [training: 0.662837155338317 | validation: 0.9100204020679015]
	TIME [epoch: 9.53 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6326723425143369		[learning rate: 0.0013898]
	Learning Rate: 0.00138978
	LOSS [training: 0.6326723425143369 | validation: 0.8543997394285022]
	TIME [epoch: 9.55 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6682931287951125		[learning rate: 0.0013847]
	Learning Rate: 0.00138474
	LOSS [training: 0.6682931287951125 | validation: 0.9173279601411392]
	TIME [epoch: 9.53 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.65209731455355		[learning rate: 0.0013797]
	Learning Rate: 0.00137972
	LOSS [training: 0.65209731455355 | validation: 0.8213815605861552]
	TIME [epoch: 9.53 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.634791308579248		[learning rate: 0.0013747]
	Learning Rate: 0.00137471
	LOSS [training: 0.634791308579248 | validation: 0.8502746153133279]
	TIME [epoch: 9.53 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6450820158356465		[learning rate: 0.0013697]
	Learning Rate: 0.00136972
	LOSS [training: 0.6450820158356465 | validation: 0.8224457809261837]
	TIME [epoch: 9.54 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6213829203524349		[learning rate: 0.0013647]
	Learning Rate: 0.00136475
	LOSS [training: 0.6213829203524349 | validation: 0.9726302757250522]
	TIME [epoch: 9.53 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6939285116145573		[learning rate: 0.0013598]
	Learning Rate: 0.0013598
	LOSS [training: 0.6939285116145573 | validation: 0.9934559542274126]
	TIME [epoch: 9.52 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6304879918290934		[learning rate: 0.0013549]
	Learning Rate: 0.00135486
	LOSS [training: 0.6304879918290934 | validation: 0.8699658262010204]
	TIME [epoch: 9.54 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6605991385774009		[learning rate: 0.0013499]
	Learning Rate: 0.00134994
	LOSS [training: 0.6605991385774009 | validation: 0.8617758741080235]
	TIME [epoch: 9.53 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6216345362135304		[learning rate: 0.001345]
	Learning Rate: 0.00134505
	LOSS [training: 0.6216345362135304 | validation: 0.8255119751652518]
	TIME [epoch: 9.53 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6162733321124193		[learning rate: 0.0013402]
	Learning Rate: 0.00134016
	LOSS [training: 0.6162733321124193 | validation: 0.8326924324567401]
	TIME [epoch: 9.53 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6427606220499151		[learning rate: 0.0013353]
	Learning Rate: 0.0013353
	LOSS [training: 0.6427606220499151 | validation: 0.9261837773215182]
	TIME [epoch: 9.55 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6705541523735284		[learning rate: 0.0013305]
	Learning Rate: 0.00133045
	LOSS [training: 0.6705541523735284 | validation: 1.0321826943191097]
	TIME [epoch: 9.53 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6286544093309331		[learning rate: 0.0013256]
	Learning Rate: 0.00132563
	LOSS [training: 0.6286544093309331 | validation: 0.8355452354777271]
	TIME [epoch: 9.53 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6775283420349305		[learning rate: 0.0013208]
	Learning Rate: 0.00132082
	LOSS [training: 0.6775283420349305 | validation: 0.8577299666832421]
	TIME [epoch: 9.55 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6223405276101153		[learning rate: 0.001316]
	Learning Rate: 0.00131602
	LOSS [training: 0.6223405276101153 | validation: 0.8249804872284703]
	TIME [epoch: 9.53 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6030679817565628		[learning rate: 0.0013112]
	Learning Rate: 0.00131125
	LOSS [training: 0.6030679817565628 | validation: 0.9144090949952164]
	TIME [epoch: 9.53 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.648046048760039		[learning rate: 0.0013065]
	Learning Rate: 0.00130649
	LOSS [training: 0.648046048760039 | validation: 0.9428964607258231]
	TIME [epoch: 9.53 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6673961972161708		[learning rate: 0.0013017]
	Learning Rate: 0.00130175
	LOSS [training: 0.6673961972161708 | validation: 0.8886083327604373]
	TIME [epoch: 9.53 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6442085478549242		[learning rate: 0.001297]
	Learning Rate: 0.00129702
	LOSS [training: 0.6442085478549242 | validation: 0.8429482380501487]
	TIME [epoch: 9.52 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6011143481241406		[learning rate: 0.0012923]
	Learning Rate: 0.00129232
	LOSS [training: 0.6011143481241406 | validation: 0.8363537023280708]
	TIME [epoch: 9.53 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.606585114685593		[learning rate: 0.0012876]
	Learning Rate: 0.00128763
	LOSS [training: 0.606585114685593 | validation: 0.8746239846450129]
	TIME [epoch: 9.55 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6696347703068254		[learning rate: 0.001283]
	Learning Rate: 0.00128295
	LOSS [training: 0.6696347703068254 | validation: 0.8341064918313148]
	TIME [epoch: 9.53 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6938496284034908		[learning rate: 0.0012783]
	Learning Rate: 0.0012783
	LOSS [training: 0.6938496284034908 | validation: 1.0567835005041]
	TIME [epoch: 9.52 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6762755061397236		[learning rate: 0.0012737]
	Learning Rate: 0.00127366
	LOSS [training: 0.6762755061397236 | validation: 0.82643055992354]
	TIME [epoch: 9.53 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6048476482198389		[learning rate: 0.001269]
	Learning Rate: 0.00126904
	LOSS [training: 0.6048476482198389 | validation: 0.9941724866589189]
	TIME [epoch: 9.54 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6692477514311157		[learning rate: 0.0012644]
	Learning Rate: 0.00126443
	LOSS [training: 0.6692477514311157 | validation: 0.9030013487232811]
	TIME [epoch: 9.53 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6181890855556494		[learning rate: 0.0012598]
	Learning Rate: 0.00125984
	LOSS [training: 0.6181890855556494 | validation: 0.8534438928819944]
	TIME [epoch: 9.52 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6295096796027951		[learning rate: 0.0012553]
	Learning Rate: 0.00125527
	LOSS [training: 0.6295096796027951 | validation: 0.8573171569490791]
	TIME [epoch: 9.55 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6532503314792237		[learning rate: 0.0012507]
	Learning Rate: 0.00125071
	LOSS [training: 0.6532503314792237 | validation: 1.5034489184044213]
	TIME [epoch: 9.53 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9345650116114484		[learning rate: 0.0012462]
	Learning Rate: 0.00124617
	LOSS [training: 0.9345650116114484 | validation: 0.9187586197750247]
	TIME [epoch: 9.52 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6276101386843905		[learning rate: 0.0012417]
	Learning Rate: 0.00124165
	LOSS [training: 0.6276101386843905 | validation: 0.8411408397417341]
	TIME [epoch: 9.53 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6253318026942603		[learning rate: 0.0012371]
	Learning Rate: 0.00123715
	LOSS [training: 0.6253318026942603 | validation: 0.8328376013482207]
	TIME [epoch: 9.54 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6198913803928672		[learning rate: 0.0012327]
	Learning Rate: 0.00123266
	LOSS [training: 0.6198913803928672 | validation: 0.8730479832344594]
	TIME [epoch: 9.52 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6378308358355563		[learning rate: 0.0012282]
	Learning Rate: 0.00122818
	LOSS [training: 0.6378308358355563 | validation: 0.9017889430588423]
	TIME [epoch: 9.52 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6390661435535032		[learning rate: 0.0012237]
	Learning Rate: 0.00122373
	LOSS [training: 0.6390661435535032 | validation: 0.9212810348273228]
	TIME [epoch: 9.54 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6897495849328291		[learning rate: 0.0012193]
	Learning Rate: 0.00121929
	LOSS [training: 0.6897495849328291 | validation: 0.8227780832513103]
	TIME [epoch: 9.53 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6071098403506606		[learning rate: 0.0012149]
	Learning Rate: 0.00121486
	LOSS [training: 0.6071098403506606 | validation: 0.8913322725579884]
	TIME [epoch: 9.53 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6325122375121659		[learning rate: 0.0012105]
	Learning Rate: 0.00121045
	LOSS [training: 0.6325122375121659 | validation: 0.9250294526249024]
	TIME [epoch: 9.54 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5907599971338661		[learning rate: 0.0012061]
	Learning Rate: 0.00120606
	LOSS [training: 0.5907599971338661 | validation: 0.7936060934859595]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_682.pth
	Model improved!!!
EPOCH 683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6288508883427028		[learning rate: 0.0012017]
	Learning Rate: 0.00120168
	LOSS [training: 0.6288508883427028 | validation: 0.8556219779699581]
	TIME [epoch: 9.52 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6412141312247429		[learning rate: 0.0011973]
	Learning Rate: 0.00119732
	LOSS [training: 0.6412141312247429 | validation: 0.7580228430167738]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_684.pth
	Model improved!!!
EPOCH 685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6100350271861688		[learning rate: 0.001193]
	Learning Rate: 0.00119298
	LOSS [training: 0.6100350271861688 | validation: 0.8462450127413493]
	TIME [epoch: 9.55 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6305608772981763		[learning rate: 0.0011886]
	Learning Rate: 0.00118865
	LOSS [training: 0.6305608772981763 | validation: 0.8604172560068042]
	TIME [epoch: 9.52 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6118597297506084		[learning rate: 0.0011843]
	Learning Rate: 0.00118433
	LOSS [training: 0.6118597297506084 | validation: 0.9168880235256294]
	TIME [epoch: 9.52 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6496680100307725		[learning rate: 0.00118]
	Learning Rate: 0.00118003
	LOSS [training: 0.6496680100307725 | validation: 0.8894284814310259]
	TIME [epoch: 9.54 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6379400309644945		[learning rate: 0.0011758]
	Learning Rate: 0.00117575
	LOSS [training: 0.6379400309644945 | validation: 0.9227463910729474]
	TIME [epoch: 9.52 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6060325874161897		[learning rate: 0.0011715]
	Learning Rate: 0.00117149
	LOSS [training: 0.6060325874161897 | validation: 0.8477886584378481]
	TIME [epoch: 9.52 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6259774418351245		[learning rate: 0.0011672]
	Learning Rate: 0.00116723
	LOSS [training: 0.6259774418351245 | validation: 0.8159566220992552]
	TIME [epoch: 9.53 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6276663242301208		[learning rate: 0.001163]
	Learning Rate: 0.001163
	LOSS [training: 0.6276663242301208 | validation: 0.8398221564427971]
	TIME [epoch: 9.54 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6467904768416538		[learning rate: 0.0011588]
	Learning Rate: 0.00115878
	LOSS [training: 0.6467904768416538 | validation: 0.863955569745109]
	TIME [epoch: 9.52 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6312169359118822		[learning rate: 0.0011546]
	Learning Rate: 0.00115457
	LOSS [training: 0.6312169359118822 | validation: 0.9230964590922831]
	TIME [epoch: 9.52 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.610264256060085		[learning rate: 0.0011504]
	Learning Rate: 0.00115038
	LOSS [training: 0.610264256060085 | validation: 0.8799745126979712]
	TIME [epoch: 9.55 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6064906700886412		[learning rate: 0.0011462]
	Learning Rate: 0.00114621
	LOSS [training: 0.6064906700886412 | validation: 0.8826293096904974]
	TIME [epoch: 9.53 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6786505579940574		[learning rate: 0.001142]
	Learning Rate: 0.00114205
	LOSS [training: 0.6786505579940574 | validation: 0.8895073288354861]
	TIME [epoch: 9.53 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6418991412722803		[learning rate: 0.0011379]
	Learning Rate: 0.0011379
	LOSS [training: 0.6418991412722803 | validation: 0.8462107928005752]
	TIME [epoch: 9.53 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6110603235947735		[learning rate: 0.0011338]
	Learning Rate: 0.00113377
	LOSS [training: 0.6110603235947735 | validation: 0.8691194743087618]
	TIME [epoch: 9.54 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.586330511115956		[learning rate: 0.0011297]
	Learning Rate: 0.00112966
	LOSS [training: 0.586330511115956 | validation: 0.907859424516628]
	TIME [epoch: 9.52 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6379796805756255		[learning rate: 0.0011256]
	Learning Rate: 0.00112556
	LOSS [training: 0.6379796805756255 | validation: 0.8849023935742303]
	TIME [epoch: 9.53 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6059430819973608		[learning rate: 0.0011215]
	Learning Rate: 0.00112147
	LOSS [training: 0.6059430819973608 | validation: 0.8672020380112688]
	TIME [epoch: 9.55 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.661196177679685		[learning rate: 0.0011174]
	Learning Rate: 0.0011174
	LOSS [training: 0.661196177679685 | validation: 0.9193898687763937]
	TIME [epoch: 9.53 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.630114725962243		[learning rate: 0.0011133]
	Learning Rate: 0.00111335
	LOSS [training: 0.630114725962243 | validation: 0.8485873802782617]
	TIME [epoch: 9.53 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5834144628778694		[learning rate: 0.0011093]
	Learning Rate: 0.00110931
	LOSS [training: 0.5834144628778694 | validation: 0.8051263463871458]
	TIME [epoch: 9.53 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5896779183660212		[learning rate: 0.0011053]
	Learning Rate: 0.00110528
	LOSS [training: 0.5896779183660212 | validation: 0.9730214821063203]
	TIME [epoch: 9.54 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6372400720039431		[learning rate: 0.0011013]
	Learning Rate: 0.00110127
	LOSS [training: 0.6372400720039431 | validation: 0.8042927721612482]
	TIME [epoch: 9.52 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6758619966106443		[learning rate: 0.0010973]
	Learning Rate: 0.00109728
	LOSS [training: 0.6758619966106443 | validation: 0.8397395480296777]
	TIME [epoch: 9.53 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6045207031202481		[learning rate: 0.0010933]
	Learning Rate: 0.00109329
	LOSS [training: 0.6045207031202481 | validation: 0.8861036051425041]
	TIME [epoch: 9.54 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5849976451579926		[learning rate: 0.0010893]
	Learning Rate: 0.00108933
	LOSS [training: 0.5849976451579926 | validation: 0.8454895212856471]
	TIME [epoch: 9.53 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5945348381646303		[learning rate: 0.0010854]
	Learning Rate: 0.00108537
	LOSS [training: 0.5945348381646303 | validation: 0.773465625935333]
	TIME [epoch: 9.53 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6005585284286215		[learning rate: 0.0010814]
	Learning Rate: 0.00108143
	LOSS [training: 0.6005585284286215 | validation: 0.834991389025665]
	TIME [epoch: 9.54 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5875922283737929		[learning rate: 0.0010775]
	Learning Rate: 0.00107751
	LOSS [training: 0.5875922283737929 | validation: 0.8149148436445398]
	TIME [epoch: 9.54 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6057321651779193		[learning rate: 0.0010736]
	Learning Rate: 0.0010736
	LOSS [training: 0.6057321651779193 | validation: 0.8597112051640707]
	TIME [epoch: 9.53 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.602743274089115		[learning rate: 0.0010697]
	Learning Rate: 0.0010697
	LOSS [training: 0.602743274089115 | validation: 0.9739248701426632]
	TIME [epoch: 9.53 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6200279339005679		[learning rate: 0.0010658]
	Learning Rate: 0.00106582
	LOSS [training: 0.6200279339005679 | validation: 0.8089234736965345]
	TIME [epoch: 9.55 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6737226366430594		[learning rate: 0.001062]
	Learning Rate: 0.00106195
	LOSS [training: 0.6737226366430594 | validation: 0.8594061093845441]
	TIME [epoch: 9.53 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5755840755636589		[learning rate: 0.0010581]
	Learning Rate: 0.0010581
	LOSS [training: 0.5755840755636589 | validation: 0.897784814729422]
	TIME [epoch: 9.52 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5893945675812078		[learning rate: 0.0010543]
	Learning Rate: 0.00105426
	LOSS [training: 0.5893945675812078 | validation: 0.8132169645967676]
	TIME [epoch: 9.54 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5530576886469565		[learning rate: 0.0010504]
	Learning Rate: 0.00105043
	LOSS [training: 0.5530576886469565 | validation: 0.8568474187043873]
	TIME [epoch: 9.53 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6284907992901073		[learning rate: 0.0010466]
	Learning Rate: 0.00104662
	LOSS [training: 0.6284907992901073 | validation: 0.8783425771976121]
	TIME [epoch: 9.53 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6109034618070062		[learning rate: 0.0010428]
	Learning Rate: 0.00104282
	LOSS [training: 0.6109034618070062 | validation: 0.8557889322585344]
	TIME [epoch: 9.52 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6450313853874161		[learning rate: 0.001039]
	Learning Rate: 0.00103904
	LOSS [training: 0.6450313853874161 | validation: 0.8262198672673324]
	TIME [epoch: 9.54 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6200290129759136		[learning rate: 0.0010353]
	Learning Rate: 0.00103527
	LOSS [training: 0.6200290129759136 | validation: 0.9052341274520092]
	TIME [epoch: 9.53 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6215890521448239		[learning rate: 0.0010315]
	Learning Rate: 0.00103151
	LOSS [training: 0.6215890521448239 | validation: 0.8361864175869579]
	TIME [epoch: 9.52 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5898299233546717		[learning rate: 0.0010278]
	Learning Rate: 0.00102777
	LOSS [training: 0.5898299233546717 | validation: 0.7933037980212987]
	TIME [epoch: 9.54 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5688044129021059		[learning rate: 0.001024]
	Learning Rate: 0.00102404
	LOSS [training: 0.5688044129021059 | validation: 0.8455853447158139]
	TIME [epoch: 9.53 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5710586318773243		[learning rate: 0.0010203]
	Learning Rate: 0.00102032
	LOSS [training: 0.5710586318773243 | validation: 0.806682790804613]
	TIME [epoch: 9.52 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5933178173405653		[learning rate: 0.0010166]
	Learning Rate: 0.00101662
	LOSS [training: 0.5933178173405653 | validation: 0.8836914457159839]
	TIME [epoch: 9.53 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5859793839438652		[learning rate: 0.0010129]
	Learning Rate: 0.00101293
	LOSS [training: 0.5859793839438652 | validation: 0.8856972882187725]
	TIME [epoch: 9.54 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.600281090277418		[learning rate: 0.0010093]
	Learning Rate: 0.00100925
	LOSS [training: 0.600281090277418 | validation: 0.8076415972139599]
	TIME [epoch: 9.53 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5848668049933096		[learning rate: 0.0010056]
	Learning Rate: 0.00100559
	LOSS [training: 0.5848668049933096 | validation: 0.8927926917722127]
	TIME [epoch: 9.53 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6001639730004925		[learning rate: 0.0010019]
	Learning Rate: 0.00100194
	LOSS [training: 0.6001639730004925 | validation: 0.806382522880424]
	TIME [epoch: 9.54 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5639017455019101		[learning rate: 0.0009983]
	Learning Rate: 0.000998305
	LOSS [training: 0.5639017455019101 | validation: 0.7869799915532264]
	TIME [epoch: 9.53 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5311640295327578		[learning rate: 0.00099468]
	Learning Rate: 0.000994682
	LOSS [training: 0.5311640295327578 | validation: 0.9473371628417155]
	TIME [epoch: 9.52 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5767748798649659		[learning rate: 0.00099107]
	Learning Rate: 0.000991072
	LOSS [training: 0.5767748798649659 | validation: 0.795529986795796]
	TIME [epoch: 9.53 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5793801499609182		[learning rate: 0.00098748]
	Learning Rate: 0.000987475
	LOSS [training: 0.5793801499609182 | validation: 0.7916032803189128]
	TIME [epoch: 9.54 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6381829228553488		[learning rate: 0.00098389]
	Learning Rate: 0.000983892
	LOSS [training: 0.6381829228553488 | validation: 1.0476457406284536]
	TIME [epoch: 9.53 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6015203677033251		[learning rate: 0.00098032]
	Learning Rate: 0.000980321
	LOSS [training: 0.6015203677033251 | validation: 0.8527148559545684]
	TIME [epoch: 9.53 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5705070819740439		[learning rate: 0.00097676]
	Learning Rate: 0.000976764
	LOSS [training: 0.5705070819740439 | validation: 0.8040165457541033]
	TIME [epoch: 9.55 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5871793699991417		[learning rate: 0.00097322]
	Learning Rate: 0.000973219
	LOSS [training: 0.5871793699991417 | validation: 0.7871765667623387]
	TIME [epoch: 9.53 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5488545596091143		[learning rate: 0.00096969]
	Learning Rate: 0.000969687
	LOSS [training: 0.5488545596091143 | validation: 0.869733957422123]
	TIME [epoch: 9.52 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.659885478900968		[learning rate: 0.00096617]
	Learning Rate: 0.000966168
	LOSS [training: 0.659885478900968 | validation: 0.9019825132723444]
	TIME [epoch: 9.52 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5444032714478408		[learning rate: 0.00096266]
	Learning Rate: 0.000962662
	LOSS [training: 0.5444032714478408 | validation: 0.8799273902843657]
	TIME [epoch: 9.55 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5878193533814023		[learning rate: 0.00095917]
	Learning Rate: 0.000959168
	LOSS [training: 0.5878193533814023 | validation: 0.8585981869640059]
	TIME [epoch: 9.53 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5778156272179263		[learning rate: 0.00095569]
	Learning Rate: 0.000955687
	LOSS [training: 0.5778156272179263 | validation: 0.8725715663242508]
	TIME [epoch: 9.53 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5787777765083844		[learning rate: 0.00095222]
	Learning Rate: 0.000952219
	LOSS [training: 0.5787777765083844 | validation: 0.8491453305243633]
	TIME [epoch: 9.54 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6417031558272531		[learning rate: 0.00094876]
	Learning Rate: 0.000948763
	LOSS [training: 0.6417031558272531 | validation: 0.9265488709672524]
	TIME [epoch: 9.53 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7055419384729885		[learning rate: 0.00094532]
	Learning Rate: 0.00094532
	LOSS [training: 0.7055419384729885 | validation: 0.8616909312607749]
	TIME [epoch: 9.53 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6127716400454901		[learning rate: 0.00094189]
	Learning Rate: 0.000941889
	LOSS [training: 0.6127716400454901 | validation: 0.9423974544495165]
	TIME [epoch: 9.54 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.592434985332427		[learning rate: 0.00093847]
	Learning Rate: 0.000938471
	LOSS [training: 0.592434985332427 | validation: 0.8161583071994929]
	TIME [epoch: 9.54 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5407502789610985		[learning rate: 0.00093507]
	Learning Rate: 0.000935066
	LOSS [training: 0.5407502789610985 | validation: 0.8753409100787672]
	TIME [epoch: 9.52 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5557704701753552		[learning rate: 0.00093167]
	Learning Rate: 0.000931672
	LOSS [training: 0.5557704701753552 | validation: 0.8119267604887577]
	TIME [epoch: 9.52 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5722015373153991		[learning rate: 0.00092829]
	Learning Rate: 0.000928291
	LOSS [training: 0.5722015373153991 | validation: 0.7711647271485331]
	TIME [epoch: 9.53 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6048587300801547		[learning rate: 0.00092492]
	Learning Rate: 0.000924922
	LOSS [training: 0.6048587300801547 | validation: 0.8184037727928077]
	TIME [epoch: 9.53 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5658638896148703		[learning rate: 0.00092157]
	Learning Rate: 0.000921566
	LOSS [training: 0.5658638896148703 | validation: 0.8257677014140892]
	TIME [epoch: 9.52 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6005015249765092		[learning rate: 0.00091822]
	Learning Rate: 0.000918221
	LOSS [training: 0.6005015249765092 | validation: 0.8236518717368434]
	TIME [epoch: 9.53 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5665798693246192		[learning rate: 0.00091489]
	Learning Rate: 0.000914889
	LOSS [training: 0.5665798693246192 | validation: 0.8638212577973476]
	TIME [epoch: 9.55 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5755041306776929		[learning rate: 0.00091157]
	Learning Rate: 0.000911569
	LOSS [training: 0.5755041306776929 | validation: 0.7671285027613388]
	TIME [epoch: 9.53 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5657556121133683		[learning rate: 0.00090826]
	Learning Rate: 0.000908261
	LOSS [training: 0.5657556121133683 | validation: 0.8320627748616376]
	TIME [epoch: 9.53 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5916506386316025		[learning rate: 0.00090496]
	Learning Rate: 0.000904965
	LOSS [training: 0.5916506386316025 | validation: 0.8664343360879476]
	TIME [epoch: 9.54 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5809361759910979		[learning rate: 0.00090168]
	Learning Rate: 0.00090168
	LOSS [training: 0.5809361759910979 | validation: 0.8643154045793235]
	TIME [epoch: 9.52 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5892933370077407		[learning rate: 0.00089841]
	Learning Rate: 0.000898408
	LOSS [training: 0.5892933370077407 | validation: 0.8322532216116898]
	TIME [epoch: 9.52 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5711692736228602		[learning rate: 0.00089515]
	Learning Rate: 0.000895148
	LOSS [training: 0.5711692736228602 | validation: 0.8274696102494299]
	TIME [epoch: 9.53 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5651335075918625		[learning rate: 0.0008919]
	Learning Rate: 0.000891899
	LOSS [training: 0.5651335075918625 | validation: 0.8814236681277199]
	TIME [epoch: 9.54 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5899142795478761		[learning rate: 0.00088866]
	Learning Rate: 0.000888663
	LOSS [training: 0.5899142795478761 | validation: 0.880984086034585]
	TIME [epoch: 9.52 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5759757717809273		[learning rate: 0.00088544]
	Learning Rate: 0.000885438
	LOSS [training: 0.5759757717809273 | validation: 0.8958060728428177]
	TIME [epoch: 9.52 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5422794443839053		[learning rate: 0.00088222]
	Learning Rate: 0.000882224
	LOSS [training: 0.5422794443839053 | validation: 0.8664607135955491]
	TIME [epoch: 9.54 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5838029182952136		[learning rate: 0.00087902]
	Learning Rate: 0.000879022
	LOSS [training: 0.5838029182952136 | validation: 0.9104865001903822]
	TIME [epoch: 9.52 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5972647962009121		[learning rate: 0.00087583]
	Learning Rate: 0.000875833
	LOSS [training: 0.5972647962009121 | validation: 0.8230149209664533]
	TIME [epoch: 9.52 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5545803908270592		[learning rate: 0.00087265]
	Learning Rate: 0.000872654
	LOSS [training: 0.5545803908270592 | validation: 0.7943603285950297]
	TIME [epoch: 9.54 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5719181404952469		[learning rate: 0.00086949]
	Learning Rate: 0.000869487
	LOSS [training: 0.5719181404952469 | validation: 0.8003132819571611]
	TIME [epoch: 9.54 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5757198143015305		[learning rate: 0.00086633]
	Learning Rate: 0.000866332
	LOSS [training: 0.5757198143015305 | validation: 0.7907140549117355]
	TIME [epoch: 9.53 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5808968972122267		[learning rate: 0.00086319]
	Learning Rate: 0.000863188
	LOSS [training: 0.5808968972122267 | validation: 0.7917151580804099]
	TIME [epoch: 9.52 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5931279107764242		[learning rate: 0.00086006]
	Learning Rate: 0.000860055
	LOSS [training: 0.5931279107764242 | validation: 0.8654788652349171]
	TIME [epoch: 9.54 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5531958680682137		[learning rate: 0.00085693]
	Learning Rate: 0.000856934
	LOSS [training: 0.5531958680682137 | validation: 0.7928648424845249]
	TIME [epoch: 9.52 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5735175700701511		[learning rate: 0.00085382]
	Learning Rate: 0.000853824
	LOSS [training: 0.5735175700701511 | validation: 0.8303252236378531]
	TIME [epoch: 9.51 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6027464107768458		[learning rate: 0.00085073]
	Learning Rate: 0.000850726
	LOSS [training: 0.6027464107768458 | validation: 0.8015826957106016]
	TIME [epoch: 9.54 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5794154341470518		[learning rate: 0.00084764]
	Learning Rate: 0.000847638
	LOSS [training: 0.5794154341470518 | validation: 0.8931042565299432]
	TIME [epoch: 9.53 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5665153464495611		[learning rate: 0.00084456]
	Learning Rate: 0.000844562
	LOSS [training: 0.5665153464495611 | validation: 0.8086716720721934]
	TIME [epoch: 9.52 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5727994215129669		[learning rate: 0.0008415]
	Learning Rate: 0.000841497
	LOSS [training: 0.5727994215129669 | validation: 0.7816344682616628]
	TIME [epoch: 9.51 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5457042617970108		[learning rate: 0.00083844]
	Learning Rate: 0.000838443
	LOSS [training: 0.5457042617970108 | validation: 0.803097312488924]
	TIME [epoch: 9.53 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.570577403277958		[learning rate: 0.0008354]
	Learning Rate: 0.000835401
	LOSS [training: 0.570577403277958 | validation: 1.0212231130997027]
	TIME [epoch: 9.51 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6278629260543912		[learning rate: 0.00083237]
	Learning Rate: 0.000832369
	LOSS [training: 0.6278629260543912 | validation: 0.8955965625945053]
	TIME [epoch: 9.52 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6935104488059641		[learning rate: 0.00082935]
	Learning Rate: 0.000829348
	LOSS [training: 0.6935104488059641 | validation: 0.8299967075460726]
	TIME [epoch: 9.53 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5660687114988789		[learning rate: 0.00082634]
	Learning Rate: 0.000826338
	LOSS [training: 0.5660687114988789 | validation: 0.8207937825864734]
	TIME [epoch: 9.51 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5605730767264036		[learning rate: 0.00082334]
	Learning Rate: 0.00082334
	LOSS [training: 0.5605730767264036 | validation: 0.8238108283492317]
	TIME [epoch: 9.52 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.527764794714584		[learning rate: 0.00082035]
	Learning Rate: 0.000820352
	LOSS [training: 0.527764794714584 | validation: 0.792935853223851]
	TIME [epoch: 9.52 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5633534488143463		[learning rate: 0.00081737]
	Learning Rate: 0.000817375
	LOSS [training: 0.5633534488143463 | validation: 0.8082650424466887]
	TIME [epoch: 9.54 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5335792174818842		[learning rate: 0.00081441]
	Learning Rate: 0.000814408
	LOSS [training: 0.5335792174818842 | validation: 0.7935400278471195]
	TIME [epoch: 9.52 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5509310430117734		[learning rate: 0.00081145]
	Learning Rate: 0.000811453
	LOSS [training: 0.5509310430117734 | validation: 0.792330046509461]
	TIME [epoch: 9.52 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5660468606444388		[learning rate: 0.00080851]
	Learning Rate: 0.000808508
	LOSS [training: 0.5660468606444388 | validation: 0.7747790119815696]
	TIME [epoch: 9.53 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5835145405451172		[learning rate: 0.00080557]
	Learning Rate: 0.000805574
	LOSS [training: 0.5835145405451172 | validation: 0.814758261526412]
	TIME [epoch: 9.52 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5509586204649487		[learning rate: 0.00080265]
	Learning Rate: 0.00080265
	LOSS [training: 0.5509586204649487 | validation: 0.7970249786901633]
	TIME [epoch: 9.51 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5795365813326642		[learning rate: 0.00079974]
	Learning Rate: 0.000799737
	LOSS [training: 0.5795365813326642 | validation: 0.8796485665932972]
	TIME [epoch: 9.52 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.593724678525715		[learning rate: 0.00079684]
	Learning Rate: 0.000796835
	LOSS [training: 0.593724678525715 | validation: 0.8270537135867337]
	TIME [epoch: 9.54 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5799820371404486		[learning rate: 0.00079394]
	Learning Rate: 0.000793943
	LOSS [training: 0.5799820371404486 | validation: 0.869601479777791]
	TIME [epoch: 9.52 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.589576290430931		[learning rate: 0.00079106]
	Learning Rate: 0.000791062
	LOSS [training: 0.589576290430931 | validation: 0.8234727859645292]
	TIME [epoch: 9.52 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5619871085166374		[learning rate: 0.00078819]
	Learning Rate: 0.000788191
	LOSS [training: 0.5619871085166374 | validation: 0.91834317071595]
	TIME [epoch: 9.54 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5968330517582032		[learning rate: 0.00078533]
	Learning Rate: 0.000785331
	LOSS [training: 0.5968330517582032 | validation: 0.9166657004966307]
	TIME [epoch: 9.53 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5755422841596023		[learning rate: 0.00078248]
	Learning Rate: 0.000782481
	LOSS [training: 0.5755422841596023 | validation: 0.884613089351056]
	TIME [epoch: 9.52 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5076296929760422		[learning rate: 0.00077964]
	Learning Rate: 0.000779641
	LOSS [training: 0.5076296929760422 | validation: 0.826043874888033]
	TIME [epoch: 9.53 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.529046549824358		[learning rate: 0.00077681]
	Learning Rate: 0.000776812
	LOSS [training: 0.529046549824358 | validation: 0.8132228930855202]
	TIME [epoch: 9.55 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5391137940682603		[learning rate: 0.00077399]
	Learning Rate: 0.000773993
	LOSS [training: 0.5391137940682603 | validation: 0.8997477011371429]
	TIME [epoch: 9.53 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5679712938371063		[learning rate: 0.00077118]
	Learning Rate: 0.000771184
	LOSS [training: 0.5679712938371063 | validation: 0.7761167371690593]
	TIME [epoch: 9.52 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.533324794737253		[learning rate: 0.00076839]
	Learning Rate: 0.000768385
	LOSS [training: 0.533324794737253 | validation: 0.7704372998472606]
	TIME [epoch: 9.54 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5363289383061142		[learning rate: 0.0007656]
	Learning Rate: 0.000765597
	LOSS [training: 0.5363289383061142 | validation: 0.7747920293164665]
	TIME [epoch: 9.53 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5339122332953534		[learning rate: 0.00076282]
	Learning Rate: 0.000762818
	LOSS [training: 0.5339122332953534 | validation: 0.8096152086284059]
	TIME [epoch: 9.53 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5611164827669598		[learning rate: 0.00076005]
	Learning Rate: 0.00076005
	LOSS [training: 0.5611164827669598 | validation: 0.880169289099106]
	TIME [epoch: 9.52 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.576256527968357		[learning rate: 0.00075729]
	Learning Rate: 0.000757292
	LOSS [training: 0.576256527968357 | validation: 1.0579861801202728]
	TIME [epoch: 9.54 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6202547864726412		[learning rate: 0.00075454]
	Learning Rate: 0.000754543
	LOSS [training: 0.6202547864726412 | validation: 0.7716631215004899]
	TIME [epoch: 9.51 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6659399649880603		[learning rate: 0.00075181]
	Learning Rate: 0.000751805
	LOSS [training: 0.6659399649880603 | validation: 0.8555205797728945]
	TIME [epoch: 9.52 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5879840217855746		[learning rate: 0.00074908]
	Learning Rate: 0.000749077
	LOSS [training: 0.5879840217855746 | validation: 0.7795695162267181]
	TIME [epoch: 9.52 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5272488419974054		[learning rate: 0.00074636]
	Learning Rate: 0.000746358
	LOSS [training: 0.5272488419974054 | validation: 0.9043815197738101]
	TIME [epoch: 9.53 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5965987900493139		[learning rate: 0.00074365]
	Learning Rate: 0.00074365
	LOSS [training: 0.5965987900493139 | validation: 0.8109734908670546]
	TIME [epoch: 9.53 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5599410051270871		[learning rate: 0.00074095]
	Learning Rate: 0.000740951
	LOSS [training: 0.5599410051270871 | validation: 0.8547172491157798]
	TIME [epoch: 9.52 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5337494963812847		[learning rate: 0.00073826]
	Learning Rate: 0.000738262
	LOSS [training: 0.5337494963812847 | validation: 0.8235082616693905]
	TIME [epoch: 9.53 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.555024655033933		[learning rate: 0.00073558]
	Learning Rate: 0.000735583
	LOSS [training: 0.555024655033933 | validation: 0.8140018055537249]
	TIME [epoch: 9.52 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5443252515100223		[learning rate: 0.00073291]
	Learning Rate: 0.000732913
	LOSS [training: 0.5443252515100223 | validation: 0.8296954500743874]
	TIME [epoch: 9.52 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5246824843844854		[learning rate: 0.00073025]
	Learning Rate: 0.000730254
	LOSS [training: 0.5246824843844854 | validation: 0.9164773088430923]
	TIME [epoch: 9.55 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5579875139773685		[learning rate: 0.0007276]
	Learning Rate: 0.000727603
	LOSS [training: 0.5579875139773685 | validation: 0.8028093451779162]
	TIME [epoch: 9.53 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5090144831870057		[learning rate: 0.00072496]
	Learning Rate: 0.000724963
	LOSS [training: 0.5090144831870057 | validation: 0.7803521604394463]
	TIME [epoch: 9.53 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5238866603602045		[learning rate: 0.00072233]
	Learning Rate: 0.000722332
	LOSS [training: 0.5238866603602045 | validation: 0.8062470480204457]
	TIME [epoch: 9.52 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5546448134195996		[learning rate: 0.00071971]
	Learning Rate: 0.000719711
	LOSS [training: 0.5546448134195996 | validation: 0.8786807661463777]
	TIME [epoch: 9.54 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5768054574274439		[learning rate: 0.0007171]
	Learning Rate: 0.000717099
	LOSS [training: 0.5768054574274439 | validation: 0.8275448331033625]
	TIME [epoch: 9.51 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5628910025174214		[learning rate: 0.0007145]
	Learning Rate: 0.000714496
	LOSS [training: 0.5628910025174214 | validation: 0.8721421287566494]
	TIME [epoch: 9.52 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6303017172002472		[learning rate: 0.0007119]
	Learning Rate: 0.000711903
	LOSS [training: 0.6303017172002472 | validation: 0.7945594793922147]
	TIME [epoch: 9.54 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5187632184115448		[learning rate: 0.00070932]
	Learning Rate: 0.00070932
	LOSS [training: 0.5187632184115448 | validation: 0.8441352996225654]
	TIME [epoch: 9.51 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5639800253236938		[learning rate: 0.00070675]
	Learning Rate: 0.000706746
	LOSS [training: 0.5639800253236938 | validation: 0.8325875210073257]
	TIME [epoch: 9.52 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5746541097737279		[learning rate: 0.00070418]
	Learning Rate: 0.000704181
	LOSS [training: 0.5746541097737279 | validation: 0.8014307646947265]
	TIME [epoch: 9.52 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5580826650676013		[learning rate: 0.00070163]
	Learning Rate: 0.000701625
	LOSS [training: 0.5580826650676013 | validation: 0.8242740645675363]
	TIME [epoch: 9.54 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5747807001163999		[learning rate: 0.00069908]
	Learning Rate: 0.000699079
	LOSS [training: 0.5747807001163999 | validation: 0.769610151747209]
	TIME [epoch: 9.53 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5440197998697063		[learning rate: 0.00069654]
	Learning Rate: 0.000696542
	LOSS [training: 0.5440197998697063 | validation: 0.7625537498685809]
	TIME [epoch: 9.53 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5028657063331734		[learning rate: 0.00069401]
	Learning Rate: 0.000694014
	LOSS [training: 0.5028657063331734 | validation: 0.8172513189823966]
	TIME [epoch: 9.53 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5439125838503863		[learning rate: 0.0006915]
	Learning Rate: 0.000691496
	LOSS [training: 0.5439125838503863 | validation: 0.8413520983275419]
	TIME [epoch: 9.52 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.551351124060725		[learning rate: 0.00068899]
	Learning Rate: 0.000688986
	LOSS [training: 0.551351124060725 | validation: 0.806224573736487]
	TIME [epoch: 9.52 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.577068004127125		[learning rate: 0.00068649]
	Learning Rate: 0.000686486
	LOSS [training: 0.577068004127125 | validation: 0.85045481159064]
	TIME [epoch: 9.53 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.554495290335448		[learning rate: 0.00068399]
	Learning Rate: 0.000683994
	LOSS [training: 0.554495290335448 | validation: 0.8460325306286833]
	TIME [epoch: 9.53 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49717973084541905		[learning rate: 0.00068151]
	Learning Rate: 0.000681512
	LOSS [training: 0.49717973084541905 | validation: 0.7980827659980042]
	TIME [epoch: 9.52 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6264892250688986		[learning rate: 0.00067904]
	Learning Rate: 0.000679039
	LOSS [training: 0.6264892250688986 | validation: 0.761748375275394]
	TIME [epoch: 9.52 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48855317526617936		[learning rate: 0.00067657]
	Learning Rate: 0.000676575
	LOSS [training: 0.48855317526617936 | validation: 0.7903552275388452]
	TIME [epoch: 9.53 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5163963263034079		[learning rate: 0.00067412]
	Learning Rate: 0.00067412
	LOSS [training: 0.5163963263034079 | validation: 0.759155195301164]
	TIME [epoch: 9.53 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6071585478547956		[learning rate: 0.00067167]
	Learning Rate: 0.000671673
	LOSS [training: 0.6071585478547956 | validation: 0.7434267319344011]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_843.pth
	Model improved!!!
EPOCH 844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5475009697715617		[learning rate: 0.00066924]
	Learning Rate: 0.000669235
	LOSS [training: 0.5475009697715617 | validation: 0.7853340036160564]
	TIME [epoch: 9.53 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7094744901757153		[learning rate: 0.00066681]
	Learning Rate: 0.000666807
	LOSS [training: 0.7094744901757153 | validation: 0.8017507360574024]
	TIME [epoch: 9.52 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5292215443267307		[learning rate: 0.00066439]
	Learning Rate: 0.000664387
	LOSS [training: 0.5292215443267307 | validation: 0.7911813100991001]
	TIME [epoch: 9.5 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5027700627153593		[learning rate: 0.00066198]
	Learning Rate: 0.000661976
	LOSS [training: 0.5027700627153593 | validation: 0.7882933769425503]
	TIME [epoch: 9.51 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5121980235500597		[learning rate: 0.00065957]
	Learning Rate: 0.000659573
	LOSS [training: 0.5121980235500597 | validation: 0.812933824522999]
	TIME [epoch: 9.53 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4957764432765484		[learning rate: 0.00065718]
	Learning Rate: 0.00065718
	LOSS [training: 0.4957764432765484 | validation: 0.8139558023997652]
	TIME [epoch: 9.51 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5140948987034327		[learning rate: 0.00065479]
	Learning Rate: 0.000654795
	LOSS [training: 0.5140948987034327 | validation: 0.7850645396925015]
	TIME [epoch: 9.5 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5230556328221152		[learning rate: 0.00065242]
	Learning Rate: 0.000652419
	LOSS [training: 0.5230556328221152 | validation: 0.9151009554511339]
	TIME [epoch: 9.52 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5517575563161744		[learning rate: 0.00065005]
	Learning Rate: 0.000650051
	LOSS [training: 0.5517575563161744 | validation: 0.7854318954627862]
	TIME [epoch: 9.51 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5703967206209948		[learning rate: 0.00064769]
	Learning Rate: 0.000647692
	LOSS [training: 0.5703967206209948 | validation: 0.8037509378010735]
	TIME [epoch: 9.51 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5716578183951444		[learning rate: 0.00064534]
	Learning Rate: 0.000645341
	LOSS [training: 0.5716578183951444 | validation: 0.771362517773432]
	TIME [epoch: 9.5 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5447727049937641		[learning rate: 0.000643]
	Learning Rate: 0.000642999
	LOSS [training: 0.5447727049937641 | validation: 0.864388234398405]
	TIME [epoch: 9.54 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5713163630634538		[learning rate: 0.00064067]
	Learning Rate: 0.000640666
	LOSS [training: 0.5713163630634538 | validation: 0.8977010831719342]
	TIME [epoch: 9.5 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5377301531542784		[learning rate: 0.00063834]
	Learning Rate: 0.000638341
	LOSS [training: 0.5377301531542784 | validation: 0.7744528125665678]
	TIME [epoch: 9.52 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.522052477406438		[learning rate: 0.00063602]
	Learning Rate: 0.000636024
	LOSS [training: 0.522052477406438 | validation: 0.8332013927080244]
	TIME [epoch: 9.52 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5425268078912341		[learning rate: 0.00063372]
	Learning Rate: 0.000633716
	LOSS [training: 0.5425268078912341 | validation: 0.8689316708750201]
	TIME [epoch: 9.52 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6139840846540789		[learning rate: 0.00063142]
	Learning Rate: 0.000631416
	LOSS [training: 0.6139840846540789 | validation: 0.7680770766505617]
	TIME [epoch: 9.52 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5733574869197107		[learning rate: 0.00062912]
	Learning Rate: 0.000629125
	LOSS [training: 0.5733574869197107 | validation: 0.8276555774361779]
	TIME [epoch: 9.5 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5867351340918747		[learning rate: 0.00062684]
	Learning Rate: 0.000626842
	LOSS [training: 0.5867351340918747 | validation: 0.8225097025342103]
	TIME [epoch: 9.52 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5525654595012267		[learning rate: 0.00062457]
	Learning Rate: 0.000624567
	LOSS [training: 0.5525654595012267 | validation: 0.8158953829453001]
	TIME [epoch: 9.5 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5414460510157353		[learning rate: 0.0006223]
	Learning Rate: 0.0006223
	LOSS [training: 0.5414460510157353 | validation: 0.7884656394981613]
	TIME [epoch: 9.51 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.555017000642827		[learning rate: 0.00062004]
	Learning Rate: 0.000620042
	LOSS [training: 0.555017000642827 | validation: 0.8141569883872726]
	TIME [epoch: 9.52 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5463778320879301		[learning rate: 0.00061779]
	Learning Rate: 0.000617792
	LOSS [training: 0.5463778320879301 | validation: 0.7801462056543766]
	TIME [epoch: 9.51 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5520416379082398		[learning rate: 0.00061555]
	Learning Rate: 0.00061555
	LOSS [training: 0.5520416379082398 | validation: 0.7756081236383581]
	TIME [epoch: 9.51 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5352871854371151		[learning rate: 0.00061332]
	Learning Rate: 0.000613316
	LOSS [training: 0.5352871854371151 | validation: 0.8387710608450917]
	TIME [epoch: 9.51 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5149883697220193		[learning rate: 0.00061109]
	Learning Rate: 0.00061109
	LOSS [training: 0.5149883697220193 | validation: 0.7564608987625044]
	TIME [epoch: 9.52 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6581448356675067		[learning rate: 0.00060887]
	Learning Rate: 0.000608872
	LOSS [training: 0.6581448356675067 | validation: 0.8804816236219266]
	TIME [epoch: 9.5 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5380479061050764		[learning rate: 0.00060666]
	Learning Rate: 0.000606663
	LOSS [training: 0.5380479061050764 | validation: 0.8445349024026112]
	TIME [epoch: 9.5 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5453556160008988		[learning rate: 0.00060446]
	Learning Rate: 0.000604461
	LOSS [training: 0.5453556160008988 | validation: 0.8052794105367181]
	TIME [epoch: 9.52 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5243210060942394		[learning rate: 0.00060227]
	Learning Rate: 0.000602268
	LOSS [training: 0.5243210060942394 | validation: 0.8078962123500617]
	TIME [epoch: 9.52 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5472840394532851		[learning rate: 0.00060008]
	Learning Rate: 0.000600082
	LOSS [training: 0.5472840394532851 | validation: 0.7875803173575682]
	TIME [epoch: 9.5 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5829082640885208		[learning rate: 0.0005979]
	Learning Rate: 0.000597904
	LOSS [training: 0.5829082640885208 | validation: 0.7708839479099696]
	TIME [epoch: 9.51 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48074293675991175		[learning rate: 0.00059573]
	Learning Rate: 0.000595734
	LOSS [training: 0.48074293675991175 | validation: 0.8188000532280547]
	TIME [epoch: 9.52 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5190151718269024		[learning rate: 0.00059357]
	Learning Rate: 0.000593572
	LOSS [training: 0.5190151718269024 | validation: 0.7553434892182418]
	TIME [epoch: 9.5 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5179883182186511		[learning rate: 0.00059142]
	Learning Rate: 0.000591418
	LOSS [training: 0.5179883182186511 | validation: 0.7700863369881406]
	TIME [epoch: 9.5 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5660873191330367		[learning rate: 0.00058927]
	Learning Rate: 0.000589272
	LOSS [training: 0.5660873191330367 | validation: 0.78682296909464]
	TIME [epoch: 9.53 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5305767404472199		[learning rate: 0.00058713]
	Learning Rate: 0.000587133
	LOSS [training: 0.5305767404472199 | validation: 0.8370989023732878]
	TIME [epoch: 9.51 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5591027812346983		[learning rate: 0.000585]
	Learning Rate: 0.000585003
	LOSS [training: 0.5591027812346983 | validation: 0.8654082397473417]
	TIME [epoch: 9.5 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5259718209633115		[learning rate: 0.00058288]
	Learning Rate: 0.00058288
	LOSS [training: 0.5259718209633115 | validation: 0.7823391656106486]
	TIME [epoch: 9.52 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5164053230603157		[learning rate: 0.00058076]
	Learning Rate: 0.000580764
	LOSS [training: 0.5164053230603157 | validation: 0.7997911076088317]
	TIME [epoch: 9.53 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5182077920955253		[learning rate: 0.00057866]
	Learning Rate: 0.000578657
	LOSS [training: 0.5182077920955253 | validation: 0.7703374548269224]
	TIME [epoch: 9.51 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5123690363257545		[learning rate: 0.00057656]
	Learning Rate: 0.000576557
	LOSS [training: 0.5123690363257545 | validation: 0.8196024580731637]
	TIME [epoch: 9.51 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5905298960787042		[learning rate: 0.00057446]
	Learning Rate: 0.000574465
	LOSS [training: 0.5905298960787042 | validation: 0.7832909728007391]
	TIME [epoch: 9.52 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5988204210142622		[learning rate: 0.00057238]
	Learning Rate: 0.00057238
	LOSS [training: 0.5988204210142622 | validation: 0.74898700118235]
	TIME [epoch: 9.52 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48652347253876		[learning rate: 0.0005703]
	Learning Rate: 0.000570303
	LOSS [training: 0.48652347253876 | validation: 0.8060394055207977]
	TIME [epoch: 9.5 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48868290380512935		[learning rate: 0.00056823]
	Learning Rate: 0.000568233
	LOSS [training: 0.48868290380512935 | validation: 0.8158817011769499]
	TIME [epoch: 9.51 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5135642914882942		[learning rate: 0.00056617]
	Learning Rate: 0.000566171
	LOSS [training: 0.5135642914882942 | validation: 0.7991823976644585]
	TIME [epoch: 9.52 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5326982070766726		[learning rate: 0.00056412]
	Learning Rate: 0.000564116
	LOSS [training: 0.5326982070766726 | validation: 0.7507214778312122]
	TIME [epoch: 9.51 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5191271333829814		[learning rate: 0.00056207]
	Learning Rate: 0.000562069
	LOSS [training: 0.5191271333829814 | validation: 0.8173364323040829]
	TIME [epoch: 9.5 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5607429453094495		[learning rate: 0.00056003]
	Learning Rate: 0.000560029
	LOSS [training: 0.5607429453094495 | validation: 0.9119490923775595]
	TIME [epoch: 9.52 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5670518267371951		[learning rate: 0.000558]
	Learning Rate: 0.000557997
	LOSS [training: 0.5670518267371951 | validation: 0.8840266572145058]
	TIME [epoch: 9.51 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5114682709622587		[learning rate: 0.00055597]
	Learning Rate: 0.000555972
	LOSS [training: 0.5114682709622587 | validation: 0.8045084947948518]
	TIME [epoch: 9.51 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5472633107075697		[learning rate: 0.00055395]
	Learning Rate: 0.000553954
	LOSS [training: 0.5472633107075697 | validation: 0.77755362426953]
	TIME [epoch: 9.51 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5098587276896834		[learning rate: 0.00055194]
	Learning Rate: 0.000551944
	LOSS [training: 0.5098587276896834 | validation: 0.8456418402146433]
	TIME [epoch: 9.52 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5219006721018938		[learning rate: 0.00054994]
	Learning Rate: 0.000549941
	LOSS [training: 0.5219006721018938 | validation: 0.7607884434320791]
	TIME [epoch: 9.52 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5026330688582716		[learning rate: 0.00054794]
	Learning Rate: 0.000547945
	LOSS [training: 0.5026330688582716 | validation: 0.7979607597772853]
	TIME [epoch: 9.51 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5106849679591587		[learning rate: 0.00054596]
	Learning Rate: 0.000545956
	LOSS [training: 0.5106849679591587 | validation: 0.8175634962677834]
	TIME [epoch: 9.53 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5696166760341321		[learning rate: 0.00054397]
	Learning Rate: 0.000543975
	LOSS [training: 0.5696166760341321 | validation: 0.7630282125021753]
	TIME [epoch: 9.52 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8980082471740447		[learning rate: 0.000542]
	Learning Rate: 0.000542001
	LOSS [training: 0.8980082471740447 | validation: 0.9983853768571734]
	TIME [epoch: 9.52 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.618746441944122		[learning rate: 0.00054003]
	Learning Rate: 0.000540034
	LOSS [training: 0.618746441944122 | validation: 0.7709358672780912]
	TIME [epoch: 9.53 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49530017486083266		[learning rate: 0.00053807]
	Learning Rate: 0.000538074
	LOSS [training: 0.49530017486083266 | validation: 0.7670010883180828]
	TIME [epoch: 9.51 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4890370454225447		[learning rate: 0.00053612]
	Learning Rate: 0.000536121
	LOSS [training: 0.4890370454225447 | validation: 0.7697687365627591]
	TIME [epoch: 9.51 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48591041678383534		[learning rate: 0.00053418]
	Learning Rate: 0.000534176
	LOSS [training: 0.48591041678383534 | validation: 0.7638877378557084]
	TIME [epoch: 9.49 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5126325649532008		[learning rate: 0.00053224]
	Learning Rate: 0.000532237
	LOSS [training: 0.5126325649532008 | validation: 0.7545055284517241]
	TIME [epoch: 9.53 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5076078592625531		[learning rate: 0.00053031]
	Learning Rate: 0.000530306
	LOSS [training: 0.5076078592625531 | validation: 0.8194709421724575]
	TIME [epoch: 9.5 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.502068999752564		[learning rate: 0.00052838]
	Learning Rate: 0.000528381
	LOSS [training: 0.502068999752564 | validation: 0.7628554711499667]
	TIME [epoch: 9.52 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5343933856822641		[learning rate: 0.00052646]
	Learning Rate: 0.000526464
	LOSS [training: 0.5343933856822641 | validation: 0.8134045921913347]
	TIME [epoch: 9.53 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48884061459036776		[learning rate: 0.00052455]
	Learning Rate: 0.000524553
	LOSS [training: 0.48884061459036776 | validation: 0.7617266982713676]
	TIME [epoch: 9.51 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5153632262309423		[learning rate: 0.00052265]
	Learning Rate: 0.000522649
	LOSS [training: 0.5153632262309423 | validation: 0.8992493383045301]
	TIME [epoch: 9.5 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5390155521121114		[learning rate: 0.00052075]
	Learning Rate: 0.000520753
	LOSS [training: 0.5390155521121114 | validation: 0.7688065636637919]
	TIME [epoch: 9.51 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5090280402763196		[learning rate: 0.00051886]
	Learning Rate: 0.000518863
	LOSS [training: 0.5090280402763196 | validation: 0.7550290048788473]
	TIME [epoch: 9.52 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48319216015266264		[learning rate: 0.00051698]
	Learning Rate: 0.00051698
	LOSS [training: 0.48319216015266264 | validation: 0.7775914193697636]
	TIME [epoch: 9.49 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5308164311664535		[learning rate: 0.0005151]
	Learning Rate: 0.000515104
	LOSS [training: 0.5308164311664535 | validation: 0.7584662050803592]
	TIME [epoch: 9.5 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5046575114150296		[learning rate: 0.00051323]
	Learning Rate: 0.000513235
	LOSS [training: 0.5046575114150296 | validation: 0.792218287915124]
	TIME [epoch: 9.51 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5671835079474373		[learning rate: 0.00051137]
	Learning Rate: 0.000511372
	LOSS [training: 0.5671835079474373 | validation: 0.8444542159309149]
	TIME [epoch: 9.51 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5481701037691624		[learning rate: 0.00050952]
	Learning Rate: 0.000509516
	LOSS [training: 0.5481701037691624 | validation: 0.7779571211135385]
	TIME [epoch: 9.5 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5180847412825057		[learning rate: 0.00050767]
	Learning Rate: 0.000507667
	LOSS [training: 0.5180847412825057 | validation: 0.790721683641782]
	TIME [epoch: 9.5 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5208195688260162		[learning rate: 0.00050582]
	Learning Rate: 0.000505825
	LOSS [training: 0.5208195688260162 | validation: 0.7822088070103402]
	TIME [epoch: 9.52 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.518993376772641		[learning rate: 0.00050399]
	Learning Rate: 0.000503989
	LOSS [training: 0.518993376772641 | validation: 0.8636576300866523]
	TIME [epoch: 9.5 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5157713056837896		[learning rate: 0.00050216]
	Learning Rate: 0.00050216
	LOSS [training: 0.5157713056837896 | validation: 0.7753419001664571]
	TIME [epoch: 9.5 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4970752288011022		[learning rate: 0.00050034]
	Learning Rate: 0.000500338
	LOSS [training: 0.4970752288011022 | validation: 0.7943000356085668]
	TIME [epoch: 9.51 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5442355776672602		[learning rate: 0.00049852]
	Learning Rate: 0.000498522
	LOSS [training: 0.5442355776672602 | validation: 0.7761792599884529]
	TIME [epoch: 9.5 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4816265440319338		[learning rate: 0.00049671]
	Learning Rate: 0.000496713
	LOSS [training: 0.4816265440319338 | validation: 0.7768304722352002]
	TIME [epoch: 9.5 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47396499172764656		[learning rate: 0.00049491]
	Learning Rate: 0.00049491
	LOSS [training: 0.47396499172764656 | validation: 0.795497577743825]
	TIME [epoch: 9.5 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5410158916761126		[learning rate: 0.00049311]
	Learning Rate: 0.000493114
	LOSS [training: 0.5410158916761126 | validation: 0.7671214700567359]
	TIME [epoch: 9.53 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48605707516990904		[learning rate: 0.00049132]
	Learning Rate: 0.000491325
	LOSS [training: 0.48605707516990904 | validation: 0.802096311965407]
	TIME [epoch: 9.5 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5050723277334096		[learning rate: 0.00048954]
	Learning Rate: 0.000489542
	LOSS [training: 0.5050723277334096 | validation: 0.7832313286665732]
	TIME [epoch: 9.5 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4943771064182658		[learning rate: 0.00048776]
	Learning Rate: 0.000487765
	LOSS [training: 0.4943771064182658 | validation: 0.8349567752635128]
	TIME [epoch: 9.51 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5310330361756584		[learning rate: 0.00048599]
	Learning Rate: 0.000485995
	LOSS [training: 0.5310330361756584 | validation: 0.765207057779296]
	TIME [epoch: 9.5 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6107013058993145		[learning rate: 0.00048423]
	Learning Rate: 0.000484231
	LOSS [training: 0.6107013058993145 | validation: 0.7471968365060835]
	TIME [epoch: 9.5 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5421559115437458		[learning rate: 0.00048247]
	Learning Rate: 0.000482474
	LOSS [training: 0.5421559115437458 | validation: 0.7687040866715005]
	TIME [epoch: 9.5 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6468611288520766		[learning rate: 0.00048072]
	Learning Rate: 0.000480723
	LOSS [training: 0.6468611288520766 | validation: 0.7432955821687582]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_935.pth
	Model improved!!!
EPOCH 936/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5156306733048968		[learning rate: 0.00047898]
	Learning Rate: 0.000478978
	LOSS [training: 0.5156306733048968 | validation: 0.7729464521046788]
	TIME [epoch: 9.51 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49207354431466016		[learning rate: 0.00047724]
	Learning Rate: 0.00047724
	LOSS [training: 0.49207354431466016 | validation: 0.7909835641736472]
	TIME [epoch: 9.49 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.519264737839101		[learning rate: 0.00047551]
	Learning Rate: 0.000475508
	LOSS [training: 0.519264737839101 | validation: 0.7966531453297064]
	TIME [epoch: 9.51 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.487020685624932		[learning rate: 0.00047378]
	Learning Rate: 0.000473782
	LOSS [training: 0.487020685624932 | validation: 0.791337904785037]
	TIME [epoch: 9.49 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5314763600539256		[learning rate: 0.00047206]
	Learning Rate: 0.000472063
	LOSS [training: 0.5314763600539256 | validation: 0.7555588966758672]
	TIME [epoch: 9.49 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4895924699470746		[learning rate: 0.00047035]
	Learning Rate: 0.00047035
	LOSS [training: 0.4895924699470746 | validation: 0.7458667638141361]
	TIME [epoch: 9.5 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5010702308413348		[learning rate: 0.00046864]
	Learning Rate: 0.000468643
	LOSS [training: 0.5010702308413348 | validation: 0.7631776377150561]
	TIME [epoch: 9.51 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4832511126925391		[learning rate: 0.00046694]
	Learning Rate: 0.000466942
	LOSS [training: 0.4832511126925391 | validation: 0.8302094194906227]
	TIME [epoch: 9.49 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5363328456463897		[learning rate: 0.00046525]
	Learning Rate: 0.000465248
	LOSS [training: 0.5363328456463897 | validation: 0.7834368948980354]
	TIME [epoch: 9.49 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5033775372246064		[learning rate: 0.00046356]
	Learning Rate: 0.000463559
	LOSS [training: 0.5033775372246064 | validation: 0.7539455375510127]
	TIME [epoch: 9.51 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5139629032270286		[learning rate: 0.00046188]
	Learning Rate: 0.000461877
	LOSS [training: 0.5139629032270286 | validation: 0.7477092974217161]
	TIME [epoch: 9.5 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5270462377291423		[learning rate: 0.0004602]
	Learning Rate: 0.000460201
	LOSS [training: 0.5270462377291423 | validation: 0.783146333966549]
	TIME [epoch: 9.5 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5214708568871671		[learning rate: 0.00045853]
	Learning Rate: 0.000458531
	LOSS [training: 0.5214708568871671 | validation: 0.7611742254627174]
	TIME [epoch: 9.5 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4906812099523526		[learning rate: 0.00045687]
	Learning Rate: 0.000456867
	LOSS [training: 0.4906812099523526 | validation: 0.7753861796001624]
	TIME [epoch: 9.51 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48387409557088523		[learning rate: 0.00045521]
	Learning Rate: 0.000455209
	LOSS [training: 0.48387409557088523 | validation: 0.76271437188568]
	TIME [epoch: 9.49 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48407534305057365		[learning rate: 0.00045356]
	Learning Rate: 0.000453557
	LOSS [training: 0.48407534305057365 | validation: 0.8100396249678821]
	TIME [epoch: 9.49 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5034302189291974		[learning rate: 0.00045191]
	Learning Rate: 0.000451911
	LOSS [training: 0.5034302189291974 | validation: 0.7326083429858165]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_952.pth
	Model improved!!!
EPOCH 953/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46393475797241485		[learning rate: 0.00045027]
	Learning Rate: 0.000450271
	LOSS [training: 0.46393475797241485 | validation: 0.8098680040497408]
	TIME [epoch: 9.51 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4820873816102492		[learning rate: 0.00044864]
	Learning Rate: 0.000448637
	LOSS [training: 0.4820873816102492 | validation: 0.7953756357978261]
	TIME [epoch: 9.5 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4885253830041768		[learning rate: 0.00044701]
	Learning Rate: 0.000447009
	LOSS [training: 0.4885253830041768 | validation: 0.7930632083784963]
	TIME [epoch: 9.49 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5072678170512274		[learning rate: 0.00044539]
	Learning Rate: 0.000445386
	LOSS [training: 0.5072678170512274 | validation: 0.7552055664802404]
	TIME [epoch: 9.51 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48101820730667544		[learning rate: 0.00044377]
	Learning Rate: 0.00044377
	LOSS [training: 0.48101820730667544 | validation: 0.7313347642790048]
	TIME [epoch: 9.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_957.pth
	Model improved!!!
EPOCH 958/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46867897462460684		[learning rate: 0.00044216]
	Learning Rate: 0.00044216
	LOSS [training: 0.46867897462460684 | validation: 0.799779225665109]
	TIME [epoch: 9.49 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4730025044740245		[learning rate: 0.00044055]
	Learning Rate: 0.000440555
	LOSS [training: 0.4730025044740245 | validation: 0.7427287341568828]
	TIME [epoch: 9.51 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4779309833524777		[learning rate: 0.00043896]
	Learning Rate: 0.000438956
	LOSS [training: 0.4779309833524777 | validation: 0.7548542354260753]
	TIME [epoch: 9.49 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49944864821192914		[learning rate: 0.00043736]
	Learning Rate: 0.000437363
	LOSS [training: 0.49944864821192914 | validation: 0.7311968204300798]
	TIME [epoch: 9.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_961.pth
	Model improved!!!
EPOCH 962/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47579474043360237		[learning rate: 0.00043578]
	Learning Rate: 0.000435776
	LOSS [training: 0.47579474043360237 | validation: 0.8428474951660563]
	TIME [epoch: 9.5 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5060263716056712		[learning rate: 0.00043419]
	Learning Rate: 0.000434194
	LOSS [training: 0.5060263716056712 | validation: 0.7635277120168681]
	TIME [epoch: 9.5 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5024653955452133		[learning rate: 0.00043262]
	Learning Rate: 0.000432619
	LOSS [training: 0.5024653955452133 | validation: 0.8036374241965686]
	TIME [epoch: 9.5 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5185069601915214		[learning rate: 0.00043105]
	Learning Rate: 0.000431049
	LOSS [training: 0.5185069601915214 | validation: 0.7475368789861176]
	TIME [epoch: 9.49 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5155130901716762		[learning rate: 0.00042948]
	Learning Rate: 0.000429484
	LOSS [training: 0.5155130901716762 | validation: 0.7758389167712456]
	TIME [epoch: 9.5 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4999548649628635		[learning rate: 0.00042793]
	Learning Rate: 0.000427926
	LOSS [training: 0.4999548649628635 | validation: 0.8020583441820717]
	TIME [epoch: 9.49 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4764590365899589		[learning rate: 0.00042637]
	Learning Rate: 0.000426373
	LOSS [training: 0.4764590365899589 | validation: 0.7836582042364265]
	TIME [epoch: 9.49 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5055119779578008		[learning rate: 0.00042483]
	Learning Rate: 0.000424825
	LOSS [training: 0.5055119779578008 | validation: 0.7707930114308339]
	TIME [epoch: 9.51 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4961894651285775		[learning rate: 0.00042328]
	Learning Rate: 0.000423284
	LOSS [training: 0.4961894651285775 | validation: 0.7364349498844854]
	TIME [epoch: 9.51 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4948292173692518		[learning rate: 0.00042175]
	Learning Rate: 0.000421748
	LOSS [training: 0.4948292173692518 | validation: 0.7623182483196552]
	TIME [epoch: 9.49 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46950599850566455		[learning rate: 0.00042022]
	Learning Rate: 0.000420217
	LOSS [training: 0.46950599850566455 | validation: 0.8301270190491602]
	TIME [epoch: 9.49 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5900362158461668		[learning rate: 0.00041869]
	Learning Rate: 0.000418692
	LOSS [training: 0.5900362158461668 | validation: 0.808552103652998]
	TIME [epoch: 9.51 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5725745743016846		[learning rate: 0.00041717]
	Learning Rate: 0.000417173
	LOSS [training: 0.5725745743016846 | validation: 0.7743194450546693]
	TIME [epoch: 9.49 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5263226710007837		[learning rate: 0.00041566]
	Learning Rate: 0.000415659
	LOSS [training: 0.5263226710007837 | validation: 0.7700993113272149]
	TIME [epoch: 9.49 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5115701750503053		[learning rate: 0.00041415]
	Learning Rate: 0.00041415
	LOSS [training: 0.5115701750503053 | validation: 0.810502110823234]
	TIME [epoch: 9.5 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5009601238837417		[learning rate: 0.00041265]
	Learning Rate: 0.000412647
	LOSS [training: 0.5009601238837417 | validation: 0.7884606257003871]
	TIME [epoch: 9.5 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5173943728333226		[learning rate: 0.00041115]
	Learning Rate: 0.00041115
	LOSS [training: 0.5173943728333226 | validation: 0.8209582630588846]
	TIME [epoch: 9.5 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4801783632414538		[learning rate: 0.00040966]
	Learning Rate: 0.000409658
	LOSS [training: 0.4801783632414538 | validation: 0.7815938205468399]
	TIME [epoch: 9.5 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49225329843256055		[learning rate: 0.00040817]
	Learning Rate: 0.000408171
	LOSS [training: 0.49225329843256055 | validation: 0.7309083245087499]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_980.pth
	Model improved!!!
EPOCH 981/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48148791487869413		[learning rate: 0.00040669]
	Learning Rate: 0.00040669
	LOSS [training: 0.48148791487869413 | validation: 0.7867790844495547]
	TIME [epoch: 9.49 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.645359558471758		[learning rate: 0.00040521]
	Learning Rate: 0.000405214
	LOSS [training: 0.645359558471758 | validation: 0.8401952210322193]
	TIME [epoch: 9.48 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5014798680589163		[learning rate: 0.00040374]
	Learning Rate: 0.000403743
	LOSS [training: 0.5014798680589163 | validation: 0.7828210476307206]
	TIME [epoch: 9.51 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.515164971678539		[learning rate: 0.00040228]
	Learning Rate: 0.000402278
	LOSS [training: 0.515164971678539 | validation: 0.7505268451785709]
	TIME [epoch: 9.49 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46171738570549287		[learning rate: 0.00040082]
	Learning Rate: 0.000400818
	LOSS [training: 0.46171738570549287 | validation: 0.7426823299005105]
	TIME [epoch: 9.49 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4526166356719954		[learning rate: 0.00039936]
	Learning Rate: 0.000399364
	LOSS [training: 0.4526166356719954 | validation: 0.771371714559924]
	TIME [epoch: 9.48 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4844796268140582		[learning rate: 0.00039791]
	Learning Rate: 0.000397914
	LOSS [training: 0.4844796268140582 | validation: 0.7779405146763232]
	TIME [epoch: 9.5 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47311636614938807		[learning rate: 0.00039647]
	Learning Rate: 0.00039647
	LOSS [training: 0.47311636614938807 | validation: 0.8039402985960653]
	TIME [epoch: 9.49 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49811743434620553		[learning rate: 0.00039503]
	Learning Rate: 0.000395031
	LOSS [training: 0.49811743434620553 | validation: 0.7739889529696253]
	TIME [epoch: 9.49 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4716844703833882		[learning rate: 0.0003936]
	Learning Rate: 0.000393598
	LOSS [training: 0.4716844703833882 | validation: 0.74238590910336]
	TIME [epoch: 9.51 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47439105678638		[learning rate: 0.00039217]
	Learning Rate: 0.000392169
	LOSS [training: 0.47439105678638 | validation: 0.7923436032277574]
	TIME [epoch: 9.5 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48593418942562805		[learning rate: 0.00039075]
	Learning Rate: 0.000390746
	LOSS [training: 0.48593418942562805 | validation: 0.7631285087661195]
	TIME [epoch: 9.49 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45460951668612654		[learning rate: 0.00038933]
	Learning Rate: 0.000389328
	LOSS [training: 0.45460951668612654 | validation: 0.8014009209907738]
	TIME [epoch: 9.48 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5156041601553113		[learning rate: 0.00038792]
	Learning Rate: 0.000387915
	LOSS [training: 0.5156041601553113 | validation: 0.7756975230958778]
	TIME [epoch: 9.51 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5050826906939074		[learning rate: 0.00038651]
	Learning Rate: 0.000386508
	LOSS [training: 0.5050826906939074 | validation: 0.7864738133109651]
	TIME [epoch: 9.49 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46437715075354047		[learning rate: 0.0003851]
	Learning Rate: 0.000385105
	LOSS [training: 0.46437715075354047 | validation: 0.7668218980211167]
	TIME [epoch: 9.49 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4614324668297134		[learning rate: 0.00038371]
	Learning Rate: 0.000383707
	LOSS [training: 0.4614324668297134 | validation: 0.724144543648549]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_997.pth
	Model improved!!!
EPOCH 998/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4564473182766364		[learning rate: 0.00038231]
	Learning Rate: 0.000382315
	LOSS [training: 0.4564473182766364 | validation: 0.7730756597207697]
	TIME [epoch: 9.52 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49108865141857877		[learning rate: 0.00038093]
	Learning Rate: 0.000380927
	LOSS [training: 0.49108865141857877 | validation: 0.8086866546411912]
	TIME [epoch: 9.51 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49835951096990155		[learning rate: 0.00037954]
	Learning Rate: 0.000379545
	LOSS [training: 0.49835951096990155 | validation: 0.7641002359756276]
	TIME [epoch: 9.51 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45197251317497955		[learning rate: 0.00037817]
	Learning Rate: 0.000378167
	LOSS [training: 0.45197251317497955 | validation: 0.7715279832841947]
	TIME [epoch: 9.52 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5327601533432895		[learning rate: 0.0003768]
	Learning Rate: 0.000376795
	LOSS [training: 0.5327601533432895 | validation: 0.7813058798991327]
	TIME [epoch: 9.5 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48021766714560543		[learning rate: 0.00037543]
	Learning Rate: 0.000375428
	LOSS [training: 0.48021766714560543 | validation: 0.7830595027832717]
	TIME [epoch: 9.51 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47923873622087926		[learning rate: 0.00037407]
	Learning Rate: 0.000374065
	LOSS [training: 0.47923873622087926 | validation: 0.7763637503641349]
	TIME [epoch: 9.53 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4790350129417459		[learning rate: 0.00037271]
	Learning Rate: 0.000372708
	LOSS [training: 0.4790350129417459 | validation: 0.7972085979259523]
	TIME [epoch: 9.51 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5166248161044433		[learning rate: 0.00037136]
	Learning Rate: 0.000371355
	LOSS [training: 0.5166248161044433 | validation: 0.7741618872256968]
	TIME [epoch: 9.51 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4825171080341441		[learning rate: 0.00037001]
	Learning Rate: 0.000370008
	LOSS [training: 0.4825171080341441 | validation: 0.7624002080192176]
	TIME [epoch: 9.51 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46487103249902273		[learning rate: 0.00036866]
	Learning Rate: 0.000368665
	LOSS [training: 0.46487103249902273 | validation: 0.7736884204038756]
	TIME [epoch: 9.53 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47551054198441955		[learning rate: 0.00036733]
	Learning Rate: 0.000367327
	LOSS [training: 0.47551054198441955 | validation: 0.7689485753010431]
	TIME [epoch: 9.52 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5014037115922424		[learning rate: 0.00036599]
	Learning Rate: 0.000365994
	LOSS [training: 0.5014037115922424 | validation: 0.7692929765156055]
	TIME [epoch: 9.51 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5055764047810408		[learning rate: 0.00036467]
	Learning Rate: 0.000364666
	LOSS [training: 0.5055764047810408 | validation: 0.7649820512994567]
	TIME [epoch: 9.53 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4673867375821539		[learning rate: 0.00036334]
	Learning Rate: 0.000363342
	LOSS [training: 0.4673867375821539 | validation: 0.7321227501911779]
	TIME [epoch: 9.51 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4759853786689784		[learning rate: 0.00036202]
	Learning Rate: 0.000362024
	LOSS [training: 0.4759853786689784 | validation: 0.809729483580754]
	TIME [epoch: 9.5 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48463906473178814		[learning rate: 0.00036071]
	Learning Rate: 0.00036071
	LOSS [training: 0.48463906473178814 | validation: 0.7436446588434475]
	TIME [epoch: 9.51 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4951005546824797		[learning rate: 0.0003594]
	Learning Rate: 0.000359401
	LOSS [training: 0.4951005546824797 | validation: 0.7543836014151754]
	TIME [epoch: 9.53 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45018620784029045		[learning rate: 0.0003581]
	Learning Rate: 0.000358096
	LOSS [training: 0.45018620784029045 | validation: 0.774710565136635]
	TIME [epoch: 9.51 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4830949220052503		[learning rate: 0.0003568]
	Learning Rate: 0.000356797
	LOSS [training: 0.4830949220052503 | validation: 0.7604903885531556]
	TIME [epoch: 9.51 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4889395767558474		[learning rate: 0.0003555]
	Learning Rate: 0.000355502
	LOSS [training: 0.4889395767558474 | validation: 0.7558705595576757]
	TIME [epoch: 9.53 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47492925689332977		[learning rate: 0.00035421]
	Learning Rate: 0.000354212
	LOSS [training: 0.47492925689332977 | validation: 0.7648546706193434]
	TIME [epoch: 9.5 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4713456495531171		[learning rate: 0.00035293]
	Learning Rate: 0.000352926
	LOSS [training: 0.4713456495531171 | validation: 0.7330446680612408]
	TIME [epoch: 9.51 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4552442511330129		[learning rate: 0.00035165]
	Learning Rate: 0.000351646
	LOSS [training: 0.4552442511330129 | validation: 0.7688182694204239]
	TIME [epoch: 9.52 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4722663766910946		[learning rate: 0.00035037]
	Learning Rate: 0.00035037
	LOSS [training: 0.4722663766910946 | validation: 0.7350122557109142]
	TIME [epoch: 9.53 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48411554827276165		[learning rate: 0.0003491]
	Learning Rate: 0.000349098
	LOSS [training: 0.48411554827276165 | validation: 0.7753347827934519]
	TIME [epoch: 9.51 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5061161231289351		[learning rate: 0.00034783]
	Learning Rate: 0.000347831
	LOSS [training: 0.5061161231289351 | validation: 0.7562742900372317]
	TIME [epoch: 9.51 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5794479476307293		[learning rate: 0.00034657]
	Learning Rate: 0.000346569
	LOSS [training: 0.5794479476307293 | validation: 0.7573793216996301]
	TIME [epoch: 9.53 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4919831219606035		[learning rate: 0.00034531]
	Learning Rate: 0.000345311
	LOSS [training: 0.4919831219606035 | validation: 0.8000900884252724]
	TIME [epoch: 9.51 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5979955175704245		[learning rate: 0.00034406]
	Learning Rate: 0.000344058
	LOSS [training: 0.5979955175704245 | validation: 0.7646576852171221]
	TIME [epoch: 9.5 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4878959791226066		[learning rate: 0.00034281]
	Learning Rate: 0.000342809
	LOSS [training: 0.4878959791226066 | validation: 0.7630092212899723]
	TIME [epoch: 9.52 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4567204396870457		[learning rate: 0.00034157]
	Learning Rate: 0.000341565
	LOSS [training: 0.4567204396870457 | validation: 0.7478776074874727]
	TIME [epoch: 9.52 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47090558511388386		[learning rate: 0.00034033]
	Learning Rate: 0.000340326
	LOSS [training: 0.47090558511388386 | validation: 0.7741332213461611]
	TIME [epoch: 9.51 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.453313373177372		[learning rate: 0.00033909]
	Learning Rate: 0.000339091
	LOSS [training: 0.453313373177372 | validation: 0.7279387712267947]
	TIME [epoch: 9.51 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4596536616322496		[learning rate: 0.00033786]
	Learning Rate: 0.00033786
	LOSS [training: 0.4596536616322496 | validation: 0.7533247935742529]
	TIME [epoch: 9.53 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.478855066206387		[learning rate: 0.00033663]
	Learning Rate: 0.000336634
	LOSS [training: 0.478855066206387 | validation: 0.7646851358733119]
	TIME [epoch: 9.5 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4872560884588908		[learning rate: 0.00033541]
	Learning Rate: 0.000335412
	LOSS [training: 0.4872560884588908 | validation: 0.7353000202932676]
	TIME [epoch: 9.51 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5062504095979758		[learning rate: 0.0003342]
	Learning Rate: 0.000334195
	LOSS [training: 0.5062504095979758 | validation: 0.7585383884060554]
	TIME [epoch: 9.52 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4527740854317571		[learning rate: 0.00033298]
	Learning Rate: 0.000332982
	LOSS [training: 0.4527740854317571 | validation: 0.7877999233571836]
	TIME [epoch: 9.51 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47743131117914156		[learning rate: 0.00033177]
	Learning Rate: 0.000331774
	LOSS [training: 0.47743131117914156 | validation: 0.7290644511539524]
	TIME [epoch: 9.5 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4602785236886039		[learning rate: 0.00033057]
	Learning Rate: 0.00033057
	LOSS [training: 0.4602785236886039 | validation: 0.7498064960826786]
	TIME [epoch: 9.51 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45640660730883004		[learning rate: 0.00032937]
	Learning Rate: 0.00032937
	LOSS [training: 0.45640660730883004 | validation: 0.7272182108667121]
	TIME [epoch: 9.52 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5932045289407745		[learning rate: 0.00032817]
	Learning Rate: 0.000328175
	LOSS [training: 0.5932045289407745 | validation: 0.7356357101633476]
	TIME [epoch: 9.51 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4677056842026907		[learning rate: 0.00032698]
	Learning Rate: 0.000326984
	LOSS [training: 0.4677056842026907 | validation: 0.7514144898453249]
	TIME [epoch: 9.51 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5025247416162234		[learning rate: 0.0003258]
	Learning Rate: 0.000325797
	LOSS [training: 0.5025247416162234 | validation: 0.7318008535675022]
	TIME [epoch: 9.52 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46133766350622646		[learning rate: 0.00032461]
	Learning Rate: 0.000324615
	LOSS [training: 0.46133766350622646 | validation: 0.7494837764816003]
	TIME [epoch: 9.51 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4525650385719901		[learning rate: 0.00032344]
	Learning Rate: 0.000323437
	LOSS [training: 0.4525650385719901 | validation: 0.7704663963728956]
	TIME [epoch: 9.5 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47215851029964384		[learning rate: 0.00032226]
	Learning Rate: 0.000322263
	LOSS [training: 0.47215851029964384 | validation: 0.7936182551132841]
	TIME [epoch: 9.5 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4874155768878786		[learning rate: 0.00032109]
	Learning Rate: 0.000321094
	LOSS [training: 0.4874155768878786 | validation: 0.7706008055333291]
	TIME [epoch: 9.53 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4628271470473663		[learning rate: 0.00031993]
	Learning Rate: 0.000319928
	LOSS [training: 0.4628271470473663 | validation: 0.7673330916478469]
	TIME [epoch: 9.51 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4557275382530254		[learning rate: 0.00031877]
	Learning Rate: 0.000318767
	LOSS [training: 0.4557275382530254 | validation: 0.7512218543955749]
	TIME [epoch: 9.51 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4673797518014743		[learning rate: 0.00031761]
	Learning Rate: 0.000317611
	LOSS [training: 0.4673797518014743 | validation: 0.7642349221186586]
	TIME [epoch: 9.52 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47257891316727296		[learning rate: 0.00031646]
	Learning Rate: 0.000316458
	LOSS [training: 0.47257891316727296 | validation: 0.7462403365659225]
	TIME [epoch: 9.51 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44864019299113683		[learning rate: 0.00031531]
	Learning Rate: 0.000315309
	LOSS [training: 0.44864019299113683 | validation: 0.7347390871427035]
	TIME [epoch: 9.51 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4508432695051538		[learning rate: 0.00031417]
	Learning Rate: 0.000314165
	LOSS [training: 0.4508432695051538 | validation: 0.7773577395603676]
	TIME [epoch: 9.51 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4603026002427274		[learning rate: 0.00031302]
	Learning Rate: 0.000313025
	LOSS [training: 0.4603026002427274 | validation: 0.7503578519404962]
	TIME [epoch: 9.53 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4602441001768211		[learning rate: 0.00031189]
	Learning Rate: 0.000311889
	LOSS [training: 0.4602441001768211 | validation: 0.7779675490165037]
	TIME [epoch: 9.51 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45216903750047954		[learning rate: 0.00031076]
	Learning Rate: 0.000310757
	LOSS [training: 0.45216903750047954 | validation: 0.7898711202188281]
	TIME [epoch: 9.51 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.520373632144479		[learning rate: 0.00030963]
	Learning Rate: 0.000309629
	LOSS [training: 0.520373632144479 | validation: 0.780554687382058]
	TIME [epoch: 9.52 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4442738875347604		[learning rate: 0.00030851]
	Learning Rate: 0.000308506
	LOSS [training: 0.4442738875347604 | validation: 0.7273087065491981]
	TIME [epoch: 9.51 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46380178768212554		[learning rate: 0.00030739]
	Learning Rate: 0.000307386
	LOSS [training: 0.46380178768212554 | validation: 0.7314744716112483]
	TIME [epoch: 9.51 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4473269803189611		[learning rate: 0.00030627]
	Learning Rate: 0.000306271
	LOSS [training: 0.4473269803189611 | validation: 0.7570346681280424]
	TIME [epoch: 9.51 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45365180923934456		[learning rate: 0.00030516]
	Learning Rate: 0.000305159
	LOSS [training: 0.45365180923934456 | validation: 0.7991008096825435]
	TIME [epoch: 9.53 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5160234289289395		[learning rate: 0.00030405]
	Learning Rate: 0.000304052
	LOSS [training: 0.5160234289289395 | validation: 0.7618377378418826]
	TIME [epoch: 9.51 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4548956167944131		[learning rate: 0.00030295]
	Learning Rate: 0.000302948
	LOSS [training: 0.4548956167944131 | validation: 0.749754776215718]
	TIME [epoch: 9.51 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.462443764629881		[learning rate: 0.00030185]
	Learning Rate: 0.000301849
	LOSS [training: 0.462443764629881 | validation: 0.7461659178037019]
	TIME [epoch: 9.53 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4558960601084139		[learning rate: 0.00030075]
	Learning Rate: 0.000300753
	LOSS [training: 0.4558960601084139 | validation: 0.7993745280343094]
	TIME [epoch: 9.51 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5726809205308139		[learning rate: 0.00029966]
	Learning Rate: 0.000299662
	LOSS [training: 0.5726809205308139 | validation: 0.7736339859728153]
	TIME [epoch: 9.51 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4730741817547669		[learning rate: 0.00029857]
	Learning Rate: 0.000298574
	LOSS [training: 0.4730741817547669 | validation: 0.7288542303038986]
	TIME [epoch: 9.51 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4643984070884266		[learning rate: 0.00029749]
	Learning Rate: 0.000297491
	LOSS [training: 0.4643984070884266 | validation: 0.7551621875168567]
	TIME [epoch: 9.52 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.446367124221564		[learning rate: 0.00029641]
	Learning Rate: 0.000296411
	LOSS [training: 0.446367124221564 | validation: 0.7541581802537928]
	TIME [epoch: 9.51 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4801775089507247		[learning rate: 0.00029534]
	Learning Rate: 0.000295336
	LOSS [training: 0.4801775089507247 | validation: 0.7460087260428003]
	TIME [epoch: 9.5 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45874927895765183		[learning rate: 0.00029426]
	Learning Rate: 0.000294264
	LOSS [training: 0.45874927895765183 | validation: 0.7690124504674634]
	TIME [epoch: 9.53 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4768260227428871		[learning rate: 0.0002932]
	Learning Rate: 0.000293196
	LOSS [training: 0.4768260227428871 | validation: 0.7595783888668015]
	TIME [epoch: 9.51 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46833762821852876		[learning rate: 0.00029213]
	Learning Rate: 0.000292132
	LOSS [training: 0.46833762821852876 | validation: 0.7306712394504371]
	TIME [epoch: 9.51 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4716587995492413		[learning rate: 0.00029107]
	Learning Rate: 0.000291072
	LOSS [training: 0.4716587995492413 | validation: 0.7556233039139448]
	TIME [epoch: 9.52 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45871554555472993		[learning rate: 0.00029002]
	Learning Rate: 0.000290015
	LOSS [training: 0.45871554555472993 | validation: 0.8009120917301988]
	TIME [epoch: 9.52 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4859042100531033		[learning rate: 0.00028896]
	Learning Rate: 0.000288963
	LOSS [training: 0.4859042100531033 | validation: 0.7810210584472348]
	TIME [epoch: 9.5 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4429214775173113		[learning rate: 0.00028791]
	Learning Rate: 0.000287914
	LOSS [training: 0.4429214775173113 | validation: 0.7542321156839042]
	TIME [epoch: 9.51 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47026176676871845		[learning rate: 0.00028687]
	Learning Rate: 0.000286869
	LOSS [training: 0.47026176676871845 | validation: 0.7362081681890461]
	TIME [epoch: 9.52 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48946951822414275		[learning rate: 0.00028583]
	Learning Rate: 0.000285828
	LOSS [training: 0.48946951822414275 | validation: 0.7857050319475812]
	TIME [epoch: 9.5 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48748465456836765		[learning rate: 0.00028479]
	Learning Rate: 0.000284791
	LOSS [training: 0.48748465456836765 | validation: 0.735960287844881]
	TIME [epoch: 9.5 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46127845262152345		[learning rate: 0.00028376]
	Learning Rate: 0.000283758
	LOSS [training: 0.46127845262152345 | validation: 0.7327812024626413]
	TIME [epoch: 9.51 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44565269045644296		[learning rate: 0.00028273]
	Learning Rate: 0.000282728
	LOSS [training: 0.44565269045644296 | validation: 0.7717193160749741]
	TIME [epoch: 9.52 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4571395368527993		[learning rate: 0.0002817]
	Learning Rate: 0.000281702
	LOSS [training: 0.4571395368527993 | validation: 0.7595472910887403]
	TIME [epoch: 9.51 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4546886707815874		[learning rate: 0.00028068]
	Learning Rate: 0.000280679
	LOSS [training: 0.4546886707815874 | validation: 0.7381868137697376]
	TIME [epoch: 9.5 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4426673379928644		[learning rate: 0.00027966]
	Learning Rate: 0.000279661
	LOSS [training: 0.4426673379928644 | validation: 0.7601700314298756]
	TIME [epoch: 9.52 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4480086389184793		[learning rate: 0.00027865]
	Learning Rate: 0.000278646
	LOSS [training: 0.4480086389184793 | validation: 0.7725606866022926]
	TIME [epoch: 9.51 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45864746467566625		[learning rate: 0.00027763]
	Learning Rate: 0.000277635
	LOSS [training: 0.45864746467566625 | validation: 0.7551229226813397]
	TIME [epoch: 9.5 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43867984730676446		[learning rate: 0.00027663]
	Learning Rate: 0.000276627
	LOSS [training: 0.43867984730676446 | validation: 0.7690783044491022]
	TIME [epoch: 9.51 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4676939339217552		[learning rate: 0.00027562]
	Learning Rate: 0.000275623
	LOSS [training: 0.4676939339217552 | validation: 0.7492606906657104]
	TIME [epoch: 9.52 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4900097093632202		[learning rate: 0.00027462]
	Learning Rate: 0.000274623
	LOSS [training: 0.4900097093632202 | validation: 0.7206908297890772]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_1089.pth
	Model improved!!!
EPOCH 1090/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44961241410288233		[learning rate: 0.00027363]
	Learning Rate: 0.000273626
	LOSS [training: 0.44961241410288233 | validation: 0.8187297987748023]
	TIME [epoch: 9.5 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5528684686560688		[learning rate: 0.00027263]
	Learning Rate: 0.000272633
	LOSS [training: 0.5528684686560688 | validation: 0.7598612131684013]
	TIME [epoch: 9.51 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4715653938911181		[learning rate: 0.00027164]
	Learning Rate: 0.000271644
	LOSS [training: 0.4715653938911181 | validation: 0.7706019889657236]
	TIME [epoch: 9.5 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4534213360923743		[learning rate: 0.00027066]
	Learning Rate: 0.000270658
	LOSS [training: 0.4534213360923743 | validation: 0.7656191990723302]
	TIME [epoch: 9.5 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4844584436713581		[learning rate: 0.00026968]
	Learning Rate: 0.000269676
	LOSS [training: 0.4844584436713581 | validation: 0.768696241576234]
	TIME [epoch: 9.51 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48254953918503407		[learning rate: 0.0002687]
	Learning Rate: 0.000268697
	LOSS [training: 0.48254953918503407 | validation: 0.7754390937473418]
	TIME [epoch: 9.51 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47858479491825234		[learning rate: 0.00026772]
	Learning Rate: 0.000267722
	LOSS [training: 0.47858479491825234 | validation: 0.7509913769252435]
	TIME [epoch: 9.5 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.455619536055083		[learning rate: 0.00026675]
	Learning Rate: 0.000266751
	LOSS [training: 0.455619536055083 | validation: 0.78849478506841]
	TIME [epoch: 9.5 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.492352763175054		[learning rate: 0.00026578]
	Learning Rate: 0.000265782
	LOSS [training: 0.492352763175054 | validation: 0.8028567386538962]
	TIME [epoch: 9.52 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5139644293702398		[learning rate: 0.00026482]
	Learning Rate: 0.000264818
	LOSS [training: 0.5139644293702398 | validation: 0.7859189438509837]
	TIME [epoch: 9.49 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46855922883746476		[learning rate: 0.00026386]
	Learning Rate: 0.000263857
	LOSS [training: 0.46855922883746476 | validation: 0.7308780348437947]
	TIME [epoch: 9.49 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4470732242383767		[learning rate: 0.0002629]
	Learning Rate: 0.000262899
	LOSS [training: 0.4470732242383767 | validation: 0.7725842633565654]
	TIME [epoch: 9.5 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5158091075138909		[learning rate: 0.00026195]
	Learning Rate: 0.000261945
	LOSS [training: 0.5158091075138909 | validation: 0.7632280636827727]
	TIME [epoch: 9.51 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4654872923270437		[learning rate: 0.00026099]
	Learning Rate: 0.000260995
	LOSS [training: 0.4654872923270437 | validation: 0.7841575045578987]
	TIME [epoch: 9.5 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4563348708120296		[learning rate: 0.00026005]
	Learning Rate: 0.000260047
	LOSS [training: 0.4563348708120296 | validation: 0.7596427340534703]
	TIME [epoch: 9.51 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46780945379888905		[learning rate: 0.0002591]
	Learning Rate: 0.000259104
	LOSS [training: 0.46780945379888905 | validation: 0.7599361133769111]
	TIME [epoch: 9.51 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5001839682104471		[learning rate: 0.00025816]
	Learning Rate: 0.000258163
	LOSS [training: 0.5001839682104471 | validation: 0.7722496904608493]
	TIME [epoch: 9.5 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.51139010304161		[learning rate: 0.00025723]
	Learning Rate: 0.000257227
	LOSS [training: 0.51139010304161 | validation: 0.736911224693894]
	TIME [epoch: 9.5 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47857960726368204		[learning rate: 0.00025629]
	Learning Rate: 0.000256293
	LOSS [training: 0.47857960726368204 | validation: 0.7470136173578911]
	TIME [epoch: 9.51 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.493967545536034		[learning rate: 0.00025536]
	Learning Rate: 0.000255363
	LOSS [training: 0.493967545536034 | validation: 0.7656346581667228]
	TIME [epoch: 9.5 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4585151305508236		[learning rate: 0.00025444]
	Learning Rate: 0.000254436
	LOSS [training: 0.4585151305508236 | validation: 0.7534596604604212]
	TIME [epoch: 9.5 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4349635122800371		[learning rate: 0.00025351]
	Learning Rate: 0.000253513
	LOSS [training: 0.4349635122800371 | validation: 0.7400550330563803]
	TIME [epoch: 9.49 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4662247068013257		[learning rate: 0.00025259]
	Learning Rate: 0.000252593
	LOSS [training: 0.4662247068013257 | validation: 0.7555104115333936]
	TIME [epoch: 9.51 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4637143597560917		[learning rate: 0.00025168]
	Learning Rate: 0.000251676
	LOSS [training: 0.4637143597560917 | validation: 0.7577860394355815]
	TIME [epoch: 9.49 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4443903776228053		[learning rate: 0.00025076]
	Learning Rate: 0.000250763
	LOSS [training: 0.4443903776228053 | validation: 0.754535009146095]
	TIME [epoch: 9.49 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5421603789848276		[learning rate: 0.00024985]
	Learning Rate: 0.000249853
	LOSS [training: 0.5421603789848276 | validation: 0.798916187227353]
	TIME [epoch: 9.51 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47267364823430036		[learning rate: 0.00024895]
	Learning Rate: 0.000248946
	LOSS [training: 0.47267364823430036 | validation: 0.7596950354366232]
	TIME [epoch: 9.5 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4386887621625549		[learning rate: 0.00024804]
	Learning Rate: 0.000248043
	LOSS [training: 0.4386887621625549 | validation: 0.7506588826213272]
	TIME [epoch: 9.5 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49943190884908456		[learning rate: 0.00024714]
	Learning Rate: 0.000247142
	LOSS [training: 0.49943190884908456 | validation: 0.7861356225460219]
	TIME [epoch: 9.49 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48853214243647647		[learning rate: 0.00024625]
	Learning Rate: 0.000246246
	LOSS [training: 0.48853214243647647 | validation: 0.7641575266788226]
	TIME [epoch: 9.51 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.513742477673525		[learning rate: 0.00024535]
	Learning Rate: 0.000245352
	LOSS [training: 0.513742477673525 | validation: 0.7203331511557215]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_1120.pth
	Model improved!!!
EPOCH 1121/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44320177358870927		[learning rate: 0.00024446]
	Learning Rate: 0.000244462
	LOSS [training: 0.44320177358870927 | validation: 0.7634225002327818]
	TIME [epoch: 9.49 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44134436758994855		[learning rate: 0.00024357]
	Learning Rate: 0.000243574
	LOSS [training: 0.44134436758994855 | validation: 0.7510795764858769]
	TIME [epoch: 9.5 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44810721227258227		[learning rate: 0.00024269]
	Learning Rate: 0.00024269
	LOSS [training: 0.44810721227258227 | validation: 0.7528753876110369]
	TIME [epoch: 9.49 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4420116151528942		[learning rate: 0.00024181]
	Learning Rate: 0.00024181
	LOSS [training: 0.4420116151528942 | validation: 0.7331108479191597]
	TIME [epoch: 9.49 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44612522422278156		[learning rate: 0.00024093]
	Learning Rate: 0.000240932
	LOSS [training: 0.44612522422278156 | validation: 0.7330360796217624]
	TIME [epoch: 9.48 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44659404278812137		[learning rate: 0.00024006]
	Learning Rate: 0.000240058
	LOSS [training: 0.44659404278812137 | validation: 0.7632432244893522]
	TIME [epoch: 9.5 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4550764639416145		[learning rate: 0.00023919]
	Learning Rate: 0.000239187
	LOSS [training: 0.4550764639416145 | validation: 0.7613245120907268]
	TIME [epoch: 9.48 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48944059287031394		[learning rate: 0.00023832]
	Learning Rate: 0.000238319
	LOSS [training: 0.48944059287031394 | validation: 0.7510728260875951]
	TIME [epoch: 9.49 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45817798444268637		[learning rate: 0.00023745]
	Learning Rate: 0.000237454
	LOSS [training: 0.45817798444268637 | validation: 0.7518703418226111]
	TIME [epoch: 9.5 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4621536824638441		[learning rate: 0.00023659]
	Learning Rate: 0.000236592
	LOSS [training: 0.4621536824638441 | validation: 0.7339460840492867]
	TIME [epoch: 9.49 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4343434813939293		[learning rate: 0.00023573]
	Learning Rate: 0.000235733
	LOSS [training: 0.4343434813939293 | validation: 0.7681412883298913]
	TIME [epoch: 9.48 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4963069502094116		[learning rate: 0.00023488]
	Learning Rate: 0.000234878
	LOSS [training: 0.4963069502094116 | validation: 0.7510059262603624]
	TIME [epoch: 9.49 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5044722845215468		[learning rate: 0.00023403]
	Learning Rate: 0.000234026
	LOSS [training: 0.5044722845215468 | validation: 0.7861453245857931]
	TIME [epoch: 9.5 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4680149747326728		[learning rate: 0.00023318]
	Learning Rate: 0.000233176
	LOSS [training: 0.4680149747326728 | validation: 0.7405745772044654]
	TIME [epoch: 9.49 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4748112142197719		[learning rate: 0.00023233]
	Learning Rate: 0.00023233
	LOSS [training: 0.4748112142197719 | validation: 0.7301297246723949]
	TIME [epoch: 9.49 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43218715454796913		[learning rate: 0.00023149]
	Learning Rate: 0.000231487
	LOSS [training: 0.43218715454796913 | validation: 0.7484181243140573]
	TIME [epoch: 9.5 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43532238255945577		[learning rate: 0.00023065]
	Learning Rate: 0.000230647
	LOSS [training: 0.43532238255945577 | validation: 0.761053380129589]
	TIME [epoch: 9.49 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4259408777504034		[learning rate: 0.00022981]
	Learning Rate: 0.00022981
	LOSS [training: 0.4259408777504034 | validation: 0.7791545027060519]
	TIME [epoch: 9.49 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5386999422278772		[learning rate: 0.00022898]
	Learning Rate: 0.000228976
	LOSS [training: 0.5386999422278772 | validation: 0.7229866623139996]
	TIME [epoch: 9.49 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4591067636920007		[learning rate: 0.00022814]
	Learning Rate: 0.000228145
	LOSS [training: 0.4591067636920007 | validation: 0.7556315924970395]
	TIME [epoch: 9.5 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4562268058653004		[learning rate: 0.00022732]
	Learning Rate: 0.000227317
	LOSS [training: 0.4562268058653004 | validation: 0.7360396488377523]
	TIME [epoch: 9.49 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4440097878045267		[learning rate: 0.00022649]
	Learning Rate: 0.000226492
	LOSS [training: 0.4440097878045267 | validation: 0.7396421033868669]
	TIME [epoch: 9.48 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45081648701751603		[learning rate: 0.00022567]
	Learning Rate: 0.00022567
	LOSS [training: 0.45081648701751603 | validation: 0.7332200280027178]
	TIME [epoch: 9.5 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4433721424122409		[learning rate: 0.00022485]
	Learning Rate: 0.000224851
	LOSS [training: 0.4433721424122409 | validation: 0.7507518871755064]
	TIME [epoch: 9.48 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.433853950996337		[learning rate: 0.00022403]
	Learning Rate: 0.000224035
	LOSS [training: 0.433853950996337 | validation: 0.7389369349176219]
	TIME [epoch: 9.49 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4439297785680858		[learning rate: 0.00022322]
	Learning Rate: 0.000223222
	LOSS [training: 0.4439297785680858 | validation: 0.7489073668234031]
	TIME [epoch: 9.49 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45904849485600147		[learning rate: 0.00022241]
	Learning Rate: 0.000222412
	LOSS [training: 0.45904849485600147 | validation: 0.7702037989463102]
	TIME [epoch: 9.5 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4437757000888203		[learning rate: 0.0002216]
	Learning Rate: 0.000221605
	LOSS [training: 0.4437757000888203 | validation: 0.7891010033485449]
	TIME [epoch: 9.49 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45258075189034025		[learning rate: 0.0002208]
	Learning Rate: 0.0002208
	LOSS [training: 0.45258075189034025 | validation: 0.7658177864338478]
	TIME [epoch: 9.49 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4555836365704985		[learning rate: 0.00022]
	Learning Rate: 0.000219999
	LOSS [training: 0.4555836365704985 | validation: 0.741560740445577]
	TIME [epoch: 9.5 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.440667984575267		[learning rate: 0.0002192]
	Learning Rate: 0.000219201
	LOSS [training: 0.440667984575267 | validation: 0.7683209944881011]
	TIME [epoch: 9.48 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4552216117299143		[learning rate: 0.00021841]
	Learning Rate: 0.000218405
	LOSS [training: 0.4552216117299143 | validation: 0.7664457644854378]
	TIME [epoch: 9.48 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46716936130487313		[learning rate: 0.00021761]
	Learning Rate: 0.000217613
	LOSS [training: 0.46716936130487313 | validation: 0.7786347651292752]
	TIME [epoch: 9.48 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46050860800467036		[learning rate: 0.00021682]
	Learning Rate: 0.000216823
	LOSS [training: 0.46050860800467036 | validation: 0.7496519969491579]
	TIME [epoch: 9.5 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4409813662867669		[learning rate: 0.00021604]
	Learning Rate: 0.000216036
	LOSS [training: 0.4409813662867669 | validation: 0.758185276072562]
	TIME [epoch: 9.48 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44432456595807135		[learning rate: 0.00021525]
	Learning Rate: 0.000215252
	LOSS [training: 0.44432456595807135 | validation: 0.7489316893752394]
	TIME [epoch: 9.48 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5204294596629495		[learning rate: 0.00021447]
	Learning Rate: 0.000214471
	LOSS [training: 0.5204294596629495 | validation: 0.7453784152222767]
	TIME [epoch: 9.51 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.501483772752656		[learning rate: 0.00021369]
	Learning Rate: 0.000213693
	LOSS [training: 0.501483772752656 | validation: 0.7690283223204258]
	TIME [epoch: 9.49 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45156884887961457		[learning rate: 0.00021292]
	Learning Rate: 0.000212917
	LOSS [training: 0.45156884887961457 | validation: 0.7565283256252456]
	TIME [epoch: 9.48 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4472260953410262		[learning rate: 0.00021214]
	Learning Rate: 0.000212144
	LOSS [training: 0.4472260953410262 | validation: 0.7707875129377088]
	TIME [epoch: 9.49 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48710606482641106		[learning rate: 0.00021137]
	Learning Rate: 0.000211375
	LOSS [training: 0.48710606482641106 | validation: 0.7448399852981199]
	TIME [epoch: 9.5 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46507353107446797		[learning rate: 0.00021061]
	Learning Rate: 0.000210607
	LOSS [training: 0.46507353107446797 | validation: 0.7502701850992406]
	TIME [epoch: 9.48 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4704702513054964		[learning rate: 0.00020984]
	Learning Rate: 0.000209843
	LOSS [training: 0.4704702513054964 | validation: 0.7527657643598782]
	TIME [epoch: 9.48 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4527749258070172		[learning rate: 0.00020908]
	Learning Rate: 0.000209082
	LOSS [training: 0.4527749258070172 | validation: 0.732433788831868]
	TIME [epoch: 9.5 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45863445841115846		[learning rate: 0.00020832]
	Learning Rate: 0.000208323
	LOSS [training: 0.45863445841115846 | validation: 0.7295946195678272]
	TIME [epoch: 9.49 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4392480768586622		[learning rate: 0.00020757]
	Learning Rate: 0.000207567
	LOSS [training: 0.4392480768586622 | validation: 0.7556298840868979]
	TIME [epoch: 9.49 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4446896161751335		[learning rate: 0.00020681]
	Learning Rate: 0.000206814
	LOSS [training: 0.4446896161751335 | validation: 0.7482829470709609]
	TIME [epoch: 9.49 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4338135479961237		[learning rate: 0.00020606]
	Learning Rate: 0.000206063
	LOSS [training: 0.4338135479961237 | validation: 0.7402237845483889]
	TIME [epoch: 9.5 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48310677048817885		[learning rate: 0.00020532]
	Learning Rate: 0.000205315
	LOSS [training: 0.48310677048817885 | validation: 0.7726564321436482]
	TIME [epoch: 9.48 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44399593509916135		[learning rate: 0.00020457]
	Learning Rate: 0.00020457
	LOSS [training: 0.44399593509916135 | validation: 0.7185762002363774]
	TIME [epoch: 9.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_1170.pth
	Model improved!!!
EPOCH 1171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.466471114262658		[learning rate: 0.00020383]
	Learning Rate: 0.000203828
	LOSS [training: 0.466471114262658 | validation: 0.7319468577026587]
	TIME [epoch: 9.51 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4559777893540938		[learning rate: 0.00020309]
	Learning Rate: 0.000203088
	LOSS [training: 0.4559777893540938 | validation: 0.7204873252190445]
	TIME [epoch: 9.5 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4514479303199305		[learning rate: 0.00020235]
	Learning Rate: 0.000202351
	LOSS [training: 0.4514479303199305 | validation: 0.7745748651194202]
	TIME [epoch: 9.49 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.447394047611284		[learning rate: 0.00020162]
	Learning Rate: 0.000201617
	LOSS [training: 0.447394047611284 | validation: 0.7625736768445015]
	TIME [epoch: 9.51 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47036519521680836		[learning rate: 0.00020088]
	Learning Rate: 0.000200885
	LOSS [training: 0.47036519521680836 | validation: 0.7296329427493222]
	TIME [epoch: 9.5 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46051012106189715		[learning rate: 0.00020016]
	Learning Rate: 0.000200156
	LOSS [training: 0.46051012106189715 | validation: 0.7301393956107533]
	TIME [epoch: 9.49 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44799464619140084		[learning rate: 0.00019943]
	Learning Rate: 0.00019943
	LOSS [training: 0.44799464619140084 | validation: 0.7658854495572359]
	TIME [epoch: 9.49 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5808666272871515		[learning rate: 0.00019871]
	Learning Rate: 0.000198706
	LOSS [training: 0.5808666272871515 | validation: 0.7865792429976246]
	TIME [epoch: 9.51 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.472467259138837		[learning rate: 0.00019798]
	Learning Rate: 0.000197985
	LOSS [training: 0.472467259138837 | validation: 0.7335477150830648]
	TIME [epoch: 9.5 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4344746679004722		[learning rate: 0.00019727]
	Learning Rate: 0.000197266
	LOSS [training: 0.4344746679004722 | validation: 0.7488367682541548]
	TIME [epoch: 9.5 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4315417893107001		[learning rate: 0.00019655]
	Learning Rate: 0.00019655
	LOSS [training: 0.4315417893107001 | validation: 0.7423503937220673]
	TIME [epoch: 9.5 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45922180894512604		[learning rate: 0.00019584]
	Learning Rate: 0.000195837
	LOSS [training: 0.45922180894512604 | validation: 0.7389847727061002]
	TIME [epoch: 9.49 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4583160418705988		[learning rate: 0.00019513]
	Learning Rate: 0.000195126
	LOSS [training: 0.4583160418705988 | validation: 0.7287251447264768]
	TIME [epoch: 9.49 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46835139722847413		[learning rate: 0.00019442]
	Learning Rate: 0.000194418
	LOSS [training: 0.46835139722847413 | validation: 0.7162975952913323]
	TIME [epoch: 9.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_1184.pth
	Model improved!!!
EPOCH 1185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43929985654197656		[learning rate: 0.00019371]
	Learning Rate: 0.000193713
	LOSS [training: 0.43929985654197656 | validation: 0.7195275717077609]
	TIME [epoch: 9.52 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4444667406296112		[learning rate: 0.00019301]
	Learning Rate: 0.00019301
	LOSS [training: 0.4444667406296112 | validation: 0.7362475357662381]
	TIME [epoch: 9.49 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45951506056130204		[learning rate: 0.00019231]
	Learning Rate: 0.000192309
	LOSS [training: 0.45951506056130204 | validation: 0.748773250662457]
	TIME [epoch: 9.5 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43312493905335037		[learning rate: 0.00019161]
	Learning Rate: 0.000191611
	LOSS [training: 0.43312493905335037 | validation: 0.7542901681941397]
	TIME [epoch: 9.5 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4537397027427543		[learning rate: 0.00019092]
	Learning Rate: 0.000190916
	LOSS [training: 0.4537397027427543 | validation: 0.7164965672534461]
	TIME [epoch: 9.49 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45601077749248453		[learning rate: 0.00019022]
	Learning Rate: 0.000190223
	LOSS [training: 0.45601077749248453 | validation: 0.7551857363245096]
	TIME [epoch: 9.48 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46582969536390095		[learning rate: 0.00018953]
	Learning Rate: 0.000189533
	LOSS [training: 0.46582969536390095 | validation: 0.750073200026882]
	TIME [epoch: 9.49 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4752394173972621		[learning rate: 0.00018884]
	Learning Rate: 0.000188845
	LOSS [training: 0.4752394173972621 | validation: 0.7565694060723365]
	TIME [epoch: 9.5 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47671490367569225		[learning rate: 0.00018816]
	Learning Rate: 0.00018816
	LOSS [training: 0.47671490367569225 | validation: 0.7650876570352176]
	TIME [epoch: 9.48 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45875956379995275		[learning rate: 0.00018748]
	Learning Rate: 0.000187477
	LOSS [training: 0.45875956379995275 | validation: 0.7373937678600307]
	TIME [epoch: 9.48 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45352706709826734		[learning rate: 0.0001868]
	Learning Rate: 0.000186796
	LOSS [training: 0.45352706709826734 | validation: 0.7373075591551829]
	TIME [epoch: 9.5 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4372833279524165		[learning rate: 0.00018612]
	Learning Rate: 0.000186119
	LOSS [training: 0.4372833279524165 | validation: 0.7506033519572046]
	TIME [epoch: 9.49 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45294849603504767		[learning rate: 0.00018544]
	Learning Rate: 0.000185443
	LOSS [training: 0.45294849603504767 | validation: 0.751032520302033]
	TIME [epoch: 9.49 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4567497437866116		[learning rate: 0.00018477]
	Learning Rate: 0.00018477
	LOSS [training: 0.4567497437866116 | validation: 0.7287036450363238]
	TIME [epoch: 9.49 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4636433087131511		[learning rate: 0.0001841]
	Learning Rate: 0.000184099
	LOSS [training: 0.4636433087131511 | validation: 0.7716081913978223]
	TIME [epoch: 9.51 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4581363966183705		[learning rate: 0.00018343]
	Learning Rate: 0.000183431
	LOSS [training: 0.4581363966183705 | validation: 0.7153151994013317]
	TIME [epoch: 9.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_1200.pth
	Model improved!!!
EPOCH 1201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4504938575557406		[learning rate: 0.00018277]
	Learning Rate: 0.000182766
	LOSS [training: 0.4504938575557406 | validation: 0.7522299515085598]
	TIME [epoch: 9.48 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48146121478887166		[learning rate: 0.0001821]
	Learning Rate: 0.000182102
	LOSS [training: 0.48146121478887166 | validation: 0.7527342322751771]
	TIME [epoch: 9.5 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4801765340319252		[learning rate: 0.00018144]
	Learning Rate: 0.000181442
	LOSS [training: 0.4801765340319252 | validation: 0.7332396574658899]
	TIME [epoch: 9.49 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4832852520504651		[learning rate: 0.00018078]
	Learning Rate: 0.000180783
	LOSS [training: 0.4832852520504651 | validation: 0.7774042816840258]
	TIME [epoch: 9.49 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.505724984158425		[learning rate: 0.00018013]
	Learning Rate: 0.000180127
	LOSS [training: 0.505724984158425 | validation: 0.7604238074190027]
	TIME [epoch: 9.48 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44750916785974376		[learning rate: 0.00017947]
	Learning Rate: 0.000179473
	LOSS [training: 0.44750916785974376 | validation: 0.7409284807893337]
	TIME [epoch: 9.5 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46721868680424583		[learning rate: 0.00017882]
	Learning Rate: 0.000178822
	LOSS [training: 0.46721868680424583 | validation: 0.7779449532405001]
	TIME [epoch: 9.48 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46357617784976324		[learning rate: 0.00017817]
	Learning Rate: 0.000178173
	LOSS [training: 0.46357617784976324 | validation: 0.7220446485935217]
	TIME [epoch: 9.48 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4470411224767427		[learning rate: 0.00017753]
	Learning Rate: 0.000177526
	LOSS [training: 0.4470411224767427 | validation: 0.7546751449615344]
	TIME [epoch: 9.5 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45290620543035603		[learning rate: 0.00017688]
	Learning Rate: 0.000176882
	LOSS [training: 0.45290620543035603 | validation: 0.7271465164201166]
	TIME [epoch: 9.49 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4430068014346912		[learning rate: 0.00017624]
	Learning Rate: 0.00017624
	LOSS [training: 0.4430068014346912 | validation: 0.7289067636471458]
	TIME [epoch: 9.48 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4558916890234112		[learning rate: 0.0001756]
	Learning Rate: 0.000175601
	LOSS [training: 0.4558916890234112 | validation: 0.7449418014572953]
	TIME [epoch: 9.49 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4312430658906778		[learning rate: 0.00017496]
	Learning Rate: 0.000174964
	LOSS [training: 0.4312430658906778 | validation: 0.7270729713580922]
	TIME [epoch: 9.5 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4673999504066275		[learning rate: 0.00017433]
	Learning Rate: 0.000174329
	LOSS [training: 0.4673999504066275 | validation: 0.7566387007934533]
	TIME [epoch: 9.49 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46385739299649076		[learning rate: 0.0001737]
	Learning Rate: 0.000173696
	LOSS [training: 0.46385739299649076 | validation: 0.7713759249251885]
	TIME [epoch: 9.48 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46938908639663957		[learning rate: 0.00017307]
	Learning Rate: 0.000173066
	LOSS [training: 0.46938908639663957 | validation: 0.7403140443428147]
	TIME [epoch: 9.5 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4493469406255291		[learning rate: 0.00017244]
	Learning Rate: 0.000172437
	LOSS [training: 0.4493469406255291 | validation: 0.7437561658526428]
	TIME [epoch: 9.49 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4552159464171267		[learning rate: 0.00017181]
	Learning Rate: 0.000171812
	LOSS [training: 0.4552159464171267 | validation: 0.7639229810434036]
	TIME [epoch: 9.49 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44886453968534656		[learning rate: 0.00017119]
	Learning Rate: 0.000171188
	LOSS [training: 0.44886453968534656 | validation: 0.7549870153298232]
	TIME [epoch: 9.49 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45564148827866635		[learning rate: 0.00017057]
	Learning Rate: 0.000170567
	LOSS [training: 0.45564148827866635 | validation: 0.7560262613140708]
	TIME [epoch: 9.49 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45727624800097216		[learning rate: 0.00016995]
	Learning Rate: 0.000169948
	LOSS [training: 0.45727624800097216 | validation: 0.7533297635199878]
	TIME [epoch: 9.49 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4563306593590326		[learning rate: 0.00016933]
	Learning Rate: 0.000169331
	LOSS [training: 0.4563306593590326 | validation: 0.7363614478602437]
	TIME [epoch: 9.48 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43553944803248196		[learning rate: 0.00016872]
	Learning Rate: 0.000168717
	LOSS [training: 0.43553944803248196 | validation: 0.7392178203839238]
	TIME [epoch: 9.5 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4445110787524844		[learning rate: 0.0001681]
	Learning Rate: 0.000168104
	LOSS [training: 0.4445110787524844 | validation: 0.7332078353085862]
	TIME [epoch: 9.48 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4386297435346198		[learning rate: 0.00016749]
	Learning Rate: 0.000167494
	LOSS [training: 0.4386297435346198 | validation: 0.7398585710713442]
	TIME [epoch: 9.48 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4141160258128469		[learning rate: 0.00016689]
	Learning Rate: 0.000166886
	LOSS [training: 0.4141160258128469 | validation: 0.7306966324776767]
	TIME [epoch: 9.48 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4277335436848289		[learning rate: 0.00016628]
	Learning Rate: 0.000166281
	LOSS [training: 0.4277335436848289 | validation: 0.7285254494056926]
	TIME [epoch: 9.5 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4363619149425918		[learning rate: 0.00016568]
	Learning Rate: 0.000165677
	LOSS [training: 0.4363619149425918 | validation: 0.7199733920203791]
	TIME [epoch: 9.47 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4581732075920856		[learning rate: 0.00016508]
	Learning Rate: 0.000165076
	LOSS [training: 0.4581732075920856 | validation: 0.7348757596603136]
	TIME [epoch: 9.48 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43983228212266556		[learning rate: 0.00016448]
	Learning Rate: 0.000164477
	LOSS [training: 0.43983228212266556 | validation: 0.7594394808235491]
	TIME [epoch: 9.5 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44250063702501097		[learning rate: 0.00016388]
	Learning Rate: 0.00016388
	LOSS [training: 0.44250063702501097 | validation: 0.7471729675737407]
	TIME [epoch: 9.49 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4463619760050201		[learning rate: 0.00016329]
	Learning Rate: 0.000163285
	LOSS [training: 0.4463619760050201 | validation: 0.7263494412025553]
	TIME [epoch: 9.48 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4433412065086926		[learning rate: 0.00016269]
	Learning Rate: 0.000162693
	LOSS [training: 0.4433412065086926 | validation: 0.7457109737810405]
	TIME [epoch: 9.48 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4780493279883354		[learning rate: 0.0001621]
	Learning Rate: 0.000162102
	LOSS [training: 0.4780493279883354 | validation: 0.7687584498526093]
	TIME [epoch: 9.5 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47092022601873806		[learning rate: 0.00016151]
	Learning Rate: 0.000161514
	LOSS [training: 0.47092022601873806 | validation: 0.730870745778324]
	TIME [epoch: 9.48 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4625338672395115		[learning rate: 0.00016093]
	Learning Rate: 0.000160928
	LOSS [training: 0.4625338672395115 | validation: 0.7357657497777388]
	TIME [epoch: 9.48 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4519216654552882		[learning rate: 0.00016034]
	Learning Rate: 0.000160344
	LOSS [training: 0.4519216654552882 | validation: 0.7238981287589524]
	TIME [epoch: 9.49 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4612386271304002		[learning rate: 0.00015976]
	Learning Rate: 0.000159762
	LOSS [training: 0.4612386271304002 | validation: 0.746377658289537]
	TIME [epoch: 9.48 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4527737445830299		[learning rate: 0.00015918]
	Learning Rate: 0.000159182
	LOSS [training: 0.4527737445830299 | validation: 0.7441463647830148]
	TIME [epoch: 9.48 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4520788144309442		[learning rate: 0.0001586]
	Learning Rate: 0.000158605
	LOSS [training: 0.4520788144309442 | validation: 0.7520115355549607]
	TIME [epoch: 9.48 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43618600739855945		[learning rate: 0.00015803]
	Learning Rate: 0.000158029
	LOSS [training: 0.43618600739855945 | validation: 0.7282547496295]
	TIME [epoch: 9.5 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46536416008607073		[learning rate: 0.00015746]
	Learning Rate: 0.000157456
	LOSS [training: 0.46536416008607073 | validation: 0.745448115654752]
	TIME [epoch: 9.48 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44090962544125406		[learning rate: 0.00015688]
	Learning Rate: 0.000156884
	LOSS [training: 0.44090962544125406 | validation: 0.7537627909379565]
	TIME [epoch: 9.48 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46697840833601106		[learning rate: 0.00015631]
	Learning Rate: 0.000156315
	LOSS [training: 0.46697840833601106 | validation: 0.7491266999007092]
	TIME [epoch: 9.5 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4559242149563694		[learning rate: 0.00015575]
	Learning Rate: 0.000155748
	LOSS [training: 0.4559242149563694 | validation: 0.7718686857703878]
	TIME [epoch: 9.48 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4377237032769732		[learning rate: 0.00015518]
	Learning Rate: 0.000155182
	LOSS [training: 0.4377237032769732 | validation: 0.7281472291503707]
	TIME [epoch: 9.48 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43583841609108037		[learning rate: 0.00015462]
	Learning Rate: 0.000154619
	LOSS [training: 0.43583841609108037 | validation: 0.7382288736849888]
	TIME [epoch: 9.49 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4396302079161556		[learning rate: 0.00015406]
	Learning Rate: 0.000154058
	LOSS [training: 0.4396302079161556 | validation: 0.7313364609107739]
	TIME [epoch: 9.51 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4864053757293507		[learning rate: 0.0001535]
	Learning Rate: 0.000153499
	LOSS [training: 0.4864053757293507 | validation: 0.7434171882347664]
	TIME [epoch: 9.48 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4750164939053739		[learning rate: 0.00015294]
	Learning Rate: 0.000152942
	LOSS [training: 0.4750164939053739 | validation: 0.7496063510584055]
	TIME [epoch: 9.48 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5213215702940096		[learning rate: 0.00015239]
	Learning Rate: 0.000152387
	LOSS [training: 0.5213215702940096 | validation: 0.7296994481630441]
	TIME [epoch: 9.5 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4679601936573598		[learning rate: 0.00015183]
	Learning Rate: 0.000151834
	LOSS [training: 0.4679601936573598 | validation: 0.7359015389484573]
	TIME [epoch: 9.49 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4341955994210654		[learning rate: 0.00015128]
	Learning Rate: 0.000151283
	LOSS [training: 0.4341955994210654 | validation: 0.7031064766466614]
	TIME [epoch: 9.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_1253.pth
	Model improved!!!
EPOCH 1254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4321838475111434		[learning rate: 0.00015073]
	Learning Rate: 0.000150734
	LOSS [training: 0.4321838475111434 | validation: 0.7209089601124598]
	TIME [epoch: 9.5 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4889012135796337		[learning rate: 0.00015019]
	Learning Rate: 0.000150187
	LOSS [training: 0.4889012135796337 | validation: 0.7296765020113748]
	TIME [epoch: 9.49 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4287382637095874		[learning rate: 0.00014964]
	Learning Rate: 0.000149642
	LOSS [training: 0.4287382637095874 | validation: 0.7214207883943015]
	TIME [epoch: 9.49 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4396173641243548		[learning rate: 0.0001491]
	Learning Rate: 0.000149099
	LOSS [training: 0.4396173641243548 | validation: 0.7156379000596159]
	TIME [epoch: 9.49 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4354094820652432		[learning rate: 0.00014856]
	Learning Rate: 0.000148558
	LOSS [training: 0.4354094820652432 | validation: 0.7491643928362233]
	TIME [epoch: 9.51 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42300524888692426		[learning rate: 0.00014802]
	Learning Rate: 0.000148018
	LOSS [training: 0.42300524888692426 | validation: 0.7568635977600048]
	TIME [epoch: 9.49 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4351246885066938		[learning rate: 0.00014748]
	Learning Rate: 0.000147481
	LOSS [training: 0.4351246885066938 | validation: 0.7404891473669009]
	TIME [epoch: 9.49 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43897825170544796		[learning rate: 0.00014695]
	Learning Rate: 0.000146946
	LOSS [training: 0.43897825170544796 | validation: 0.7265188035370101]
	TIME [epoch: 9.51 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42356994192446196		[learning rate: 0.00014641]
	Learning Rate: 0.000146413
	LOSS [training: 0.42356994192446196 | validation: 0.7438040281720172]
	TIME [epoch: 9.5 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43718570879759566		[learning rate: 0.00014588]
	Learning Rate: 0.000145881
	LOSS [training: 0.43718570879759566 | validation: 0.751515084387653]
	TIME [epoch: 9.48 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43734601838906134		[learning rate: 0.00014535]
	Learning Rate: 0.000145352
	LOSS [training: 0.43734601838906134 | validation: 0.7103685749834765]
	TIME [epoch: 9.49 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4321656240063785		[learning rate: 0.00014482]
	Learning Rate: 0.000144825
	LOSS [training: 0.4321656240063785 | validation: 0.7554072045068746]
	TIME [epoch: 9.5 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4510403108653767		[learning rate: 0.0001443]
	Learning Rate: 0.000144299
	LOSS [training: 0.4510403108653767 | validation: 0.7588223695498352]
	TIME [epoch: 9.49 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4536879862600195		[learning rate: 0.00014378]
	Learning Rate: 0.000143775
	LOSS [training: 0.4536879862600195 | validation: 0.7445532573092456]
	TIME [epoch: 9.49 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4269243552208729		[learning rate: 0.00014325]
	Learning Rate: 0.000143253
	LOSS [training: 0.4269243552208729 | validation: 0.7227084633090399]
	TIME [epoch: 9.5 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44225146915219493		[learning rate: 0.00014273]
	Learning Rate: 0.000142734
	LOSS [training: 0.44225146915219493 | validation: 0.7380622811658631]
	TIME [epoch: 9.49 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4286165129823026		[learning rate: 0.00014222]
	Learning Rate: 0.000142216
	LOSS [training: 0.4286165129823026 | validation: 0.7461844771117453]
	TIME [epoch: 9.49 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43232075707651807		[learning rate: 0.0001417]
	Learning Rate: 0.0001417
	LOSS [training: 0.43232075707651807 | validation: 0.7242397196689235]
	TIME [epoch: 9.49 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44857341086901076		[learning rate: 0.00014119]
	Learning Rate: 0.000141185
	LOSS [training: 0.44857341086901076 | validation: 0.735777518983474]
	TIME [epoch: 9.5 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4432418747827591		[learning rate: 0.00014067]
	Learning Rate: 0.000140673
	LOSS [training: 0.4432418747827591 | validation: 0.7466306432988634]
	TIME [epoch: 9.5 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46051305334887094		[learning rate: 0.00014016]
	Learning Rate: 0.000140162
	LOSS [training: 0.46051305334887094 | validation: 0.7254042735368336]
	TIME [epoch: 9.49 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44030277446589683		[learning rate: 0.00013965]
	Learning Rate: 0.000139654
	LOSS [training: 0.44030277446589683 | validation: 0.7246674850766425]
	TIME [epoch: 9.51 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43197088032542286		[learning rate: 0.00013915]
	Learning Rate: 0.000139147
	LOSS [training: 0.43197088032542286 | validation: 0.7597152720889565]
	TIME [epoch: 9.49 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45243902060774444		[learning rate: 0.00013864]
	Learning Rate: 0.000138642
	LOSS [training: 0.45243902060774444 | validation: 0.7468543420639293]
	TIME [epoch: 9.49 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4344700036257332		[learning rate: 0.00013814]
	Learning Rate: 0.000138139
	LOSS [training: 0.4344700036257332 | validation: 0.7424576063484566]
	TIME [epoch: 9.49 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4466225985115318		[learning rate: 0.00013764]
	Learning Rate: 0.000137638
	LOSS [training: 0.4466225985115318 | validation: 0.7481024779064347]
	TIME [epoch: 9.51 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43667296139056927		[learning rate: 0.00013714]
	Learning Rate: 0.000137138
	LOSS [training: 0.43667296139056927 | validation: 0.7446236772991597]
	TIME [epoch: 9.49 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4296193735494541		[learning rate: 0.00013664]
	Learning Rate: 0.00013664
	LOSS [training: 0.4296193735494541 | validation: 0.7414730087106728]
	TIME [epoch: 9.49 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42348349547312125		[learning rate: 0.00013614]
	Learning Rate: 0.000136144
	LOSS [training: 0.42348349547312125 | validation: 0.7403476207022991]
	TIME [epoch: 9.51 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4433049020423427		[learning rate: 0.00013565]
	Learning Rate: 0.00013565
	LOSS [training: 0.4433049020423427 | validation: 0.7507996152496879]
	TIME [epoch: 9.49 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4454331912730942		[learning rate: 0.00013516]
	Learning Rate: 0.000135158
	LOSS [training: 0.4454331912730942 | validation: 0.7387198478535046]
	TIME [epoch: 9.49 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4454987489211863		[learning rate: 0.00013467]
	Learning Rate: 0.000134668
	LOSS [training: 0.4454987489211863 | validation: 0.7312762441501982]
	TIME [epoch: 9.49 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46083447861713883		[learning rate: 0.00013418]
	Learning Rate: 0.000134179
	LOSS [training: 0.46083447861713883 | validation: 0.7168618618954707]
	TIME [epoch: 9.52 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4580901884476753		[learning rate: 0.00013369]
	Learning Rate: 0.000133692
	LOSS [training: 0.4580901884476753 | validation: 0.7243714298284151]
	TIME [epoch: 9.49 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4513382510846453		[learning rate: 0.00013321]
	Learning Rate: 0.000133207
	LOSS [training: 0.4513382510846453 | validation: 0.7232295759926564]
	TIME [epoch: 9.49 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43569902087857104		[learning rate: 0.00013272]
	Learning Rate: 0.000132723
	LOSS [training: 0.43569902087857104 | validation: 0.7072585728420779]
	TIME [epoch: 9.5 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43761666404405164		[learning rate: 0.00013224]
	Learning Rate: 0.000132242
	LOSS [training: 0.43761666404405164 | validation: 0.7423455274968648]
	TIME [epoch: 9.51 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44231308200465635		[learning rate: 0.00013176]
	Learning Rate: 0.000131762
	LOSS [training: 0.44231308200465635 | validation: 0.7270106889634447]
	TIME [epoch: 9.5 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4308243528013632		[learning rate: 0.00013128]
	Learning Rate: 0.000131284
	LOSS [training: 0.4308243528013632 | validation: 0.7224750631819059]
	TIME [epoch: 9.49 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44404348007272976		[learning rate: 0.00013081]
	Learning Rate: 0.000130807
	LOSS [training: 0.44404348007272976 | validation: 0.7456873063894213]
	TIME [epoch: 9.51 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42710852937370997		[learning rate: 0.00013033]
	Learning Rate: 0.000130332
	LOSS [training: 0.42710852937370997 | validation: 0.7183331704720775]
	TIME [epoch: 9.49 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43938069109929023		[learning rate: 0.00012986]
	Learning Rate: 0.000129859
	LOSS [training: 0.43938069109929023 | validation: 0.7527265162460754]
	TIME [epoch: 9.49 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44087023170563455		[learning rate: 0.00012939]
	Learning Rate: 0.000129388
	LOSS [training: 0.44087023170563455 | validation: 0.7385545826290411]
	TIME [epoch: 9.5 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43829990895553517		[learning rate: 0.00012892]
	Learning Rate: 0.000128919
	LOSS [training: 0.43829990895553517 | validation: 0.7364414051799265]
	TIME [epoch: 9.5 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4582363343745536		[learning rate: 0.00012845]
	Learning Rate: 0.000128451
	LOSS [training: 0.4582363343745536 | validation: 0.7227761242540407]
	TIME [epoch: 9.49 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4635518077183791		[learning rate: 0.00012798]
	Learning Rate: 0.000127985
	LOSS [training: 0.4635518077183791 | validation: 0.7219630393374971]
	TIME [epoch: 9.49 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4404632453883951		[learning rate: 0.00012752]
	Learning Rate: 0.00012752
	LOSS [training: 0.4404632453883951 | validation: 0.7351758211321038]
	TIME [epoch: 9.5 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4618264320557352		[learning rate: 0.00012706]
	Learning Rate: 0.000127057
	LOSS [training: 0.4618264320557352 | validation: 0.7401130596648742]
	TIME [epoch: 9.49 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4548226521528358		[learning rate: 0.0001266]
	Learning Rate: 0.000126596
	LOSS [training: 0.4548226521528358 | validation: 0.7444408963408821]
	TIME [epoch: 9.49 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4500033398439974		[learning rate: 0.00012614]
	Learning Rate: 0.000126137
	LOSS [training: 0.4500033398439974 | validation: 0.7587667069746626]
	TIME [epoch: 9.5 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5044609598285071		[learning rate: 0.00012568]
	Learning Rate: 0.000125679
	LOSS [training: 0.5044609598285071 | validation: 0.7465689657433007]
	TIME [epoch: 9.5 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46219784444225287		[learning rate: 0.00012522]
	Learning Rate: 0.000125223
	LOSS [training: 0.46219784444225287 | validation: 0.7510915319644326]
	TIME [epoch: 9.49 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4593583900277933		[learning rate: 0.00012477]
	Learning Rate: 0.000124769
	LOSS [training: 0.4593583900277933 | validation: 0.7345969709693767]
	TIME [epoch: 9.49 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46072037995918835		[learning rate: 0.00012432]
	Learning Rate: 0.000124316
	LOSS [training: 0.46072037995918835 | validation: 0.7536522582096195]
	TIME [epoch: 9.5 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45345282133610587		[learning rate: 0.00012386]
	Learning Rate: 0.000123865
	LOSS [training: 0.45345282133610587 | validation: 0.7419961803836108]
	TIME [epoch: 9.49 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43122164120867373		[learning rate: 0.00012342]
	Learning Rate: 0.000123415
	LOSS [training: 0.43122164120867373 | validation: 0.7530891386678235]
	TIME [epoch: 9.49 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4557115074813197		[learning rate: 0.00012297]
	Learning Rate: 0.000122967
	LOSS [training: 0.4557115074813197 | validation: 0.730596979223912]
	TIME [epoch: 9.51 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4798711447072518		[learning rate: 0.00012252]
	Learning Rate: 0.000122521
	LOSS [training: 0.4798711447072518 | validation: 0.7503200644819694]
	TIME [epoch: 9.49 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.444886834452315		[learning rate: 0.00012208]
	Learning Rate: 0.000122076
	LOSS [training: 0.444886834452315 | validation: 0.7497375104392054]
	TIME [epoch: 9.49 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44096145312998536		[learning rate: 0.00012163]
	Learning Rate: 0.000121633
	LOSS [training: 0.44096145312998536 | validation: 0.7292264839802144]
	TIME [epoch: 9.49 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4600413463791021		[learning rate: 0.00012119]
	Learning Rate: 0.000121192
	LOSS [training: 0.4600413463791021 | validation: 0.7422121115877363]
	TIME [epoch: 9.51 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44516925547690517		[learning rate: 0.00012075]
	Learning Rate: 0.000120752
	LOSS [training: 0.44516925547690517 | validation: 0.7178879795211784]
	TIME [epoch: 9.49 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4675853585013689		[learning rate: 0.00012031]
	Learning Rate: 0.000120314
	LOSS [training: 0.4675853585013689 | validation: 0.7159133095354209]
	TIME [epoch: 9.49 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49148387483566847		[learning rate: 0.00011988]
	Learning Rate: 0.000119877
	LOSS [training: 0.49148387483566847 | validation: 0.7502637297615605]
	TIME [epoch: 9.51 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4707004741604533		[learning rate: 0.00011944]
	Learning Rate: 0.000119442
	LOSS [training: 0.4707004741604533 | validation: 0.7079288458228458]
	TIME [epoch: 9.5 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4566799637714712		[learning rate: 0.00011901]
	Learning Rate: 0.000119009
	LOSS [training: 0.4566799637714712 | validation: 0.7340690778071647]
	TIME [epoch: 9.49 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44039961216414253		[learning rate: 0.00011858]
	Learning Rate: 0.000118577
	LOSS [training: 0.44039961216414253 | validation: 0.747071811208439]
	TIME [epoch: 9.49 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42740756936337254		[learning rate: 0.00011815]
	Learning Rate: 0.000118147
	LOSS [training: 0.42740756936337254 | validation: 0.7451922560039428]
	TIME [epoch: 9.51 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.447798608321886		[learning rate: 0.00011772]
	Learning Rate: 0.000117718
	LOSS [training: 0.447798608321886 | validation: 0.7142736801914393]
	TIME [epoch: 9.49 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4317578592817289		[learning rate: 0.00011729]
	Learning Rate: 0.000117291
	LOSS [training: 0.4317578592817289 | validation: 0.7057508331138442]
	TIME [epoch: 9.5 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4403357091966891		[learning rate: 0.00011686]
	Learning Rate: 0.000116865
	LOSS [training: 0.4403357091966891 | validation: 0.7332855767352285]
	TIME [epoch: 9.51 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44098383507977823		[learning rate: 0.00011644]
	Learning Rate: 0.000116441
	LOSS [training: 0.44098383507977823 | validation: 0.7636807658981885]
	TIME [epoch: 9.49 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4372449742468896		[learning rate: 0.00011602]
	Learning Rate: 0.000116018
	LOSS [training: 0.4372449742468896 | validation: 0.7400340920162324]
	TIME [epoch: 9.5 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4531486925085801		[learning rate: 0.0001156]
	Learning Rate: 0.000115597
	LOSS [training: 0.4531486925085801 | validation: 0.7339586174894198]
	TIME [epoch: 9.5 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4338634381169384		[learning rate: 0.00011518]
	Learning Rate: 0.000115178
	LOSS [training: 0.4338634381169384 | validation: 0.7189981265895458]
	TIME [epoch: 9.5 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4526764068643634		[learning rate: 0.00011476]
	Learning Rate: 0.00011476
	LOSS [training: 0.4526764068643634 | validation: 0.7456028803063066]
	TIME [epoch: 9.5 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42832832876736215		[learning rate: 0.00011434]
	Learning Rate: 0.000114343
	LOSS [training: 0.42832832876736215 | validation: 0.7336223731757072]
	TIME [epoch: 9.49 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.437785422275143		[learning rate: 0.00011393]
	Learning Rate: 0.000113928
	LOSS [training: 0.437785422275143 | validation: 0.7275813913302838]
	TIME [epoch: 9.51 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4542251325632217		[learning rate: 0.00011351]
	Learning Rate: 0.000113515
	LOSS [training: 0.4542251325632217 | validation: 0.7264880909760377]
	TIME [epoch: 9.49 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42974017714537166		[learning rate: 0.0001131]
	Learning Rate: 0.000113103
	LOSS [training: 0.42974017714537166 | validation: 0.744767768152592]
	TIME [epoch: 9.49 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42636177399108544		[learning rate: 0.00011269]
	Learning Rate: 0.000112692
	LOSS [training: 0.42636177399108544 | validation: 0.7495700206927953]
	TIME [epoch: 9.51 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4512425455979283		[learning rate: 0.00011228]
	Learning Rate: 0.000112283
	LOSS [training: 0.4512425455979283 | validation: 0.7340944428789353]
	TIME [epoch: 9.5 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43089592826766		[learning rate: 0.00011188]
	Learning Rate: 0.000111876
	LOSS [training: 0.43089592826766 | validation: 0.7503086122953324]
	TIME [epoch: 9.5 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43705348327954585		[learning rate: 0.00011147]
	Learning Rate: 0.00011147
	LOSS [training: 0.43705348327954585 | validation: 0.7176290737027471]
	TIME [epoch: 9.49 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42514484873928904		[learning rate: 0.00011107]
	Learning Rate: 0.000111065
	LOSS [training: 0.42514484873928904 | validation: 0.7367610973343454]
	TIME [epoch: 9.52 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43768627686294403		[learning rate: 0.00011066]
	Learning Rate: 0.000110662
	LOSS [training: 0.43768627686294403 | validation: 0.7390265047854091]
	TIME [epoch: 9.49 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43943040502940073		[learning rate: 0.00011026]
	Learning Rate: 0.000110261
	LOSS [training: 0.43943040502940073 | validation: 0.7334885792747742]
	TIME [epoch: 9.49 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4322547177967168		[learning rate: 0.00010986]
	Learning Rate: 0.000109861
	LOSS [training: 0.4322547177967168 | validation: 0.7467567631433909]
	TIME [epoch: 9.5 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4331177900971441		[learning rate: 0.00010946]
	Learning Rate: 0.000109462
	LOSS [training: 0.4331177900971441 | validation: 0.7526765158269256]
	TIME [epoch: 9.5 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41572581859450725		[learning rate: 0.00010906]
	Learning Rate: 0.000109065
	LOSS [training: 0.41572581859450725 | validation: 0.7324800673170979]
	TIME [epoch: 9.49 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.429283769901122		[learning rate: 0.00010867]
	Learning Rate: 0.000108669
	LOSS [training: 0.429283769901122 | validation: 0.721227371111909]
	TIME [epoch: 9.49 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42957041221675246		[learning rate: 0.00010827]
	Learning Rate: 0.000108275
	LOSS [training: 0.42957041221675246 | validation: 0.7364285594704809]
	TIME [epoch: 9.51 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4402565900756441		[learning rate: 0.00010788]
	Learning Rate: 0.000107882
	LOSS [training: 0.4402565900756441 | validation: 0.7132324739539253]
	TIME [epoch: 9.49 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4411516127046447		[learning rate: 0.00010749]
	Learning Rate: 0.00010749
	LOSS [training: 0.4411516127046447 | validation: 0.7322262290196784]
	TIME [epoch: 9.49 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47595166416954654		[learning rate: 0.0001071]
	Learning Rate: 0.0001071
	LOSS [training: 0.47595166416954654 | validation: 0.7360327912518045]
	TIME [epoch: 9.5 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45369326633226326		[learning rate: 0.00010671]
	Learning Rate: 0.000106711
	LOSS [training: 0.45369326633226326 | validation: 0.7218481620825401]
	TIME [epoch: 9.5 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4291664068496884		[learning rate: 0.00010632]
	Learning Rate: 0.000106324
	LOSS [training: 0.4291664068496884 | validation: 0.7398113212350913]
	TIME [epoch: 9.49 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43313051898218563		[learning rate: 0.00010594]
	Learning Rate: 0.000105938
	LOSS [training: 0.43313051898218563 | validation: 0.7293456301136572]
	TIME [epoch: 9.49 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4346691470832595		[learning rate: 0.00010555]
	Learning Rate: 0.000105554
	LOSS [training: 0.4346691470832595 | validation: 0.7336216023499423]
	TIME [epoch: 9.51 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42717632101738523		[learning rate: 0.00010517]
	Learning Rate: 0.000105171
	LOSS [training: 0.42717632101738523 | validation: 0.7290823446791346]
	TIME [epoch: 9.49 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43289326054826593		[learning rate: 0.00010479]
	Learning Rate: 0.000104789
	LOSS [training: 0.43289326054826593 | validation: 0.7210059993404512]
	TIME [epoch: 9.49 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42418693733401874		[learning rate: 0.00010441]
	Learning Rate: 0.000104409
	LOSS [training: 0.42418693733401874 | validation: 0.743832706928431]
	TIME [epoch: 9.51 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42953075426067483		[learning rate: 0.00010403]
	Learning Rate: 0.00010403
	LOSS [training: 0.42953075426067483 | validation: 0.6960162820904572]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_1356.pth
	Model improved!!!
EPOCH 1357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42194117196399344		[learning rate: 0.00010365]
	Learning Rate: 0.000103652
	LOSS [training: 0.42194117196399344 | validation: 0.7383050595860623]
	TIME [epoch: 9.49 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4304894891602988		[learning rate: 0.00010328]
	Learning Rate: 0.000103276
	LOSS [training: 0.4304894891602988 | validation: 0.7571820365838398]
	TIME [epoch: 9.48 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4542172740209741		[learning rate: 0.0001029]
	Learning Rate: 0.000102901
	LOSS [training: 0.4542172740209741 | validation: 0.7236952753420787]
	TIME [epoch: 9.5 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48069540964436913		[learning rate: 0.00010253]
	Learning Rate: 0.000102528
	LOSS [training: 0.48069540964436913 | validation: 0.7435160190423261]
	TIME [epoch: 9.49 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43397349095969817		[learning rate: 0.00010216]
	Learning Rate: 0.000102156
	LOSS [training: 0.43397349095969817 | validation: 0.7306308573549553]
	TIME [epoch: 9.49 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43821637252403045		[learning rate: 0.00010179]
	Learning Rate: 0.000101785
	LOSS [training: 0.43821637252403045 | validation: 0.7294874486766925]
	TIME [epoch: 9.51 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4283110925456602		[learning rate: 0.00010142]
	Learning Rate: 0.000101416
	LOSS [training: 0.4283110925456602 | validation: 0.7294107064277696]
	TIME [epoch: 9.49 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4190755953454463		[learning rate: 0.00010105]
	Learning Rate: 0.000101048
	LOSS [training: 0.4190755953454463 | validation: 0.7325209227195616]
	TIME [epoch: 9.49 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4194280935947591		[learning rate: 0.00010068]
	Learning Rate: 0.000100681
	LOSS [training: 0.4194280935947591 | validation: 0.7414323838436846]
	TIME [epoch: 9.49 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4326711802207857		[learning rate: 0.00010032]
	Learning Rate: 0.000100316
	LOSS [training: 0.4326711802207857 | validation: 0.7540948140158134]
	TIME [epoch: 9.51 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4515666546990408		[learning rate: 9.9952e-05]
	Learning Rate: 9.99515e-05
	LOSS [training: 0.4515666546990408 | validation: 0.7517963487957532]
	TIME [epoch: 9.48 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46037633007234985		[learning rate: 9.9589e-05]
	Learning Rate: 9.95888e-05
	LOSS [training: 0.46037633007234985 | validation: 0.7446616855452975]
	TIME [epoch: 9.48 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45539989007085524		[learning rate: 9.9227e-05]
	Learning Rate: 9.92274e-05
	LOSS [training: 0.45539989007085524 | validation: 0.7463663245864045]
	TIME [epoch: 9.5 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44376968541472417		[learning rate: 9.8867e-05]
	Learning Rate: 9.88673e-05
	LOSS [training: 0.44376968541472417 | validation: 0.7480668009674196]
	TIME [epoch: 9.48 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4544033525941427		[learning rate: 9.8509e-05]
	Learning Rate: 9.85085e-05
	LOSS [training: 0.4544033525941427 | validation: 0.7404398637348095]
	TIME [epoch: 9.49 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42052556291169785		[learning rate: 9.8151e-05]
	Learning Rate: 9.8151e-05
	LOSS [training: 0.42052556291169785 | validation: 0.7491886318974501]
	TIME [epoch: 9.48 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4283580556325594		[learning rate: 9.7795e-05]
	Learning Rate: 9.77948e-05
	LOSS [training: 0.4283580556325594 | validation: 0.7380724878455245]
	TIME [epoch: 9.5 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42580406958571226		[learning rate: 9.744e-05]
	Learning Rate: 9.74399e-05
	LOSS [training: 0.42580406958571226 | validation: 0.7231591283891149]
	TIME [epoch: 9.48 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4256838490987508		[learning rate: 9.7086e-05]
	Learning Rate: 9.70863e-05
	LOSS [training: 0.4256838490987508 | validation: 0.7578351043305301]
	TIME [epoch: 9.49 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4328464230785161		[learning rate: 9.6734e-05]
	Learning Rate: 9.6734e-05
	LOSS [training: 0.4328464230785161 | validation: 0.7373854170727377]
	TIME [epoch: 9.49 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.431279082176378		[learning rate: 9.6383e-05]
	Learning Rate: 9.63829e-05
	LOSS [training: 0.431279082176378 | validation: 0.720865983594518]
	TIME [epoch: 9.49 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4401264732152096		[learning rate: 9.6033e-05]
	Learning Rate: 9.60331e-05
	LOSS [training: 0.4401264732152096 | validation: 0.7600654808574698]
	TIME [epoch: 9.48 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4354524485717862		[learning rate: 9.5685e-05]
	Learning Rate: 9.56846e-05
	LOSS [training: 0.4354524485717862 | validation: 0.7521564569330232]
	TIME [epoch: 9.49 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43071098398956675		[learning rate: 9.5337e-05]
	Learning Rate: 9.53374e-05
	LOSS [training: 0.43071098398956675 | validation: 0.7466347919501379]
	TIME [epoch: 9.5 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4185020667811892		[learning rate: 9.4991e-05]
	Learning Rate: 9.49914e-05
	LOSS [training: 0.4185020667811892 | validation: 0.7159402417019125]
	TIME [epoch: 9.49 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4200143062826047		[learning rate: 9.4647e-05]
	Learning Rate: 9.46466e-05
	LOSS [training: 0.4200143062826047 | validation: 0.7217863439510106]
	TIME [epoch: 9.48 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44647772605823066		[learning rate: 9.4303e-05]
	Learning Rate: 9.43032e-05
	LOSS [training: 0.44647772605823066 | validation: 0.7230010613982123]
	TIME [epoch: 9.51 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42051125886237883		[learning rate: 9.3961e-05]
	Learning Rate: 9.39609e-05
	LOSS [training: 0.42051125886237883 | validation: 0.7090426243707529]
	TIME [epoch: 9.49 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43660827501991417		[learning rate: 9.362e-05]
	Learning Rate: 9.362e-05
	LOSS [training: 0.43660827501991417 | validation: 0.7339087442357851]
	TIME [epoch: 9.49 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4251436185796118		[learning rate: 9.328e-05]
	Learning Rate: 9.32802e-05
	LOSS [training: 0.4251436185796118 | validation: 0.7367188571505822]
	TIME [epoch: 9.5 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42431604583656773		[learning rate: 9.2942e-05]
	Learning Rate: 9.29417e-05
	LOSS [training: 0.42431604583656773 | validation: 0.7007442649364617]
	TIME [epoch: 9.51 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4444096010352883		[learning rate: 9.2604e-05]
	Learning Rate: 9.26044e-05
	LOSS [training: 0.4444096010352883 | validation: 0.7509298089770218]
	TIME [epoch: 9.48 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45868317061932923		[learning rate: 9.2268e-05]
	Learning Rate: 9.22683e-05
	LOSS [training: 0.45868317061932923 | validation: 0.7574010028367212]
	TIME [epoch: 9.49 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4616776319025053		[learning rate: 9.1933e-05]
	Learning Rate: 9.19335e-05
	LOSS [training: 0.4616776319025053 | validation: 0.7481766994527401]
	TIME [epoch: 9.5 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4267501591536439		[learning rate: 9.16e-05]
	Learning Rate: 9.15998e-05
	LOSS [training: 0.4267501591536439 | validation: 0.7470600374435119]
	TIME [epoch: 9.49 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4337487282225395		[learning rate: 9.1267e-05]
	Learning Rate: 9.12674e-05
	LOSS [training: 0.4337487282225395 | validation: 0.7275648929413175]
	TIME [epoch: 9.49 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43543954196895857		[learning rate: 9.0936e-05]
	Learning Rate: 9.09362e-05
	LOSS [training: 0.43543954196895857 | validation: 0.7221541412176317]
	TIME [epoch: 9.5 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4532834335444632		[learning rate: 9.0606e-05]
	Learning Rate: 9.06062e-05
	LOSS [training: 0.4532834335444632 | validation: 0.7230388313106161]
	TIME [epoch: 9.51 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46357743936962426		[learning rate: 9.0277e-05]
	Learning Rate: 9.02774e-05
	LOSS [training: 0.46357743936962426 | validation: 0.7287752550922011]
	TIME [epoch: 9.49 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46336798902124665		[learning rate: 8.995e-05]
	Learning Rate: 8.99498e-05
	LOSS [training: 0.46336798902124665 | validation: 0.7568072938959135]
	TIME [epoch: 9.49 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44511023781679837		[learning rate: 8.9623e-05]
	Learning Rate: 8.96233e-05
	LOSS [training: 0.44511023781679837 | validation: 0.7077322773550817]
	TIME [epoch: 9.51 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43444052482675255		[learning rate: 8.9298e-05]
	Learning Rate: 8.92981e-05
	LOSS [training: 0.43444052482675255 | validation: 0.7248106318287946]
	TIME [epoch: 9.49 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4384829173412064		[learning rate: 8.8974e-05]
	Learning Rate: 8.8974e-05
	LOSS [training: 0.4384829173412064 | validation: 0.728990266109814]
	TIME [epoch: 9.49 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44775241278279976		[learning rate: 8.8651e-05]
	Learning Rate: 8.86511e-05
	LOSS [training: 0.44775241278279976 | validation: 0.7638195461339167]
	TIME [epoch: 9.5 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44445522113935176		[learning rate: 8.8329e-05]
	Learning Rate: 8.83294e-05
	LOSS [training: 0.44445522113935176 | validation: 0.7386714472565561]
	TIME [epoch: 9.51 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4519762767362153		[learning rate: 8.8009e-05]
	Learning Rate: 8.80088e-05
	LOSS [training: 0.4519762767362153 | validation: 0.7353974406725192]
	TIME [epoch: 9.49 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.435230776799479		[learning rate: 8.7689e-05]
	Learning Rate: 8.76895e-05
	LOSS [training: 0.435230776799479 | validation: 0.741830001715871]
	TIME [epoch: 9.49 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44254250490088276		[learning rate: 8.7371e-05]
	Learning Rate: 8.73712e-05
	LOSS [training: 0.44254250490088276 | validation: 0.7461075878958963]
	TIME [epoch: 9.51 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4476212881299858		[learning rate: 8.7054e-05]
	Learning Rate: 8.70542e-05
	LOSS [training: 0.4476212881299858 | validation: 0.73784322740145]
	TIME [epoch: 9.49 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4458564478254168		[learning rate: 8.6738e-05]
	Learning Rate: 8.67382e-05
	LOSS [training: 0.4458564478254168 | validation: 0.7197291443534107]
	TIME [epoch: 9.49 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4219670695061297		[learning rate: 8.6423e-05]
	Learning Rate: 8.64235e-05
	LOSS [training: 0.4219670695061297 | validation: 0.7267407277854961]
	TIME [epoch: 9.5 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43024620630184496		[learning rate: 8.611e-05]
	Learning Rate: 8.61098e-05
	LOSS [training: 0.43024620630184496 | validation: 0.7341352447885103]
	TIME [epoch: 9.51 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43448201519710183		[learning rate: 8.5797e-05]
	Learning Rate: 8.57973e-05
	LOSS [training: 0.43448201519710183 | validation: 0.7350926687966528]
	TIME [epoch: 9.49 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43159857023342846		[learning rate: 8.5486e-05]
	Learning Rate: 8.54859e-05
	LOSS [training: 0.43159857023342846 | validation: 0.727874977970452]
	TIME [epoch: 9.49 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4289514120200346		[learning rate: 8.5176e-05]
	Learning Rate: 8.51757e-05
	LOSS [training: 0.4289514120200346 | validation: 0.7365551678303026]
	TIME [epoch: 9.52 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.426173523264943		[learning rate: 8.4867e-05]
	Learning Rate: 8.48666e-05
	LOSS [training: 0.426173523264943 | validation: 0.7369576497196016]
	TIME [epoch: 9.5 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41404430821577726		[learning rate: 8.4559e-05]
	Learning Rate: 8.45586e-05
	LOSS [training: 0.41404430821577726 | validation: 0.7299561343840917]
	TIME [epoch: 9.49 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4358328484038861		[learning rate: 8.4252e-05]
	Learning Rate: 8.42518e-05
	LOSS [training: 0.4358328484038861 | validation: 0.7418955401602431]
	TIME [epoch: 9.51 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43997699921163225		[learning rate: 8.3946e-05]
	Learning Rate: 8.3946e-05
	LOSS [training: 0.43997699921163225 | validation: 0.7438318188234078]
	TIME [epoch: 9.5 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4222799129038125		[learning rate: 8.3641e-05]
	Learning Rate: 8.36414e-05
	LOSS [training: 0.4222799129038125 | validation: 0.7266376686736342]
	TIME [epoch: 9.49 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43790001721355265		[learning rate: 8.3338e-05]
	Learning Rate: 8.33378e-05
	LOSS [training: 0.43790001721355265 | validation: 0.7437447178317622]
	TIME [epoch: 9.49 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4273489097874611		[learning rate: 8.3035e-05]
	Learning Rate: 8.30354e-05
	LOSS [training: 0.4273489097874611 | validation: 0.7184199974187385]
	TIME [epoch: 9.51 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4211660000915514		[learning rate: 8.2734e-05]
	Learning Rate: 8.2734e-05
	LOSS [training: 0.4211660000915514 | validation: 0.7297303833017671]
	TIME [epoch: 9.49 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43713476360936915		[learning rate: 8.2434e-05]
	Learning Rate: 8.24338e-05
	LOSS [training: 0.43713476360936915 | validation: 0.7605721855913288]
	TIME [epoch: 9.49 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4195671705857912		[learning rate: 8.2135e-05]
	Learning Rate: 8.21346e-05
	LOSS [training: 0.4195671705857912 | validation: 0.7331789226067142]
	TIME [epoch: 9.5 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43149796738306945		[learning rate: 8.1837e-05]
	Learning Rate: 8.18366e-05
	LOSS [training: 0.43149796738306945 | validation: 0.726401075886965]
	TIME [epoch: 9.49 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44309672819620527		[learning rate: 8.154e-05]
	Learning Rate: 8.15396e-05
	LOSS [training: 0.44309672819620527 | validation: 0.7323415834792959]
	TIME [epoch: 9.49 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4496683175708721		[learning rate: 8.1244e-05]
	Learning Rate: 8.12437e-05
	LOSS [training: 0.4496683175708721 | validation: 0.7331713269333789]
	TIME [epoch: 9.49 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44938373207811155		[learning rate: 8.0949e-05]
	Learning Rate: 8.09488e-05
	LOSS [training: 0.44938373207811155 | validation: 0.7173350030661968]
	TIME [epoch: 9.51 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43102236199474475		[learning rate: 8.0655e-05]
	Learning Rate: 8.0655e-05
	LOSS [training: 0.43102236199474475 | validation: 0.7388181860808085]
	TIME [epoch: 9.49 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4413335543131625		[learning rate: 8.0362e-05]
	Learning Rate: 8.03623e-05
	LOSS [training: 0.4413335543131625 | validation: 0.7340178532050087]
	TIME [epoch: 9.49 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43185309724479637		[learning rate: 8.0071e-05]
	Learning Rate: 8.00707e-05
	LOSS [training: 0.43185309724479637 | validation: 0.7229874179992158]
	TIME [epoch: 9.5 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42258030820358244		[learning rate: 7.978e-05]
	Learning Rate: 7.97801e-05
	LOSS [training: 0.42258030820358244 | validation: 0.7324724189804871]
	TIME [epoch: 9.5 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4291882859353125		[learning rate: 7.9491e-05]
	Learning Rate: 7.94906e-05
	LOSS [training: 0.4291882859353125 | validation: 0.7197046255949718]
	TIME [epoch: 9.49 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43255090307284305		[learning rate: 7.9202e-05]
	Learning Rate: 7.92021e-05
	LOSS [training: 0.43255090307284305 | validation: 0.7490335979635142]
	TIME [epoch: 9.5 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4069659857787017		[learning rate: 7.8915e-05]
	Learning Rate: 7.89147e-05
	LOSS [training: 0.4069659857787017 | validation: 0.7282923783120535]
	TIME [epoch: 9.51 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4141642664822503		[learning rate: 7.8628e-05]
	Learning Rate: 7.86283e-05
	LOSS [training: 0.4141642664822503 | validation: 0.7508996128788724]
	TIME [epoch: 9.49 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4354602689176927		[learning rate: 7.8343e-05]
	Learning Rate: 7.8343e-05
	LOSS [training: 0.4354602689176927 | validation: 0.7268451040127747]
	TIME [epoch: 9.5 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42234788004740587		[learning rate: 7.8059e-05]
	Learning Rate: 7.80586e-05
	LOSS [training: 0.42234788004740587 | validation: 0.7440561150081704]
	TIME [epoch: 9.5 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42706378995680366		[learning rate: 7.7775e-05]
	Learning Rate: 7.77754e-05
	LOSS [training: 0.42706378995680366 | validation: 0.7302321465725108]
	TIME [epoch: 9.5 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4201036568819749		[learning rate: 7.7493e-05]
	Learning Rate: 7.74931e-05
	LOSS [training: 0.4201036568819749 | validation: 0.7412156114668628]
	TIME [epoch: 9.5 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43289113038831006		[learning rate: 7.7212e-05]
	Learning Rate: 7.72119e-05
	LOSS [training: 0.43289113038831006 | validation: 0.7134537596942964]
	TIME [epoch: 9.49 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4299408648781363		[learning rate: 7.6932e-05]
	Learning Rate: 7.69317e-05
	LOSS [training: 0.4299408648781363 | validation: 0.7497272084953338]
	TIME [epoch: 9.52 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43619327320777607		[learning rate: 7.6653e-05]
	Learning Rate: 7.66525e-05
	LOSS [training: 0.43619327320777607 | validation: 0.7122609895607914]
	TIME [epoch: 9.49 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.433479813466619		[learning rate: 7.6374e-05]
	Learning Rate: 7.63743e-05
	LOSS [training: 0.433479813466619 | validation: 0.7134138296134814]
	TIME [epoch: 9.49 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4161223473952937		[learning rate: 7.6097e-05]
	Learning Rate: 7.60972e-05
	LOSS [training: 0.4161223473952937 | validation: 0.7002672810481251]
	TIME [epoch: 9.5 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41883877988795487		[learning rate: 7.5821e-05]
	Learning Rate: 7.5821e-05
	LOSS [training: 0.41883877988795487 | validation: 0.7306250119667717]
	TIME [epoch: 9.5 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42462339438652774		[learning rate: 7.5546e-05]
	Learning Rate: 7.55458e-05
	LOSS [training: 0.42462339438652774 | validation: 0.69422436769109]
	TIME [epoch: 9.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_1444.pth
	Model improved!!!
EPOCH 1445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.411402010289794		[learning rate: 7.5272e-05]
	Learning Rate: 7.52717e-05
	LOSS [training: 0.411402010289794 | validation: 0.7450140466617545]
	TIME [epoch: 9.49 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42350480197255636		[learning rate: 7.4999e-05]
	Learning Rate: 7.49985e-05
	LOSS [training: 0.42350480197255636 | validation: 0.7158591540393059]
	TIME [epoch: 9.51 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41902455589719095		[learning rate: 7.4726e-05]
	Learning Rate: 7.47263e-05
	LOSS [training: 0.41902455589719095 | validation: 0.7277091440999957]
	TIME [epoch: 9.48 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.430148894700889		[learning rate: 7.4455e-05]
	Learning Rate: 7.44552e-05
	LOSS [training: 0.430148894700889 | validation: 0.7275384935522399]
	TIME [epoch: 9.49 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44042084437785867		[learning rate: 7.4185e-05]
	Learning Rate: 7.4185e-05
	LOSS [training: 0.44042084437785867 | validation: 0.7378600228396833]
	TIME [epoch: 9.5 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43431429185854303		[learning rate: 7.3916e-05]
	Learning Rate: 7.39157e-05
	LOSS [training: 0.43431429185854303 | validation: 0.7337570593732845]
	TIME [epoch: 9.49 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4196386816273536		[learning rate: 7.3647e-05]
	Learning Rate: 7.36475e-05
	LOSS [training: 0.4196386816273536 | validation: 0.714709076718854]
	TIME [epoch: 9.48 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4327317850708985		[learning rate: 7.338e-05]
	Learning Rate: 7.33802e-05
	LOSS [training: 0.4327317850708985 | validation: 0.7407304802923597]
	TIME [epoch: 9.48 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4904649254582202		[learning rate: 7.3114e-05]
	Learning Rate: 7.31139e-05
	LOSS [training: 0.4904649254582202 | validation: 0.7086591159464655]
	TIME [epoch: 9.5 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4515063808405003		[learning rate: 7.2849e-05]
	Learning Rate: 7.28486e-05
	LOSS [training: 0.4515063808405003 | validation: 0.7302249525828558]
	TIME [epoch: 9.48 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42466015672223484		[learning rate: 7.2584e-05]
	Learning Rate: 7.25842e-05
	LOSS [training: 0.42466015672223484 | validation: 0.7080868633258137]
	TIME [epoch: 9.49 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.422555603773476		[learning rate: 7.2321e-05]
	Learning Rate: 7.23208e-05
	LOSS [training: 0.422555603773476 | validation: 0.7203010544003184]
	TIME [epoch: 9.5 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4344002809189316		[learning rate: 7.2058e-05]
	Learning Rate: 7.20583e-05
	LOSS [training: 0.4344002809189316 | validation: 0.73729137410265]
	TIME [epoch: 9.48 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41779083266889644		[learning rate: 7.1797e-05]
	Learning Rate: 7.17968e-05
	LOSS [training: 0.41779083266889644 | validation: 0.7398907548920134]
	TIME [epoch: 9.48 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4178709323575226		[learning rate: 7.1536e-05]
	Learning Rate: 7.15363e-05
	LOSS [training: 0.4178709323575226 | validation: 0.7179000041393812]
	TIME [epoch: 9.49 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41880047958835237		[learning rate: 7.1277e-05]
	Learning Rate: 7.12767e-05
	LOSS [training: 0.41880047958835237 | validation: 0.7305881747905529]
	TIME [epoch: 9.51 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42649981265406733		[learning rate: 7.1018e-05]
	Learning Rate: 7.1018e-05
	LOSS [training: 0.42649981265406733 | validation: 0.7418756101473238]
	TIME [epoch: 9.49 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42785707201582096		[learning rate: 7.076e-05]
	Learning Rate: 7.07603e-05
	LOSS [training: 0.42785707201582096 | validation: 0.724381992868204]
	TIME [epoch: 9.49 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4173962580754548		[learning rate: 7.0503e-05]
	Learning Rate: 7.05035e-05
	LOSS [training: 0.4173962580754548 | validation: 0.7344343385865051]
	TIME [epoch: 9.51 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4300606021211042		[learning rate: 7.0248e-05]
	Learning Rate: 7.02476e-05
	LOSS [training: 0.4300606021211042 | validation: 0.7060449379876327]
	TIME [epoch: 9.49 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4163091911839162		[learning rate: 6.9993e-05]
	Learning Rate: 6.99927e-05
	LOSS [training: 0.4163091911839162 | validation: 0.7053616175212158]
	TIME [epoch: 9.48 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4207303501806655		[learning rate: 6.9739e-05]
	Learning Rate: 6.97387e-05
	LOSS [training: 0.4207303501806655 | validation: 0.71069026038112]
	TIME [epoch: 9.49 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43883139959439826		[learning rate: 6.9486e-05]
	Learning Rate: 6.94856e-05
	LOSS [training: 0.43883139959439826 | validation: 0.7017342573280649]
	TIME [epoch: 9.51 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42497106310393107		[learning rate: 6.9233e-05]
	Learning Rate: 6.92334e-05
	LOSS [training: 0.42497106310393107 | validation: 0.7507878675136144]
	TIME [epoch: 9.49 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4129111729539526		[learning rate: 6.8982e-05]
	Learning Rate: 6.89822e-05
	LOSS [training: 0.4129111729539526 | validation: 0.7446399582665868]
	TIME [epoch: 9.49 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42065575195827887		[learning rate: 6.8732e-05]
	Learning Rate: 6.87318e-05
	LOSS [training: 0.42065575195827887 | validation: 0.7316800114528078]
	TIME [epoch: 9.5 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4299804349921691		[learning rate: 6.8482e-05]
	Learning Rate: 6.84824e-05
	LOSS [training: 0.4299804349921691 | validation: 0.7438441242766481]
	TIME [epoch: 9.49 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42675708111594945		[learning rate: 6.8234e-05]
	Learning Rate: 6.82339e-05
	LOSS [training: 0.42675708111594945 | validation: 0.7393117815775944]
	TIME [epoch: 9.48 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4255311963145874		[learning rate: 6.7986e-05]
	Learning Rate: 6.79862e-05
	LOSS [training: 0.4255311963145874 | validation: 0.7199092650722291]
	TIME [epoch: 9.49 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4212822172469502		[learning rate: 6.774e-05]
	Learning Rate: 6.77395e-05
	LOSS [training: 0.4212822172469502 | validation: 0.732719844182745]
	TIME [epoch: 9.51 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40917934691301683		[learning rate: 6.7494e-05]
	Learning Rate: 6.74937e-05
	LOSS [training: 0.40917934691301683 | validation: 0.748850084301821]
	TIME [epoch: 9.49 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4218154073229039		[learning rate: 6.7249e-05]
	Learning Rate: 6.72488e-05
	LOSS [training: 0.4218154073229039 | validation: 0.744289094648961]
	TIME [epoch: 9.48 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4205365420130824		[learning rate: 6.7005e-05]
	Learning Rate: 6.70047e-05
	LOSS [training: 0.4205365420130824 | validation: 0.7271255575764384]
	TIME [epoch: 9.51 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4338295661260963		[learning rate: 6.6762e-05]
	Learning Rate: 6.67616e-05
	LOSS [training: 0.4338295661260963 | validation: 0.7016965621070069]
	TIME [epoch: 9.48 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42465427250478494		[learning rate: 6.6519e-05]
	Learning Rate: 6.65192e-05
	LOSS [training: 0.42465427250478494 | validation: 0.744583263216143]
	TIME [epoch: 9.49 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4084160295629496		[learning rate: 6.6278e-05]
	Learning Rate: 6.62778e-05
	LOSS [training: 0.4084160295629496 | validation: 0.7175897106048283]
	TIME [epoch: 9.49 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4233703067966127		[learning rate: 6.6037e-05]
	Learning Rate: 6.60373e-05
	LOSS [training: 0.4233703067966127 | validation: 0.7336058459023588]
	TIME [epoch: 9.5 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4075102998792278		[learning rate: 6.5798e-05]
	Learning Rate: 6.57977e-05
	LOSS [training: 0.4075102998792278 | validation: 0.6974388940490277]
	TIME [epoch: 9.49 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42244568961911727		[learning rate: 6.5559e-05]
	Learning Rate: 6.55589e-05
	LOSS [training: 0.42244568961911727 | validation: 0.7096025034000215]
	TIME [epoch: 9.49 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42153455603150525		[learning rate: 6.5321e-05]
	Learning Rate: 6.5321e-05
	LOSS [training: 0.42153455603150525 | validation: 0.7214999617685274]
	TIME [epoch: 9.5 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4210934241729807		[learning rate: 6.5084e-05]
	Learning Rate: 6.50839e-05
	LOSS [training: 0.4210934241729807 | validation: 0.7077344378821573]
	TIME [epoch: 9.49 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41831242026838256		[learning rate: 6.4848e-05]
	Learning Rate: 6.48477e-05
	LOSS [training: 0.41831242026838256 | validation: 0.7217393321190736]
	TIME [epoch: 9.49 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42463624438541425		[learning rate: 6.4612e-05]
	Learning Rate: 6.46124e-05
	LOSS [training: 0.42463624438541425 | validation: 0.7321443573761258]
	TIME [epoch: 9.5 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4280517757310619		[learning rate: 6.4378e-05]
	Learning Rate: 6.43779e-05
	LOSS [training: 0.4280517757310619 | validation: 0.7440620460560264]
	TIME [epoch: 9.51 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42523110992740765		[learning rate: 6.4144e-05]
	Learning Rate: 6.41443e-05
	LOSS [training: 0.42523110992740765 | validation: 0.7319765697224625]
	TIME [epoch: 9.48 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42140279229775		[learning rate: 6.3911e-05]
	Learning Rate: 6.39115e-05
	LOSS [training: 0.42140279229775 | validation: 0.7256162801635602]
	TIME [epoch: 9.48 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41961654960818107		[learning rate: 6.368e-05]
	Learning Rate: 6.36795e-05
	LOSS [training: 0.41961654960818107 | validation: 0.7236715283911096]
	TIME [epoch: 9.5 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43928938082770835		[learning rate: 6.3448e-05]
	Learning Rate: 6.34485e-05
	LOSS [training: 0.43928938082770835 | validation: 0.7249925476797986]
	TIME [epoch: 9.49 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45703606368534927		[learning rate: 6.3218e-05]
	Learning Rate: 6.32182e-05
	LOSS [training: 0.45703606368534927 | validation: 0.734673737612816]
	TIME [epoch: 9.49 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44354785388967316		[learning rate: 6.2989e-05]
	Learning Rate: 6.29888e-05
	LOSS [training: 0.44354785388967316 | validation: 0.7266972969050738]
	TIME [epoch: 9.5 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4202561920888046		[learning rate: 6.276e-05]
	Learning Rate: 6.27602e-05
	LOSS [training: 0.4202561920888046 | validation: 0.7177180070605694]
	TIME [epoch: 9.5 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43176558331548226		[learning rate: 6.2532e-05]
	Learning Rate: 6.25324e-05
	LOSS [training: 0.43176558331548226 | validation: 0.7317776466219293]
	TIME [epoch: 9.49 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43697719848581107		[learning rate: 6.2305e-05]
	Learning Rate: 6.23055e-05
	LOSS [training: 0.43697719848581107 | validation: 0.7519560163131681]
	TIME [epoch: 9.49 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4502524596702527		[learning rate: 6.2079e-05]
	Learning Rate: 6.20794e-05
	LOSS [training: 0.4502524596702527 | validation: 0.7198051275444162]
	TIME [epoch: 9.5 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43276457909253496		[learning rate: 6.1854e-05]
	Learning Rate: 6.18541e-05
	LOSS [training: 0.43276457909253496 | validation: 0.741783164173656]
	TIME [epoch: 9.49 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42672144400778544		[learning rate: 6.163e-05]
	Learning Rate: 6.16296e-05
	LOSS [training: 0.42672144400778544 | validation: 0.7319502986681979]
	TIME [epoch: 9.49 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44176321581352507		[learning rate: 6.1406e-05]
	Learning Rate: 6.1406e-05
	LOSS [training: 0.44176321581352507 | validation: 0.7096416787945421]
	TIME [epoch: 9.5 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45252506064598064		[learning rate: 6.1183e-05]
	Learning Rate: 6.11831e-05
	LOSS [training: 0.45252506064598064 | validation: 0.7493873382821522]
	TIME [epoch: 9.49 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4269461529317672		[learning rate: 6.0961e-05]
	Learning Rate: 6.09611e-05
	LOSS [training: 0.4269461529317672 | validation: 0.7393868959023838]
	TIME [epoch: 9.49 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4538455043911602		[learning rate: 6.074e-05]
	Learning Rate: 6.07399e-05
	LOSS [training: 0.4538455043911602 | validation: 0.717884351662796]
	TIME [epoch: 9.49 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4211467277570371		[learning rate: 6.0519e-05]
	Learning Rate: 6.05194e-05
	LOSS [training: 0.4211467277570371 | validation: 0.735141519368826]
	TIME [epoch: 9.51 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4451425880709638		[learning rate: 6.03e-05]
	Learning Rate: 6.02998e-05
	LOSS [training: 0.4451425880709638 | validation: 0.7073036453837042]
	TIME [epoch: 9.5 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4230537456029929		[learning rate: 6.0081e-05]
	Learning Rate: 6.0081e-05
	LOSS [training: 0.4230537456029929 | validation: 0.7180579016014755]
	TIME [epoch: 9.49 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42207102265757424		[learning rate: 5.9863e-05]
	Learning Rate: 5.98629e-05
	LOSS [training: 0.42207102265757424 | validation: 0.7344489668121591]
	TIME [epoch: 9.5 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43265567785555065		[learning rate: 5.9646e-05]
	Learning Rate: 5.96457e-05
	LOSS [training: 0.43265567785555065 | validation: 0.7754326739575601]
	TIME [epoch: 9.5 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4149109250424449		[learning rate: 5.9429e-05]
	Learning Rate: 5.94292e-05
	LOSS [training: 0.4149109250424449 | validation: 0.7316020072135205]
	TIME [epoch: 9.48 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43213928268729285		[learning rate: 5.9214e-05]
	Learning Rate: 5.92136e-05
	LOSS [training: 0.43213928268729285 | validation: 0.7130903689139068]
	TIME [epoch: 9.49 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41776021309439726		[learning rate: 5.8999e-05]
	Learning Rate: 5.89987e-05
	LOSS [training: 0.41776021309439726 | validation: 0.7301385023638673]
	TIME [epoch: 9.51 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41556327075285165		[learning rate: 5.8785e-05]
	Learning Rate: 5.87846e-05
	LOSS [training: 0.41556327075285165 | validation: 0.7156391100482862]
	TIME [epoch: 9.5 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4270549305957296		[learning rate: 5.8571e-05]
	Learning Rate: 5.85712e-05
	LOSS [training: 0.4270549305957296 | validation: 0.739231544817579]
	TIME [epoch: 9.49 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42677351564000576		[learning rate: 5.8359e-05]
	Learning Rate: 5.83586e-05
	LOSS [training: 0.42677351564000576 | validation: 0.7319013783257166]
	TIME [epoch: 9.51 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43080645651031074		[learning rate: 5.8147e-05]
	Learning Rate: 5.81469e-05
	LOSS [training: 0.43080645651031074 | validation: 0.7332609070601589]
	TIME [epoch: 9.5 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46786375266065994		[learning rate: 5.7936e-05]
	Learning Rate: 5.79358e-05
	LOSS [training: 0.46786375266065994 | validation: 0.7412235142876861]
	TIME [epoch: 9.49 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4454548691582314		[learning rate: 5.7726e-05]
	Learning Rate: 5.77256e-05
	LOSS [training: 0.4454548691582314 | validation: 0.7250506569309456]
	TIME [epoch: 9.49 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4346776573502294		[learning rate: 5.7516e-05]
	Learning Rate: 5.75161e-05
	LOSS [training: 0.4346776573502294 | validation: 0.7153452767957641]
	TIME [epoch: 9.52 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4250873480206033		[learning rate: 5.7307e-05]
	Learning Rate: 5.73074e-05
	LOSS [training: 0.4250873480206033 | validation: 0.7469360351145199]
	TIME [epoch: 9.49 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4369708493287915		[learning rate: 5.7099e-05]
	Learning Rate: 5.70994e-05
	LOSS [training: 0.4369708493287915 | validation: 0.7115947504804142]
	TIME [epoch: 9.49 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42472903462012257		[learning rate: 5.6892e-05]
	Learning Rate: 5.68922e-05
	LOSS [training: 0.42472903462012257 | validation: 0.7386395215538477]
	TIME [epoch: 9.51 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4281166151573091		[learning rate: 5.6686e-05]
	Learning Rate: 5.66857e-05
	LOSS [training: 0.4281166151573091 | validation: 0.7169460069440488]
	TIME [epoch: 9.49 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4240106135320028		[learning rate: 5.648e-05]
	Learning Rate: 5.648e-05
	LOSS [training: 0.4240106135320028 | validation: 0.7421654772422238]
	TIME [epoch: 9.49 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41819483423398857		[learning rate: 5.6275e-05]
	Learning Rate: 5.6275e-05
	LOSS [training: 0.41819483423398857 | validation: 0.7055506551924625]
	TIME [epoch: 9.5 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4226942919940765		[learning rate: 5.6071e-05]
	Learning Rate: 5.60708e-05
	LOSS [training: 0.4226942919940765 | validation: 0.7171483395227929]
	TIME [epoch: 9.51 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4203111359586547		[learning rate: 5.5867e-05]
	Learning Rate: 5.58673e-05
	LOSS [training: 0.4203111359586547 | validation: 0.7124365689990356]
	TIME [epoch: 9.49 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42398103312720103		[learning rate: 5.5665e-05]
	Learning Rate: 5.56646e-05
	LOSS [training: 0.42398103312720103 | validation: 0.7275066329671873]
	TIME [epoch: 9.49 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4224274832004185		[learning rate: 5.5463e-05]
	Learning Rate: 5.54626e-05
	LOSS [training: 0.4224274832004185 | validation: 0.7208233794529627]
	TIME [epoch: 9.51 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.422723950252201		[learning rate: 5.5261e-05]
	Learning Rate: 5.52613e-05
	LOSS [training: 0.422723950252201 | validation: 0.721467717082945]
	TIME [epoch: 9.49 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.401768300715064		[learning rate: 5.5061e-05]
	Learning Rate: 5.50608e-05
	LOSS [training: 0.401768300715064 | validation: 0.7373165919610601]
	TIME [epoch: 9.49 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41630919758601853		[learning rate: 5.4861e-05]
	Learning Rate: 5.48609e-05
	LOSS [training: 0.41630919758601853 | validation: 0.7209863922935312]
	TIME [epoch: 9.5 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41601641013673485		[learning rate: 5.4662e-05]
	Learning Rate: 5.46618e-05
	LOSS [training: 0.41601641013673485 | validation: 0.7079075373952407]
	TIME [epoch: 9.51 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41818153166317984		[learning rate: 5.4463e-05]
	Learning Rate: 5.44635e-05
	LOSS [training: 0.41818153166317984 | validation: 0.7229149038842492]
	TIME [epoch: 9.49 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41623426073242775		[learning rate: 5.4266e-05]
	Learning Rate: 5.42658e-05
	LOSS [training: 0.41623426073242775 | validation: 0.7034962128706791]
	TIME [epoch: 9.49 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4273091821725603		[learning rate: 5.4069e-05]
	Learning Rate: 5.40689e-05
	LOSS [training: 0.4273091821725603 | validation: 0.7108930677437262]
	TIME [epoch: 9.51 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4333994061207786		[learning rate: 5.3873e-05]
	Learning Rate: 5.38727e-05
	LOSS [training: 0.4333994061207786 | validation: 0.7269574590548176]
	TIME [epoch: 9.49 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41129174816814684		[learning rate: 5.3677e-05]
	Learning Rate: 5.36772e-05
	LOSS [training: 0.41129174816814684 | validation: 0.7436474279592362]
	TIME [epoch: 9.49 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.426891767794351		[learning rate: 5.3482e-05]
	Learning Rate: 5.34824e-05
	LOSS [training: 0.426891767794351 | validation: 0.7272144628762648]
	TIME [epoch: 9.49 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4210931012246208		[learning rate: 5.3288e-05]
	Learning Rate: 5.32883e-05
	LOSS [training: 0.4210931012246208 | validation: 0.7166716490124756]
	TIME [epoch: 9.51 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4275039246711277		[learning rate: 5.3095e-05]
	Learning Rate: 5.30949e-05
	LOSS [training: 0.4275039246711277 | validation: 0.7161616695542261]
	TIME [epoch: 9.49 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4396370561733553		[learning rate: 5.2902e-05]
	Learning Rate: 5.29022e-05
	LOSS [training: 0.4396370561733553 | validation: 0.731876912072681]
	TIME [epoch: 9.49 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43552564149087714		[learning rate: 5.271e-05]
	Learning Rate: 5.27102e-05
	LOSS [training: 0.43552564149087714 | validation: 0.7206074667443687]
	TIME [epoch: 9.5 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43345540423995266		[learning rate: 5.2519e-05]
	Learning Rate: 5.25189e-05
	LOSS [training: 0.43345540423995266 | validation: 0.7263776078462414]
	TIME [epoch: 9.49 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4305671983074973		[learning rate: 5.2328e-05]
	Learning Rate: 5.23283e-05
	LOSS [training: 0.4305671983074973 | validation: 0.7345434553689301]
	TIME [epoch: 9.49 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42452436347944256		[learning rate: 5.2138e-05]
	Learning Rate: 5.21384e-05
	LOSS [training: 0.42452436347944256 | validation: 0.7333212721464878]
	TIME [epoch: 9.49 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41242293086551846		[learning rate: 5.1949e-05]
	Learning Rate: 5.19492e-05
	LOSS [training: 0.41242293086551846 | validation: 0.7286244307902203]
	TIME [epoch: 9.5 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4197557806937132		[learning rate: 5.1761e-05]
	Learning Rate: 5.17607e-05
	LOSS [training: 0.4197557806937132 | validation: 0.7004398874945659]
	TIME [epoch: 9.49 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4124394661509836		[learning rate: 5.1573e-05]
	Learning Rate: 5.15729e-05
	LOSS [training: 0.4124394661509836 | validation: 0.7103009265398283]
	TIME [epoch: 9.49 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.431578889210657		[learning rate: 5.1386e-05]
	Learning Rate: 5.13857e-05
	LOSS [training: 0.431578889210657 | validation: 0.7309432179565911]
	TIME [epoch: 9.51 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42623690798824765		[learning rate: 5.1199e-05]
	Learning Rate: 5.11992e-05
	LOSS [training: 0.42623690798824765 | validation: 0.7302612623934428]
	TIME [epoch: 9.5 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4322444847245069		[learning rate: 5.1013e-05]
	Learning Rate: 5.10134e-05
	LOSS [training: 0.4322444847245069 | validation: 0.7084743065300374]
	TIME [epoch: 9.49 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42099029117410486		[learning rate: 5.0828e-05]
	Learning Rate: 5.08283e-05
	LOSS [training: 0.42099029117410486 | validation: 0.7215742359909474]
	TIME [epoch: 9.49 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4150436321511828		[learning rate: 5.0644e-05]
	Learning Rate: 5.06438e-05
	LOSS [training: 0.4150436321511828 | validation: 0.7210470100338434]
	TIME [epoch: 9.51 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42489783931016534		[learning rate: 5.046e-05]
	Learning Rate: 5.046e-05
	LOSS [training: 0.42489783931016534 | validation: 0.7029324122771304]
	TIME [epoch: 9.49 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4309149987481886		[learning rate: 5.0277e-05]
	Learning Rate: 5.02769e-05
	LOSS [training: 0.4309149987481886 | validation: 0.7172981456240287]
	TIME [epoch: 9.49 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4267104133394737		[learning rate: 5.0094e-05]
	Learning Rate: 5.00944e-05
	LOSS [training: 0.4267104133394737 | validation: 0.7313230148222362]
	TIME [epoch: 9.51 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4345219743170502		[learning rate: 4.9913e-05]
	Learning Rate: 4.99127e-05
	LOSS [training: 0.4345219743170502 | validation: 0.707481161422083]
	TIME [epoch: 9.49 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4165591055240056		[learning rate: 4.9732e-05]
	Learning Rate: 4.97315e-05
	LOSS [training: 0.4165591055240056 | validation: 0.7112494205322044]
	TIME [epoch: 9.49 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41402648316196144		[learning rate: 4.9551e-05]
	Learning Rate: 4.9551e-05
	LOSS [training: 0.41402648316196144 | validation: 0.7557900990868472]
	TIME [epoch: 9.49 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42673632968839464		[learning rate: 4.9371e-05]
	Learning Rate: 4.93712e-05
	LOSS [training: 0.42673632968839464 | validation: 0.7420757984991448]
	TIME [epoch: 9.5 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42284478349033583		[learning rate: 4.9192e-05]
	Learning Rate: 4.9192e-05
	LOSS [training: 0.42284478349033583 | validation: 0.7143246456600295]
	TIME [epoch: 9.49 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.423243399292916		[learning rate: 4.9014e-05]
	Learning Rate: 4.90135e-05
	LOSS [training: 0.423243399292916 | validation: 0.7079464792625509]
	TIME [epoch: 9.49 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42168332073335224		[learning rate: 4.8836e-05]
	Learning Rate: 4.88356e-05
	LOSS [training: 0.42168332073335224 | validation: 0.6936848572416708]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_1564.pth
	Model improved!!!
EPOCH 1565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41992602453266115		[learning rate: 4.8658e-05]
	Learning Rate: 4.86584e-05
	LOSS [training: 0.41992602453266115 | validation: 0.7277338674846701]
	TIME [epoch: 9.53 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4422644694378066		[learning rate: 4.8482e-05]
	Learning Rate: 4.84818e-05
	LOSS [training: 0.4422644694378066 | validation: 0.7203259821392008]
	TIME [epoch: 9.5 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4312165247390679		[learning rate: 4.8306e-05]
	Learning Rate: 4.83059e-05
	LOSS [training: 0.4312165247390679 | validation: 0.7140040699800819]
	TIME [epoch: 9.51 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41950231552267575		[learning rate: 4.8131e-05]
	Learning Rate: 4.81306e-05
	LOSS [training: 0.41950231552267575 | validation: 0.7028239005912411]
	TIME [epoch: 9.5 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4192977460607509		[learning rate: 4.7956e-05]
	Learning Rate: 4.79559e-05
	LOSS [training: 0.4192977460607509 | validation: 0.7303605419315815]
	TIME [epoch: 9.5 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4265508484014397		[learning rate: 4.7782e-05]
	Learning Rate: 4.77819e-05
	LOSS [training: 0.4265508484014397 | validation: 0.7457698360084875]
	TIME [epoch: 9.49 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41493523908192237		[learning rate: 4.7608e-05]
	Learning Rate: 4.76085e-05
	LOSS [training: 0.41493523908192237 | validation: 0.7000877194905187]
	TIME [epoch: 9.51 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41143953714555137		[learning rate: 4.7436e-05]
	Learning Rate: 4.74357e-05
	LOSS [training: 0.41143953714555137 | validation: 0.7098976998631951]
	TIME [epoch: 9.49 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41888595219290037		[learning rate: 4.7264e-05]
	Learning Rate: 4.72636e-05
	LOSS [training: 0.41888595219290037 | validation: 0.7105746858125115]
	TIME [epoch: 9.49 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4154468345504208		[learning rate: 4.7092e-05]
	Learning Rate: 4.7092e-05
	LOSS [training: 0.4154468345504208 | validation: 0.7355253877939885]
	TIME [epoch: 9.5 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4140108782415088		[learning rate: 4.6921e-05]
	Learning Rate: 4.69211e-05
	LOSS [training: 0.4140108782415088 | validation: 0.7192949250711215]
	TIME [epoch: 9.5 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41619495109576066		[learning rate: 4.6751e-05]
	Learning Rate: 4.67508e-05
	LOSS [training: 0.41619495109576066 | validation: 0.68319686287982]
	TIME [epoch: 9.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r2_20240219_235153/states/model_tr_study205_1576.pth
	Model improved!!!
EPOCH 1577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42437386191487364		[learning rate: 4.6581e-05]
	Learning Rate: 4.65812e-05
	LOSS [training: 0.42437386191487364 | validation: 0.7284357815343344]
	TIME [epoch: 9.49 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4122119506553464		[learning rate: 4.6412e-05]
	Learning Rate: 4.64121e-05
	LOSS [training: 0.4122119506553464 | validation: 0.7135382305102351]
	TIME [epoch: 9.51 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4200228819107439		[learning rate: 4.6244e-05]
	Learning Rate: 4.62437e-05
	LOSS [training: 0.4200228819107439 | validation: 0.7301177642416559]
	TIME [epoch: 9.49 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42155597683774		[learning rate: 4.6076e-05]
	Learning Rate: 4.60759e-05
	LOSS [training: 0.42155597683774 | validation: 0.7048501820472381]
	TIME [epoch: 9.49 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41853086586066357		[learning rate: 4.5909e-05]
	Learning Rate: 4.59087e-05
	LOSS [training: 0.41853086586066357 | validation: 0.7277555613661002]
	TIME [epoch: 9.51 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42671807489167024		[learning rate: 4.5742e-05]
	Learning Rate: 4.57421e-05
	LOSS [training: 0.42671807489167024 | validation: 0.7193242703126108]
	TIME [epoch: 9.49 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41961378577817043		[learning rate: 4.5576e-05]
	Learning Rate: 4.55761e-05
	LOSS [training: 0.41961378577817043 | validation: 0.7156421770018144]
	TIME [epoch: 9.49 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41598397203809967		[learning rate: 4.5411e-05]
	Learning Rate: 4.54107e-05
	LOSS [training: 0.41598397203809967 | validation: 0.7207920816070228]
	TIME [epoch: 9.49 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4155108079017958		[learning rate: 4.5246e-05]
	Learning Rate: 4.52459e-05
	LOSS [training: 0.4155108079017958 | validation: 0.7146435388781884]
	TIME [epoch: 9.51 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4242478662904904		[learning rate: 4.5082e-05]
	Learning Rate: 4.50817e-05
	LOSS [training: 0.4242478662904904 | validation: 0.7233205028755174]
	TIME [epoch: 9.49 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4222612069639906		[learning rate: 4.4918e-05]
	Learning Rate: 4.49181e-05
	LOSS [training: 0.4222612069639906 | validation: 0.7407715964437748]
	TIME [epoch: 9.49 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41458198265391283		[learning rate: 4.4755e-05]
	Learning Rate: 4.47551e-05
	LOSS [training: 0.41458198265391283 | validation: 0.6986525317013667]
	TIME [epoch: 9.5 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4255785779007198		[learning rate: 4.4593e-05]
	Learning Rate: 4.45926e-05
	LOSS [training: 0.4255785779007198 | validation: 0.7278314202969622]
	TIME [epoch: 9.49 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41429571123020176		[learning rate: 4.4431e-05]
	Learning Rate: 4.44308e-05
	LOSS [training: 0.41429571123020176 | validation: 0.7364343375805109]
	TIME [epoch: 9.49 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43796843256965623		[learning rate: 4.427e-05]
	Learning Rate: 4.42696e-05
	LOSS [training: 0.43796843256965623 | validation: 0.7167543961699123]
	TIME [epoch: 9.48 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4266646986150118		[learning rate: 4.4109e-05]
	Learning Rate: 4.41089e-05
	LOSS [training: 0.4266646986150118 | validation: 0.7232986675809125]
	TIME [epoch: 9.51 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41390764633376625		[learning rate: 4.3949e-05]
	Learning Rate: 4.39489e-05
	LOSS [training: 0.41390764633376625 | validation: 0.7237380429625643]
	TIME [epoch: 9.5 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4269083512989057		[learning rate: 4.3789e-05]
	Learning Rate: 4.37893e-05
	LOSS [training: 0.4269083512989057 | validation: 0.7147891493304965]
	TIME [epoch: 9.49 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42864583267217027		[learning rate: 4.363e-05]
	Learning Rate: 4.36304e-05
	LOSS [training: 0.42864583267217027 | validation: 0.7081289071063931]
	TIME [epoch: 9.51 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42119055175003073		[learning rate: 4.3472e-05]
	Learning Rate: 4.34721e-05
	LOSS [training: 0.42119055175003073 | validation: 0.7265466654370917]
	TIME [epoch: 9.49 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.418730532290377		[learning rate: 4.3314e-05]
	Learning Rate: 4.33143e-05
	LOSS [training: 0.418730532290377 | validation: 0.7320051022467127]
	TIME [epoch: 9.5 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41029713166399323		[learning rate: 4.3157e-05]
	Learning Rate: 4.31571e-05
	LOSS [training: 0.41029713166399323 | validation: 0.724549331981388]
	TIME [epoch: 9.49 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43250783931666437		[learning rate: 4.3001e-05]
	Learning Rate: 4.30005e-05
	LOSS [training: 0.43250783931666437 | validation: 0.7239147313318128]
	TIME [epoch: 9.51 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41281511586062214		[learning rate: 4.2844e-05]
	Learning Rate: 4.28445e-05
	LOSS [training: 0.41281511586062214 | validation: 0.7264134135358817]
	TIME [epoch: 9.5 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43584500840060303		[learning rate: 4.2689e-05]
	Learning Rate: 4.2689e-05
	LOSS [training: 0.43584500840060303 | validation: 0.7469031599502657]
	TIME [epoch: 9.49 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4299006105601893		[learning rate: 4.2534e-05]
	Learning Rate: 4.25341e-05
	LOSS [training: 0.4299006105601893 | validation: 0.7184851721903925]
	TIME [epoch: 9.51 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42372220407916944		[learning rate: 4.238e-05]
	Learning Rate: 4.23797e-05
	LOSS [training: 0.42372220407916944 | validation: 0.7464866955352042]
	TIME [epoch: 9.49 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4248593576304659		[learning rate: 4.2226e-05]
	Learning Rate: 4.22259e-05
	LOSS [training: 0.4248593576304659 | validation: 0.7236223539632392]
	TIME [epoch: 9.49 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41620119420977914		[learning rate: 4.2073e-05]
	Learning Rate: 4.20727e-05
	LOSS [training: 0.41620119420977914 | validation: 0.7067415776264957]
	TIME [epoch: 9.49 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43256245484329103		[learning rate: 4.192e-05]
	Learning Rate: 4.192e-05
	LOSS [training: 0.43256245484329103 | validation: 0.7325816331143594]
	TIME [epoch: 9.51 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4211676741548661		[learning rate: 4.1768e-05]
	Learning Rate: 4.17679e-05
	LOSS [training: 0.4211676741548661 | validation: 0.7286600066517815]
	TIME [epoch: 9.5 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4322835101744392		[learning rate: 4.1616e-05]
	Learning Rate: 4.16163e-05
	LOSS [training: 0.4322835101744392 | validation: 0.716914045445376]
	TIME [epoch: 9.49 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4194246735245928		[learning rate: 4.1465e-05]
	Learning Rate: 4.14652e-05
	LOSS [training: 0.4194246735245928 | validation: 0.705884157970526]
	TIME [epoch: 9.5 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4355809054038978		[learning rate: 4.1315e-05]
	Learning Rate: 4.13148e-05
	LOSS [training: 0.4355809054038978 | validation: 0.7247847542404284]
	TIME [epoch: 9.49 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42460007363087404		[learning rate: 4.1165e-05]
	Learning Rate: 4.11648e-05
	LOSS [training: 0.42460007363087404 | validation: 0.719649172589852]
	TIME [epoch: 9.49 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42140613116771447		[learning rate: 4.1015e-05]
	Learning Rate: 4.10154e-05
	LOSS [training: 0.42140613116771447 | validation: 0.7352776380107399]
	TIME [epoch: 9.5 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4309295003086949		[learning rate: 4.0867e-05]
	Learning Rate: 4.08666e-05
	LOSS [training: 0.4309295003086949 | validation: 0.7309901394047802]
	TIME [epoch: 9.51 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4288470974324719		[learning rate: 4.0718e-05]
	Learning Rate: 4.07183e-05
	LOSS [training: 0.4288470974324719 | validation: 0.708196064203094]
	TIME [epoch: 9.49 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4131937061342604		[learning rate: 4.0571e-05]
	Learning Rate: 4.05705e-05
	LOSS [training: 0.4131937061342604 | validation: 0.73261414232251]
	TIME [epoch: 9.49 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40856810904110735		[learning rate: 4.0423e-05]
	Learning Rate: 4.04233e-05
	LOSS [training: 0.40856810904110735 | validation: 0.73397444322496]
	TIME [epoch: 9.5 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4182534768151519		[learning rate: 4.0277e-05]
	Learning Rate: 4.02766e-05
	LOSS [training: 0.4182534768151519 | validation: 0.6876785360761503]
	TIME [epoch: 9.49 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4188485456673233		[learning rate: 4.013e-05]
	Learning Rate: 4.01304e-05
	LOSS [training: 0.4188485456673233 | validation: 0.709091016697995]
	TIME [epoch: 9.49 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4147484604322644		[learning rate: 3.9985e-05]
	Learning Rate: 3.99848e-05
	LOSS [training: 0.4147484604322644 | validation: 0.7034155793950568]
	TIME [epoch: 9.5 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43303725582087155		[learning rate: 3.984e-05]
	Learning Rate: 3.98397e-05
	LOSS [training: 0.43303725582087155 | validation: 0.7345100013939256]
	TIME [epoch: 9.5 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4188989696315361		[learning rate: 3.9695e-05]
	Learning Rate: 3.96951e-05
	LOSS [training: 0.4188989696315361 | validation: 0.7068158413995181]
	TIME [epoch: 9.49 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42119919682122847		[learning rate: 3.9551e-05]
	Learning Rate: 3.9551e-05
	LOSS [training: 0.42119919682122847 | validation: 0.7105118727214168]
	TIME [epoch: 9.49 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4189932084955858		[learning rate: 3.9408e-05]
	Learning Rate: 3.94075e-05
	LOSS [training: 0.4189932084955858 | validation: 0.7225621761378582]
	TIME [epoch: 9.51 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4317046158784329		[learning rate: 3.9264e-05]
	Learning Rate: 3.92645e-05
	LOSS [training: 0.4317046158784329 | validation: 0.705609846496412]
	TIME [epoch: 9.49 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42289631201972033		[learning rate: 3.9122e-05]
	Learning Rate: 3.9122e-05
	LOSS [training: 0.42289631201972033 | validation: 0.7164061939094579]
	TIME [epoch: 9.49 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4160133584417042		[learning rate: 3.898e-05]
	Learning Rate: 3.898e-05
	LOSS [training: 0.4160133584417042 | validation: 0.7117931912354608]
	TIME [epoch: 9.49 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4178573606461134		[learning rate: 3.8839e-05]
	Learning Rate: 3.88386e-05
	LOSS [training: 0.4178573606461134 | validation: 0.7175815650736559]
	TIME [epoch: 9.51 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4274286819032371		[learning rate: 3.8698e-05]
	Learning Rate: 3.86976e-05
	LOSS [training: 0.4274286819032371 | validation: 0.7173183068924073]
	TIME [epoch: 9.49 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41527521897790487		[learning rate: 3.8557e-05]
	Learning Rate: 3.85572e-05
	LOSS [training: 0.41527521897790487 | validation: 0.7252976244599805]
	TIME [epoch: 9.49 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41516707102468875		[learning rate: 3.8417e-05]
	Learning Rate: 3.84173e-05
	LOSS [training: 0.41516707102468875 | validation: 0.7543453016130447]
	TIME [epoch: 9.51 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41573547758950413		[learning rate: 3.8278e-05]
	Learning Rate: 3.82778e-05
	LOSS [training: 0.41573547758950413 | validation: 0.7545823450847465]
	TIME [epoch: 9.5 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4126205087387385		[learning rate: 3.8139e-05]
	Learning Rate: 3.81389e-05
	LOSS [training: 0.4126205087387385 | validation: 0.7257863143917861]
	TIME [epoch: 9.5 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42234200264429694		[learning rate: 3.8001e-05]
	Learning Rate: 3.80005e-05
	LOSS [training: 0.42234200264429694 | validation: 0.7147131942828926]
	TIME [epoch: 9.5 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4188241677543997		[learning rate: 3.7863e-05]
	Learning Rate: 3.78626e-05
	LOSS [training: 0.4188241677543997 | validation: 0.7347069550518669]
	TIME [epoch: 9.5 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.415747441759471		[learning rate: 3.7725e-05]
	Learning Rate: 3.77252e-05
	LOSS [training: 0.415747441759471 | validation: 0.7211048248281702]
	TIME [epoch: 9.48 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41694047328306577		[learning rate: 3.7588e-05]
	Learning Rate: 3.75883e-05
	LOSS [training: 0.41694047328306577 | validation: 0.7405362949697536]
	TIME [epoch: 9.49 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42418513514773315		[learning rate: 3.7452e-05]
	Learning Rate: 3.74519e-05
	LOSS [training: 0.42418513514773315 | validation: 0.710988413995922]
	TIME [epoch: 9.51 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42485182331757726		[learning rate: 3.7316e-05]
	Learning Rate: 3.7316e-05
	LOSS [training: 0.42485182331757726 | validation: 0.7434205669364016]
	TIME [epoch: 9.5 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42389908309060154		[learning rate: 3.7181e-05]
	Learning Rate: 3.71805e-05
	LOSS [training: 0.42389908309060154 | validation: 0.7219269108850804]
	TIME [epoch: 9.49 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41311948163221485		[learning rate: 3.7046e-05]
	Learning Rate: 3.70456e-05
	LOSS [training: 0.41311948163221485 | validation: 0.7535356452735353]
	TIME [epoch: 9.5 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4193025574630684		[learning rate: 3.6911e-05]
	Learning Rate: 3.69112e-05
	LOSS [training: 0.4193025574630684 | validation: 0.7427753931258348]
	TIME [epoch: 9.49 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4210414847373185		[learning rate: 3.6777e-05]
	Learning Rate: 3.67772e-05
	LOSS [training: 0.4210414847373185 | validation: 0.7183501038689543]
	TIME [epoch: 9.49 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41632476468502233		[learning rate: 3.6644e-05]
	Learning Rate: 3.66438e-05
	LOSS [training: 0.41632476468502233 | validation: 0.7196214854556481]
	TIME [epoch: 9.49 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4231436843261968		[learning rate: 3.6511e-05]
	Learning Rate: 3.65108e-05
	LOSS [training: 0.4231436843261968 | validation: 0.707644225208218]
	TIME [epoch: 9.51 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42432748888627414		[learning rate: 3.6378e-05]
	Learning Rate: 3.63783e-05
	LOSS [training: 0.42432748888627414 | validation: 0.6939135638830665]
	TIME [epoch: 9.48 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4083298402978202		[learning rate: 3.6246e-05]
	Learning Rate: 3.62463e-05
	LOSS [training: 0.4083298402978202 | validation: 0.7216652917027984]
	TIME [epoch: 9.49 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41524988836195426		[learning rate: 3.6115e-05]
	Learning Rate: 3.61147e-05
	LOSS [training: 0.41524988836195426 | validation: 0.7392097844822217]
	TIME [epoch: 9.5 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4159069372624602		[learning rate: 3.5984e-05]
	Learning Rate: 3.59837e-05
	LOSS [training: 0.4159069372624602 | validation: 0.7263573100310867]
	TIME [epoch: 9.5 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41246121327969376		[learning rate: 3.5853e-05]
	Learning Rate: 3.58531e-05
	LOSS [training: 0.41246121327969376 | validation: 0.7257110815366796]
	TIME [epoch: 9.49 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4228781481950283		[learning rate: 3.5723e-05]
	Learning Rate: 3.5723e-05
	LOSS [training: 0.4228781481950283 | validation: 0.741624025526303]
	TIME [epoch: 9.49 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.417188212877236		[learning rate: 3.5593e-05]
	Learning Rate: 3.55933e-05
	LOSS [training: 0.417188212877236 | validation: 0.7187977848530006]
	TIME [epoch: 9.52 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4204133709462181		[learning rate: 3.5464e-05]
	Learning Rate: 3.54641e-05
	LOSS [training: 0.4204133709462181 | validation: 0.7178764080956305]
	TIME [epoch: 9.49 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41361407115468624		[learning rate: 3.5335e-05]
	Learning Rate: 3.53354e-05
	LOSS [training: 0.41361407115468624 | validation: 0.7157975602573516]
	TIME [epoch: 9.49 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4119656591711992		[learning rate: 3.5207e-05]
	Learning Rate: 3.52072e-05
	LOSS [training: 0.4119656591711992 | validation: 0.7035576066517055]
	TIME [epoch: 9.5 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4229914765335058		[learning rate: 3.5079e-05]
	Learning Rate: 3.50794e-05
	LOSS [training: 0.4229914765335058 | validation: 0.7363886255014146]
	TIME [epoch: 9.5 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4149206139180607		[learning rate: 3.4952e-05]
	Learning Rate: 3.49521e-05
	LOSS [training: 0.4149206139180607 | validation: 0.7260817570140157]
	TIME [epoch: 9.49 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4060583371203861		[learning rate: 3.4825e-05]
	Learning Rate: 3.48253e-05
	LOSS [training: 0.4060583371203861 | validation: 0.7155964957011551]
	TIME [epoch: 9.51 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4111685185210252		[learning rate: 3.4699e-05]
	Learning Rate: 3.46989e-05
	LOSS [training: 0.4111685185210252 | validation: 0.7122243247317255]
	TIME [epoch: 9.5 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42224323465941777		[learning rate: 3.4573e-05]
	Learning Rate: 3.4573e-05
	LOSS [training: 0.42224323465941777 | validation: 0.7163228479833329]
	TIME [epoch: 9.49 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41415869288728374		[learning rate: 3.4448e-05]
	Learning Rate: 3.44475e-05
	LOSS [training: 0.41415869288728374 | validation: 0.7224446888147665]
	TIME [epoch: 9.49 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4264698440272271		[learning rate: 3.4323e-05]
	Learning Rate: 3.43225e-05
	LOSS [training: 0.4264698440272271 | validation: 0.737978346456201]
	TIME [epoch: 9.51 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4114620136547488		[learning rate: 3.4198e-05]
	Learning Rate: 3.4198e-05
	LOSS [training: 0.4114620136547488 | validation: 0.7271623677976643]
	TIME [epoch: 9.49 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41298373050063253		[learning rate: 3.4074e-05]
	Learning Rate: 3.40738e-05
	LOSS [training: 0.41298373050063253 | validation: 0.7425931802489163]
	TIME [epoch: 9.49 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41373660110018573		[learning rate: 3.395e-05]
	Learning Rate: 3.39502e-05
	LOSS [training: 0.41373660110018573 | validation: 0.7285379724856408]
	TIME [epoch: 9.49 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4109134580800222		[learning rate: 3.3827e-05]
	Learning Rate: 3.3827e-05
	LOSS [training: 0.4109134580800222 | validation: 0.6908837768301355]
	TIME [epoch: 9.51 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41778219129659905		[learning rate: 3.3704e-05]
	Learning Rate: 3.37042e-05
	LOSS [training: 0.41778219129659905 | validation: 0.7229268640429458]
	TIME [epoch: 9.49 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4246994637332501		[learning rate: 3.3582e-05]
	Learning Rate: 3.35819e-05
	LOSS [training: 0.4246994637332501 | validation: 0.7188798952656222]
	TIME [epoch: 9.49 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4229806012946433		[learning rate: 3.346e-05]
	Learning Rate: 3.346e-05
	LOSS [training: 0.4229806012946433 | validation: 0.7166358975974777]
	TIME [epoch: 9.51 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4174235963489174		[learning rate: 3.3339e-05]
	Learning Rate: 3.33386e-05
	LOSS [training: 0.4174235963489174 | validation: 0.7128623048831401]
	TIME [epoch: 9.5 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4136902860636516		[learning rate: 3.3218e-05]
	Learning Rate: 3.32176e-05
	LOSS [training: 0.4136902860636516 | validation: 0.7091544232004023]
	TIME [epoch: 9.49 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42192426078470346		[learning rate: 3.3097e-05]
	Learning Rate: 3.30971e-05
	LOSS [training: 0.42192426078470346 | validation: 0.7189978560257396]
	TIME [epoch: 9.49 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4136794847185013		[learning rate: 3.2977e-05]
	Learning Rate: 3.2977e-05
	LOSS [training: 0.4136794847185013 | validation: 0.7378292670942497]
	TIME [epoch: 9.51 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41117831983742975		[learning rate: 3.2857e-05]
	Learning Rate: 3.28573e-05
	LOSS [training: 0.41117831983742975 | validation: 0.7234896669950649]
	TIME [epoch: 9.49 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42125702171845536		[learning rate: 3.2738e-05]
	Learning Rate: 3.2738e-05
	LOSS [training: 0.42125702171845536 | validation: 0.7090877505279218]
	TIME [epoch: 9.49 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.421679706915441		[learning rate: 3.2619e-05]
	Learning Rate: 3.26192e-05
	LOSS [training: 0.421679706915441 | validation: 0.7380712647673682]
	TIME [epoch: 9.5 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.418816646338937		[learning rate: 3.2501e-05]
	Learning Rate: 3.25009e-05
	LOSS [training: 0.418816646338937 | validation: 0.7283075027172393]
	TIME [epoch: 9.49 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43093285586041413		[learning rate: 3.2383e-05]
	Learning Rate: 3.23829e-05
	LOSS [training: 0.43093285586041413 | validation: 0.7279289969442365]
	TIME [epoch: 9.48 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4169542970503947		[learning rate: 3.2265e-05]
	Learning Rate: 3.22654e-05
	LOSS [training: 0.4169542970503947 | validation: 0.7248532370464438]
	TIME [epoch: 9.49 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4142183734623955		[learning rate: 3.2148e-05]
	Learning Rate: 3.21483e-05
	LOSS [training: 0.4142183734623955 | validation: 0.7312116533283453]
	TIME [epoch: 9.51 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42119429115225915		[learning rate: 3.2032e-05]
	Learning Rate: 3.20316e-05
	LOSS [training: 0.42119429115225915 | validation: 0.7106734543127311]
	TIME [epoch: 9.49 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41802396822454335		[learning rate: 3.1915e-05]
	Learning Rate: 3.19154e-05
	LOSS [training: 0.41802396822454335 | validation: 0.7360779016719369]
	TIME [epoch: 9.49 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4165182508152279		[learning rate: 3.18e-05]
	Learning Rate: 3.17996e-05
	LOSS [training: 0.4165182508152279 | validation: 0.7288440178312277]
	TIME [epoch: 9.51 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4130916279863384		[learning rate: 3.1684e-05]
	Learning Rate: 3.16842e-05
	LOSS [training: 0.4130916279863384 | validation: 0.7327122554584784]
	TIME [epoch: 9.49 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4250636831579036		[learning rate: 3.1569e-05]
	Learning Rate: 3.15692e-05
	LOSS [training: 0.4250636831579036 | validation: 0.7593501718648985]
	TIME [epoch: 9.49 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4200420662848602		[learning rate: 3.1455e-05]
	Learning Rate: 3.14546e-05
	LOSS [training: 0.4200420662848602 | validation: 0.7189788982361796]
	TIME [epoch: 9.49 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4341807076192551		[learning rate: 3.134e-05]
	Learning Rate: 3.13405e-05
	LOSS [training: 0.4341807076192551 | validation: 0.7385537044661412]
	TIME [epoch: 9.51 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4267786606698202		[learning rate: 3.1227e-05]
	Learning Rate: 3.12267e-05
	LOSS [training: 0.4267786606698202 | validation: 0.7198169600540127]
	TIME [epoch: 9.49 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41725179012089547		[learning rate: 3.1113e-05]
	Learning Rate: 3.11134e-05
	LOSS [training: 0.41725179012089547 | validation: 0.7361903391474983]
	TIME [epoch: 9.48 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4090227218807643		[learning rate: 3.1e-05]
	Learning Rate: 3.10005e-05
	LOSS [training: 0.4090227218807643 | validation: 0.724699664950688]
	TIME [epoch: 9.51 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4132585952233071		[learning rate: 3.0888e-05]
	Learning Rate: 3.0888e-05
	LOSS [training: 0.4132585952233071 | validation: 0.7223416391462064]
	TIME [epoch: 9.49 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41440708245171354		[learning rate: 3.0776e-05]
	Learning Rate: 3.07759e-05
	LOSS [training: 0.41440708245171354 | validation: 0.7232088152875978]
	TIME [epoch: 9.49 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4170584546025523		[learning rate: 3.0664e-05]
	Learning Rate: 3.06642e-05
	LOSS [training: 0.4170584546025523 | validation: 0.7224532880991309]
	TIME [epoch: 9.49 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41878666627567707		[learning rate: 3.0553e-05]
	Learning Rate: 3.05529e-05
	LOSS [training: 0.41878666627567707 | validation: 0.7372653531014386]
	TIME [epoch: 9.51 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4209709841700512		[learning rate: 3.0442e-05]
	Learning Rate: 3.0442e-05
	LOSS [training: 0.4209709841700512 | validation: 0.7197864489215917]
	TIME [epoch: 9.5 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4173548534689049		[learning rate: 3.0332e-05]
	Learning Rate: 3.03316e-05
	LOSS [training: 0.4173548534689049 | validation: 0.7295708000785769]
	TIME [epoch: 9.5 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4097891094159463		[learning rate: 3.0221e-05]
	Learning Rate: 3.02215e-05
	LOSS [training: 0.4097891094159463 | validation: 0.7292621764006768]
	TIME [epoch: 9.51 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4166965424365099		[learning rate: 3.0112e-05]
	Learning Rate: 3.01118e-05
	LOSS [training: 0.4166965424365099 | validation: 0.7156022729868591]
	TIME [epoch: 9.49 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42546441153751263		[learning rate: 3.0003e-05]
	Learning Rate: 3.00025e-05
	LOSS [training: 0.42546441153751263 | validation: 0.7346397399403651]
	TIME [epoch: 9.49 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41158065095385393		[learning rate: 2.9894e-05]
	Learning Rate: 2.98936e-05
	LOSS [training: 0.41158065095385393 | validation: 0.723178101767006]
	TIME [epoch: 9.49 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42305495614821986		[learning rate: 2.9785e-05]
	Learning Rate: 2.97852e-05
	LOSS [training: 0.42305495614821986 | validation: 0.7308066968771081]
	TIME [epoch: 9.51 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42506648627187615		[learning rate: 2.9677e-05]
	Learning Rate: 2.96771e-05
	LOSS [training: 0.42506648627187615 | validation: 0.7397982176360023]
	TIME [epoch: 9.49 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41555012280885384		[learning rate: 2.9569e-05]
	Learning Rate: 2.95694e-05
	LOSS [training: 0.41555012280885384 | validation: 0.7062876456135728]
	TIME [epoch: 9.49 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4178233693842415		[learning rate: 2.9462e-05]
	Learning Rate: 2.94621e-05
	LOSS [training: 0.4178233693842415 | validation: 0.7166273394285173]
	TIME [epoch: 9.5 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4175140583680288		[learning rate: 2.9355e-05]
	Learning Rate: 2.93551e-05
	LOSS [training: 0.4175140583680288 | validation: 0.7090326752897896]
	TIME [epoch: 9.49 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43330998344342486		[learning rate: 2.9249e-05]
	Learning Rate: 2.92486e-05
	LOSS [training: 0.43330998344342486 | validation: 0.7152622284766297]
	TIME [epoch: 9.49 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41418096548054145		[learning rate: 2.9142e-05]
	Learning Rate: 2.91425e-05
	LOSS [training: 0.41418096548054145 | validation: 0.7137735428305747]
	TIME [epoch: 9.5 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40514645463658827		[learning rate: 2.9037e-05]
	Learning Rate: 2.90367e-05
	LOSS [training: 0.40514645463658827 | validation: 0.7259506001464788]
	TIME [epoch: 9.51 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42069905651391704		[learning rate: 2.8931e-05]
	Learning Rate: 2.89313e-05
	LOSS [training: 0.42069905651391704 | validation: 0.7297060893003886]
	TIME [epoch: 9.5 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.417431746027601		[learning rate: 2.8826e-05]
	Learning Rate: 2.88263e-05
	LOSS [training: 0.417431746027601 | validation: 0.7388010585130428]
	TIME [epoch: 9.49 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.416671539974445		[learning rate: 2.8722e-05]
	Learning Rate: 2.87217e-05
	LOSS [training: 0.416671539974445 | validation: 0.743831749052059]
	TIME [epoch: 9.51 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4184009406967547		[learning rate: 2.8617e-05]
	Learning Rate: 2.86175e-05
	LOSS [training: 0.4184009406967547 | validation: 0.7368064968304718]
	TIME [epoch: 9.49 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4063523282195563		[learning rate: 2.8514e-05]
	Learning Rate: 2.85136e-05
	LOSS [training: 0.4063523282195563 | validation: 0.7198542624311068]
	TIME [epoch: 9.48 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41916492770073716		[learning rate: 2.841e-05]
	Learning Rate: 2.84102e-05
	LOSS [training: 0.41916492770073716 | validation: 0.7298074493620206]
	TIME [epoch: 9.49 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4157739715112919		[learning rate: 2.8307e-05]
	Learning Rate: 2.83071e-05
	LOSS [training: 0.4157739715112919 | validation: 0.714676851818962]
	TIME [epoch: 9.5 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4127853538351987		[learning rate: 2.8204e-05]
	Learning Rate: 2.82043e-05
	LOSS [training: 0.4127853538351987 | validation: 0.7263049958169995]
	TIME [epoch: 9.48 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4255250994739564		[learning rate: 2.8102e-05]
	Learning Rate: 2.8102e-05
	LOSS [training: 0.4255250994739564 | validation: 0.7289356814499663]
	TIME [epoch: 9.49 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4215136947330344		[learning rate: 2.8e-05]
	Learning Rate: 2.8e-05
	LOSS [training: 0.4215136947330344 | validation: 0.7484122980954586]
	TIME [epoch: 9.51 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42282323133488864		[learning rate: 2.7898e-05]
	Learning Rate: 2.78984e-05
	LOSS [training: 0.42282323133488864 | validation: 0.6949495486332279]
	TIME [epoch: 9.49 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4077914872678111		[learning rate: 2.7797e-05]
	Learning Rate: 2.77971e-05
	LOSS [training: 0.4077914872678111 | validation: 0.7102034754159229]
	TIME [epoch: 9.5 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4277994848235534		[learning rate: 2.7696e-05]
	Learning Rate: 2.76963e-05
	LOSS [training: 0.4277994848235534 | validation: 0.7267479526288585]
	TIME [epoch: 9.5 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41300505716810554		[learning rate: 2.7596e-05]
	Learning Rate: 2.75957e-05
	LOSS [training: 0.41300505716810554 | validation: 0.7276625314073087]
	TIME [epoch: 9.5 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41816346550167205		[learning rate: 2.7496e-05]
	Learning Rate: 2.74956e-05
	LOSS [training: 0.41816346550167205 | validation: 0.6996934704130454]
	TIME [epoch: 9.5 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41497260220767807		[learning rate: 2.7396e-05]
	Learning Rate: 2.73958e-05
	LOSS [training: 0.41497260220767807 | validation: 0.7191857569460892]
	TIME [epoch: 9.49 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42024613379633413		[learning rate: 2.7296e-05]
	Learning Rate: 2.72964e-05
	LOSS [training: 0.42024613379633413 | validation: 0.6964360546090896]
	TIME [epoch: 9.51 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.421274428648596		[learning rate: 2.7197e-05]
	Learning Rate: 2.71973e-05
	LOSS [training: 0.421274428648596 | validation: 0.7207751737460981]
	TIME [epoch: 9.49 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4240462881475316		[learning rate: 2.7099e-05]
	Learning Rate: 2.70986e-05
	LOSS [training: 0.4240462881475316 | validation: 0.7189162492870739]
	TIME [epoch: 9.49 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42605931063373587		[learning rate: 2.7e-05]
	Learning Rate: 2.70003e-05
	LOSS [training: 0.42605931063373587 | validation: 0.7105837847568887]
	TIME [epoch: 9.5 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.427349856455087		[learning rate: 2.6902e-05]
	Learning Rate: 2.69023e-05
	LOSS [training: 0.427349856455087 | validation: 0.7196667824037809]
	TIME [epoch: 9.5 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42529896977741866		[learning rate: 2.6805e-05]
	Learning Rate: 2.68047e-05
	LOSS [training: 0.42529896977741866 | validation: 0.7050767606647312]
	TIME [epoch: 9.49 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41737748569119476		[learning rate: 2.6707e-05]
	Learning Rate: 2.67074e-05
	LOSS [training: 0.41737748569119476 | validation: 0.7107584448899266]
	TIME [epoch: 9.49 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4172302109019707		[learning rate: 2.661e-05]
	Learning Rate: 2.66105e-05
	LOSS [training: 0.4172302109019707 | validation: 0.6956122186631681]
	TIME [epoch: 9.52 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4196563637951304		[learning rate: 2.6514e-05]
	Learning Rate: 2.65139e-05
	LOSS [training: 0.4196563637951304 | validation: 0.7077113310189717]
	TIME [epoch: 9.49 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40729953608443525		[learning rate: 2.6418e-05]
	Learning Rate: 2.64177e-05
	LOSS [training: 0.40729953608443525 | validation: 0.7113505850578565]
	TIME [epoch: 9.5 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42286421600093577		[learning rate: 2.6322e-05]
	Learning Rate: 2.63218e-05
	LOSS [training: 0.42286421600093577 | validation: 0.723564247853225]
	TIME [epoch: 9.51 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41917971274826		[learning rate: 2.6226e-05]
	Learning Rate: 2.62263e-05
	LOSS [training: 0.41917971274826 | validation: 0.7203283857945678]
	TIME [epoch: 9.5 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4155407469165887		[learning rate: 2.6131e-05]
	Learning Rate: 2.61311e-05
	LOSS [training: 0.4155407469165887 | validation: 0.7299701966943787]
	TIME [epoch: 9.5 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42472442312891545		[learning rate: 2.6036e-05]
	Learning Rate: 2.60363e-05
	LOSS [training: 0.42472442312891545 | validation: 0.7189492150624676]
	TIME [epoch: 9.49 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41274702609576536		[learning rate: 2.5942e-05]
	Learning Rate: 2.59418e-05
	LOSS [training: 0.41274702609576536 | validation: 0.7226127393131587]
	TIME [epoch: 9.52 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.421330350240143		[learning rate: 2.5848e-05]
	Learning Rate: 2.58477e-05
	LOSS [training: 0.421330350240143 | validation: 0.7597534890352183]
	TIME [epoch: 9.49 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42324007690433374		[learning rate: 2.5754e-05]
	Learning Rate: 2.57539e-05
	LOSS [training: 0.42324007690433374 | validation: 0.7388357155358852]
	TIME [epoch: 9.49 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42494403719229873		[learning rate: 2.566e-05]
	Learning Rate: 2.56604e-05
	LOSS [training: 0.42494403719229873 | validation: 0.7203205811787123]
	TIME [epoch: 9.51 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41812467360840877		[learning rate: 2.5567e-05]
	Learning Rate: 2.55673e-05
	LOSS [training: 0.41812467360840877 | validation: 0.7358374647570779]
	TIME [epoch: 9.49 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4242096356316095		[learning rate: 2.5474e-05]
	Learning Rate: 2.54745e-05
	LOSS [training: 0.4242096356316095 | validation: 0.7405498577330656]
	TIME [epoch: 9.49 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4244371338707721		[learning rate: 2.5382e-05]
	Learning Rate: 2.5382e-05
	LOSS [training: 0.4244371338707721 | validation: 0.7279737761562146]
	TIME [epoch: 9.49 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4254295527762252		[learning rate: 2.529e-05]
	Learning Rate: 2.52899e-05
	LOSS [training: 0.4254295527762252 | validation: 0.7145207771270023]
	TIME [epoch: 9.51 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4277166105397865		[learning rate: 2.5198e-05]
	Learning Rate: 2.51981e-05
	LOSS [training: 0.4277166105397865 | validation: 0.7144093624986049]
	TIME [epoch: 9.49 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41407523543094243		[learning rate: 2.5107e-05]
	Learning Rate: 2.51067e-05
	LOSS [training: 0.41407523543094243 | validation: 0.7188829524153862]
	TIME [epoch: 9.49 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41993650968175744		[learning rate: 2.5016e-05]
	Learning Rate: 2.50156e-05
	LOSS [training: 0.41993650968175744 | validation: 0.7108668121382528]
	TIME [epoch: 9.5 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4235237840181892		[learning rate: 2.4925e-05]
	Learning Rate: 2.49248e-05
	LOSS [training: 0.4235237840181892 | validation: 0.7136956349363344]
	TIME [epoch: 9.49 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4032185995548521		[learning rate: 2.4834e-05]
	Learning Rate: 2.48343e-05
	LOSS [training: 0.4032185995548521 | validation: 0.7013278351768368]
	TIME [epoch: 9.49 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41564405707959046		[learning rate: 2.4744e-05]
	Learning Rate: 2.47442e-05
	LOSS [training: 0.41564405707959046 | validation: 0.7308306610560342]
	TIME [epoch: 9.49 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4170883197691687		[learning rate: 2.4654e-05]
	Learning Rate: 2.46544e-05
	LOSS [training: 0.4170883197691687 | validation: 0.7302222752090611]
	TIME [epoch: 9.51 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41714474270613283		[learning rate: 2.4565e-05]
	Learning Rate: 2.45649e-05
	LOSS [training: 0.41714474270613283 | validation: 0.735353381274889]
	TIME [epoch: 9.49 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4296147994242605		[learning rate: 2.4476e-05]
	Learning Rate: 2.44758e-05
	LOSS [training: 0.4296147994242605 | validation: 0.7184533836593471]
	TIME [epoch: 9.49 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41567553416216974		[learning rate: 2.4387e-05]
	Learning Rate: 2.4387e-05
	LOSS [training: 0.41567553416216974 | validation: 0.7441288485205476]
	TIME [epoch: 9.5 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4323851739040599		[learning rate: 2.4298e-05]
	Learning Rate: 2.42985e-05
	LOSS [training: 0.4323851739040599 | validation: 0.7119765082479458]
	TIME [epoch: 9.5 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4232131035610755		[learning rate: 2.421e-05]
	Learning Rate: 2.42103e-05
	LOSS [training: 0.4232131035610755 | validation: 0.7345829827757456]
	TIME [epoch: 9.49 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4225330798017268		[learning rate: 2.4122e-05]
	Learning Rate: 2.41224e-05
	LOSS [training: 0.4225330798017268 | validation: 0.6846019144328608]
	TIME [epoch: 9.49 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43040007322107987		[learning rate: 2.4035e-05]
	Learning Rate: 2.40349e-05
	LOSS [training: 0.43040007322107987 | validation: 0.6936363592264002]
	TIME [epoch: 9.51 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42167763575881506		[learning rate: 2.3948e-05]
	Learning Rate: 2.39477e-05
	LOSS [training: 0.42167763575881506 | validation: 0.712650933712454]
	TIME [epoch: 9.49 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42849750129735015		[learning rate: 2.3861e-05]
	Learning Rate: 2.38608e-05
	LOSS [training: 0.42849750129735015 | validation: 0.7048373817820442]
	TIME [epoch: 9.49 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4210566273437883		[learning rate: 2.3774e-05]
	Learning Rate: 2.37742e-05
	LOSS [training: 0.4210566273437883 | validation: 0.7309323748407454]
	TIME [epoch: 9.5 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4209979279199481		[learning rate: 2.3688e-05]
	Learning Rate: 2.36879e-05
	LOSS [training: 0.4209979279199481 | validation: 0.7429621609360205]
	TIME [epoch: 9.49 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40561398592179954		[learning rate: 2.3602e-05]
	Learning Rate: 2.36019e-05
	LOSS [training: 0.40561398592179954 | validation: 0.7087392132131665]
	TIME [epoch: 9.49 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4139209972673211		[learning rate: 2.3516e-05]
	Learning Rate: 2.35163e-05
	LOSS [training: 0.4139209972673211 | validation: 0.7080690806319739]
	TIME [epoch: 9.48 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4212762844275472		[learning rate: 2.3431e-05]
	Learning Rate: 2.34309e-05
	LOSS [training: 0.4212762844275472 | validation: 0.7025788583197923]
	TIME [epoch: 9.5 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4306249585778417		[learning rate: 2.3346e-05]
	Learning Rate: 2.33459e-05
	LOSS [training: 0.4306249585778417 | validation: 0.7178834777658388]
	TIME [epoch: 9.48 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4249959495021124		[learning rate: 2.3261e-05]
	Learning Rate: 2.32612e-05
	LOSS [training: 0.4249959495021124 | validation: 0.732295819819482]
	TIME [epoch: 9.5 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4122247447294686		[learning rate: 2.3177e-05]
	Learning Rate: 2.31768e-05
	LOSS [training: 0.4122247447294686 | validation: 0.7220083359957056]
	TIME [epoch: 9.51 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41149540663156187		[learning rate: 2.3093e-05]
	Learning Rate: 2.30926e-05
	LOSS [training: 0.41149540663156187 | validation: 0.7184756492488525]
	TIME [epoch: 9.49 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40965562775839154		[learning rate: 2.3009e-05]
	Learning Rate: 2.30088e-05
	LOSS [training: 0.40965562775839154 | validation: 0.7344306591850659]
	TIME [epoch: 9.49 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41015872486505306		[learning rate: 2.2925e-05]
	Learning Rate: 2.29253e-05
	LOSS [training: 0.41015872486505306 | validation: 0.6896073411660737]
	TIME [epoch: 9.49 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4264892102482255		[learning rate: 2.2842e-05]
	Learning Rate: 2.28421e-05
	LOSS [training: 0.4264892102482255 | validation: 0.762989011712232]
	TIME [epoch: 9.5 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40746887390365655		[learning rate: 2.2759e-05]
	Learning Rate: 2.27592e-05
	LOSS [training: 0.40746887390365655 | validation: 0.7213504268282668]
	TIME [epoch: 9.49 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4140398616610529		[learning rate: 2.2677e-05]
	Learning Rate: 2.26767e-05
	LOSS [training: 0.4140398616610529 | validation: 0.7143927629433212]
	TIME [epoch: 9.49 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4174928365736149		[learning rate: 2.2594e-05]
	Learning Rate: 2.25944e-05
	LOSS [training: 0.4174928365736149 | validation: 0.710794014004928]
	TIME [epoch: 9.51 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42226727950829224		[learning rate: 2.2512e-05]
	Learning Rate: 2.25124e-05
	LOSS [training: 0.42226727950829224 | validation: 0.7299402494945642]
	TIME [epoch: 9.49 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40734335264445065		[learning rate: 2.2431e-05]
	Learning Rate: 2.24307e-05
	LOSS [training: 0.40734335264445065 | validation: 0.7183250246923959]
	TIME [epoch: 9.49 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40853835954087137		[learning rate: 2.2349e-05]
	Learning Rate: 2.23493e-05
	LOSS [training: 0.40853835954087137 | validation: 0.7109671451102235]
	TIME [epoch: 9.49 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40908492741816094		[learning rate: 2.2268e-05]
	Learning Rate: 2.22682e-05
	LOSS [training: 0.40908492741816094 | validation: 0.7290455016623344]
	TIME [epoch: 9.51 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42356118543128246		[learning rate: 2.2187e-05]
	Learning Rate: 2.21873e-05
	LOSS [training: 0.42356118543128246 | validation: 0.7045998292068987]
	TIME [epoch: 9.49 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4067545239568533		[learning rate: 2.2107e-05]
	Learning Rate: 2.21068e-05
	LOSS [training: 0.4067545239568533 | validation: 0.704621335280155]
	TIME [epoch: 9.49 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42158969449976347		[learning rate: 2.2027e-05]
	Learning Rate: 2.20266e-05
	LOSS [training: 0.42158969449976347 | validation: 0.7187605548856729]
	TIME [epoch: 9.5 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4151396773310946		[learning rate: 2.1947e-05]
	Learning Rate: 2.19467e-05
	LOSS [training: 0.4151396773310946 | validation: 0.6987722681628712]
	TIME [epoch: 9.49 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4208944472945898		[learning rate: 2.1867e-05]
	Learning Rate: 2.1867e-05
	LOSS [training: 0.4208944472945898 | validation: 0.7343735080064476]
	TIME [epoch: 9.48 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4213234098200543		[learning rate: 2.1788e-05]
	Learning Rate: 2.17877e-05
	LOSS [training: 0.4213234098200543 | validation: 0.6938149706813124]
	TIME [epoch: 9.49 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41471178647270623		[learning rate: 2.1709e-05]
	Learning Rate: 2.17086e-05
	LOSS [training: 0.41471178647270623 | validation: 0.7374792185892483]
	TIME [epoch: 9.5 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4108573878465446		[learning rate: 2.163e-05]
	Learning Rate: 2.16298e-05
	LOSS [training: 0.4108573878465446 | validation: 0.7399807522214829]
	TIME [epoch: 9.49 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4146184239481542		[learning rate: 2.1551e-05]
	Learning Rate: 2.15513e-05
	LOSS [training: 0.4146184239481542 | validation: 0.710099272878865]
	TIME [epoch: 9.49 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4154959511351713		[learning rate: 2.1473e-05]
	Learning Rate: 2.14731e-05
	LOSS [training: 0.4154959511351713 | validation: 0.7196404863149616]
	TIME [epoch: 9.5 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42472528679225235		[learning rate: 2.1395e-05]
	Learning Rate: 2.13952e-05
	LOSS [training: 0.42472528679225235 | validation: 0.7378380390504939]
	TIME [epoch: 9.49 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41781487620988217		[learning rate: 2.1318e-05]
	Learning Rate: 2.13175e-05
	LOSS [training: 0.41781487620988217 | validation: 0.7378870000570676]
	TIME [epoch: 9.49 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42090336056848654		[learning rate: 2.124e-05]
	Learning Rate: 2.12402e-05
	LOSS [training: 0.42090336056848654 | validation: 0.7297088161493437]
	TIME [epoch: 9.48 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4196484047033885		[learning rate: 2.1163e-05]
	Learning Rate: 2.11631e-05
	LOSS [training: 0.4196484047033885 | validation: 0.7307105344646476]
	TIME [epoch: 9.5 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4196611961434362		[learning rate: 2.1086e-05]
	Learning Rate: 2.10863e-05
	LOSS [training: 0.4196611961434362 | validation: 0.7387159016936928]
	TIME [epoch: 9.48 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40777409347568244		[learning rate: 2.101e-05]
	Learning Rate: 2.10098e-05
	LOSS [training: 0.40777409347568244 | validation: 0.7366403984352428]
	TIME [epoch: 9.5 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4177080482183804		[learning rate: 2.0934e-05]
	Learning Rate: 2.09335e-05
	LOSS [training: 0.4177080482183804 | validation: 0.7359818833151431]
	TIME [epoch: 9.52 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41855967182521275		[learning rate: 2.0858e-05]
	Learning Rate: 2.08575e-05
	LOSS [training: 0.41855967182521275 | validation: 0.7086773801179581]
	TIME [epoch: 9.5 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41866096837880395		[learning rate: 2.0782e-05]
	Learning Rate: 2.07819e-05
	LOSS [training: 0.41866096837880395 | validation: 0.71627207476513]
	TIME [epoch: 9.5 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4110935164306831		[learning rate: 2.0706e-05]
	Learning Rate: 2.07064e-05
	LOSS [training: 0.4110935164306831 | validation: 0.7150784339514965]
	TIME [epoch: 9.51 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4119053477778376		[learning rate: 2.0631e-05]
	Learning Rate: 2.06313e-05
	LOSS [training: 0.4119053477778376 | validation: 0.7165015859199045]
	TIME [epoch: 9.51 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4183321904232966		[learning rate: 2.0556e-05]
	Learning Rate: 2.05564e-05
	LOSS [training: 0.4183321904232966 | validation: 0.7411425024939393]
	TIME [epoch: 9.5 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4142308912549638		[learning rate: 2.0482e-05]
	Learning Rate: 2.04818e-05
	LOSS [training: 0.4142308912549638 | validation: 0.7272193215738461]
	TIME [epoch: 9.51 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4057722494858441		[learning rate: 2.0407e-05]
	Learning Rate: 2.04075e-05
	LOSS [training: 0.4057722494858441 | validation: 0.7186522681872213]
	TIME [epoch: 9.52 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42223185886820874		[learning rate: 2.0333e-05]
	Learning Rate: 2.03334e-05
	LOSS [training: 0.42223185886820874 | validation: 0.7204222280288468]
	TIME [epoch: 9.5 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4234946121043901		[learning rate: 2.026e-05]
	Learning Rate: 2.02596e-05
	LOSS [training: 0.4234946121043901 | validation: 0.7058291178380628]
	TIME [epoch: 9.51 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4063374215725915		[learning rate: 2.0186e-05]
	Learning Rate: 2.01861e-05
	LOSS [training: 0.4063374215725915 | validation: 0.7210613336078288]
	TIME [epoch: 9.51 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41900950570039563		[learning rate: 2.0113e-05]
	Learning Rate: 2.01129e-05
	LOSS [training: 0.41900950570039563 | validation: 0.7192292649642752]
	TIME [epoch: 9.51 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42680057068599053		[learning rate: 2.004e-05]
	Learning Rate: 2.00399e-05
	LOSS [training: 0.42680057068599053 | validation: 0.7220612447148023]
	TIME [epoch: 9.51 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41819200172708315		[learning rate: 1.9967e-05]
	Learning Rate: 1.99671e-05
	LOSS [training: 0.41819200172708315 | validation: 0.7432766745593077]
	TIME [epoch: 9.5 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41146002527704917		[learning rate: 1.9895e-05]
	Learning Rate: 1.98947e-05
	LOSS [training: 0.41146002527704917 | validation: 0.7247531738018523]
	TIME [epoch: 9.52 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.415471382832616		[learning rate: 1.9822e-05]
	Learning Rate: 1.98225e-05
	LOSS [training: 0.415471382832616 | validation: 0.7487693585872129]
	TIME [epoch: 9.51 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42504634537620395		[learning rate: 1.9751e-05]
	Learning Rate: 1.97505e-05
	LOSS [training: 0.42504634537620395 | validation: 0.7416303497042713]
	TIME [epoch: 9.5 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4325958381413206		[learning rate: 1.9679e-05]
	Learning Rate: 1.96789e-05
	LOSS [training: 0.4325958381413206 | validation: 0.7016412219240012]
	TIME [epoch: 9.52 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41587622650862066		[learning rate: 1.9607e-05]
	Learning Rate: 1.96074e-05
	LOSS [training: 0.41587622650862066 | validation: 0.7228421774610431]
	TIME [epoch: 9.5 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4192555628182836		[learning rate: 1.9536e-05]
	Learning Rate: 1.95363e-05
	LOSS [training: 0.4192555628182836 | validation: 0.7250514802002082]
	TIME [epoch: 9.5 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4085515557355266		[learning rate: 1.9465e-05]
	Learning Rate: 1.94654e-05
	LOSS [training: 0.4085515557355266 | validation: 0.7165969576691782]
	TIME [epoch: 9.5 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41711500945607743		[learning rate: 1.9395e-05]
	Learning Rate: 1.93948e-05
	LOSS [training: 0.41711500945607743 | validation: 0.7073464251786901]
	TIME [epoch: 9.52 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4137445880015189		[learning rate: 1.9324e-05]
	Learning Rate: 1.93244e-05
	LOSS [training: 0.4137445880015189 | validation: 0.713577043628504]
	TIME [epoch: 9.5 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43181766132184796		[learning rate: 1.9254e-05]
	Learning Rate: 1.92542e-05
	LOSS [training: 0.43181766132184796 | validation: 0.7152694704142135]
	TIME [epoch: 9.51 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42185952966989254		[learning rate: 1.9184e-05]
	Learning Rate: 1.91844e-05
	LOSS [training: 0.42185952966989254 | validation: 0.7485621233335662]
	TIME [epoch: 9.52 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41352352684794863		[learning rate: 1.9115e-05]
	Learning Rate: 1.91147e-05
	LOSS [training: 0.41352352684794863 | validation: 0.7123751837473375]
	TIME [epoch: 9.5 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4154085578598791		[learning rate: 1.9045e-05]
	Learning Rate: 1.90454e-05
	LOSS [training: 0.4154085578598791 | validation: 0.7068393270940425]
	TIME [epoch: 9.5 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42175792832132875		[learning rate: 1.8976e-05]
	Learning Rate: 1.89763e-05
	LOSS [training: 0.42175792832132875 | validation: 0.714782110769]
	TIME [epoch: 9.5 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41706092644693343		[learning rate: 1.8907e-05]
	Learning Rate: 1.89074e-05
	LOSS [training: 0.41706092644693343 | validation: 0.7167474074817147]
	TIME [epoch: 9.52 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4223782663049004		[learning rate: 1.8839e-05]
	Learning Rate: 1.88388e-05
	LOSS [training: 0.4223782663049004 | validation: 0.7473281888140644]
	TIME [epoch: 9.5 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4053062226821641		[learning rate: 1.877e-05]
	Learning Rate: 1.87704e-05
	LOSS [training: 0.4053062226821641 | validation: 0.7116087605720454]
	TIME [epoch: 9.49 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40709712228060424		[learning rate: 1.8702e-05]
	Learning Rate: 1.87023e-05
	LOSS [training: 0.40709712228060424 | validation: 0.7425847234753554]
	TIME [epoch: 9.52 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41807001258830223		[learning rate: 1.8634e-05]
	Learning Rate: 1.86344e-05
	LOSS [training: 0.41807001258830223 | validation: 0.7144212748845691]
	TIME [epoch: 9.5 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41558702027004457		[learning rate: 1.8567e-05]
	Learning Rate: 1.85668e-05
	LOSS [training: 0.41558702027004457 | validation: 0.7069130225603913]
	TIME [epoch: 9.49 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4093544906288621		[learning rate: 1.8499e-05]
	Learning Rate: 1.84994e-05
	LOSS [training: 0.4093544906288621 | validation: 0.7469414244697572]
	TIME [epoch: 9.49 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4164386129083094		[learning rate: 1.8432e-05]
	Learning Rate: 1.84323e-05
	LOSS [training: 0.4164386129083094 | validation: 0.7147527931651416]
	TIME [epoch: 9.52 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4206753620615132		[learning rate: 1.8365e-05]
	Learning Rate: 1.83654e-05
	LOSS [training: 0.4206753620615132 | validation: 0.7351658028624336]
	TIME [epoch: 9.5 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42447644860823297		[learning rate: 1.8299e-05]
	Learning Rate: 1.82987e-05
	LOSS [training: 0.42447644860823297 | validation: 0.7229369151801117]
	TIME [epoch: 9.49 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4111111498775964		[learning rate: 1.8232e-05]
	Learning Rate: 1.82323e-05
	LOSS [training: 0.4111111498775964 | validation: 0.7244854198324938]
	TIME [epoch: 9.51 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41974423907737723		[learning rate: 1.8166e-05]
	Learning Rate: 1.81662e-05
	LOSS [training: 0.41974423907737723 | validation: 0.7470690577671403]
	TIME [epoch: 9.5 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4270509998070737		[learning rate: 1.81e-05]
	Learning Rate: 1.81002e-05
	LOSS [training: 0.4270509998070737 | validation: 0.7318685500131296]
	TIME [epoch: 9.49 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4064180926363692		[learning rate: 1.8035e-05]
	Learning Rate: 1.80346e-05
	LOSS [training: 0.4064180926363692 | validation: 0.7255072591285423]
	TIME [epoch: 9.5 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4272111693973725		[learning rate: 1.7969e-05]
	Learning Rate: 1.79691e-05
	LOSS [training: 0.4272111693973725 | validation: 0.6961499346026699]
	TIME [epoch: 9.51 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41740324492251624		[learning rate: 1.7904e-05]
	Learning Rate: 1.79039e-05
	LOSS [training: 0.41740324492251624 | validation: 0.7080051754119749]
	TIME [epoch: 9.5 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4106461413483581		[learning rate: 1.7839e-05]
	Learning Rate: 1.78389e-05
	LOSS [training: 0.4106461413483581 | validation: 0.7225050158280558]
	TIME [epoch: 9.49 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4279340839577669		[learning rate: 1.7774e-05]
	Learning Rate: 1.77742e-05
	LOSS [training: 0.4279340839577669 | validation: 0.7134931317334864]
	TIME [epoch: 9.5 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.416247595170093		[learning rate: 1.771e-05]
	Learning Rate: 1.77097e-05
	LOSS [training: 0.416247595170093 | validation: 0.7358757521547261]
	TIME [epoch: 9.5 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4133957607970614		[learning rate: 1.7645e-05]
	Learning Rate: 1.76454e-05
	LOSS [training: 0.4133957607970614 | validation: 0.7253547520015715]
	TIME [epoch: 9.49 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4277953012228366		[learning rate: 1.7581e-05]
	Learning Rate: 1.75814e-05
	LOSS [training: 0.4277953012228366 | validation: 0.720609449255386]
	TIME [epoch: 9.49 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41883053717293384		[learning rate: 1.7518e-05]
	Learning Rate: 1.75176e-05
	LOSS [training: 0.41883053717293384 | validation: 0.7231120963877669]
	TIME [epoch: 9.5 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4147134280867301		[learning rate: 1.7454e-05]
	Learning Rate: 1.7454e-05
	LOSS [training: 0.4147134280867301 | validation: 0.732769230947483]
	TIME [epoch: 9.49 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4186960827842513		[learning rate: 1.7391e-05]
	Learning Rate: 1.73907e-05
	LOSS [training: 0.4186960827842513 | validation: 0.7273030795817315]
	TIME [epoch: 9.5 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4167089900575836		[learning rate: 1.7328e-05]
	Learning Rate: 1.73275e-05
	LOSS [training: 0.4167089900575836 | validation: 0.7286217768441913]
	TIME [epoch: 9.5 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41550014002529584		[learning rate: 1.7265e-05]
	Learning Rate: 1.72647e-05
	LOSS [training: 0.41550014002529584 | validation: 0.7188609753325491]
	TIME [epoch: 9.49 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41865524332243426		[learning rate: 1.7202e-05]
	Learning Rate: 1.7202e-05
	LOSS [training: 0.41865524332243426 | validation: 0.7340556407676587]
	TIME [epoch: 9.48 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42191085133846407		[learning rate: 1.714e-05]
	Learning Rate: 1.71396e-05
	LOSS [training: 0.42191085133846407 | validation: 0.7246869074630008]
	TIME [epoch: 9.49 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41126936669483405		[learning rate: 1.7077e-05]
	Learning Rate: 1.70774e-05
	LOSS [training: 0.41126936669483405 | validation: 0.7383824456277519]
	TIME [epoch: 9.5 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42095301768692306		[learning rate: 1.7015e-05]
	Learning Rate: 1.70154e-05
	LOSS [training: 0.42095301768692306 | validation: 0.710466681981276]
	TIME [epoch: 9.49 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4196661947640134		[learning rate: 1.6954e-05]
	Learning Rate: 1.69537e-05
	LOSS [training: 0.4196661947640134 | validation: 0.7451123693412178]
	TIME [epoch: 9.49 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41575086890457735		[learning rate: 1.6892e-05]
	Learning Rate: 1.68921e-05
	LOSS [training: 0.41575086890457735 | validation: 0.7429647867414434]
	TIME [epoch: 9.51 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4286488503285117		[learning rate: 1.6831e-05]
	Learning Rate: 1.68308e-05
	LOSS [training: 0.4286488503285117 | validation: 0.7310008424560107]
	TIME [epoch: 9.49 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4199208080388212		[learning rate: 1.677e-05]
	Learning Rate: 1.67697e-05
	LOSS [training: 0.4199208080388212 | validation: 0.7220815898570477]
	TIME [epoch: 9.49 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40805261844080115		[learning rate: 1.6709e-05]
	Learning Rate: 1.67089e-05
	LOSS [training: 0.40805261844080115 | validation: 0.7143537330052697]
	TIME [epoch: 9.49 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40768033814138815		[learning rate: 1.6648e-05]
	Learning Rate: 1.66482e-05
	LOSS [training: 0.40768033814138815 | validation: 0.7096016850417126]
	TIME [epoch: 9.51 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4153514280883875		[learning rate: 1.6588e-05]
	Learning Rate: 1.65878e-05
	LOSS [training: 0.4153514280883875 | validation: 0.7328034237110996]
	TIME [epoch: 9.49 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41658712141654003		[learning rate: 1.6528e-05]
	Learning Rate: 1.65276e-05
	LOSS [training: 0.41658712141654003 | validation: 0.7112237207328636]
	TIME [epoch: 9.49 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4158615192552594		[learning rate: 1.6468e-05]
	Learning Rate: 1.64677e-05
	LOSS [training: 0.4158615192552594 | validation: 0.7250478075129309]
	TIME [epoch: 9.51 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41365628025932316		[learning rate: 1.6408e-05]
	Learning Rate: 1.64079e-05
	LOSS [training: 0.41365628025932316 | validation: 0.7109402852757103]
	TIME [epoch: 9.49 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41014865970158654		[learning rate: 1.6348e-05]
	Learning Rate: 1.63483e-05
	LOSS [training: 0.41014865970158654 | validation: 0.7267449085390709]
	TIME [epoch: 9.49 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4189761145265625		[learning rate: 1.6289e-05]
	Learning Rate: 1.6289e-05
	LOSS [training: 0.4189761145265625 | validation: 0.7395051390379415]
	TIME [epoch: 9.5 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41426450045026286		[learning rate: 1.623e-05]
	Learning Rate: 1.62299e-05
	LOSS [training: 0.41426450045026286 | validation: 0.7237848266198695]
	TIME [epoch: 9.51 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4175476081116326		[learning rate: 1.6171e-05]
	Learning Rate: 1.6171e-05
	LOSS [training: 0.4175476081116326 | validation: 0.734915392992092]
	TIME [epoch: 9.49 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4065178705693239		[learning rate: 1.6112e-05]
	Learning Rate: 1.61123e-05
	LOSS [training: 0.4065178705693239 | validation: 0.6872972910374581]
	TIME [epoch: 9.5 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41424579147866003		[learning rate: 1.6054e-05]
	Learning Rate: 1.60538e-05
	LOSS [training: 0.41424579147866003 | validation: 0.7092089207500648]
	TIME [epoch: 9.51 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40948752922495746		[learning rate: 1.5996e-05]
	Learning Rate: 1.59956e-05
	LOSS [training: 0.40948752922495746 | validation: 0.7298282982178429]
	TIME [epoch: 9.5 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4183757237628812		[learning rate: 1.5938e-05]
	Learning Rate: 1.59375e-05
	LOSS [training: 0.4183757237628812 | validation: 0.7144342195186687]
	TIME [epoch: 9.48 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4181678459447252		[learning rate: 1.588e-05]
	Learning Rate: 1.58797e-05
	LOSS [training: 0.4181678459447252 | validation: 0.7034073822090643]
	TIME [epoch: 9.5 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4133938324009456		[learning rate: 1.5822e-05]
	Learning Rate: 1.58221e-05
	LOSS [training: 0.4133938324009456 | validation: 0.7292636970689099]
	TIME [epoch: 9.5 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41800719147458487		[learning rate: 1.5765e-05]
	Learning Rate: 1.57647e-05
	LOSS [training: 0.41800719147458487 | validation: 0.697970391922911]
	TIME [epoch: 9.5 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41392961391217237		[learning rate: 1.5707e-05]
	Learning Rate: 1.57074e-05
	LOSS [training: 0.41392961391217237 | validation: 0.7097440158029396]
	TIME [epoch: 9.49 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41963469833268485		[learning rate: 1.565e-05]
	Learning Rate: 1.56504e-05
	LOSS [training: 0.41963469833268485 | validation: 0.7247863791538146]
	TIME [epoch: 9.52 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40749197002777826		[learning rate: 1.5594e-05]
	Learning Rate: 1.55936e-05
	LOSS [training: 0.40749197002777826 | validation: 0.7102385610543098]
	TIME [epoch: 9.49 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4187284709338844		[learning rate: 1.5537e-05]
	Learning Rate: 1.5537e-05
	LOSS [training: 0.4187284709338844 | validation: 0.7336799298362057]
	TIME [epoch: 9.49 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41829536462330913		[learning rate: 1.5481e-05]
	Learning Rate: 1.54807e-05
	LOSS [training: 0.41829536462330913 | validation: 0.6997165309082446]
	TIME [epoch: 9.5 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41043372640602566		[learning rate: 1.5424e-05]
	Learning Rate: 1.54245e-05
	LOSS [training: 0.41043372640602566 | validation: 0.7179681840468772]
	TIME [epoch: 9.51 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4087149354857692		[learning rate: 1.5369e-05]
	Learning Rate: 1.53685e-05
	LOSS [training: 0.4087149354857692 | validation: 0.7151906827735846]
	TIME [epoch: 9.5 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4210271815312095		[learning rate: 1.5313e-05]
	Learning Rate: 1.53127e-05
	LOSS [training: 0.4210271815312095 | validation: 0.7356920004713555]
	TIME [epoch: 9.49 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4121033011569084		[learning rate: 1.5257e-05]
	Learning Rate: 1.52572e-05
	LOSS [training: 0.4121033011569084 | validation: 0.7231495428231403]
	TIME [epoch: 9.51 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41325840499508903		[learning rate: 1.5202e-05]
	Learning Rate: 1.52018e-05
	LOSS [training: 0.41325840499508903 | validation: 0.7294143813008543]
	TIME [epoch: 9.49 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42465039117850106		[learning rate: 1.5147e-05]
	Learning Rate: 1.51466e-05
	LOSS [training: 0.42465039117850106 | validation: 0.6994114288141703]
	TIME [epoch: 9.48 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.422762192880305		[learning rate: 1.5092e-05]
	Learning Rate: 1.50917e-05
	LOSS [training: 0.422762192880305 | validation: 0.7226630795284683]
	TIME [epoch: 9.51 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4229029268014711		[learning rate: 1.5037e-05]
	Learning Rate: 1.50369e-05
	LOSS [training: 0.4229029268014711 | validation: 0.7140916247073759]
	TIME [epoch: 9.49 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3966016498594208		[learning rate: 1.4982e-05]
	Learning Rate: 1.49823e-05
	LOSS [training: 0.3966016498594208 | validation: 0.7206632375048811]
	TIME [epoch: 9.49 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41538350337691615		[learning rate: 1.4928e-05]
	Learning Rate: 1.49279e-05
	LOSS [training: 0.41538350337691615 | validation: 0.716398535479393]
	TIME [epoch: 9.49 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4113602597305258		[learning rate: 1.4874e-05]
	Learning Rate: 1.48738e-05
	LOSS [training: 0.4113602597305258 | validation: 0.725648950057952]
	TIME [epoch: 9.5 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4235833426647031		[learning rate: 1.482e-05]
	Learning Rate: 1.48198e-05
	LOSS [training: 0.4235833426647031 | validation: 0.7113071627416179]
	TIME [epoch: 9.49 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41002383208008786		[learning rate: 1.4766e-05]
	Learning Rate: 1.4766e-05
	LOSS [training: 0.41002383208008786 | validation: 0.697610031364097]
	TIME [epoch: 9.48 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41114800899409953		[learning rate: 1.4712e-05]
	Learning Rate: 1.47124e-05
	LOSS [training: 0.41114800899409953 | validation: 0.7164787570593992]
	TIME [epoch: 9.51 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42107920376493635		[learning rate: 1.4659e-05]
	Learning Rate: 1.4659e-05
	LOSS [training: 0.42107920376493635 | validation: 0.719406157501705]
	TIME [epoch: 9.49 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4138562385905787		[learning rate: 1.4606e-05]
	Learning Rate: 1.46058e-05
	LOSS [training: 0.4138562385905787 | validation: 0.7246932296210485]
	TIME [epoch: 9.49 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42578561964014605		[learning rate: 1.4553e-05]
	Learning Rate: 1.45528e-05
	LOSS [training: 0.42578561964014605 | validation: 0.7167954155825961]
	TIME [epoch: 9.5 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4150014398000942		[learning rate: 1.45e-05]
	Learning Rate: 1.45e-05
	LOSS [training: 0.4150014398000942 | validation: 0.7272839574107167]
	TIME [epoch: 9.51 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4158836931767517		[learning rate: 1.4447e-05]
	Learning Rate: 1.44474e-05
	LOSS [training: 0.4158836931767517 | validation: 0.708664076124069]
	TIME [epoch: 9.49 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4275895270729744		[learning rate: 1.4395e-05]
	Learning Rate: 1.4395e-05
	LOSS [training: 0.4275895270729744 | validation: 0.7139266661674389]
	TIME [epoch: 9.49 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4066258178727062		[learning rate: 1.4343e-05]
	Learning Rate: 1.43427e-05
	LOSS [training: 0.4066258178727062 | validation: 0.6901163628475091]
	TIME [epoch: 9.51 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41889388364933317		[learning rate: 1.4291e-05]
	Learning Rate: 1.42907e-05
	LOSS [training: 0.41889388364933317 | validation: 0.7308179767601328]
	TIME [epoch: 9.5 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4142685255474431		[learning rate: 1.4239e-05]
	Learning Rate: 1.42388e-05
	LOSS [training: 0.4142685255474431 | validation: 0.7127406358489682]
	TIME [epoch: 9.5 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4073261011261403		[learning rate: 1.4187e-05]
	Learning Rate: 1.41871e-05
	LOSS [training: 0.4073261011261403 | validation: 0.7184635683662219]
	TIME [epoch: 9.49 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4225793075883793		[learning rate: 1.4136e-05]
	Learning Rate: 1.41357e-05
	LOSS [training: 0.4225793075883793 | validation: 0.7306453420928728]
	TIME [epoch: 9.51 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40650108416907854		[learning rate: 1.4084e-05]
	Learning Rate: 1.40844e-05
	LOSS [training: 0.40650108416907854 | validation: 0.7350654466130755]
	TIME [epoch: 9.49 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41775625142738376		[learning rate: 1.4033e-05]
	Learning Rate: 1.40332e-05
	LOSS [training: 0.41775625142738376 | validation: 0.6919368459063051]
	TIME [epoch: 9.5 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4216074787980862		[learning rate: 1.3982e-05]
	Learning Rate: 1.39823e-05
	LOSS [training: 0.4216074787980862 | validation: 0.7051781845972654]
	TIME [epoch: 9.51 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4163374664084872		[learning rate: 1.3932e-05]
	Learning Rate: 1.39316e-05
	LOSS [training: 0.4163374664084872 | validation: 0.7185283004654548]
	TIME [epoch: 9.5 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4184460625928487		[learning rate: 1.3881e-05]
	Learning Rate: 1.3881e-05
	LOSS [training: 0.4184460625928487 | validation: 0.7236660193855282]
	TIME [epoch: 9.49 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40451758457007997		[learning rate: 1.3831e-05]
	Learning Rate: 1.38306e-05
	LOSS [training: 0.40451758457007997 | validation: 0.7474454566112675]
	TIME [epoch: 9.5 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41942478697870894		[learning rate: 1.378e-05]
	Learning Rate: 1.37804e-05
	LOSS [training: 0.41942478697870894 | validation: 0.7153566028172165]
	TIME [epoch: 9.51 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41977597963878444		[learning rate: 1.373e-05]
	Learning Rate: 1.37304e-05
	LOSS [training: 0.41977597963878444 | validation: 0.7199886342184577]
	TIME [epoch: 9.49 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41941060788508705		[learning rate: 1.3681e-05]
	Learning Rate: 1.36806e-05
	LOSS [training: 0.41941060788508705 | validation: 0.7280008456684526]
	TIME [epoch: 9.49 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41742093283701953		[learning rate: 1.3631e-05]
	Learning Rate: 1.3631e-05
	LOSS [training: 0.41742093283701953 | validation: 0.7181692569053476]
	TIME [epoch: 9.51 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41778826866122254		[learning rate: 1.3581e-05]
	Learning Rate: 1.35815e-05
	LOSS [training: 0.41778826866122254 | validation: 0.7351662330922346]
	TIME [epoch: 9.5 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4135664342738816		[learning rate: 1.3532e-05]
	Learning Rate: 1.35322e-05
	LOSS [training: 0.4135664342738816 | validation: 0.7119195311409157]
	TIME [epoch: 9.49 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4162261430349313		[learning rate: 1.3483e-05]
	Learning Rate: 1.34831e-05
	LOSS [training: 0.4162261430349313 | validation: 0.710598761403306]
	TIME [epoch: 9.5 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42095946508824095		[learning rate: 1.3434e-05]
	Learning Rate: 1.34342e-05
	LOSS [training: 0.42095946508824095 | validation: 0.725523483195833]
	TIME [epoch: 9.51 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4156511441521548		[learning rate: 1.3385e-05]
	Learning Rate: 1.33854e-05
	LOSS [training: 0.4156511441521548 | validation: 0.6934082765100493]
	TIME [epoch: 9.49 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4186922788090971		[learning rate: 1.3337e-05]
	Learning Rate: 1.33368e-05
	LOSS [training: 0.4186922788090971 | validation: 0.707702575052917]
	TIME [epoch: 9.49 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41220318349339874		[learning rate: 1.3288e-05]
	Learning Rate: 1.32884e-05
	LOSS [training: 0.41220318349339874 | validation: 0.7212121488607016]
	TIME [epoch: 9.51 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4177019636363199		[learning rate: 1.324e-05]
	Learning Rate: 1.32402e-05
	LOSS [training: 0.4177019636363199 | validation: 0.7166418679795313]
	TIME [epoch: 9.5 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4121583240779648		[learning rate: 1.3192e-05]
	Learning Rate: 1.31922e-05
	LOSS [training: 0.4121583240779648 | validation: 0.7118220657187702]
	TIME [epoch: 9.49 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41834503536692924		[learning rate: 1.3144e-05]
	Learning Rate: 1.31443e-05
	LOSS [training: 0.41834503536692924 | validation: 0.7154436558198611]
	TIME [epoch: 9.5 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4110813005899362		[learning rate: 1.3097e-05]
	Learning Rate: 1.30966e-05
	LOSS [training: 0.4110813005899362 | validation: 0.7058046586488266]
	TIME [epoch: 9.51 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41213026264792096		[learning rate: 1.3049e-05]
	Learning Rate: 1.30491e-05
	LOSS [training: 0.41213026264792096 | validation: 0.7025491133929057]
	TIME [epoch: 9.51 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.415798757455781		[learning rate: 1.3002e-05]
	Learning Rate: 1.30017e-05
	LOSS [training: 0.415798757455781 | validation: 0.731424212868696]
	TIME [epoch: 9.49 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4161924914989494		[learning rate: 1.2955e-05]
	Learning Rate: 1.29545e-05
	LOSS [training: 0.4161924914989494 | validation: 0.7215783427545819]
	TIME [epoch: 9.52 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.414618319274861		[learning rate: 1.2907e-05]
	Learning Rate: 1.29075e-05
	LOSS [training: 0.414618319274861 | validation: 0.7064427261204478]
	TIME [epoch: 9.49 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42014230378545286		[learning rate: 1.2861e-05]
	Learning Rate: 1.28607e-05
	LOSS [training: 0.42014230378545286 | validation: 0.70933252563195]
	TIME [epoch: 9.5 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4200443684427859		[learning rate: 1.2814e-05]
	Learning Rate: 1.2814e-05
	LOSS [training: 0.4200443684427859 | validation: 0.7206011517087876]
	TIME [epoch: 9.49 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40746324291483366		[learning rate: 1.2767e-05]
	Learning Rate: 1.27675e-05
	LOSS [training: 0.40746324291483366 | validation: 0.7041762873890383]
	TIME [epoch: 9.5 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40021738452829075		[learning rate: 1.2721e-05]
	Learning Rate: 1.27212e-05
	LOSS [training: 0.40021738452829075 | validation: 0.7251132144423627]
	TIME [epoch: 9.49 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41718598860220324		[learning rate: 1.2675e-05]
	Learning Rate: 1.2675e-05
	LOSS [training: 0.41718598860220324 | validation: 0.7030077414053082]
	TIME [epoch: 9.5 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4232421149238575		[learning rate: 1.2629e-05]
	Learning Rate: 1.2629e-05
	LOSS [training: 0.4232421149238575 | validation: 0.721231606651709]
	TIME [epoch: 9.52 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42176290135589134		[learning rate: 1.2583e-05]
	Learning Rate: 1.25832e-05
	LOSS [training: 0.42176290135589134 | validation: 0.7138348468947625]
	TIME [epoch: 9.5 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40646881213117		[learning rate: 1.2537e-05]
	Learning Rate: 1.25375e-05
	LOSS [training: 0.40646881213117 | validation: 0.7183547155691848]
	TIME [epoch: 9.5 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4151132017258048		[learning rate: 1.2492e-05]
	Learning Rate: 1.2492e-05
	LOSS [training: 0.4151132017258048 | validation: 0.7218188640097578]
	TIME [epoch: 9.52 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41088829686765793		[learning rate: 1.2447e-05]
	Learning Rate: 1.24467e-05
	LOSS [training: 0.41088829686765793 | validation: 0.7125865394292181]
	TIME [epoch: 9.51 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41601491766479476		[learning rate: 1.2401e-05]
	Learning Rate: 1.24015e-05
	LOSS [training: 0.41601491766479476 | validation: 0.7180192285113572]
	TIME [epoch: 9.49 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4153864561991526		[learning rate: 1.2356e-05]
	Learning Rate: 1.23565e-05
	LOSS [training: 0.4153864561991526 | validation: 0.7206329560939392]
	TIME [epoch: 9.5 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41208927091881176		[learning rate: 1.2312e-05]
	Learning Rate: 1.23116e-05
	LOSS [training: 0.41208927091881176 | validation: 0.7114995865765434]
	TIME [epoch: 9.51 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41467902677669055		[learning rate: 1.2267e-05]
	Learning Rate: 1.2267e-05
	LOSS [training: 0.41467902677669055 | validation: 0.7340927095948863]
	TIME [epoch: 9.5 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41054798640234863		[learning rate: 1.2222e-05]
	Learning Rate: 1.22224e-05
	LOSS [training: 0.41054798640234863 | validation: 0.7348207499786575]
	TIME [epoch: 9.49 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40946912194396445		[learning rate: 1.2178e-05]
	Learning Rate: 1.21781e-05
	LOSS [training: 0.40946912194396445 | validation: 0.7146081832112168]
	TIME [epoch: 9.51 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41628013055588803		[learning rate: 1.2134e-05]
	Learning Rate: 1.21339e-05
	LOSS [training: 0.41628013055588803 | validation: 0.7144423896963561]
	TIME [epoch: 9.5 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4197298592380635		[learning rate: 1.209e-05]
	Learning Rate: 1.20899e-05
	LOSS [training: 0.4197298592380635 | validation: 0.7181155070598658]
	TIME [epoch: 9.49 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4234434684417948		[learning rate: 1.2046e-05]
	Learning Rate: 1.2046e-05
	LOSS [training: 0.4234434684417948 | validation: 0.727631662121929]
	TIME [epoch: 9.5 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4303487953143924		[learning rate: 1.2002e-05]
	Learning Rate: 1.20023e-05
	LOSS [training: 0.4303487953143924 | validation: 0.7202479005892316]
	TIME [epoch: 9.51 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4223765901731573		[learning rate: 1.1959e-05]
	Learning Rate: 1.19587e-05
	LOSS [training: 0.4223765901731573 | validation: 0.7089510977576822]
	TIME [epoch: 9.49 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4216227547529329		[learning rate: 1.1915e-05]
	Learning Rate: 1.19153e-05
	LOSS [training: 0.4216227547529329 | validation: 0.6884131880798193]
	TIME [epoch: 9.49 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42484939974414937		[learning rate: 1.1872e-05]
	Learning Rate: 1.18721e-05
	LOSS [training: 0.42484939974414937 | validation: 0.7243797949484927]
	TIME [epoch: 9.51 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.407420693746927		[learning rate: 1.1829e-05]
	Learning Rate: 1.1829e-05
	LOSS [training: 0.407420693746927 | validation: 0.7230584409084635]
	TIME [epoch: 9.5 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4201702207719826		[learning rate: 1.1786e-05]
	Learning Rate: 1.17861e-05
	LOSS [training: 0.4201702207719826 | validation: 0.7257480982454443]
	TIME [epoch: 9.49 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4241814800229521		[learning rate: 1.1743e-05]
	Learning Rate: 1.17433e-05
	LOSS [training: 0.4241814800229521 | validation: 0.7215646691636822]
	TIME [epoch: 9.49 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41306951111894774		[learning rate: 1.1701e-05]
	Learning Rate: 1.17007e-05
	LOSS [training: 0.41306951111894774 | validation: 0.7349824277711343]
	TIME [epoch: 9.51 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4173135682135719		[learning rate: 1.1658e-05]
	Learning Rate: 1.16582e-05
	LOSS [training: 0.4173135682135719 | validation: 0.7219658019635518]
	TIME [epoch: 9.49 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4151919798694161		[learning rate: 1.1616e-05]
	Learning Rate: 1.16159e-05
	LOSS [training: 0.4151919798694161 | validation: 0.6981214765709578]
	TIME [epoch: 9.49 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4195502238309789		[learning rate: 1.1574e-05]
	Learning Rate: 1.15737e-05
	LOSS [training: 0.4195502238309789 | validation: 0.7352004759084617]
	TIME [epoch: 9.51 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41162314629236435		[learning rate: 1.1532e-05]
	Learning Rate: 1.15317e-05
	LOSS [training: 0.41162314629236435 | validation: 0.7176447181878254]
	TIME [epoch: 9.5 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4150476903577901		[learning rate: 1.149e-05]
	Learning Rate: 1.14899e-05
	LOSS [training: 0.4150476903577901 | validation: 0.7204526435278368]
	TIME [epoch: 9.49 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4210411864460271		[learning rate: 1.1448e-05]
	Learning Rate: 1.14482e-05
	LOSS [training: 0.4210411864460271 | validation: 0.7452620741829814]
	TIME [epoch: 9.49 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41196496140039907		[learning rate: 1.1407e-05]
	Learning Rate: 1.14066e-05
	LOSS [training: 0.41196496140039907 | validation: 0.6974495692677596]
	TIME [epoch: 9.51 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42286383081180234		[learning rate: 1.1365e-05]
	Learning Rate: 1.13652e-05
	LOSS [training: 0.42286383081180234 | validation: 0.712131878158278]
	TIME [epoch: 9.5 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4240722308337707		[learning rate: 1.1324e-05]
	Learning Rate: 1.1324e-05
	LOSS [training: 0.4240722308337707 | validation: 0.7294339676400131]
	TIME [epoch: 9.49 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.411000113319045		[learning rate: 1.1283e-05]
	Learning Rate: 1.12829e-05
	LOSS [training: 0.411000113319045 | validation: 0.7118848820324319]
	TIME [epoch: 9.5 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.420963110049256		[learning rate: 1.1242e-05]
	Learning Rate: 1.1242e-05
	LOSS [training: 0.420963110049256 | validation: 0.7460255749369893]
	TIME [epoch: 9.49 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4121058080167902		[learning rate: 1.1201e-05]
	Learning Rate: 1.12012e-05
	LOSS [training: 0.4121058080167902 | validation: 0.7225772392181432]
	TIME [epoch: 9.5 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42985988392725083		[learning rate: 1.1161e-05]
	Learning Rate: 1.11605e-05
	LOSS [training: 0.42985988392725083 | validation: 0.7434649128140416]
	TIME [epoch: 9.5 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4172512306141421		[learning rate: 1.112e-05]
	Learning Rate: 1.112e-05
	LOSS [training: 0.4172512306141421 | validation: 0.7323527642591465]
	TIME [epoch: 9.52 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42486702886808353		[learning rate: 1.108e-05]
	Learning Rate: 1.10797e-05
	LOSS [training: 0.42486702886808353 | validation: 0.7562017475606387]
	TIME [epoch: 9.5 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42590695129024747		[learning rate: 1.1039e-05]
	Learning Rate: 1.10394e-05
	LOSS [training: 0.42590695129024747 | validation: 0.6954819152395276]
	TIME [epoch: 9.5 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4198194374175258		[learning rate: 1.0999e-05]
	Learning Rate: 1.09994e-05
	LOSS [training: 0.4198194374175258 | validation: 0.7149919281458003]
	TIME [epoch: 9.5 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4193368933575557		[learning rate: 1.0959e-05]
	Learning Rate: 1.09595e-05
	LOSS [training: 0.4193368933575557 | validation: 0.7194165441169704]
	TIME [epoch: 9.49 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42310933044710825		[learning rate: 1.092e-05]
	Learning Rate: 1.09197e-05
	LOSS [training: 0.42310933044710825 | validation: 0.7290921354263461]
	TIME [epoch: 9.49 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4125420524076252		[learning rate: 1.088e-05]
	Learning Rate: 1.08801e-05
	LOSS [training: 0.4125420524076252 | validation: 0.7162594672940696]
	TIME [epoch: 9.49 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42708612952936287		[learning rate: 1.0841e-05]
	Learning Rate: 1.08406e-05
	LOSS [training: 0.42708612952936287 | validation: 0.7172399657137086]
	TIME [epoch: 9.51 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41123202696669753		[learning rate: 1.0801e-05]
	Learning Rate: 1.08012e-05
	LOSS [training: 0.41123202696669753 | validation: 0.721699806749009]
	TIME [epoch: 9.49 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4099212490565387		[learning rate: 1.0762e-05]
	Learning Rate: 1.0762e-05
	LOSS [training: 0.4099212490565387 | validation: 0.7135964098006764]
	TIME [epoch: 9.5 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41967561449156277		[learning rate: 1.0723e-05]
	Learning Rate: 1.0723e-05
	LOSS [training: 0.41967561449156277 | validation: 0.7354747638157497]
	TIME [epoch: 9.51 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42142934232387086		[learning rate: 1.0684e-05]
	Learning Rate: 1.06841e-05
	LOSS [training: 0.42142934232387086 | validation: 0.7058275835853351]
	TIME [epoch: 9.5 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41827604444170347		[learning rate: 1.0645e-05]
	Learning Rate: 1.06453e-05
	LOSS [training: 0.41827604444170347 | validation: 0.7164684421566117]
	TIME [epoch: 9.5 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4157275805484937		[learning rate: 1.0607e-05]
	Learning Rate: 1.06067e-05
	LOSS [training: 0.4157275805484937 | validation: 0.6982206177564231]
	TIME [epoch: 9.5 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4172398403743685		[learning rate: 1.0568e-05]
	Learning Rate: 1.05682e-05
	LOSS [training: 0.4172398403743685 | validation: 0.7222889154447936]
	TIME [epoch: 9.51 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4209617925749087		[learning rate: 1.053e-05]
	Learning Rate: 1.05298e-05
	LOSS [training: 0.4209617925749087 | validation: 0.7480937816466589]
	TIME [epoch: 9.49 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4084827152656015		[learning rate: 1.0492e-05]
	Learning Rate: 1.04916e-05
	LOSS [training: 0.4084827152656015 | validation: 0.7297190482464793]
	TIME [epoch: 9.49 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41512404012582066		[learning rate: 1.0454e-05]
	Learning Rate: 1.04535e-05
	LOSS [training: 0.41512404012582066 | validation: 0.7243692265355779]
	TIME [epoch: 9.52 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4136501844277432		[learning rate: 1.0416e-05]
	Learning Rate: 1.04156e-05
	LOSS [training: 0.4136501844277432 | validation: 0.7014905599543936]
	TIME [epoch: 9.51 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39892708541360655		[learning rate: 1.0378e-05]
	Learning Rate: 1.03778e-05
	LOSS [training: 0.39892708541360655 | validation: 0.729370518919012]
	TIME [epoch: 9.5 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41111936069215566		[learning rate: 1.034e-05]
	Learning Rate: 1.03401e-05
	LOSS [training: 0.41111936069215566 | validation: 0.7097745836711531]
	TIME [epoch: 9.5 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41067261369585173		[learning rate: 1.0303e-05]
	Learning Rate: 1.03026e-05
	LOSS [training: 0.41067261369585173 | validation: 0.7119434212903282]
	TIME [epoch: 9.51 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40850536884991706		[learning rate: 1.0265e-05]
	Learning Rate: 1.02652e-05
	LOSS [training: 0.40850536884991706 | validation: 0.7193472797613921]
	TIME [epoch: 9.49 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42331341294043573		[learning rate: 1.0228e-05]
	Learning Rate: 1.0228e-05
	LOSS [training: 0.42331341294043573 | validation: 0.7110885160064169]
	TIME [epoch: 9.5 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41162141840409283		[learning rate: 1.0191e-05]
	Learning Rate: 1.01909e-05
	LOSS [training: 0.41162141840409283 | validation: 0.7015948785550137]
	TIME [epoch: 9.51 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4269589793449894		[learning rate: 1.0154e-05]
	Learning Rate: 1.01539e-05
	LOSS [training: 0.4269589793449894 | validation: 0.7371588971201537]
	TIME [epoch: 9.5 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42488342532845297		[learning rate: 1.0117e-05]
	Learning Rate: 1.0117e-05
	LOSS [training: 0.42488342532845297 | validation: 0.7256648484009665]
	TIME [epoch: 9.51 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4178253948675241		[learning rate: 1.008e-05]
	Learning Rate: 1.00803e-05
	LOSS [training: 0.4178253948675241 | validation: 0.7344937387509529]
	TIME [epoch: 9.5 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4240658665617305		[learning rate: 1.0044e-05]
	Learning Rate: 1.00437e-05
	LOSS [training: 0.4240658665617305 | validation: 0.7174911807945281]
	TIME [epoch: 9.51 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4187597373073908		[learning rate: 1.0007e-05]
	Learning Rate: 1.00073e-05
	LOSS [training: 0.4187597373073908 | validation: 0.720349922408519]
	TIME [epoch: 9.5 sec]
Finished training in 19263.862 seconds.
