Args:
Namespace(name='model_tr_study205', outdir='out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3', training_data='data/transition_rate_studies/tr_study205/tr_study205_training/r3', validation_data='data/transition_rate_studies/tr_study205/tr_study205_validation/r3', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.075, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=100, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 4019583870

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 5/5] avg loss: 13.148989104923164		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 13.148989104923164 | validation: 13.542629839863766]
	TIME [epoch: 79.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 5/5] avg loss: 13.010079758819987		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 13.010079758819987 | validation: 10.428586348649683]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 5/5] avg loss: 12.221448162801185		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 12.221448162801185 | validation: 12.029188639096038]
	TIME [epoch: 9.53 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 5/5] avg loss: 11.491555048091623		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.491555048091623 | validation: 9.779238304480444]
	TIME [epoch: 9.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 5/5] avg loss: 11.769814929692552		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.769814929692552 | validation: 12.143027264984626]
	TIME [epoch: 9.52 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 5/5] avg loss: 11.377165745910283		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.377165745910283 | validation: 11.397090643115675]
	TIME [epoch: 9.53 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 5/5] avg loss: 10.33313542664445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.33313542664445 | validation: 10.20681952662714]
	TIME [epoch: 9.55 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.330666034364517		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.330666034364517 | validation: 10.80994362365842]
	TIME [epoch: 9.54 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 5/5] avg loss: 10.02475085727857		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.02475085727857 | validation: 9.547609877403623]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.717007355399883		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.717007355399883 | validation: 9.582375263120309]
	TIME [epoch: 9.53 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.150283621958675		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.150283621958675 | validation: 6.950750593299223]
	TIME [epoch: 9.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.493290291984633		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.493290291984633 | validation: 6.501617846636909]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.608639266995123		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.608639266995123 | validation: 6.648675096795828]
	TIME [epoch: 9.53 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.635907058596717		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.635907058596717 | validation: 7.164305149072624]
	TIME [epoch: 9.52 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.580939224617415		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.580939224617415 | validation: 6.336198307186087]
	TIME [epoch: 9.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.45512764311659		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.45512764311659 | validation: 6.636056265987768]
	TIME [epoch: 9.51 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.351202574371274		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.351202574371274 | validation: 7.3679593069299045]
	TIME [epoch: 9.51 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.688016549181657		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.688016549181657 | validation: 7.3524342753282195]
	TIME [epoch: 9.52 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.713315111198139		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.713315111198139 | validation: 10.36667705877947]
	TIME [epoch: 9.54 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.583280049970675		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.583280049970675 | validation: 8.650741801619706]
	TIME [epoch: 9.51 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.628194097308968		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.628194097308968 | validation: 6.319087007320554]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.955412014317439		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.955412014317439 | validation: 5.227241667710898]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.031995057348642		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.031995057348642 | validation: 5.7192375456299285]
	TIME [epoch: 9.52 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.17982614977093		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.17982614977093 | validation: 7.00149898657768]
	TIME [epoch: 9.52 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.866894946642958		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.866894946642958 | validation: 8.569375032036486]
	TIME [epoch: 9.51 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.0745264315980405		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.0745264315980405 | validation: 6.048810959063691]
	TIME [epoch: 9.55 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.663129330944021		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.663129330944021 | validation: 7.97778842756498]
	TIME [epoch: 9.53 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.521475359110232		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.521475359110232 | validation: 6.050704625248119]
	TIME [epoch: 9.52 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.498972537245559		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.498972537245559 | validation: 6.5903279633842065]
	TIME [epoch: 9.51 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.550101275702633		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.550101275702633 | validation: 8.490347980501012]
	TIME [epoch: 9.55 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.039768774906908		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.039768774906908 | validation: 3.925316475903366]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.672079152108817		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.672079152108817 | validation: 6.074584140524827]
	TIME [epoch: 9.51 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.539036395368481		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.539036395368481 | validation: 6.026256369942989]
	TIME [epoch: 9.52 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.448199555373674		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.448199555373674 | validation: 7.073945207719512]
	TIME [epoch: 9.54 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.886393373182504		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.886393373182504 | validation: 7.0633921207985555]
	TIME [epoch: 9.52 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.273039968733548		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.273039968733548 | validation: 7.466477171812666]
	TIME [epoch: 9.52 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.373801407157507		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.373801407157507 | validation: 5.472296706647653]
	TIME [epoch: 9.53 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.183791794738196		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.183791794738196 | validation: 4.9881447826965415]
	TIME [epoch: 9.52 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.897904006473583		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.897904006473583 | validation: 3.9247004514223818]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.846327717888036		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.846327717888036 | validation: 7.44691094805441]
	TIME [epoch: 9.51 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.7766342461759175		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.7766342461759175 | validation: 4.074222287925328]
	TIME [epoch: 9.54 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.929122683410254		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.929122683410254 | validation: 4.140532517152515]
	TIME [epoch: 9.55 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.582620500602928		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.582620500602928 | validation: 6.621307564507819]
	TIME [epoch: 9.53 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.289750603152596		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.289750603152596 | validation: 4.316442827255103]
	TIME [epoch: 9.53 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.2226793984558935		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.2226793984558935 | validation: 7.110563500358353]
	TIME [epoch: 9.55 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.30910758653074		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.30910758653074 | validation: 7.173208840170587]
	TIME [epoch: 9.54 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.759623561267427		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.759623561267427 | validation: 7.364594365791172]
	TIME [epoch: 9.53 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.753872863135774		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.753872863135774 | validation: 4.287845350918664]
	TIME [epoch: 9.53 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.922907446871633		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.922907446871633 | validation: 7.11866545273808]
	TIME [epoch: 9.54 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.597600153463979		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.597600153463979 | validation: 4.614648608028798]
	TIME [epoch: 9.53 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.704821531159307		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.704821531159307 | validation: 5.171860590079653]
	TIME [epoch: 9.52 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.282154325503507		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.282154325503507 | validation: 5.554954387011167]
	TIME [epoch: 9.51 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.771075187855332		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.771075187855332 | validation: 4.6728496382169205]
	TIME [epoch: 9.55 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.39470055120829		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.39470055120829 | validation: 5.175201896674397]
	TIME [epoch: 9.54 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.513082337627251		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.513082337627251 | validation: 4.684443598642788]
	TIME [epoch: 9.53 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.376813755811362		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.376813755811362 | validation: 5.253862042195715]
	TIME [epoch: 9.54 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.347691082705519		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.347691082705519 | validation: 4.642203769159243]
	TIME [epoch: 9.54 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.626614764684559		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.626614764684559 | validation: 3.7964815380198513]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.5970582779722715		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.5970582779722715 | validation: 5.642824964123101]
	TIME [epoch: 9.52 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.388963474427266		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.388963474427266 | validation: 5.159717465522699]
	TIME [epoch: 9.55 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.2922034804760285		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.2922034804760285 | validation: 6.0163823289211305]
	TIME [epoch: 9.52 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.648336600374362		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.648336600374362 | validation: 4.656563748993088]
	TIME [epoch: 9.52 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.217948034476695		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.217948034476695 | validation: 4.620521745927027]
	TIME [epoch: 9.52 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.095744504951366		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.095744504951366 | validation: 5.177157430222671]
	TIME [epoch: 9.54 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.17739435497789		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.17739435497789 | validation: 6.745546590960619]
	TIME [epoch: 9.52 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.583719903947986		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.583719903947986 | validation: 4.263106635856415]
	TIME [epoch: 9.52 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.242645593746946		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.242645593746946 | validation: 3.5204287569831805]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.1198152912685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.1198152912685 | validation: 4.148566034338168]
	TIME [epoch: 9.54 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9773291975622427		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9773291975622427 | validation: 4.1233642043784196]
	TIME [epoch: 9.52 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.005215641420891		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.005215641420891 | validation: 4.859893096342257]
	TIME [epoch: 9.52 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9879578962321176		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9879578962321176 | validation: 4.384066058407956]
	TIME [epoch: 9.53 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.967042931364041		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.967042931364041 | validation: 4.679793648382551]
	TIME [epoch: 9.53 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.086607619301157		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.086607619301157 | validation: 4.63500368004825]
	TIME [epoch: 9.52 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9309362317118177		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9309362317118177 | validation: 4.382626049509646]
	TIME [epoch: 9.52 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.882936739224982		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.882936739224982 | validation: 9.012698534966653]
	TIME [epoch: 9.55 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.043158950362914		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.043158950362914 | validation: 4.028729567057182]
	TIME [epoch: 9.53 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.770842213488655		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.770842213488655 | validation: 4.537221355074742]
	TIME [epoch: 9.53 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.790763051375207		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.790763051375207 | validation: 4.10324000640564]
	TIME [epoch: 9.53 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.812604519970285		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.812604519970285 | validation: 4.513896259260117]
	TIME [epoch: 9.55 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.801360923223389		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.801360923223389 | validation: 4.7829492485072205]
	TIME [epoch: 9.52 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.140810764291328		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.140810764291328 | validation: 3.8904770464128524]
	TIME [epoch: 9.52 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9023212196458195		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9023212196458195 | validation: 4.266951087212057]
	TIME [epoch: 9.52 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.021817864935085		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.021817864935085 | validation: 4.30541744806725]
	TIME [epoch: 9.55 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.7930887825134176		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7930887825134176 | validation: 4.175658916315101]
	TIME [epoch: 9.53 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.787264642298612		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.787264642298612 | validation: 4.139569552525909]
	TIME [epoch: 9.53 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.5933855987074255		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5933855987074255 | validation: 3.9917463636611905]
	TIME [epoch: 9.53 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9800167387508956		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9800167387508956 | validation: 4.110023266106915]
	TIME [epoch: 9.55 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.851505897339897		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.851505897339897 | validation: 3.9738504142754567]
	TIME [epoch: 9.52 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.7161964838136656		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7161964838136656 | validation: 4.104703603768623]
	TIME [epoch: 9.52 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.8927966414708393		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8927966414708393 | validation: 3.9540464441439305]
	TIME [epoch: 9.53 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6252303306472777		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6252303306472777 | validation: 4.918771438826865]
	TIME [epoch: 9.54 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.71394383561962		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.71394383561962 | validation: 4.070990974173661]
	TIME [epoch: 9.53 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.8069031723308298		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8069031723308298 | validation: 4.405973692657076]
	TIME [epoch: 9.53 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.912155869348638		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.912155869348638 | validation: 4.242447262892978]
	TIME [epoch: 9.55 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6810398992896927		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6810398992896927 | validation: 3.8318968390382664]
	TIME [epoch: 9.54 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.8204397073364773		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8204397073364773 | validation: 3.9446427423282144]
	TIME [epoch: 9.53 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.560174411624172		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.560174411624172 | validation: 4.239816712431514]
	TIME [epoch: 9.52 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.797357919583773		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.797357919583773 | validation: 4.668560724791403]
	TIME [epoch: 9.55 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.0174832393221696		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.0174832393221696 | validation: 4.307300315334519]
	TIME [epoch: 9.53 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.652151646621166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.652151646621166 | validation: 4.9909561839405745]
	TIME [epoch: 9.53 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.7633931391140814		[learning rate: 0.009971]
	Learning Rate: 0.00997096
	LOSS [training: 3.7633931391140814 | validation: 5.195678095755816]
	TIME [epoch: 9.54 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9930268539899023		[learning rate: 0.0099348]
	Learning Rate: 0.00993477
	LOSS [training: 3.9930268539899023 | validation: 3.952028451539447]
	TIME [epoch: 9.55 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.8719829545924846		[learning rate: 0.0098987]
	Learning Rate: 0.00989872
	LOSS [training: 3.8719829545924846 | validation: 4.845198416813657]
	TIME [epoch: 9.53 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.8283053268663005		[learning rate: 0.0098628]
	Learning Rate: 0.00986279
	LOSS [training: 3.8283053268663005 | validation: 3.924048269887056]
	TIME [epoch: 9.53 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.8624772281850612		[learning rate: 0.009827]
	Learning Rate: 0.009827
	LOSS [training: 3.8624772281850612 | validation: 3.4155580156238057]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_105.pth
	Model improved!!!
EPOCH 106/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.7072216625438785		[learning rate: 0.0097913]
	Learning Rate: 0.00979134
	LOSS [training: 3.7072216625438785 | validation: 4.136017129618836]
	TIME [epoch: 9.56 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.792181472708415		[learning rate: 0.0097558]
	Learning Rate: 0.00975581
	LOSS [training: 3.792181472708415 | validation: 4.317954733929002]
	TIME [epoch: 9.54 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.7086148825774954		[learning rate: 0.0097204]
	Learning Rate: 0.0097204
	LOSS [training: 3.7086148825774954 | validation: 4.205512346622839]
	TIME [epoch: 9.53 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.5510533527617634		[learning rate: 0.0096851]
	Learning Rate: 0.00968513
	LOSS [training: 3.5510533527617634 | validation: 3.787787325571267]
	TIME [epoch: 9.57 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.490137807173346		[learning rate: 0.00965]
	Learning Rate: 0.00964998
	LOSS [training: 3.490137807173346 | validation: 4.030159027738216]
	TIME [epoch: 9.54 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.5800191575094744		[learning rate: 0.009615]
	Learning Rate: 0.00961496
	LOSS [training: 3.5800191575094744 | validation: 3.4274576582691356]
	TIME [epoch: 9.53 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6421295576928983		[learning rate: 0.0095801]
	Learning Rate: 0.00958006
	LOSS [training: 3.6421295576928983 | validation: 3.585455189764721]
	TIME [epoch: 9.53 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3342481661785803		[learning rate: 0.0095453]
	Learning Rate: 0.0095453
	LOSS [training: 3.3342481661785803 | validation: 3.631935493494467]
	TIME [epoch: 9.57 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4849244989093		[learning rate: 0.0095107]
	Learning Rate: 0.00951066
	LOSS [training: 3.4849244989093 | validation: 3.967194226738071]
	TIME [epoch: 9.54 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.455169326736603		[learning rate: 0.0094761]
	Learning Rate: 0.00947614
	LOSS [training: 3.455169326736603 | validation: 5.423214669359031]
	TIME [epoch: 9.53 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6644473739547103		[learning rate: 0.0094418]
	Learning Rate: 0.00944175
	LOSS [training: 3.6644473739547103 | validation: 3.9704935493508913]
	TIME [epoch: 9.52 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.435579998618406		[learning rate: 0.0094075]
	Learning Rate: 0.00940749
	LOSS [training: 3.435579998618406 | validation: 3.9212788885846885]
	TIME [epoch: 9.55 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.523100731462211		[learning rate: 0.0093733]
	Learning Rate: 0.00937335
	LOSS [training: 3.523100731462211 | validation: 4.7876628890596935]
	TIME [epoch: 9.53 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4868616059210353		[learning rate: 0.0093393]
	Learning Rate: 0.00933933
	LOSS [training: 3.4868616059210353 | validation: 5.657338516053767]
	TIME [epoch: 9.53 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.807572103403591		[learning rate: 0.0093054]
	Learning Rate: 0.00930544
	LOSS [training: 3.807572103403591 | validation: 3.3865217178618763]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_120.pth
	Model improved!!!
EPOCH 121/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1020723481229373		[learning rate: 0.0092717]
	Learning Rate: 0.00927167
	LOSS [training: 3.1020723481229373 | validation: 3.1757860668611104]
	TIME [epoch: 9.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_121.pth
	Model improved!!!
EPOCH 122/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9990502735030633		[learning rate: 0.009238]
	Learning Rate: 0.00923802
	LOSS [training: 2.9990502735030633 | validation: 3.228925563936871]
	TIME [epoch: 9.54 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1525609222098923		[learning rate: 0.0092045]
	Learning Rate: 0.0092045
	LOSS [training: 3.1525609222098923 | validation: 2.836435664143744]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_123.pth
	Model improved!!!
EPOCH 124/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8469583929257096		[learning rate: 0.0091711]
	Learning Rate: 0.00917109
	LOSS [training: 2.8469583929257096 | validation: 2.9866498736380844]
	TIME [epoch: 9.55 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.971713765619043		[learning rate: 0.0091378]
	Learning Rate: 0.00913781
	LOSS [training: 2.971713765619043 | validation: 2.8592458596774306]
	TIME [epoch: 9.55 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6754324278187496		[learning rate: 0.0091046]
	Learning Rate: 0.00910465
	LOSS [training: 2.6754324278187496 | validation: 3.5850315259681227]
	TIME [epoch: 9.54 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0025340194820607		[learning rate: 0.0090716]
	Learning Rate: 0.00907161
	LOSS [training: 3.0025340194820607 | validation: 6.609939987299933]
	TIME [epoch: 9.53 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.1841308392381045		[learning rate: 0.0090387]
	Learning Rate: 0.00903868
	LOSS [training: 4.1841308392381045 | validation: 2.5462833081518315]
	TIME [epoch: 9.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_128.pth
	Model improved!!!
EPOCH 129/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.7062612081840305		[learning rate: 0.0090059]
	Learning Rate: 0.00900588
	LOSS [training: 3.7062612081840305 | validation: 4.27154494409512]
	TIME [epoch: 9.54 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6241253178770214		[learning rate: 0.0089732]
	Learning Rate: 0.0089732
	LOSS [training: 3.6241253178770214 | validation: 2.6760866132892933]
	TIME [epoch: 9.54 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.02683651764414		[learning rate: 0.0089406]
	Learning Rate: 0.00894064
	LOSS [training: 4.02683651764414 | validation: 2.659616630757832]
	TIME [epoch: 9.53 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.823063888561593		[learning rate: 0.0089082]
	Learning Rate: 0.00890819
	LOSS [training: 2.823063888561593 | validation: 3.0302346094443626]
	TIME [epoch: 9.57 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8354418390776077		[learning rate: 0.0088759]
	Learning Rate: 0.00887586
	LOSS [training: 2.8354418390776077 | validation: 2.5123059822843805]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_133.pth
	Model improved!!!
EPOCH 134/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.594922887398458		[learning rate: 0.0088437]
	Learning Rate: 0.00884365
	LOSS [training: 2.594922887398458 | validation: 3.111323881036775]
	TIME [epoch: 9.54 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5697291572683123		[learning rate: 0.0088116]
	Learning Rate: 0.00881156
	LOSS [training: 2.5697291572683123 | validation: 3.362326447784608]
	TIME [epoch: 9.53 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.798583511352376		[learning rate: 0.0087796]
	Learning Rate: 0.00877958
	LOSS [training: 2.798583511352376 | validation: 2.9515400313872737]
	TIME [epoch: 9.56 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6683633799334534		[learning rate: 0.0087477]
	Learning Rate: 0.00874772
	LOSS [training: 2.6683633799334534 | validation: 2.581042169708144]
	TIME [epoch: 9.54 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5004449123820947		[learning rate: 0.008716]
	Learning Rate: 0.00871597
	LOSS [training: 2.5004449123820947 | validation: 2.663620640962456]
	TIME [epoch: 9.53 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.50648281890354		[learning rate: 0.0086843]
	Learning Rate: 0.00868434
	LOSS [training: 2.50648281890354 | validation: 2.6651516208460317]
	TIME [epoch: 9.54 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6658605549612617		[learning rate: 0.0086528]
	Learning Rate: 0.00865282
	LOSS [training: 2.6658605549612617 | validation: 2.521654301611595]
	TIME [epoch: 9.56 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5329265246168378		[learning rate: 0.0086214]
	Learning Rate: 0.00862142
	LOSS [training: 2.5329265246168378 | validation: 2.584760877611219]
	TIME [epoch: 9.52 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5049198950596328		[learning rate: 0.0085901]
	Learning Rate: 0.00859013
	LOSS [training: 2.5049198950596328 | validation: 2.5522045920313077]
	TIME [epoch: 9.54 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7271333976558876		[learning rate: 0.008559]
	Learning Rate: 0.00855896
	LOSS [training: 2.7271333976558876 | validation: 2.159211639257159]
	TIME [epoch: 9.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_143.pth
	Model improved!!!
EPOCH 144/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4431348236006385		[learning rate: 0.0085279]
	Learning Rate: 0.0085279
	LOSS [training: 2.4431348236006385 | validation: 3.110511214170044]
	TIME [epoch: 9.53 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.608706498658414		[learning rate: 0.008497]
	Learning Rate: 0.00849695
	LOSS [training: 2.608706498658414 | validation: 3.3992704889513305]
	TIME [epoch: 9.53 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.611431920789001		[learning rate: 0.0084661]
	Learning Rate: 0.00846612
	LOSS [training: 2.611431920789001 | validation: 2.8068131367948457]
	TIME [epoch: 9.53 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3906642021083404		[learning rate: 0.0084354]
	Learning Rate: 0.00843539
	LOSS [training: 2.3906642021083404 | validation: 3.408183732719859]
	TIME [epoch: 9.56 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.619308693083045		[learning rate: 0.0084048]
	Learning Rate: 0.00840478
	LOSS [training: 2.619308693083045 | validation: 3.189317965768901]
	TIME [epoch: 9.53 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.512800594198872		[learning rate: 0.0083743]
	Learning Rate: 0.00837428
	LOSS [training: 2.512800594198872 | validation: 2.340984612908175]
	TIME [epoch: 9.52 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.609793856729877		[learning rate: 0.0083439]
	Learning Rate: 0.00834389
	LOSS [training: 2.609793856729877 | validation: 2.3429406365568872]
	TIME [epoch: 9.53 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4389977561885368		[learning rate: 0.0083136]
	Learning Rate: 0.00831361
	LOSS [training: 2.4389977561885368 | validation: 2.3798318477668103]
	TIME [epoch: 9.55 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.298295514713028		[learning rate: 0.0082834]
	Learning Rate: 0.00828344
	LOSS [training: 2.298295514713028 | validation: 3.2729278118968352]
	TIME [epoch: 9.53 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5051286530741534		[learning rate: 0.0082534]
	Learning Rate: 0.00825338
	LOSS [training: 2.5051286530741534 | validation: 2.803483305456293]
	TIME [epoch: 9.53 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3986294939179746		[learning rate: 0.0082234]
	Learning Rate: 0.00822342
	LOSS [training: 2.3986294939179746 | validation: 2.9980949458538806]
	TIME [epoch: 9.53 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.44936275709899		[learning rate: 0.0081936]
	Learning Rate: 0.00819358
	LOSS [training: 2.44936275709899 | validation: 4.309568770320006]
	TIME [epoch: 9.54 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.453694233163669		[learning rate: 0.0081638]
	Learning Rate: 0.00816384
	LOSS [training: 3.453694233163669 | validation: 2.3506813650702743]
	TIME [epoch: 9.53 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8914502828824507		[learning rate: 0.0081342]
	Learning Rate: 0.00813422
	LOSS [training: 2.8914502828824507 | validation: 4.207405478536893]
	TIME [epoch: 9.53 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.491511003911125		[learning rate: 0.0081047]
	Learning Rate: 0.0081047
	LOSS [training: 3.491511003911125 | validation: 2.4258334812405873]
	TIME [epoch: 9.54 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.854418907951167		[learning rate: 0.0080753]
	Learning Rate: 0.00807529
	LOSS [training: 2.854418907951167 | validation: 3.286353087816561]
	TIME [epoch: 9.53 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.877229612962987		[learning rate: 0.008046]
	Learning Rate: 0.00804598
	LOSS [training: 2.877229612962987 | validation: 2.5466857394915725]
	TIME [epoch: 9.53 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.60184065831575		[learning rate: 0.0080168]
	Learning Rate: 0.00801678
	LOSS [training: 2.60184065831575 | validation: 2.9910421276379417]
	TIME [epoch: 9.52 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4838378421246436		[learning rate: 0.0079877]
	Learning Rate: 0.00798769
	LOSS [training: 2.4838378421246436 | validation: 2.6973301360172934]
	TIME [epoch: 9.55 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2854877199198365		[learning rate: 0.0079587]
	Learning Rate: 0.0079587
	LOSS [training: 2.2854877199198365 | validation: 2.605211332111438]
	TIME [epoch: 9.54 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5180945191267035		[learning rate: 0.0079298]
	Learning Rate: 0.00792982
	LOSS [training: 2.5180945191267035 | validation: 3.17233317094222]
	TIME [epoch: 9.53 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2701594465289743		[learning rate: 0.007901]
	Learning Rate: 0.00790104
	LOSS [training: 2.2701594465289743 | validation: 2.39179642430864]
	TIME [epoch: 9.52 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1795559067762094		[learning rate: 0.0078724]
	Learning Rate: 0.00787237
	LOSS [training: 2.1795559067762094 | validation: 2.6968124689746436]
	TIME [epoch: 9.55 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.351891894890634		[learning rate: 0.0078438]
	Learning Rate: 0.0078438
	LOSS [training: 2.351891894890634 | validation: 2.187844722621106]
	TIME [epoch: 9.53 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.282735426750155		[learning rate: 0.0078153]
	Learning Rate: 0.00781533
	LOSS [training: 2.282735426750155 | validation: 2.8060423320863004]
	TIME [epoch: 9.53 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6433507399655474		[learning rate: 0.007787]
	Learning Rate: 0.00778697
	LOSS [training: 3.6433507399655474 | validation: 3.1031260091288604]
	TIME [epoch: 9.53 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4192880934674945		[learning rate: 0.0077587]
	Learning Rate: 0.00775871
	LOSS [training: 3.4192880934674945 | validation: 4.7678526986684275]
	TIME [epoch: 9.55 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.543414589097175		[learning rate: 0.0077306]
	Learning Rate: 0.00773055
	LOSS [training: 3.543414589097175 | validation: 2.3388243336647214]
	TIME [epoch: 9.52 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3956277593800563		[learning rate: 0.0077025]
	Learning Rate: 0.0077025
	LOSS [training: 2.3956277593800563 | validation: 3.1815741010367877]
	TIME [epoch: 9.53 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3606634316726565		[learning rate: 0.0076745]
	Learning Rate: 0.00767455
	LOSS [training: 2.3606634316726565 | validation: 2.487209058174311]
	TIME [epoch: 9.54 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.274945859405262		[learning rate: 0.0076467]
	Learning Rate: 0.00764669
	LOSS [training: 2.274945859405262 | validation: 2.5646505271608295]
	TIME [epoch: 9.54 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.310078909302179		[learning rate: 0.0076189]
	Learning Rate: 0.00761894
	LOSS [training: 2.310078909302179 | validation: 3.199486445579919]
	TIME [epoch: 9.53 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3250127245122303		[learning rate: 0.0075913]
	Learning Rate: 0.00759129
	LOSS [training: 2.3250127245122303 | validation: 3.025563285229255]
	TIME [epoch: 9.53 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.235674966923419		[learning rate: 0.0075637]
	Learning Rate: 0.00756374
	LOSS [training: 2.235674966923419 | validation: 2.8283459101824495]
	TIME [epoch: 9.54 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1986878773771896		[learning rate: 0.0075363]
	Learning Rate: 0.00753629
	LOSS [training: 2.1986878773771896 | validation: 2.5999454699549633]
	TIME [epoch: 9.54 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0565277434968356		[learning rate: 0.0075089]
	Learning Rate: 0.00750895
	LOSS [training: 2.0565277434968356 | validation: 3.832209814988835]
	TIME [epoch: 9.54 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.68781481762034		[learning rate: 0.0074817]
	Learning Rate: 0.00748169
	LOSS [training: 2.68781481762034 | validation: 2.033102990064541]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_180.pth
	Model improved!!!
EPOCH 181/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4306968783885856		[learning rate: 0.0074545]
	Learning Rate: 0.00745454
	LOSS [training: 2.4306968783885856 | validation: 2.3266990454951477]
	TIME [epoch: 9.56 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1579018110119024		[learning rate: 0.0074275]
	Learning Rate: 0.00742749
	LOSS [training: 2.1579018110119024 | validation: 2.983763609006985]
	TIME [epoch: 9.52 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0953473138399783		[learning rate: 0.0074005]
	Learning Rate: 0.00740054
	LOSS [training: 2.0953473138399783 | validation: 2.5484686756150245]
	TIME [epoch: 9.53 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3559049912478587		[learning rate: 0.0073737]
	Learning Rate: 0.00737368
	LOSS [training: 2.3559049912478587 | validation: 3.3854424434630506]
	TIME [epoch: 9.52 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.301451944910238		[learning rate: 0.0073469]
	Learning Rate: 0.00734692
	LOSS [training: 2.301451944910238 | validation: 3.5711632082302174]
	TIME [epoch: 9.55 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1762072993024253		[learning rate: 0.0073203]
	Learning Rate: 0.00732026
	LOSS [training: 3.1762072993024253 | validation: 3.186262775988822]
	TIME [epoch: 9.53 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.536538000204851		[learning rate: 0.0072937]
	Learning Rate: 0.00729369
	LOSS [training: 2.536538000204851 | validation: 2.2057455950366833]
	TIME [epoch: 9.52 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3713655309173416		[learning rate: 0.0072672]
	Learning Rate: 0.00726722
	LOSS [training: 2.3713655309173416 | validation: 2.6463268465321494]
	TIME [epoch: 9.53 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.966297247931656		[learning rate: 0.0072408]
	Learning Rate: 0.00724085
	LOSS [training: 2.966297247931656 | validation: 4.488310783373734]
	TIME [epoch: 9.55 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.335561014868157		[learning rate: 0.0072146]
	Learning Rate: 0.00721457
	LOSS [training: 3.335561014868157 | validation: 2.219793845964061]
	TIME [epoch: 9.52 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.728965298538707		[learning rate: 0.0071884]
	Learning Rate: 0.00718839
	LOSS [training: 2.728965298538707 | validation: 4.506365212337455]
	TIME [epoch: 9.53 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3229504670048997		[learning rate: 0.0071623]
	Learning Rate: 0.0071623
	LOSS [training: 3.3229504670048997 | validation: 2.3448888918734365]
	TIME [epoch: 9.53 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.990241492670534		[learning rate: 0.0071363]
	Learning Rate: 0.00713631
	LOSS [training: 2.990241492670534 | validation: 3.79024544422833]
	TIME [epoch: 9.55 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3903945775663984		[learning rate: 0.0071104]
	Learning Rate: 0.00711041
	LOSS [training: 3.3903945775663984 | validation: 2.3871986834908614]
	TIME [epoch: 9.52 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2605326154463645		[learning rate: 0.0070846]
	Learning Rate: 0.00708461
	LOSS [training: 2.2605326154463645 | validation: 2.2600643399185603]
	TIME [epoch: 9.53 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9110816374905906		[learning rate: 0.0070589]
	Learning Rate: 0.0070589
	LOSS [training: 1.9110816374905906 | validation: 2.313812959272553]
	TIME [epoch: 9.55 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.956526954017385		[learning rate: 0.0070333]
	Learning Rate: 0.00703328
	LOSS [training: 1.956526954017385 | validation: 2.562131040357781]
	TIME [epoch: 9.53 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.104641332001361		[learning rate: 0.0070078]
	Learning Rate: 0.00700776
	LOSS [training: 2.104641332001361 | validation: 2.6945366640596062]
	TIME [epoch: 9.53 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.130189246778035		[learning rate: 0.0069823]
	Learning Rate: 0.00698232
	LOSS [training: 2.130189246778035 | validation: 5.846001211076205]
	TIME [epoch: 9.53 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.259284508770689		[learning rate: 0.006957]
	Learning Rate: 0.00695698
	LOSS [training: 3.259284508770689 | validation: 2.3392424206334455]
	TIME [epoch: 9.55 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9136848734797236		[learning rate: 0.0069317]
	Learning Rate: 0.00693174
	LOSS [training: 1.9136848734797236 | validation: 2.030195966132705]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_201.pth
	Model improved!!!
EPOCH 202/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.963808910736881		[learning rate: 0.0069066]
	Learning Rate: 0.00690658
	LOSS [training: 1.963808910736881 | validation: 1.9351579140266024]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_202.pth
	Model improved!!!
EPOCH 203/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.83386444377614		[learning rate: 0.0068815]
	Learning Rate: 0.00688152
	LOSS [training: 1.83386444377614 | validation: 2.3239728760724216]
	TIME [epoch: 9.53 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8296989767755527		[learning rate: 0.0068565]
	Learning Rate: 0.00685654
	LOSS [training: 1.8296989767755527 | validation: 2.914904797795866]
	TIME [epoch: 9.55 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1512751012914		[learning rate: 0.0068317]
	Learning Rate: 0.00683166
	LOSS [training: 2.1512751012914 | validation: 1.8254471897182618]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_205.pth
	Model improved!!!
EPOCH 206/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.050831595587897		[learning rate: 0.0068069]
	Learning Rate: 0.00680687
	LOSS [training: 2.050831595587897 | validation: 1.8587345983255439]
	TIME [epoch: 9.53 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.226368159635304		[learning rate: 0.0067822]
	Learning Rate: 0.00678217
	LOSS [training: 2.226368159635304 | validation: 1.6697266023343218]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_207.pth
	Model improved!!!
EPOCH 208/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7929935780062274		[learning rate: 0.0067576]
	Learning Rate: 0.00675755
	LOSS [training: 1.7929935780062274 | validation: 2.9978394504960857]
	TIME [epoch: 9.55 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0446065868303522		[learning rate: 0.006733]
	Learning Rate: 0.00673303
	LOSS [training: 2.0446065868303522 | validation: 1.669758929098017]
	TIME [epoch: 9.53 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7762016599668342		[learning rate: 0.0067086]
	Learning Rate: 0.00670859
	LOSS [training: 1.7762016599668342 | validation: 2.064991251261591]
	TIME [epoch: 9.53 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8782287484843798		[learning rate: 0.0066842]
	Learning Rate: 0.00668425
	LOSS [training: 1.8782287484843798 | validation: 2.1836405919336563]
	TIME [epoch: 9.54 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8597696357918796		[learning rate: 0.00666]
	Learning Rate: 0.00665999
	LOSS [training: 1.8597696357918796 | validation: 2.199691689016416]
	TIME [epoch: 9.53 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8918633892100623		[learning rate: 0.0066358]
	Learning Rate: 0.00663582
	LOSS [training: 1.8918633892100623 | validation: 1.938283309534028]
	TIME [epoch: 9.52 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6932351904003018		[learning rate: 0.0066117]
	Learning Rate: 0.00661174
	LOSS [training: 1.6932351904003018 | validation: 1.9933227955562551]
	TIME [epoch: 9.54 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.870199885280821		[learning rate: 0.0065877]
	Learning Rate: 0.00658775
	LOSS [training: 1.870199885280821 | validation: 2.481206417035545]
	TIME [epoch: 9.55 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8540563926386546		[learning rate: 0.0065638]
	Learning Rate: 0.00656384
	LOSS [training: 1.8540563926386546 | validation: 1.9240793909371763]
	TIME [epoch: 9.53 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.05826949367852		[learning rate: 0.00654]
	Learning Rate: 0.00654002
	LOSS [training: 2.05826949367852 | validation: 2.6033780665102046]
	TIME [epoch: 9.52 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9428342521203752		[learning rate: 0.0065163]
	Learning Rate: 0.00651628
	LOSS [training: 1.9428342521203752 | validation: 1.8977211516525274]
	TIME [epoch: 9.53 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8639857930588921		[learning rate: 0.0064926]
	Learning Rate: 0.00649264
	LOSS [training: 1.8639857930588921 | validation: 2.7573086203330766]
	TIME [epoch: 9.55 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9142370459911575		[learning rate: 0.0064691]
	Learning Rate: 0.00646907
	LOSS [training: 1.9142370459911575 | validation: 2.0646698585644128]
	TIME [epoch: 9.52 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9928172186529132		[learning rate: 0.0064456]
	Learning Rate: 0.0064456
	LOSS [training: 1.9928172186529132 | validation: 2.1687064370804827]
	TIME [epoch: 9.52 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7744810544691525		[learning rate: 0.0064222]
	Learning Rate: 0.00642221
	LOSS [training: 1.7744810544691525 | validation: 1.9157826034834922]
	TIME [epoch: 9.53 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7449822493674028		[learning rate: 0.0063989]
	Learning Rate: 0.0063989
	LOSS [training: 1.7449822493674028 | validation: 2.0525517938498834]
	TIME [epoch: 9.54 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7857037766694788		[learning rate: 0.0063757]
	Learning Rate: 0.00637568
	LOSS [training: 1.7857037766694788 | validation: 2.6760005283790544]
	TIME [epoch: 9.53 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0286308944965272		[learning rate: 0.0063525]
	Learning Rate: 0.00635254
	LOSS [training: 2.0286308944965272 | validation: 2.5877357070632523]
	TIME [epoch: 9.53 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0290222572962824		[learning rate: 0.0063295]
	Learning Rate: 0.00632949
	LOSS [training: 2.0290222572962824 | validation: 1.7430090421641269]
	TIME [epoch: 9.55 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7102280826826601		[learning rate: 0.0063065]
	Learning Rate: 0.00630652
	LOSS [training: 1.7102280826826601 | validation: 2.247611519459857]
	TIME [epoch: 9.53 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8126405777546097		[learning rate: 0.0062836]
	Learning Rate: 0.00628363
	LOSS [training: 1.8126405777546097 | validation: 2.085989680405232]
	TIME [epoch: 9.53 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0104189377637196		[learning rate: 0.0062608]
	Learning Rate: 0.00626082
	LOSS [training: 2.0104189377637196 | validation: 1.9969252746111696]
	TIME [epoch: 9.53 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7025146686385848		[learning rate: 0.0062381]
	Learning Rate: 0.0062381
	LOSS [training: 1.7025146686385848 | validation: 3.01739045563489]
	TIME [epoch: 9.55 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.108825521111524		[learning rate: 0.0062155]
	Learning Rate: 0.00621547
	LOSS [training: 2.108825521111524 | validation: 1.9743775192489852]
	TIME [epoch: 9.53 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8347305726647747		[learning rate: 0.0061929]
	Learning Rate: 0.00619291
	LOSS [training: 1.8347305726647747 | validation: 1.8425182727053055]
	TIME [epoch: 9.53 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.811962078786414		[learning rate: 0.0061704]
	Learning Rate: 0.00617043
	LOSS [training: 1.811962078786414 | validation: 1.682574534859379]
	TIME [epoch: 9.52 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.747619776560871		[learning rate: 0.006148]
	Learning Rate: 0.00614804
	LOSS [training: 1.747619776560871 | validation: 1.7272516936763518]
	TIME [epoch: 9.55 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.75172273770202		[learning rate: 0.0061257]
	Learning Rate: 0.00612573
	LOSS [training: 1.75172273770202 | validation: 1.9387034909723115]
	TIME [epoch: 9.53 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8064253973854143		[learning rate: 0.0061035]
	Learning Rate: 0.0061035
	LOSS [training: 1.8064253973854143 | validation: 2.1827256702297992]
	TIME [epoch: 9.52 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7662173554444212		[learning rate: 0.0060814]
	Learning Rate: 0.00608135
	LOSS [training: 1.7662173554444212 | validation: 1.5734842086026755]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_237.pth
	Model improved!!!
EPOCH 238/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8469263494000299		[learning rate: 0.0060593]
	Learning Rate: 0.00605928
	LOSS [training: 1.8469263494000299 | validation: 1.4643115609774622]
	TIME [epoch: 9.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_238.pth
	Model improved!!!
EPOCH 239/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2270940681209783		[learning rate: 0.0060373]
	Learning Rate: 0.00603729
	LOSS [training: 2.2270940681209783 | validation: 3.3021124496578103]
	TIME [epoch: 9.52 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0388916684151464		[learning rate: 0.0060154]
	Learning Rate: 0.00601538
	LOSS [training: 2.0388916684151464 | validation: 1.7446661917588597]
	TIME [epoch: 9.52 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.724242784038364		[learning rate: 0.0059936]
	Learning Rate: 0.00599355
	LOSS [training: 1.724242784038364 | validation: 2.2395109967951377]
	TIME [epoch: 9.52 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.777752530934442		[learning rate: 0.0059718]
	Learning Rate: 0.0059718
	LOSS [training: 1.777752530934442 | validation: 2.3215719793203102]
	TIME [epoch: 9.54 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8250214982926962		[learning rate: 0.0059501]
	Learning Rate: 0.00595013
	LOSS [training: 1.8250214982926962 | validation: 2.21362775319416]
	TIME [epoch: 9.52 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.796930302513207		[learning rate: 0.0059285]
	Learning Rate: 0.00592853
	LOSS [training: 1.796930302513207 | validation: 3.9226528330989106]
	TIME [epoch: 9.53 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.815684304159262		[learning rate: 0.005907]
	Learning Rate: 0.00590702
	LOSS [training: 2.815684304159262 | validation: 2.3184072999844965]
	TIME [epoch: 9.54 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.465301897580485		[learning rate: 0.0058856]
	Learning Rate: 0.00588558
	LOSS [training: 2.465301897580485 | validation: 3.607549776890622]
	TIME [epoch: 9.52 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5735067343238986		[learning rate: 0.0058642]
	Learning Rate: 0.00586422
	LOSS [training: 2.5735067343238986 | validation: 1.9605697736045324]
	TIME [epoch: 9.52 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1934859158630102		[learning rate: 0.0058429]
	Learning Rate: 0.00584294
	LOSS [training: 2.1934859158630102 | validation: 3.1207087655474455]
	TIME [epoch: 9.52 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.057349235334506		[learning rate: 0.0058217]
	Learning Rate: 0.00582174
	LOSS [training: 2.057349235334506 | validation: 1.9544713855408204]
	TIME [epoch: 9.54 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7231096443348008		[learning rate: 0.0058006]
	Learning Rate: 0.00580061
	LOSS [training: 1.7231096443348008 | validation: 2.8106910032909145]
	TIME [epoch: 9.53 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.98072881649446		[learning rate: 0.0057796]
	Learning Rate: 0.00577956
	LOSS [training: 1.98072881649446 | validation: 2.214534720790684]
	TIME [epoch: 9.51 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7179924526233343		[learning rate: 0.0057586]
	Learning Rate: 0.00575859
	LOSS [training: 1.7179924526233343 | validation: 2.127354392778929]
	TIME [epoch: 9.51 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7431402796798419		[learning rate: 0.0057377]
	Learning Rate: 0.00573769
	LOSS [training: 1.7431402796798419 | validation: 2.052764646619226]
	TIME [epoch: 9.55 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7328260574730368		[learning rate: 0.0057169]
	Learning Rate: 0.00571686
	LOSS [training: 1.7328260574730368 | validation: 2.2941353466268937]
	TIME [epoch: 9.52 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7532122453932715		[learning rate: 0.0056961]
	Learning Rate: 0.00569612
	LOSS [training: 1.7532122453932715 | validation: 2.1779944312962876]
	TIME [epoch: 9.52 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6700615750508192		[learning rate: 0.0056754]
	Learning Rate: 0.00567545
	LOSS [training: 1.6700615750508192 | validation: 2.1003448501127058]
	TIME [epoch: 9.51 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.766460617439034		[learning rate: 0.0056548]
	Learning Rate: 0.00565485
	LOSS [training: 1.766460617439034 | validation: 1.6418167865341418]
	TIME [epoch: 9.54 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6514719271430551		[learning rate: 0.0056343]
	Learning Rate: 0.00563433
	LOSS [training: 1.6514719271430551 | validation: 1.9428316895238609]
	TIME [epoch: 9.52 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6616173462894328		[learning rate: 0.0056139]
	Learning Rate: 0.00561388
	LOSS [training: 1.6616173462894328 | validation: 1.6989766796771095]
	TIME [epoch: 9.52 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7341078353639077		[learning rate: 0.0055935]
	Learning Rate: 0.00559351
	LOSS [training: 1.7341078353639077 | validation: 1.937308558859354]
	TIME [epoch: 9.53 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8124962762627526		[learning rate: 0.0055732]
	Learning Rate: 0.00557321
	LOSS [training: 1.8124962762627526 | validation: 1.891422575145712]
	TIME [epoch: 9.55 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8786094371464874		[learning rate: 0.005553]
	Learning Rate: 0.00555298
	LOSS [training: 1.8786094371464874 | validation: 2.8772120997712025]
	TIME [epoch: 9.51 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8407208471109004		[learning rate: 0.0055328]
	Learning Rate: 0.00553283
	LOSS [training: 1.8407208471109004 | validation: 1.7800300099077206]
	TIME [epoch: 9.52 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6804068201444515		[learning rate: 0.0055128]
	Learning Rate: 0.00551275
	LOSS [training: 1.6804068201444515 | validation: 2.027864117680549]
	TIME [epoch: 9.53 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6973376095182438		[learning rate: 0.0054927]
	Learning Rate: 0.00549274
	LOSS [training: 1.6973376095182438 | validation: 1.6043356335520558]
	TIME [epoch: 9.52 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6031449313797452		[learning rate: 0.0054728]
	Learning Rate: 0.00547281
	LOSS [training: 1.6031449313797452 | validation: 1.941400631798511]
	TIME [epoch: 9.52 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5370655948783174		[learning rate: 0.005453]
	Learning Rate: 0.00545295
	LOSS [training: 1.5370655948783174 | validation: 1.7764874478193478]
	TIME [epoch: 9.52 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.198951489001393		[learning rate: 0.0054332]
	Learning Rate: 0.00543316
	LOSS [training: 2.198951489001393 | validation: 1.7971883667509128]
	TIME [epoch: 9.53 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2336345412035223		[learning rate: 0.0054134]
	Learning Rate: 0.00541344
	LOSS [training: 2.2336345412035223 | validation: 2.7440365611743993]
	TIME [epoch: 9.52 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5187640446910713		[learning rate: 0.0053938]
	Learning Rate: 0.0053938
	LOSS [training: 2.5187640446910713 | validation: 2.0012428651448597]
	TIME [epoch: 9.52 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9676260399656686		[learning rate: 0.0053742]
	Learning Rate: 0.00537422
	LOSS [training: 1.9676260399656686 | validation: 3.9037479804216275]
	TIME [epoch: 9.52 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3726251771306175		[learning rate: 0.0053547]
	Learning Rate: 0.00535472
	LOSS [training: 2.3726251771306175 | validation: 1.8130402065722502]
	TIME [epoch: 9.54 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1095909605626852		[learning rate: 0.0053353]
	Learning Rate: 0.00533529
	LOSS [training: 2.1095909605626852 | validation: 3.0270692031016724]
	TIME [epoch: 9.52 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.037025113571337		[learning rate: 0.0053159]
	Learning Rate: 0.00531593
	LOSS [training: 2.037025113571337 | validation: 1.564853445778956]
	TIME [epoch: 9.52 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5218319885148073		[learning rate: 0.0052966]
	Learning Rate: 0.00529663
	LOSS [training: 1.5218319885148073 | validation: 1.666739013405793]
	TIME [epoch: 9.52 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5980016114310929		[learning rate: 0.0052774]
	Learning Rate: 0.00527741
	LOSS [training: 1.5980016114310929 | validation: 1.7432388761603232]
	TIME [epoch: 9.54 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5401147807728737		[learning rate: 0.0052583]
	Learning Rate: 0.00525826
	LOSS [training: 1.5401147807728737 | validation: 2.185945110927822]
	TIME [epoch: 9.53 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5711453749443067		[learning rate: 0.0052392]
	Learning Rate: 0.00523918
	LOSS [training: 1.5711453749443067 | validation: 1.9673218852166934]
	TIME [epoch: 9.52 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.204533434051263		[learning rate: 0.0052202]
	Learning Rate: 0.00522017
	LOSS [training: 2.204533434051263 | validation: 1.7004805940475862]
	TIME [epoch: 9.53 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6364201466380563		[learning rate: 0.0052012]
	Learning Rate: 0.00520122
	LOSS [training: 1.6364201466380563 | validation: 2.5211731229515872]
	TIME [epoch: 9.54 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.70672143713182		[learning rate: 0.0051823]
	Learning Rate: 0.00518234
	LOSS [training: 1.70672143713182 | validation: 1.5356942674835967]
	TIME [epoch: 9.53 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7130522659173355		[learning rate: 0.0051635]
	Learning Rate: 0.00516354
	LOSS [training: 1.7130522659173355 | validation: 1.673491978164106]
	TIME [epoch: 9.52 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4890615353068521		[learning rate: 0.0051448]
	Learning Rate: 0.0051448
	LOSS [training: 1.4890615353068521 | validation: 2.571633979629721]
	TIME [epoch: 9.54 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7560438643064724		[learning rate: 0.0051261]
	Learning Rate: 0.00512613
	LOSS [training: 1.7560438643064724 | validation: 1.6636785311751312]
	TIME [epoch: 9.52 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.614497406707833		[learning rate: 0.0051075]
	Learning Rate: 0.00510753
	LOSS [training: 1.614497406707833 | validation: 1.5976833956435221]
	TIME [epoch: 9.52 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4716299319929314		[learning rate: 0.005089]
	Learning Rate: 0.00508899
	LOSS [training: 1.4716299319929314 | validation: 1.8156163751286847]
	TIME [epoch: 9.52 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6144170997455745		[learning rate: 0.0050705]
	Learning Rate: 0.00507052
	LOSS [training: 1.6144170997455745 | validation: 2.787290758434506]
	TIME [epoch: 9.54 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7901855728006257		[learning rate: 0.0050521]
	Learning Rate: 0.00505212
	LOSS [training: 1.7901855728006257 | validation: 2.6531231940346585]
	TIME [epoch: 9.52 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6572555117728527		[learning rate: 0.0050338]
	Learning Rate: 0.00503379
	LOSS [training: 1.6572555117728527 | validation: 1.7722642116714482]
	TIME [epoch: 9.52 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8939816246069796		[learning rate: 0.0050155]
	Learning Rate: 0.00501552
	LOSS [training: 1.8939816246069796 | validation: 2.7054081016089584]
	TIME [epoch: 9.52 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8240267024213388		[learning rate: 0.0049973]
	Learning Rate: 0.00499732
	LOSS [training: 1.8240267024213388 | validation: 1.6983430711304852]
	TIME [epoch: 9.55 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5120242432375708		[learning rate: 0.0049792]
	Learning Rate: 0.00497918
	LOSS [training: 1.5120242432375708 | validation: 1.8999414758216413]
	TIME [epoch: 9.52 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.936238151103036		[learning rate: 0.0049611]
	Learning Rate: 0.00496111
	LOSS [training: 1.936238151103036 | validation: 2.833060396232436]
	TIME [epoch: 9.52 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1620583513751215		[learning rate: 0.0049431]
	Learning Rate: 0.00494311
	LOSS [training: 2.1620583513751215 | validation: 1.517546456917256]
	TIME [epoch: 9.52 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5038351122473559		[learning rate: 0.0049252]
	Learning Rate: 0.00492517
	LOSS [training: 1.5038351122473559 | validation: 1.6994306721832875]
	TIME [epoch: 9.55 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4902239332557632		[learning rate: 0.0049073]
	Learning Rate: 0.00490729
	LOSS [training: 1.4902239332557632 | validation: 1.6600049500888907]
	TIME [epoch: 9.53 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7050703825831235		[learning rate: 0.0048895]
	Learning Rate: 0.00488948
	LOSS [training: 1.7050703825831235 | validation: 1.8318400480337242]
	TIME [epoch: 9.52 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.666946791928828		[learning rate: 0.0048717]
	Learning Rate: 0.00487174
	LOSS [training: 1.666946791928828 | validation: 1.9074553895702964]
	TIME [epoch: 9.53 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6471775647569546		[learning rate: 0.0048541]
	Learning Rate: 0.00485406
	LOSS [training: 1.6471775647569546 | validation: 1.4098242729953818]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_299.pth
	Model improved!!!
EPOCH 300/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4580262376193804		[learning rate: 0.0048364]
	Learning Rate: 0.00483645
	LOSS [training: 1.4580262376193804 | validation: 1.5502602868346167]
	TIME [epoch: 9.53 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6356989198396619		[learning rate: 0.0048189]
	Learning Rate: 0.00481889
	LOSS [training: 1.6356989198396619 | validation: 1.4880814454206017]
	TIME [epoch: 9.52 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5835380424983396		[learning rate: 0.0048014]
	Learning Rate: 0.00480141
	LOSS [training: 1.5835380424983396 | validation: 1.4407865359263037]
	TIME [epoch: 9.54 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.518972893830518		[learning rate: 0.004784]
	Learning Rate: 0.00478398
	LOSS [training: 1.518972893830518 | validation: 3.0356546918975846]
	TIME [epoch: 9.53 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.080445665872495		[learning rate: 0.0047666]
	Learning Rate: 0.00476662
	LOSS [training: 2.080445665872495 | validation: 1.723489387105113]
	TIME [epoch: 9.53 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4972455593313678		[learning rate: 0.0047493]
	Learning Rate: 0.00474932
	LOSS [training: 1.4972455593313678 | validation: 2.136588878124843]
	TIME [epoch: 9.52 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.59770169996266		[learning rate: 0.0047321]
	Learning Rate: 0.00473209
	LOSS [training: 1.59770169996266 | validation: 1.637695424226165]
	TIME [epoch: 9.55 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5453316682219902		[learning rate: 0.0047149]
	Learning Rate: 0.00471491
	LOSS [training: 1.5453316682219902 | validation: 1.6520627010204134]
	TIME [epoch: 9.52 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3625786270694715		[learning rate: 0.0046978]
	Learning Rate: 0.0046978
	LOSS [training: 1.3625786270694715 | validation: 1.779109052006196]
	TIME [epoch: 9.53 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5525278954809476		[learning rate: 0.0046808]
	Learning Rate: 0.00468075
	LOSS [training: 1.5525278954809476 | validation: 1.7483527771247058]
	TIME [epoch: 9.52 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4999314655975957		[learning rate: 0.0046638]
	Learning Rate: 0.00466377
	LOSS [training: 1.4999314655975957 | validation: 1.9594996875788115]
	TIME [epoch: 9.55 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4743172568850624		[learning rate: 0.0046468]
	Learning Rate: 0.00464684
	LOSS [training: 1.4743172568850624 | validation: 1.9472237884205927]
	TIME [epoch: 9.52 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5452357632015015		[learning rate: 0.00463]
	Learning Rate: 0.00462998
	LOSS [training: 1.5452357632015015 | validation: 1.634212658753593]
	TIME [epoch: 9.51 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4308169971349067		[learning rate: 0.0046132]
	Learning Rate: 0.00461318
	LOSS [training: 1.4308169971349067 | validation: 1.7031324495907472]
	TIME [epoch: 9.53 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5104044818992428		[learning rate: 0.0045964]
	Learning Rate: 0.00459643
	LOSS [training: 1.5104044818992428 | validation: 1.8148862131071508]
	TIME [epoch: 9.54 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4027471246257393		[learning rate: 0.0045798]
	Learning Rate: 0.00457975
	LOSS [training: 1.4027471246257393 | validation: 1.7509434501010608]
	TIME [epoch: 9.52 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3979778768291926		[learning rate: 0.0045631]
	Learning Rate: 0.00456313
	LOSS [training: 1.3979778768291926 | validation: 1.593111099671645]
	TIME [epoch: 9.52 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4118437497868737		[learning rate: 0.0045466]
	Learning Rate: 0.00454657
	LOSS [training: 1.4118437497868737 | validation: 2.080900571457449]
	TIME [epoch: 9.53 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4529944693795753		[learning rate: 0.0045301]
	Learning Rate: 0.00453007
	LOSS [training: 1.4529944693795753 | validation: 1.566560218998916]
	TIME [epoch: 9.53 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6635861337480278		[learning rate: 0.0045136]
	Learning Rate: 0.00451363
	LOSS [training: 1.6635861337480278 | validation: 1.4998385863155594]
	TIME [epoch: 9.53 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5162410928308212		[learning rate: 0.0044973]
	Learning Rate: 0.00449725
	LOSS [training: 1.5162410928308212 | validation: 1.6129774650727542]
	TIME [epoch: 9.52 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.679936223556809		[learning rate: 0.0044809]
	Learning Rate: 0.00448093
	LOSS [training: 1.679936223556809 | validation: 1.6602058963042594]
	TIME [epoch: 9.54 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4642278784345386		[learning rate: 0.0044647]
	Learning Rate: 0.00446467
	LOSS [training: 1.4642278784345386 | validation: 1.455855683350623]
	TIME [epoch: 9.53 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4091908152542165		[learning rate: 0.0044485]
	Learning Rate: 0.00444847
	LOSS [training: 1.4091908152542165 | validation: 2.195420901111073]
	TIME [epoch: 9.51 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4957314011831433		[learning rate: 0.0044323]
	Learning Rate: 0.00443232
	LOSS [training: 1.4957314011831433 | validation: 1.441402792459985]
	TIME [epoch: 9.52 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5309065050275346		[learning rate: 0.0044162]
	Learning Rate: 0.00441624
	LOSS [training: 1.5309065050275346 | validation: 2.428241762615669]
	TIME [epoch: 9.54 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.758272006733027		[learning rate: 0.0044002]
	Learning Rate: 0.00440021
	LOSS [training: 1.758272006733027 | validation: 1.574506058940354]
	TIME [epoch: 9.52 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6761969514907293		[learning rate: 0.0043842]
	Learning Rate: 0.00438424
	LOSS [training: 1.6761969514907293 | validation: 1.975578766182604]
	TIME [epoch: 9.52 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.434618712837512		[learning rate: 0.0043683]
	Learning Rate: 0.00436833
	LOSS [training: 1.434618712837512 | validation: 1.5674594234377304]
	TIME [epoch: 9.52 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3827677144214943		[learning rate: 0.0043525]
	Learning Rate: 0.00435248
	LOSS [training: 1.3827677144214943 | validation: 1.6590288409417087]
	TIME [epoch: 9.54 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.557116332417816		[learning rate: 0.0043367]
	Learning Rate: 0.00433668
	LOSS [training: 1.557116332417816 | validation: 1.552301694986236]
	TIME [epoch: 9.51 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.343136956485768		[learning rate: 0.0043209]
	Learning Rate: 0.00432095
	LOSS [training: 1.343136956485768 | validation: 2.148228256018285]
	TIME [epoch: 9.52 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8759296505720673		[learning rate: 0.0043053]
	Learning Rate: 0.00430527
	LOSS [training: 1.8759296505720673 | validation: 2.4824327203969996]
	TIME [epoch: 9.52 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6803820162099872		[learning rate: 0.0042896]
	Learning Rate: 0.00428964
	LOSS [training: 1.6803820162099872 | validation: 2.1056019122025527]
	TIME [epoch: 9.54 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.500982067062924		[learning rate: 0.0042741]
	Learning Rate: 0.00427407
	LOSS [training: 1.500982067062924 | validation: 1.980047108795112]
	TIME [epoch: 9.52 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.351399504557032		[learning rate: 0.0042586]
	Learning Rate: 0.00425856
	LOSS [training: 1.351399504557032 | validation: 1.7119121992898252]
	TIME [epoch: 9.52 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.661324891805664		[learning rate: 0.0042431]
	Learning Rate: 0.00424311
	LOSS [training: 1.661324891805664 | validation: 2.9012666623784344]
	TIME [epoch: 9.53 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9109962149405118		[learning rate: 0.0042277]
	Learning Rate: 0.00422771
	LOSS [training: 1.9109962149405118 | validation: 1.5931373683402716]
	TIME [epoch: 9.51 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.580263739230317		[learning rate: 0.0042124]
	Learning Rate: 0.00421237
	LOSS [training: 1.580263739230317 | validation: 1.5464242490512794]
	TIME [epoch: 9.51 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3498100501386976		[learning rate: 0.0041971]
	Learning Rate: 0.00419708
	LOSS [training: 1.3498100501386976 | validation: 1.4691532280312607]
	TIME [epoch: 9.51 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3129394290151613		[learning rate: 0.0041818]
	Learning Rate: 0.00418185
	LOSS [training: 1.3129394290151613 | validation: 1.387451474195341]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_340.pth
	Model improved!!!
EPOCH 341/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5182065344461992		[learning rate: 0.0041667]
	Learning Rate: 0.00416667
	LOSS [training: 1.5182065344461992 | validation: 1.5101326574896654]
	TIME [epoch: 9.52 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3585084718809635		[learning rate: 0.0041516]
	Learning Rate: 0.00415155
	LOSS [training: 1.3585084718809635 | validation: 1.6805467806639047]
	TIME [epoch: 9.52 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5357610805602757		[learning rate: 0.0041365]
	Learning Rate: 0.00413649
	LOSS [training: 1.5357610805602757 | validation: 1.845320641748654]
	TIME [epoch: 9.51 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.343903025406334		[learning rate: 0.0041215]
	Learning Rate: 0.00412147
	LOSS [training: 1.343903025406334 | validation: 1.7929673220168514]
	TIME [epoch: 9.54 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2862978155526865		[learning rate: 0.0041065]
	Learning Rate: 0.00410652
	LOSS [training: 1.2862978155526865 | validation: 2.234141570706374]
	TIME [epoch: 9.52 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4100771922468736		[learning rate: 0.0040916]
	Learning Rate: 0.00409161
	LOSS [training: 1.4100771922468736 | validation: 1.8386270723863378]
	TIME [epoch: 9.51 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4597238788377742		[learning rate: 0.0040768]
	Learning Rate: 0.00407677
	LOSS [training: 1.4597238788377742 | validation: 1.4972186212538332]
	TIME [epoch: 9.52 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3462129497925155		[learning rate: 0.004062]
	Learning Rate: 0.00406197
	LOSS [training: 1.3462129497925155 | validation: 1.7318927526857695]
	TIME [epoch: 9.53 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4016521528863226		[learning rate: 0.0040472]
	Learning Rate: 0.00404723
	LOSS [training: 1.4016521528863226 | validation: 1.5650407695541373]
	TIME [epoch: 9.52 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.393294540666592		[learning rate: 0.0040325]
	Learning Rate: 0.00403254
	LOSS [training: 1.393294540666592 | validation: 1.5029215729227818]
	TIME [epoch: 9.51 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.300118196376524		[learning rate: 0.0040179]
	Learning Rate: 0.00401791
	LOSS [training: 1.300118196376524 | validation: 1.8873259012736594]
	TIME [epoch: 9.52 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.45378604158876		[learning rate: 0.0040033]
	Learning Rate: 0.00400333
	LOSS [training: 1.45378604158876 | validation: 1.855369354098118]
	TIME [epoch: 9.53 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4978028089881275		[learning rate: 0.0039888]
	Learning Rate: 0.0039888
	LOSS [training: 1.4978028089881275 | validation: 1.5481644968793098]
	TIME [epoch: 9.52 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2768348863954397		[learning rate: 0.0039743]
	Learning Rate: 0.00397432
	LOSS [training: 1.2768348863954397 | validation: 1.4412014173505554]
	TIME [epoch: 9.51 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3315015384715045		[learning rate: 0.0039599]
	Learning Rate: 0.0039599
	LOSS [training: 1.3315015384715045 | validation: 1.5824010229293393]
	TIME [epoch: 9.54 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3864742524454958		[learning rate: 0.0039455]
	Learning Rate: 0.00394553
	LOSS [training: 1.3864742524454958 | validation: 1.8319266469124522]
	TIME [epoch: 9.52 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3675079899448754		[learning rate: 0.0039312]
	Learning Rate: 0.00393121
	LOSS [training: 1.3675079899448754 | validation: 1.5220444917095126]
	TIME [epoch: 9.53 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3904433272322765		[learning rate: 0.0039169]
	Learning Rate: 0.00391694
	LOSS [training: 1.3904433272322765 | validation: 1.9495858604416685]
	TIME [epoch: 9.51 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.682853933014964		[learning rate: 0.0039027]
	Learning Rate: 0.00390273
	LOSS [training: 1.682853933014964 | validation: 1.442939914336264]
	TIME [epoch: 9.54 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.333025227433403		[learning rate: 0.0038886]
	Learning Rate: 0.00388857
	LOSS [training: 1.333025227433403 | validation: 1.5444647123666568]
	TIME [epoch: 9.52 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2242366232891346		[learning rate: 0.0038745]
	Learning Rate: 0.00387445
	LOSS [training: 1.2242366232891346 | validation: 1.5757440624150645]
	TIME [epoch: 9.52 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.376847028948121		[learning rate: 0.0038604]
	Learning Rate: 0.00386039
	LOSS [training: 1.376847028948121 | validation: 1.6465703891838006]
	TIME [epoch: 9.52 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3805366384348996		[learning rate: 0.0038464]
	Learning Rate: 0.00384638
	LOSS [training: 1.3805366384348996 | validation: 1.8100309218893165]
	TIME [epoch: 9.54 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3936740506429548		[learning rate: 0.0038324]
	Learning Rate: 0.00383242
	LOSS [training: 1.3936740506429548 | validation: 1.5324896916803874]
	TIME [epoch: 9.52 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4030764323263045		[learning rate: 0.0038185]
	Learning Rate: 0.00381852
	LOSS [training: 1.4030764323263045 | validation: 1.5061046939559932]
	TIME [epoch: 9.51 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5541781400381671		[learning rate: 0.0038047]
	Learning Rate: 0.00380466
	LOSS [training: 1.5541781400381671 | validation: 1.4086915726522085]
	TIME [epoch: 9.52 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.35715184534484		[learning rate: 0.0037909]
	Learning Rate: 0.00379085
	LOSS [training: 1.35715184534484 | validation: 1.4553907722165826]
	TIME [epoch: 9.54 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2588695797939127		[learning rate: 0.0037771]
	Learning Rate: 0.00377709
	LOSS [training: 1.2588695797939127 | validation: 1.6046399792164505]
	TIME [epoch: 9.52 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3261416547468206		[learning rate: 0.0037634]
	Learning Rate: 0.00376339
	LOSS [training: 1.3261416547468206 | validation: 2.004624276646297]
	TIME [epoch: 9.51 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3990205604740136		[learning rate: 0.0037497]
	Learning Rate: 0.00374973
	LOSS [training: 1.3990205604740136 | validation: 1.5294973514501855]
	TIME [epoch: 9.53 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3344386851714065		[learning rate: 0.0037361]
	Learning Rate: 0.00373612
	LOSS [training: 1.3344386851714065 | validation: 1.6158578589945858]
	TIME [epoch: 9.53 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4001628209600236		[learning rate: 0.0037226]
	Learning Rate: 0.00372256
	LOSS [training: 1.4001628209600236 | validation: 2.344879997208501]
	TIME [epoch: 9.52 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4179038462817097		[learning rate: 0.0037091]
	Learning Rate: 0.00370905
	LOSS [training: 1.4179038462817097 | validation: 1.438800098069105]
	TIME [epoch: 9.52 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2172525773612506		[learning rate: 0.0036956]
	Learning Rate: 0.00369559
	LOSS [training: 1.2172525773612506 | validation: 1.6229611041654444]
	TIME [epoch: 9.54 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3136091981979334		[learning rate: 0.0036822]
	Learning Rate: 0.00368218
	LOSS [training: 1.3136091981979334 | validation: 1.4342139429694976]
	TIME [epoch: 9.52 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.31874158847702		[learning rate: 0.0036688]
	Learning Rate: 0.00366882
	LOSS [training: 1.31874158847702 | validation: 1.5685094595147948]
	TIME [epoch: 9.53 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4455787703879475		[learning rate: 0.0036555]
	Learning Rate: 0.0036555
	LOSS [training: 1.4455787703879475 | validation: 1.4877319093485557]
	TIME [epoch: 9.53 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.336042701925532		[learning rate: 0.0036422]
	Learning Rate: 0.00364224
	LOSS [training: 1.336042701925532 | validation: 1.3861983567149923]
	TIME [epoch: 9.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_378.pth
	Model improved!!!
EPOCH 379/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3367106365161348		[learning rate: 0.003629]
	Learning Rate: 0.00362902
	LOSS [training: 1.3367106365161348 | validation: 1.6921796124345179]
	TIME [epoch: 9.52 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2795617708732796		[learning rate: 0.0036159]
	Learning Rate: 0.00361585
	LOSS [training: 1.2795617708732796 | validation: 1.451152114501596]
	TIME [epoch: 9.52 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.167040243443828		[learning rate: 0.0036027]
	Learning Rate: 0.00360273
	LOSS [training: 1.167040243443828 | validation: 1.5762146804710233]
	TIME [epoch: 9.53 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2580114757527712		[learning rate: 0.0035897]
	Learning Rate: 0.00358965
	LOSS [training: 1.2580114757527712 | validation: 2.452757970677843]
	TIME [epoch: 9.55 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4623455561428274		[learning rate: 0.0035766]
	Learning Rate: 0.00357663
	LOSS [training: 1.4623455561428274 | validation: 1.6069560721699498]
	TIME [epoch: 9.54 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4160537451332351		[learning rate: 0.0035636]
	Learning Rate: 0.00356365
	LOSS [training: 1.4160537451332351 | validation: 1.5653861215838354]
	TIME [epoch: 9.53 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3239742629363154		[learning rate: 0.0035507]
	Learning Rate: 0.00355072
	LOSS [training: 1.3239742629363154 | validation: 1.7807679410308226]
	TIME [epoch: 9.54 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.353660629325828		[learning rate: 0.0035378]
	Learning Rate: 0.00353783
	LOSS [training: 1.353660629325828 | validation: 1.4379485915781687]
	TIME [epoch: 9.54 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2456034488903225		[learning rate: 0.003525]
	Learning Rate: 0.00352499
	LOSS [training: 1.2456034488903225 | validation: 1.5892956296979253]
	TIME [epoch: 9.53 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2633136748293787		[learning rate: 0.0035122]
	Learning Rate: 0.0035122
	LOSS [training: 1.2633136748293787 | validation: 1.5642262461951242]
	TIME [epoch: 9.53 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4716579636478204		[learning rate: 0.0034995]
	Learning Rate: 0.00349945
	LOSS [training: 1.4716579636478204 | validation: 1.4163743630038306]
	TIME [epoch: 9.54 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4349224233558249		[learning rate: 0.0034868]
	Learning Rate: 0.00348675
	LOSS [training: 1.4349224233558249 | validation: 1.4230820938854072]
	TIME [epoch: 9.54 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2560164259586006		[learning rate: 0.0034741]
	Learning Rate: 0.0034741
	LOSS [training: 1.2560164259586006 | validation: 1.667708947035651]
	TIME [epoch: 9.52 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2680840588508926		[learning rate: 0.0034615]
	Learning Rate: 0.00346149
	LOSS [training: 1.2680840588508926 | validation: 1.6173467430305053]
	TIME [epoch: 9.53 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4558498650688831		[learning rate: 0.0034489]
	Learning Rate: 0.00344893
	LOSS [training: 1.4558498650688831 | validation: 1.4079976232848026]
	TIME [epoch: 9.54 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.191410203487213		[learning rate: 0.0034364]
	Learning Rate: 0.00343641
	LOSS [training: 1.191410203487213 | validation: 1.5585438678593158]
	TIME [epoch: 9.53 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7746058280142005		[learning rate: 0.0034239]
	Learning Rate: 0.00342394
	LOSS [training: 1.7746058280142005 | validation: 1.5084105795579354]
	TIME [epoch: 9.53 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.320539778712083		[learning rate: 0.0034115]
	Learning Rate: 0.00341152
	LOSS [training: 1.320539778712083 | validation: 1.6930110069621904]
	TIME [epoch: 9.52 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2965024566647376		[learning rate: 0.0033991]
	Learning Rate: 0.00339914
	LOSS [training: 1.2965024566647376 | validation: 1.4363900849372795]
	TIME [epoch: 9.55 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1818097092231934		[learning rate: 0.0033868]
	Learning Rate: 0.0033868
	LOSS [training: 1.1818097092231934 | validation: 1.4877381063184438]
	TIME [epoch: 9.52 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1698386614637364		[learning rate: 0.0033745]
	Learning Rate: 0.00337451
	LOSS [training: 1.1698386614637364 | validation: 1.833877985536211]
	TIME [epoch: 9.53 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2502577737813503		[learning rate: 0.0033623]
	Learning Rate: 0.00336226
	LOSS [training: 1.2502577737813503 | validation: 1.4155447156190997]
	TIME [epoch: 9.51 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2000376526633576		[learning rate: 0.0033501]
	Learning Rate: 0.00335006
	LOSS [training: 1.2000376526633576 | validation: 1.6513674652981916]
	TIME [epoch: 9.55 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2960333610521677		[learning rate: 0.0033379]
	Learning Rate: 0.0033379
	LOSS [training: 1.2960333610521677 | validation: 1.4665181302269625]
	TIME [epoch: 9.51 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2400659086539987		[learning rate: 0.0033258]
	Learning Rate: 0.00332579
	LOSS [training: 1.2400659086539987 | validation: 1.4542292678010877]
	TIME [epoch: 9.52 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2720858848127878		[learning rate: 0.0033137]
	Learning Rate: 0.00331372
	LOSS [training: 1.2720858848127878 | validation: 1.5219615494532903]
	TIME [epoch: 9.53 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.31358585407128		[learning rate: 0.0033017]
	Learning Rate: 0.00330169
	LOSS [training: 1.31358585407128 | validation: 2.00179524902745]
	TIME [epoch: 9.54 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3064517697720253		[learning rate: 0.0032897]
	Learning Rate: 0.00328971
	LOSS [training: 1.3064517697720253 | validation: 1.8007357803596846]
	TIME [epoch: 9.52 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2387510905312022		[learning rate: 0.0032778]
	Learning Rate: 0.00327777
	LOSS [training: 1.2387510905312022 | validation: 1.4264484676490201]
	TIME [epoch: 9.53 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.223911607613056		[learning rate: 0.0032659]
	Learning Rate: 0.00326588
	LOSS [training: 1.223911607613056 | validation: 1.3838124062814874]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_408.pth
	Model improved!!!
EPOCH 409/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.266793289691908		[learning rate: 0.003254]
	Learning Rate: 0.00325403
	LOSS [training: 1.266793289691908 | validation: 1.4514704573845354]
	TIME [epoch: 9.52 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1651799668996343		[learning rate: 0.0032422]
	Learning Rate: 0.00324222
	LOSS [training: 1.1651799668996343 | validation: 1.84661096279104]
	TIME [epoch: 9.51 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2743240679168613		[learning rate: 0.0032305]
	Learning Rate: 0.00323045
	LOSS [training: 1.2743240679168613 | validation: 1.6509628139999035]
	TIME [epoch: 9.53 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.268145862703899		[learning rate: 0.0032187]
	Learning Rate: 0.00321873
	LOSS [training: 1.268145862703899 | validation: 1.374311818782868]
	TIME [epoch: 9.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_412.pth
	Model improved!!!
EPOCH 413/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2243819587467648		[learning rate: 0.003207]
	Learning Rate: 0.00320705
	LOSS [training: 1.2243819587467648 | validation: 1.4435837250150179]
	TIME [epoch: 9.52 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2270989692516434		[learning rate: 0.0031954]
	Learning Rate: 0.00319541
	LOSS [training: 1.2270989692516434 | validation: 1.5092730362158393]
	TIME [epoch: 9.82 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2993454039041414		[learning rate: 0.0031838]
	Learning Rate: 0.00318381
	LOSS [training: 1.2993454039041414 | validation: 1.496794155333479]
	TIME [epoch: 9.52 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2582241696568945		[learning rate: 0.0031723]
	Learning Rate: 0.00317226
	LOSS [training: 1.2582241696568945 | validation: 1.950890125562777]
	TIME [epoch: 9.54 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.554379315737494		[learning rate: 0.0031607]
	Learning Rate: 0.00316075
	LOSS [training: 1.554379315737494 | validation: 1.6155704556693196]
	TIME [epoch: 9.52 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.200744113131107		[learning rate: 0.0031493]
	Learning Rate: 0.00314927
	LOSS [training: 1.200744113131107 | validation: 1.5469075849272054]
	TIME [epoch: 9.52 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3292877240687104		[learning rate: 0.0031378]
	Learning Rate: 0.00313785
	LOSS [training: 1.3292877240687104 | validation: 1.5127617159917204]
	TIME [epoch: 9.53 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4033965783875022		[learning rate: 0.0031265]
	Learning Rate: 0.00312646
	LOSS [training: 1.4033965783875022 | validation: 1.7441068288399302]
	TIME [epoch: 9.54 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.29695746730495		[learning rate: 0.0031151]
	Learning Rate: 0.00311511
	LOSS [training: 1.29695746730495 | validation: 1.990763587090269]
	TIME [epoch: 9.52 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1888684076906302		[learning rate: 0.0031038]
	Learning Rate: 0.00310381
	LOSS [training: 1.1888684076906302 | validation: 1.3152441083736373]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_422.pth
	Model improved!!!
EPOCH 423/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.717378788828637		[learning rate: 0.0030925]
	Learning Rate: 0.00309254
	LOSS [training: 1.717378788828637 | validation: 1.3373598994177376]
	TIME [epoch: 9.54 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1109318082455713		[learning rate: 0.0030813]
	Learning Rate: 0.00308132
	LOSS [training: 1.1109318082455713 | validation: 1.4401761223755112]
	TIME [epoch: 9.52 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1872732134788009		[learning rate: 0.0030701]
	Learning Rate: 0.00307014
	LOSS [training: 1.1872732134788009 | validation: 1.569789009351369]
	TIME [epoch: 9.52 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2046773984097372		[learning rate: 0.003059]
	Learning Rate: 0.003059
	LOSS [training: 1.2046773984097372 | validation: 1.3406872090117208]
	TIME [epoch: 9.52 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2826513100052526		[learning rate: 0.0030479]
	Learning Rate: 0.0030479
	LOSS [training: 1.2826513100052526 | validation: 1.518645077954553]
	TIME [epoch: 9.53 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2474556966474322		[learning rate: 0.0030368]
	Learning Rate: 0.00303683
	LOSS [training: 1.2474556966474322 | validation: 1.4124349625065429]
	TIME [epoch: 9.52 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1448005545429099		[learning rate: 0.0030258]
	Learning Rate: 0.00302581
	LOSS [training: 1.1448005545429099 | validation: 1.523425779372152]
	TIME [epoch: 9.52 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2055250511122189		[learning rate: 0.0030148]
	Learning Rate: 0.00301483
	LOSS [training: 1.2055250511122189 | validation: 1.3414746251921525]
	TIME [epoch: 9.52 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1707490072445748		[learning rate: 0.0030039]
	Learning Rate: 0.00300389
	LOSS [training: 1.1707490072445748 | validation: 1.3188901674436115]
	TIME [epoch: 9.55 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1472057336164674		[learning rate: 0.002993]
	Learning Rate: 0.00299299
	LOSS [training: 1.1472057336164674 | validation: 1.7010131438672529]
	TIME [epoch: 9.52 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2388061565289952		[learning rate: 0.0029821]
	Learning Rate: 0.00298213
	LOSS [training: 1.2388061565289952 | validation: 1.4886381589220792]
	TIME [epoch: 9.52 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1583948429853326		[learning rate: 0.0029713]
	Learning Rate: 0.00297131
	LOSS [training: 1.1583948429853326 | validation: 1.4530115206266243]
	TIME [epoch: 9.52 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1837453933856057		[learning rate: 0.0029605]
	Learning Rate: 0.00296052
	LOSS [training: 1.1837453933856057 | validation: 1.3662364280488821]
	TIME [epoch: 9.54 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.130876860813274		[learning rate: 0.0029498]
	Learning Rate: 0.00294978
	LOSS [training: 1.130876860813274 | validation: 1.3272040021956302]
	TIME [epoch: 9.52 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0806519430668033		[learning rate: 0.0029391]
	Learning Rate: 0.00293907
	LOSS [training: 1.0806519430668033 | validation: 1.6631654834844583]
	TIME [epoch: 9.52 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3083868397667275		[learning rate: 0.0029284]
	Learning Rate: 0.00292841
	LOSS [training: 1.3083868397667275 | validation: 1.285731967667671]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_438.pth
	Model improved!!!
EPOCH 439/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2880418494732526		[learning rate: 0.0029178]
	Learning Rate: 0.00291778
	LOSS [training: 1.2880418494732526 | validation: 1.4279067424604879]
	TIME [epoch: 9.54 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1813964844265095		[learning rate: 0.0029072]
	Learning Rate: 0.00290719
	LOSS [training: 1.1813964844265095 | validation: 1.6861030166810498]
	TIME [epoch: 9.52 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2242405044223361		[learning rate: 0.0028966]
	Learning Rate: 0.00289664
	LOSS [training: 1.2242405044223361 | validation: 1.3394173360440889]
	TIME [epoch: 9.52 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1486712000855703		[learning rate: 0.0028861]
	Learning Rate: 0.00288613
	LOSS [training: 1.1486712000855703 | validation: 1.3552590709736696]
	TIME [epoch: 9.54 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1312300383673453		[learning rate: 0.0028757]
	Learning Rate: 0.00287566
	LOSS [training: 1.1312300383673453 | validation: 1.7090894993056218]
	TIME [epoch: 9.52 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2206237274543155		[learning rate: 0.0028652]
	Learning Rate: 0.00286522
	LOSS [training: 1.2206237274543155 | validation: 1.3350608335966316]
	TIME [epoch: 9.52 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2706322190543564		[learning rate: 0.0028548]
	Learning Rate: 0.00285482
	LOSS [training: 1.2706322190543564 | validation: 1.5372658874150378]
	TIME [epoch: 9.52 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1405060757935284		[learning rate: 0.0028445]
	Learning Rate: 0.00284446
	LOSS [training: 1.1405060757935284 | validation: 1.382318992957882]
	TIME [epoch: 9.54 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1704380976009687		[learning rate: 0.0028341]
	Learning Rate: 0.00283414
	LOSS [training: 1.1704380976009687 | validation: 1.5069798071379603]
	TIME [epoch: 9.52 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.134578135192329		[learning rate: 0.0028239]
	Learning Rate: 0.00282385
	LOSS [training: 1.134578135192329 | validation: 1.4416967248021906]
	TIME [epoch: 9.51 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2323663322954128		[learning rate: 0.0028136]
	Learning Rate: 0.00281361
	LOSS [training: 1.2323663322954128 | validation: 1.3465142163445862]
	TIME [epoch: 9.52 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1588857823740286		[learning rate: 0.0028034]
	Learning Rate: 0.00280339
	LOSS [training: 1.1588857823740286 | validation: 1.7612210499283762]
	TIME [epoch: 9.55 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3258691498221027		[learning rate: 0.0027932]
	Learning Rate: 0.00279322
	LOSS [training: 1.3258691498221027 | validation: 1.5410684053126051]
	TIME [epoch: 9.52 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1566145358135842		[learning rate: 0.0027831]
	Learning Rate: 0.00278308
	LOSS [training: 1.1566145358135842 | validation: 1.339864950662306]
	TIME [epoch: 9.52 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1021972099631692		[learning rate: 0.002773]
	Learning Rate: 0.00277298
	LOSS [training: 1.1021972099631692 | validation: 1.3477214155823654]
	TIME [epoch: 9.53 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.095387285294692		[learning rate: 0.0027629]
	Learning Rate: 0.00276292
	LOSS [training: 1.095387285294692 | validation: 1.325302246761749]
	TIME [epoch: 9.53 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1565059465026652		[learning rate: 0.0027529]
	Learning Rate: 0.00275289
	LOSS [training: 1.1565059465026652 | validation: 1.420035351101878]
	TIME [epoch: 9.51 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0608107511222369		[learning rate: 0.0027429]
	Learning Rate: 0.0027429
	LOSS [training: 1.0608107511222369 | validation: 1.4579693986683648]
	TIME [epoch: 9.52 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3042453488377013		[learning rate: 0.0027329]
	Learning Rate: 0.00273295
	LOSS [training: 1.3042453488377013 | validation: 1.3559273596971955]
	TIME [epoch: 9.53 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.248818367624586		[learning rate: 0.002723]
	Learning Rate: 0.00272303
	LOSS [training: 1.248818367624586 | validation: 1.4402981302542208]
	TIME [epoch: 9.53 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1410008625726646		[learning rate: 0.0027131]
	Learning Rate: 0.00271315
	LOSS [training: 1.1410008625726646 | validation: 1.476428183191077]
	TIME [epoch: 9.52 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1152502023608917		[learning rate: 0.0027033]
	Learning Rate: 0.0027033
	LOSS [training: 1.1152502023608917 | validation: 1.31862474698098]
	TIME [epoch: 9.52 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1523057628301383		[learning rate: 0.0026935]
	Learning Rate: 0.00269349
	LOSS [training: 1.1523057628301383 | validation: 1.6181177640828275]
	TIME [epoch: 9.54 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2028093845113872		[learning rate: 0.0026837]
	Learning Rate: 0.00268372
	LOSS [training: 1.2028093845113872 | validation: 1.4617864601542587]
	TIME [epoch: 9.52 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1222913669259562		[learning rate: 0.002674]
	Learning Rate: 0.00267398
	LOSS [training: 1.1222913669259562 | validation: 1.3841254983083098]
	TIME [epoch: 9.52 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0781362944277615		[learning rate: 0.0026643]
	Learning Rate: 0.00266427
	LOSS [training: 1.0781362944277615 | validation: 1.4232156014079473]
	TIME [epoch: 9.52 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1587157323361121		[learning rate: 0.0026546]
	Learning Rate: 0.00265461
	LOSS [training: 1.1587157323361121 | validation: 1.363190732785587]
	TIME [epoch: 9.54 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1380418314649479		[learning rate: 0.002645]
	Learning Rate: 0.00264497
	LOSS [training: 1.1380418314649479 | validation: 1.84835914831057]
	TIME [epoch: 9.52 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.178253054844684		[learning rate: 0.0026354]
	Learning Rate: 0.00263537
	LOSS [training: 1.178253054844684 | validation: 1.411685937033066]
	TIME [epoch: 9.51 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0287604595378574		[learning rate: 0.0026258]
	Learning Rate: 0.00262581
	LOSS [training: 1.0287604595378574 | validation: 1.6610368467022778]
	TIME [epoch: 9.52 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.212367872996539		[learning rate: 0.0026163]
	Learning Rate: 0.00261628
	LOSS [training: 1.212367872996539 | validation: 2.1166985930799056]
	TIME [epoch: 9.54 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2398238354128361		[learning rate: 0.0026068]
	Learning Rate: 0.00260679
	LOSS [training: 1.2398238354128361 | validation: 1.3731181655549876]
	TIME [epoch: 9.52 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.140724444248274		[learning rate: 0.0025973]
	Learning Rate: 0.00259733
	LOSS [training: 1.140724444248274 | validation: 1.578919182572833]
	TIME [epoch: 9.52 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1785765512972377		[learning rate: 0.0025879]
	Learning Rate: 0.0025879
	LOSS [training: 1.1785765512972377 | validation: 1.4860221187963851]
	TIME [epoch: 9.53 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.167235256701111		[learning rate: 0.0025785]
	Learning Rate: 0.00257851
	LOSS [training: 1.167235256701111 | validation: 1.3382199300955575]
	TIME [epoch: 9.54 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.186640197778995		[learning rate: 0.0025691]
	Learning Rate: 0.00256915
	LOSS [training: 1.186640197778995 | validation: 1.3445173414727996]
	TIME [epoch: 9.52 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.104065713097896		[learning rate: 0.0025598]
	Learning Rate: 0.00255983
	LOSS [training: 1.104065713097896 | validation: 1.469057843529377]
	TIME [epoch: 9.52 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0987038671282998		[learning rate: 0.0025505]
	Learning Rate: 0.00255054
	LOSS [training: 1.0987038671282998 | validation: 1.547586761069171]
	TIME [epoch: 9.54 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3338872571747957		[learning rate: 0.0025413]
	Learning Rate: 0.00254128
	LOSS [training: 1.3338872571747957 | validation: 1.4757997120166737]
	TIME [epoch: 9.53 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0556407479466416		[learning rate: 0.0025321]
	Learning Rate: 0.00253206
	LOSS [training: 1.0556407479466416 | validation: 1.2925524117785367]
	TIME [epoch: 9.53 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9891144364223077		[learning rate: 0.0025229]
	Learning Rate: 0.00252287
	LOSS [training: 0.9891144364223077 | validation: 1.5379861697183923]
	TIME [epoch: 9.52 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2122031244578422		[learning rate: 0.0025137]
	Learning Rate: 0.00251371
	LOSS [training: 1.2122031244578422 | validation: 1.3739413304548804]
	TIME [epoch: 9.54 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1878770379338004		[learning rate: 0.0025046]
	Learning Rate: 0.00250459
	LOSS [training: 1.1878770379338004 | validation: 1.65099390461901]
	TIME [epoch: 9.52 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.12094391304336		[learning rate: 0.0024955]
	Learning Rate: 0.0024955
	LOSS [training: 1.12094391304336 | validation: 1.3593696988988924]
	TIME [epoch: 9.52 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0912844343375707		[learning rate: 0.0024864]
	Learning Rate: 0.00248645
	LOSS [training: 1.0912844343375707 | validation: 1.2717127843491356]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_483.pth
	Model improved!!!
EPOCH 484/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0698918130257293		[learning rate: 0.0024774]
	Learning Rate: 0.00247742
	LOSS [training: 1.0698918130257293 | validation: 1.387652275025415]
	TIME [epoch: 9.55 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1104310739045622		[learning rate: 0.0024684]
	Learning Rate: 0.00246843
	LOSS [training: 1.1104310739045622 | validation: 1.375958799238631]
	TIME [epoch: 9.51 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9910798257231791		[learning rate: 0.0024595]
	Learning Rate: 0.00245947
	LOSS [training: 0.9910798257231791 | validation: 1.387339465178531]
	TIME [epoch: 9.52 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0778376420937916		[learning rate: 0.0024505]
	Learning Rate: 0.00245055
	LOSS [training: 1.0778376420937916 | validation: 1.2567093285405686]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_487.pth
	Model improved!!!
EPOCH 488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9915890807748262		[learning rate: 0.0024417]
	Learning Rate: 0.00244165
	LOSS [training: 0.9915890807748262 | validation: 1.315502372035174]
	TIME [epoch: 9.54 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0690064538246031		[learning rate: 0.0024328]
	Learning Rate: 0.00243279
	LOSS [training: 1.0690064538246031 | validation: 1.436813080244919]
	TIME [epoch: 9.52 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.015131519141841		[learning rate: 0.002424]
	Learning Rate: 0.00242396
	LOSS [training: 1.015131519141841 | validation: 1.361130174387726]
	TIME [epoch: 9.52 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0798486424786211		[learning rate: 0.0024152]
	Learning Rate: 0.00241517
	LOSS [training: 1.0798486424786211 | validation: 1.5285665333249367]
	TIME [epoch: 9.53 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.109312082634141		[learning rate: 0.0024064]
	Learning Rate: 0.0024064
	LOSS [training: 1.109312082634141 | validation: 1.338282399803046]
	TIME [epoch: 9.53 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.078369827584645		[learning rate: 0.0023977]
	Learning Rate: 0.00239767
	LOSS [training: 1.078369827584645 | validation: 1.2837859505369735]
	TIME [epoch: 9.52 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9637520776915613		[learning rate: 0.002389]
	Learning Rate: 0.00238897
	LOSS [training: 0.9637520776915613 | validation: 1.3595538529483038]
	TIME [epoch: 9.52 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0476634260004976		[learning rate: 0.0023803]
	Learning Rate: 0.0023803
	LOSS [training: 1.0476634260004976 | validation: 1.3737072835171882]
	TIME [epoch: 9.54 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.023027137989852		[learning rate: 0.0023717]
	Learning Rate: 0.00237166
	LOSS [training: 1.023027137989852 | validation: 1.336790619548915]
	TIME [epoch: 9.52 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0739229040564877		[learning rate: 0.0023631]
	Learning Rate: 0.00236305
	LOSS [training: 1.0739229040564877 | validation: 1.350357427336486]
	TIME [epoch: 9.52 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0360796144970859		[learning rate: 0.0023545]
	Learning Rate: 0.00235448
	LOSS [training: 1.0360796144970859 | validation: 1.252031299235563]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_498.pth
	Model improved!!!
EPOCH 499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9481503011611734		[learning rate: 0.0023459]
	Learning Rate: 0.00234593
	LOSS [training: 0.9481503011611734 | validation: 1.921214663644565]
	TIME [epoch: 9.55 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6092110742401835		[learning rate: 0.0023374]
	Learning Rate: 0.00233742
	LOSS [training: 1.6092110742401835 | validation: 1.4435766846409732]
	TIME [epoch: 9.53 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9842926626724011		[learning rate: 0.0023289]
	Learning Rate: 0.00232894
	LOSS [training: 0.9842926626724011 | validation: 1.2408775621811372]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_501.pth
	Model improved!!!
EPOCH 502/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0296908927486121		[learning rate: 0.0023205]
	Learning Rate: 0.00232049
	LOSS [training: 1.0296908927486121 | validation: 1.5556925533765367]
	TIME [epoch: 9.53 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.184496619433353		[learning rate: 0.0023121]
	Learning Rate: 0.00231206
	LOSS [training: 1.184496619433353 | validation: 1.297227700538117]
	TIME [epoch: 9.55 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.041331796965313		[learning rate: 0.0023037]
	Learning Rate: 0.00230367
	LOSS [training: 1.041331796965313 | validation: 1.348410062661506]
	TIME [epoch: 9.53 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.031283607093853		[learning rate: 0.0022953]
	Learning Rate: 0.00229531
	LOSS [training: 1.031283607093853 | validation: 1.5353319245107053]
	TIME [epoch: 9.53 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0237406717379147		[learning rate: 0.002287]
	Learning Rate: 0.00228698
	LOSS [training: 1.0237406717379147 | validation: 1.4519543923740452]
	TIME [epoch: 9.53 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9939036360024132		[learning rate: 0.0022787]
	Learning Rate: 0.00227868
	LOSS [training: 0.9939036360024132 | validation: 1.2734740990836988]
	TIME [epoch: 9.53 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2524914910392158		[learning rate: 0.0022704]
	Learning Rate: 0.00227042
	LOSS [training: 1.2524914910392158 | validation: 1.3167284990122305]
	TIME [epoch: 9.53 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.020507474554431		[learning rate: 0.0022622]
	Learning Rate: 0.00226218
	LOSS [training: 1.020507474554431 | validation: 1.482654703176065]
	TIME [epoch: 9.52 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.174618304938138		[learning rate: 0.002254]
	Learning Rate: 0.00225397
	LOSS [training: 1.174618304938138 | validation: 1.367243479399448]
	TIME [epoch: 9.55 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1008677225410035		[learning rate: 0.0022458]
	Learning Rate: 0.00224579
	LOSS [training: 1.1008677225410035 | validation: 1.3456361385922042]
	TIME [epoch: 9.53 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0177729648110252		[learning rate: 0.0022376]
	Learning Rate: 0.00223764
	LOSS [training: 1.0177729648110252 | validation: 1.3163478882337685]
	TIME [epoch: 9.52 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0503051024884562		[learning rate: 0.0022295]
	Learning Rate: 0.00222952
	LOSS [training: 1.0503051024884562 | validation: 1.289805676857537]
	TIME [epoch: 9.53 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.96890278052988		[learning rate: 0.0022214]
	Learning Rate: 0.00222142
	LOSS [training: 0.96890278052988 | validation: 1.5240576150533867]
	TIME [epoch: 9.55 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0782674318691015		[learning rate: 0.0022134]
	Learning Rate: 0.00221336
	LOSS [training: 1.0782674318691015 | validation: 1.3958919946498332]
	TIME [epoch: 9.53 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0431366789827927		[learning rate: 0.0022053]
	Learning Rate: 0.00220533
	LOSS [training: 1.0431366789827927 | validation: 1.5478062471253633]
	TIME [epoch: 9.53 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.254435187507815		[learning rate: 0.0021973]
	Learning Rate: 0.00219733
	LOSS [training: 1.254435187507815 | validation: 1.3686658651057428]
	TIME [epoch: 9.52 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9953672663043704		[learning rate: 0.0021894]
	Learning Rate: 0.00218935
	LOSS [training: 0.9953672663043704 | validation: 1.2820361034719638]
	TIME [epoch: 9.56 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.005688336318242		[learning rate: 0.0021814]
	Learning Rate: 0.00218141
	LOSS [training: 1.005688336318242 | validation: 1.3727562502544362]
	TIME [epoch: 9.52 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.061865307301218		[learning rate: 0.0021735]
	Learning Rate: 0.00217349
	LOSS [training: 1.061865307301218 | validation: 1.5299003655133339]
	TIME [epoch: 9.53 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0913406618463632		[learning rate: 0.0021656]
	Learning Rate: 0.0021656
	LOSS [training: 1.0913406618463632 | validation: 1.2874596127679991]
	TIME [epoch: 9.52 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0209740114240464		[learning rate: 0.0021577]
	Learning Rate: 0.00215774
	LOSS [training: 1.0209740114240464 | validation: 1.250821908784506]
	TIME [epoch: 9.54 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9612192074404557		[learning rate: 0.0021499]
	Learning Rate: 0.00214991
	LOSS [training: 0.9612192074404557 | validation: 1.2824121950321847]
	TIME [epoch: 9.53 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.063695385646847		[learning rate: 0.0021421]
	Learning Rate: 0.00214211
	LOSS [training: 1.063695385646847 | validation: 1.512903432574526]
	TIME [epoch: 9.53 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0371173365790038		[learning rate: 0.0021343]
	Learning Rate: 0.00213434
	LOSS [training: 1.0371173365790038 | validation: 1.2862093539783945]
	TIME [epoch: 9.53 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0420898023674394		[learning rate: 0.0021266]
	Learning Rate: 0.00212659
	LOSS [training: 1.0420898023674394 | validation: 1.1943534263232787]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_526.pth
	Model improved!!!
EPOCH 527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9150534662310654		[learning rate: 0.0021189]
	Learning Rate: 0.00211887
	LOSS [training: 0.9150534662310654 | validation: 1.2851769075501704]
	TIME [epoch: 9.52 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.072272476742744		[learning rate: 0.0021112]
	Learning Rate: 0.00211119
	LOSS [training: 1.072272476742744 | validation: 1.3178667839396776]
	TIME [epoch: 9.52 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.966071499014037		[learning rate: 0.0021035]
	Learning Rate: 0.00210352
	LOSS [training: 0.966071499014037 | validation: 1.3539638951564041]
	TIME [epoch: 9.54 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0258640837202173		[learning rate: 0.0020959]
	Learning Rate: 0.00209589
	LOSS [training: 1.0258640837202173 | validation: 1.2905655792420982]
	TIME [epoch: 9.53 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0087001277602075		[learning rate: 0.0020883]
	Learning Rate: 0.00208828
	LOSS [training: 1.0087001277602075 | validation: 1.210143780746415]
	TIME [epoch: 9.52 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9802742949544117		[learning rate: 0.0020807]
	Learning Rate: 0.00208071
	LOSS [training: 0.9802742949544117 | validation: 1.2766933737088955]
	TIME [epoch: 9.52 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9904664765756428		[learning rate: 0.0020732]
	Learning Rate: 0.00207315
	LOSS [training: 0.9904664765756428 | validation: 1.337219912578163]
	TIME [epoch: 9.55 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.966311565215635		[learning rate: 0.0020656]
	Learning Rate: 0.00206563
	LOSS [training: 0.966311565215635 | validation: 1.1871236730768915]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_534.pth
	Model improved!!!
EPOCH 535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9718079037991594		[learning rate: 0.0020581]
	Learning Rate: 0.00205813
	LOSS [training: 0.9718079037991594 | validation: 1.4392357979840227]
	TIME [epoch: 9.53 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.952534529043168		[learning rate: 0.0020507]
	Learning Rate: 0.00205067
	LOSS [training: 0.952534529043168 | validation: 1.4227111401286225]
	TIME [epoch: 9.52 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9909262445177933		[learning rate: 0.0020432]
	Learning Rate: 0.00204322
	LOSS [training: 0.9909262445177933 | validation: 1.7276416219854682]
	TIME [epoch: 9.54 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0928136678570923		[learning rate: 0.0020358]
	Learning Rate: 0.00203581
	LOSS [training: 1.0928136678570923 | validation: 1.3935827260883469]
	TIME [epoch: 9.54 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.073587477588164		[learning rate: 0.0020284]
	Learning Rate: 0.00202842
	LOSS [training: 1.073587477588164 | validation: 1.2070021942242075]
	TIME [epoch: 9.53 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8931062056861556		[learning rate: 0.0020211]
	Learning Rate: 0.00202106
	LOSS [training: 0.8931062056861556 | validation: 1.62130044057004]
	TIME [epoch: 9.53 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0525383062303368		[learning rate: 0.0020137]
	Learning Rate: 0.00201372
	LOSS [training: 1.0525383062303368 | validation: 1.193314942529365]
	TIME [epoch: 9.54 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9523820085596164		[learning rate: 0.0020064]
	Learning Rate: 0.00200642
	LOSS [training: 0.9523820085596164 | validation: 1.3294029402555259]
	TIME [epoch: 9.53 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.010322764462086		[learning rate: 0.0019991]
	Learning Rate: 0.00199913
	LOSS [training: 1.010322764462086 | validation: 1.3567566135239282]
	TIME [epoch: 9.52 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9668329191674392		[learning rate: 0.0019919]
	Learning Rate: 0.00199188
	LOSS [training: 0.9668329191674392 | validation: 1.244069858265189]
	TIME [epoch: 9.55 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1041619906404705		[learning rate: 0.0019847]
	Learning Rate: 0.00198465
	LOSS [training: 1.1041619906404705 | validation: 1.3221834311286933]
	TIME [epoch: 9.53 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9292276211608946		[learning rate: 0.0019774]
	Learning Rate: 0.00197745
	LOSS [training: 0.9292276211608946 | validation: 1.2793850628552665]
	TIME [epoch: 9.53 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9549476207815445		[learning rate: 0.0019703]
	Learning Rate: 0.00197027
	LOSS [training: 0.9549476207815445 | validation: 1.4581244910104425]
	TIME [epoch: 9.53 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9143971110752165		[learning rate: 0.0019631]
	Learning Rate: 0.00196312
	LOSS [training: 0.9143971110752165 | validation: 1.379612785452261]
	TIME [epoch: 9.55 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9957897971019971		[learning rate: 0.001956]
	Learning Rate: 0.001956
	LOSS [training: 0.9957897971019971 | validation: 1.4467665056118866]
	TIME [epoch: 9.53 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9715285941134824		[learning rate: 0.0019489]
	Learning Rate: 0.0019489
	LOSS [training: 0.9715285941134824 | validation: 1.1890127710952396]
	TIME [epoch: 9.52 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9345042577033619		[learning rate: 0.0019418]
	Learning Rate: 0.00194183
	LOSS [training: 0.9345042577033619 | validation: 1.4645693979052652]
	TIME [epoch: 9.52 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9435756211816282		[learning rate: 0.0019348]
	Learning Rate: 0.00193478
	LOSS [training: 0.9435756211816282 | validation: 1.2398299495206435]
	TIME [epoch: 9.54 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.885692653076043		[learning rate: 0.0019278]
	Learning Rate: 0.00192776
	LOSS [training: 0.885692653076043 | validation: 1.170208905065963]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_553.pth
	Model improved!!!
EPOCH 554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9302367296891173		[learning rate: 0.0019208]
	Learning Rate: 0.00192076
	LOSS [training: 0.9302367296891173 | validation: 1.1431365563862892]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_554.pth
	Model improved!!!
EPOCH 555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9316157435644724		[learning rate: 0.0019138]
	Learning Rate: 0.00191379
	LOSS [training: 0.9316157435644724 | validation: 1.2028697533583768]
	TIME [epoch: 9.53 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9483801360455812		[learning rate: 0.0019068]
	Learning Rate: 0.00190685
	LOSS [training: 0.9483801360455812 | validation: 1.3901998012431105]
	TIME [epoch: 9.53 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0412233914516036		[learning rate: 0.0018999]
	Learning Rate: 0.00189993
	LOSS [training: 1.0412233914516036 | validation: 1.2188788291633383]
	TIME [epoch: 9.51 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9386009277200728		[learning rate: 0.001893]
	Learning Rate: 0.00189303
	LOSS [training: 0.9386009277200728 | validation: 1.1911442507228087]
	TIME [epoch: 9.51 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.881228056815249		[learning rate: 0.0018862]
	Learning Rate: 0.00188616
	LOSS [training: 0.881228056815249 | validation: 1.2192650961218956]
	TIME [epoch: 9.53 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8940863097239029		[learning rate: 0.0018793]
	Learning Rate: 0.00187932
	LOSS [training: 0.8940863097239029 | validation: 1.220351948109651]
	TIME [epoch: 9.53 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9591673625380459		[learning rate: 0.0018725]
	Learning Rate: 0.0018725
	LOSS [training: 0.9591673625380459 | validation: 1.2002193643370749]
	TIME [epoch: 9.52 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8851973729641338		[learning rate: 0.0018657]
	Learning Rate: 0.0018657
	LOSS [training: 0.8851973729641338 | validation: 1.2116371744370806]
	TIME [epoch: 9.53 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9417343408469968		[learning rate: 0.0018589]
	Learning Rate: 0.00185893
	LOSS [training: 0.9417343408469968 | validation: 1.1350838788653812]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_563.pth
	Model improved!!!
EPOCH 564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9012184848192157		[learning rate: 0.0018522]
	Learning Rate: 0.00185218
	LOSS [training: 0.9012184848192157 | validation: 1.1449719352876964]
	TIME [epoch: 9.53 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9729166875753142		[learning rate: 0.0018455]
	Learning Rate: 0.00184546
	LOSS [training: 0.9729166875753142 | validation: 1.472140900473014]
	TIME [epoch: 9.52 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0041165651433448		[learning rate: 0.0018388]
	Learning Rate: 0.00183877
	LOSS [training: 1.0041165651433448 | validation: 1.20749138575288]
	TIME [epoch: 9.53 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8558165363856801		[learning rate: 0.0018321]
	Learning Rate: 0.00183209
	LOSS [training: 0.8558165363856801 | validation: 1.8348200983371783]
	TIME [epoch: 9.55 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1127969439866614		[learning rate: 0.0018254]
	Learning Rate: 0.00182544
	LOSS [training: 1.1127969439866614 | validation: 1.2506437414112939]
	TIME [epoch: 9.52 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9687902742414316		[learning rate: 0.0018188]
	Learning Rate: 0.00181882
	LOSS [training: 0.9687902742414316 | validation: 1.2722153266460352]
	TIME [epoch: 9.53 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8936980795469696		[learning rate: 0.0018122]
	Learning Rate: 0.00181222
	LOSS [training: 0.8936980795469696 | validation: 1.2926279627537667]
	TIME [epoch: 9.53 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.93473488697894		[learning rate: 0.0018056]
	Learning Rate: 0.00180564
	LOSS [training: 0.93473488697894 | validation: 1.1399927120507503]
	TIME [epoch: 9.56 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.947571304573805		[learning rate: 0.0017991]
	Learning Rate: 0.00179909
	LOSS [training: 0.947571304573805 | validation: 1.1841499105421884]
	TIME [epoch: 9.51 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.955768578078884		[learning rate: 0.0017926]
	Learning Rate: 0.00179256
	LOSS [training: 0.955768578078884 | validation: 1.2325384610323087]
	TIME [epoch: 9.52 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9021229662806469		[learning rate: 0.0017861]
	Learning Rate: 0.00178605
	LOSS [training: 0.9021229662806469 | validation: 1.3101459715927126]
	TIME [epoch: 9.53 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9007677212144876		[learning rate: 0.0017796]
	Learning Rate: 0.00177957
	LOSS [training: 0.9007677212144876 | validation: 1.2831412410885583]
	TIME [epoch: 9.54 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0586304032315008		[learning rate: 0.0017731]
	Learning Rate: 0.00177311
	LOSS [training: 1.0586304032315008 | validation: 1.1714033538753126]
	TIME [epoch: 9.53 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0018082787538414		[learning rate: 0.0017667]
	Learning Rate: 0.00176668
	LOSS [training: 1.0018082787538414 | validation: 1.2210733762661388]
	TIME [epoch: 9.53 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8545808417643244		[learning rate: 0.0017603]
	Learning Rate: 0.00176027
	LOSS [training: 0.8545808417643244 | validation: 1.201961413319229]
	TIME [epoch: 9.56 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8861859714793516		[learning rate: 0.0017539]
	Learning Rate: 0.00175388
	LOSS [training: 0.8861859714793516 | validation: 1.258572966804662]
	TIME [epoch: 9.53 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8875431285772859		[learning rate: 0.0017475]
	Learning Rate: 0.00174752
	LOSS [training: 0.8875431285772859 | validation: 1.186061285918805]
	TIME [epoch: 9.52 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.925983929607072		[learning rate: 0.0017412]
	Learning Rate: 0.00174117
	LOSS [training: 0.925983929607072 | validation: 1.1317213460752265]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_581.pth
	Model improved!!!
EPOCH 582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.909679762179986		[learning rate: 0.0017349]
	Learning Rate: 0.00173486
	LOSS [training: 0.909679762179986 | validation: 1.1542382105703166]
	TIME [epoch: 9.55 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9260309424931638		[learning rate: 0.0017286]
	Learning Rate: 0.00172856
	LOSS [training: 0.9260309424931638 | validation: 1.1402487822568932]
	TIME [epoch: 9.53 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8635231406660466		[learning rate: 0.0017223]
	Learning Rate: 0.00172229
	LOSS [training: 0.8635231406660466 | validation: 1.3663950626486838]
	TIME [epoch: 9.52 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9649807545871676		[learning rate: 0.001716]
	Learning Rate: 0.00171604
	LOSS [training: 0.9649807545871676 | validation: 1.124405791526225]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_585.pth
	Model improved!!!
EPOCH 586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9133673000296636		[learning rate: 0.0017098]
	Learning Rate: 0.00170981
	LOSS [training: 0.9133673000296636 | validation: 1.1962727945509701]
	TIME [epoch: 9.55 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.871849146706032		[learning rate: 0.0017036]
	Learning Rate: 0.0017036
	LOSS [training: 0.871849146706032 | validation: 1.2555557699820452]
	TIME [epoch: 9.52 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8495262086691747		[learning rate: 0.0016974]
	Learning Rate: 0.00169742
	LOSS [training: 0.8495262086691747 | validation: 1.12612764854337]
	TIME [epoch: 9.52 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8672092336358054		[learning rate: 0.0016913]
	Learning Rate: 0.00169126
	LOSS [training: 0.8672092336358054 | validation: 1.3160586628641466]
	TIME [epoch: 9.53 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9014238576041066		[learning rate: 0.0016851]
	Learning Rate: 0.00168512
	LOSS [training: 0.9014238576041066 | validation: 1.1044791664785658]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_590.pth
	Model improved!!!
EPOCH 591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9099171738782277		[learning rate: 0.001679]
	Learning Rate: 0.00167901
	LOSS [training: 0.9099171738782277 | validation: 1.2156798730202918]
	TIME [epoch: 9.53 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8893090484636872		[learning rate: 0.0016729]
	Learning Rate: 0.00167291
	LOSS [training: 0.8893090484636872 | validation: 1.1962363471744495]
	TIME [epoch: 9.52 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8831169258824548		[learning rate: 0.0016668]
	Learning Rate: 0.00166684
	LOSS [training: 0.8831169258824548 | validation: 1.4637758373392669]
	TIME [epoch: 9.53 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0564504711990408		[learning rate: 0.0016608]
	Learning Rate: 0.00166079
	LOSS [training: 1.0564504711990408 | validation: 1.1656436968583976]
	TIME [epoch: 9.53 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9269669517163583		[learning rate: 0.0016548]
	Learning Rate: 0.00165477
	LOSS [training: 0.9269669517163583 | validation: 1.483090778119113]
	TIME [epoch: 9.52 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.92761494958139		[learning rate: 0.0016488]
	Learning Rate: 0.00164876
	LOSS [training: 0.92761494958139 | validation: 1.1967418674718122]
	TIME [epoch: 9.52 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8761488560250967		[learning rate: 0.0016428]
	Learning Rate: 0.00164278
	LOSS [training: 0.8761488560250967 | validation: 1.1364684859950427]
	TIME [epoch: 9.55 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.885471405321297		[learning rate: 0.0016368]
	Learning Rate: 0.00163682
	LOSS [training: 0.885471405321297 | validation: 1.2567922069414303]
	TIME [epoch: 9.52 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.958822426392772		[learning rate: 0.0016309]
	Learning Rate: 0.00163088
	LOSS [training: 0.958822426392772 | validation: 1.1304612287160347]
	TIME [epoch: 9.53 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8193589730104284		[learning rate: 0.001625]
	Learning Rate: 0.00162496
	LOSS [training: 0.8193589730104284 | validation: 1.2047032710367338]
	TIME [epoch: 9.52 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9112227212066006		[learning rate: 0.0016191]
	Learning Rate: 0.00161906
	LOSS [training: 0.9112227212066006 | validation: 1.157008497407769]
	TIME [epoch: 9.54 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9507997336847247		[learning rate: 0.0016132]
	Learning Rate: 0.00161319
	LOSS [training: 0.9507997336847247 | validation: 1.1844835632547837]
	TIME [epoch: 9.52 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8745072882002061		[learning rate: 0.0016073]
	Learning Rate: 0.00160733
	LOSS [training: 0.8745072882002061 | validation: 1.191433195189802]
	TIME [epoch: 9.53 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9208443735676148		[learning rate: 0.0016015]
	Learning Rate: 0.0016015
	LOSS [training: 0.9208443735676148 | validation: 1.1225464431792218]
	TIME [epoch: 9.52 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8620976730621719		[learning rate: 0.0015957]
	Learning Rate: 0.00159569
	LOSS [training: 0.8620976730621719 | validation: 1.1776102167117022]
	TIME [epoch: 9.54 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8682877926272408		[learning rate: 0.0015899]
	Learning Rate: 0.00158989
	LOSS [training: 0.8682877926272408 | validation: 1.122843242913263]
	TIME [epoch: 9.52 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8880874890825521		[learning rate: 0.0015841]
	Learning Rate: 0.00158413
	LOSS [training: 0.8880874890825521 | validation: 1.2093223464819816]
	TIME [epoch: 9.52 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.972444404756704		[learning rate: 0.0015784]
	Learning Rate: 0.00157838
	LOSS [training: 0.972444404756704 | validation: 1.1449615035389087]
	TIME [epoch: 9.54 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8679343110887203		[learning rate: 0.0015726]
	Learning Rate: 0.00157265
	LOSS [training: 0.8679343110887203 | validation: 1.1628409888734264]
	TIME [epoch: 9.53 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.876765525583281		[learning rate: 0.0015669]
	Learning Rate: 0.00156694
	LOSS [training: 0.876765525583281 | validation: 1.1734387221881435]
	TIME [epoch: 9.53 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8954336525184907		[learning rate: 0.0015613]
	Learning Rate: 0.00156125
	LOSS [training: 0.8954336525184907 | validation: 1.137299083468569]
	TIME [epoch: 9.52 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.860519470780365		[learning rate: 0.0015556]
	Learning Rate: 0.00155559
	LOSS [training: 0.860519470780365 | validation: 1.5689150586195137]
	TIME [epoch: 9.54 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9673450566446522		[learning rate: 0.0015499]
	Learning Rate: 0.00154994
	LOSS [training: 0.9673450566446522 | validation: 1.2375053578052986]
	TIME [epoch: 9.52 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8956818847283307		[learning rate: 0.0015443]
	Learning Rate: 0.00154432
	LOSS [training: 0.8956818847283307 | validation: 1.2901693401296155]
	TIME [epoch: 9.53 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8835813196105203		[learning rate: 0.0015387]
	Learning Rate: 0.00153871
	LOSS [training: 0.8835813196105203 | validation: 1.301342853516944]
	TIME [epoch: 9.53 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8570338741893722		[learning rate: 0.0015331]
	Learning Rate: 0.00153313
	LOSS [training: 0.8570338741893722 | validation: 1.1461373581363765]
	TIME [epoch: 9.56 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8194266125866256		[learning rate: 0.0015276]
	Learning Rate: 0.00152757
	LOSS [training: 0.8194266125866256 | validation: 1.113895678087725]
	TIME [epoch: 9.53 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8315313415267902		[learning rate: 0.001522]
	Learning Rate: 0.00152202
	LOSS [training: 0.8315313415267902 | validation: 1.1479244949860943]
	TIME [epoch: 9.53 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8704320588871921		[learning rate: 0.0015165]
	Learning Rate: 0.0015165
	LOSS [training: 0.8704320588871921 | validation: 1.2073951008343013]
	TIME [epoch: 9.53 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8818107080105975		[learning rate: 0.001511]
	Learning Rate: 0.001511
	LOSS [training: 0.8818107080105975 | validation: 1.1325629823938703]
	TIME [epoch: 9.55 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8476287416871445		[learning rate: 0.0015055]
	Learning Rate: 0.00150551
	LOSS [training: 0.8476287416871445 | validation: 1.1141280829233842]
	TIME [epoch: 9.52 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8110820319487377		[learning rate: 0.0015]
	Learning Rate: 0.00150005
	LOSS [training: 0.8110820319487377 | validation: 1.1120994137496418]
	TIME [epoch: 9.53 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8246948414219745		[learning rate: 0.0014946]
	Learning Rate: 0.0014946
	LOSS [training: 0.8246948414219745 | validation: 1.186912388400596]
	TIME [epoch: 9.54 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8628502914111774		[learning rate: 0.0014892]
	Learning Rate: 0.00148918
	LOSS [training: 0.8628502914111774 | validation: 1.1296811248741718]
	TIME [epoch: 9.54 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8353140123827014		[learning rate: 0.0014838]
	Learning Rate: 0.00148378
	LOSS [training: 0.8353140123827014 | validation: 1.118042311157527]
	TIME [epoch: 9.52 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8740970246977667		[learning rate: 0.0014784]
	Learning Rate: 0.00147839
	LOSS [training: 0.8740970246977667 | validation: 1.1461614289651734]
	TIME [epoch: 9.52 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8556334287604095		[learning rate: 0.001473]
	Learning Rate: 0.00147303
	LOSS [training: 0.8556334287604095 | validation: 1.2854236353863746]
	TIME [epoch: 9.54 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8950149794807306		[learning rate: 0.0014677]
	Learning Rate: 0.00146768
	LOSS [training: 0.8950149794807306 | validation: 1.3050528232155716]
	TIME [epoch: 9.54 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8782525030477852		[learning rate: 0.0014624]
	Learning Rate: 0.00146235
	LOSS [training: 0.8782525030477852 | validation: 1.0923999955856944]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_629.pth
	Model improved!!!
EPOCH 630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8447197096039577		[learning rate: 0.001457]
	Learning Rate: 0.00145705
	LOSS [training: 0.8447197096039577 | validation: 1.136118033299808]
	TIME [epoch: 9.53 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8205161744787477		[learning rate: 0.0014518]
	Learning Rate: 0.00145176
	LOSS [training: 0.8205161744787477 | validation: 1.1234053105084396]
	TIME [epoch: 9.55 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9356135333550919		[learning rate: 0.0014465]
	Learning Rate: 0.00144649
	LOSS [training: 0.9356135333550919 | validation: 1.1764354781048227]
	TIME [epoch: 9.53 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.892953706509207		[learning rate: 0.0014412]
	Learning Rate: 0.00144124
	LOSS [training: 0.892953706509207 | validation: 1.1088226603662616]
	TIME [epoch: 9.52 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.789314255285007		[learning rate: 0.001436]
	Learning Rate: 0.00143601
	LOSS [training: 0.789314255285007 | validation: 1.1196456798415941]
	TIME [epoch: 9.53 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8512187450318882		[learning rate: 0.0014308]
	Learning Rate: 0.0014308
	LOSS [training: 0.8512187450318882 | validation: 1.0883905818842974]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_635.pth
	Model improved!!!
EPOCH 636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8818950543703803		[learning rate: 0.0014256]
	Learning Rate: 0.00142561
	LOSS [training: 0.8818950543703803 | validation: 1.1446854949277014]
	TIME [epoch: 9.53 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8437567854075849		[learning rate: 0.0014204]
	Learning Rate: 0.00142043
	LOSS [training: 0.8437567854075849 | validation: 1.1323014382721706]
	TIME [epoch: 9.53 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8332101915522978		[learning rate: 0.0014153]
	Learning Rate: 0.00141528
	LOSS [training: 0.8332101915522978 | validation: 1.203050237531395]
	TIME [epoch: 9.53 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8429211274180985		[learning rate: 0.0014101]
	Learning Rate: 0.00141014
	LOSS [training: 0.8429211274180985 | validation: 1.1633920464730334]
	TIME [epoch: 9.55 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8744230875074639		[learning rate: 0.001405]
	Learning Rate: 0.00140503
	LOSS [training: 0.8744230875074639 | validation: 1.0744673306200614]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_640.pth
	Model improved!!!
EPOCH 641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7801063134628992		[learning rate: 0.0013999]
	Learning Rate: 0.00139993
	LOSS [training: 0.7801063134628992 | validation: 1.1853466333652132]
	TIME [epoch: 9.53 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8497333856866671		[learning rate: 0.0013948]
	Learning Rate: 0.00139485
	LOSS [training: 0.8497333856866671 | validation: 1.069071162653678]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_642.pth
	Model improved!!!
EPOCH 643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8462184603946517		[learning rate: 0.0013898]
	Learning Rate: 0.00138978
	LOSS [training: 0.8462184603946517 | validation: 1.2336803867613464]
	TIME [epoch: 9.54 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.926759817610462		[learning rate: 0.0013847]
	Learning Rate: 0.00138474
	LOSS [training: 0.926759817610462 | validation: 1.087047705248515]
	TIME [epoch: 9.53 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8363892817844795		[learning rate: 0.0013797]
	Learning Rate: 0.00137972
	LOSS [training: 0.8363892817844795 | validation: 1.1070602840737647]
	TIME [epoch: 9.53 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9101882090358536		[learning rate: 0.0013747]
	Learning Rate: 0.00137471
	LOSS [training: 0.9101882090358536 | validation: 1.1029268591275352]
	TIME [epoch: 9.55 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8358142286553161		[learning rate: 0.0013697]
	Learning Rate: 0.00136972
	LOSS [training: 0.8358142286553161 | validation: 1.2438904214336783]
	TIME [epoch: 9.53 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8981920151479162		[learning rate: 0.0013647]
	Learning Rate: 0.00136475
	LOSS [training: 0.8981920151479162 | validation: 1.0948951004012295]
	TIME [epoch: 9.52 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8626319780524065		[learning rate: 0.0013598]
	Learning Rate: 0.0013598
	LOSS [training: 0.8626319780524065 | validation: 1.263884593586563]
	TIME [epoch: 9.53 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8668119268212408		[learning rate: 0.0013549]
	Learning Rate: 0.00135486
	LOSS [training: 0.8668119268212408 | validation: 1.0964602359898805]
	TIME [epoch: 9.55 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7910889858593773		[learning rate: 0.0013499]
	Learning Rate: 0.00134994
	LOSS [training: 0.7910889858593773 | validation: 1.1402955963967032]
	TIME [epoch: 9.52 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8292326671340877		[learning rate: 0.001345]
	Learning Rate: 0.00134505
	LOSS [training: 0.8292326671340877 | validation: 1.1731343821974616]
	TIME [epoch: 9.53 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8282776546910761		[learning rate: 0.0013402]
	Learning Rate: 0.00134016
	LOSS [training: 0.8282776546910761 | validation: 1.3654347220453227]
	TIME [epoch: 9.52 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9443232534784809		[learning rate: 0.0013353]
	Learning Rate: 0.0013353
	LOSS [training: 0.9443232534784809 | validation: 1.0886607715401089]
	TIME [epoch: 9.55 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8155586359885969		[learning rate: 0.0013305]
	Learning Rate: 0.00133045
	LOSS [training: 0.8155586359885969 | validation: 1.0754337236837057]
	TIME [epoch: 9.52 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8224604340674369		[learning rate: 0.0013256]
	Learning Rate: 0.00132563
	LOSS [training: 0.8224604340674369 | validation: 1.0880036132181068]
	TIME [epoch: 9.52 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8473232109542476		[learning rate: 0.0013208]
	Learning Rate: 0.00132082
	LOSS [training: 0.8473232109542476 | validation: 1.0955227837935941]
	TIME [epoch: 9.53 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7913149429912729		[learning rate: 0.001316]
	Learning Rate: 0.00131602
	LOSS [training: 0.7913149429912729 | validation: 1.0552002913019514]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_658.pth
	Model improved!!!
EPOCH 659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8146024556136929		[learning rate: 0.0013112]
	Learning Rate: 0.00131125
	LOSS [training: 0.8146024556136929 | validation: 1.1430336527108238]
	TIME [epoch: 9.52 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8170629323806444		[learning rate: 0.0013065]
	Learning Rate: 0.00130649
	LOSS [training: 0.8170629323806444 | validation: 1.1660743445296047]
	TIME [epoch: 9.52 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8114629929947498		[learning rate: 0.0013017]
	Learning Rate: 0.00130175
	LOSS [training: 0.8114629929947498 | validation: 1.0906413801958548]
	TIME [epoch: 9.54 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8435595683808292		[learning rate: 0.001297]
	Learning Rate: 0.00129702
	LOSS [training: 0.8435595683808292 | validation: 1.0566383996711302]
	TIME [epoch: 9.52 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8088664849934647		[learning rate: 0.0012923]
	Learning Rate: 0.00129232
	LOSS [training: 0.8088664849934647 | validation: 1.1372949799619534]
	TIME [epoch: 9.51 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8308097639796049		[learning rate: 0.0012876]
	Learning Rate: 0.00128763
	LOSS [training: 0.8308097639796049 | validation: 1.2435198120860431]
	TIME [epoch: 9.52 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8751789489181594		[learning rate: 0.001283]
	Learning Rate: 0.00128295
	LOSS [training: 0.8751789489181594 | validation: 1.0607053054638973]
	TIME [epoch: 9.55 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7850078276292282		[learning rate: 0.0012783]
	Learning Rate: 0.0012783
	LOSS [training: 0.7850078276292282 | validation: 1.0942252541485236]
	TIME [epoch: 9.52 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7955294200244627		[learning rate: 0.0012737]
	Learning Rate: 0.00127366
	LOSS [training: 0.7955294200244627 | validation: 1.1725051360278078]
	TIME [epoch: 9.53 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8565794514707423		[learning rate: 0.001269]
	Learning Rate: 0.00126904
	LOSS [training: 0.8565794514707423 | validation: 1.1325299710280277]
	TIME [epoch: 9.52 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8176701520258403		[learning rate: 0.0012644]
	Learning Rate: 0.00126443
	LOSS [training: 0.8176701520258403 | validation: 1.3714128400147112]
	TIME [epoch: 9.54 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8546712727155181		[learning rate: 0.0012598]
	Learning Rate: 0.00125984
	LOSS [training: 0.8546712727155181 | validation: 1.0486739317036267]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_670.pth
	Model improved!!!
EPOCH 671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7775080910370354		[learning rate: 0.0012553]
	Learning Rate: 0.00125527
	LOSS [training: 0.7775080910370354 | validation: 1.1088132928604373]
	TIME [epoch: 9.52 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8075346481027135		[learning rate: 0.0012507]
	Learning Rate: 0.00125071
	LOSS [training: 0.8075346481027135 | validation: 1.131389497410316]
	TIME [epoch: 9.53 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7954147565849738		[learning rate: 0.0012462]
	Learning Rate: 0.00124617
	LOSS [training: 0.7954147565849738 | validation: 1.2412539125690167]
	TIME [epoch: 9.54 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9023441461552177		[learning rate: 0.0012417]
	Learning Rate: 0.00124165
	LOSS [training: 0.9023441461552177 | validation: 1.2864232968302873]
	TIME [epoch: 9.53 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.858969926268719		[learning rate: 0.0012371]
	Learning Rate: 0.00123715
	LOSS [training: 0.858969926268719 | validation: 1.1052029315782617]
	TIME [epoch: 9.53 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7666648493137584		[learning rate: 0.0012327]
	Learning Rate: 0.00123266
	LOSS [training: 0.7666648493137584 | validation: 1.489576185812532]
	TIME [epoch: 9.54 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.927866981087748		[learning rate: 0.0012282]
	Learning Rate: 0.00122818
	LOSS [training: 0.927866981087748 | validation: 1.0593123860589142]
	TIME [epoch: 9.52 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.79681531472381		[learning rate: 0.0012237]
	Learning Rate: 0.00122373
	LOSS [training: 0.79681531472381 | validation: 1.1845276033427217]
	TIME [epoch: 9.52 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8409693038998028		[learning rate: 0.0012193]
	Learning Rate: 0.00121929
	LOSS [training: 0.8409693038998028 | validation: 1.2197311954466055]
	TIME [epoch: 9.52 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7975075238611277		[learning rate: 0.0012149]
	Learning Rate: 0.00121486
	LOSS [training: 0.7975075238611277 | validation: 1.0620385855575925]
	TIME [epoch: 9.55 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8247918251793822		[learning rate: 0.0012105]
	Learning Rate: 0.00121045
	LOSS [training: 0.8247918251793822 | validation: 1.1452648555948077]
	TIME [epoch: 9.54 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8412416317588285		[learning rate: 0.0012061]
	Learning Rate: 0.00120606
	LOSS [training: 0.8412416317588285 | validation: 1.1153474203677576]
	TIME [epoch: 9.52 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.783852959973275		[learning rate: 0.0012017]
	Learning Rate: 0.00120168
	LOSS [training: 0.783852959973275 | validation: 1.2229770662340085]
	TIME [epoch: 9.53 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8210221291245485		[learning rate: 0.0011973]
	Learning Rate: 0.00119732
	LOSS [training: 0.8210221291245485 | validation: 1.2476121666688256]
	TIME [epoch: 9.56 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8022974284402048		[learning rate: 0.001193]
	Learning Rate: 0.00119298
	LOSS [training: 0.8022974284402048 | validation: 1.0446971986521283]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_685.pth
	Model improved!!!
EPOCH 686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8454493770028284		[learning rate: 0.0011886]
	Learning Rate: 0.00118865
	LOSS [training: 0.8454493770028284 | validation: 1.1040948929100145]
	TIME [epoch: 9.53 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8280736530055368		[learning rate: 0.0011843]
	Learning Rate: 0.00118433
	LOSS [training: 0.8280736530055368 | validation: 1.0930834484249408]
	TIME [epoch: 9.52 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8180799441722902		[learning rate: 0.00118]
	Learning Rate: 0.00118003
	LOSS [training: 0.8180799441722902 | validation: 1.172321679615213]
	TIME [epoch: 9.55 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.823945060206114		[learning rate: 0.0011758]
	Learning Rate: 0.00117575
	LOSS [training: 0.823945060206114 | validation: 1.2245426702624034]
	TIME [epoch: 9.52 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.839395503390967		[learning rate: 0.0011715]
	Learning Rate: 0.00117149
	LOSS [training: 0.839395503390967 | validation: 1.1049537071585258]
	TIME [epoch: 9.53 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7928615602567217		[learning rate: 0.0011672]
	Learning Rate: 0.00116723
	LOSS [training: 0.7928615602567217 | validation: 1.0346004890296596]
	TIME [epoch: 9.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_691.pth
	Model improved!!!
EPOCH 692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7565804572248915		[learning rate: 0.001163]
	Learning Rate: 0.001163
	LOSS [training: 0.7565804572248915 | validation: 1.120680347435862]
	TIME [epoch: 9.53 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8201253972630788		[learning rate: 0.0011588]
	Learning Rate: 0.00115878
	LOSS [training: 0.8201253972630788 | validation: 1.0824774077512023]
	TIME [epoch: 9.52 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7812296996904554		[learning rate: 0.0011546]
	Learning Rate: 0.00115457
	LOSS [training: 0.7812296996904554 | validation: 1.270023420786991]
	TIME [epoch: 9.51 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8557582949663329		[learning rate: 0.0011504]
	Learning Rate: 0.00115038
	LOSS [training: 0.8557582949663329 | validation: 1.1822023760527025]
	TIME [epoch: 9.54 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.836280293689142		[learning rate: 0.0011462]
	Learning Rate: 0.00114621
	LOSS [training: 0.836280293689142 | validation: 1.1728152935639735]
	TIME [epoch: 9.53 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8471981688012058		[learning rate: 0.001142]
	Learning Rate: 0.00114205
	LOSS [training: 0.8471981688012058 | validation: 1.066734346031151]
	TIME [epoch: 9.53 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7691753689994102		[learning rate: 0.0011379]
	Learning Rate: 0.0011379
	LOSS [training: 0.7691753689994102 | validation: 1.0529220355638613]
	TIME [epoch: 9.52 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7899504575396236		[learning rate: 0.0011338]
	Learning Rate: 0.00113377
	LOSS [training: 0.7899504575396236 | validation: 1.0922849028779638]
	TIME [epoch: 9.55 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7610991479781534		[learning rate: 0.0011297]
	Learning Rate: 0.00112966
	LOSS [training: 0.7610991479781534 | validation: 1.2755268853887842]
	TIME [epoch: 9.52 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8297373483071997		[learning rate: 0.0011256]
	Learning Rate: 0.00112556
	LOSS [training: 0.8297373483071997 | validation: 1.0737859566627683]
	TIME [epoch: 9.52 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8160482309212552		[learning rate: 0.0011215]
	Learning Rate: 0.00112147
	LOSS [training: 0.8160482309212552 | validation: 1.0707129920971377]
	TIME [epoch: 9.52 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8162980000694612		[learning rate: 0.0011174]
	Learning Rate: 0.0011174
	LOSS [training: 0.8162980000694612 | validation: 1.0543211895762878]
	TIME [epoch: 9.54 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7636911583308088		[learning rate: 0.0011133]
	Learning Rate: 0.00111335
	LOSS [training: 0.7636911583308088 | validation: 1.1083298238806285]
	TIME [epoch: 9.52 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7831777231350083		[learning rate: 0.0011093]
	Learning Rate: 0.00110931
	LOSS [training: 0.7831777231350083 | validation: 1.060612926579065]
	TIME [epoch: 9.52 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8329894447561234		[learning rate: 0.0011053]
	Learning Rate: 0.00110528
	LOSS [training: 0.8329894447561234 | validation: 1.222816100102676]
	TIME [epoch: 9.53 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7962363859615467		[learning rate: 0.0011013]
	Learning Rate: 0.00110127
	LOSS [training: 0.7962363859615467 | validation: 1.0378172426144556]
	TIME [epoch: 9.54 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7740107657592568		[learning rate: 0.0010973]
	Learning Rate: 0.00109728
	LOSS [training: 0.7740107657592568 | validation: 1.0520057554805096]
	TIME [epoch: 9.52 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7525473904033402		[learning rate: 0.0010933]
	Learning Rate: 0.00109329
	LOSS [training: 0.7525473904033402 | validation: 1.0671199532005584]
	TIME [epoch: 9.54 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7965821247148724		[learning rate: 0.0010893]
	Learning Rate: 0.00108933
	LOSS [training: 0.7965821247148724 | validation: 1.0460397873697544]
	TIME [epoch: 9.54 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7854239106167393		[learning rate: 0.0010854]
	Learning Rate: 0.00108537
	LOSS [training: 0.7854239106167393 | validation: 1.0843620577076036]
	TIME [epoch: 9.53 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8052033722599294		[learning rate: 0.0010814]
	Learning Rate: 0.00108143
	LOSS [training: 0.8052033722599294 | validation: 1.0504409201137803]
	TIME [epoch: 9.52 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7507605127146292		[learning rate: 0.0010775]
	Learning Rate: 0.00107751
	LOSS [training: 0.7507605127146292 | validation: 1.0688944318935214]
	TIME [epoch: 9.53 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.778339625551833		[learning rate: 0.0010736]
	Learning Rate: 0.0010736
	LOSS [training: 0.778339625551833 | validation: 1.0460303171128156]
	TIME [epoch: 9.55 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8228425602791075		[learning rate: 0.0010697]
	Learning Rate: 0.0010697
	LOSS [training: 0.8228425602791075 | validation: 1.105531187796218]
	TIME [epoch: 9.54 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8027060690845167		[learning rate: 0.0010658]
	Learning Rate: 0.00106582
	LOSS [training: 0.8027060690845167 | validation: 1.0509675236580018]
	TIME [epoch: 9.52 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7861592224542993		[learning rate: 0.001062]
	Learning Rate: 0.00106195
	LOSS [training: 0.7861592224542993 | validation: 1.1716815644440801]
	TIME [epoch: 9.53 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8466580582971138		[learning rate: 0.0010581]
	Learning Rate: 0.0010581
	LOSS [training: 0.8466580582971138 | validation: 1.0443169045450642]
	TIME [epoch: 9.56 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7574386504691567		[learning rate: 0.0010543]
	Learning Rate: 0.00105426
	LOSS [training: 0.7574386504691567 | validation: 1.041355080209709]
	TIME [epoch: 9.52 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8416945078935534		[learning rate: 0.0010504]
	Learning Rate: 0.00105043
	LOSS [training: 0.8416945078935534 | validation: 1.2544046082654456]
	TIME [epoch: 9.53 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.820203421227462		[learning rate: 0.0010466]
	Learning Rate: 0.00104662
	LOSS [training: 0.820203421227462 | validation: 1.1214358542690903]
	TIME [epoch: 9.53 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7732033374667173		[learning rate: 0.0010428]
	Learning Rate: 0.00104282
	LOSS [training: 0.7732033374667173 | validation: 1.0624198533579585]
	TIME [epoch: 9.55 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7876712004076992		[learning rate: 0.001039]
	Learning Rate: 0.00103904
	LOSS [training: 0.7876712004076992 | validation: 1.0671217860014524]
	TIME [epoch: 9.56 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8002751300141894		[learning rate: 0.0010353]
	Learning Rate: 0.00103527
	LOSS [training: 0.8002751300141894 | validation: 1.0465607687940681]
	TIME [epoch: 9.53 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8126144482843604		[learning rate: 0.0010315]
	Learning Rate: 0.00103151
	LOSS [training: 0.8126144482843604 | validation: 1.0294034249079511]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_725.pth
	Model improved!!!
EPOCH 726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8085493079077841		[learning rate: 0.0010278]
	Learning Rate: 0.00102777
	LOSS [training: 0.8085493079077841 | validation: 1.020022720909977]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_726.pth
	Model improved!!!
EPOCH 727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7777341905343731		[learning rate: 0.001024]
	Learning Rate: 0.00102404
	LOSS [training: 0.7777341905343731 | validation: 1.0363192085450614]
	TIME [epoch: 9.52 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7608932964743257		[learning rate: 0.0010203]
	Learning Rate: 0.00102032
	LOSS [training: 0.7608932964743257 | validation: 1.1304287750887516]
	TIME [epoch: 9.52 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7450002386962964		[learning rate: 0.0010166]
	Learning Rate: 0.00101662
	LOSS [training: 0.7450002386962964 | validation: 1.220461153169194]
	TIME [epoch: 9.54 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8944381028287477		[learning rate: 0.0010129]
	Learning Rate: 0.00101293
	LOSS [training: 0.8944381028287477 | validation: 1.0424724187355048]
	TIME [epoch: 9.52 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8306871922192963		[learning rate: 0.0010093]
	Learning Rate: 0.00100925
	LOSS [training: 0.8306871922192963 | validation: 1.0543910070878724]
	TIME [epoch: 9.52 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7558001364026059		[learning rate: 0.0010056]
	Learning Rate: 0.00100559
	LOSS [training: 0.7558001364026059 | validation: 1.0767643805871376]
	TIME [epoch: 9.52 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7583104040068787		[learning rate: 0.0010019]
	Learning Rate: 0.00100194
	LOSS [training: 0.7583104040068787 | validation: 1.0475829596739519]
	TIME [epoch: 9.55 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7845701374628506		[learning rate: 0.0009983]
	Learning Rate: 0.000998305
	LOSS [training: 0.7845701374628506 | validation: 1.150000206468059]
	TIME [epoch: 9.52 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8187962328539635		[learning rate: 0.00099468]
	Learning Rate: 0.000994682
	LOSS [training: 0.8187962328539635 | validation: 1.0796059200490902]
	TIME [epoch: 9.52 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7802233077891886		[learning rate: 0.00099107]
	Learning Rate: 0.000991072
	LOSS [training: 0.7802233077891886 | validation: 1.099808350512959]
	TIME [epoch: 9.52 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8135197823697993		[learning rate: 0.00098748]
	Learning Rate: 0.000987475
	LOSS [training: 0.8135197823697993 | validation: 1.1199551194868473]
	TIME [epoch: 9.53 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7874819021750583		[learning rate: 0.00098389]
	Learning Rate: 0.000983892
	LOSS [training: 0.7874819021750583 | validation: 1.2053086819253924]
	TIME [epoch: 9.52 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7794908453455003		[learning rate: 0.00098032]
	Learning Rate: 0.000980321
	LOSS [training: 0.7794908453455003 | validation: 1.174002988338939]
	TIME [epoch: 9.52 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8164212806087491		[learning rate: 0.00097676]
	Learning Rate: 0.000976764
	LOSS [training: 0.8164212806087491 | validation: 1.136614066598943]
	TIME [epoch: 9.52 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7871298574942662		[learning rate: 0.00097322]
	Learning Rate: 0.000973219
	LOSS [training: 0.7871298574942662 | validation: 1.04476173550299]
	TIME [epoch: 9.53 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7586938051445071		[learning rate: 0.00096969]
	Learning Rate: 0.000969687
	LOSS [training: 0.7586938051445071 | validation: 1.1407814251182573]
	TIME [epoch: 9.52 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8025200252600841		[learning rate: 0.00096617]
	Learning Rate: 0.000966168
	LOSS [training: 0.8025200252600841 | validation: 1.1786786226851949]
	TIME [epoch: 9.52 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7823449386327226		[learning rate: 0.00096266]
	Learning Rate: 0.000962662
	LOSS [training: 0.7823449386327226 | validation: 1.070514561316692]
	TIME [epoch: 9.54 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.826064192216023		[learning rate: 0.00095917]
	Learning Rate: 0.000959168
	LOSS [training: 0.826064192216023 | validation: 1.1802268455072085]
	TIME [epoch: 9.52 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7763361482366348		[learning rate: 0.00095569]
	Learning Rate: 0.000955687
	LOSS [training: 0.7763361482366348 | validation: 1.0991560723543463]
	TIME [epoch: 9.52 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7912744045062864		[learning rate: 0.00095222]
	Learning Rate: 0.000952219
	LOSS [training: 0.7912744045062864 | validation: 1.0695441765794906]
	TIME [epoch: 9.52 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.808548708940247		[learning rate: 0.00094876]
	Learning Rate: 0.000948763
	LOSS [training: 0.808548708940247 | validation: 1.065885835054467]
	TIME [epoch: 9.54 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7610889411166959		[learning rate: 0.00094532]
	Learning Rate: 0.00094532
	LOSS [training: 0.7610889411166959 | validation: 1.023404717447902]
	TIME [epoch: 9.53 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7626101432060778		[learning rate: 0.00094189]
	Learning Rate: 0.000941889
	LOSS [training: 0.7626101432060778 | validation: 1.0372787216233323]
	TIME [epoch: 9.52 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7625118764193793		[learning rate: 0.00093847]
	Learning Rate: 0.000938471
	LOSS [training: 0.7625118764193793 | validation: 1.1183025706110838]
	TIME [epoch: 9.52 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7349964756318392		[learning rate: 0.00093507]
	Learning Rate: 0.000935066
	LOSS [training: 0.7349964756318392 | validation: 1.1294293996873672]
	TIME [epoch: 9.55 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7878347315115567		[learning rate: 0.00093167]
	Learning Rate: 0.000931672
	LOSS [training: 0.7878347315115567 | validation: 1.074924684313962]
	TIME [epoch: 9.52 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8039449676385401		[learning rate: 0.00092829]
	Learning Rate: 0.000928291
	LOSS [training: 0.8039449676385401 | validation: 1.0197067969626852]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_754.pth
	Model improved!!!
EPOCH 755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7501579287525543		[learning rate: 0.00092492]
	Learning Rate: 0.000924922
	LOSS [training: 0.7501579287525543 | validation: 1.0781092523049358]
	TIME [epoch: 9.53 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7687533107831592		[learning rate: 0.00092157]
	Learning Rate: 0.000921566
	LOSS [training: 0.7687533107831592 | validation: 1.0747806995206295]
	TIME [epoch: 9.53 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8210645293032842		[learning rate: 0.00091822]
	Learning Rate: 0.000918221
	LOSS [training: 0.8210645293032842 | validation: 1.059496279179092]
	TIME [epoch: 9.51 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7996319357650409		[learning rate: 0.00091489]
	Learning Rate: 0.000914889
	LOSS [training: 0.7996319357650409 | validation: 1.0389191852047006]
	TIME [epoch: 9.52 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7538450508035404		[learning rate: 0.00091157]
	Learning Rate: 0.000911569
	LOSS [training: 0.7538450508035404 | validation: 1.2537800143541125]
	TIME [epoch: 9.53 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8616490624864698		[learning rate: 0.00090826]
	Learning Rate: 0.000908261
	LOSS [training: 0.8616490624864698 | validation: 1.1077984417385447]
	TIME [epoch: 9.52 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7474718797207077		[learning rate: 0.00090496]
	Learning Rate: 0.000904965
	LOSS [training: 0.7474718797207077 | validation: 1.4097852474758366]
	TIME [epoch: 9.53 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.908181047583185		[learning rate: 0.00090168]
	Learning Rate: 0.00090168
	LOSS [training: 0.908181047583185 | validation: 1.060363565367203]
	TIME [epoch: 9.51 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7460701316894982		[learning rate: 0.00089841]
	Learning Rate: 0.000898408
	LOSS [training: 0.7460701316894982 | validation: 1.0672651892490952]
	TIME [epoch: 9.55 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7740706172440077		[learning rate: 0.00089515]
	Learning Rate: 0.000895148
	LOSS [training: 0.7740706172440077 | validation: 1.0668283325579893]
	TIME [epoch: 9.52 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7917433386621444		[learning rate: 0.0008919]
	Learning Rate: 0.000891899
	LOSS [training: 0.7917433386621444 | validation: 1.0761190823341182]
	TIME [epoch: 9.53 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7727110655237964		[learning rate: 0.00088866]
	Learning Rate: 0.000888663
	LOSS [training: 0.7727110655237964 | validation: 1.017057119494681]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_766.pth
	Model improved!!!
EPOCH 767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7398770822959889		[learning rate: 0.00088544]
	Learning Rate: 0.000885438
	LOSS [training: 0.7398770822959889 | validation: 1.073981357025113]
	TIME [epoch: 9.55 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7734828987658624		[learning rate: 0.00088222]
	Learning Rate: 0.000882224
	LOSS [training: 0.7734828987658624 | validation: 1.1229638178285901]
	TIME [epoch: 9.54 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7578289866252111		[learning rate: 0.00087902]
	Learning Rate: 0.000879022
	LOSS [training: 0.7578289866252111 | validation: 1.0173584181135786]
	TIME [epoch: 9.53 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7493947447297329		[learning rate: 0.00087583]
	Learning Rate: 0.000875833
	LOSS [training: 0.7493947447297329 | validation: 1.0587924765222625]
	TIME [epoch: 9.54 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7845566256913223		[learning rate: 0.00087265]
	Learning Rate: 0.000872654
	LOSS [training: 0.7845566256913223 | validation: 1.0735146164298712]
	TIME [epoch: 9.55 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7504092025266427		[learning rate: 0.00086949]
	Learning Rate: 0.000869487
	LOSS [training: 0.7504092025266427 | validation: 1.1112542346133014]
	TIME [epoch: 9.54 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.74484029429353		[learning rate: 0.00086633]
	Learning Rate: 0.000866332
	LOSS [training: 0.74484029429353 | validation: 1.1199901335053661]
	TIME [epoch: 9.53 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7708223191561451		[learning rate: 0.00086319]
	Learning Rate: 0.000863188
	LOSS [training: 0.7708223191561451 | validation: 1.2219313608843698]
	TIME [epoch: 9.53 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7677786573785139		[learning rate: 0.00086006]
	Learning Rate: 0.000860055
	LOSS [training: 0.7677786573785139 | validation: 1.1726139969507963]
	TIME [epoch: 9.55 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7745136226149942		[learning rate: 0.00085693]
	Learning Rate: 0.000856934
	LOSS [training: 0.7745136226149942 | validation: 1.1295249661972684]
	TIME [epoch: 9.53 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7684485723236433		[learning rate: 0.00085382]
	Learning Rate: 0.000853824
	LOSS [training: 0.7684485723236433 | validation: 1.0538908890892895]
	TIME [epoch: 9.53 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7103341242206728		[learning rate: 0.00085073]
	Learning Rate: 0.000850726
	LOSS [training: 0.7103341242206728 | validation: 1.1040809378513299]
	TIME [epoch: 9.54 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.765299509582757		[learning rate: 0.00084764]
	Learning Rate: 0.000847638
	LOSS [training: 0.765299509582757 | validation: 1.0206178782248234]
	TIME [epoch: 9.52 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7440871604015221		[learning rate: 0.00084456]
	Learning Rate: 0.000844562
	LOSS [training: 0.7440871604015221 | validation: 1.0173432101450788]
	TIME [epoch: 9.52 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7769892311674299		[learning rate: 0.0008415]
	Learning Rate: 0.000841497
	LOSS [training: 0.7769892311674299 | validation: 0.9879024084522839]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_781.pth
	Model improved!!!
EPOCH 782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7654576046996681		[learning rate: 0.00083844]
	Learning Rate: 0.000838443
	LOSS [training: 0.7654576046996681 | validation: 1.0204810735066403]
	TIME [epoch: 9.56 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8234371179648468		[learning rate: 0.0008354]
	Learning Rate: 0.000835401
	LOSS [training: 0.8234371179648468 | validation: 1.039267256656932]
	TIME [epoch: 9.53 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7363726603281735		[learning rate: 0.00083237]
	Learning Rate: 0.000832369
	LOSS [training: 0.7363726603281735 | validation: 1.0211310729191387]
	TIME [epoch: 9.53 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.750775406774186		[learning rate: 0.00082935]
	Learning Rate: 0.000829348
	LOSS [training: 0.750775406774186 | validation: 1.1268464817813577]
	TIME [epoch: 9.53 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.757232443741403		[learning rate: 0.00082634]
	Learning Rate: 0.000826338
	LOSS [training: 0.757232443741403 | validation: 1.0136457536528125]
	TIME [epoch: 9.55 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7229957660894514		[learning rate: 0.00082334]
	Learning Rate: 0.00082334
	LOSS [training: 0.7229957660894514 | validation: 1.048560942980337]
	TIME [epoch: 9.52 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7659425583442616		[learning rate: 0.00082035]
	Learning Rate: 0.000820352
	LOSS [training: 0.7659425583442616 | validation: 1.0587645933652858]
	TIME [epoch: 9.52 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7750682889654227		[learning rate: 0.00081737]
	Learning Rate: 0.000817375
	LOSS [training: 0.7750682889654227 | validation: 0.994094980948792]
	TIME [epoch: 9.53 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7245032974947951		[learning rate: 0.00081441]
	Learning Rate: 0.000814408
	LOSS [training: 0.7245032974947951 | validation: 1.0984242980725114]
	TIME [epoch: 9.54 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7318689542038738		[learning rate: 0.00081145]
	Learning Rate: 0.000811453
	LOSS [training: 0.7318689542038738 | validation: 1.004092938344889]
	TIME [epoch: 9.52 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7691219845799956		[learning rate: 0.00080851]
	Learning Rate: 0.000808508
	LOSS [training: 0.7691219845799956 | validation: 1.029847012551156]
	TIME [epoch: 9.52 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7496036637047518		[learning rate: 0.00080557]
	Learning Rate: 0.000805574
	LOSS [training: 0.7496036637047518 | validation: 1.1498637472374744]
	TIME [epoch: 9.54 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7437154790450737		[learning rate: 0.00080265]
	Learning Rate: 0.00080265
	LOSS [training: 0.7437154790450737 | validation: 1.0125654917127838]
	TIME [epoch: 9.53 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7457609167279591		[learning rate: 0.00079974]
	Learning Rate: 0.000799737
	LOSS [training: 0.7457609167279591 | validation: 1.067136260446979]
	TIME [epoch: 9.52 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7746032544781164		[learning rate: 0.00079684]
	Learning Rate: 0.000796835
	LOSS [training: 0.7746032544781164 | validation: 1.1040693794741636]
	TIME [epoch: 9.52 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7783548287172337		[learning rate: 0.00079394]
	Learning Rate: 0.000793943
	LOSS [training: 0.7783548287172337 | validation: 1.0598669292249159]
	TIME [epoch: 9.54 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7232412130602964		[learning rate: 0.00079106]
	Learning Rate: 0.000791062
	LOSS [training: 0.7232412130602964 | validation: 0.9786177830934674]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_798.pth
	Model improved!!!
EPOCH 799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7612818536215784		[learning rate: 0.00078819]
	Learning Rate: 0.000788191
	LOSS [training: 0.7612818536215784 | validation: 1.0259798315718345]
	TIME [epoch: 9.52 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7433491152254478		[learning rate: 0.00078533]
	Learning Rate: 0.000785331
	LOSS [training: 0.7433491152254478 | validation: 1.0031829836126247]
	TIME [epoch: 9.52 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7556451498765377		[learning rate: 0.00078248]
	Learning Rate: 0.000782481
	LOSS [training: 0.7556451498765377 | validation: 1.0294255939508443]
	TIME [epoch: 9.54 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7815847199907124		[learning rate: 0.00077964]
	Learning Rate: 0.000779641
	LOSS [training: 0.7815847199907124 | validation: 1.0015410994352008]
	TIME [epoch: 9.51 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7447838120821488		[learning rate: 0.00077681]
	Learning Rate: 0.000776812
	LOSS [training: 0.7447838120821488 | validation: 1.0449618125564424]
	TIME [epoch: 9.52 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7379459995855766		[learning rate: 0.00077399]
	Learning Rate: 0.000773993
	LOSS [training: 0.7379459995855766 | validation: 0.9768489105951786]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_804.pth
	Model improved!!!
EPOCH 805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7174626573885925		[learning rate: 0.00077118]
	Learning Rate: 0.000771184
	LOSS [training: 0.7174626573885925 | validation: 1.0739954654142532]
	TIME [epoch: 9.55 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7416177258489668		[learning rate: 0.00076839]
	Learning Rate: 0.000768385
	LOSS [training: 0.7416177258489668 | validation: 1.0394821939196224]
	TIME [epoch: 9.54 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7699643173002307		[learning rate: 0.0007656]
	Learning Rate: 0.000765597
	LOSS [training: 0.7699643173002307 | validation: 1.0122100821181244]
	TIME [epoch: 9.52 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7402890191436436		[learning rate: 0.00076282]
	Learning Rate: 0.000762818
	LOSS [training: 0.7402890191436436 | validation: 1.0043798212549524]
	TIME [epoch: 9.53 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7753557473980615		[learning rate: 0.00076005]
	Learning Rate: 0.00076005
	LOSS [training: 0.7753557473980615 | validation: 1.1800441486045246]
	TIME [epoch: 9.54 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.733764443934979		[learning rate: 0.00075729]
	Learning Rate: 0.000757292
	LOSS [training: 0.733764443934979 | validation: 1.0267851717906644]
	TIME [epoch: 9.52 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7100193264142431		[learning rate: 0.00075454]
	Learning Rate: 0.000754543
	LOSS [training: 0.7100193264142431 | validation: 1.0242358334981956]
	TIME [epoch: 9.52 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7154448986972017		[learning rate: 0.00075181]
	Learning Rate: 0.000751805
	LOSS [training: 0.7154448986972017 | validation: 1.040806424812084]
	TIME [epoch: 9.54 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7707009057538615		[learning rate: 0.00074908]
	Learning Rate: 0.000749077
	LOSS [training: 0.7707009057538615 | validation: 1.0459582234790548]
	TIME [epoch: 9.52 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7407428897383593		[learning rate: 0.00074636]
	Learning Rate: 0.000746358
	LOSS [training: 0.7407428897383593 | validation: 1.0025904594493797]
	TIME [epoch: 9.52 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.843116964031213		[learning rate: 0.00074365]
	Learning Rate: 0.00074365
	LOSS [training: 0.843116964031213 | validation: 1.0980194222397233]
	TIME [epoch: 9.52 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7767693648814826		[learning rate: 0.00074095]
	Learning Rate: 0.000740951
	LOSS [training: 0.7767693648814826 | validation: 0.9887992757061824]
	TIME [epoch: 9.54 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7232424236202251		[learning rate: 0.00073826]
	Learning Rate: 0.000738262
	LOSS [training: 0.7232424236202251 | validation: 1.313847923232077]
	TIME [epoch: 9.52 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8263133663158138		[learning rate: 0.00073558]
	Learning Rate: 0.000735583
	LOSS [training: 0.8263133663158138 | validation: 1.1905386580168051]
	TIME [epoch: 9.52 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7496451218564577		[learning rate: 0.00073291]
	Learning Rate: 0.000732913
	LOSS [training: 0.7496451218564577 | validation: 1.0414684963273306]
	TIME [epoch: 9.52 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7670546373351178		[learning rate: 0.00073025]
	Learning Rate: 0.000730254
	LOSS [training: 0.7670546373351178 | validation: 1.0584982747082976]
	TIME [epoch: 9.54 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.735786530958493		[learning rate: 0.0007276]
	Learning Rate: 0.000727603
	LOSS [training: 0.735786530958493 | validation: 0.9930241511767917]
	TIME [epoch: 9.52 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7740112334688332		[learning rate: 0.00072496]
	Learning Rate: 0.000724963
	LOSS [training: 0.7740112334688332 | validation: 1.0620215668169208]
	TIME [epoch: 9.52 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7554876477349817		[learning rate: 0.00072233]
	Learning Rate: 0.000722332
	LOSS [training: 0.7554876477349817 | validation: 1.0072075966199427]
	TIME [epoch: 9.53 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7163404477510439		[learning rate: 0.00071971]
	Learning Rate: 0.000719711
	LOSS [training: 0.7163404477510439 | validation: 1.0630656311986695]
	TIME [epoch: 9.54 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7516437161927348		[learning rate: 0.0007171]
	Learning Rate: 0.000717099
	LOSS [training: 0.7516437161927348 | validation: 1.0202137994411309]
	TIME [epoch: 9.52 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7386948577347637		[learning rate: 0.0007145]
	Learning Rate: 0.000714496
	LOSS [training: 0.7386948577347637 | validation: 0.9713387372504186]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_826.pth
	Model improved!!!
EPOCH 827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7292411471960137		[learning rate: 0.0007119]
	Learning Rate: 0.000711903
	LOSS [training: 0.7292411471960137 | validation: 1.0414605996325543]
	TIME [epoch: 9.54 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7129229650855786		[learning rate: 0.00070932]
	Learning Rate: 0.00070932
	LOSS [training: 0.7129229650855786 | validation: 1.0197387518724024]
	TIME [epoch: 9.53 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7241122254499418		[learning rate: 0.00070675]
	Learning Rate: 0.000706746
	LOSS [training: 0.7241122254499418 | validation: 1.0379168356689308]
	TIME [epoch: 9.52 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7228268615335944		[learning rate: 0.00070418]
	Learning Rate: 0.000704181
	LOSS [training: 0.7228268615335944 | validation: 1.0271989018989462]
	TIME [epoch: 9.52 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7476747030932185		[learning rate: 0.00070163]
	Learning Rate: 0.000701625
	LOSS [training: 0.7476747030932185 | validation: 1.1107071118333665]
	TIME [epoch: 9.55 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7433174155910243		[learning rate: 0.00069908]
	Learning Rate: 0.000699079
	LOSS [training: 0.7433174155910243 | validation: 1.0092362727530253]
	TIME [epoch: 9.53 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7302538673052623		[learning rate: 0.00069654]
	Learning Rate: 0.000696542
	LOSS [training: 0.7302538673052623 | validation: 1.0107004855801724]
	TIME [epoch: 9.53 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.73516786282257		[learning rate: 0.00069401]
	Learning Rate: 0.000694014
	LOSS [training: 0.73516786282257 | validation: 1.000805214878505]
	TIME [epoch: 9.52 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.749602186167351		[learning rate: 0.0006915]
	Learning Rate: 0.000691496
	LOSS [training: 0.749602186167351 | validation: 1.0354242108805585]
	TIME [epoch: 9.54 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7367328799586192		[learning rate: 0.00068899]
	Learning Rate: 0.000688986
	LOSS [training: 0.7367328799586192 | validation: 0.9761972691857826]
	TIME [epoch: 9.53 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6972122299269625		[learning rate: 0.00068649]
	Learning Rate: 0.000686486
	LOSS [training: 0.6972122299269625 | validation: 1.0118805330269456]
	TIME [epoch: 9.52 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7816750777386801		[learning rate: 0.00068399]
	Learning Rate: 0.000683994
	LOSS [training: 0.7816750777386801 | validation: 1.0308383612724383]
	TIME [epoch: 9.52 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.736433879990679		[learning rate: 0.00068151]
	Learning Rate: 0.000681512
	LOSS [training: 0.736433879990679 | validation: 1.0779940782253215]
	TIME [epoch: 9.55 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7537599273872331		[learning rate: 0.00067904]
	Learning Rate: 0.000679039
	LOSS [training: 0.7537599273872331 | validation: 1.0039980555057755]
	TIME [epoch: 9.52 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.720291577001633		[learning rate: 0.00067657]
	Learning Rate: 0.000676575
	LOSS [training: 0.720291577001633 | validation: 0.9889231755590032]
	TIME [epoch: 9.51 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7045914135018737		[learning rate: 0.00067412]
	Learning Rate: 0.00067412
	LOSS [training: 0.7045914135018737 | validation: 1.0113614628603185]
	TIME [epoch: 9.53 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7445507082832767		[learning rate: 0.00067167]
	Learning Rate: 0.000671673
	LOSS [training: 0.7445507082832767 | validation: 1.1599072900747696]
	TIME [epoch: 9.54 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7395935528340936		[learning rate: 0.00066924]
	Learning Rate: 0.000669235
	LOSS [training: 0.7395935528340936 | validation: 1.1855605150064734]
	TIME [epoch: 9.51 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7732681851641652		[learning rate: 0.00066681]
	Learning Rate: 0.000666807
	LOSS [training: 0.7732681851641652 | validation: 1.0123144856462607]
	TIME [epoch: 9.52 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7042768578973836		[learning rate: 0.00066439]
	Learning Rate: 0.000664387
	LOSS [training: 0.7042768578973836 | validation: 0.9806133173174243]
	TIME [epoch: 9.54 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6931097772905671		[learning rate: 0.00066198]
	Learning Rate: 0.000661976
	LOSS [training: 0.6931097772905671 | validation: 0.9981960653822397]
	TIME [epoch: 9.53 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7242777105576408		[learning rate: 0.00065957]
	Learning Rate: 0.000659573
	LOSS [training: 0.7242777105576408 | validation: 0.981283205210078]
	TIME [epoch: 9.52 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.708683041034145		[learning rate: 0.00065718]
	Learning Rate: 0.00065718
	LOSS [training: 0.708683041034145 | validation: 1.0024935595329405]
	TIME [epoch: 9.52 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7166767152332941		[learning rate: 0.00065479]
	Learning Rate: 0.000654795
	LOSS [training: 0.7166767152332941 | validation: 1.0643914113301498]
	TIME [epoch: 9.53 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7479963316594638		[learning rate: 0.00065242]
	Learning Rate: 0.000652419
	LOSS [training: 0.7479963316594638 | validation: 1.010210490182794]
	TIME [epoch: 9.52 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7285443382369718		[learning rate: 0.00065005]
	Learning Rate: 0.000650051
	LOSS [training: 0.7285443382369718 | validation: 0.9992773071868201]
	TIME [epoch: 9.52 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7172147531655165		[learning rate: 0.00064769]
	Learning Rate: 0.000647692
	LOSS [training: 0.7172147531655165 | validation: 0.9627969883269646]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_853.pth
	Model improved!!!
EPOCH 854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7261177436940252		[learning rate: 0.00064534]
	Learning Rate: 0.000645341
	LOSS [training: 0.7261177436940252 | validation: 1.0272729179041074]
	TIME [epoch: 9.54 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7179013079525746		[learning rate: 0.000643]
	Learning Rate: 0.000642999
	LOSS [training: 0.7179013079525746 | validation: 1.0355831067284382]
	TIME [epoch: 9.52 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7096201011246939		[learning rate: 0.00064067]
	Learning Rate: 0.000640666
	LOSS [training: 0.7096201011246939 | validation: 1.036777341906463]
	TIME [epoch: 9.52 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7106853459115594		[learning rate: 0.00063834]
	Learning Rate: 0.000638341
	LOSS [training: 0.7106853459115594 | validation: 1.01578179256986]
	TIME [epoch: 9.52 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7616822881921086		[learning rate: 0.00063602]
	Learning Rate: 0.000636024
	LOSS [training: 0.7616822881921086 | validation: 0.9673131095529476]
	TIME [epoch: 9.54 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7183276459746877		[learning rate: 0.00063372]
	Learning Rate: 0.000633716
	LOSS [training: 0.7183276459746877 | validation: 1.0547022128890047]
	TIME [epoch: 9.52 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7215705352407438		[learning rate: 0.00063142]
	Learning Rate: 0.000631416
	LOSS [training: 0.7215705352407438 | validation: 0.9769267933597547]
	TIME [epoch: 9.52 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.712843545552327		[learning rate: 0.00062912]
	Learning Rate: 0.000629125
	LOSS [training: 0.712843545552327 | validation: 1.0215472159610972]
	TIME [epoch: 9.53 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.724641736469577		[learning rate: 0.00062684]
	Learning Rate: 0.000626842
	LOSS [training: 0.724641736469577 | validation: 1.0131040062558987]
	TIME [epoch: 9.53 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7274527284288749		[learning rate: 0.00062457]
	Learning Rate: 0.000624567
	LOSS [training: 0.7274527284288749 | validation: 0.9824339823729946]
	TIME [epoch: 9.52 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7325210797568693		[learning rate: 0.0006223]
	Learning Rate: 0.0006223
	LOSS [training: 0.7325210797568693 | validation: 1.0413647540899196]
	TIME [epoch: 9.52 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7121049756818947		[learning rate: 0.00062004]
	Learning Rate: 0.000620042
	LOSS [training: 0.7121049756818947 | validation: 1.0514652268660138]
	TIME [epoch: 9.53 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7286750567292556		[learning rate: 0.00061779]
	Learning Rate: 0.000617792
	LOSS [training: 0.7286750567292556 | validation: 1.0492777740332246]
	TIME [epoch: 9.52 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7376481185348821		[learning rate: 0.00061555]
	Learning Rate: 0.00061555
	LOSS [training: 0.7376481185348821 | validation: 1.0274944028761255]
	TIME [epoch: 9.52 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7216476160086385		[learning rate: 0.00061332]
	Learning Rate: 0.000613316
	LOSS [training: 0.7216476160086385 | validation: 1.0401114563390688]
	TIME [epoch: 9.52 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7293823261983222		[learning rate: 0.00061109]
	Learning Rate: 0.00061109
	LOSS [training: 0.7293823261983222 | validation: 1.0164700650563134]
	TIME [epoch: 9.54 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6984012733072349		[learning rate: 0.00060887]
	Learning Rate: 0.000608872
	LOSS [training: 0.6984012733072349 | validation: 0.9803228790731733]
	TIME [epoch: 9.51 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7361841064993588		[learning rate: 0.00060666]
	Learning Rate: 0.000606663
	LOSS [training: 0.7361841064993588 | validation: 1.0454136800621259]
	TIME [epoch: 9.51 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7286704083246024		[learning rate: 0.00060446]
	Learning Rate: 0.000604461
	LOSS [training: 0.7286704083246024 | validation: 0.9848563309115304]
	TIME [epoch: 9.52 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7373141679356255		[learning rate: 0.00060227]
	Learning Rate: 0.000602268
	LOSS [training: 0.7373141679356255 | validation: 0.9908111159493257]
	TIME [epoch: 9.53 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6906418506647894		[learning rate: 0.00060008]
	Learning Rate: 0.000600082
	LOSS [training: 0.6906418506647894 | validation: 0.9661247562394439]
	TIME [epoch: 9.52 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6997968456745196		[learning rate: 0.0005979]
	Learning Rate: 0.000597904
	LOSS [training: 0.6997968456745196 | validation: 0.9713106000763216]
	TIME [epoch: 9.51 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7441067014494901		[learning rate: 0.00059573]
	Learning Rate: 0.000595734
	LOSS [training: 0.7441067014494901 | validation: 0.9827813681166748]
	TIME [epoch: 9.52 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.715586249678841		[learning rate: 0.00059357]
	Learning Rate: 0.000593572
	LOSS [training: 0.715586249678841 | validation: 1.0255238849758057]
	TIME [epoch: 9.53 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7291402454559014		[learning rate: 0.00059142]
	Learning Rate: 0.000591418
	LOSS [training: 0.7291402454559014 | validation: 1.0527275451739169]
	TIME [epoch: 9.52 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7132622830311518		[learning rate: 0.00058927]
	Learning Rate: 0.000589272
	LOSS [training: 0.7132622830311518 | validation: 1.0356801079478835]
	TIME [epoch: 9.51 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7281734391217191		[learning rate: 0.00058713]
	Learning Rate: 0.000587133
	LOSS [training: 0.7281734391217191 | validation: 1.1558366274379952]
	TIME [epoch: 9.54 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7269872623573223		[learning rate: 0.000585]
	Learning Rate: 0.000585003
	LOSS [training: 0.7269872623573223 | validation: 0.9772448794198216]
	TIME [epoch: 9.52 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7101233332528059		[learning rate: 0.00058288]
	Learning Rate: 0.00058288
	LOSS [training: 0.7101233332528059 | validation: 0.9973183072618096]
	TIME [epoch: 9.51 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7205894037660391		[learning rate: 0.00058076]
	Learning Rate: 0.000580764
	LOSS [training: 0.7205894037660391 | validation: 0.9819498447577902]
	TIME [epoch: 9.51 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.699861731552901		[learning rate: 0.00057866]
	Learning Rate: 0.000578657
	LOSS [training: 0.699861731552901 | validation: 1.0683807290880072]
	TIME [epoch: 9.54 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7370687881436775		[learning rate: 0.00057656]
	Learning Rate: 0.000576557
	LOSS [training: 0.7370687881436775 | validation: 1.0239365505732239]
	TIME [epoch: 9.53 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7371018811432786		[learning rate: 0.00057446]
	Learning Rate: 0.000574465
	LOSS [training: 0.7371018811432786 | validation: 1.0274398740475312]
	TIME [epoch: 9.51 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7355188119222154		[learning rate: 0.00057238]
	Learning Rate: 0.00057238
	LOSS [training: 0.7355188119222154 | validation: 1.0018599468953309]
	TIME [epoch: 9.52 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6987971467618131		[learning rate: 0.0005703]
	Learning Rate: 0.000570303
	LOSS [training: 0.6987971467618131 | validation: 1.1116189574456206]
	TIME [epoch: 9.55 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7381938448670496		[learning rate: 0.00056823]
	Learning Rate: 0.000568233
	LOSS [training: 0.7381938448670496 | validation: 1.0016217682174782]
	TIME [epoch: 9.52 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6848978774814719		[learning rate: 0.00056617]
	Learning Rate: 0.000566171
	LOSS [training: 0.6848978774814719 | validation: 1.013244151593887]
	TIME [epoch: 9.53 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7156984156025803		[learning rate: 0.00056412]
	Learning Rate: 0.000564116
	LOSS [training: 0.7156984156025803 | validation: 0.9714179367324194]
	TIME [epoch: 9.51 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6997387625152558		[learning rate: 0.00056207]
	Learning Rate: 0.000562069
	LOSS [training: 0.6997387625152558 | validation: 0.9657977433535655]
	TIME [epoch: 9.55 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6946197636445411		[learning rate: 0.00056003]
	Learning Rate: 0.000560029
	LOSS [training: 0.6946197636445411 | validation: 1.050451188323751]
	TIME [epoch: 9.52 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7530419375758431		[learning rate: 0.000558]
	Learning Rate: 0.000557997
	LOSS [training: 0.7530419375758431 | validation: 0.961548804031168]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_894.pth
	Model improved!!!
EPOCH 895/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.697409075908077		[learning rate: 0.00055597]
	Learning Rate: 0.000555972
	LOSS [training: 0.697409075908077 | validation: 1.056318403543797]
	TIME [epoch: 9.52 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7061991551236076		[learning rate: 0.00055395]
	Learning Rate: 0.000553954
	LOSS [training: 0.7061991551236076 | validation: 0.9711709887485133]
	TIME [epoch: 9.53 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7151924416545665		[learning rate: 0.00055194]
	Learning Rate: 0.000551944
	LOSS [training: 0.7151924416545665 | validation: 0.9580875043798972]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_897.pth
	Model improved!!!
EPOCH 898/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7139353623843707		[learning rate: 0.00054994]
	Learning Rate: 0.000549941
	LOSS [training: 0.7139353623843707 | validation: 0.9954627334362656]
	TIME [epoch: 9.51 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.701726797022721		[learning rate: 0.00054794]
	Learning Rate: 0.000547945
	LOSS [training: 0.701726797022721 | validation: 1.005508593109149]
	TIME [epoch: 9.53 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7369694316086817		[learning rate: 0.00054596]
	Learning Rate: 0.000545956
	LOSS [training: 0.7369694316086817 | validation: 1.0429646265796155]
	TIME [epoch: 9.53 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7293405919675864		[learning rate: 0.00054397]
	Learning Rate: 0.000543975
	LOSS [training: 0.7293405919675864 | validation: 0.9835489373324131]
	TIME [epoch: 9.52 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7037523778186519		[learning rate: 0.000542]
	Learning Rate: 0.000542001
	LOSS [training: 0.7037523778186519 | validation: 0.9759986643517953]
	TIME [epoch: 9.52 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6926236014452807		[learning rate: 0.00054003]
	Learning Rate: 0.000540034
	LOSS [training: 0.6926236014452807 | validation: 0.9816413094550663]
	TIME [epoch: 9.54 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7153344383190839		[learning rate: 0.00053807]
	Learning Rate: 0.000538074
	LOSS [training: 0.7153344383190839 | validation: 1.0032055937780207]
	TIME [epoch: 9.52 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7075260757099604		[learning rate: 0.00053612]
	Learning Rate: 0.000536121
	LOSS [training: 0.7075260757099604 | validation: 1.0114732178829013]
	TIME [epoch: 9.52 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.727185664997935		[learning rate: 0.00053418]
	Learning Rate: 0.000534176
	LOSS [training: 0.727185664997935 | validation: 0.9715692709984728]
	TIME [epoch: 9.51 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7126660487817814		[learning rate: 0.00053224]
	Learning Rate: 0.000532237
	LOSS [training: 0.7126660487817814 | validation: 1.0553058333029695]
	TIME [epoch: 9.54 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.712121862512565		[learning rate: 0.00053031]
	Learning Rate: 0.000530306
	LOSS [training: 0.712121862512565 | validation: 1.058027525182452]
	TIME [epoch: 9.52 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7314391665041862		[learning rate: 0.00052838]
	Learning Rate: 0.000528381
	LOSS [training: 0.7314391665041862 | validation: 0.9756311040462614]
	TIME [epoch: 9.52 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6915230073740214		[learning rate: 0.00052646]
	Learning Rate: 0.000526464
	LOSS [training: 0.6915230073740214 | validation: 1.075582777079436]
	TIME [epoch: 9.52 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7222928101370047		[learning rate: 0.00052455]
	Learning Rate: 0.000524553
	LOSS [training: 0.7222928101370047 | validation: 0.9553867523758808]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_911.pth
	Model improved!!!
EPOCH 912/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7124270228563713		[learning rate: 0.00052265]
	Learning Rate: 0.000522649
	LOSS [training: 0.7124270228563713 | validation: 0.9779133961664238]
	TIME [epoch: 9.51 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6983796360215647		[learning rate: 0.00052075]
	Learning Rate: 0.000520753
	LOSS [training: 0.6983796360215647 | validation: 0.9774377075884634]
	TIME [epoch: 9.52 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7157915725180921		[learning rate: 0.00051886]
	Learning Rate: 0.000518863
	LOSS [training: 0.7157915725180921 | validation: 1.004676103264908]
	TIME [epoch: 9.54 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7302358765856127		[learning rate: 0.00051698]
	Learning Rate: 0.00051698
	LOSS [training: 0.7302358765856127 | validation: 0.9914618838216585]
	TIME [epoch: 9.53 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6989409515722363		[learning rate: 0.0005151]
	Learning Rate: 0.000515104
	LOSS [training: 0.6989409515722363 | validation: 0.9422610015768317]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_916.pth
	Model improved!!!
EPOCH 917/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7034000983912186		[learning rate: 0.00051323]
	Learning Rate: 0.000513235
	LOSS [training: 0.7034000983912186 | validation: 1.0212643427798773]
	TIME [epoch: 9.52 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7277355762636326		[learning rate: 0.00051137]
	Learning Rate: 0.000511372
	LOSS [training: 0.7277355762636326 | validation: 0.9608197935937878]
	TIME [epoch: 9.54 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6903943941011959		[learning rate: 0.00050952]
	Learning Rate: 0.000509516
	LOSS [training: 0.6903943941011959 | validation: 0.960773480790555]
	TIME [epoch: 9.52 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6908236834699778		[learning rate: 0.00050767]
	Learning Rate: 0.000507667
	LOSS [training: 0.6908236834699778 | validation: 1.048455124273044]
	TIME [epoch: 9.53 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7212290343685522		[learning rate: 0.00050582]
	Learning Rate: 0.000505825
	LOSS [training: 0.7212290343685522 | validation: 1.005494277134273]
	TIME [epoch: 9.53 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7025033445609882		[learning rate: 0.00050399]
	Learning Rate: 0.000503989
	LOSS [training: 0.7025033445609882 | validation: 0.9538014552376578]
	TIME [epoch: 9.55 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6752644747729245		[learning rate: 0.00050216]
	Learning Rate: 0.00050216
	LOSS [training: 0.6752644747729245 | validation: 1.0002484352213117]
	TIME [epoch: 9.52 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7070455505847926		[learning rate: 0.00050034]
	Learning Rate: 0.000500338
	LOSS [training: 0.7070455505847926 | validation: 0.9849816958160316]
	TIME [epoch: 9.53 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7218907649542974		[learning rate: 0.00049852]
	Learning Rate: 0.000498522
	LOSS [training: 0.7218907649542974 | validation: 0.9876904222053645]
	TIME [epoch: 9.52 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6982260155977003		[learning rate: 0.00049671]
	Learning Rate: 0.000496713
	LOSS [training: 0.6982260155977003 | validation: 0.9352414167178745]
	TIME [epoch: 9.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_926.pth
	Model improved!!!
EPOCH 927/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7256714531330519		[learning rate: 0.00049491]
	Learning Rate: 0.00049491
	LOSS [training: 0.7256714531330519 | validation: 0.9923962256986133]
	TIME [epoch: 9.52 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.697266304895306		[learning rate: 0.00049311]
	Learning Rate: 0.000493114
	LOSS [training: 0.697266304895306 | validation: 0.961262405435029]
	TIME [epoch: 9.51 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7066189716557034		[learning rate: 0.00049132]
	Learning Rate: 0.000491325
	LOSS [training: 0.7066189716557034 | validation: 1.005973328962218]
	TIME [epoch: 9.53 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6883419420325139		[learning rate: 0.00048954]
	Learning Rate: 0.000489542
	LOSS [training: 0.6883419420325139 | validation: 0.9614643125068346]
	TIME [epoch: 9.52 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6978946015285514		[learning rate: 0.00048776]
	Learning Rate: 0.000487765
	LOSS [training: 0.6978946015285514 | validation: 0.9551997795932053]
	TIME [epoch: 9.52 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6874965870539113		[learning rate: 0.00048599]
	Learning Rate: 0.000485995
	LOSS [training: 0.6874965870539113 | validation: 0.9612836628742841]
	TIME [epoch: 9.52 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7004808323909186		[learning rate: 0.00048423]
	Learning Rate: 0.000484231
	LOSS [training: 0.7004808323909186 | validation: 1.039851550163733]
	TIME [epoch: 9.54 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6988560149666629		[learning rate: 0.00048247]
	Learning Rate: 0.000482474
	LOSS [training: 0.6988560149666629 | validation: 1.0290159256509708]
	TIME [epoch: 9.52 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7240742622025255		[learning rate: 0.00048072]
	Learning Rate: 0.000480723
	LOSS [training: 0.7240742622025255 | validation: 0.9553229104698051]
	TIME [epoch: 9.52 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6912847827010571		[learning rate: 0.00047898]
	Learning Rate: 0.000478978
	LOSS [training: 0.6912847827010571 | validation: 1.0059788336049744]
	TIME [epoch: 9.53 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7025006846202857		[learning rate: 0.00047724]
	Learning Rate: 0.00047724
	LOSS [training: 0.7025006846202857 | validation: 0.9712336229365031]
	TIME [epoch: 9.54 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7045485945968954		[learning rate: 0.00047551]
	Learning Rate: 0.000475508
	LOSS [training: 0.7045485945968954 | validation: 0.9949451589346942]
	TIME [epoch: 9.52 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6977558603815496		[learning rate: 0.00047378]
	Learning Rate: 0.000473782
	LOSS [training: 0.6977558603815496 | validation: 0.9501184219915032]
	TIME [epoch: 9.53 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6947376550608904		[learning rate: 0.00047206]
	Learning Rate: 0.000472063
	LOSS [training: 0.6947376550608904 | validation: 0.9833725957544406]
	TIME [epoch: 9.51 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6888681809905436		[learning rate: 0.00047035]
	Learning Rate: 0.00047035
	LOSS [training: 0.6888681809905436 | validation: 0.9931742241576075]
	TIME [epoch: 9.55 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7116675595467553		[learning rate: 0.00046864]
	Learning Rate: 0.000468643
	LOSS [training: 0.7116675595467553 | validation: 1.0055095515560382]
	TIME [epoch: 9.51 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6811785602501506		[learning rate: 0.00046694]
	Learning Rate: 0.000466942
	LOSS [training: 0.6811785602501506 | validation: 0.9766468330234589]
	TIME [epoch: 9.52 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6976912731118615		[learning rate: 0.00046525]
	Learning Rate: 0.000465248
	LOSS [training: 0.6976912731118615 | validation: 0.9698207597447086]
	TIME [epoch: 9.52 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6784623713504645		[learning rate: 0.00046356]
	Learning Rate: 0.000463559
	LOSS [training: 0.6784623713504645 | validation: 0.9432079458687713]
	TIME [epoch: 9.54 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7063876682265222		[learning rate: 0.00046188]
	Learning Rate: 0.000461877
	LOSS [training: 0.7063876682265222 | validation: 0.9416530116274621]
	TIME [epoch: 9.52 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6989997882276092		[learning rate: 0.0004602]
	Learning Rate: 0.000460201
	LOSS [training: 0.6989997882276092 | validation: 0.9794718875443549]
	TIME [epoch: 9.52 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6914528119814849		[learning rate: 0.00045853]
	Learning Rate: 0.000458531
	LOSS [training: 0.6914528119814849 | validation: 0.9396759632322664]
	TIME [epoch: 9.53 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7039659879268607		[learning rate: 0.00045687]
	Learning Rate: 0.000456867
	LOSS [training: 0.7039659879268607 | validation: 0.9879530561697465]
	TIME [epoch: 9.53 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7035233431671503		[learning rate: 0.00045521]
	Learning Rate: 0.000455209
	LOSS [training: 0.7035233431671503 | validation: 1.0760462019217263]
	TIME [epoch: 9.52 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7172357949514392		[learning rate: 0.00045356]
	Learning Rate: 0.000453557
	LOSS [training: 0.7172357949514392 | validation: 0.9500451909826021]
	TIME [epoch: 9.52 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6724482952723088		[learning rate: 0.00045191]
	Learning Rate: 0.000451911
	LOSS [training: 0.6724482952723088 | validation: 0.971792683639766]
	TIME [epoch: 9.54 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6772317307102403		[learning rate: 0.00045027]
	Learning Rate: 0.000450271
	LOSS [training: 0.6772317307102403 | validation: 0.9866469290826554]
	TIME [epoch: 9.52 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7021487114039937		[learning rate: 0.00044864]
	Learning Rate: 0.000448637
	LOSS [training: 0.7021487114039937 | validation: 0.9454668716919102]
	TIME [epoch: 9.52 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7116397679673062		[learning rate: 0.00044701]
	Learning Rate: 0.000447009
	LOSS [training: 0.7116397679673062 | validation: 0.9533974071595519]
	TIME [epoch: 9.52 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.681943905610046		[learning rate: 0.00044539]
	Learning Rate: 0.000445386
	LOSS [training: 0.681943905610046 | validation: 0.9491221631606035]
	TIME [epoch: 9.54 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6837806735226606		[learning rate: 0.00044377]
	Learning Rate: 0.00044377
	LOSS [training: 0.6837806735226606 | validation: 0.9970570594245817]
	TIME [epoch: 9.52 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7196953067060884		[learning rate: 0.00044216]
	Learning Rate: 0.00044216
	LOSS [training: 0.7196953067060884 | validation: 0.9742220054479168]
	TIME [epoch: 9.52 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6903756028467335		[learning rate: 0.00044055]
	Learning Rate: 0.000440555
	LOSS [training: 0.6903756028467335 | validation: 1.0000754593366814]
	TIME [epoch: 9.52 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7062675391744389		[learning rate: 0.00043896]
	Learning Rate: 0.000438956
	LOSS [training: 0.7062675391744389 | validation: 0.9987878906903549]
	TIME [epoch: 9.54 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7006035853671992		[learning rate: 0.00043736]
	Learning Rate: 0.000437363
	LOSS [training: 0.7006035853671992 | validation: 0.9557394211405084]
	TIME [epoch: 9.53 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6857813932951781		[learning rate: 0.00043578]
	Learning Rate: 0.000435776
	LOSS [training: 0.6857813932951781 | validation: 0.9505238573540254]
	TIME [epoch: 9.52 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.678368980908018		[learning rate: 0.00043419]
	Learning Rate: 0.000434194
	LOSS [training: 0.678368980908018 | validation: 0.9788031368641246]
	TIME [epoch: 9.53 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6960205039894476		[learning rate: 0.00043262]
	Learning Rate: 0.000432619
	LOSS [training: 0.6960205039894476 | validation: 0.9510151760838444]
	TIME [epoch: 9.53 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6708957813658741		[learning rate: 0.00043105]
	Learning Rate: 0.000431049
	LOSS [training: 0.6708957813658741 | validation: 0.9886992680912106]
	TIME [epoch: 9.52 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7147625101323118		[learning rate: 0.00042948]
	Learning Rate: 0.000429484
	LOSS [training: 0.7147625101323118 | validation: 0.9739042912351891]
	TIME [epoch: 9.52 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.697803559668142		[learning rate: 0.00042793]
	Learning Rate: 0.000427926
	LOSS [training: 0.697803559668142 | validation: 1.0046162008531119]
	TIME [epoch: 9.55 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6970742691303882		[learning rate: 0.00042637]
	Learning Rate: 0.000426373
	LOSS [training: 0.6970742691303882 | validation: 0.965032957824619]
	TIME [epoch: 9.53 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6960274856654116		[learning rate: 0.00042483]
	Learning Rate: 0.000424825
	LOSS [training: 0.6960274856654116 | validation: 0.9882650145444436]
	TIME [epoch: 9.53 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6829190634522806		[learning rate: 0.00042328]
	Learning Rate: 0.000423284
	LOSS [training: 0.6829190634522806 | validation: 0.9281632456703421]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_970.pth
	Model improved!!!
EPOCH 971/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7079195052561522		[learning rate: 0.00042175]
	Learning Rate: 0.000421748
	LOSS [training: 0.7079195052561522 | validation: 1.01565969912093]
	TIME [epoch: 9.54 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6972480791811169		[learning rate: 0.00042022]
	Learning Rate: 0.000420217
	LOSS [training: 0.6972480791811169 | validation: 0.9737369220945863]
	TIME [epoch: 9.52 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6931838880651602		[learning rate: 0.00041869]
	Learning Rate: 0.000418692
	LOSS [training: 0.6931838880651602 | validation: 0.9804199751832353]
	TIME [epoch: 9.52 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6874628978628587		[learning rate: 0.00041717]
	Learning Rate: 0.000417173
	LOSS [training: 0.6874628978628587 | validation: 1.0251854043007274]
	TIME [epoch: 9.51 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6867440196924777		[learning rate: 0.00041566]
	Learning Rate: 0.000415659
	LOSS [training: 0.6867440196924777 | validation: 0.9734110968365847]
	TIME [epoch: 9.55 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6815170791942011		[learning rate: 0.00041415]
	Learning Rate: 0.00041415
	LOSS [training: 0.6815170791942011 | validation: 0.9602563082868387]
	TIME [epoch: 9.51 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6811318409642184		[learning rate: 0.00041265]
	Learning Rate: 0.000412647
	LOSS [training: 0.6811318409642184 | validation: 0.9707350329781281]
	TIME [epoch: 9.52 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7270563485492262		[learning rate: 0.00041115]
	Learning Rate: 0.00041115
	LOSS [training: 0.7270563485492262 | validation: 0.9997925641121423]
	TIME [epoch: 9.52 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7199734089155847		[learning rate: 0.00040966]
	Learning Rate: 0.000409658
	LOSS [training: 0.7199734089155847 | validation: 0.9385081140123306]
	TIME [epoch: 9.53 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6930090944862082		[learning rate: 0.00040817]
	Learning Rate: 0.000408171
	LOSS [training: 0.6930090944862082 | validation: 0.9822636959961861]
	TIME [epoch: 9.52 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.698222446798506		[learning rate: 0.00040669]
	Learning Rate: 0.00040669
	LOSS [training: 0.698222446798506 | validation: 0.9883262941344007]
	TIME [epoch: 9.51 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6959616826149343		[learning rate: 0.00040521]
	Learning Rate: 0.000405214
	LOSS [training: 0.6959616826149343 | validation: 0.993440263979076]
	TIME [epoch: 9.54 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6973640556962766		[learning rate: 0.00040374]
	Learning Rate: 0.000403743
	LOSS [training: 0.6973640556962766 | validation: 1.0156357675470749]
	TIME [epoch: 9.53 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7149432824617105		[learning rate: 0.00040228]
	Learning Rate: 0.000402278
	LOSS [training: 0.7149432824617105 | validation: 0.9682698339485114]
	TIME [epoch: 9.52 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7008881051374722		[learning rate: 0.00040082]
	Learning Rate: 0.000400818
	LOSS [training: 0.7008881051374722 | validation: 1.0066104086589198]
	TIME [epoch: 9.52 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6916190775041811		[learning rate: 0.00039936]
	Learning Rate: 0.000399364
	LOSS [training: 0.6916190775041811 | validation: 0.9579350742145561]
	TIME [epoch: 9.53 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6895244007452844		[learning rate: 0.00039791]
	Learning Rate: 0.000397914
	LOSS [training: 0.6895244007452844 | validation: 0.9502100279389819]
	TIME [epoch: 9.53 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6797738545878236		[learning rate: 0.00039647]
	Learning Rate: 0.00039647
	LOSS [training: 0.6797738545878236 | validation: 0.938945062093498]
	TIME [epoch: 9.52 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.700621070107142		[learning rate: 0.00039503]
	Learning Rate: 0.000395031
	LOSS [training: 0.700621070107142 | validation: 1.0571500306416137]
	TIME [epoch: 9.52 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7041383540847944		[learning rate: 0.0003936]
	Learning Rate: 0.000393598
	LOSS [training: 0.7041383540847944 | validation: 0.9540577773925049]
	TIME [epoch: 9.54 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.688488429842444		[learning rate: 0.00039217]
	Learning Rate: 0.000392169
	LOSS [training: 0.688488429842444 | validation: 0.9690530236134215]
	TIME [epoch: 9.53 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6713979488815338		[learning rate: 0.00039075]
	Learning Rate: 0.000390746
	LOSS [training: 0.6713979488815338 | validation: 0.9149457012309692]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_992.pth
	Model improved!!!
EPOCH 993/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.690152541197169		[learning rate: 0.00038933]
	Learning Rate: 0.000389328
	LOSS [training: 0.690152541197169 | validation: 0.9787885560140214]
	TIME [epoch: 9.52 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6930131756243834		[learning rate: 0.00038792]
	Learning Rate: 0.000387915
	LOSS [training: 0.6930131756243834 | validation: 0.9529646548018649]
	TIME [epoch: 9.54 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6849921455974768		[learning rate: 0.00038651]
	Learning Rate: 0.000386508
	LOSS [training: 0.6849921455974768 | validation: 0.9511155664702602]
	TIME [epoch: 9.53 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6934912974494203		[learning rate: 0.0003851]
	Learning Rate: 0.000385105
	LOSS [training: 0.6934912974494203 | validation: 0.9940775659404061]
	TIME [epoch: 9.52 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6869611400523887		[learning rate: 0.00038371]
	Learning Rate: 0.000383707
	LOSS [training: 0.6869611400523887 | validation: 0.979362523985568]
	TIME [epoch: 9.54 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6897456384629034		[learning rate: 0.00038231]
	Learning Rate: 0.000382315
	LOSS [training: 0.6897456384629034 | validation: 0.9520872681557474]
	TIME [epoch: 9.54 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6738378836671025		[learning rate: 0.00038093]
	Learning Rate: 0.000380927
	LOSS [training: 0.6738378836671025 | validation: 0.9645523217271682]
	TIME [epoch: 9.52 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6827917378874441		[learning rate: 0.00037954]
	Learning Rate: 0.000379545
	LOSS [training: 0.6827917378874441 | validation: 1.0094680153111373]
	TIME [epoch: 9.52 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6939929824573903		[learning rate: 0.00037817]
	Learning Rate: 0.000378167
	LOSS [training: 0.6939929824573903 | validation: 0.9570157723125473]
	TIME [epoch: 9.55 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6743653884515869		[learning rate: 0.0003768]
	Learning Rate: 0.000376795
	LOSS [training: 0.6743653884515869 | validation: 0.9588097119118345]
	TIME [epoch: 9.53 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6851832622504166		[learning rate: 0.00037543]
	Learning Rate: 0.000375428
	LOSS [training: 0.6851832622504166 | validation: 1.0428044464315773]
	TIME [epoch: 9.52 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.723507663861059		[learning rate: 0.00037407]
	Learning Rate: 0.000374065
	LOSS [training: 0.723507663861059 | validation: 0.988812270200432]
	TIME [epoch: 9.52 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7098220857666211		[learning rate: 0.00037271]
	Learning Rate: 0.000372708
	LOSS [training: 0.7098220857666211 | validation: 0.9690502280017669]
	TIME [epoch: 9.54 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6795877709766727		[learning rate: 0.00037136]
	Learning Rate: 0.000371355
	LOSS [training: 0.6795877709766727 | validation: 0.9888478150055093]
	TIME [epoch: 9.52 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7042831796420221		[learning rate: 0.00037001]
	Learning Rate: 0.000370008
	LOSS [training: 0.7042831796420221 | validation: 0.9494819323425084]
	TIME [epoch: 9.52 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6762411895714646		[learning rate: 0.00036866]
	Learning Rate: 0.000368665
	LOSS [training: 0.6762411895714646 | validation: 0.9648053732952733]
	TIME [epoch: 9.52 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.675082053181647		[learning rate: 0.00036733]
	Learning Rate: 0.000367327
	LOSS [training: 0.675082053181647 | validation: 1.0127383244622365]
	TIME [epoch: 9.54 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.674136053591107		[learning rate: 0.00036599]
	Learning Rate: 0.000365994
	LOSS [training: 0.674136053591107 | validation: 0.9394239298735079]
	TIME [epoch: 9.52 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6841047744254215		[learning rate: 0.00036467]
	Learning Rate: 0.000364666
	LOSS [training: 0.6841047744254215 | validation: 0.9757547161844332]
	TIME [epoch: 9.52 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6732559976081041		[learning rate: 0.00036334]
	Learning Rate: 0.000363342
	LOSS [training: 0.6732559976081041 | validation: 0.966446775376127]
	TIME [epoch: 9.52 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6829190620851515		[learning rate: 0.00036202]
	Learning Rate: 0.000362024
	LOSS [training: 0.6829190620851515 | validation: 0.9553387491858919]
	TIME [epoch: 9.54 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6768204902639221		[learning rate: 0.00036071]
	Learning Rate: 0.00036071
	LOSS [training: 0.6768204902639221 | validation: 0.9671233779614954]
	TIME [epoch: 9.53 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6793930512229438		[learning rate: 0.0003594]
	Learning Rate: 0.000359401
	LOSS [training: 0.6793930512229438 | validation: 0.9324557581662414]
	TIME [epoch: 9.52 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6775705615134477		[learning rate: 0.0003581]
	Learning Rate: 0.000358096
	LOSS [training: 0.6775705615134477 | validation: 0.9721305523952719]
	TIME [epoch: 9.54 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.683099044604342		[learning rate: 0.0003568]
	Learning Rate: 0.000356797
	LOSS [training: 0.683099044604342 | validation: 1.0385546324703934]
	TIME [epoch: 9.53 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.70057430154216		[learning rate: 0.0003555]
	Learning Rate: 0.000355502
	LOSS [training: 0.70057430154216 | validation: 0.949781241826415]
	TIME [epoch: 9.52 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6740988815110387		[learning rate: 0.00035421]
	Learning Rate: 0.000354212
	LOSS [training: 0.6740988815110387 | validation: 0.9297818125501819]
	TIME [epoch: 9.52 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6908283583747818		[learning rate: 0.00035293]
	Learning Rate: 0.000352926
	LOSS [training: 0.6908283583747818 | validation: 1.0977206712691951]
	TIME [epoch: 9.54 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7017575818323681		[learning rate: 0.00035165]
	Learning Rate: 0.000351646
	LOSS [training: 0.7017575818323681 | validation: 0.948768243957787]
	TIME [epoch: 9.53 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6645831168719878		[learning rate: 0.00035037]
	Learning Rate: 0.00035037
	LOSS [training: 0.6645831168719878 | validation: 0.9479860144621072]
	TIME [epoch: 9.52 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7021581066917928		[learning rate: 0.0003491]
	Learning Rate: 0.000349098
	LOSS [training: 0.7021581066917928 | validation: 1.006787068330685]
	TIME [epoch: 9.51 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6869015993816858		[learning rate: 0.00034783]
	Learning Rate: 0.000347831
	LOSS [training: 0.6869015993816858 | validation: 0.956397151981065]
	TIME [epoch: 9.55 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6884789634664148		[learning rate: 0.00034657]
	Learning Rate: 0.000346569
	LOSS [training: 0.6884789634664148 | validation: 0.9630805255175582]
	TIME [epoch: 9.53 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.678185884722932		[learning rate: 0.00034531]
	Learning Rate: 0.000345311
	LOSS [training: 0.678185884722932 | validation: 0.9311565257604066]
	TIME [epoch: 9.52 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.704544323674144		[learning rate: 0.00034406]
	Learning Rate: 0.000344058
	LOSS [training: 0.704544323674144 | validation: 1.0312274539371595]
	TIME [epoch: 9.53 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.690372050477488		[learning rate: 0.00034281]
	Learning Rate: 0.000342809
	LOSS [training: 0.690372050477488 | validation: 0.9505757064079454]
	TIME [epoch: 9.55 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6753902617715646		[learning rate: 0.00034157]
	Learning Rate: 0.000341565
	LOSS [training: 0.6753902617715646 | validation: 1.0028063753220366]
	TIME [epoch: 9.52 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6825639777137801		[learning rate: 0.00034033]
	Learning Rate: 0.000340326
	LOSS [training: 0.6825639777137801 | validation: 0.9662569842556363]
	TIME [epoch: 9.53 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6805606718767946		[learning rate: 0.00033909]
	Learning Rate: 0.000339091
	LOSS [training: 0.6805606718767946 | validation: 0.9722344508480508]
	TIME [epoch: 9.53 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6869275808279307		[learning rate: 0.00033786]
	Learning Rate: 0.00033786
	LOSS [training: 0.6869275808279307 | validation: 1.0282618742990972]
	TIME [epoch: 9.53 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.683788141285003		[learning rate: 0.00033663]
	Learning Rate: 0.000336634
	LOSS [training: 0.683788141285003 | validation: 0.9429824031860132]
	TIME [epoch: 9.53 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6825744719173844		[learning rate: 0.00033541]
	Learning Rate: 0.000335412
	LOSS [training: 0.6825744719173844 | validation: 0.9461133541719869]
	TIME [epoch: 9.52 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6670946802542881		[learning rate: 0.0003342]
	Learning Rate: 0.000334195
	LOSS [training: 0.6670946802542881 | validation: 0.9532682950823943]
	TIME [epoch: 9.54 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6890962705790434		[learning rate: 0.00033298]
	Learning Rate: 0.000332982
	LOSS [training: 0.6890962705790434 | validation: 0.9313184948032456]
	TIME [epoch: 9.52 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6731198124720827		[learning rate: 0.00033177]
	Learning Rate: 0.000331774
	LOSS [training: 0.6731198124720827 | validation: 0.9713696000518323]
	TIME [epoch: 9.52 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.681185347289397		[learning rate: 0.00033057]
	Learning Rate: 0.00033057
	LOSS [training: 0.681185347289397 | validation: 0.9498957909909738]
	TIME [epoch: 9.53 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6896089140827751		[learning rate: 0.00032937]
	Learning Rate: 0.00032937
	LOSS [training: 0.6896089140827751 | validation: 0.9642096323776593]
	TIME [epoch: 9.53 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6702112355778589		[learning rate: 0.00032817]
	Learning Rate: 0.000328175
	LOSS [training: 0.6702112355778589 | validation: 0.9557606770739858]
	TIME [epoch: 9.52 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.67184280499459		[learning rate: 0.00032698]
	Learning Rate: 0.000326984
	LOSS [training: 0.67184280499459 | validation: 0.9499879633888522]
	TIME [epoch: 9.52 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6754605989769397		[learning rate: 0.0003258]
	Learning Rate: 0.000325797
	LOSS [training: 0.6754605989769397 | validation: 0.9663877867779924]
	TIME [epoch: 9.52 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7024671177958013		[learning rate: 0.00032461]
	Learning Rate: 0.000324615
	LOSS [training: 0.7024671177958013 | validation: 1.0088809426025187]
	TIME [epoch: 9.55 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7203508898505846		[learning rate: 0.00032344]
	Learning Rate: 0.000323437
	LOSS [training: 0.7203508898505846 | validation: 0.9741958019996635]
	TIME [epoch: 9.53 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6645836065717905		[learning rate: 0.00032226]
	Learning Rate: 0.000322263
	LOSS [training: 0.6645836065717905 | validation: 0.9460338894818481]
	TIME [epoch: 9.52 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6957937584710048		[learning rate: 0.00032109]
	Learning Rate: 0.000321094
	LOSS [training: 0.6957937584710048 | validation: 0.9844751034118403]
	TIME [epoch: 9.52 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6891908075179117		[learning rate: 0.00031993]
	Learning Rate: 0.000319928
	LOSS [training: 0.6891908075179117 | validation: 1.0092762642028699]
	TIME [epoch: 9.54 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6868498170506857		[learning rate: 0.00031877]
	Learning Rate: 0.000318767
	LOSS [training: 0.6868498170506857 | validation: 0.9374789262151488]
	TIME [epoch: 9.52 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6838202962123802		[learning rate: 0.00031761]
	Learning Rate: 0.000317611
	LOSS [training: 0.6838202962123802 | validation: 0.9243467801944166]
	TIME [epoch: 9.52 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6684935547072455		[learning rate: 0.00031646]
	Learning Rate: 0.000316458
	LOSS [training: 0.6684935547072455 | validation: 1.0152284792165112]
	TIME [epoch: 9.53 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6960493562108995		[learning rate: 0.00031531]
	Learning Rate: 0.000315309
	LOSS [training: 0.6960493562108995 | validation: 0.9612231307896746]
	TIME [epoch: 9.54 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6692695436695036		[learning rate: 0.00031417]
	Learning Rate: 0.000314165
	LOSS [training: 0.6692695436695036 | validation: 0.9843334918131666]
	TIME [epoch: 9.52 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6704124448301546		[learning rate: 0.00031302]
	Learning Rate: 0.000313025
	LOSS [training: 0.6704124448301546 | validation: 0.9552028793615116]
	TIME [epoch: 9.52 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.678592134598623		[learning rate: 0.00031189]
	Learning Rate: 0.000311889
	LOSS [training: 0.678592134598623 | validation: 0.9687583240119184]
	TIME [epoch: 9.54 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6926150487936692		[learning rate: 0.00031076]
	Learning Rate: 0.000310757
	LOSS [training: 0.6926150487936692 | validation: 0.9589425163980515]
	TIME [epoch: 9.53 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6651605726484898		[learning rate: 0.00030963]
	Learning Rate: 0.000309629
	LOSS [training: 0.6651605726484898 | validation: 0.9592869247809459]
	TIME [epoch: 9.52 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6910229082150972		[learning rate: 0.00030851]
	Learning Rate: 0.000308506
	LOSS [training: 0.6910229082150972 | validation: 1.0251478338919007]
	TIME [epoch: 9.52 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7007188805941855		[learning rate: 0.00030739]
	Learning Rate: 0.000307386
	LOSS [training: 0.7007188805941855 | validation: 0.9283282551463649]
	TIME [epoch: 9.54 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.670274763996507		[learning rate: 0.00030627]
	Learning Rate: 0.000306271
	LOSS [training: 0.670274763996507 | validation: 0.9342291681278607]
	TIME [epoch: 9.53 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6639866796345294		[learning rate: 0.00030516]
	Learning Rate: 0.000305159
	LOSS [training: 0.6639866796345294 | validation: 0.9792194244032356]
	TIME [epoch: 9.52 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6784407276382748		[learning rate: 0.00030405]
	Learning Rate: 0.000304052
	LOSS [training: 0.6784407276382748 | validation: 0.9777303120327113]
	TIME [epoch: 9.52 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6822651776037814		[learning rate: 0.00030295]
	Learning Rate: 0.000302948
	LOSS [training: 0.6822651776037814 | validation: 0.9533674373664384]
	TIME [epoch: 9.55 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6681659576242316		[learning rate: 0.00030185]
	Learning Rate: 0.000301849
	LOSS [training: 0.6681659576242316 | validation: 0.9465485757119236]
	TIME [epoch: 9.52 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6727505399679068		[learning rate: 0.00030075]
	Learning Rate: 0.000300753
	LOSS [training: 0.6727505399679068 | validation: 0.9857085144261782]
	TIME [epoch: 9.52 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6731636505590618		[learning rate: 0.00029966]
	Learning Rate: 0.000299662
	LOSS [training: 0.6731636505590618 | validation: 0.9395857452948385]
	TIME [epoch: 9.52 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7085731466023599		[learning rate: 0.00029857]
	Learning Rate: 0.000298574
	LOSS [training: 0.7085731466023599 | validation: 0.984170159492672]
	TIME [epoch: 9.55 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6974333734740088		[learning rate: 0.00029749]
	Learning Rate: 0.000297491
	LOSS [training: 0.6974333734740088 | validation: 0.9943210094251851]
	TIME [epoch: 9.52 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6900510400574916		[learning rate: 0.00029641]
	Learning Rate: 0.000296411
	LOSS [training: 0.6900510400574916 | validation: 0.9685243097062406]
	TIME [epoch: 9.52 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6724486370944699		[learning rate: 0.00029534]
	Learning Rate: 0.000295336
	LOSS [training: 0.6724486370944699 | validation: 0.9340622233633257]
	TIME [epoch: 9.53 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6757944384374479		[learning rate: 0.00029426]
	Learning Rate: 0.000294264
	LOSS [training: 0.6757944384374479 | validation: 0.9745878299979601]
	TIME [epoch: 9.54 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6923618691452964		[learning rate: 0.0002932]
	Learning Rate: 0.000293196
	LOSS [training: 0.6923618691452964 | validation: 0.9355144673546836]
	TIME [epoch: 9.53 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6661465945706653		[learning rate: 0.00029213]
	Learning Rate: 0.000292132
	LOSS [training: 0.6661465945706653 | validation: 0.9724146824193244]
	TIME [epoch: 9.52 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6858334731485461		[learning rate: 0.00029107]
	Learning Rate: 0.000291072
	LOSS [training: 0.6858334731485461 | validation: 1.0026870836076942]
	TIME [epoch: 9.54 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6810248812611106		[learning rate: 0.00029002]
	Learning Rate: 0.000290015
	LOSS [training: 0.6810248812611106 | validation: 0.9262802830757942]
	TIME [epoch: 9.52 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6758907001784963		[learning rate: 0.00028896]
	Learning Rate: 0.000288963
	LOSS [training: 0.6758907001784963 | validation: 0.9362327617867192]
	TIME [epoch: 9.52 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6727138186673989		[learning rate: 0.00028791]
	Learning Rate: 0.000287914
	LOSS [training: 0.6727138186673989 | validation: 0.9377959806941383]
	TIME [epoch: 9.53 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.677664865729488		[learning rate: 0.00028687]
	Learning Rate: 0.000286869
	LOSS [training: 0.677664865729488 | validation: 0.9239387843739618]
	TIME [epoch: 9.55 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.683897679161614		[learning rate: 0.00028583]
	Learning Rate: 0.000285828
	LOSS [training: 0.683897679161614 | validation: 0.9384203146100805]
	TIME [epoch: 9.54 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6774807318486574		[learning rate: 0.00028479]
	Learning Rate: 0.000284791
	LOSS [training: 0.6774807318486574 | validation: 0.9213017902507693]
	TIME [epoch: 9.54 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6591600475433195		[learning rate: 0.00028376]
	Learning Rate: 0.000283758
	LOSS [training: 0.6591600475433195 | validation: 0.9514445937595444]
	TIME [epoch: 9.53 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6566471688619838		[learning rate: 0.00028273]
	Learning Rate: 0.000282728
	LOSS [training: 0.6566471688619838 | validation: 0.9320697524517493]
	TIME [epoch: 9.55 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6561218307028424		[learning rate: 0.0002817]
	Learning Rate: 0.000281702
	LOSS [training: 0.6561218307028424 | validation: 0.9626269204142126]
	TIME [epoch: 9.53 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6586797449708724		[learning rate: 0.00028068]
	Learning Rate: 0.000280679
	LOSS [training: 0.6586797449708724 | validation: 0.9271293169535156]
	TIME [epoch: 9.53 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6677305620788265		[learning rate: 0.00027966]
	Learning Rate: 0.000279661
	LOSS [training: 0.6677305620788265 | validation: 0.9766179525101256]
	TIME [epoch: 9.53 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.686559435426809		[learning rate: 0.00027865]
	Learning Rate: 0.000278646
	LOSS [training: 0.686559435426809 | validation: 0.962202226486934]
	TIME [epoch: 9.55 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6539434459139984		[learning rate: 0.00027763]
	Learning Rate: 0.000277635
	LOSS [training: 0.6539434459139984 | validation: 0.9207559109002952]
	TIME [epoch: 9.53 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.667426793563286		[learning rate: 0.00027663]
	Learning Rate: 0.000276627
	LOSS [training: 0.667426793563286 | validation: 0.9478923902632412]
	TIME [epoch: 9.52 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6665520757945045		[learning rate: 0.00027562]
	Learning Rate: 0.000275623
	LOSS [training: 0.6665520757945045 | validation: 0.920933792332232]
	TIME [epoch: 9.54 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6646400648419467		[learning rate: 0.00027462]
	Learning Rate: 0.000274623
	LOSS [training: 0.6646400648419467 | validation: 0.9181860667206161]
	TIME [epoch: 9.54 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6767975284196378		[learning rate: 0.00027363]
	Learning Rate: 0.000273626
	LOSS [training: 0.6767975284196378 | validation: 0.9352924210010249]
	TIME [epoch: 9.53 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6591211990381894		[learning rate: 0.00027263]
	Learning Rate: 0.000272633
	LOSS [training: 0.6591211990381894 | validation: 0.9231858351633437]
	TIME [epoch: 9.53 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6633287084065224		[learning rate: 0.00027164]
	Learning Rate: 0.000271644
	LOSS [training: 0.6633287084065224 | validation: 0.941442857857591]
	TIME [epoch: 9.54 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6654064338259938		[learning rate: 0.00027066]
	Learning Rate: 0.000270658
	LOSS [training: 0.6654064338259938 | validation: 0.9487350082167945]
	TIME [epoch: 9.53 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6755496490577204		[learning rate: 0.00026968]
	Learning Rate: 0.000269676
	LOSS [training: 0.6755496490577204 | validation: 0.9391939656029423]
	TIME [epoch: 9.52 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6640464030353577		[learning rate: 0.0002687]
	Learning Rate: 0.000268697
	LOSS [training: 0.6640464030353577 | validation: 0.9286003107738802]
	TIME [epoch: 9.53 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6780333827403489		[learning rate: 0.00026772]
	Learning Rate: 0.000267722
	LOSS [training: 0.6780333827403489 | validation: 0.9397984461778001]
	TIME [epoch: 9.55 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6696616276804052		[learning rate: 0.00026675]
	Learning Rate: 0.000266751
	LOSS [training: 0.6696616276804052 | validation: 0.9351293957381631]
	TIME [epoch: 9.53 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6777495944974122		[learning rate: 0.00026578]
	Learning Rate: 0.000265782
	LOSS [training: 0.6777495944974122 | validation: 0.9335919359164992]
	TIME [epoch: 9.52 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6931851277719174		[learning rate: 0.00026482]
	Learning Rate: 0.000264818
	LOSS [training: 0.6931851277719174 | validation: 0.9599375855053723]
	TIME [epoch: 9.52 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.681748490605325		[learning rate: 0.00026386]
	Learning Rate: 0.000263857
	LOSS [training: 0.681748490605325 | validation: 0.9529592831120993]
	TIME [epoch: 9.55 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6584453372544372		[learning rate: 0.0002629]
	Learning Rate: 0.000262899
	LOSS [training: 0.6584453372544372 | validation: 0.98010926954975]
	TIME [epoch: 9.52 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6720773849026654		[learning rate: 0.00026195]
	Learning Rate: 0.000261945
	LOSS [training: 0.6720773849026654 | validation: 0.9142074909790648]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_1102.pth
	Model improved!!!
EPOCH 1103/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6593481472995684		[learning rate: 0.00026099]
	Learning Rate: 0.000260995
	LOSS [training: 0.6593481472995684 | validation: 0.9556299512817559]
	TIME [epoch: 9.53 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6808190533217487		[learning rate: 0.00026005]
	Learning Rate: 0.000260047
	LOSS [training: 0.6808190533217487 | validation: 0.9506159494679096]
	TIME [epoch: 9.54 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6624852278131982		[learning rate: 0.0002591]
	Learning Rate: 0.000259104
	LOSS [training: 0.6624852278131982 | validation: 0.9235210187542374]
	TIME [epoch: 9.52 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6929753399642753		[learning rate: 0.00025816]
	Learning Rate: 0.000258163
	LOSS [training: 0.6929753399642753 | validation: 0.9739004069691893]
	TIME [epoch: 9.53 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.667850786506317		[learning rate: 0.00025723]
	Learning Rate: 0.000257227
	LOSS [training: 0.667850786506317 | validation: 0.9667115461282798]
	TIME [epoch: 9.53 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6545287694679478		[learning rate: 0.00025629]
	Learning Rate: 0.000256293
	LOSS [training: 0.6545287694679478 | validation: 0.913932482101072]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_1108.pth
	Model improved!!!
EPOCH 1109/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6648242370521997		[learning rate: 0.00025536]
	Learning Rate: 0.000255363
	LOSS [training: 0.6648242370521997 | validation: 0.9110418214342261]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_1109.pth
	Model improved!!!
EPOCH 1110/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6585222512303888		[learning rate: 0.00025444]
	Learning Rate: 0.000254436
	LOSS [training: 0.6585222512303888 | validation: 0.9342844188099488]
	TIME [epoch: 9.53 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6914021083121241		[learning rate: 0.00025351]
	Learning Rate: 0.000253513
	LOSS [training: 0.6914021083121241 | validation: 0.9349389596983368]
	TIME [epoch: 9.54 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.659025010889237		[learning rate: 0.00025259]
	Learning Rate: 0.000252593
	LOSS [training: 0.659025010889237 | validation: 0.9193145176209429]
	TIME [epoch: 9.51 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6625208672285883		[learning rate: 0.00025168]
	Learning Rate: 0.000251676
	LOSS [training: 0.6625208672285883 | validation: 0.9425004380052724]
	TIME [epoch: 9.52 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6582919529102572		[learning rate: 0.00025076]
	Learning Rate: 0.000250763
	LOSS [training: 0.6582919529102572 | validation: 0.9485339877085127]
	TIME [epoch: 9.51 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6697030130029666		[learning rate: 0.00024985]
	Learning Rate: 0.000249853
	LOSS [training: 0.6697030130029666 | validation: 0.9738250180748648]
	TIME [epoch: 9.54 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6722724174602719		[learning rate: 0.00024895]
	Learning Rate: 0.000248946
	LOSS [training: 0.6722724174602719 | validation: 0.9243584620704123]
	TIME [epoch: 9.52 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6614258193285629		[learning rate: 0.00024804]
	Learning Rate: 0.000248043
	LOSS [training: 0.6614258193285629 | validation: 0.9505114788827074]
	TIME [epoch: 9.52 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6574508999153502		[learning rate: 0.00024714]
	Learning Rate: 0.000247142
	LOSS [training: 0.6574508999153502 | validation: 0.9233751472709065]
	TIME [epoch: 9.52 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6658885572716386		[learning rate: 0.00024625]
	Learning Rate: 0.000246246
	LOSS [training: 0.6658885572716386 | validation: 0.9265475873274156]
	TIME [epoch: 9.54 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.686465153495963		[learning rate: 0.00024535]
	Learning Rate: 0.000245352
	LOSS [training: 0.686465153495963 | validation: 0.939270152203155]
	TIME [epoch: 9.53 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6701194869286993		[learning rate: 0.00024446]
	Learning Rate: 0.000244462
	LOSS [training: 0.6701194869286993 | validation: 0.9319726043573978]
	TIME [epoch: 9.52 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6668430621250454		[learning rate: 0.00024357]
	Learning Rate: 0.000243574
	LOSS [training: 0.6668430621250454 | validation: 0.9034710194356645]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_1122.pth
	Model improved!!!
EPOCH 1123/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.65776505227535		[learning rate: 0.00024269]
	Learning Rate: 0.00024269
	LOSS [training: 0.65776505227535 | validation: 0.9213572755044456]
	TIME [epoch: 9.54 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6633632813573171		[learning rate: 0.00024181]
	Learning Rate: 0.00024181
	LOSS [training: 0.6633632813573171 | validation: 0.9526808723894824]
	TIME [epoch: 9.52 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6645487939622431		[learning rate: 0.00024093]
	Learning Rate: 0.000240932
	LOSS [training: 0.6645487939622431 | validation: 0.9588555686675487]
	TIME [epoch: 9.52 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6664135892919877		[learning rate: 0.00024006]
	Learning Rate: 0.000240058
	LOSS [training: 0.6664135892919877 | validation: 0.9356988685565482]
	TIME [epoch: 9.54 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6520104376413443		[learning rate: 0.00023919]
	Learning Rate: 0.000239187
	LOSS [training: 0.6520104376413443 | validation: 0.9236403980708079]
	TIME [epoch: 9.53 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6592869579718018		[learning rate: 0.00023832]
	Learning Rate: 0.000238319
	LOSS [training: 0.6592869579718018 | validation: 0.9280436484918589]
	TIME [epoch: 9.52 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6637363346116174		[learning rate: 0.00023745]
	Learning Rate: 0.000237454
	LOSS [training: 0.6637363346116174 | validation: 0.9409713436109977]
	TIME [epoch: 9.53 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6675276998757314		[learning rate: 0.00023659]
	Learning Rate: 0.000236592
	LOSS [training: 0.6675276998757314 | validation: 0.9371886066889564]
	TIME [epoch: 9.54 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6678444237654542		[learning rate: 0.00023573]
	Learning Rate: 0.000235733
	LOSS [training: 0.6678444237654542 | validation: 0.9354042603186795]
	TIME [epoch: 9.52 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6458770527688557		[learning rate: 0.00023488]
	Learning Rate: 0.000234878
	LOSS [training: 0.6458770527688557 | validation: 0.9367577703673692]
	TIME [epoch: 9.51 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6675096210276366		[learning rate: 0.00023403]
	Learning Rate: 0.000234026
	LOSS [training: 0.6675096210276366 | validation: 0.9283289150717547]
	TIME [epoch: 9.53 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6654162411583676		[learning rate: 0.00023318]
	Learning Rate: 0.000233176
	LOSS [training: 0.6654162411583676 | validation: 0.9313319344956921]
	TIME [epoch: 9.53 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.67932294590135		[learning rate: 0.00023233]
	Learning Rate: 0.00023233
	LOSS [training: 0.67932294590135 | validation: 0.9704436367837707]
	TIME [epoch: 9.53 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6952541420702852		[learning rate: 0.00023149]
	Learning Rate: 0.000231487
	LOSS [training: 0.6952541420702852 | validation: 0.9337046397870842]
	TIME [epoch: 9.52 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6681703432985225		[learning rate: 0.00023065]
	Learning Rate: 0.000230647
	LOSS [training: 0.6681703432985225 | validation: 0.9306204834917301]
	TIME [epoch: 9.54 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6702772492488376		[learning rate: 0.00022981]
	Learning Rate: 0.00022981
	LOSS [training: 0.6702772492488376 | validation: 0.9332146807277133]
	TIME [epoch: 9.52 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6521927401575617		[learning rate: 0.00022898]
	Learning Rate: 0.000228976
	LOSS [training: 0.6521927401575617 | validation: 0.9137450694402739]
	TIME [epoch: 9.53 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6729833188390363		[learning rate: 0.00022814]
	Learning Rate: 0.000228145
	LOSS [training: 0.6729833188390363 | validation: 0.9133690732221513]
	TIME [epoch: 9.52 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6511531378560167		[learning rate: 0.00022732]
	Learning Rate: 0.000227317
	LOSS [training: 0.6511531378560167 | validation: 0.937877684282551]
	TIME [epoch: 9.53 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6581361279269199		[learning rate: 0.00022649]
	Learning Rate: 0.000226492
	LOSS [training: 0.6581361279269199 | validation: 0.9716578975340929]
	TIME [epoch: 9.53 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6560802632774719		[learning rate: 0.00022567]
	Learning Rate: 0.00022567
	LOSS [training: 0.6560802632774719 | validation: 0.9415441364829151]
	TIME [epoch: 9.52 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6576261046454718		[learning rate: 0.00022485]
	Learning Rate: 0.000224851
	LOSS [training: 0.6576261046454718 | validation: 0.9543675061590183]
	TIME [epoch: 9.52 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6690011907036878		[learning rate: 0.00022403]
	Learning Rate: 0.000224035
	LOSS [training: 0.6690011907036878 | validation: 0.9202449019394832]
	TIME [epoch: 9.54 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6516494025241983		[learning rate: 0.00022322]
	Learning Rate: 0.000223222
	LOSS [training: 0.6516494025241983 | validation: 0.9048378416936614]
	TIME [epoch: 9.52 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.664562913359019		[learning rate: 0.00022241]
	Learning Rate: 0.000222412
	LOSS [training: 0.664562913359019 | validation: 0.9236669284921517]
	TIME [epoch: 9.52 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6667483332020405		[learning rate: 0.0002216]
	Learning Rate: 0.000221605
	LOSS [training: 0.6667483332020405 | validation: 0.9269866781259591]
	TIME [epoch: 9.51 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6826118448295594		[learning rate: 0.0002208]
	Learning Rate: 0.0002208
	LOSS [training: 0.6826118448295594 | validation: 0.9620939463638855]
	TIME [epoch: 9.54 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6712596598655002		[learning rate: 0.00022]
	Learning Rate: 0.000219999
	LOSS [training: 0.6712596598655002 | validation: 0.9368534022418494]
	TIME [epoch: 9.52 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6503005236767987		[learning rate: 0.0002192]
	Learning Rate: 0.000219201
	LOSS [training: 0.6503005236767987 | validation: 0.9254666805595757]
	TIME [epoch: 9.52 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6691550157999334		[learning rate: 0.00021841]
	Learning Rate: 0.000218405
	LOSS [training: 0.6691550157999334 | validation: 0.9104461863637998]
	TIME [epoch: 9.53 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6739690190771819		[learning rate: 0.00021761]
	Learning Rate: 0.000217613
	LOSS [training: 0.6739690190771819 | validation: 0.9342434047301095]
	TIME [epoch: 9.54 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6554366385696175		[learning rate: 0.00021682]
	Learning Rate: 0.000216823
	LOSS [training: 0.6554366385696175 | validation: 0.944670890171208]
	TIME [epoch: 9.51 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6897971974822874		[learning rate: 0.00021604]
	Learning Rate: 0.000216036
	LOSS [training: 0.6897971974822874 | validation: 0.9737692281337941]
	TIME [epoch: 9.53 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6777197837518943		[learning rate: 0.00021525]
	Learning Rate: 0.000215252
	LOSS [training: 0.6777197837518943 | validation: 0.9371985067602552]
	TIME [epoch: 9.52 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6623169485381811		[learning rate: 0.00021447]
	Learning Rate: 0.000214471
	LOSS [training: 0.6623169485381811 | validation: 0.9415839232878053]
	TIME [epoch: 9.52 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.667821873686283		[learning rate: 0.00021369]
	Learning Rate: 0.000213693
	LOSS [training: 0.667821873686283 | validation: 0.955245741898435]
	TIME [epoch: 9.51 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6751836084430274		[learning rate: 0.00021292]
	Learning Rate: 0.000212917
	LOSS [training: 0.6751836084430274 | validation: 0.9468398136947213]
	TIME [epoch: 9.52 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6712778877031907		[learning rate: 0.00021214]
	Learning Rate: 0.000212144
	LOSS [training: 0.6712778877031907 | validation: 0.9920670058121919]
	TIME [epoch: 9.54 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6618555930783637		[learning rate: 0.00021137]
	Learning Rate: 0.000211375
	LOSS [training: 0.6618555930783637 | validation: 0.9064175293370198]
	TIME [epoch: 9.52 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6481022670394575		[learning rate: 0.00021061]
	Learning Rate: 0.000210607
	LOSS [training: 0.6481022670394575 | validation: 0.9209724091768967]
	TIME [epoch: 9.53 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6529986578336772		[learning rate: 0.00020984]
	Learning Rate: 0.000209843
	LOSS [training: 0.6529986578336772 | validation: 0.9456080748461958]
	TIME [epoch: 9.52 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6758645283038669		[learning rate: 0.00020908]
	Learning Rate: 0.000209082
	LOSS [training: 0.6758645283038669 | validation: 0.9334141810490728]
	TIME [epoch: 9.54 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6525239390829143		[learning rate: 0.00020832]
	Learning Rate: 0.000208323
	LOSS [training: 0.6525239390829143 | validation: 0.9345931412877195]
	TIME [epoch: 9.51 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6700176354230253		[learning rate: 0.00020757]
	Learning Rate: 0.000207567
	LOSS [training: 0.6700176354230253 | validation: 0.9081486482941447]
	TIME [epoch: 9.52 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6705962437535202		[learning rate: 0.00020681]
	Learning Rate: 0.000206814
	LOSS [training: 0.6705962437535202 | validation: 0.9425829214540792]
	TIME [epoch: 9.51 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6554950313843968		[learning rate: 0.00020606]
	Learning Rate: 0.000206063
	LOSS [training: 0.6554950313843968 | validation: 0.9356513775404324]
	TIME [epoch: 9.54 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6635871137146079		[learning rate: 0.00020532]
	Learning Rate: 0.000205315
	LOSS [training: 0.6635871137146079 | validation: 0.9717173869875865]
	TIME [epoch: 9.52 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.677735416415901		[learning rate: 0.00020457]
	Learning Rate: 0.00020457
	LOSS [training: 0.677735416415901 | validation: 0.9377733244899232]
	TIME [epoch: 9.52 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6686294478611507		[learning rate: 0.00020383]
	Learning Rate: 0.000203828
	LOSS [training: 0.6686294478611507 | validation: 0.9217654635474263]
	TIME [epoch: 9.53 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6516368659571075		[learning rate: 0.00020309]
	Learning Rate: 0.000203088
	LOSS [training: 0.6516368659571075 | validation: 0.9310226632721796]
	TIME [epoch: 9.54 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6630575124560465		[learning rate: 0.00020235]
	Learning Rate: 0.000202351
	LOSS [training: 0.6630575124560465 | validation: 0.9352889677491294]
	TIME [epoch: 9.52 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6630963595764253		[learning rate: 0.00020162]
	Learning Rate: 0.000201617
	LOSS [training: 0.6630963595764253 | validation: 0.9535208011542703]
	TIME [epoch: 9.52 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6520241844696957		[learning rate: 0.00020088]
	Learning Rate: 0.000200885
	LOSS [training: 0.6520241844696957 | validation: 0.9572314061002455]
	TIME [epoch: 9.53 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.653296109383682		[learning rate: 0.00020016]
	Learning Rate: 0.000200156
	LOSS [training: 0.653296109383682 | validation: 0.9669386475058415]
	TIME [epoch: 9.52 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6625528301637198		[learning rate: 0.00019943]
	Learning Rate: 0.00019943
	LOSS [training: 0.6625528301637198 | validation: 0.9327121295474061]
	TIME [epoch: 9.51 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6641393653756704		[learning rate: 0.00019871]
	Learning Rate: 0.000198706
	LOSS [training: 0.6641393653756704 | validation: 0.9220458513714077]
	TIME [epoch: 9.53 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6635387690847665		[learning rate: 0.00019798]
	Learning Rate: 0.000197985
	LOSS [training: 0.6635387690847665 | validation: 0.952898225745288]
	TIME [epoch: 9.54 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6479665427121005		[learning rate: 0.00019727]
	Learning Rate: 0.000197266
	LOSS [training: 0.6479665427121005 | validation: 0.9325390903882993]
	TIME [epoch: 9.52 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6488421274252164		[learning rate: 0.00019655]
	Learning Rate: 0.00019655
	LOSS [training: 0.6488421274252164 | validation: 0.9287199336785947]
	TIME [epoch: 9.52 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6480303223449058		[learning rate: 0.00019584]
	Learning Rate: 0.000195837
	LOSS [training: 0.6480303223449058 | validation: 0.9268622214436095]
	TIME [epoch: 9.52 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6504973143258205		[learning rate: 0.00019513]
	Learning Rate: 0.000195126
	LOSS [training: 0.6504973143258205 | validation: 0.9178292469482077]
	TIME [epoch: 9.55 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6580622101271234		[learning rate: 0.00019442]
	Learning Rate: 0.000194418
	LOSS [training: 0.6580622101271234 | validation: 0.9786901757154601]
	TIME [epoch: 9.52 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.670406900633954		[learning rate: 0.00019371]
	Learning Rate: 0.000193713
	LOSS [training: 0.670406900633954 | validation: 0.9085175180993322]
	TIME [epoch: 9.53 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6603851241036729		[learning rate: 0.00019301]
	Learning Rate: 0.00019301
	LOSS [training: 0.6603851241036729 | validation: 0.9323186231687852]
	TIME [epoch: 9.52 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6597877120455131		[learning rate: 0.00019231]
	Learning Rate: 0.000192309
	LOSS [training: 0.6597877120455131 | validation: 0.9500530892629905]
	TIME [epoch: 9.55 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6723030329413622		[learning rate: 0.00019161]
	Learning Rate: 0.000191611
	LOSS [training: 0.6723030329413622 | validation: 0.9280245397431739]
	TIME [epoch: 9.53 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6529318220506399		[learning rate: 0.00019092]
	Learning Rate: 0.000190916
	LOSS [training: 0.6529318220506399 | validation: 0.8991025664976506]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_1189.pth
	Model improved!!!
EPOCH 1190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6544718896982525		[learning rate: 0.00019022]
	Learning Rate: 0.000190223
	LOSS [training: 0.6544718896982525 | validation: 0.9246160713200228]
	TIME [epoch: 9.54 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6468940917779962		[learning rate: 0.00018953]
	Learning Rate: 0.000189533
	LOSS [training: 0.6468940917779962 | validation: 0.9734475858944173]
	TIME [epoch: 9.53 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6573868595275216		[learning rate: 0.00018884]
	Learning Rate: 0.000188845
	LOSS [training: 0.6573868595275216 | validation: 0.9117681333546475]
	TIME [epoch: 9.51 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6497742132013227		[learning rate: 0.00018816]
	Learning Rate: 0.00018816
	LOSS [training: 0.6497742132013227 | validation: 0.9354675147493413]
	TIME [epoch: 9.52 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6681476631972971		[learning rate: 0.00018748]
	Learning Rate: 0.000187477
	LOSS [training: 0.6681476631972971 | validation: 0.931459223084093]
	TIME [epoch: 9.55 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6756807748294493		[learning rate: 0.0001868]
	Learning Rate: 0.000186796
	LOSS [training: 0.6756807748294493 | validation: 0.9382607018883523]
	TIME [epoch: 9.52 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6694149176446176		[learning rate: 0.00018612]
	Learning Rate: 0.000186119
	LOSS [training: 0.6694149176446176 | validation: 0.9268759986928382]
	TIME [epoch: 9.52 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6539703392258712		[learning rate: 0.00018544]
	Learning Rate: 0.000185443
	LOSS [training: 0.6539703392258712 | validation: 0.9300524106567414]
	TIME [epoch: 9.52 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6588833500780884		[learning rate: 0.00018477]
	Learning Rate: 0.00018477
	LOSS [training: 0.6588833500780884 | validation: 0.9407844131421854]
	TIME [epoch: 9.54 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6604584101400207		[learning rate: 0.0001841]
	Learning Rate: 0.000184099
	LOSS [training: 0.6604584101400207 | validation: 0.9067647355959458]
	TIME [epoch: 9.52 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6521294009117236		[learning rate: 0.00018343]
	Learning Rate: 0.000183431
	LOSS [training: 0.6521294009117236 | validation: 0.9487238837984312]
	TIME [epoch: 9.52 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6552139399059707		[learning rate: 0.00018277]
	Learning Rate: 0.000182766
	LOSS [training: 0.6552139399059707 | validation: 0.956890146714077]
	TIME [epoch: 9.52 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6583150567852851		[learning rate: 0.0001821]
	Learning Rate: 0.000182102
	LOSS [training: 0.6583150567852851 | validation: 0.9263275376645375]
	TIME [epoch: 9.55 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6566015058657626		[learning rate: 0.00018144]
	Learning Rate: 0.000181442
	LOSS [training: 0.6566015058657626 | validation: 0.9416555821642706]
	TIME [epoch: 9.53 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6646747966821905		[learning rate: 0.00018078]
	Learning Rate: 0.000180783
	LOSS [training: 0.6646747966821905 | validation: 0.9132863892476342]
	TIME [epoch: 9.51 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6548861395304035		[learning rate: 0.00018013]
	Learning Rate: 0.000180127
	LOSS [training: 0.6548861395304035 | validation: 0.9252181030917107]
	TIME [epoch: 9.52 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6535283954537994		[learning rate: 0.00017947]
	Learning Rate: 0.000179473
	LOSS [training: 0.6535283954537994 | validation: 0.9454568926784559]
	TIME [epoch: 9.53 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6626828914245143		[learning rate: 0.00017882]
	Learning Rate: 0.000178822
	LOSS [training: 0.6626828914245143 | validation: 0.9729505041592966]
	TIME [epoch: 9.53 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6658492738509002		[learning rate: 0.00017817]
	Learning Rate: 0.000178173
	LOSS [training: 0.6658492738509002 | validation: 0.9365598197799608]
	TIME [epoch: 9.51 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6679421224355895		[learning rate: 0.00017753]
	Learning Rate: 0.000177526
	LOSS [training: 0.6679421224355895 | validation: 0.9084644966928072]
	TIME [epoch: 9.53 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6695634076892029		[learning rate: 0.00017688]
	Learning Rate: 0.000176882
	LOSS [training: 0.6695634076892029 | validation: 0.9352053863757737]
	TIME [epoch: 9.52 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6700749059469138		[learning rate: 0.00017624]
	Learning Rate: 0.00017624
	LOSS [training: 0.6700749059469138 | validation: 0.9604885983549202]
	TIME [epoch: 9.52 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6656957214035578		[learning rate: 0.0001756]
	Learning Rate: 0.000175601
	LOSS [training: 0.6656957214035578 | validation: 0.9259833521237028]
	TIME [epoch: 9.52 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6587691182619047		[learning rate: 0.00017496]
	Learning Rate: 0.000174964
	LOSS [training: 0.6587691182619047 | validation: 0.9433955377299416]
	TIME [epoch: 9.54 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6519614767468545		[learning rate: 0.00017433]
	Learning Rate: 0.000174329
	LOSS [training: 0.6519614767468545 | validation: 0.9104689569505859]
	TIME [epoch: 9.51 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6578838538578936		[learning rate: 0.0001737]
	Learning Rate: 0.000173696
	LOSS [training: 0.6578838538578936 | validation: 0.9269561715648738]
	TIME [epoch: 9.53 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6457775380490314		[learning rate: 0.00017307]
	Learning Rate: 0.000173066
	LOSS [training: 0.6457775380490314 | validation: 0.935637694156847]
	TIME [epoch: 9.53 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6455207720954131		[learning rate: 0.00017244]
	Learning Rate: 0.000172437
	LOSS [training: 0.6455207720954131 | validation: 0.9151497134171909]
	TIME [epoch: 9.54 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6358495898594358		[learning rate: 0.00017181]
	Learning Rate: 0.000171812
	LOSS [training: 0.6358495898594358 | validation: 0.9464095231827305]
	TIME [epoch: 9.52 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6456579972998004		[learning rate: 0.00017119]
	Learning Rate: 0.000171188
	LOSS [training: 0.6456579972998004 | validation: 0.9322013149663723]
	TIME [epoch: 9.52 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6618080653824512		[learning rate: 0.00017057]
	Learning Rate: 0.000170567
	LOSS [training: 0.6618080653824512 | validation: 0.9146790222840782]
	TIME [epoch: 9.52 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6422321513577021		[learning rate: 0.00016995]
	Learning Rate: 0.000169948
	LOSS [training: 0.6422321513577021 | validation: 0.9390442150124321]
	TIME [epoch: 9.55 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.66154094614981		[learning rate: 0.00016933]
	Learning Rate: 0.000169331
	LOSS [training: 0.66154094614981 | validation: 0.945825989431764]
	TIME [epoch: 9.53 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6578953800317145		[learning rate: 0.00016872]
	Learning Rate: 0.000168717
	LOSS [training: 0.6578953800317145 | validation: 0.9228504977691205]
	TIME [epoch: 9.51 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6471251728604427		[learning rate: 0.0001681]
	Learning Rate: 0.000168104
	LOSS [training: 0.6471251728604427 | validation: 0.9174442308694059]
	TIME [epoch: 9.52 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.644913663834802		[learning rate: 0.00016749]
	Learning Rate: 0.000167494
	LOSS [training: 0.644913663834802 | validation: 0.9336210149631384]
	TIME [epoch: 9.53 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6506688421445078		[learning rate: 0.00016689]
	Learning Rate: 0.000166886
	LOSS [training: 0.6506688421445078 | validation: 0.9113375013043097]
	TIME [epoch: 9.51 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6507066473643207		[learning rate: 0.00016628]
	Learning Rate: 0.000166281
	LOSS [training: 0.6507066473643207 | validation: 0.9124017189142007]
	TIME [epoch: 9.53 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6613697703881563		[learning rate: 0.00016568]
	Learning Rate: 0.000165677
	LOSS [training: 0.6613697703881563 | validation: 0.9533998447407342]
	TIME [epoch: 9.54 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6473440356317133		[learning rate: 0.00016508]
	Learning Rate: 0.000165076
	LOSS [training: 0.6473440356317133 | validation: 0.950191955147822]
	TIME [epoch: 9.53 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6559514869193454		[learning rate: 0.00016448]
	Learning Rate: 0.000164477
	LOSS [training: 0.6559514869193454 | validation: 0.9215573255454694]
	TIME [epoch: 9.51 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6532816988342371		[learning rate: 0.00016388]
	Learning Rate: 0.00016388
	LOSS [training: 0.6532816988342371 | validation: 0.924607310612245]
	TIME [epoch: 9.52 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6534779437575005		[learning rate: 0.00016329]
	Learning Rate: 0.000163285
	LOSS [training: 0.6534779437575005 | validation: 0.9175087354188517]
	TIME [epoch: 9.53 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6424792325908567		[learning rate: 0.00016269]
	Learning Rate: 0.000162693
	LOSS [training: 0.6424792325908567 | validation: 0.9250936000107346]
	TIME [epoch: 9.52 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6518588804096483		[learning rate: 0.0001621]
	Learning Rate: 0.000162102
	LOSS [training: 0.6518588804096483 | validation: 0.9422285935853296]
	TIME [epoch: 9.51 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6475102043493243		[learning rate: 0.00016151]
	Learning Rate: 0.000161514
	LOSS [training: 0.6475102043493243 | validation: 0.9397472160392504]
	TIME [epoch: 9.52 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6580200438013752		[learning rate: 0.00016093]
	Learning Rate: 0.000160928
	LOSS [training: 0.6580200438013752 | validation: 0.9292428928272004]
	TIME [epoch: 9.55 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6575256249982703		[learning rate: 0.00016034]
	Learning Rate: 0.000160344
	LOSS [training: 0.6575256249982703 | validation: 0.8959367847024338]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_1237.pth
	Model improved!!!
EPOCH 1238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.646713461282178		[learning rate: 0.00015976]
	Learning Rate: 0.000159762
	LOSS [training: 0.646713461282178 | validation: 0.9254945418746451]
	TIME [epoch: 9.52 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6468895070424603		[learning rate: 0.00015918]
	Learning Rate: 0.000159182
	LOSS [training: 0.6468895070424603 | validation: 0.9246750070955877]
	TIME [epoch: 9.52 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6491446403220346		[learning rate: 0.0001586]
	Learning Rate: 0.000158605
	LOSS [training: 0.6491446403220346 | validation: 0.9068733049337803]
	TIME [epoch: 9.53 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6534737350793354		[learning rate: 0.00015803]
	Learning Rate: 0.000158029
	LOSS [training: 0.6534737350793354 | validation: 0.9206361688534332]
	TIME [epoch: 9.51 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6541004097658415		[learning rate: 0.00015746]
	Learning Rate: 0.000157456
	LOSS [training: 0.6541004097658415 | validation: 0.9279653114696694]
	TIME [epoch: 9.51 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6488755638742875		[learning rate: 0.00015688]
	Learning Rate: 0.000156884
	LOSS [training: 0.6488755638742875 | validation: 0.9212181972674686]
	TIME [epoch: 9.53 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6492834841428339		[learning rate: 0.00015631]
	Learning Rate: 0.000156315
	LOSS [training: 0.6492834841428339 | validation: 0.9270931990866451]
	TIME [epoch: 9.52 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6552232390522528		[learning rate: 0.00015575]
	Learning Rate: 0.000155748
	LOSS [training: 0.6552232390522528 | validation: 0.9508061291224402]
	TIME [epoch: 9.51 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6757842544963		[learning rate: 0.00015518]
	Learning Rate: 0.000155182
	LOSS [training: 0.6757842544963 | validation: 0.9199933617456364]
	TIME [epoch: 9.52 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6537151084393968		[learning rate: 0.00015462]
	Learning Rate: 0.000154619
	LOSS [training: 0.6537151084393968 | validation: 0.9226783751607818]
	TIME [epoch: 9.54 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6448339531880904		[learning rate: 0.00015406]
	Learning Rate: 0.000154058
	LOSS [training: 0.6448339531880904 | validation: 0.9453089873079842]
	TIME [epoch: 9.52 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6425820981061203		[learning rate: 0.0001535]
	Learning Rate: 0.000153499
	LOSS [training: 0.6425820981061203 | validation: 0.9186114624036614]
	TIME [epoch: 9.51 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.656141693110899		[learning rate: 0.00015294]
	Learning Rate: 0.000152942
	LOSS [training: 0.656141693110899 | validation: 0.9277213846328698]
	TIME [epoch: 9.52 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6611551851974748		[learning rate: 0.00015239]
	Learning Rate: 0.000152387
	LOSS [training: 0.6611551851974748 | validation: 0.9353263725957931]
	TIME [epoch: 9.53 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6652454725829363		[learning rate: 0.00015183]
	Learning Rate: 0.000151834
	LOSS [training: 0.6652454725829363 | validation: 0.9431697782135694]
	TIME [epoch: 9.51 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6516011648280984		[learning rate: 0.00015128]
	Learning Rate: 0.000151283
	LOSS [training: 0.6516011648280984 | validation: 0.9293753296680975]
	TIME [epoch: 9.51 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.657193994012706		[learning rate: 0.00015073]
	Learning Rate: 0.000150734
	LOSS [training: 0.657193994012706 | validation: 0.9221294809704066]
	TIME [epoch: 9.52 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6626004501066656		[learning rate: 0.00015019]
	Learning Rate: 0.000150187
	LOSS [training: 0.6626004501066656 | validation: 0.9140427788038725]
	TIME [epoch: 9.53 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6397427344989675		[learning rate: 0.00014964]
	Learning Rate: 0.000149642
	LOSS [training: 0.6397427344989675 | validation: 0.9217522429305842]
	TIME [epoch: 9.52 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6514690148219086		[learning rate: 0.0001491]
	Learning Rate: 0.000149099
	LOSS [training: 0.6514690148219086 | validation: 0.93212229922304]
	TIME [epoch: 9.52 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6461418958250025		[learning rate: 0.00014856]
	Learning Rate: 0.000148558
	LOSS [training: 0.6461418958250025 | validation: 0.9250507039195686]
	TIME [epoch: 9.51 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.668413458259764		[learning rate: 0.00014802]
	Learning Rate: 0.000148018
	LOSS [training: 0.668413458259764 | validation: 0.9169952061849351]
	TIME [epoch: 9.53 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.660816688621318		[learning rate: 0.00014748]
	Learning Rate: 0.000147481
	LOSS [training: 0.660816688621318 | validation: 0.9152547356562789]
	TIME [epoch: 9.51 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6356534914440404		[learning rate: 0.00014695]
	Learning Rate: 0.000146946
	LOSS [training: 0.6356534914440404 | validation: 0.9080980189609349]
	TIME [epoch: 9.51 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6391339759615807		[learning rate: 0.00014641]
	Learning Rate: 0.000146413
	LOSS [training: 0.6391339759615807 | validation: 0.9040828909798956]
	TIME [epoch: 9.54 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6493342064738702		[learning rate: 0.00014588]
	Learning Rate: 0.000145881
	LOSS [training: 0.6493342064738702 | validation: 0.9447583100410291]
	TIME [epoch: 9.52 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6587731946849041		[learning rate: 0.00014535]
	Learning Rate: 0.000145352
	LOSS [training: 0.6587731946849041 | validation: 0.8884555372353644]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_1264.pth
	Model improved!!!
EPOCH 1265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.645953628376273		[learning rate: 0.00014482]
	Learning Rate: 0.000144825
	LOSS [training: 0.645953628376273 | validation: 0.9441857069965373]
	TIME [epoch: 9.51 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6503393655763048		[learning rate: 0.0001443]
	Learning Rate: 0.000144299
	LOSS [training: 0.6503393655763048 | validation: 0.925089150336887]
	TIME [epoch: 9.53 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6520810848380366		[learning rate: 0.00014378]
	Learning Rate: 0.000143775
	LOSS [training: 0.6520810848380366 | validation: 0.9168189968754272]
	TIME [epoch: 9.52 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6534112649894797		[learning rate: 0.00014325]
	Learning Rate: 0.000143253
	LOSS [training: 0.6534112649894797 | validation: 0.9207931853898791]
	TIME [epoch: 9.51 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6505019612299204		[learning rate: 0.00014273]
	Learning Rate: 0.000142734
	LOSS [training: 0.6505019612299204 | validation: 0.9314669129151585]
	TIME [epoch: 9.51 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6552170697811387		[learning rate: 0.00014222]
	Learning Rate: 0.000142216
	LOSS [training: 0.6552170697811387 | validation: 0.9092010238085538]
	TIME [epoch: 9.53 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.643221568537042		[learning rate: 0.0001417]
	Learning Rate: 0.0001417
	LOSS [training: 0.643221568537042 | validation: 0.9491745821241847]
	TIME [epoch: 9.52 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6475439254374684		[learning rate: 0.00014119]
	Learning Rate: 0.000141185
	LOSS [training: 0.6475439254374684 | validation: 0.9202427270052529]
	TIME [epoch: 9.51 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6461600384335335		[learning rate: 0.00014067]
	Learning Rate: 0.000140673
	LOSS [training: 0.6461600384335335 | validation: 0.9181950427815169]
	TIME [epoch: 9.52 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6451686062446761		[learning rate: 0.00014016]
	Learning Rate: 0.000140162
	LOSS [training: 0.6451686062446761 | validation: 0.9131908610179216]
	TIME [epoch: 9.53 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6526154868742312		[learning rate: 0.00013965]
	Learning Rate: 0.000139654
	LOSS [training: 0.6526154868742312 | validation: 0.9100731980348702]
	TIME [epoch: 9.52 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6504521170888171		[learning rate: 0.00013915]
	Learning Rate: 0.000139147
	LOSS [training: 0.6504521170888171 | validation: 0.9599959850064366]
	TIME [epoch: 9.51 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6568475769390151		[learning rate: 0.00013864]
	Learning Rate: 0.000138642
	LOSS [training: 0.6568475769390151 | validation: 0.9187857073915051]
	TIME [epoch: 9.52 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6501113858726739		[learning rate: 0.00013814]
	Learning Rate: 0.000138139
	LOSS [training: 0.6501113858726739 | validation: 0.9144653953653356]
	TIME [epoch: 9.53 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6470273257324011		[learning rate: 0.00013764]
	Learning Rate: 0.000137638
	LOSS [training: 0.6470273257324011 | validation: 0.9378112531125143]
	TIME [epoch: 9.52 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6433135556110339		[learning rate: 0.00013714]
	Learning Rate: 0.000137138
	LOSS [training: 0.6433135556110339 | validation: 0.918619460742197]
	TIME [epoch: 9.52 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6588320520475368		[learning rate: 0.00013664]
	Learning Rate: 0.00013664
	LOSS [training: 0.6588320520475368 | validation: 0.9154935732507433]
	TIME [epoch: 9.54 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6463189910985563		[learning rate: 0.00013614]
	Learning Rate: 0.000136144
	LOSS [training: 0.6463189910985563 | validation: 0.9278134595564094]
	TIME [epoch: 9.51 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6477000220772821		[learning rate: 0.00013565]
	Learning Rate: 0.00013565
	LOSS [training: 0.6477000220772821 | validation: 0.9329388593167829]
	TIME [epoch: 9.51 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6603982713014015		[learning rate: 0.00013516]
	Learning Rate: 0.000135158
	LOSS [training: 0.6603982713014015 | validation: 0.933063313965762]
	TIME [epoch: 9.51 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6634862939363498		[learning rate: 0.00013467]
	Learning Rate: 0.000134668
	LOSS [training: 0.6634862939363498 | validation: 0.9196258723687547]
	TIME [epoch: 9.54 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6506895546775547		[learning rate: 0.00013418]
	Learning Rate: 0.000134179
	LOSS [training: 0.6506895546775547 | validation: 0.9177348602682861]
	TIME [epoch: 9.51 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6441462281035493		[learning rate: 0.00013369]
	Learning Rate: 0.000133692
	LOSS [training: 0.6441462281035493 | validation: 0.9296874614119602]
	TIME [epoch: 9.52 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6570725487618533		[learning rate: 0.00013321]
	Learning Rate: 0.000133207
	LOSS [training: 0.6570725487618533 | validation: 0.9363065424808446]
	TIME [epoch: 9.52 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.650892243004135		[learning rate: 0.00013272]
	Learning Rate: 0.000132723
	LOSS [training: 0.650892243004135 | validation: 0.926402137515411]
	TIME [epoch: 9.55 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6544618317457288		[learning rate: 0.00013224]
	Learning Rate: 0.000132242
	LOSS [training: 0.6544618317457288 | validation: 0.9373991300367353]
	TIME [epoch: 9.52 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6602008321460531		[learning rate: 0.00013176]
	Learning Rate: 0.000131762
	LOSS [training: 0.6602008321460531 | validation: 0.9272768430438856]
	TIME [epoch: 9.51 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6540118478536098		[learning rate: 0.00013128]
	Learning Rate: 0.000131284
	LOSS [training: 0.6540118478536098 | validation: 0.9182714798127221]
	TIME [epoch: 9.52 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6426104009457221		[learning rate: 0.00013081]
	Learning Rate: 0.000130807
	LOSS [training: 0.6426104009457221 | validation: 0.910806695284025]
	TIME [epoch: 9.52 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6494733230742898		[learning rate: 0.00013033]
	Learning Rate: 0.000130332
	LOSS [training: 0.6494733230742898 | validation: 0.9175720645458704]
	TIME [epoch: 9.52 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6517744876303583		[learning rate: 0.00012986]
	Learning Rate: 0.000129859
	LOSS [training: 0.6517744876303583 | validation: 0.9247757310076422]
	TIME [epoch: 9.52 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6543114938010736		[learning rate: 0.00012939]
	Learning Rate: 0.000129388
	LOSS [training: 0.6543114938010736 | validation: 0.9318907072762784]
	TIME [epoch: 9.53 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6513700953990864		[learning rate: 0.00012892]
	Learning Rate: 0.000128919
	LOSS [training: 0.6513700953990864 | validation: 0.9103254463336891]
	TIME [epoch: 9.52 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6424914856794015		[learning rate: 0.00012845]
	Learning Rate: 0.000128451
	LOSS [training: 0.6424914856794015 | validation: 0.900668401929488]
	TIME [epoch: 9.51 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6438580802594391		[learning rate: 0.00012798]
	Learning Rate: 0.000127985
	LOSS [training: 0.6438580802594391 | validation: 0.916587834121643]
	TIME [epoch: 9.51 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.649616349345365		[learning rate: 0.00012752]
	Learning Rate: 0.00012752
	LOSS [training: 0.649616349345365 | validation: 0.9384140033577353]
	TIME [epoch: 9.53 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6364022867808552		[learning rate: 0.00012706]
	Learning Rate: 0.000127057
	LOSS [training: 0.6364022867808552 | validation: 0.9138672065664352]
	TIME [epoch: 9.52 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6527327656308982		[learning rate: 0.0001266]
	Learning Rate: 0.000126596
	LOSS [training: 0.6527327656308982 | validation: 0.9095890286624186]
	TIME [epoch: 9.52 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6555055316480871		[learning rate: 0.00012614]
	Learning Rate: 0.000126137
	LOSS [training: 0.6555055316480871 | validation: 0.9082664786398045]
	TIME [epoch: 9.52 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6487459774418445		[learning rate: 0.00012568]
	Learning Rate: 0.000125679
	LOSS [training: 0.6487459774418445 | validation: 0.9309869278186972]
	TIME [epoch: 9.54 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6529698619237954		[learning rate: 0.00012522]
	Learning Rate: 0.000125223
	LOSS [training: 0.6529698619237954 | validation: 0.9422184210122285]
	TIME [epoch: 9.52 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6713771155648344		[learning rate: 0.00012477]
	Learning Rate: 0.000124769
	LOSS [training: 0.6713771155648344 | validation: 0.9200551169594974]
	TIME [epoch: 9.51 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6509377688291266		[learning rate: 0.00012432]
	Learning Rate: 0.000124316
	LOSS [training: 0.6509377688291266 | validation: 0.8964278380689359]
	TIME [epoch: 9.52 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6474971606425988		[learning rate: 0.00012386]
	Learning Rate: 0.000123865
	LOSS [training: 0.6474971606425988 | validation: 0.9149640409502487]
	TIME [epoch: 9.53 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6488344543791082		[learning rate: 0.00012342]
	Learning Rate: 0.000123415
	LOSS [training: 0.6488344543791082 | validation: 0.927261937612776]
	TIME [epoch: 9.53 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6589015390718393		[learning rate: 0.00012297]
	Learning Rate: 0.000122967
	LOSS [training: 0.6589015390718393 | validation: 0.9199893042310574]
	TIME [epoch: 9.52 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6513470898445954		[learning rate: 0.00012252]
	Learning Rate: 0.000122521
	LOSS [training: 0.6513470898445954 | validation: 0.9347190243460856]
	TIME [epoch: 9.53 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6542173170679193		[learning rate: 0.00012208]
	Learning Rate: 0.000122076
	LOSS [training: 0.6542173170679193 | validation: 0.9466781118821221]
	TIME [epoch: 9.53 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6589716311553756		[learning rate: 0.00012163]
	Learning Rate: 0.000121633
	LOSS [training: 0.6589716311553756 | validation: 0.9452592521599641]
	TIME [epoch: 9.52 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6500504001953467		[learning rate: 0.00012119]
	Learning Rate: 0.000121192
	LOSS [training: 0.6500504001953467 | validation: 0.9179637840216094]
	TIME [epoch: 9.52 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6430927420703125		[learning rate: 0.00012075]
	Learning Rate: 0.000120752
	LOSS [training: 0.6430927420703125 | validation: 0.9383493880738497]
	TIME [epoch: 9.54 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6450330239610204		[learning rate: 0.00012031]
	Learning Rate: 0.000120314
	LOSS [training: 0.6450330239610204 | validation: 0.930542421770041]
	TIME [epoch: 9.52 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6542008071620756		[learning rate: 0.00011988]
	Learning Rate: 0.000119877
	LOSS [training: 0.6542008071620756 | validation: 0.9113410265139582]
	TIME [epoch: 9.52 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6448194366904432		[learning rate: 0.00011944]
	Learning Rate: 0.000119442
	LOSS [training: 0.6448194366904432 | validation: 0.9195404777046003]
	TIME [epoch: 9.51 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6474223034614202		[learning rate: 0.00011901]
	Learning Rate: 0.000119009
	LOSS [training: 0.6474223034614202 | validation: 0.9155524042025583]
	TIME [epoch: 9.53 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6622540370583171		[learning rate: 0.00011858]
	Learning Rate: 0.000118577
	LOSS [training: 0.6622540370583171 | validation: 0.9155392423890141]
	TIME [epoch: 9.51 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6588979030107139		[learning rate: 0.00011815]
	Learning Rate: 0.000118147
	LOSS [training: 0.6588979030107139 | validation: 0.9293647162041131]
	TIME [epoch: 9.51 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6473791896080247		[learning rate: 0.00011772]
	Learning Rate: 0.000117718
	LOSS [training: 0.6473791896080247 | validation: 0.9286159720028403]
	TIME [epoch: 9.51 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6383074428387856		[learning rate: 0.00011729]
	Learning Rate: 0.000117291
	LOSS [training: 0.6383074428387856 | validation: 0.9077862768513839]
	TIME [epoch: 9.53 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6477901196390847		[learning rate: 0.00011686]
	Learning Rate: 0.000116865
	LOSS [training: 0.6477901196390847 | validation: 0.911501966006235]
	TIME [epoch: 9.52 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6412210472315464		[learning rate: 0.00011644]
	Learning Rate: 0.000116441
	LOSS [training: 0.6412210472315464 | validation: 0.9130047679982488]
	TIME [epoch: 9.51 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6387594074530587		[learning rate: 0.00011602]
	Learning Rate: 0.000116018
	LOSS [training: 0.6387594074530587 | validation: 0.9272465987643304]
	TIME [epoch: 9.52 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6414571717372894		[learning rate: 0.0001156]
	Learning Rate: 0.000115597
	LOSS [training: 0.6414571717372894 | validation: 0.9136859718430276]
	TIME [epoch: 9.55 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6520747918445322		[learning rate: 0.00011518]
	Learning Rate: 0.000115178
	LOSS [training: 0.6520747918445322 | validation: 0.9214914279758698]
	TIME [epoch: 9.52 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6548181487453255		[learning rate: 0.00011476]
	Learning Rate: 0.00011476
	LOSS [training: 0.6548181487453255 | validation: 0.9189769294665462]
	TIME [epoch: 9.53 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6407800183267961		[learning rate: 0.00011434]
	Learning Rate: 0.000114343
	LOSS [training: 0.6407800183267961 | validation: 0.9152229370332796]
	TIME [epoch: 9.52 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6509892693273247		[learning rate: 0.00011393]
	Learning Rate: 0.000113928
	LOSS [training: 0.6509892693273247 | validation: 0.9232728493634095]
	TIME [epoch: 9.53 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6304069252732164		[learning rate: 0.00011351]
	Learning Rate: 0.000113515
	LOSS [training: 0.6304069252732164 | validation: 0.9182713456916648]
	TIME [epoch: 9.52 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6384019431838364		[learning rate: 0.0001131]
	Learning Rate: 0.000113103
	LOSS [training: 0.6384019431838364 | validation: 0.9461452365070331]
	TIME [epoch: 9.52 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6441028957405516		[learning rate: 0.00011269]
	Learning Rate: 0.000112692
	LOSS [training: 0.6441028957405516 | validation: 0.9449418596364256]
	TIME [epoch: 9.54 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6496654866787379		[learning rate: 0.00011228]
	Learning Rate: 0.000112283
	LOSS [training: 0.6496654866787379 | validation: 0.9342380623078671]
	TIME [epoch: 9.52 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6683359089000187		[learning rate: 0.00011188]
	Learning Rate: 0.000111876
	LOSS [training: 0.6683359089000187 | validation: 0.913809144920813]
	TIME [epoch: 9.52 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6398904109113857		[learning rate: 0.00011147]
	Learning Rate: 0.00011147
	LOSS [training: 0.6398904109113857 | validation: 0.9014883373048233]
	TIME [epoch: 9.52 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6395276946027435		[learning rate: 0.00011107]
	Learning Rate: 0.000111065
	LOSS [training: 0.6395276946027435 | validation: 0.914325940419757]
	TIME [epoch: 9.53 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6526698425964651		[learning rate: 0.00011066]
	Learning Rate: 0.000110662
	LOSS [training: 0.6526698425964651 | validation: 0.9127404538625319]
	TIME [epoch: 9.52 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6325352019797847		[learning rate: 0.00011026]
	Learning Rate: 0.000110261
	LOSS [training: 0.6325352019797847 | validation: 0.9202840594027046]
	TIME [epoch: 9.52 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6469308185866459		[learning rate: 0.00010986]
	Learning Rate: 0.000109861
	LOSS [training: 0.6469308185866459 | validation: 0.926436439928408]
	TIME [epoch: 9.52 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6451043471291217		[learning rate: 0.00010946]
	Learning Rate: 0.000109462
	LOSS [training: 0.6451043471291217 | validation: 0.9114835857474841]
	TIME [epoch: 9.55 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6481723610619514		[learning rate: 0.00010906]
	Learning Rate: 0.000109065
	LOSS [training: 0.6481723610619514 | validation: 0.9103381789503213]
	TIME [epoch: 9.52 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.65876629534663		[learning rate: 0.00010867]
	Learning Rate: 0.000108669
	LOSS [training: 0.65876629534663 | validation: 0.9542061514561408]
	TIME [epoch: 9.53 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6443161240238124		[learning rate: 0.00010827]
	Learning Rate: 0.000108275
	LOSS [training: 0.6443161240238124 | validation: 0.9231860549990174]
	TIME [epoch: 9.52 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.644011707448403		[learning rate: 0.00010788]
	Learning Rate: 0.000107882
	LOSS [training: 0.644011707448403 | validation: 0.929260920673922]
	TIME [epoch: 9.54 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6479409272897045		[learning rate: 0.00010749]
	Learning Rate: 0.00010749
	LOSS [training: 0.6479409272897045 | validation: 0.9059080517169928]
	TIME [epoch: 9.52 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6436265362734062		[learning rate: 0.0001071]
	Learning Rate: 0.0001071
	LOSS [training: 0.6436265362734062 | validation: 0.9075239019795294]
	TIME [epoch: 9.53 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6528288562426717		[learning rate: 0.00010671]
	Learning Rate: 0.000106711
	LOSS [training: 0.6528288562426717 | validation: 0.9239395878303591]
	TIME [epoch: 9.53 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6442308417477137		[learning rate: 0.00010632]
	Learning Rate: 0.000106324
	LOSS [training: 0.6442308417477137 | validation: 0.9183495120238035]
	TIME [epoch: 9.52 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6493066422054238		[learning rate: 0.00010594]
	Learning Rate: 0.000105938
	LOSS [training: 0.6493066422054238 | validation: 0.9103877593802787]
	TIME [epoch: 9.52 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.640054649518215		[learning rate: 0.00010555]
	Learning Rate: 0.000105554
	LOSS [training: 0.640054649518215 | validation: 0.9244598573186223]
	TIME [epoch: 9.53 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6375291890287285		[learning rate: 0.00010517]
	Learning Rate: 0.000105171
	LOSS [training: 0.6375291890287285 | validation: 0.9332765808008402]
	TIME [epoch: 9.54 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6408172613624609		[learning rate: 0.00010479]
	Learning Rate: 0.000104789
	LOSS [training: 0.6408172613624609 | validation: 0.9162343377987088]
	TIME [epoch: 9.53 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6495422875553079		[learning rate: 0.00010441]
	Learning Rate: 0.000104409
	LOSS [training: 0.6495422875553079 | validation: 0.9153500159760118]
	TIME [epoch: 9.53 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6478507587982977		[learning rate: 0.00010403]
	Learning Rate: 0.00010403
	LOSS [training: 0.6478507587982977 | validation: 0.9185530090433415]
	TIME [epoch: 9.52 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6571556160118124		[learning rate: 0.00010365]
	Learning Rate: 0.000103652
	LOSS [training: 0.6571556160118124 | validation: 0.9084069261709459]
	TIME [epoch: 9.54 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6595945519679403		[learning rate: 0.00010328]
	Learning Rate: 0.000103276
	LOSS [training: 0.6595945519679403 | validation: 0.9312666420949318]
	TIME [epoch: 9.52 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6560465402100714		[learning rate: 0.0001029]
	Learning Rate: 0.000102901
	LOSS [training: 0.6560465402100714 | validation: 0.9373092677290044]
	TIME [epoch: 9.52 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6473672249899678		[learning rate: 0.00010253]
	Learning Rate: 0.000102528
	LOSS [training: 0.6473672249899678 | validation: 0.9124164397930378]
	TIME [epoch: 9.52 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6387759035738066		[learning rate: 0.00010216]
	Learning Rate: 0.000102156
	LOSS [training: 0.6387759035738066 | validation: 0.9300733300462483]
	TIME [epoch: 9.54 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6494431243814983		[learning rate: 0.00010179]
	Learning Rate: 0.000101785
	LOSS [training: 0.6494431243814983 | validation: 0.9234140495569924]
	TIME [epoch: 9.52 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.63802304089608		[learning rate: 0.00010142]
	Learning Rate: 0.000101416
	LOSS [training: 0.63802304089608 | validation: 0.9269168557488865]
	TIME [epoch: 9.52 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6459211677123342		[learning rate: 0.00010105]
	Learning Rate: 0.000101048
	LOSS [training: 0.6459211677123342 | validation: 0.9043919508929927]
	TIME [epoch: 9.53 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6534217829721352		[learning rate: 0.00010068]
	Learning Rate: 0.000100681
	LOSS [training: 0.6534217829721352 | validation: 0.9080160589779734]
	TIME [epoch: 9.54 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6494105945521756		[learning rate: 0.00010032]
	Learning Rate: 0.000100316
	LOSS [training: 0.6494105945521756 | validation: 0.9130042327292324]
	TIME [epoch: 9.51 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6555137199173537		[learning rate: 9.9952e-05]
	Learning Rate: 9.99515e-05
	LOSS [training: 0.6555137199173537 | validation: 0.9067844881928678]
	TIME [epoch: 9.52 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6531236737701576		[learning rate: 9.9589e-05]
	Learning Rate: 9.95888e-05
	LOSS [training: 0.6531236737701576 | validation: 0.9399443095688171]
	TIME [epoch: 9.53 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6437455248542934		[learning rate: 9.9227e-05]
	Learning Rate: 9.92274e-05
	LOSS [training: 0.6437455248542934 | validation: 0.9154125216569591]
	TIME [epoch: 9.52 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6448010777326537		[learning rate: 9.8867e-05]
	Learning Rate: 9.88673e-05
	LOSS [training: 0.6448010777326537 | validation: 0.9150907075799896]
	TIME [epoch: 9.51 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6493362962872344		[learning rate: 9.8509e-05]
	Learning Rate: 9.85085e-05
	LOSS [training: 0.6493362962872344 | validation: 0.9247940638157072]
	TIME [epoch: 9.52 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6518806738719356		[learning rate: 9.8151e-05]
	Learning Rate: 9.8151e-05
	LOSS [training: 0.6518806738719356 | validation: 0.9050913232843192]
	TIME [epoch: 9.55 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6490837769010362		[learning rate: 9.7795e-05]
	Learning Rate: 9.77948e-05
	LOSS [training: 0.6490837769010362 | validation: 0.9147073933576875]
	TIME [epoch: 9.52 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6467861617564014		[learning rate: 9.744e-05]
	Learning Rate: 9.74399e-05
	LOSS [training: 0.6467861617564014 | validation: 0.9069833992951705]
	TIME [epoch: 9.51 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6488042974242337		[learning rate: 9.7086e-05]
	Learning Rate: 9.70863e-05
	LOSS [training: 0.6488042974242337 | validation: 0.9243829195101161]
	TIME [epoch: 9.52 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6297799132321595		[learning rate: 9.6734e-05]
	Learning Rate: 9.6734e-05
	LOSS [training: 0.6297799132321595 | validation: 0.9138095541668778]
	TIME [epoch: 9.54 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6418104091563586		[learning rate: 9.6383e-05]
	Learning Rate: 9.63829e-05
	LOSS [training: 0.6418104091563586 | validation: 0.9309173335397898]
	TIME [epoch: 9.55 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6397642921289652		[learning rate: 9.6033e-05]
	Learning Rate: 9.60331e-05
	LOSS [training: 0.6397642921289652 | validation: 0.8960373986778363]
	TIME [epoch: 9.52 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6441846086598815		[learning rate: 9.5685e-05]
	Learning Rate: 9.56846e-05
	LOSS [training: 0.6441846086598815 | validation: 0.9017742256705995]
	TIME [epoch: 9.52 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6395257148115469		[learning rate: 9.5337e-05]
	Learning Rate: 9.53374e-05
	LOSS [training: 0.6395257148115469 | validation: 0.9175473362409171]
	TIME [epoch: 9.54 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6406989761805284		[learning rate: 9.4991e-05]
	Learning Rate: 9.49914e-05
	LOSS [training: 0.6406989761805284 | validation: 0.9051004495254067]
	TIME [epoch: 9.52 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6409072318583983		[learning rate: 9.4647e-05]
	Learning Rate: 9.46466e-05
	LOSS [training: 0.6409072318583983 | validation: 0.898988423578017]
	TIME [epoch: 9.5 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6397802050249325		[learning rate: 9.4303e-05]
	Learning Rate: 9.43032e-05
	LOSS [training: 0.6397802050249325 | validation: 0.9026571317173049]
	TIME [epoch: 9.51 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6517297888365199		[learning rate: 9.3961e-05]
	Learning Rate: 9.39609e-05
	LOSS [training: 0.6517297888365199 | validation: 0.9143325880289603]
	TIME [epoch: 9.53 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6429867441018889		[learning rate: 9.362e-05]
	Learning Rate: 9.362e-05
	LOSS [training: 0.6429867441018889 | validation: 0.9056449268432161]
	TIME [epoch: 9.51 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6582946324333345		[learning rate: 9.328e-05]
	Learning Rate: 9.32802e-05
	LOSS [training: 0.6582946324333345 | validation: 0.9150858397353747]
	TIME [epoch: 9.53 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6363381737421723		[learning rate: 9.2942e-05]
	Learning Rate: 9.29417e-05
	LOSS [training: 0.6363381737421723 | validation: 0.9085810403046302]
	TIME [epoch: 9.53 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6389665631985648		[learning rate: 9.2604e-05]
	Learning Rate: 9.26044e-05
	LOSS [training: 0.6389665631985648 | validation: 0.9037064167702178]
	TIME [epoch: 9.52 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6483433861162252		[learning rate: 9.2268e-05]
	Learning Rate: 9.22683e-05
	LOSS [training: 0.6483433861162252 | validation: 0.9095588875003345]
	TIME [epoch: 9.52 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.64389140207362		[learning rate: 9.1933e-05]
	Learning Rate: 9.19335e-05
	LOSS [training: 0.64389140207362 | validation: 0.9100009919125435]
	TIME [epoch: 9.52 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6300328835426984		[learning rate: 9.16e-05]
	Learning Rate: 9.15998e-05
	LOSS [training: 0.6300328835426984 | validation: 0.910296912672405]
	TIME [epoch: 9.54 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6403846001467709		[learning rate: 9.1267e-05]
	Learning Rate: 9.12674e-05
	LOSS [training: 0.6403846001467709 | validation: 0.9034941888489612]
	TIME [epoch: 9.52 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6362677409453165		[learning rate: 9.0936e-05]
	Learning Rate: 9.09362e-05
	LOSS [training: 0.6362677409453165 | validation: 0.9038641355821441]
	TIME [epoch: 9.52 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6498805781617953		[learning rate: 9.0606e-05]
	Learning Rate: 9.06062e-05
	LOSS [training: 0.6498805781617953 | validation: 0.9205604461442061]
	TIME [epoch: 9.52 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6529774076309003		[learning rate: 9.0277e-05]
	Learning Rate: 9.02774e-05
	LOSS [training: 0.6529774076309003 | validation: 0.9278012578863496]
	TIME [epoch: 9.54 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6502953134892142		[learning rate: 8.995e-05]
	Learning Rate: 8.99498e-05
	LOSS [training: 0.6502953134892142 | validation: 0.9221089611878841]
	TIME [epoch: 9.52 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.645080686643305		[learning rate: 8.9623e-05]
	Learning Rate: 8.96233e-05
	LOSS [training: 0.645080686643305 | validation: 0.9134740677104946]
	TIME [epoch: 9.52 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.645423202573487		[learning rate: 8.9298e-05]
	Learning Rate: 8.92981e-05
	LOSS [training: 0.645423202573487 | validation: 0.9264614393646622]
	TIME [epoch: 9.52 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6382938306334538		[learning rate: 8.8974e-05]
	Learning Rate: 8.8974e-05
	LOSS [training: 0.6382938306334538 | validation: 0.9011528072575127]
	TIME [epoch: 9.55 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6419674370272463		[learning rate: 8.8651e-05]
	Learning Rate: 8.86511e-05
	LOSS [training: 0.6419674370272463 | validation: 0.9068932358207861]
	TIME [epoch: 9.52 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.644188558673396		[learning rate: 8.8329e-05]
	Learning Rate: 8.83294e-05
	LOSS [training: 0.644188558673396 | validation: 0.9096205006116602]
	TIME [epoch: 9.52 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6419814545520888		[learning rate: 8.8009e-05]
	Learning Rate: 8.80088e-05
	LOSS [training: 0.6419814545520888 | validation: 0.8879537337428903]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_1402.pth
	Model improved!!!
EPOCH 1403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6605170922795218		[learning rate: 8.7689e-05]
	Learning Rate: 8.76895e-05
	LOSS [training: 0.6605170922795218 | validation: 0.9034860577377896]
	TIME [epoch: 9.53 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.637910533501177		[learning rate: 8.7371e-05]
	Learning Rate: 8.73712e-05
	LOSS [training: 0.637910533501177 | validation: 0.892890685487171]
	TIME [epoch: 9.53 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6361690416200867		[learning rate: 8.7054e-05]
	Learning Rate: 8.70542e-05
	LOSS [training: 0.6361690416200867 | validation: 0.9165556759611935]
	TIME [epoch: 9.52 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6415522091687341		[learning rate: 8.6738e-05]
	Learning Rate: 8.67382e-05
	LOSS [training: 0.6415522091687341 | validation: 0.9043542066387145]
	TIME [epoch: 9.53 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.636329191139432		[learning rate: 8.6423e-05]
	Learning Rate: 8.64235e-05
	LOSS [training: 0.636329191139432 | validation: 0.9067597382948747]
	TIME [epoch: 9.53 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6399280013294658		[learning rate: 8.611e-05]
	Learning Rate: 8.61098e-05
	LOSS [training: 0.6399280013294658 | validation: 0.9208543796743754]
	TIME [epoch: 9.53 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6465820620482915		[learning rate: 8.5797e-05]
	Learning Rate: 8.57973e-05
	LOSS [training: 0.6465820620482915 | validation: 0.9123114838787197]
	TIME [epoch: 9.52 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6544076591833223		[learning rate: 8.5486e-05]
	Learning Rate: 8.54859e-05
	LOSS [training: 0.6544076591833223 | validation: 0.9207922938701916]
	TIME [epoch: 9.55 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6297681576212151		[learning rate: 8.5176e-05]
	Learning Rate: 8.51757e-05
	LOSS [training: 0.6297681576212151 | validation: 0.8919176221960422]
	TIME [epoch: 9.53 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6474207388715875		[learning rate: 8.4867e-05]
	Learning Rate: 8.48666e-05
	LOSS [training: 0.6474207388715875 | validation: 0.9203400474717555]
	TIME [epoch: 9.53 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6468984519936887		[learning rate: 8.4559e-05]
	Learning Rate: 8.45586e-05
	LOSS [training: 0.6468984519936887 | validation: 0.9063785763538132]
	TIME [epoch: 9.52 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6426470544926837		[learning rate: 8.4252e-05]
	Learning Rate: 8.42518e-05
	LOSS [training: 0.6426470544926837 | validation: 0.9337500930025171]
	TIME [epoch: 9.54 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6695882600549848		[learning rate: 8.3946e-05]
	Learning Rate: 8.3946e-05
	LOSS [training: 0.6695882600549848 | validation: 0.896246354727686]
	TIME [epoch: 9.51 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6410491000537866		[learning rate: 8.3641e-05]
	Learning Rate: 8.36414e-05
	LOSS [training: 0.6410491000537866 | validation: 0.8984008197656204]
	TIME [epoch: 9.52 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6421438346540527		[learning rate: 8.3338e-05]
	Learning Rate: 8.33378e-05
	LOSS [training: 0.6421438346540527 | validation: 0.9234277192250335]
	TIME [epoch: 9.52 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6373749447403356		[learning rate: 8.3035e-05]
	Learning Rate: 8.30354e-05
	LOSS [training: 0.6373749447403356 | validation: 0.9375836615756146]
	TIME [epoch: 9.53 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6430647601999109		[learning rate: 8.2734e-05]
	Learning Rate: 8.2734e-05
	LOSS [training: 0.6430647601999109 | validation: 0.9025544991272694]
	TIME [epoch: 9.52 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.650712126647876		[learning rate: 8.2434e-05]
	Learning Rate: 8.24338e-05
	LOSS [training: 0.650712126647876 | validation: 0.9093052174466667]
	TIME [epoch: 9.52 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6411292776247957		[learning rate: 8.2135e-05]
	Learning Rate: 8.21346e-05
	LOSS [training: 0.6411292776247957 | validation: 0.9029798215169188]
	TIME [epoch: 9.54 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.638653426530911		[learning rate: 8.1837e-05]
	Learning Rate: 8.18366e-05
	LOSS [training: 0.638653426530911 | validation: 0.919698534043869]
	TIME [epoch: 9.53 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6469676129895912		[learning rate: 8.154e-05]
	Learning Rate: 8.15396e-05
	LOSS [training: 0.6469676129895912 | validation: 0.9201098772868476]
	TIME [epoch: 9.51 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6382230237783082		[learning rate: 8.1244e-05]
	Learning Rate: 8.12437e-05
	LOSS [training: 0.6382230237783082 | validation: 0.9338391509702245]
	TIME [epoch: 9.52 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6323160352062203		[learning rate: 8.0949e-05]
	Learning Rate: 8.09488e-05
	LOSS [training: 0.6323160352062203 | validation: 0.919875672535909]
	TIME [epoch: 9.54 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6434124949585677		[learning rate: 8.0655e-05]
	Learning Rate: 8.0655e-05
	LOSS [training: 0.6434124949585677 | validation: 0.8928511351330191]
	TIME [epoch: 9.53 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6415416067125786		[learning rate: 8.0362e-05]
	Learning Rate: 8.03623e-05
	LOSS [training: 0.6415416067125786 | validation: 0.9101873887529103]
	TIME [epoch: 9.52 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.634812607390147		[learning rate: 8.0071e-05]
	Learning Rate: 8.00707e-05
	LOSS [training: 0.634812607390147 | validation: 0.9209019100879101]
	TIME [epoch: 9.52 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6435219772537598		[learning rate: 7.978e-05]
	Learning Rate: 7.97801e-05
	LOSS [training: 0.6435219772537598 | validation: 0.9027643595678765]
	TIME [epoch: 9.54 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6530185748872194		[learning rate: 7.9491e-05]
	Learning Rate: 7.94906e-05
	LOSS [training: 0.6530185748872194 | validation: 0.949741527825853]
	TIME [epoch: 9.52 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6507933167492569		[learning rate: 7.9202e-05]
	Learning Rate: 7.92021e-05
	LOSS [training: 0.6507933167492569 | validation: 0.9204727321513884]
	TIME [epoch: 9.52 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.64837981653794		[learning rate: 7.8915e-05]
	Learning Rate: 7.89147e-05
	LOSS [training: 0.64837981653794 | validation: 0.9228717496389328]
	TIME [epoch: 9.53 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6462517115684019		[learning rate: 7.8628e-05]
	Learning Rate: 7.86283e-05
	LOSS [training: 0.6462517115684019 | validation: 0.9394667471462862]
	TIME [epoch: 9.53 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6494991006462522		[learning rate: 7.8343e-05]
	Learning Rate: 7.8343e-05
	LOSS [training: 0.6494991006462522 | validation: 0.9385754152510861]
	TIME [epoch: 9.53 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6486434076494199		[learning rate: 7.8059e-05]
	Learning Rate: 7.80586e-05
	LOSS [training: 0.6486434076494199 | validation: 0.9132396375839562]
	TIME [epoch: 9.52 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6448431246875312		[learning rate: 7.7775e-05]
	Learning Rate: 7.77754e-05
	LOSS [training: 0.6448431246875312 | validation: 0.9062425438279167]
	TIME [epoch: 9.54 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.664312262038087		[learning rate: 7.7493e-05]
	Learning Rate: 7.74931e-05
	LOSS [training: 0.664312262038087 | validation: 0.9056160479800732]
	TIME [epoch: 9.54 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6380895739679767		[learning rate: 7.7212e-05]
	Learning Rate: 7.72119e-05
	LOSS [training: 0.6380895739679767 | validation: 0.9132458676028461]
	TIME [epoch: 9.52 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6375111595039673		[learning rate: 7.6932e-05]
	Learning Rate: 7.69317e-05
	LOSS [training: 0.6375111595039673 | validation: 0.9354886542724574]
	TIME [epoch: 9.52 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6415564446175848		[learning rate: 7.6653e-05]
	Learning Rate: 7.66525e-05
	LOSS [training: 0.6415564446175848 | validation: 0.9301315895924915]
	TIME [epoch: 9.54 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6500965817367211		[learning rate: 7.6374e-05]
	Learning Rate: 7.63743e-05
	LOSS [training: 0.6500965817367211 | validation: 0.9427118079281844]
	TIME [epoch: 9.51 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6483026746317956		[learning rate: 7.6097e-05]
	Learning Rate: 7.60972e-05
	LOSS [training: 0.6483026746317956 | validation: 0.9174944035529459]
	TIME [epoch: 9.52 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6533955085600346		[learning rate: 7.5821e-05]
	Learning Rate: 7.5821e-05
	LOSS [training: 0.6533955085600346 | validation: 0.9385764213398992]
	TIME [epoch: 9.52 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6365346679869471		[learning rate: 7.5546e-05]
	Learning Rate: 7.55458e-05
	LOSS [training: 0.6365346679869471 | validation: 0.9222909305839551]
	TIME [epoch: 9.54 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6516678339407604		[learning rate: 7.5272e-05]
	Learning Rate: 7.52717e-05
	LOSS [training: 0.6516678339407604 | validation: 0.9058286597795902]
	TIME [epoch: 9.53 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.646020932847556		[learning rate: 7.4999e-05]
	Learning Rate: 7.49985e-05
	LOSS [training: 0.646020932847556 | validation: 0.9249355563323641]
	TIME [epoch: 9.52 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6427568770918173		[learning rate: 7.4726e-05]
	Learning Rate: 7.47263e-05
	LOSS [training: 0.6427568770918173 | validation: 0.9064411551751878]
	TIME [epoch: 9.52 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.647107661261608		[learning rate: 7.4455e-05]
	Learning Rate: 7.44552e-05
	LOSS [training: 0.647107661261608 | validation: 0.9104245526642621]
	TIME [epoch: 9.55 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6262072672042557		[learning rate: 7.4185e-05]
	Learning Rate: 7.4185e-05
	LOSS [training: 0.6262072672042557 | validation: 0.951550320644575]
	TIME [epoch: 9.53 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6485085080796325		[learning rate: 7.3916e-05]
	Learning Rate: 7.39157e-05
	LOSS [training: 0.6485085080796325 | validation: 0.9212413920309507]
	TIME [epoch: 9.52 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6323048310099351		[learning rate: 7.3647e-05]
	Learning Rate: 7.36475e-05
	LOSS [training: 0.6323048310099351 | validation: 0.9220230259508532]
	TIME [epoch: 9.53 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.629682068711121		[learning rate: 7.338e-05]
	Learning Rate: 7.33802e-05
	LOSS [training: 0.629682068711121 | validation: 0.9185025119525702]
	TIME [epoch: 9.53 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6362403832748061		[learning rate: 7.3114e-05]
	Learning Rate: 7.31139e-05
	LOSS [training: 0.6362403832748061 | validation: 0.8926027164529583]
	TIME [epoch: 9.52 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6382235314986708		[learning rate: 7.2849e-05]
	Learning Rate: 7.28486e-05
	LOSS [training: 0.6382235314986708 | validation: 0.9238623474145289]
	TIME [epoch: 9.51 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6410042763417596		[learning rate: 7.2584e-05]
	Learning Rate: 7.25842e-05
	LOSS [training: 0.6410042763417596 | validation: 0.899839982811513]
	TIME [epoch: 9.54 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6378983324196988		[learning rate: 7.2321e-05]
	Learning Rate: 7.23208e-05
	LOSS [training: 0.6378983324196988 | validation: 0.9270606319893347]
	TIME [epoch: 9.51 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6341156936914867		[learning rate: 7.2058e-05]
	Learning Rate: 7.20583e-05
	LOSS [training: 0.6341156936914867 | validation: 0.9093964739193269]
	TIME [epoch: 9.52 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6500878076132351		[learning rate: 7.1797e-05]
	Learning Rate: 7.17968e-05
	LOSS [training: 0.6500878076132351 | validation: 0.916453979131725]
	TIME [epoch: 9.52 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6398100123635039		[learning rate: 7.1536e-05]
	Learning Rate: 7.15363e-05
	LOSS [training: 0.6398100123635039 | validation: 0.9135928504006876]
	TIME [epoch: 9.54 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6382382161341004		[learning rate: 7.1277e-05]
	Learning Rate: 7.12767e-05
	LOSS [training: 0.6382382161341004 | validation: 0.9065753555081975]
	TIME [epoch: 9.52 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6377432507452736		[learning rate: 7.1018e-05]
	Learning Rate: 7.1018e-05
	LOSS [training: 0.6377432507452736 | validation: 0.9200881755012847]
	TIME [epoch: 9.52 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6322737798986156		[learning rate: 7.076e-05]
	Learning Rate: 7.07603e-05
	LOSS [training: 0.6322737798986156 | validation: 0.9123358453768322]
	TIME [epoch: 9.52 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6434001167288375		[learning rate: 7.0503e-05]
	Learning Rate: 7.05035e-05
	LOSS [training: 0.6434001167288375 | validation: 0.9115460978118367]
	TIME [epoch: 9.53 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6456763545014919		[learning rate: 7.0248e-05]
	Learning Rate: 7.02476e-05
	LOSS [training: 0.6456763545014919 | validation: 0.9066147934839462]
	TIME [epoch: 9.51 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6320166407046495		[learning rate: 6.9993e-05]
	Learning Rate: 6.99927e-05
	LOSS [training: 0.6320166407046495 | validation: 0.9202678231846807]
	TIME [epoch: 9.53 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6400815492165449		[learning rate: 6.9739e-05]
	Learning Rate: 6.97387e-05
	LOSS [training: 0.6400815492165449 | validation: 0.9152666751785026]
	TIME [epoch: 9.53 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6339380163189997		[learning rate: 6.9486e-05]
	Learning Rate: 6.94856e-05
	LOSS [training: 0.6339380163189997 | validation: 0.8864598266045816]
	TIME [epoch: 9.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_1467.pth
	Model improved!!!
EPOCH 1468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6352011492642162		[learning rate: 6.9233e-05]
	Learning Rate: 6.92334e-05
	LOSS [training: 0.6352011492642162 | validation: 0.9171286432791987]
	TIME [epoch: 9.52 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6399139120766417		[learning rate: 6.8982e-05]
	Learning Rate: 6.89822e-05
	LOSS [training: 0.6399139120766417 | validation: 0.8948878523627036]
	TIME [epoch: 9.52 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6332545019864211		[learning rate: 6.8732e-05]
	Learning Rate: 6.87318e-05
	LOSS [training: 0.6332545019864211 | validation: 0.9321978140706273]
	TIME [epoch: 9.52 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6516704672567428		[learning rate: 6.8482e-05]
	Learning Rate: 6.84824e-05
	LOSS [training: 0.6516704672567428 | validation: 0.9097366723193777]
	TIME [epoch: 9.53 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.632056560644537		[learning rate: 6.8234e-05]
	Learning Rate: 6.82339e-05
	LOSS [training: 0.632056560644537 | validation: 0.8980128201236083]
	TIME [epoch: 9.51 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6367736655256092		[learning rate: 6.7986e-05]
	Learning Rate: 6.79862e-05
	LOSS [training: 0.6367736655256092 | validation: 0.8998597540105849]
	TIME [epoch: 9.53 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6325484937755593		[learning rate: 6.774e-05]
	Learning Rate: 6.77395e-05
	LOSS [training: 0.6325484937755593 | validation: 0.9225760208340306]
	TIME [epoch: 9.54 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6539597568371687		[learning rate: 6.7494e-05]
	Learning Rate: 6.74937e-05
	LOSS [training: 0.6539597568371687 | validation: 0.9581500825129511]
	TIME [epoch: 9.53 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.640141777837562		[learning rate: 6.7249e-05]
	Learning Rate: 6.72488e-05
	LOSS [training: 0.640141777837562 | validation: 0.9167089438907177]
	TIME [epoch: 9.52 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6536024433869266		[learning rate: 6.7005e-05]
	Learning Rate: 6.70047e-05
	LOSS [training: 0.6536024433869266 | validation: 0.9093753832231384]
	TIME [epoch: 9.51 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6468157634714724		[learning rate: 6.6762e-05]
	Learning Rate: 6.67616e-05
	LOSS [training: 0.6468157634714724 | validation: 0.8960425085396313]
	TIME [epoch: 9.54 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6353291042540733		[learning rate: 6.6519e-05]
	Learning Rate: 6.65192e-05
	LOSS [training: 0.6353291042540733 | validation: 0.9126879338061662]
	TIME [epoch: 9.52 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6290617148798375		[learning rate: 6.6278e-05]
	Learning Rate: 6.62778e-05
	LOSS [training: 0.6290617148798375 | validation: 0.9192505999631624]
	TIME [epoch: 9.52 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6497583674360916		[learning rate: 6.6037e-05]
	Learning Rate: 6.60373e-05
	LOSS [training: 0.6497583674360916 | validation: 0.895139091601254]
	TIME [epoch: 9.52 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6397298162901123		[learning rate: 6.5798e-05]
	Learning Rate: 6.57977e-05
	LOSS [training: 0.6397298162901123 | validation: 0.9219348926659575]
	TIME [epoch: 9.56 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6441847147073505		[learning rate: 6.5559e-05]
	Learning Rate: 6.55589e-05
	LOSS [training: 0.6441847147073505 | validation: 0.9481871441826933]
	TIME [epoch: 9.53 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6457514731984375		[learning rate: 6.5321e-05]
	Learning Rate: 6.5321e-05
	LOSS [training: 0.6457514731984375 | validation: 0.9379558688008177]
	TIME [epoch: 9.52 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6441833293571273		[learning rate: 6.5084e-05]
	Learning Rate: 6.50839e-05
	LOSS [training: 0.6441833293571273 | validation: 0.9128866228673246]
	TIME [epoch: 9.52 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6425750932551564		[learning rate: 6.4848e-05]
	Learning Rate: 6.48477e-05
	LOSS [training: 0.6425750932551564 | validation: 0.9185019226404887]
	TIME [epoch: 9.55 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6337510898419302		[learning rate: 6.4612e-05]
	Learning Rate: 6.46124e-05
	LOSS [training: 0.6337510898419302 | validation: 0.9216210522705788]
	TIME [epoch: 9.52 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6436791706102347		[learning rate: 6.4378e-05]
	Learning Rate: 6.43779e-05
	LOSS [training: 0.6436791706102347 | validation: 0.9179787115379417]
	TIME [epoch: 9.53 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6330583271049642		[learning rate: 6.4144e-05]
	Learning Rate: 6.41443e-05
	LOSS [training: 0.6330583271049642 | validation: 0.9110945961911259]
	TIME [epoch: 9.54 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6347997868629968		[learning rate: 6.3911e-05]
	Learning Rate: 6.39115e-05
	LOSS [training: 0.6347997868629968 | validation: 0.9045321716064]
	TIME [epoch: 9.54 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6456516271989181		[learning rate: 6.368e-05]
	Learning Rate: 6.36795e-05
	LOSS [training: 0.6456516271989181 | validation: 0.9086482346145003]
	TIME [epoch: 9.53 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6383271977359933		[learning rate: 6.3448e-05]
	Learning Rate: 6.34485e-05
	LOSS [training: 0.6383271977359933 | validation: 0.887113602025723]
	TIME [epoch: 9.52 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6377016996538964		[learning rate: 6.3218e-05]
	Learning Rate: 6.32182e-05
	LOSS [training: 0.6377016996538964 | validation: 0.9026033185288777]
	TIME [epoch: 9.54 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6420804986182592		[learning rate: 6.2989e-05]
	Learning Rate: 6.29888e-05
	LOSS [training: 0.6420804986182592 | validation: 0.8945893948733195]
	TIME [epoch: 9.53 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6396110527843903		[learning rate: 6.276e-05]
	Learning Rate: 6.27602e-05
	LOSS [training: 0.6396110527843903 | validation: 0.898567042227139]
	TIME [epoch: 9.51 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6399259765005489		[learning rate: 6.2532e-05]
	Learning Rate: 6.25324e-05
	LOSS [training: 0.6399259765005489 | validation: 0.9123023042505537]
	TIME [epoch: 9.54 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6338218571405088		[learning rate: 6.2305e-05]
	Learning Rate: 6.23055e-05
	LOSS [training: 0.6338218571405088 | validation: 0.9201268690204891]
	TIME [epoch: 9.54 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6514946396549786		[learning rate: 6.2079e-05]
	Learning Rate: 6.20794e-05
	LOSS [training: 0.6514946396549786 | validation: 0.921472065179436]
	TIME [epoch: 9.51 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6296559823437095		[learning rate: 6.1854e-05]
	Learning Rate: 6.18541e-05
	LOSS [training: 0.6296559823437095 | validation: 0.9084797180188207]
	TIME [epoch: 9.53 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6448715762732358		[learning rate: 6.163e-05]
	Learning Rate: 6.16296e-05
	LOSS [training: 0.6448715762732358 | validation: 0.918458726257686]
	TIME [epoch: 9.53 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6331856140538082		[learning rate: 6.1406e-05]
	Learning Rate: 6.1406e-05
	LOSS [training: 0.6331856140538082 | validation: 0.9205357293609984]
	TIME [epoch: 9.54 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6312678371926456		[learning rate: 6.1183e-05]
	Learning Rate: 6.11831e-05
	LOSS [training: 0.6312678371926456 | validation: 0.9187953653296854]
	TIME [epoch: 9.52 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6393011132756884		[learning rate: 6.0961e-05]
	Learning Rate: 6.09611e-05
	LOSS [training: 0.6393011132756884 | validation: 0.9123546332906652]
	TIME [epoch: 9.53 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6241808056303983		[learning rate: 6.074e-05]
	Learning Rate: 6.07399e-05
	LOSS [training: 0.6241808056303983 | validation: 0.9004048117923451]
	TIME [epoch: 9.53 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6396983367994807		[learning rate: 6.0519e-05]
	Learning Rate: 6.05194e-05
	LOSS [training: 0.6396983367994807 | validation: 0.9235713064226494]
	TIME [epoch: 9.54 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6366739705473179		[learning rate: 6.03e-05]
	Learning Rate: 6.02998e-05
	LOSS [training: 0.6366739705473179 | validation: 0.9063897654360886]
	TIME [epoch: 9.53 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.633828640589815		[learning rate: 6.0081e-05]
	Learning Rate: 6.0081e-05
	LOSS [training: 0.633828640589815 | validation: 0.9119796519111512]
	TIME [epoch: 9.53 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6390792920132864		[learning rate: 5.9863e-05]
	Learning Rate: 5.98629e-05
	LOSS [training: 0.6390792920132864 | validation: 0.9078905098919084]
	TIME [epoch: 9.53 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6461941530718308		[learning rate: 5.9646e-05]
	Learning Rate: 5.96457e-05
	LOSS [training: 0.6461941530718308 | validation: 0.9011882130378307]
	TIME [epoch: 9.54 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6365864898215866		[learning rate: 5.9429e-05]
	Learning Rate: 5.94292e-05
	LOSS [training: 0.6365864898215866 | validation: 0.8942194227634442]
	TIME [epoch: 9.54 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6485398122415007		[learning rate: 5.9214e-05]
	Learning Rate: 5.92136e-05
	LOSS [training: 0.6485398122415007 | validation: 0.901748529291761]
	TIME [epoch: 9.53 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6342278563183751		[learning rate: 5.8999e-05]
	Learning Rate: 5.89987e-05
	LOSS [training: 0.6342278563183751 | validation: 0.9176815856115479]
	TIME [epoch: 9.54 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6396857624974152		[learning rate: 5.8785e-05]
	Learning Rate: 5.87846e-05
	LOSS [training: 0.6396857624974152 | validation: 0.9171604060661457]
	TIME [epoch: 9.52 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6475074434097511		[learning rate: 5.8571e-05]
	Learning Rate: 5.85712e-05
	LOSS [training: 0.6475074434097511 | validation: 0.9146030690649302]
	TIME [epoch: 9.54 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6407689910192316		[learning rate: 5.8359e-05]
	Learning Rate: 5.83586e-05
	LOSS [training: 0.6407689910192316 | validation: 0.9187930067729774]
	TIME [epoch: 9.53 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6479211878530234		[learning rate: 5.8147e-05]
	Learning Rate: 5.81469e-05
	LOSS [training: 0.6479211878530234 | validation: 0.9073447736460816]
	TIME [epoch: 9.55 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6372430604950392		[learning rate: 5.7936e-05]
	Learning Rate: 5.79358e-05
	LOSS [training: 0.6372430604950392 | validation: 0.9080101173196373]
	TIME [epoch: 9.53 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6422546602864765		[learning rate: 5.7726e-05]
	Learning Rate: 5.77256e-05
	LOSS [training: 0.6422546602864765 | validation: 0.9229569211654186]
	TIME [epoch: 9.52 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.63754831908912		[learning rate: 5.7516e-05]
	Learning Rate: 5.75161e-05
	LOSS [training: 0.63754831908912 | validation: 0.9268379909214711]
	TIME [epoch: 9.53 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6266487062907651		[learning rate: 5.7307e-05]
	Learning Rate: 5.73074e-05
	LOSS [training: 0.6266487062907651 | validation: 0.9057495389331899]
	TIME [epoch: 9.56 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6306044262240287		[learning rate: 5.7099e-05]
	Learning Rate: 5.70994e-05
	LOSS [training: 0.6306044262240287 | validation: 0.8924207648011659]
	TIME [epoch: 9.51 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6251403218478478		[learning rate: 5.6892e-05]
	Learning Rate: 5.68922e-05
	LOSS [training: 0.6251403218478478 | validation: 0.8992989430867349]
	TIME [epoch: 9.52 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6372859843858502		[learning rate: 5.6686e-05]
	Learning Rate: 5.66857e-05
	LOSS [training: 0.6372859843858502 | validation: 0.894765657761715]
	TIME [epoch: 9.54 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6327964200184011		[learning rate: 5.648e-05]
	Learning Rate: 5.648e-05
	LOSS [training: 0.6327964200184011 | validation: 0.9169779415199335]
	TIME [epoch: 9.54 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6335112274205382		[learning rate: 5.6275e-05]
	Learning Rate: 5.6275e-05
	LOSS [training: 0.6335112274205382 | validation: 0.8987538674893757]
	TIME [epoch: 9.53 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6395857127280695		[learning rate: 5.6071e-05]
	Learning Rate: 5.60708e-05
	LOSS [training: 0.6395857127280695 | validation: 0.9110324421194571]
	TIME [epoch: 9.53 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6383147493426244		[learning rate: 5.5867e-05]
	Learning Rate: 5.58673e-05
	LOSS [training: 0.6383147493426244 | validation: 0.9175979677493813]
	TIME [epoch: 9.53 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.646495701444066		[learning rate: 5.5665e-05]
	Learning Rate: 5.56646e-05
	LOSS [training: 0.646495701444066 | validation: 0.9105858821666274]
	TIME [epoch: 9.54 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6365507903514483		[learning rate: 5.5463e-05]
	Learning Rate: 5.54626e-05
	LOSS [training: 0.6365507903514483 | validation: 0.8983622441779463]
	TIME [epoch: 9.52 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6412354123680241		[learning rate: 5.5261e-05]
	Learning Rate: 5.52613e-05
	LOSS [training: 0.6412354123680241 | validation: 0.9203073865816339]
	TIME [epoch: 9.53 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6373158564692936		[learning rate: 5.5061e-05]
	Learning Rate: 5.50608e-05
	LOSS [training: 0.6373158564692936 | validation: 0.9117526758240314]
	TIME [epoch: 9.54 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.646814657366215		[learning rate: 5.4861e-05]
	Learning Rate: 5.48609e-05
	LOSS [training: 0.646814657366215 | validation: 0.9039130905799226]
	TIME [epoch: 9.53 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6395215669805063		[learning rate: 5.4662e-05]
	Learning Rate: 5.46618e-05
	LOSS [training: 0.6395215669805063 | validation: 0.8959416228647937]
	TIME [epoch: 9.52 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6404048612668974		[learning rate: 5.4463e-05]
	Learning Rate: 5.44635e-05
	LOSS [training: 0.6404048612668974 | validation: 0.9148897821164067]
	TIME [epoch: 9.53 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6354674308200724		[learning rate: 5.4266e-05]
	Learning Rate: 5.42658e-05
	LOSS [training: 0.6354674308200724 | validation: 0.9182359708582237]
	TIME [epoch: 9.55 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.639615182462949		[learning rate: 5.4069e-05]
	Learning Rate: 5.40689e-05
	LOSS [training: 0.639615182462949 | validation: 0.9180490849034183]
	TIME [epoch: 9.52 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.650709005093218		[learning rate: 5.3873e-05]
	Learning Rate: 5.38727e-05
	LOSS [training: 0.650709005093218 | validation: 0.9250217911548544]
	TIME [epoch: 9.52 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6371698131811789		[learning rate: 5.3677e-05]
	Learning Rate: 5.36772e-05
	LOSS [training: 0.6371698131811789 | validation: 0.90326744610316]
	TIME [epoch: 9.54 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6433902160578097		[learning rate: 5.3482e-05]
	Learning Rate: 5.34824e-05
	LOSS [training: 0.6433902160578097 | validation: 0.9258579441068945]
	TIME [epoch: 9.54 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6372042720839086		[learning rate: 5.3288e-05]
	Learning Rate: 5.32883e-05
	LOSS [training: 0.6372042720839086 | validation: 0.9337015607296468]
	TIME [epoch: 9.52 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6432522056468317		[learning rate: 5.3095e-05]
	Learning Rate: 5.30949e-05
	LOSS [training: 0.6432522056468317 | validation: 0.944839897948005]
	TIME [epoch: 9.52 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6443881678179939		[learning rate: 5.2902e-05]
	Learning Rate: 5.29022e-05
	LOSS [training: 0.6443881678179939 | validation: 0.916598873280593]
	TIME [epoch: 9.54 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6410852908204756		[learning rate: 5.271e-05]
	Learning Rate: 5.27102e-05
	LOSS [training: 0.6410852908204756 | validation: 0.912669163195815]
	TIME [epoch: 9.53 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6544226328308552		[learning rate: 5.2519e-05]
	Learning Rate: 5.25189e-05
	LOSS [training: 0.6544226328308552 | validation: 0.8868069735852536]
	TIME [epoch: 9.53 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6389495878225858		[learning rate: 5.2328e-05]
	Learning Rate: 5.23283e-05
	LOSS [training: 0.6389495878225858 | validation: 0.9248950445900961]
	TIME [epoch: 9.54 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6336657410933142		[learning rate: 5.2138e-05]
	Learning Rate: 5.21384e-05
	LOSS [training: 0.6336657410933142 | validation: 0.9115377642286688]
	TIME [epoch: 9.56 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.640300966442213		[learning rate: 5.1949e-05]
	Learning Rate: 5.19492e-05
	LOSS [training: 0.640300966442213 | validation: 0.9088146225616458]
	TIME [epoch: 9.56 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6306398852969961		[learning rate: 5.1761e-05]
	Learning Rate: 5.17607e-05
	LOSS [training: 0.6306398852969961 | validation: 0.9130465392734319]
	TIME [epoch: 9.53 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6322695352730161		[learning rate: 5.1573e-05]
	Learning Rate: 5.15729e-05
	LOSS [training: 0.6322695352730161 | validation: 0.9059479082500238]
	TIME [epoch: 9.52 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6361607305894046		[learning rate: 5.1386e-05]
	Learning Rate: 5.13857e-05
	LOSS [training: 0.6361607305894046 | validation: 0.9296877942670858]
	TIME [epoch: 9.55 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6426868757829309		[learning rate: 5.1199e-05]
	Learning Rate: 5.11992e-05
	LOSS [training: 0.6426868757829309 | validation: 0.9245531392141288]
	TIME [epoch: 9.53 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6520565391291799		[learning rate: 5.1013e-05]
	Learning Rate: 5.10134e-05
	LOSS [training: 0.6520565391291799 | validation: 0.886772547888682]
	TIME [epoch: 9.53 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6403026218764275		[learning rate: 5.0828e-05]
	Learning Rate: 5.08283e-05
	LOSS [training: 0.6403026218764275 | validation: 0.9055794892853984]
	TIME [epoch: 9.52 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6486924742253182		[learning rate: 5.0644e-05]
	Learning Rate: 5.06438e-05
	LOSS [training: 0.6486924742253182 | validation: 0.910495510645223]
	TIME [epoch: 9.54 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6389184726714376		[learning rate: 5.046e-05]
	Learning Rate: 5.046e-05
	LOSS [training: 0.6389184726714376 | validation: 0.910488994494291]
	TIME [epoch: 9.53 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6409617455464294		[learning rate: 5.0277e-05]
	Learning Rate: 5.02769e-05
	LOSS [training: 0.6409617455464294 | validation: 0.904656547431274]
	TIME [epoch: 9.52 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6502922783011927		[learning rate: 5.0094e-05]
	Learning Rate: 5.00944e-05
	LOSS [training: 0.6502922783011927 | validation: 0.9044880688184429]
	TIME [epoch: 9.54 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6267049097157382		[learning rate: 4.9913e-05]
	Learning Rate: 4.99127e-05
	LOSS [training: 0.6267049097157382 | validation: 0.9194627519919125]
	TIME [epoch: 9.54 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6278857518693298		[learning rate: 4.9732e-05]
	Learning Rate: 4.97315e-05
	LOSS [training: 0.6278857518693298 | validation: 0.9109525987797644]
	TIME [epoch: 9.53 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6331468921291681		[learning rate: 4.9551e-05]
	Learning Rate: 4.9551e-05
	LOSS [training: 0.6331468921291681 | validation: 0.9010824671381343]
	TIME [epoch: 9.53 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6363992374799767		[learning rate: 4.9371e-05]
	Learning Rate: 4.93712e-05
	LOSS [training: 0.6363992374799767 | validation: 0.8996720366052519]
	TIME [epoch: 9.55 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6321004159150809		[learning rate: 4.9192e-05]
	Learning Rate: 4.9192e-05
	LOSS [training: 0.6321004159150809 | validation: 0.914574510664817]
	TIME [epoch: 9.53 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6353920117544407		[learning rate: 4.9014e-05]
	Learning Rate: 4.90135e-05
	LOSS [training: 0.6353920117544407 | validation: 0.9064896087922606]
	TIME [epoch: 9.52 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.627859465745688		[learning rate: 4.8836e-05]
	Learning Rate: 4.88356e-05
	LOSS [training: 0.627859465745688 | validation: 0.911391434095731]
	TIME [epoch: 9.53 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6382234414648449		[learning rate: 4.8658e-05]
	Learning Rate: 4.86584e-05
	LOSS [training: 0.6382234414648449 | validation: 0.913223438745133]
	TIME [epoch: 9.55 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6331785736167752		[learning rate: 4.8482e-05]
	Learning Rate: 4.84818e-05
	LOSS [training: 0.6331785736167752 | validation: 0.8979481297716586]
	TIME [epoch: 9.54 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6382901812011705		[learning rate: 4.8306e-05]
	Learning Rate: 4.83059e-05
	LOSS [training: 0.6382901812011705 | validation: 0.8974219238850586]
	TIME [epoch: 9.52 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6343318109412742		[learning rate: 4.8131e-05]
	Learning Rate: 4.81306e-05
	LOSS [training: 0.6343318109412742 | validation: 0.9006747756916778]
	TIME [epoch: 9.54 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6414710218336669		[learning rate: 4.7956e-05]
	Learning Rate: 4.79559e-05
	LOSS [training: 0.6414710218336669 | validation: 0.8834224158303627]
	TIME [epoch: 9.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_1569.pth
	Model improved!!!
EPOCH 1570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6393105922542984		[learning rate: 4.7782e-05]
	Learning Rate: 4.77819e-05
	LOSS [training: 0.6393105922542984 | validation: 0.9121719064421158]
	TIME [epoch: 9.53 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6285267867063424		[learning rate: 4.7608e-05]
	Learning Rate: 4.76085e-05
	LOSS [training: 0.6285267867063424 | validation: 0.9041302399662589]
	TIME [epoch: 9.52 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6292585515145831		[learning rate: 4.7436e-05]
	Learning Rate: 4.74357e-05
	LOSS [training: 0.6292585515145831 | validation: 0.9074410166354637]
	TIME [epoch: 9.54 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6289301198005257		[learning rate: 4.7264e-05]
	Learning Rate: 4.72636e-05
	LOSS [training: 0.6289301198005257 | validation: 0.9181124867853392]
	TIME [epoch: 9.55 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6398376435567027		[learning rate: 4.7092e-05]
	Learning Rate: 4.7092e-05
	LOSS [training: 0.6398376435567027 | validation: 0.8948531093193719]
	TIME [epoch: 9.53 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.632850989148414		[learning rate: 4.6921e-05]
	Learning Rate: 4.69211e-05
	LOSS [training: 0.632850989148414 | validation: 0.9098884037423429]
	TIME [epoch: 9.53 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6290970557345912		[learning rate: 4.6751e-05]
	Learning Rate: 4.67508e-05
	LOSS [training: 0.6290970557345912 | validation: 0.9084374218378528]
	TIME [epoch: 9.55 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6365557478923064		[learning rate: 4.6581e-05]
	Learning Rate: 4.65812e-05
	LOSS [training: 0.6365557478923064 | validation: 0.9066820455444995]
	TIME [epoch: 9.54 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6360075392502281		[learning rate: 4.6412e-05]
	Learning Rate: 4.64121e-05
	LOSS [training: 0.6360075392502281 | validation: 0.877912705405559]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_1578.pth
	Model improved!!!
EPOCH 1579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6436661058194053		[learning rate: 4.6244e-05]
	Learning Rate: 4.62437e-05
	LOSS [training: 0.6436661058194053 | validation: 0.9189683445591414]
	TIME [epoch: 9.54 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.644391370946984		[learning rate: 4.6076e-05]
	Learning Rate: 4.60759e-05
	LOSS [training: 0.644391370946984 | validation: 0.9099716797329961]
	TIME [epoch: 9.54 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6342705780571899		[learning rate: 4.5909e-05]
	Learning Rate: 4.59087e-05
	LOSS [training: 0.6342705780571899 | validation: 0.9008613086984062]
	TIME [epoch: 9.52 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6360168259428339		[learning rate: 4.5742e-05]
	Learning Rate: 4.57421e-05
	LOSS [training: 0.6360168259428339 | validation: 0.9117400346624459]
	TIME [epoch: 9.52 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6326595440905876		[learning rate: 4.5576e-05]
	Learning Rate: 4.55761e-05
	LOSS [training: 0.6326595440905876 | validation: 0.9217229711377783]
	TIME [epoch: 9.52 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.631001620338723		[learning rate: 4.5411e-05]
	Learning Rate: 4.54107e-05
	LOSS [training: 0.631001620338723 | validation: 0.9023990450043455]
	TIME [epoch: 9.55 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6307830863023967		[learning rate: 4.5246e-05]
	Learning Rate: 4.52459e-05
	LOSS [training: 0.6307830863023967 | validation: 0.920175572371075]
	TIME [epoch: 9.52 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6401155612500539		[learning rate: 4.5082e-05]
	Learning Rate: 4.50817e-05
	LOSS [training: 0.6401155612500539 | validation: 0.9183410861864494]
	TIME [epoch: 9.52 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6308796557639426		[learning rate: 4.4918e-05]
	Learning Rate: 4.49181e-05
	LOSS [training: 0.6308796557639426 | validation: 0.92168751362075]
	TIME [epoch: 9.53 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6270866866959612		[learning rate: 4.4755e-05]
	Learning Rate: 4.47551e-05
	LOSS [training: 0.6270866866959612 | validation: 0.9017485389687039]
	TIME [epoch: 9.55 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.631261170338161		[learning rate: 4.4593e-05]
	Learning Rate: 4.45926e-05
	LOSS [training: 0.631261170338161 | validation: 0.9044939921472991]
	TIME [epoch: 9.53 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6361112419984892		[learning rate: 4.4431e-05]
	Learning Rate: 4.44308e-05
	LOSS [training: 0.6361112419984892 | validation: 0.9096028531105076]
	TIME [epoch: 9.53 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6278780078586879		[learning rate: 4.427e-05]
	Learning Rate: 4.42696e-05
	LOSS [training: 0.6278780078586879 | validation: 0.9013705658272713]
	TIME [epoch: 9.53 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6372696841899608		[learning rate: 4.4109e-05]
	Learning Rate: 4.41089e-05
	LOSS [training: 0.6372696841899608 | validation: 0.937649912139386]
	TIME [epoch: 9.53 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.626500073883419		[learning rate: 4.3949e-05]
	Learning Rate: 4.39489e-05
	LOSS [training: 0.626500073883419 | validation: 0.918543000459275]
	TIME [epoch: 9.52 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6232695287565047		[learning rate: 4.3789e-05]
	Learning Rate: 4.37893e-05
	LOSS [training: 0.6232695287565047 | validation: 0.8929340933787718]
	TIME [epoch: 9.53 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.635143909315908		[learning rate: 4.363e-05]
	Learning Rate: 4.36304e-05
	LOSS [training: 0.635143909315908 | validation: 0.890209352326672]
	TIME [epoch: 9.54 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.647580580992315		[learning rate: 4.3472e-05]
	Learning Rate: 4.34721e-05
	LOSS [training: 0.647580580992315 | validation: 0.9002641518910978]
	TIME [epoch: 9.52 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6301539552813605		[learning rate: 4.3314e-05]
	Learning Rate: 4.33143e-05
	LOSS [training: 0.6301539552813605 | validation: 0.898300460233302]
	TIME [epoch: 9.52 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6314971172263453		[learning rate: 4.3157e-05]
	Learning Rate: 4.31571e-05
	LOSS [training: 0.6314971172263453 | validation: 0.9181876327095342]
	TIME [epoch: 9.52 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6355281022724448		[learning rate: 4.3001e-05]
	Learning Rate: 4.30005e-05
	LOSS [training: 0.6355281022724448 | validation: 0.9024598888205455]
	TIME [epoch: 9.55 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6250482938852325		[learning rate: 4.2844e-05]
	Learning Rate: 4.28445e-05
	LOSS [training: 0.6250482938852325 | validation: 0.9164536849700179]
	TIME [epoch: 9.52 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6398423184605931		[learning rate: 4.2689e-05]
	Learning Rate: 4.2689e-05
	LOSS [training: 0.6398423184605931 | validation: 0.9339550519069195]
	TIME [epoch: 9.52 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6447145952507991		[learning rate: 4.2534e-05]
	Learning Rate: 4.25341e-05
	LOSS [training: 0.6447145952507991 | validation: 0.903139335623286]
	TIME [epoch: 9.53 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6334510298251553		[learning rate: 4.238e-05]
	Learning Rate: 4.23797e-05
	LOSS [training: 0.6334510298251553 | validation: 0.9041872751836776]
	TIME [epoch: 9.54 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6335836391733938		[learning rate: 4.2226e-05]
	Learning Rate: 4.22259e-05
	LOSS [training: 0.6335836391733938 | validation: 0.8888452985838771]
	TIME [epoch: 9.52 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6405102920859325		[learning rate: 4.2073e-05]
	Learning Rate: 4.20727e-05
	LOSS [training: 0.6405102920859325 | validation: 0.9072199680005142]
	TIME [epoch: 9.53 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6281090991934545		[learning rate: 4.192e-05]
	Learning Rate: 4.192e-05
	LOSS [training: 0.6281090991934545 | validation: 0.8996141131992589]
	TIME [epoch: 9.52 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6335521111912807		[learning rate: 4.1768e-05]
	Learning Rate: 4.17679e-05
	LOSS [training: 0.6335521111912807 | validation: 0.8971552714753497]
	TIME [epoch: 9.53 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6390906197753067		[learning rate: 4.1616e-05]
	Learning Rate: 4.16163e-05
	LOSS [training: 0.6390906197753067 | validation: 0.9289177290289196]
	TIME [epoch: 9.53 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.640569285985396		[learning rate: 4.1465e-05]
	Learning Rate: 4.14652e-05
	LOSS [training: 0.640569285985396 | validation: 0.9026864105163808]
	TIME [epoch: 9.52 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6511282921444157		[learning rate: 4.1315e-05]
	Learning Rate: 4.13148e-05
	LOSS [training: 0.6511282921444157 | validation: 0.9116938896320395]
	TIME [epoch: 9.55 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6314270684888961		[learning rate: 4.1165e-05]
	Learning Rate: 4.11648e-05
	LOSS [training: 0.6314270684888961 | validation: 0.9105125657281536]
	TIME [epoch: 9.53 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6271352662067133		[learning rate: 4.1015e-05]
	Learning Rate: 4.10154e-05
	LOSS [training: 0.6271352662067133 | validation: 0.9047880076297449]
	TIME [epoch: 9.52 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6400132230220499		[learning rate: 4.0867e-05]
	Learning Rate: 4.08666e-05
	LOSS [training: 0.6400132230220499 | validation: 0.9007370584577402]
	TIME [epoch: 9.52 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6297407262385809		[learning rate: 4.0718e-05]
	Learning Rate: 4.07183e-05
	LOSS [training: 0.6297407262385809 | validation: 0.921605586846306]
	TIME [epoch: 9.54 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6397177755246041		[learning rate: 4.0571e-05]
	Learning Rate: 4.05705e-05
	LOSS [training: 0.6397177755246041 | validation: 0.9049968887586323]
	TIME [epoch: 9.52 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6498640001272287		[learning rate: 4.0423e-05]
	Learning Rate: 4.04233e-05
	LOSS [training: 0.6498640001272287 | validation: 0.9059177327564945]
	TIME [epoch: 9.52 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6330527532877922		[learning rate: 4.0277e-05]
	Learning Rate: 4.02766e-05
	LOSS [training: 0.6330527532877922 | validation: 0.9038616934401077]
	TIME [epoch: 9.52 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6355487991032973		[learning rate: 4.013e-05]
	Learning Rate: 4.01304e-05
	LOSS [training: 0.6355487991032973 | validation: 0.9026523514375719]
	TIME [epoch: 9.55 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6316137455572408		[learning rate: 3.9985e-05]
	Learning Rate: 3.99848e-05
	LOSS [training: 0.6316137455572408 | validation: 0.908386427858743]
	TIME [epoch: 9.53 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6423510842764169		[learning rate: 3.984e-05]
	Learning Rate: 3.98397e-05
	LOSS [training: 0.6423510842764169 | validation: 0.9125163056019231]
	TIME [epoch: 9.52 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6440671791352741		[learning rate: 3.9695e-05]
	Learning Rate: 3.96951e-05
	LOSS [training: 0.6440671791352741 | validation: 0.9230316885498318]
	TIME [epoch: 9.53 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6374524459168291		[learning rate: 3.9551e-05]
	Learning Rate: 3.9551e-05
	LOSS [training: 0.6374524459168291 | validation: 0.9061607634998664]
	TIME [epoch: 9.54 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6363968416532377		[learning rate: 3.9408e-05]
	Learning Rate: 3.94075e-05
	LOSS [training: 0.6363968416532377 | validation: 0.8879734882060308]
	TIME [epoch: 9.51 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6332663149239763		[learning rate: 3.9264e-05]
	Learning Rate: 3.92645e-05
	LOSS [training: 0.6332663149239763 | validation: 0.90509751903781]
	TIME [epoch: 9.52 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6456673029747437		[learning rate: 3.9122e-05]
	Learning Rate: 3.9122e-05
	LOSS [training: 0.6456673029747437 | validation: 0.9123826129188853]
	TIME [epoch: 9.53 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6417149303868901		[learning rate: 3.898e-05]
	Learning Rate: 3.898e-05
	LOSS [training: 0.6417149303868901 | validation: 0.896088809817372]
	TIME [epoch: 9.54 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6435049339097517		[learning rate: 3.8839e-05]
	Learning Rate: 3.88386e-05
	LOSS [training: 0.6435049339097517 | validation: 0.8964927601095174]
	TIME [epoch: 9.52 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6341157989404194		[learning rate: 3.8698e-05]
	Learning Rate: 3.86976e-05
	LOSS [training: 0.6341157989404194 | validation: 0.9164235299638355]
	TIME [epoch: 9.53 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6338516090228183		[learning rate: 3.8557e-05]
	Learning Rate: 3.85572e-05
	LOSS [training: 0.6338516090228183 | validation: 0.9129448511291424]
	TIME [epoch: 9.54 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6323865629280169		[learning rate: 3.8417e-05]
	Learning Rate: 3.84173e-05
	LOSS [training: 0.6323865629280169 | validation: 0.9028985245483492]
	TIME [epoch: 9.53 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6319817142078643		[learning rate: 3.8278e-05]
	Learning Rate: 3.82778e-05
	LOSS [training: 0.6319817142078643 | validation: 0.8986731001798575]
	TIME [epoch: 9.51 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6486154899666366		[learning rate: 3.8139e-05]
	Learning Rate: 3.81389e-05
	LOSS [training: 0.6486154899666366 | validation: 0.9032060901538548]
	TIME [epoch: 9.54 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6420565047220507		[learning rate: 3.8001e-05]
	Learning Rate: 3.80005e-05
	LOSS [training: 0.6420565047220507 | validation: 0.8855922008246655]
	TIME [epoch: 9.54 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6288543398747657		[learning rate: 3.7863e-05]
	Learning Rate: 3.78626e-05
	LOSS [training: 0.6288543398747657 | validation: 0.8987841750212465]
	TIME [epoch: 9.52 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6420258610990852		[learning rate: 3.7725e-05]
	Learning Rate: 3.77252e-05
	LOSS [training: 0.6420258610990852 | validation: 0.8929394817214218]
	TIME [epoch: 9.52 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6296951109796859		[learning rate: 3.7588e-05]
	Learning Rate: 3.75883e-05
	LOSS [training: 0.6296951109796859 | validation: 0.9163328189453926]
	TIME [epoch: 9.52 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6330600472568876		[learning rate: 3.7452e-05]
	Learning Rate: 3.74519e-05
	LOSS [training: 0.6330600472568876 | validation: 0.9016113500777203]
	TIME [epoch: 9.55 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6262188481888088		[learning rate: 3.7316e-05]
	Learning Rate: 3.7316e-05
	LOSS [training: 0.6262188481888088 | validation: 0.9002406725635266]
	TIME [epoch: 9.52 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.642871733996581		[learning rate: 3.7181e-05]
	Learning Rate: 3.71805e-05
	LOSS [training: 0.642871733996581 | validation: 0.9197315015515491]
	TIME [epoch: 9.51 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6301178470154986		[learning rate: 3.7046e-05]
	Learning Rate: 3.70456e-05
	LOSS [training: 0.6301178470154986 | validation: 0.9177098657703557]
	TIME [epoch: 9.53 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6265211765485892		[learning rate: 3.6911e-05]
	Learning Rate: 3.69112e-05
	LOSS [training: 0.6265211765485892 | validation: 0.8985168588785178]
	TIME [epoch: 9.53 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6307177496559101		[learning rate: 3.6777e-05]
	Learning Rate: 3.67772e-05
	LOSS [training: 0.6307177496559101 | validation: 0.9108382847941309]
	TIME [epoch: 9.53 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6377644300477463		[learning rate: 3.6644e-05]
	Learning Rate: 3.66438e-05
	LOSS [training: 0.6377644300477463 | validation: 0.9002873692614829]
	TIME [epoch: 9.52 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6345064774710266		[learning rate: 3.6511e-05]
	Learning Rate: 3.65108e-05
	LOSS [training: 0.6345064774710266 | validation: 0.9328828991299659]
	TIME [epoch: 9.55 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6362165326169771		[learning rate: 3.6378e-05]
	Learning Rate: 3.63783e-05
	LOSS [training: 0.6362165326169771 | validation: 0.9197161239381445]
	TIME [epoch: 9.53 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6327381004316776		[learning rate: 3.6246e-05]
	Learning Rate: 3.62463e-05
	LOSS [training: 0.6327381004316776 | validation: 0.911431595614788]
	TIME [epoch: 9.52 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6393190829756052		[learning rate: 3.6115e-05]
	Learning Rate: 3.61147e-05
	LOSS [training: 0.6393190829756052 | validation: 0.9046616812237028]
	TIME [epoch: 9.52 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6308960826201686		[learning rate: 3.5984e-05]
	Learning Rate: 3.59837e-05
	LOSS [training: 0.6308960826201686 | validation: 0.9063733635285326]
	TIME [epoch: 9.54 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6339297672108499		[learning rate: 3.5853e-05]
	Learning Rate: 3.58531e-05
	LOSS [training: 0.6339297672108499 | validation: 0.9000899225719116]
	TIME [epoch: 9.53 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6181689709607667		[learning rate: 3.5723e-05]
	Learning Rate: 3.5723e-05
	LOSS [training: 0.6181689709607667 | validation: 0.8959912717317184]
	TIME [epoch: 9.53 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6329992534955713		[learning rate: 3.5593e-05]
	Learning Rate: 3.55933e-05
	LOSS [training: 0.6329992534955713 | validation: 0.893865175908981]
	TIME [epoch: 9.51 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6220632728391428		[learning rate: 3.5464e-05]
	Learning Rate: 3.54641e-05
	LOSS [training: 0.6220632728391428 | validation: 0.8979396574179376]
	TIME [epoch: 9.54 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6371762873170673		[learning rate: 3.5335e-05]
	Learning Rate: 3.53354e-05
	LOSS [training: 0.6371762873170673 | validation: 0.9036154725247609]
	TIME [epoch: 9.52 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6210297873042201		[learning rate: 3.5207e-05]
	Learning Rate: 3.52072e-05
	LOSS [training: 0.6210297873042201 | validation: 0.8819987783301643]
	TIME [epoch: 9.52 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6360363769254515		[learning rate: 3.5079e-05]
	Learning Rate: 3.50794e-05
	LOSS [training: 0.6360363769254515 | validation: 0.90627746584359]
	TIME [epoch: 9.53 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6247414977496433		[learning rate: 3.4952e-05]
	Learning Rate: 3.49521e-05
	LOSS [training: 0.6247414977496433 | validation: 0.9113175199985389]
	TIME [epoch: 9.54 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6355554537695804		[learning rate: 3.4825e-05]
	Learning Rate: 3.48253e-05
	LOSS [training: 0.6355554537695804 | validation: 0.913465270733119]
	TIME [epoch: 9.52 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6349007008752965		[learning rate: 3.4699e-05]
	Learning Rate: 3.46989e-05
	LOSS [training: 0.6349007008752965 | validation: 0.9007703498062316]
	TIME [epoch: 9.52 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6421446803426709		[learning rate: 3.4573e-05]
	Learning Rate: 3.4573e-05
	LOSS [training: 0.6421446803426709 | validation: 0.9058637916902711]
	TIME [epoch: 9.53 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.633526526598351		[learning rate: 3.4448e-05]
	Learning Rate: 3.44475e-05
	LOSS [training: 0.633526526598351 | validation: 0.8942963278956628]
	TIME [epoch: 9.54 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6277426763144663		[learning rate: 3.4323e-05]
	Learning Rate: 3.43225e-05
	LOSS [training: 0.6277426763144663 | validation: 0.9146025962635017]
	TIME [epoch: 9.52 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6249890669345312		[learning rate: 3.4198e-05]
	Learning Rate: 3.4198e-05
	LOSS [training: 0.6249890669345312 | validation: 0.9049895396129563]
	TIME [epoch: 9.53 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.635063119528809		[learning rate: 3.4074e-05]
	Learning Rate: 3.40738e-05
	LOSS [training: 0.635063119528809 | validation: 0.9125943272587412]
	TIME [epoch: 9.54 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6402592876848188		[learning rate: 3.395e-05]
	Learning Rate: 3.39502e-05
	LOSS [training: 0.6402592876848188 | validation: 0.8935675800565618]
	TIME [epoch: 9.53 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6321447106234859		[learning rate: 3.3827e-05]
	Learning Rate: 3.3827e-05
	LOSS [training: 0.6321447106234859 | validation: 0.8997462521401723]
	TIME [epoch: 9.53 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6302113952144329		[learning rate: 3.3704e-05]
	Learning Rate: 3.37042e-05
	LOSS [training: 0.6302113952144329 | validation: 0.9273471549614162]
	TIME [epoch: 9.52 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6326387362721453		[learning rate: 3.3582e-05]
	Learning Rate: 3.35819e-05
	LOSS [training: 0.6326387362721453 | validation: 0.9122137886991528]
	TIME [epoch: 9.56 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6301973276577169		[learning rate: 3.346e-05]
	Learning Rate: 3.346e-05
	LOSS [training: 0.6301973276577169 | validation: 0.9102784333446786]
	TIME [epoch: 9.52 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6340214369553617		[learning rate: 3.3339e-05]
	Learning Rate: 3.33386e-05
	LOSS [training: 0.6340214369553617 | validation: 0.9104663512921323]
	TIME [epoch: 9.53 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6311368830846744		[learning rate: 3.3218e-05]
	Learning Rate: 3.32176e-05
	LOSS [training: 0.6311368830846744 | validation: 0.9035651036578853]
	TIME [epoch: 9.51 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6257609985022471		[learning rate: 3.3097e-05]
	Learning Rate: 3.30971e-05
	LOSS [training: 0.6257609985022471 | validation: 0.902611591928628]
	TIME [epoch: 9.56 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6370841675875123		[learning rate: 3.2977e-05]
	Learning Rate: 3.2977e-05
	LOSS [training: 0.6370841675875123 | validation: 0.8932958599759525]
	TIME [epoch: 9.52 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6304730682844957		[learning rate: 3.2857e-05]
	Learning Rate: 3.28573e-05
	LOSS [training: 0.6304730682844957 | validation: 0.9120141817484282]
	TIME [epoch: 9.54 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6438782490413433		[learning rate: 3.2738e-05]
	Learning Rate: 3.2738e-05
	LOSS [training: 0.6438782490413433 | validation: 0.9127974583177318]
	TIME [epoch: 9.52 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6318603971101362		[learning rate: 3.2619e-05]
	Learning Rate: 3.26192e-05
	LOSS [training: 0.6318603971101362 | validation: 0.9053591293185949]
	TIME [epoch: 9.55 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6384049173872274		[learning rate: 3.2501e-05]
	Learning Rate: 3.25009e-05
	LOSS [training: 0.6384049173872274 | validation: 0.8902934651307711]
	TIME [epoch: 9.52 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6369200897580578		[learning rate: 3.2383e-05]
	Learning Rate: 3.23829e-05
	LOSS [training: 0.6369200897580578 | validation: 0.8984354533615624]
	TIME [epoch: 9.53 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6345870618273126		[learning rate: 3.2265e-05]
	Learning Rate: 3.22654e-05
	LOSS [training: 0.6345870618273126 | validation: 0.9091277381000024]
	TIME [epoch: 9.55 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6351869869247677		[learning rate: 3.2148e-05]
	Learning Rate: 3.21483e-05
	LOSS [training: 0.6351869869247677 | validation: 0.8901002244549053]
	TIME [epoch: 9.54 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6284477777218946		[learning rate: 3.2032e-05]
	Learning Rate: 3.20316e-05
	LOSS [training: 0.6284477777218946 | validation: 0.9043847633575216]
	TIME [epoch: 9.53 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6298324426457226		[learning rate: 3.1915e-05]
	Learning Rate: 3.19154e-05
	LOSS [training: 0.6298324426457226 | validation: 0.8935787302906434]
	TIME [epoch: 9.54 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6339535782233928		[learning rate: 3.18e-05]
	Learning Rate: 3.17996e-05
	LOSS [training: 0.6339535782233928 | validation: 0.8943185817783555]
	TIME [epoch: 9.54 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6285393191699253		[learning rate: 3.1684e-05]
	Learning Rate: 3.16842e-05
	LOSS [training: 0.6285393191699253 | validation: 0.9292484989542378]
	TIME [epoch: 9.54 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6360027493062368		[learning rate: 3.1569e-05]
	Learning Rate: 3.15692e-05
	LOSS [training: 0.6360027493062368 | validation: 0.9197604024141299]
	TIME [epoch: 9.51 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6434356702911345		[learning rate: 3.1455e-05]
	Learning Rate: 3.14546e-05
	LOSS [training: 0.6434356702911345 | validation: 0.914219239739116]
	TIME [epoch: 9.53 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.629144983202948		[learning rate: 3.134e-05]
	Learning Rate: 3.13405e-05
	LOSS [training: 0.629144983202948 | validation: 0.9228270905898244]
	TIME [epoch: 9.54 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6245811017919289		[learning rate: 3.1227e-05]
	Learning Rate: 3.12267e-05
	LOSS [training: 0.6245811017919289 | validation: 0.9115378198073384]
	TIME [epoch: 9.52 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6282173627311172		[learning rate: 3.1113e-05]
	Learning Rate: 3.11134e-05
	LOSS [training: 0.6282173627311172 | validation: 0.8862053715344889]
	TIME [epoch: 9.52 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.63140212479743		[learning rate: 3.1e-05]
	Learning Rate: 3.10005e-05
	LOSS [training: 0.63140212479743 | validation: 0.8968967151884752]
	TIME [epoch: 9.54 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6270892907424044		[learning rate: 3.0888e-05]
	Learning Rate: 3.0888e-05
	LOSS [training: 0.6270892907424044 | validation: 0.9141519033038489]
	TIME [epoch: 9.56 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6458969628111655		[learning rate: 3.0776e-05]
	Learning Rate: 3.07759e-05
	LOSS [training: 0.6458969628111655 | validation: 0.9225133677781336]
	TIME [epoch: 9.53 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6489678427341972		[learning rate: 3.0664e-05]
	Learning Rate: 3.06642e-05
	LOSS [training: 0.6489678427341972 | validation: 0.9026069464026384]
	TIME [epoch: 9.54 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6457534678180521		[learning rate: 3.0553e-05]
	Learning Rate: 3.05529e-05
	LOSS [training: 0.6457534678180521 | validation: 0.9057149610858588]
	TIME [epoch: 9.53 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6388082651532253		[learning rate: 3.0442e-05]
	Learning Rate: 3.0442e-05
	LOSS [training: 0.6388082651532253 | validation: 0.9086090254553296]
	TIME [epoch: 9.54 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6419863829343869		[learning rate: 3.0332e-05]
	Learning Rate: 3.03316e-05
	LOSS [training: 0.6419863829343869 | validation: 0.9088356485848832]
	TIME [epoch: 9.53 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6340297237903376		[learning rate: 3.0221e-05]
	Learning Rate: 3.02215e-05
	LOSS [training: 0.6340297237903376 | validation: 0.8872607454984857]
	TIME [epoch: 9.53 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6497561681907991		[learning rate: 3.0112e-05]
	Learning Rate: 3.01118e-05
	LOSS [training: 0.6497561681907991 | validation: 0.9042935253651107]
	TIME [epoch: 9.55 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6435196440325807		[learning rate: 3.0003e-05]
	Learning Rate: 3.00025e-05
	LOSS [training: 0.6435196440325807 | validation: 0.9135767927308809]
	TIME [epoch: 9.54 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6382797558924607		[learning rate: 2.9894e-05]
	Learning Rate: 2.98936e-05
	LOSS [training: 0.6382797558924607 | validation: 0.8951569213468709]
	TIME [epoch: 9.53 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6367012407531419		[learning rate: 2.9785e-05]
	Learning Rate: 2.97852e-05
	LOSS [training: 0.6367012407531419 | validation: 0.9066169585110382]
	TIME [epoch: 9.53 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6501184803110073		[learning rate: 2.9677e-05]
	Learning Rate: 2.96771e-05
	LOSS [training: 0.6501184803110073 | validation: 0.8980763634286794]
	TIME [epoch: 9.54 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6350871422854049		[learning rate: 2.9569e-05]
	Learning Rate: 2.95694e-05
	LOSS [training: 0.6350871422854049 | validation: 0.8988902867685559]
	TIME [epoch: 9.53 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6310350960587388		[learning rate: 2.9462e-05]
	Learning Rate: 2.94621e-05
	LOSS [training: 0.6310350960587388 | validation: 0.9194188214334347]
	TIME [epoch: 9.52 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6308917347319084		[learning rate: 2.9355e-05]
	Learning Rate: 2.93551e-05
	LOSS [training: 0.6308917347319084 | validation: 0.9079013090849]
	TIME [epoch: 9.54 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6428043824248784		[learning rate: 2.9249e-05]
	Learning Rate: 2.92486e-05
	LOSS [training: 0.6428043824248784 | validation: 0.9165810131341162]
	TIME [epoch: 9.56 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6334223279420069		[learning rate: 2.9142e-05]
	Learning Rate: 2.91425e-05
	LOSS [training: 0.6334223279420069 | validation: 0.9138220865287514]
	TIME [epoch: 9.52 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6325552083844224		[learning rate: 2.9037e-05]
	Learning Rate: 2.90367e-05
	LOSS [training: 0.6325552083844224 | validation: 0.9033761965243845]
	TIME [epoch: 9.53 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6438196553210702		[learning rate: 2.8931e-05]
	Learning Rate: 2.89313e-05
	LOSS [training: 0.6438196553210702 | validation: 0.906084267320697]
	TIME [epoch: 9.52 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6432049958082614		[learning rate: 2.8826e-05]
	Learning Rate: 2.88263e-05
	LOSS [training: 0.6432049958082614 | validation: 0.9009085483210865]
	TIME [epoch: 9.55 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6369150640436371		[learning rate: 2.8722e-05]
	Learning Rate: 2.87217e-05
	LOSS [training: 0.6369150640436371 | validation: 0.9105735869336975]
	TIME [epoch: 9.52 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6292282176849697		[learning rate: 2.8617e-05]
	Learning Rate: 2.86175e-05
	LOSS [training: 0.6292282176849697 | validation: 0.9068655337028685]
	TIME [epoch: 9.53 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6339981884530086		[learning rate: 2.8514e-05]
	Learning Rate: 2.85136e-05
	LOSS [training: 0.6339981884530086 | validation: 0.9100373446696804]
	TIME [epoch: 9.53 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6315734571182873		[learning rate: 2.841e-05]
	Learning Rate: 2.84102e-05
	LOSS [training: 0.6315734571182873 | validation: 0.9009245980436551]
	TIME [epoch: 9.54 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6483811148332991		[learning rate: 2.8307e-05]
	Learning Rate: 2.83071e-05
	LOSS [training: 0.6483811148332991 | validation: 0.8943580385789345]
	TIME [epoch: 9.53 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6365496069779246		[learning rate: 2.8204e-05]
	Learning Rate: 2.82043e-05
	LOSS [training: 0.6365496069779246 | validation: 0.8998527096223239]
	TIME [epoch: 9.52 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6269595840251869		[learning rate: 2.8102e-05]
	Learning Rate: 2.8102e-05
	LOSS [training: 0.6269595840251869 | validation: 0.9011183261866011]
	TIME [epoch: 9.55 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6413469399896207		[learning rate: 2.8e-05]
	Learning Rate: 2.8e-05
	LOSS [training: 0.6413469399896207 | validation: 0.8934987275506896]
	TIME [epoch: 9.53 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6287788348553638		[learning rate: 2.7898e-05]
	Learning Rate: 2.78984e-05
	LOSS [training: 0.6287788348553638 | validation: 0.908143101911866]
	TIME [epoch: 9.54 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6447915243160095		[learning rate: 2.7797e-05]
	Learning Rate: 2.77971e-05
	LOSS [training: 0.6447915243160095 | validation: 0.9060864404217316]
	TIME [epoch: 9.53 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6351617235902463		[learning rate: 2.7696e-05]
	Learning Rate: 2.76963e-05
	LOSS [training: 0.6351617235902463 | validation: 0.9030090688368909]
	TIME [epoch: 9.55 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6446125318881433		[learning rate: 2.7596e-05]
	Learning Rate: 2.75957e-05
	LOSS [training: 0.6446125318881433 | validation: 0.9038148390760707]
	TIME [epoch: 9.54 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.634743095595165		[learning rate: 2.7496e-05]
	Learning Rate: 2.74956e-05
	LOSS [training: 0.634743095595165 | validation: 0.9228832063601142]
	TIME [epoch: 9.53 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6325177838273868		[learning rate: 2.7396e-05]
	Learning Rate: 2.73958e-05
	LOSS [training: 0.6325177838273868 | validation: 0.9099662507950459]
	TIME [epoch: 9.54 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6393152757091548		[learning rate: 2.7296e-05]
	Learning Rate: 2.72964e-05
	LOSS [training: 0.6393152757091548 | validation: 0.9096311126686388]
	TIME [epoch: 9.54 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6356994772723953		[learning rate: 2.7197e-05]
	Learning Rate: 2.71973e-05
	LOSS [training: 0.6356994772723953 | validation: 0.9143021861612849]
	TIME [epoch: 9.53 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6315056907332648		[learning rate: 2.7099e-05]
	Learning Rate: 2.70986e-05
	LOSS [training: 0.6315056907332648 | validation: 0.8898301497379555]
	TIME [epoch: 9.53 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6483600191729587		[learning rate: 2.7e-05]
	Learning Rate: 2.70003e-05
	LOSS [training: 0.6483600191729587 | validation: 0.8954364813055267]
	TIME [epoch: 9.54 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6300473943435619		[learning rate: 2.6902e-05]
	Learning Rate: 2.69023e-05
	LOSS [training: 0.6300473943435619 | validation: 0.9165493361650225]
	TIME [epoch: 9.54 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6337233073191599		[learning rate: 2.6805e-05]
	Learning Rate: 2.68047e-05
	LOSS [training: 0.6337233073191599 | validation: 0.8892994618852859]
	TIME [epoch: 9.52 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6337875700619824		[learning rate: 2.6707e-05]
	Learning Rate: 2.67074e-05
	LOSS [training: 0.6337875700619824 | validation: 0.8984841238466277]
	TIME [epoch: 9.52 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6361792049677983		[learning rate: 2.661e-05]
	Learning Rate: 2.66105e-05
	LOSS [training: 0.6361792049677983 | validation: 0.9015257680039386]
	TIME [epoch: 9.53 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6356426166538854		[learning rate: 2.6514e-05]
	Learning Rate: 2.65139e-05
	LOSS [training: 0.6356426166538854 | validation: 0.9001250060513581]
	TIME [epoch: 9.54 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.636770022985977		[learning rate: 2.6418e-05]
	Learning Rate: 2.64177e-05
	LOSS [training: 0.636770022985977 | validation: 0.8999153823442632]
	TIME [epoch: 9.52 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.637029076815865		[learning rate: 2.6322e-05]
	Learning Rate: 2.63218e-05
	LOSS [training: 0.637029076815865 | validation: 0.9128839370567188]
	TIME [epoch: 9.52 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6394297511293725		[learning rate: 2.6226e-05]
	Learning Rate: 2.62263e-05
	LOSS [training: 0.6394297511293725 | validation: 0.8913876238584174]
	TIME [epoch: 9.55 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6312245127733368		[learning rate: 2.6131e-05]
	Learning Rate: 2.61311e-05
	LOSS [training: 0.6312245127733368 | validation: 0.8874541363530725]
	TIME [epoch: 9.54 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6367754243923429		[learning rate: 2.6036e-05]
	Learning Rate: 2.60363e-05
	LOSS [training: 0.6367754243923429 | validation: 0.9236396529504461]
	TIME [epoch: 9.53 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6372894316709926		[learning rate: 2.5942e-05]
	Learning Rate: 2.59418e-05
	LOSS [training: 0.6372894316709926 | validation: 0.9041850734167978]
	TIME [epoch: 9.53 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6276870607408216		[learning rate: 2.5848e-05]
	Learning Rate: 2.58477e-05
	LOSS [training: 0.6276870607408216 | validation: 0.9118586887166924]
	TIME [epoch: 9.55 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6339519933317845		[learning rate: 2.5754e-05]
	Learning Rate: 2.57539e-05
	LOSS [training: 0.6339519933317845 | validation: 0.9226172622554007]
	TIME [epoch: 9.53 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6329585212432673		[learning rate: 2.566e-05]
	Learning Rate: 2.56604e-05
	LOSS [training: 0.6329585212432673 | validation: 0.9211998062393773]
	TIME [epoch: 9.52 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6297100720903873		[learning rate: 2.5567e-05]
	Learning Rate: 2.55673e-05
	LOSS [training: 0.6297100720903873 | validation: 0.9055911934508687]
	TIME [epoch: 9.53 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6278497299709158		[learning rate: 2.5474e-05]
	Learning Rate: 2.54745e-05
	LOSS [training: 0.6278497299709158 | validation: 0.9081629477534565]
	TIME [epoch: 9.55 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6427719041014056		[learning rate: 2.5382e-05]
	Learning Rate: 2.5382e-05
	LOSS [training: 0.6427719041014056 | validation: 0.9072373941652275]
	TIME [epoch: 9.53 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6363370779460564		[learning rate: 2.529e-05]
	Learning Rate: 2.52899e-05
	LOSS [training: 0.6363370779460564 | validation: 0.9119772859965981]
	TIME [epoch: 9.53 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.640510202302461		[learning rate: 2.5198e-05]
	Learning Rate: 2.51981e-05
	LOSS [training: 0.640510202302461 | validation: 0.8996415853339752]
	TIME [epoch: 9.53 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6453294447229061		[learning rate: 2.5107e-05]
	Learning Rate: 2.51067e-05
	LOSS [training: 0.6453294447229061 | validation: 0.8945185548104534]
	TIME [epoch: 9.54 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6372916141049071		[learning rate: 2.5016e-05]
	Learning Rate: 2.50156e-05
	LOSS [training: 0.6372916141049071 | validation: 0.885861381398558]
	TIME [epoch: 9.53 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6198340656443901		[learning rate: 2.4925e-05]
	Learning Rate: 2.49248e-05
	LOSS [training: 0.6198340656443901 | validation: 0.8876778286596053]
	TIME [epoch: 9.52 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6310812356850876		[learning rate: 2.4834e-05]
	Learning Rate: 2.48343e-05
	LOSS [training: 0.6310812356850876 | validation: 0.8945491917354016]
	TIME [epoch: 9.54 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6216292378526211		[learning rate: 2.4744e-05]
	Learning Rate: 2.47442e-05
	LOSS [training: 0.6216292378526211 | validation: 0.8973543300737866]
	TIME [epoch: 9.53 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6292694870684465		[learning rate: 2.4654e-05]
	Learning Rate: 2.46544e-05
	LOSS [training: 0.6292694870684465 | validation: 0.8986760950871662]
	TIME [epoch: 9.53 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6355761476519799		[learning rate: 2.4565e-05]
	Learning Rate: 2.45649e-05
	LOSS [training: 0.6355761476519799 | validation: 0.8950342978920196]
	TIME [epoch: 9.53 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.634412341623171		[learning rate: 2.4476e-05]
	Learning Rate: 2.44758e-05
	LOSS [training: 0.634412341623171 | validation: 0.912520395327424]
	TIME [epoch: 9.55 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6305924982097778		[learning rate: 2.4387e-05]
	Learning Rate: 2.4387e-05
	LOSS [training: 0.6305924982097778 | validation: 0.9196625205738604]
	TIME [epoch: 9.54 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.637363895407729		[learning rate: 2.4298e-05]
	Learning Rate: 2.42985e-05
	LOSS [training: 0.637363895407729 | validation: 0.9111941837204881]
	TIME [epoch: 9.53 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.63226840929972		[learning rate: 2.421e-05]
	Learning Rate: 2.42103e-05
	LOSS [training: 0.63226840929972 | validation: 0.909373085676448]
	TIME [epoch: 9.53 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6327097857766115		[learning rate: 2.4122e-05]
	Learning Rate: 2.41224e-05
	LOSS [training: 0.6327097857766115 | validation: 0.8910241109903504]
	TIME [epoch: 9.54 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6372241689284248		[learning rate: 2.4035e-05]
	Learning Rate: 2.40349e-05
	LOSS [training: 0.6372241689284248 | validation: 0.9021101191354624]
	TIME [epoch: 9.54 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6333541700140347		[learning rate: 2.3948e-05]
	Learning Rate: 2.39477e-05
	LOSS [training: 0.6333541700140347 | validation: 0.9203258015697319]
	TIME [epoch: 9.52 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6247609960894085		[learning rate: 2.3861e-05]
	Learning Rate: 2.38608e-05
	LOSS [training: 0.6247609960894085 | validation: 0.9059545145561723]
	TIME [epoch: 9.54 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.629536630284286		[learning rate: 2.3774e-05]
	Learning Rate: 2.37742e-05
	LOSS [training: 0.629536630284286 | validation: 0.9016740608478787]
	TIME [epoch: 9.54 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6364477147781423		[learning rate: 2.3688e-05]
	Learning Rate: 2.36879e-05
	LOSS [training: 0.6364477147781423 | validation: 0.8989496761748629]
	TIME [epoch: 9.53 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6272906121348402		[learning rate: 2.3602e-05]
	Learning Rate: 2.36019e-05
	LOSS [training: 0.6272906121348402 | validation: 0.8912586518052656]
	TIME [epoch: 9.52 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6320874605056999		[learning rate: 2.3516e-05]
	Learning Rate: 2.35163e-05
	LOSS [training: 0.6320874605056999 | validation: 0.8894287772796969]
	TIME [epoch: 9.55 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.641587888381523		[learning rate: 2.3431e-05]
	Learning Rate: 2.34309e-05
	LOSS [training: 0.641587888381523 | validation: 0.9103406498802674]
	TIME [epoch: 9.53 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6281538224609938		[learning rate: 2.3346e-05]
	Learning Rate: 2.33459e-05
	LOSS [training: 0.6281538224609938 | validation: 0.8933137236486269]
	TIME [epoch: 9.53 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6369494671832736		[learning rate: 2.3261e-05]
	Learning Rate: 2.32612e-05
	LOSS [training: 0.6369494671832736 | validation: 0.8933278640185388]
	TIME [epoch: 9.52 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6314180615463487		[learning rate: 2.3177e-05]
	Learning Rate: 2.31768e-05
	LOSS [training: 0.6314180615463487 | validation: 0.8955424074765074]
	TIME [epoch: 9.55 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6361850154643498		[learning rate: 2.3093e-05]
	Learning Rate: 2.30926e-05
	LOSS [training: 0.6361850154643498 | validation: 0.9139627275060227]
	TIME [epoch: 9.53 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6298933658299615		[learning rate: 2.3009e-05]
	Learning Rate: 2.30088e-05
	LOSS [training: 0.6298933658299615 | validation: 0.9078649916197955]
	TIME [epoch: 9.53 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.638469150251706		[learning rate: 2.2925e-05]
	Learning Rate: 2.29253e-05
	LOSS [training: 0.638469150251706 | validation: 0.9094105918769494]
	TIME [epoch: 9.53 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.636137811486644		[learning rate: 2.2842e-05]
	Learning Rate: 2.28421e-05
	LOSS [training: 0.636137811486644 | validation: 0.9100576746967722]
	TIME [epoch: 9.56 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.64394114507389		[learning rate: 2.2759e-05]
	Learning Rate: 2.27592e-05
	LOSS [training: 0.64394114507389 | validation: 0.8997613948250645]
	TIME [epoch: 9.54 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6434927429205184		[learning rate: 2.2677e-05]
	Learning Rate: 2.26767e-05
	LOSS [training: 0.6434927429205184 | validation: 0.8883702397933095]
	TIME [epoch: 9.54 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6267980347098898		[learning rate: 2.2594e-05]
	Learning Rate: 2.25944e-05
	LOSS [training: 0.6267980347098898 | validation: 0.9161323748065098]
	TIME [epoch: 9.53 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6374434504918306		[learning rate: 2.2512e-05]
	Learning Rate: 2.25124e-05
	LOSS [training: 0.6374434504918306 | validation: 0.8957478917321988]
	TIME [epoch: 9.55 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.642899329109399		[learning rate: 2.2431e-05]
	Learning Rate: 2.24307e-05
	LOSS [training: 0.642899329109399 | validation: 0.9081923797120064]
	TIME [epoch: 9.52 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6393986322654042		[learning rate: 2.2349e-05]
	Learning Rate: 2.23493e-05
	LOSS [training: 0.6393986322654042 | validation: 0.9126584952980852]
	TIME [epoch: 9.53 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6366239627492152		[learning rate: 2.2268e-05]
	Learning Rate: 2.22682e-05
	LOSS [training: 0.6366239627492152 | validation: 0.9147910074389544]
	TIME [epoch: 9.54 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6369161279625788		[learning rate: 2.2187e-05]
	Learning Rate: 2.21873e-05
	LOSS [training: 0.6369161279625788 | validation: 0.9141854997786498]
	TIME [epoch: 9.55 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6282488443618774		[learning rate: 2.2107e-05]
	Learning Rate: 2.21068e-05
	LOSS [training: 0.6282488443618774 | validation: 0.9221303163087851]
	TIME [epoch: 9.53 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.63843455865881		[learning rate: 2.2027e-05]
	Learning Rate: 2.20266e-05
	LOSS [training: 0.63843455865881 | validation: 0.8881793610143629]
	TIME [epoch: 9.54 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6388478872675671		[learning rate: 2.1947e-05]
	Learning Rate: 2.19467e-05
	LOSS [training: 0.6388478872675671 | validation: 0.8867398052575631]
	TIME [epoch: 9.55 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6341001893538646		[learning rate: 2.1867e-05]
	Learning Rate: 2.1867e-05
	LOSS [training: 0.6341001893538646 | validation: 0.908822343300238]
	TIME [epoch: 9.54 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6241826744751069		[learning rate: 2.1788e-05]
	Learning Rate: 2.17877e-05
	LOSS [training: 0.6241826744751069 | validation: 0.8981427773574643]
	TIME [epoch: 9.54 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6342515081502954		[learning rate: 2.1709e-05]
	Learning Rate: 2.17086e-05
	LOSS [training: 0.6342515081502954 | validation: 0.9053323331281236]
	TIME [epoch: 9.54 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6234790796698579		[learning rate: 2.163e-05]
	Learning Rate: 2.16298e-05
	LOSS [training: 0.6234790796698579 | validation: 0.9071262680423914]
	TIME [epoch: 9.56 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6383266689478415		[learning rate: 2.1551e-05]
	Learning Rate: 2.15513e-05
	LOSS [training: 0.6383266689478415 | validation: 0.9147478337619134]
	TIME [epoch: 9.54 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6331792296306402		[learning rate: 2.1473e-05]
	Learning Rate: 2.14731e-05
	LOSS [training: 0.6331792296306402 | validation: 0.9124274479310964]
	TIME [epoch: 9.54 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6335315896947475		[learning rate: 2.1395e-05]
	Learning Rate: 2.13952e-05
	LOSS [training: 0.6335315896947475 | validation: 0.888543795192524]
	TIME [epoch: 9.54 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6266714996711594		[learning rate: 2.1318e-05]
	Learning Rate: 2.13175e-05
	LOSS [training: 0.6266714996711594 | validation: 0.8923168049863062]
	TIME [epoch: 9.56 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6326976982825687		[learning rate: 2.124e-05]
	Learning Rate: 2.12402e-05
	LOSS [training: 0.6326976982825687 | validation: 0.9046756820920736]
	TIME [epoch: 9.53 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6372238250376953		[learning rate: 2.1163e-05]
	Learning Rate: 2.11631e-05
	LOSS [training: 0.6372238250376953 | validation: 0.9062575249429958]
	TIME [epoch: 9.54 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6361153523315781		[learning rate: 2.1086e-05]
	Learning Rate: 2.10863e-05
	LOSS [training: 0.6361153523315781 | validation: 0.895797270416544]
	TIME [epoch: 9.54 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6311732280619459		[learning rate: 2.101e-05]
	Learning Rate: 2.10098e-05
	LOSS [training: 0.6311732280619459 | validation: 0.8941474685472622]
	TIME [epoch: 9.56 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6378927452986467		[learning rate: 2.0934e-05]
	Learning Rate: 2.09335e-05
	LOSS [training: 0.6378927452986467 | validation: 0.9003505323556198]
	TIME [epoch: 9.52 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6416969095643654		[learning rate: 2.0858e-05]
	Learning Rate: 2.08575e-05
	LOSS [training: 0.6416969095643654 | validation: 0.8956257063204329]
	TIME [epoch: 9.54 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6301450639527779		[learning rate: 2.0782e-05]
	Learning Rate: 2.07819e-05
	LOSS [training: 0.6301450639527779 | validation: 0.9000483125987303]
	TIME [epoch: 9.54 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6371670867457319		[learning rate: 2.0706e-05]
	Learning Rate: 2.07064e-05
	LOSS [training: 0.6371670867457319 | validation: 0.8734531998931998]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2_fix_noise/tr_study205/model_tr_study205_r3_20240219_235153/states/model_tr_study205_1800.pth
	Model improved!!!
EPOCH 1801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6286048476360626		[learning rate: 2.0631e-05]
	Learning Rate: 2.06313e-05
	LOSS [training: 0.6286048476360626 | validation: 0.8966764884118275]
	TIME [epoch: 9.52 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6228010936142773		[learning rate: 2.0556e-05]
	Learning Rate: 2.05564e-05
	LOSS [training: 0.6228010936142773 | validation: 0.9240789882982865]
	TIME [epoch: 9.53 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6307543150770115		[learning rate: 2.0482e-05]
	Learning Rate: 2.04818e-05
	LOSS [training: 0.6307543150770115 | validation: 0.8988104969494123]
	TIME [epoch: 9.54 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6278311574868429		[learning rate: 2.0407e-05]
	Learning Rate: 2.04075e-05
	LOSS [training: 0.6278311574868429 | validation: 0.8987722259449785]
	TIME [epoch: 9.53 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6392199835135752		[learning rate: 2.0333e-05]
	Learning Rate: 2.03334e-05
	LOSS [training: 0.6392199835135752 | validation: 0.8895822494050092]
	TIME [epoch: 9.53 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6224331510302554		[learning rate: 2.026e-05]
	Learning Rate: 2.02596e-05
	LOSS [training: 0.6224331510302554 | validation: 0.9114506155692541]
	TIME [epoch: 9.53 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6280000615270376		[learning rate: 2.0186e-05]
	Learning Rate: 2.01861e-05
	LOSS [training: 0.6280000615270376 | validation: 0.9051304067178633]
	TIME [epoch: 9.56 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6256049158248358		[learning rate: 2.0113e-05]
	Learning Rate: 2.01129e-05
	LOSS [training: 0.6256049158248358 | validation: 0.9321160442845542]
	TIME [epoch: 9.54 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6254881928526819		[learning rate: 2.004e-05]
	Learning Rate: 2.00399e-05
	LOSS [training: 0.6254881928526819 | validation: 0.910405316577328]
	TIME [epoch: 9.53 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.634502611526174		[learning rate: 1.9967e-05]
	Learning Rate: 1.99671e-05
	LOSS [training: 0.634502611526174 | validation: 0.9044108887250074]
	TIME [epoch: 9.54 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6417415118472244		[learning rate: 1.9895e-05]
	Learning Rate: 1.98947e-05
	LOSS [training: 0.6417415118472244 | validation: 0.8956671265124354]
	TIME [epoch: 9.55 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6341242263104528		[learning rate: 1.9822e-05]
	Learning Rate: 1.98225e-05
	LOSS [training: 0.6341242263104528 | validation: 0.892407248557654]
	TIME [epoch: 9.53 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6331333321752985		[learning rate: 1.9751e-05]
	Learning Rate: 1.97505e-05
	LOSS [training: 0.6331333321752985 | validation: 0.9022117032736133]
	TIME [epoch: 9.54 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6389544547220541		[learning rate: 1.9679e-05]
	Learning Rate: 1.96789e-05
	LOSS [training: 0.6389544547220541 | validation: 0.8936248790440143]
	TIME [epoch: 9.53 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6370754757556805		[learning rate: 1.9607e-05]
	Learning Rate: 1.96074e-05
	LOSS [training: 0.6370754757556805 | validation: 0.9053462639542668]
	TIME [epoch: 9.55 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.640978211734894		[learning rate: 1.9536e-05]
	Learning Rate: 1.95363e-05
	LOSS [training: 0.640978211734894 | validation: 0.9083094229533074]
	TIME [epoch: 9.53 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6283041958005271		[learning rate: 1.9465e-05]
	Learning Rate: 1.94654e-05
	LOSS [training: 0.6283041958005271 | validation: 0.9073698904550412]
	TIME [epoch: 9.51 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6326569406612336		[learning rate: 1.9395e-05]
	Learning Rate: 1.93948e-05
	LOSS [training: 0.6326569406612336 | validation: 0.9142075254217226]
	TIME [epoch: 9.54 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6315319592932426		[learning rate: 1.9324e-05]
	Learning Rate: 1.93244e-05
	LOSS [training: 0.6315319592932426 | validation: 0.8943055173646113]
	TIME [epoch: 9.52 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6414861114512405		[learning rate: 1.9254e-05]
	Learning Rate: 1.92542e-05
	LOSS [training: 0.6414861114512405 | validation: 0.9069711564609546]
	TIME [epoch: 9.53 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6302466326428962		[learning rate: 1.9184e-05]
	Learning Rate: 1.91844e-05
	LOSS [training: 0.6302466326428962 | validation: 0.90927650951695]
	TIME [epoch: 9.52 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6259308366481426		[learning rate: 1.9115e-05]
	Learning Rate: 1.91147e-05
	LOSS [training: 0.6259308366481426 | validation: 0.9145697530982608]
	TIME [epoch: 9.54 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6284299301680153		[learning rate: 1.9045e-05]
	Learning Rate: 1.90454e-05
	LOSS [training: 0.6284299301680153 | validation: 0.9045964846922122]
	TIME [epoch: 9.53 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6305051875753632		[learning rate: 1.8976e-05]
	Learning Rate: 1.89763e-05
	LOSS [training: 0.6305051875753632 | validation: 0.9002079685852477]
	TIME [epoch: 9.53 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.631415722117342		[learning rate: 1.8907e-05]
	Learning Rate: 1.89074e-05
	LOSS [training: 0.631415722117342 | validation: 0.9026873936756019]
	TIME [epoch: 9.51 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.64084260961003		[learning rate: 1.8839e-05]
	Learning Rate: 1.88388e-05
	LOSS [training: 0.64084260961003 | validation: 0.9111436736261584]
	TIME [epoch: 9.54 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6198009669622311		[learning rate: 1.877e-05]
	Learning Rate: 1.87704e-05
	LOSS [training: 0.6198009669622311 | validation: 0.9004477291192846]
	TIME [epoch: 9.52 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6297836095987923		[learning rate: 1.8702e-05]
	Learning Rate: 1.87023e-05
	LOSS [training: 0.6297836095987923 | validation: 0.9041137926307881]
	TIME [epoch: 9.52 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6224238229681145		[learning rate: 1.8634e-05]
	Learning Rate: 1.86344e-05
	LOSS [training: 0.6224238229681145 | validation: 0.9117743538332337]
	TIME [epoch: 9.53 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6296878091968193		[learning rate: 1.8567e-05]
	Learning Rate: 1.85668e-05
	LOSS [training: 0.6296878091968193 | validation: 0.9161005236556226]
	TIME [epoch: 9.54 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6423840115953647		[learning rate: 1.8499e-05]
	Learning Rate: 1.84994e-05
	LOSS [training: 0.6423840115953647 | validation: 0.8961050046072089]
	TIME [epoch: 9.54 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.631593197043031		[learning rate: 1.8432e-05]
	Learning Rate: 1.84323e-05
	LOSS [training: 0.631593197043031 | validation: 0.8818423565155807]
	TIME [epoch: 9.53 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6381794706480254		[learning rate: 1.8365e-05]
	Learning Rate: 1.83654e-05
	LOSS [training: 0.6381794706480254 | validation: 0.9283307880440265]
	TIME [epoch: 9.55 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6389470365371821		[learning rate: 1.8299e-05]
	Learning Rate: 1.82987e-05
	LOSS [training: 0.6389470365371821 | validation: 0.9041199433860713]
	TIME [epoch: 9.53 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6383968753302673		[learning rate: 1.8232e-05]
	Learning Rate: 1.82323e-05
	LOSS [training: 0.6383968753302673 | validation: 0.9135757595746472]
	TIME [epoch: 9.53 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6331217359166619		[learning rate: 1.8166e-05]
	Learning Rate: 1.81662e-05
	LOSS [training: 0.6331217359166619 | validation: 0.9124783182759739]
	TIME [epoch: 9.52 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6238544953989503		[learning rate: 1.81e-05]
	Learning Rate: 1.81002e-05
	LOSS [training: 0.6238544953989503 | validation: 0.9063960151926089]
	TIME [epoch: 9.54 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6265328888754779		[learning rate: 1.8035e-05]
	Learning Rate: 1.80346e-05
	LOSS [training: 0.6265328888754779 | validation: 0.9000869252309909]
	TIME [epoch: 9.53 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6307395394970255		[learning rate: 1.7969e-05]
	Learning Rate: 1.79691e-05
	LOSS [training: 0.6307395394970255 | validation: 0.9076481690882208]
	TIME [epoch: 9.52 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6399443658534922		[learning rate: 1.7904e-05]
	Learning Rate: 1.79039e-05
	LOSS [training: 0.6399443658534922 | validation: 0.8953413730956352]
	TIME [epoch: 9.53 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6298312964381798		[learning rate: 1.7839e-05]
	Learning Rate: 1.78389e-05
	LOSS [training: 0.6298312964381798 | validation: 0.9044483710606767]
	TIME [epoch: 9.55 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6257218580782358		[learning rate: 1.7774e-05]
	Learning Rate: 1.77742e-05
	LOSS [training: 0.6257218580782358 | validation: 0.899157525200263]
	TIME [epoch: 9.52 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6324165896508184		[learning rate: 1.771e-05]
	Learning Rate: 1.77097e-05
	LOSS [training: 0.6324165896508184 | validation: 0.9079621696119898]
	TIME [epoch: 9.52 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6314802236071143		[learning rate: 1.7645e-05]
	Learning Rate: 1.76454e-05
	LOSS [training: 0.6314802236071143 | validation: 0.9081664279881363]
	TIME [epoch: 9.52 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6272448964222724		[learning rate: 1.7581e-05]
	Learning Rate: 1.75814e-05
	LOSS [training: 0.6272448964222724 | validation: 0.905859406452152]
	TIME [epoch: 9.55 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.635172406124884		[learning rate: 1.7518e-05]
	Learning Rate: 1.75176e-05
	LOSS [training: 0.635172406124884 | validation: 0.8981425230178073]
	TIME [epoch: 9.52 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6320323903260394		[learning rate: 1.7454e-05]
	Learning Rate: 1.7454e-05
	LOSS [training: 0.6320323903260394 | validation: 0.9044911815168406]
	TIME [epoch: 9.52 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6268224946190093		[learning rate: 1.7391e-05]
	Learning Rate: 1.73907e-05
	LOSS [training: 0.6268224946190093 | validation: 0.895036197518044]
	TIME [epoch: 9.52 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6259920858760579		[learning rate: 1.7328e-05]
	Learning Rate: 1.73275e-05
	LOSS [training: 0.6259920858760579 | validation: 0.8950540334064251]
	TIME [epoch: 9.52 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6282225823748848		[learning rate: 1.7265e-05]
	Learning Rate: 1.72647e-05
	LOSS [training: 0.6282225823748848 | validation: 0.9018576200180306]
	TIME [epoch: 9.52 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6253001476267848		[learning rate: 1.7202e-05]
	Learning Rate: 1.7202e-05
	LOSS [training: 0.6253001476267848 | validation: 0.906816220252256]
	TIME [epoch: 9.51 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6395334676884054		[learning rate: 1.714e-05]
	Learning Rate: 1.71396e-05
	LOSS [training: 0.6395334676884054 | validation: 0.9007663500988092]
	TIME [epoch: 9.54 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6354162601687021		[learning rate: 1.7077e-05]
	Learning Rate: 1.70774e-05
	LOSS [training: 0.6354162601687021 | validation: 0.9062968966924159]
	TIME [epoch: 9.52 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6318053079841263		[learning rate: 1.7015e-05]
	Learning Rate: 1.70154e-05
	LOSS [training: 0.6318053079841263 | validation: 0.9020777432405604]
	TIME [epoch: 9.52 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6233209672828561		[learning rate: 1.6954e-05]
	Learning Rate: 1.69537e-05
	LOSS [training: 0.6233209672828561 | validation: 0.8919138659015573]
	TIME [epoch: 9.52 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6299372024786556		[learning rate: 1.6892e-05]
	Learning Rate: 1.68921e-05
	LOSS [training: 0.6299372024786556 | validation: 0.9065760804011135]
	TIME [epoch: 9.54 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6256560608912703		[learning rate: 1.6831e-05]
	Learning Rate: 1.68308e-05
	LOSS [training: 0.6256560608912703 | validation: 0.9087841772046796]
	TIME [epoch: 9.52 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6347735191851598		[learning rate: 1.677e-05]
	Learning Rate: 1.67697e-05
	LOSS [training: 0.6347735191851598 | validation: 0.92265928012551]
	TIME [epoch: 9.52 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6278180942241443		[learning rate: 1.6709e-05]
	Learning Rate: 1.67089e-05
	LOSS [training: 0.6278180942241443 | validation: 0.9006940085180825]
	TIME [epoch: 9.52 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6297166107529047		[learning rate: 1.6648e-05]
	Learning Rate: 1.66482e-05
	LOSS [training: 0.6297166107529047 | validation: 0.9031016363004232]
	TIME [epoch: 9.56 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6333379217194048		[learning rate: 1.6588e-05]
	Learning Rate: 1.65878e-05
	LOSS [training: 0.6333379217194048 | validation: 0.9105743408858203]
	TIME [epoch: 9.52 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6370151019367644		[learning rate: 1.6528e-05]
	Learning Rate: 1.65276e-05
	LOSS [training: 0.6370151019367644 | validation: 0.8974887035835951]
	TIME [epoch: 9.51 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6334977523461462		[learning rate: 1.6468e-05]
	Learning Rate: 1.64677e-05
	LOSS [training: 0.6334977523461462 | validation: 0.9115194768885236]
	TIME [epoch: 9.52 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6315839313709029		[learning rate: 1.6408e-05]
	Learning Rate: 1.64079e-05
	LOSS [training: 0.6315839313709029 | validation: 0.9052778158007243]
	TIME [epoch: 9.54 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6239357055588541		[learning rate: 1.6348e-05]
	Learning Rate: 1.63483e-05
	LOSS [training: 0.6239357055588541 | validation: 0.9125130401142053]
	TIME [epoch: 9.52 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6350653153236502		[learning rate: 1.6289e-05]
	Learning Rate: 1.6289e-05
	LOSS [training: 0.6350653153236502 | validation: 0.9207168563740852]
	TIME [epoch: 9.53 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6318770487910588		[learning rate: 1.623e-05]
	Learning Rate: 1.62299e-05
	LOSS [training: 0.6318770487910588 | validation: 0.902521384245307]
	TIME [epoch: 9.53 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6370314618921272		[learning rate: 1.6171e-05]
	Learning Rate: 1.6171e-05
	LOSS [training: 0.6370314618921272 | validation: 0.9009811029647176]
	TIME [epoch: 9.53 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6267191683496708		[learning rate: 1.6112e-05]
	Learning Rate: 1.61123e-05
	LOSS [training: 0.6267191683496708 | validation: 0.9010007054996195]
	TIME [epoch: 9.52 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6340172565449047		[learning rate: 1.6054e-05]
	Learning Rate: 1.60538e-05
	LOSS [training: 0.6340172565449047 | validation: 0.9131265896792335]
	TIME [epoch: 9.54 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6343708278427944		[learning rate: 1.5996e-05]
	Learning Rate: 1.59956e-05
	LOSS [training: 0.6343708278427944 | validation: 0.9032871457701633]
	TIME [epoch: 9.54 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6330390943067241		[learning rate: 1.5938e-05]
	Learning Rate: 1.59375e-05
	LOSS [training: 0.6330390943067241 | validation: 0.8982556878596296]
	TIME [epoch: 9.53 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.631348387143101		[learning rate: 1.588e-05]
	Learning Rate: 1.58797e-05
	LOSS [training: 0.631348387143101 | validation: 0.901426985480536]
	TIME [epoch: 9.52 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6306589622777381		[learning rate: 1.5822e-05]
	Learning Rate: 1.58221e-05
	LOSS [training: 0.6306589622777381 | validation: 0.9104477170071974]
	TIME [epoch: 9.52 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6344083793482083		[learning rate: 1.5765e-05]
	Learning Rate: 1.57647e-05
	LOSS [training: 0.6344083793482083 | validation: 0.8992679074786213]
	TIME [epoch: 9.54 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6309964906109807		[learning rate: 1.5707e-05]
	Learning Rate: 1.57074e-05
	LOSS [training: 0.6309964906109807 | validation: 0.9182328385087047]
	TIME [epoch: 9.52 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6291229916544662		[learning rate: 1.565e-05]
	Learning Rate: 1.56504e-05
	LOSS [training: 0.6291229916544662 | validation: 0.9090107671190338]
	TIME [epoch: 9.52 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6244678029506628		[learning rate: 1.5594e-05]
	Learning Rate: 1.55936e-05
	LOSS [training: 0.6244678029506628 | validation: 0.9085774013290899]
	TIME [epoch: 9.52 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6411341195422438		[learning rate: 1.5537e-05]
	Learning Rate: 1.5537e-05
	LOSS [training: 0.6411341195422438 | validation: 0.9078361397399306]
	TIME [epoch: 9.54 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6306668602884619		[learning rate: 1.5481e-05]
	Learning Rate: 1.54807e-05
	LOSS [training: 0.6306668602884619 | validation: 0.90454994143264]
	TIME [epoch: 9.52 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6216798590193078		[learning rate: 1.5424e-05]
	Learning Rate: 1.54245e-05
	LOSS [training: 0.6216798590193078 | validation: 0.8953222652423017]
	TIME [epoch: 9.53 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.631324349661875		[learning rate: 1.5369e-05]
	Learning Rate: 1.53685e-05
	LOSS [training: 0.631324349661875 | validation: 0.89061437165129]
	TIME [epoch: 9.51 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.637377964121159		[learning rate: 1.5313e-05]
	Learning Rate: 1.53127e-05
	LOSS [training: 0.637377964121159 | validation: 0.9121443141036896]
	TIME [epoch: 9.56 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6250880282703852		[learning rate: 1.5257e-05]
	Learning Rate: 1.52572e-05
	LOSS [training: 0.6250880282703852 | validation: 0.9133620054605187]
	TIME [epoch: 9.51 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6352880154041196		[learning rate: 1.5202e-05]
	Learning Rate: 1.52018e-05
	LOSS [training: 0.6352880154041196 | validation: 0.8971560656104623]
	TIME [epoch: 9.52 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6353995715160434		[learning rate: 1.5147e-05]
	Learning Rate: 1.51466e-05
	LOSS [training: 0.6353995715160434 | validation: 0.9217388109857133]
	TIME [epoch: 9.53 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6353644745293971		[learning rate: 1.5092e-05]
	Learning Rate: 1.50917e-05
	LOSS [training: 0.6353644745293971 | validation: 0.8996355188592577]
	TIME [epoch: 9.53 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6341176296357277		[learning rate: 1.5037e-05]
	Learning Rate: 1.50369e-05
	LOSS [training: 0.6341176296357277 | validation: 0.8952881996027793]
	TIME [epoch: 9.52 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6383233434909725		[learning rate: 1.4982e-05]
	Learning Rate: 1.49823e-05
	LOSS [training: 0.6383233434909725 | validation: 0.8899773379722384]
	TIME [epoch: 9.52 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6286535474576054		[learning rate: 1.4928e-05]
	Learning Rate: 1.49279e-05
	LOSS [training: 0.6286535474576054 | validation: 0.9023621439282724]
	TIME [epoch: 9.54 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6275871376628324		[learning rate: 1.4874e-05]
	Learning Rate: 1.48738e-05
	LOSS [training: 0.6275871376628324 | validation: 0.8929884246746401]
	TIME [epoch: 9.53 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6246288285231911		[learning rate: 1.482e-05]
	Learning Rate: 1.48198e-05
	LOSS [training: 0.6246288285231911 | validation: 0.9042713171875586]
	TIME [epoch: 9.52 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.634452001254285		[learning rate: 1.4766e-05]
	Learning Rate: 1.4766e-05
	LOSS [training: 0.634452001254285 | validation: 0.908202480793374]
	TIME [epoch: 9.53 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6314789510424612		[learning rate: 1.4712e-05]
	Learning Rate: 1.47124e-05
	LOSS [training: 0.6314789510424612 | validation: 0.8925416161019442]
	TIME [epoch: 9.54 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6333672972281607		[learning rate: 1.4659e-05]
	Learning Rate: 1.4659e-05
	LOSS [training: 0.6333672972281607 | validation: 0.891320950320008]
	TIME [epoch: 9.52 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6376816496306958		[learning rate: 1.4606e-05]
	Learning Rate: 1.46058e-05
	LOSS [training: 0.6376816496306958 | validation: 0.8986715760890783]
	TIME [epoch: 9.52 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6319545898855654		[learning rate: 1.4553e-05]
	Learning Rate: 1.45528e-05
	LOSS [training: 0.6319545898855654 | validation: 0.8947571808829377]
	TIME [epoch: 9.53 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6358778001648926		[learning rate: 1.45e-05]
	Learning Rate: 1.45e-05
	LOSS [training: 0.6358778001648926 | validation: 0.909546779489314]
	TIME [epoch: 9.56 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6355219722132621		[learning rate: 1.4447e-05]
	Learning Rate: 1.44474e-05
	LOSS [training: 0.6355219722132621 | validation: 0.8992736795371326]
	TIME [epoch: 9.51 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6323123084426964		[learning rate: 1.4395e-05]
	Learning Rate: 1.4395e-05
	LOSS [training: 0.6323123084426964 | validation: 0.8959283797895577]
	TIME [epoch: 9.52 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6303930312948106		[learning rate: 1.4343e-05]
	Learning Rate: 1.43427e-05
	LOSS [training: 0.6303930312948106 | validation: 0.9017435573446063]
	TIME [epoch: 9.54 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6289266243235863		[learning rate: 1.4291e-05]
	Learning Rate: 1.42907e-05
	LOSS [training: 0.6289266243235863 | validation: 0.8941699373353265]
	TIME [epoch: 9.53 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6388806979043927		[learning rate: 1.4239e-05]
	Learning Rate: 1.42388e-05
	LOSS [training: 0.6388806979043927 | validation: 0.9140613021924691]
	TIME [epoch: 9.53 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6365021002865918		[learning rate: 1.4187e-05]
	Learning Rate: 1.41871e-05
	LOSS [training: 0.6365021002865918 | validation: 0.912173247745345]
	TIME [epoch: 9.52 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6236070278995469		[learning rate: 1.4136e-05]
	Learning Rate: 1.41357e-05
	LOSS [training: 0.6236070278995469 | validation: 0.9039464150352012]
	TIME [epoch: 9.54 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6298300540056373		[learning rate: 1.4084e-05]
	Learning Rate: 1.40844e-05
	LOSS [training: 0.6298300540056373 | validation: 0.9139244032706931]
	TIME [epoch: 9.53 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6367827704162314		[learning rate: 1.4033e-05]
	Learning Rate: 1.40332e-05
	LOSS [training: 0.6367827704162314 | validation: 0.8847756466030967]
	TIME [epoch: 9.54 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6228298922765336		[learning rate: 1.3982e-05]
	Learning Rate: 1.39823e-05
	LOSS [training: 0.6228298922765336 | validation: 0.8995092757710612]
	TIME [epoch: 9.53 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6367120071538763		[learning rate: 1.3932e-05]
	Learning Rate: 1.39316e-05
	LOSS [training: 0.6367120071538763 | validation: 0.9020071330925834]
	TIME [epoch: 9.55 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6264494162564179		[learning rate: 1.3881e-05]
	Learning Rate: 1.3881e-05
	LOSS [training: 0.6264494162564179 | validation: 0.905379074436126]
	TIME [epoch: 9.53 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6221647158464986		[learning rate: 1.3831e-05]
	Learning Rate: 1.38306e-05
	LOSS [training: 0.6221647158464986 | validation: 0.9020893881497523]
	TIME [epoch: 9.52 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6361238624697819		[learning rate: 1.378e-05]
	Learning Rate: 1.37804e-05
	LOSS [training: 0.6361238624697819 | validation: 0.9004898199798504]
	TIME [epoch: 9.52 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6379767563105563		[learning rate: 1.373e-05]
	Learning Rate: 1.37304e-05
	LOSS [training: 0.6379767563105563 | validation: 0.9038191312454423]
	TIME [epoch: 9.55 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6380306405518145		[learning rate: 1.3681e-05]
	Learning Rate: 1.36806e-05
	LOSS [training: 0.6380306405518145 | validation: 0.9056927208736854]
	TIME [epoch: 9.53 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6244575909956701		[learning rate: 1.3631e-05]
	Learning Rate: 1.3631e-05
	LOSS [training: 0.6244575909956701 | validation: 0.8914822316235342]
	TIME [epoch: 9.5 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6319399129315936		[learning rate: 1.3581e-05]
	Learning Rate: 1.35815e-05
	LOSS [training: 0.6319399129315936 | validation: 0.8982897814677893]
	TIME [epoch: 9.54 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6409764891448011		[learning rate: 1.3532e-05]
	Learning Rate: 1.35322e-05
	LOSS [training: 0.6409764891448011 | validation: 0.8930146554274601]
	TIME [epoch: 9.53 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.632593169106762		[learning rate: 1.3483e-05]
	Learning Rate: 1.34831e-05
	LOSS [training: 0.632593169106762 | validation: 0.8895045762383598]
	TIME [epoch: 9.53 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6267531784943468		[learning rate: 1.3434e-05]
	Learning Rate: 1.34342e-05
	LOSS [training: 0.6267531784943468 | validation: 0.8820147921893411]
	TIME [epoch: 9.53 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6297508292510342		[learning rate: 1.3385e-05]
	Learning Rate: 1.33854e-05
	LOSS [training: 0.6297508292510342 | validation: 0.9056854105614476]
	TIME [epoch: 9.54 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6386681586694518		[learning rate: 1.3337e-05]
	Learning Rate: 1.33368e-05
	LOSS [training: 0.6386681586694518 | validation: 0.8941916456985415]
	TIME [epoch: 9.54 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6449956811126574		[learning rate: 1.3288e-05]
	Learning Rate: 1.32884e-05
	LOSS [training: 0.6449956811126574 | validation: 0.9094101653726497]
	TIME [epoch: 9.54 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.625932997318061		[learning rate: 1.324e-05]
	Learning Rate: 1.32402e-05
	LOSS [training: 0.625932997318061 | validation: 0.8959336081435236]
	TIME [epoch: 9.52 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6296812546218015		[learning rate: 1.3192e-05]
	Learning Rate: 1.31922e-05
	LOSS [training: 0.6296812546218015 | validation: 0.896895712394864]
	TIME [epoch: 9.56 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6258922219513899		[learning rate: 1.3144e-05]
	Learning Rate: 1.31443e-05
	LOSS [training: 0.6258922219513899 | validation: 0.885970737566471]
	TIME [epoch: 9.52 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6389034301782053		[learning rate: 1.3097e-05]
	Learning Rate: 1.30966e-05
	LOSS [training: 0.6389034301782053 | validation: 0.891706737217842]
	TIME [epoch: 9.53 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6429340835745262		[learning rate: 1.3049e-05]
	Learning Rate: 1.30491e-05
	LOSS [training: 0.6429340835745262 | validation: 0.8870519191521814]
	TIME [epoch: 9.51 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6222805021570679		[learning rate: 1.3002e-05]
	Learning Rate: 1.30017e-05
	LOSS [training: 0.6222805021570679 | validation: 0.8843238252660709]
	TIME [epoch: 9.55 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6374312345844756		[learning rate: 1.2955e-05]
	Learning Rate: 1.29545e-05
	LOSS [training: 0.6374312345844756 | validation: 0.8850665739104675]
	TIME [epoch: 9.52 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6390609556152229		[learning rate: 1.2907e-05]
	Learning Rate: 1.29075e-05
	LOSS [training: 0.6390609556152229 | validation: 0.9018936913652205]
	TIME [epoch: 9.53 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6399116558117866		[learning rate: 1.2861e-05]
	Learning Rate: 1.28607e-05
	LOSS [training: 0.6399116558117866 | validation: 0.8996400134159126]
	TIME [epoch: 9.51 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6422295837357804		[learning rate: 1.2814e-05]
	Learning Rate: 1.2814e-05
	LOSS [training: 0.6422295837357804 | validation: 0.9097989278433382]
	TIME [epoch: 9.55 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6268509896787868		[learning rate: 1.2767e-05]
	Learning Rate: 1.27675e-05
	LOSS [training: 0.6268509896787868 | validation: 0.913606494805015]
	TIME [epoch: 9.54 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6223019407010293		[learning rate: 1.2721e-05]
	Learning Rate: 1.27212e-05
	LOSS [training: 0.6223019407010293 | validation: 0.890174918066003]
	TIME [epoch: 9.54 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6265175613877613		[learning rate: 1.2675e-05]
	Learning Rate: 1.2675e-05
	LOSS [training: 0.6265175613877613 | validation: 0.9299794508252697]
	TIME [epoch: 9.53 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6289028110529141		[learning rate: 1.2629e-05]
	Learning Rate: 1.2629e-05
	LOSS [training: 0.6289028110529141 | validation: 0.905485937528768]
	TIME [epoch: 9.55 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6343613343613482		[learning rate: 1.2583e-05]
	Learning Rate: 1.25832e-05
	LOSS [training: 0.6343613343613482 | validation: 0.9029859910627485]
	TIME [epoch: 9.54 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6286107265731896		[learning rate: 1.2537e-05]
	Learning Rate: 1.25375e-05
	LOSS [training: 0.6286107265731896 | validation: 0.9067648477829724]
	TIME [epoch: 9.52 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6366826221032685		[learning rate: 1.2492e-05]
	Learning Rate: 1.2492e-05
	LOSS [training: 0.6366826221032685 | validation: 0.8967857996146618]
	TIME [epoch: 9.55 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6474230919046863		[learning rate: 1.2447e-05]
	Learning Rate: 1.24467e-05
	LOSS [training: 0.6474230919046863 | validation: 0.916618643370126]
	TIME [epoch: 9.52 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6356101277899798		[learning rate: 1.2401e-05]
	Learning Rate: 1.24015e-05
	LOSS [training: 0.6356101277899798 | validation: 0.8991246866573601]
	TIME [epoch: 9.52 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6430795673394333		[learning rate: 1.2356e-05]
	Learning Rate: 1.23565e-05
	LOSS [training: 0.6430795673394333 | validation: 0.9015859763997642]
	TIME [epoch: 9.52 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6342525175593833		[learning rate: 1.2312e-05]
	Learning Rate: 1.23116e-05
	LOSS [training: 0.6342525175593833 | validation: 0.9045193070718611]
	TIME [epoch: 9.55 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6199414562421286		[learning rate: 1.2267e-05]
	Learning Rate: 1.2267e-05
	LOSS [training: 0.6199414562421286 | validation: 0.9047737923243053]
	TIME [epoch: 9.53 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6324578081590579		[learning rate: 1.2222e-05]
	Learning Rate: 1.22224e-05
	LOSS [training: 0.6324578081590579 | validation: 0.9087527653764227]
	TIME [epoch: 9.52 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6292663215801483		[learning rate: 1.2178e-05]
	Learning Rate: 1.21781e-05
	LOSS [training: 0.6292663215801483 | validation: 0.9035785566046001]
	TIME [epoch: 9.54 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6282060822973698		[learning rate: 1.2134e-05]
	Learning Rate: 1.21339e-05
	LOSS [training: 0.6282060822973698 | validation: 0.9064670584143945]
	TIME [epoch: 9.55 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6340694639134298		[learning rate: 1.209e-05]
	Learning Rate: 1.20899e-05
	LOSS [training: 0.6340694639134298 | validation: 0.9198306984124522]
	TIME [epoch: 9.52 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6309107938940671		[learning rate: 1.2046e-05]
	Learning Rate: 1.2046e-05
	LOSS [training: 0.6309107938940671 | validation: 0.9035588908075125]
	TIME [epoch: 9.52 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6341667085469098		[learning rate: 1.2002e-05]
	Learning Rate: 1.20023e-05
	LOSS [training: 0.6341667085469098 | validation: 0.9028375877884621]
	TIME [epoch: 9.53 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6300039505539374		[learning rate: 1.1959e-05]
	Learning Rate: 1.19587e-05
	LOSS [training: 0.6300039505539374 | validation: 0.8871350052218288]
	TIME [epoch: 9.53 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6332433688725803		[learning rate: 1.1915e-05]
	Learning Rate: 1.19153e-05
	LOSS [training: 0.6332433688725803 | validation: 0.9046335101765142]
	TIME [epoch: 9.53 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6319804700057556		[learning rate: 1.1872e-05]
	Learning Rate: 1.18721e-05
	LOSS [training: 0.6319804700057556 | validation: 0.9005143582924379]
	TIME [epoch: 9.51 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6302645024089677		[learning rate: 1.1829e-05]
	Learning Rate: 1.1829e-05
	LOSS [training: 0.6302645024089677 | validation: 0.8880659936519638]
	TIME [epoch: 9.55 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6308140950121247		[learning rate: 1.1786e-05]
	Learning Rate: 1.17861e-05
	LOSS [training: 0.6308140950121247 | validation: 0.8929125447585845]
	TIME [epoch: 9.52 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6313180085630674		[learning rate: 1.1743e-05]
	Learning Rate: 1.17433e-05
	LOSS [training: 0.6313180085630674 | validation: 0.8876893471491899]
	TIME [epoch: 9.53 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6333950923537282		[learning rate: 1.1701e-05]
	Learning Rate: 1.17007e-05
	LOSS [training: 0.6333950923537282 | validation: 0.8927355207745538]
	TIME [epoch: 9.53 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6298246588832815		[learning rate: 1.1658e-05]
	Learning Rate: 1.16582e-05
	LOSS [training: 0.6298246588832815 | validation: 0.8964013629910497]
	TIME [epoch: 9.56 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6336526535153024		[learning rate: 1.1616e-05]
	Learning Rate: 1.16159e-05
	LOSS [training: 0.6336526535153024 | validation: 0.906991792510674]
	TIME [epoch: 9.53 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6242753898041888		[learning rate: 1.1574e-05]
	Learning Rate: 1.15737e-05
	LOSS [training: 0.6242753898041888 | validation: 0.9005240098891204]
	TIME [epoch: 9.52 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6337732469895219		[learning rate: 1.1532e-05]
	Learning Rate: 1.15317e-05
	LOSS [training: 0.6337732469895219 | validation: 0.907851261019313]
	TIME [epoch: 9.52 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6226829069289428		[learning rate: 1.149e-05]
	Learning Rate: 1.14899e-05
	LOSS [training: 0.6226829069289428 | validation: 0.8863770896125326]
	TIME [epoch: 9.56 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6341872475083109		[learning rate: 1.1448e-05]
	Learning Rate: 1.14482e-05
	LOSS [training: 0.6341872475083109 | validation: 0.8924057076784621]
	TIME [epoch: 9.53 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6277107402455157		[learning rate: 1.1407e-05]
	Learning Rate: 1.14066e-05
	LOSS [training: 0.6277107402455157 | validation: 0.8863739173425154]
	TIME [epoch: 9.52 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6262362691620165		[learning rate: 1.1365e-05]
	Learning Rate: 1.13652e-05
	LOSS [training: 0.6262362691620165 | validation: 0.8945349645623941]
	TIME [epoch: 9.52 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6326898969884931		[learning rate: 1.1324e-05]
	Learning Rate: 1.1324e-05
	LOSS [training: 0.6326898969884931 | validation: 0.8907344115825839]
	TIME [epoch: 9.56 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6358037507845666		[learning rate: 1.1283e-05]
	Learning Rate: 1.12829e-05
	LOSS [training: 0.6358037507845666 | validation: 0.9007211938023096]
	TIME [epoch: 9.54 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6335167789827134		[learning rate: 1.1242e-05]
	Learning Rate: 1.1242e-05
	LOSS [training: 0.6335167789827134 | validation: 0.897848765134846]
	TIME [epoch: 9.54 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6289137097922608		[learning rate: 1.1201e-05]
	Learning Rate: 1.12012e-05
	LOSS [training: 0.6289137097922608 | validation: 0.8921053039507022]
	TIME [epoch: 9.54 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6425645417571292		[learning rate: 1.1161e-05]
	Learning Rate: 1.11605e-05
	LOSS [training: 0.6425645417571292 | validation: 0.8971934697427618]
	TIME [epoch: 9.55 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6365165394090251		[learning rate: 1.112e-05]
	Learning Rate: 1.112e-05
	LOSS [training: 0.6365165394090251 | validation: 0.9032629323498799]
	TIME [epoch: 9.51 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.63718998793202		[learning rate: 1.108e-05]
	Learning Rate: 1.10797e-05
	LOSS [training: 0.63718998793202 | validation: 0.8944172495822902]
	TIME [epoch: 9.53 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.631226435806514		[learning rate: 1.1039e-05]
	Learning Rate: 1.10394e-05
	LOSS [training: 0.631226435806514 | validation: 0.8946367896098675]
	TIME [epoch: 9.55 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6339075995276442		[learning rate: 1.0999e-05]
	Learning Rate: 1.09994e-05
	LOSS [training: 0.6339075995276442 | validation: 0.9114697920560388]
	TIME [epoch: 9.54 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.631826431985002		[learning rate: 1.0959e-05]
	Learning Rate: 1.09595e-05
	LOSS [training: 0.631826431985002 | validation: 0.8894323293790712]
	TIME [epoch: 9.53 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6353304343225361		[learning rate: 1.092e-05]
	Learning Rate: 1.09197e-05
	LOSS [training: 0.6353304343225361 | validation: 0.8997308574211061]
	TIME [epoch: 9.54 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6378304889538773		[learning rate: 1.088e-05]
	Learning Rate: 1.08801e-05
	LOSS [training: 0.6378304889538773 | validation: 0.8765220932231585]
	TIME [epoch: 9.55 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6188840500605721		[learning rate: 1.0841e-05]
	Learning Rate: 1.08406e-05
	LOSS [training: 0.6188840500605721 | validation: 0.8929780417892758]
	TIME [epoch: 9.52 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6312715836644388		[learning rate: 1.0801e-05]
	Learning Rate: 1.08012e-05
	LOSS [training: 0.6312715836644388 | validation: 0.9045663369994003]
	TIME [epoch: 9.52 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6347110663090133		[learning rate: 1.0762e-05]
	Learning Rate: 1.0762e-05
	LOSS [training: 0.6347110663090133 | validation: 0.8968040122238543]
	TIME [epoch: 9.53 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6307213054780906		[learning rate: 1.0723e-05]
	Learning Rate: 1.0723e-05
	LOSS [training: 0.6307213054780906 | validation: 0.9001685600416182]
	TIME [epoch: 9.56 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6297930214779772		[learning rate: 1.0684e-05]
	Learning Rate: 1.06841e-05
	LOSS [training: 0.6297930214779772 | validation: 0.8922720917424778]
	TIME [epoch: 9.53 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6232148236296838		[learning rate: 1.0645e-05]
	Learning Rate: 1.06453e-05
	LOSS [training: 0.6232148236296838 | validation: 0.8836597388015406]
	TIME [epoch: 9.53 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6443888236742535		[learning rate: 1.0607e-05]
	Learning Rate: 1.06067e-05
	LOSS [training: 0.6443888236742535 | validation: 0.8990449184807504]
	TIME [epoch: 9.54 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6341910891668274		[learning rate: 1.0568e-05]
	Learning Rate: 1.05682e-05
	LOSS [training: 0.6341910891668274 | validation: 0.8857590557065556]
	TIME [epoch: 9.54 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6448032937463949		[learning rate: 1.053e-05]
	Learning Rate: 1.05298e-05
	LOSS [training: 0.6448032937463949 | validation: 0.9255706024160034]
	TIME [epoch: 9.52 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6218715561852713		[learning rate: 1.0492e-05]
	Learning Rate: 1.04916e-05
	LOSS [training: 0.6218715561852713 | validation: 0.9093272131428074]
	TIME [epoch: 9.53 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6252366033072656		[learning rate: 1.0454e-05]
	Learning Rate: 1.04535e-05
	LOSS [training: 0.6252366033072656 | validation: 0.9033187297877845]
	TIME [epoch: 9.54 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.624985622090944		[learning rate: 1.0416e-05]
	Learning Rate: 1.04156e-05
	LOSS [training: 0.624985622090944 | validation: 0.911099866395413]
	TIME [epoch: 9.54 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6276036305728805		[learning rate: 1.0378e-05]
	Learning Rate: 1.03778e-05
	LOSS [training: 0.6276036305728805 | validation: 0.8951855561693027]
	TIME [epoch: 9.55 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6243674468099		[learning rate: 1.034e-05]
	Learning Rate: 1.03401e-05
	LOSS [training: 0.6243674468099 | validation: 0.9144422722730022]
	TIME [epoch: 9.53 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6402664929634421		[learning rate: 1.0303e-05]
	Learning Rate: 1.03026e-05
	LOSS [training: 0.6402664929634421 | validation: 0.9040821792879252]
	TIME [epoch: 9.55 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6374278356673949		[learning rate: 1.0265e-05]
	Learning Rate: 1.02652e-05
	LOSS [training: 0.6374278356673949 | validation: 0.8965799543216864]
	TIME [epoch: 9.53 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6298702789445229		[learning rate: 1.0228e-05]
	Learning Rate: 1.0228e-05
	LOSS [training: 0.6298702789445229 | validation: 0.9024929113452843]
	TIME [epoch: 9.52 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6409595598247284		[learning rate: 1.0191e-05]
	Learning Rate: 1.01909e-05
	LOSS [training: 0.6409595598247284 | validation: 0.9032696780680891]
	TIME [epoch: 9.53 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6192807411414252		[learning rate: 1.0154e-05]
	Learning Rate: 1.01539e-05
	LOSS [training: 0.6192807411414252 | validation: 0.9106643033837812]
	TIME [epoch: 9.56 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6311710897415814		[learning rate: 1.0117e-05]
	Learning Rate: 1.0117e-05
	LOSS [training: 0.6311710897415814 | validation: 0.9012437020404409]
	TIME [epoch: 9.55 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6331002065517695		[learning rate: 1.008e-05]
	Learning Rate: 1.00803e-05
	LOSS [training: 0.6331002065517695 | validation: 0.8968726607235116]
	TIME [epoch: 9.53 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6380653387390582		[learning rate: 1.0044e-05]
	Learning Rate: 1.00437e-05
	LOSS [training: 0.6380653387390582 | validation: 0.8995483173736406]
	TIME [epoch: 9.54 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6222203197792859		[learning rate: 1.0007e-05]
	Learning Rate: 1.00073e-05
	LOSS [training: 0.6222203197792859 | validation: 0.9077542946754921]
	TIME [epoch: 9.56 sec]
Finished training in 19231.246 seconds.
