Args:
Namespace(name='model_tr_study206', outdir='out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3', training_data='data/transition_rate_studies/tr_study206/tr_study206_training/r3', validation_data='data/transition_rate_studies/tr_study206/tr_study206_validation/r3', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.075, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 308923188

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 12.083852909619207		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 12.083852909619207 | validation: 12.239255968240055]
	TIME [epoch: 113 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 12.047543060195983		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 12.047543060195983 | validation: 11.52410398649356]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.075713792098096		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.075713792098096 | validation: 11.763079228832986]
	TIME [epoch: 24.7 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.068674542072783		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.068674542072783 | validation: 11.529651593541185]
	TIME [epoch: 24.8 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.341609794220993		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.341609794220993 | validation: 11.379519596524657]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.719438982570855		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.719438982570855 | validation: 9.02568082262834]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.975002676088275		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.975002676088275 | validation: 8.255332113403842]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.377544192426392		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.377544192426392 | validation: 7.813430199514829]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.732858040147328		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.732858040147328 | validation: 7.525113111150993]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.124340357174094		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.124340357174094 | validation: 8.508602858357007]
	TIME [epoch: 24.8 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.988932923052367		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.988932923052367 | validation: 5.588063625294808]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.457503885967483		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.457503885967483 | validation: 5.859967788015836]
	TIME [epoch: 24.8 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.992904474284351		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.992904474284351 | validation: 10.788674566340532]
	TIME [epoch: 24.8 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.51806315925535		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.51806315925535 | validation: 6.34789597212037]
	TIME [epoch: 24.7 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.09291458758042		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.09291458758042 | validation: 5.919195526841812]
	TIME [epoch: 24.8 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.866082103347162		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.866082103347162 | validation: 5.569821381331699]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.717793876640298		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.717793876640298 | validation: 5.5449848076054105]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.028632758778061		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.028632758778061 | validation: 5.56089542170424]
	TIME [epoch: 24.8 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.682743255020271		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.682743255020271 | validation: 5.6963548704711755]
	TIME [epoch: 24.8 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.4173092315291775		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.4173092315291775 | validation: 7.582161217123287]
	TIME [epoch: 24.8 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.304266552635054		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.304266552635054 | validation: 5.692058120995589]
	TIME [epoch: 24.8 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.6813946559428965		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.6813946559428965 | validation: 5.594379115844064]
	TIME [epoch: 24.7 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.0744201642038185		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.0744201642038185 | validation: 5.44168296881788]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.767522360211288		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.767522360211288 | validation: 6.613754606685563]
	TIME [epoch: 24.8 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.950995202791693		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.950995202791693 | validation: 5.870357494368697]
	TIME [epoch: 24.7 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.0943608529411		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.0943608529411 | validation: 6.215119290556183]
	TIME [epoch: 24.8 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.731542909479979		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.731542909479979 | validation: 5.544093334040411]
	TIME [epoch: 24.8 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.780364259728823		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.780364259728823 | validation: 6.10570775851676]
	TIME [epoch: 24.7 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.614984030703827		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.614984030703827 | validation: 5.820736760279465]
	TIME [epoch: 24.8 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.641294101465008		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.641294101465008 | validation: 5.28229355448748]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.6566358248157735		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.6566358248157735 | validation: 5.447600299562878]
	TIME [epoch: 24.7 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.927352350601116		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.927352350601116 | validation: 5.271956258935926]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.434901467870219		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.434901467870219 | validation: 5.447883731387572]
	TIME [epoch: 24.7 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.661809908959805		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.661809908959805 | validation: 6.82506732033275]
	TIME [epoch: 24.7 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.784296197753587		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.784296197753587 | validation: 5.5684716866636]
	TIME [epoch: 24.8 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.661382053253579		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.661382053253579 | validation: 5.261657610748251]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.517727974326458		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.517727974326458 | validation: 5.756531340938808]
	TIME [epoch: 24.8 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.511053571723254		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.511053571723254 | validation: 5.722182423855489]
	TIME [epoch: 24.8 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.505058588194773		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.505058588194773 | validation: 5.151542021447573]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.293420308745809		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.293420308745809 | validation: 5.2466636256039925]
	TIME [epoch: 24.8 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.609743754692472		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.609743754692472 | validation: 5.899385610992998]
	TIME [epoch: 24.8 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.803600929302259		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.803600929302259 | validation: 5.093693602555114]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.469776941957948		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.469776941957948 | validation: 5.334323607676484]
	TIME [epoch: 24.8 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.187298169504446		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.187298169504446 | validation: 5.262292290039611]
	TIME [epoch: 24.7 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.527682613472555		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.527682613472555 | validation: 5.217503217635017]
	TIME [epoch: 24.8 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.302238159624935		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.302238159624935 | validation: 5.154860019521343]
	TIME [epoch: 24.8 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.440062812128312		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.440062812128312 | validation: 6.013885498555614]
	TIME [epoch: 24.8 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.5400318396180666		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.5400318396180666 | validation: 5.450012861619498]
	TIME [epoch: 24.8 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.668412011502494		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.668412011502494 | validation: 5.010608596684672]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.240661095453023		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.240661095453023 | validation: 5.645208265528945]
	TIME [epoch: 24.7 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.213270509620889		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 5.213270509620889 | validation: 6.3349299386563915]
	TIME [epoch: 24.8 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.755524164022797		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 5.755524164022797 | validation: 5.1682604648517865]
	TIME [epoch: 24.7 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.20463727858782		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 5.20463727858782 | validation: 6.758641805901229]
	TIME [epoch: 24.8 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7485561228048505		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 5.7485561228048505 | validation: 4.975428891947841]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.101906205075492		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 5.101906205075492 | validation: 4.876074772964987]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.152692109845124		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 5.152692109845124 | validation: 5.338571397235405]
	TIME [epoch: 24.8 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.206162154841348		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 5.206162154841348 | validation: 4.828395841968756]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.4349345703968455		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 5.4349345703968455 | validation: 5.12430582745056]
	TIME [epoch: 24.8 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.265346767554755		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 5.265346767554755 | validation: 5.02212571165481]
	TIME [epoch: 24.8 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.272258049028581		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 5.272258049028581 | validation: 5.127357534132791]
	TIME [epoch: 24.8 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.289298938082859		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 5.289298938082859 | validation: 4.939384188039821]
	TIME [epoch: 24.8 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.079041372882367		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 5.079041372882367 | validation: 5.430610377338773]
	TIME [epoch: 24.8 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.165463368609257		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 5.165463368609257 | validation: 4.86993067463812]
	TIME [epoch: 24.8 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.271620816078476		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 5.271620816078476 | validation: 4.896893172878574]
	TIME [epoch: 24.7 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.081792873270004		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 5.081792873270004 | validation: 5.978209299818854]
	TIME [epoch: 24.8 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.3204534224390105		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 5.3204534224390105 | validation: 4.906289510906149]
	TIME [epoch: 24.7 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.995318531469856		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 4.995318531469856 | validation: 4.881153998145274]
	TIME [epoch: 24.7 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.045045474166487		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 5.045045474166487 | validation: 5.354074873448635]
	TIME [epoch: 24.8 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.215553733716675		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 5.215553733716675 | validation: 4.845349089631495]
	TIME [epoch: 24.7 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.014028550110314		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 5.014028550110314 | validation: 5.144891917661753]
	TIME [epoch: 24.7 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.2850415538551525		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 5.2850415538551525 | validation: 4.768186507792615]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.036912029917821		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 5.036912029917821 | validation: 4.760519318841196]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.095714575104363		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 5.095714575104363 | validation: 4.726089470551435]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.142682897845196		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 5.142682897845196 | validation: 4.865640017162092]
	TIME [epoch: 24.8 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.992733024793264		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 4.992733024793264 | validation: 5.074172403647136]
	TIME [epoch: 24.7 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.010734061051318		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 5.010734061051318 | validation: 5.087606911829684]
	TIME [epoch: 24.7 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.083283415481468		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 5.083283415481468 | validation: 4.74502053367214]
	TIME [epoch: 24.8 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.025852599296876		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 5.025852599296876 | validation: 4.804570521585726]
	TIME [epoch: 24.7 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.010139829183306		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 5.010139829183306 | validation: 5.094354804535999]
	TIME [epoch: 24.7 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.0687191316594085		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 5.0687191316594085 | validation: 5.159881588935043]
	TIME [epoch: 24.8 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.067911802727448		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 5.067911802727448 | validation: 4.767598287444196]
	TIME [epoch: 24.7 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.002311620905136		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 5.002311620905136 | validation: 4.9781053507143485]
	TIME [epoch: 24.7 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.999862613384499		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 4.999862613384499 | validation: 5.035090322888111]
	TIME [epoch: 24.8 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.954835164041397		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 4.954835164041397 | validation: 4.852828894523484]
	TIME [epoch: 24.7 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.047682284805028		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 5.047682284805028 | validation: 5.0937397822481]
	TIME [epoch: 24.7 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.101159284815635		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 5.101159284815635 | validation: 5.199034969022895]
	TIME [epoch: 24.8 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.128680242615715		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 5.128680242615715 | validation: 4.677699545919008]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_87.pth
	Model improved!!!
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.839314335424636		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 4.839314335424636 | validation: 4.683977533905192]
	TIME [epoch: 24.7 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.956866533726313		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 4.956866533726313 | validation: 4.740600964230362]
	TIME [epoch: 24.8 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.89878768608154		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 4.89878768608154 | validation: 4.613135266758771]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_90.pth
	Model improved!!!
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.243827707839622		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 5.243827707839622 | validation: 4.824535764926996]
	TIME [epoch: 24.7 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.234639559263081		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 5.234639559263081 | validation: 4.735607124514612]
	TIME [epoch: 24.7 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.849583337510385		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 4.849583337510385 | validation: 4.648975949980329]
	TIME [epoch: 24.7 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.8572273193777775		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 4.8572273193777775 | validation: 4.528535190028707]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_94.pth
	Model improved!!!
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.076806773253728		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 4.076806773253728 | validation: 4.386864282580982]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_95.pth
	Model improved!!!
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.695357296110366		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 3.695357296110366 | validation: 3.653231209568493]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_96.pth
	Model improved!!!
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6736516127340964		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 3.6736516127340964 | validation: 3.884082559599421]
	TIME [epoch: 24.8 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5850726780860205		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 3.5850726780860205 | validation: 3.82148263946666]
	TIME [epoch: 24.8 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4033253106025203		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 3.4033253106025203 | validation: 3.4807366152008767]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_99.pth
	Model improved!!!
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.3944987897129995		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 4.3944987897129995 | validation: 5.806833671637543]
	TIME [epoch: 24.7 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.137362257070363		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 5.137362257070363 | validation: 4.74472280761284]
	TIME [epoch: 24.8 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.985578123801703		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 4.985578123801703 | validation: 4.723458553434552]
	TIME [epoch: 24.7 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.933509176192015		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 4.933509176192015 | validation: 5.2343208221369615]
	TIME [epoch: 24.8 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.98603499213584		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 4.98603499213584 | validation: 5.446888943556244]
	TIME [epoch: 24.8 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.997779619892892		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 4.997779619892892 | validation: 4.646936862811956]
	TIME [epoch: 24.8 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.943809424029284		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 4.943809424029284 | validation: 4.997566693640246]
	TIME [epoch: 24.7 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.04331409329182		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 5.04331409329182 | validation: 4.829878285169099]
	TIME [epoch: 24.8 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.3615188600178225		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 4.3615188600178225 | validation: 4.231259171031975]
	TIME [epoch: 24.7 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461823803461719		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 4.461823803461719 | validation: 4.288144348293518]
	TIME [epoch: 24.7 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.807437837854296		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 3.807437837854296 | validation: 3.8534619962615513]
	TIME [epoch: 24.8 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5530562045648773		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 3.5530562045648773 | validation: 3.910672848428405]
	TIME [epoch: 24.8 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.368342055059652		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 3.368342055059652 | validation: 3.6281460604508347]
	TIME [epoch: 24.7 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.172943331622161		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 4.172943331622161 | validation: 5.7725367639526155]
	TIME [epoch: 24.7 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.08537507266341		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 5.08537507266341 | validation: 5.306006588519314]
	TIME [epoch: 24.8 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.968646038013028		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 4.968646038013028 | validation: 4.782857138247033]
	TIME [epoch: 24.8 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.792378046103261		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 4.792378046103261 | validation: 4.695436149208491]
	TIME [epoch: 24.8 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.846336025748498		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 4.846336025748498 | validation: 5.77974126032108]
	TIME [epoch: 24.7 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.107216618702935		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 5.107216618702935 | validation: 5.354175169877983]
	TIME [epoch: 24.7 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.9606734130867505		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 4.9606734130867505 | validation: 4.685562547181751]
	TIME [epoch: 24.8 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.9009458844288645		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 4.9009458844288645 | validation: 4.674182336006779]
	TIME [epoch: 24.7 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.897971494210963		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 4.897971494210963 | validation: 4.575094982456541]
	TIME [epoch: 24.7 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.783287130201227		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 4.783287130201227 | validation: 4.550441563866275]
	TIME [epoch: 24.8 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.642261926822716		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 4.642261926822716 | validation: 6.6440272986601485]
	TIME [epoch: 24.7 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.842915041008828		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 4.842915041008828 | validation: 4.123644185576094]
	TIME [epoch: 24.8 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9276805560906927		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 3.9276805560906927 | validation: 4.1195939683191725]
	TIME [epoch: 24.8 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.318052590095913		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 4.318052590095913 | validation: 3.8913019618161706]
	TIME [epoch: 24.8 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.561940647697064		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 3.561940647697064 | validation: 4.2370391428563945]
	TIME [epoch: 24.8 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.57566483280615		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 3.57566483280615 | validation: 3.5908710260338617]
	TIME [epoch: 24.8 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4121619694830145		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 3.4121619694830145 | validation: 3.587218651104227]
	TIME [epoch: 24.7 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4354244721670097		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 3.4354244721670097 | validation: 4.250297525964875]
	TIME [epoch: 24.8 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4137651063434835		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 3.4137651063434835 | validation: 3.496614975528006]
	TIME [epoch: 24.8 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.269687194522658		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 3.269687194522658 | validation: 3.628012614425696]
	TIME [epoch: 24.8 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5009599467869		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 3.5009599467869 | validation: 9.461059887456807]
	TIME [epoch: 24.8 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.122519870255401		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 5.122519870255401 | validation: 3.4481592591815535]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_134.pth
	Model improved!!!
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1365062177400596		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 3.1365062177400596 | validation: 3.828764415817368]
	TIME [epoch: 24.7 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3538542742786284		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 3.3538542742786284 | validation: 3.593268284855445]
	TIME [epoch: 24.8 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9111541888252206		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 3.9111541888252206 | validation: 3.9287624515992263]
	TIME [epoch: 24.8 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4184809719847764		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 3.4184809719847764 | validation: 3.6231372786367855]
	TIME [epoch: 24.8 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.250912828774581		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 3.250912828774581 | validation: 3.7280704768625528]
	TIME [epoch: 24.7 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1703827862486973		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 3.1703827862486973 | validation: 3.4839387734932643]
	TIME [epoch: 24.8 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5629652931454885		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 3.5629652931454885 | validation: 4.124764800613166]
	TIME [epoch: 24.7 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.592101031968947		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 3.592101031968947 | validation: 5.966586886809449]
	TIME [epoch: 24.8 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.512160589342147		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 4.512160589342147 | validation: 3.7996388386817985]
	TIME [epoch: 24.8 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3312005039984944		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 3.3312005039984944 | validation: 3.529728564982101]
	TIME [epoch: 24.7 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1247570954107857		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 3.1247570954107857 | validation: 3.5756552732086533]
	TIME [epoch: 24.8 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1495767845167495		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 3.1495767845167495 | validation: 3.4483214118670844]
	TIME [epoch: 24.8 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2229974554155936		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 3.2229974554155936 | validation: 3.457497422780448]
	TIME [epoch: 24.7 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1609147465277574		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 3.1609147465277574 | validation: 3.6661372368792082]
	TIME [epoch: 24.7 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2938721454272666		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 3.2938721454272666 | validation: 3.80775701528774]
	TIME [epoch: 24.8 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4708463184034555		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 3.4708463184034555 | validation: 3.44733703791477]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_150.pth
	Model improved!!!
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.112778326390143		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 3.112778326390143 | validation: 3.8403983216626956]
	TIME [epoch: 24.8 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.141989565977325		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 3.141989565977325 | validation: 3.389421869266803]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_152.pth
	Model improved!!!
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1739914975296193		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 3.1739914975296193 | validation: 3.691139935526335]
	TIME [epoch: 24.8 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.236173336609509		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 3.236173336609509 | validation: 4.192182814799277]
	TIME [epoch: 24.8 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3689504646027317		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 3.3689504646027317 | validation: 3.570423039468242]
	TIME [epoch: 24.8 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1652093460041364		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 3.1652093460041364 | validation: 3.535663920649971]
	TIME [epoch: 24.7 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.245375328140443		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 3.245375328140443 | validation: 3.899642456601437]
	TIME [epoch: 24.8 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3172542842034076		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 3.3172542842034076 | validation: 3.5300523858158215]
	TIME [epoch: 24.8 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1756997254755577		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 3.1756997254755577 | validation: 4.320735581419437]
	TIME [epoch: 24.7 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.357982051307396		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 3.357982051307396 | validation: 3.58848256251443]
	TIME [epoch: 24.8 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0851344778561347		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 3.0851344778561347 | validation: 3.3814813970596607]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_161.pth
	Model improved!!!
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9796097428259056		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 2.9796097428259056 | validation: 3.3811464928302613]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_162.pth
	Model improved!!!
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.330445429502268		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 3.330445429502268 | validation: 3.3783673201481794]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_163.pth
	Model improved!!!
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1786572299190903		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 3.1786572299190903 | validation: 3.8831772777499864]
	TIME [epoch: 24.8 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.155310259974253		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 3.155310259974253 | validation: 3.7994119171634204]
	TIME [epoch: 24.7 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.07867920792341		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 3.07867920792341 | validation: 4.390221742150849]
	TIME [epoch: 24.8 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2816619160329856		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 3.2816619160329856 | validation: 3.534441892253823]
	TIME [epoch: 24.8 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1266601951468624		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 3.1266601951468624 | validation: 3.396158083221909]
	TIME [epoch: 24.7 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.025934947791202		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 3.025934947791202 | validation: 3.6556191806621428]
	TIME [epoch: 24.8 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0450108868801875		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 3.0450108868801875 | validation: 3.5448431540587526]
	TIME [epoch: 24.8 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.208407143379943		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 3.208407143379943 | validation: 3.495124130829725]
	TIME [epoch: 24.7 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0950703859088406		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 3.0950703859088406 | validation: 3.763531401364172]
	TIME [epoch: 24.8 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1637547161641693		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 3.1637547161641693 | validation: 3.416185591729466]
	TIME [epoch: 24.8 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0911656823310993		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 3.0911656823310993 | validation: 3.4540811389471244]
	TIME [epoch: 24.7 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.100907773903184		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 3.100907773903184 | validation: 3.5234143829851123]
	TIME [epoch: 24.8 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.991169391484832		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 2.991169391484832 | validation: 3.5332826175355048]
	TIME [epoch: 24.8 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.177703609131514		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 3.177703609131514 | validation: 3.4374494288607678]
	TIME [epoch: 24.7 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1631326863895928		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 3.1631326863895928 | validation: 4.090977496562421]
	TIME [epoch: 24.8 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6175745214155413		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 3.6175745214155413 | validation: 3.6248205646916984]
	TIME [epoch: 24.8 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.044753251647456		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 3.044753251647456 | validation: 3.3499733563371663]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_180.pth
	Model improved!!!
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0361594142939254		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 3.0361594142939254 | validation: 3.4965213048430073]
	TIME [epoch: 24.8 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0193707016679836		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 3.0193707016679836 | validation: 3.372410177955875]
	TIME [epoch: 24.7 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.150413155726448		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 3.150413155726448 | validation: 3.352482284669053]
	TIME [epoch: 24.7 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.010925634160912		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 3.010925634160912 | validation: 3.3438912289984732]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_184.pth
	Model improved!!!
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0073657303727734		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 3.0073657303727734 | validation: 3.963331126571658]
	TIME [epoch: 24.7 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1995954940684586		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 3.1995954940684586 | validation: 3.391008370201771]
	TIME [epoch: 24.7 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0285549100125797		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 3.0285549100125797 | validation: 3.380038436311512]
	TIME [epoch: 24.7 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.02721669797565		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 3.02721669797565 | validation: 3.2998383199127876]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_188.pth
	Model improved!!!
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.968520886033116		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 2.968520886033116 | validation: 3.6762078842857]
	TIME [epoch: 24.7 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0197378616506745		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 3.0197378616506745 | validation: 3.346940269590199]
	TIME [epoch: 24.7 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.152663222937002		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 3.152663222937002 | validation: 3.306179862201408]
	TIME [epoch: 24.8 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.005305248908076		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 3.005305248908076 | validation: 3.3220115842207454]
	TIME [epoch: 24.7 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9650087020750275		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 2.9650087020750275 | validation: 3.592936168006166]
	TIME [epoch: 24.8 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0500689485517936		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 3.0500689485517936 | validation: 3.612842853765756]
	TIME [epoch: 24.8 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0162885244232944		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 3.0162885244232944 | validation: 3.5639755916144105]
	TIME [epoch: 24.7 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.972913269384647		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 2.972913269384647 | validation: 3.548553431365771]
	TIME [epoch: 24.8 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.214771169668359		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 3.214771169668359 | validation: 3.3953730045553465]
	TIME [epoch: 24.8 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9667702484123515		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 2.9667702484123515 | validation: 3.31081931479617]
	TIME [epoch: 24.7 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1327960595702247		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 3.1327960595702247 | validation: 3.467723913744777]
	TIME [epoch: 24.8 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9812195422660506		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 2.9812195422660506 | validation: 3.3787274508084195]
	TIME [epoch: 24.8 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9709995929057635		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 2.9709995929057635 | validation: 3.8214905404736705]
	TIME [epoch: 24.7 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0723019941787326		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 3.0723019941787326 | validation: 3.4094509099378025]
	TIME [epoch: 24.8 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.892946229058145		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 2.892946229058145 | validation: 4.720765852603471]
	TIME [epoch: 24.8 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4522531591589876		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 3.4522531591589876 | validation: 3.330108003182636]
	TIME [epoch: 24.8 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9136314243922468		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 2.9136314243922468 | validation: 3.2918307096318133]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_205.pth
	Model improved!!!
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8846611350413642		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 2.8846611350413642 | validation: 3.694840665752993]
	TIME [epoch: 24.7 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0368686266020246		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 3.0368686266020246 | validation: 3.5015722043451696]
	TIME [epoch: 24.7 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9639749693305935		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 2.9639749693305935 | validation: 3.2438247643061158]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_208.pth
	Model improved!!!
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1682839288504323		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 3.1682839288504323 | validation: 3.361246453703454]
	TIME [epoch: 24.8 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9694850098892713		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 2.9694850098892713 | validation: 3.477682821931406]
	TIME [epoch: 24.8 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.945552535639685		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 2.945552535639685 | validation: 3.5209681294296526]
	TIME [epoch: 24.8 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9725234096590243		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 2.9725234096590243 | validation: 3.5410967659610413]
	TIME [epoch: 24.7 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1850040494283207		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 3.1850040494283207 | validation: 3.4233833139169487]
	TIME [epoch: 24.7 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.97550399286197		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 2.97550399286197 | validation: 3.308093778101899]
	TIME [epoch: 24.8 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.936522177404921		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 2.936522177404921 | validation: 3.4932786026196245]
	TIME [epoch: 24.7 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.121031803782703		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 3.121031803782703 | validation: 3.269690603296482]
	TIME [epoch: 24.8 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.070121802442836		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 3.070121802442836 | validation: 3.4728945363110455]
	TIME [epoch: 24.8 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.98201692976117		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 2.98201692976117 | validation: 3.292607318503704]
	TIME [epoch: 24.7 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.932060612278403		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 2.932060612278403 | validation: 3.4221745347292347]
	TIME [epoch: 24.7 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9823732536881025		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 2.9823732536881025 | validation: 3.6319646598094106]
	TIME [epoch: 24.7 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9861295434165758		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 2.9861295434165758 | validation: 3.507296891266776]
	TIME [epoch: 24.7 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.961568277007804		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 2.961568277007804 | validation: 3.415871556352599]
	TIME [epoch: 24.7 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.066138406755039		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 3.066138406755039 | validation: 3.434740294127282]
	TIME [epoch: 24.7 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.003404684018698		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 3.003404684018698 | validation: 3.6068263579869573]
	TIME [epoch: 24.8 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0961845542332043		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 3.0961845542332043 | validation: 3.3604769639781513]
	TIME [epoch: 24.7 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0219387978939123		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 3.0219387978939123 | validation: 3.4044454859605673]
	TIME [epoch: 24.8 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8772382957791494		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 2.8772382957791494 | validation: 3.6718084061833576]
	TIME [epoch: 24.8 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0949479266350908		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 3.0949479266350908 | validation: 3.399530227607665]
	TIME [epoch: 24.8 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9715816202107566		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 2.9715816202107566 | validation: 3.338597812732343]
	TIME [epoch: 24.7 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8479757568364694		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 2.8479757568364694 | validation: 3.204109178954472]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_230.pth
	Model improved!!!
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9850091579845226		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 2.9850091579845226 | validation: 3.3646712656765754]
	TIME [epoch: 24.7 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1908421195104513		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 3.1908421195104513 | validation: 3.2785031578858197]
	TIME [epoch: 24.8 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8538113346977525		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 2.8538113346977525 | validation: 3.3646478687404304]
	TIME [epoch: 24.8 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.792251754628547		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 4.792251754628547 | validation: 6.191841731827979]
	TIME [epoch: 24.7 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.913931937701665		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 3.913931937701665 | validation: 3.377613866799685]
	TIME [epoch: 24.8 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.922551915865548		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 2.922551915865548 | validation: 3.3742735901700365]
	TIME [epoch: 24.8 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8946009434810183		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 2.8946009434810183 | validation: 3.7441135271903727]
	TIME [epoch: 24.8 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.006065044087406		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 3.006065044087406 | validation: 3.2318807209578813]
	TIME [epoch: 24.8 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9392206049879794		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 2.9392206049879794 | validation: 3.4634947475573687]
	TIME [epoch: 24.8 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1303427208656243		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 3.1303427208656243 | validation: 3.4796232665287703]
	TIME [epoch: 24.8 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9703842747705225		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 2.9703842747705225 | validation: 3.4100430697751607]
	TIME [epoch: 24.8 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.92096693391296		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 2.92096693391296 | validation: 3.4885823164277054]
	TIME [epoch: 24.7 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.933015465538291		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 2.933015465538291 | validation: 3.280180920457041]
	TIME [epoch: 24.7 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9900548270702485		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 2.9900548270702485 | validation: 3.2861814122072053]
	TIME [epoch: 24.7 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.907560388049255		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 2.907560388049255 | validation: 3.3620212736771657]
	TIME [epoch: 24.7 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8724055666791886		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 2.8724055666791886 | validation: 3.54919208681246]
	TIME [epoch: 24.8 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9157290576094166		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 2.9157290576094166 | validation: 3.256381007552303]
	TIME [epoch: 24.8 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.82183160894811		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 2.82183160894811 | validation: 3.8635384430813953]
	TIME [epoch: 24.7 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.99383558388074		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 2.99383558388074 | validation: 3.4098515575461206]
	TIME [epoch: 24.8 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9247639214284016		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 2.9247639214284016 | validation: 3.6147468552049373]
	TIME [epoch: 24.8 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.043540874778957		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 3.043540874778957 | validation: 5.608576117034682]
	TIME [epoch: 24.7 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6645454785364375		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 3.6645454785364375 | validation: 3.1731105071588033]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_252.pth
	Model improved!!!
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.755210614359103		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 2.755210614359103 | validation: 3.230765649600496]
	TIME [epoch: 24.8 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8684300671659		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 2.8684300671659 | validation: 3.482297147625228]
	TIME [epoch: 24.8 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.910734365533205		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 2.910734365533205 | validation: 3.3637670859403017]
	TIME [epoch: 24.7 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.829250098910997		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 2.829250098910997 | validation: 3.232567346848083]
	TIME [epoch: 24.7 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2528587964479683		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 3.2528587964479683 | validation: 3.3785926209455956]
	TIME [epoch: 24.8 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8492641582632054		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 2.8492641582632054 | validation: 3.0852261050002476]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_258.pth
	Model improved!!!
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7273166170019754		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 2.7273166170019754 | validation: 3.239974640231228]
	TIME [epoch: 25 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7954863102112304		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 2.7954863102112304 | validation: 3.245500904659674]
	TIME [epoch: 24.8 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8897503937798206		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 2.8897503937798206 | validation: 3.2482648884919967]
	TIME [epoch: 24.7 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.773808118848359		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 2.773808118848359 | validation: 3.330794174117463]
	TIME [epoch: 24.8 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.834349761619071		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 2.834349761619071 | validation: 3.180463030806208]
	TIME [epoch: 24.7 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.843217885263808		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 2.843217885263808 | validation: 3.338559659682618]
	TIME [epoch: 24.8 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.80091907739392		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 2.80091907739392 | validation: 3.131862058083204]
	TIME [epoch: 24.8 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7299090347976875		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 2.7299090347976875 | validation: 3.2330117770983544]
	TIME [epoch: 24.7 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.732389788123514		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 4.732389788123514 | validation: 3.6965787756624366]
	TIME [epoch: 24.8 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1294607182988057		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 3.1294607182988057 | validation: 3.6894129091431296]
	TIME [epoch: 24.8 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.122940588690523		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 3.122940588690523 | validation: 3.6334576274943813]
	TIME [epoch: 24.7 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0158592761199112		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 3.0158592761199112 | validation: 3.188253099455967]
	TIME [epoch: 24.8 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0031377948387954		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 3.0031377948387954 | validation: 3.2178794290094435]
	TIME [epoch: 24.8 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.803272117062966		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 2.803272117062966 | validation: 3.2245614017668114]
	TIME [epoch: 24.7 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.829326104870078		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 2.829326104870078 | validation: 3.352838751341824]
	TIME [epoch: 24.8 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9038937082116254		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 2.9038937082116254 | validation: 3.1590667133629724]
	TIME [epoch: 24.8 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8177815944881175		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 2.8177815944881175 | validation: 3.541318856901573]
	TIME [epoch: 24.7 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7596483322486476		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 2.7596483322486476 | validation: 2.986664723263093]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_276.pth
	Model improved!!!
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.674019147481948		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 2.674019147481948 | validation: 3.2658726409417853]
	TIME [epoch: 24.8 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.792012219465831		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 2.792012219465831 | validation: 3.237081125351523]
	TIME [epoch: 24.7 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.672151893382715		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 2.672151893382715 | validation: 3.586462210130835]
	TIME [epoch: 24.8 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.042508843960416		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 3.042508843960416 | validation: 3.145465414895617]
	TIME [epoch: 24.8 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.766496441466125		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 2.766496441466125 | validation: 3.061689510348719]
	TIME [epoch: 24.7 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.976653722534264		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 2.976653722534264 | validation: 3.0986375047617742]
	TIME [epoch: 24.8 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7057570006847853		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 2.7057570006847853 | validation: 2.9060293209146075]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_283.pth
	Model improved!!!
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9814629991021757		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 2.9814629991021757 | validation: 3.235442962155419]
	TIME [epoch: 24.7 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.739898768610258		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 2.739898768610258 | validation: 2.96285589473178]
	TIME [epoch: 24.8 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5121033989554817		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 2.5121033989554817 | validation: 3.05435467579684]
	TIME [epoch: 24.8 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.52668928296141		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 2.52668928296141 | validation: 5.766029828629285]
	TIME [epoch: 24.7 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5146498375457234		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 3.5146498375457234 | validation: 2.899018395489329]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_288.pth
	Model improved!!!
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5389093419649633		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 2.5389093419649633 | validation: 2.8003584745945953]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_289.pth
	Model improved!!!
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3914213111709755		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 2.3914213111709755 | validation: 2.977514664335124]
	TIME [epoch: 24.7 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.514368025163924		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 2.514368025163924 | validation: 2.8291129853173365]
	TIME [epoch: 24.8 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3525613849786238		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 2.3525613849786238 | validation: 2.6582283317723365]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_292.pth
	Model improved!!!
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.398701940008381		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 2.398701940008381 | validation: 2.744516400056292]
	TIME [epoch: 24.7 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.333285050026369		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 2.333285050026369 | validation: 2.6849686796061896]
	TIME [epoch: 24.7 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7002945498907787		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 2.7002945498907787 | validation: 2.66547294721178]
	TIME [epoch: 24.8 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.26972988043425		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 2.26972988043425 | validation: 2.4735088325924477]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_296.pth
	Model improved!!!
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2952920686707934		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 2.2952920686707934 | validation: 2.8898821738911478]
	TIME [epoch: 24.8 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6555425916570154		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 2.6555425916570154 | validation: 2.5581431300413517]
	TIME [epoch: 24.8 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.211075748910574		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 2.211075748910574 | validation: 2.3973177679864466]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_299.pth
	Model improved!!!
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6169956555742977		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 2.6169956555742977 | validation: 2.898013989272266]
	TIME [epoch: 24.8 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6554334793589156		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 2.6554334793589156 | validation: 2.1974602844509854]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_301.pth
	Model improved!!!
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.202571316477552		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 2.202571316477552 | validation: 2.207035567134931]
	TIME [epoch: 24.7 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9166708391669434		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 1.9166708391669434 | validation: 2.2685604612775854]
	TIME [epoch: 24.7 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.89610695359161		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 1.89610695359161 | validation: 1.5895397908021809]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_304.pth
	Model improved!!!
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5306796290708449		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 1.5306796290708449 | validation: 2.254775780822261]
	TIME [epoch: 24.7 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6338292066681588		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 1.6338292066681588 | validation: 1.452417459626032]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_306.pth
	Model improved!!!
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4941315832937794		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 1.4941315832937794 | validation: 1.1412435987477216]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_307.pth
	Model improved!!!
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3932859047125954		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 1.3932859047125954 | validation: 1.6513389429662995]
	TIME [epoch: 24.8 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.400135574803404		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 1.400135574803404 | validation: 1.3714880189402743]
	TIME [epoch: 25 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3866510884630436		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 1.3866510884630436 | validation: 1.5224159915569977]
	TIME [epoch: 24.8 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7657686045928074		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 1.7657686045928074 | validation: 1.5082361473422745]
	TIME [epoch: 24.7 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2209335572455111		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 1.2209335572455111 | validation: 1.1813012521149302]
	TIME [epoch: 24.8 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9911908349040333		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.9911908349040333 | validation: 1.013923213073876]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_313.pth
	Model improved!!!
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9639937511754956		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.9639937511754956 | validation: 1.2897037991325788]
	TIME [epoch: 24.7 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0842616598949657		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 1.0842616598949657 | validation: 1.0911025910236039]
	TIME [epoch: 24.7 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.093720493568195		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 1.093720493568195 | validation: 1.1015386712274278]
	TIME [epoch: 24.8 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1413470542978827		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 1.1413470542978827 | validation: 1.0575159119119293]
	TIME [epoch: 24.7 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0576305050675656		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 1.0576305050675656 | validation: 1.0464934722475765]
	TIME [epoch: 24.7 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.003706880021024		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 1.003706880021024 | validation: 0.9918846110089193]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_319.pth
	Model improved!!!
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1851944783949728		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 1.1851944783949728 | validation: 1.1554847225789906]
	TIME [epoch: 24.7 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9474627791530694		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.9474627791530694 | validation: 1.3117409857292088]
	TIME [epoch: 24.8 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0942908232302184		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 1.0942908232302184 | validation: 0.9817302005177149]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_322.pth
	Model improved!!!
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8787948089664334		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.8787948089664334 | validation: 1.0845859247382519]
	TIME [epoch: 24.7 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9748148262007821		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.9748148262007821 | validation: 0.9569595550164743]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_324.pth
	Model improved!!!
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8848810691767721		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.8848810691767721 | validation: 1.080638430862446]
	TIME [epoch: 24.8 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9262758358444585		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.9262758358444585 | validation: 0.9679371529661814]
	TIME [epoch: 24.7 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9430094292871598		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.9430094292871598 | validation: 1.1845652181485118]
	TIME [epoch: 24.7 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9211721501121171		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.9211721501121171 | validation: 1.4789623327267174]
	TIME [epoch: 24.7 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.907344917381274		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.907344917381274 | validation: 0.8684227430643765]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_329.pth
	Model improved!!!
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9200618083264378		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.9200618083264378 | validation: 0.8930797336385328]
	TIME [epoch: 24.7 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9069303376968061		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.9069303376968061 | validation: 1.107306561403491]
	TIME [epoch: 24.8 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0073742928641303		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 1.0073742928641303 | validation: 1.0518263977881752]
	TIME [epoch: 24.8 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8463680675426493		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.8463680675426493 | validation: 1.2634144421529694]
	TIME [epoch: 24.7 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.033871854814524		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 1.033871854814524 | validation: 0.9059827318242312]
	TIME [epoch: 24.8 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9551241389273349		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.9551241389273349 | validation: 0.9039893868769664]
	TIME [epoch: 24.8 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0199227709200813		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 1.0199227709200813 | validation: 0.8692515680744002]
	TIME [epoch: 24.8 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7608996755379809		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.7608996755379809 | validation: 1.0788481803062313]
	TIME [epoch: 24.8 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9227124754855877		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.9227124754855877 | validation: 0.9437537824825091]
	TIME [epoch: 24.8 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8808119257352525		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.8808119257352525 | validation: 1.1045438301444999]
	TIME [epoch: 24.8 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.884935521374017		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.884935521374017 | validation: 3.695781772161353]
	TIME [epoch: 24.8 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6723866945158155		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 1.6723866945158155 | validation: 1.5531201941276624]
	TIME [epoch: 24.8 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0774233996964035		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 1.0774233996964035 | validation: 1.6143213625781743]
	TIME [epoch: 24.8 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1217466755145968		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 1.1217466755145968 | validation: 1.6991969280201609]
	TIME [epoch: 24.8 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2021586023642425		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 1.2021586023642425 | validation: 1.3580440473749316]
	TIME [epoch: 24.7 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9236924283702		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.9236924283702 | validation: 0.7958218129936699]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_345.pth
	Model improved!!!
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8950835461688028		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.8950835461688028 | validation: 1.7755719969213413]
	TIME [epoch: 24.7 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.218141818547588		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 1.218141818547588 | validation: 1.461685958438788]
	TIME [epoch: 24.8 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.151055538020102		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 1.151055538020102 | validation: 1.3823630234966942]
	TIME [epoch: 24.8 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0421912852200845		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 1.0421912852200845 | validation: 1.0814624820486278]
	TIME [epoch: 24.8 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8267887382050471		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.8267887382050471 | validation: 1.1461743733822625]
	TIME [epoch: 24.8 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9834132536453055		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.9834132536453055 | validation: 0.923096310729487]
	TIME [epoch: 24.8 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8646934544720419		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.8646934544720419 | validation: 0.7601436551278619]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_352.pth
	Model improved!!!
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8174901353791253		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.8174901353791253 | validation: 1.0733860601437135]
	TIME [epoch: 24.8 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8280639766016586		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.8280639766016586 | validation: 0.8316836562696307]
	TIME [epoch: 24.7 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.810025356331181		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.810025356331181 | validation: 1.0896591926493115]
	TIME [epoch: 24.7 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8297286104341214		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.8297286104341214 | validation: 0.7673692078280806]
	TIME [epoch: 24.7 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.793541071819027		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.793541071819027 | validation: 0.7775502458456294]
	TIME [epoch: 24.8 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8260374309067058		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.8260374309067058 | validation: 0.7646587197559715]
	TIME [epoch: 24.8 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7106941746090846		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.7106941746090846 | validation: 1.1854277207242334]
	TIME [epoch: 24.8 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0644737103655808		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 1.0644737103655808 | validation: 0.9392666401758252]
	TIME [epoch: 24.8 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8362688862957307		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.8362688862957307 | validation: 1.2066126799500358]
	TIME [epoch: 24.8 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8230151529253353		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.8230151529253353 | validation: 1.1334410254039355]
	TIME [epoch: 24.8 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.870118252847977		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.870118252847977 | validation: 1.1133353225929734]
	TIME [epoch: 24.8 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8755620198126766		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.8755620198126766 | validation: 0.7392446253939576]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_364.pth
	Model improved!!!
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7352162842978738		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.7352162842978738 | validation: 0.8783207400358143]
	TIME [epoch: 24.8 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7296841038936211		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.7296841038936211 | validation: 1.4521477378649275]
	TIME [epoch: 24.7 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9202761126555561		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.9202761126555561 | validation: 0.9375553667271578]
	TIME [epoch: 24.7 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7676072254965479		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.7676072254965479 | validation: 0.8858129008030556]
	TIME [epoch: 24.8 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7997749098900453		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.7997749098900453 | validation: 1.0493127779868419]
	TIME [epoch: 24.8 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7838266798498024		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.7838266798498024 | validation: 1.225637882582704]
	TIME [epoch: 24.8 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8507188559283092		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.8507188559283092 | validation: 0.7240593796956182]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_371.pth
	Model improved!!!
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.702974644418046		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.702974644418046 | validation: 0.7669290327551141]
	TIME [epoch: 24.8 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7080685840941934		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.7080685840941934 | validation: 0.851148050080873]
	TIME [epoch: 24.8 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8261948094038154		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.8261948094038154 | validation: 0.8937783085062065]
	TIME [epoch: 24.8 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7922612753729716		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.7922612753729716 | validation: 0.7699017691780157]
	TIME [epoch: 24.8 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7290286340381849		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.7290286340381849 | validation: 0.7769605348639493]
	TIME [epoch: 24.8 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6460268183101503		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.6460268183101503 | validation: 0.7267707059595995]
	TIME [epoch: 24.8 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8174934005437893		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.8174934005437893 | validation: 0.7753442019063153]
	TIME [epoch: 24.8 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5850792607846476		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 1.5850792607846476 | validation: 0.9733171163548804]
	TIME [epoch: 24.8 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7799967070685903		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.7799967070685903 | validation: 1.099587821532315]
	TIME [epoch: 24.8 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9750694920901928		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.9750694920901928 | validation: 1.0782394694110464]
	TIME [epoch: 24.8 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9020451634963196		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.9020451634963196 | validation: 0.7198491942116612]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_382.pth
	Model improved!!!
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7484136492294874		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.7484136492294874 | validation: 0.8135088710305494]
	TIME [epoch: 24.7 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7397256333116856		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.7397256333116856 | validation: 0.7928458785662121]
	TIME [epoch: 24.8 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7067353491996089		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.7067353491996089 | validation: 1.03872563113343]
	TIME [epoch: 24.7 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7742760512346342		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.7742760512346342 | validation: 0.9219722220966771]
	TIME [epoch: 24.8 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8522223922882717		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 1.8522223922882717 | validation: 4.756140372147956]
	TIME [epoch: 24.8 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9921500234987453		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 1.9921500234987453 | validation: 0.6255509676262072]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_388.pth
	Model improved!!!
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1050795750500844		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 1.1050795750500844 | validation: 1.1029612873874866]
	TIME [epoch: 24.8 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.830633051969476		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.830633051969476 | validation: 0.6917057905711943]
	TIME [epoch: 24.8 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7455601203895825		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.7455601203895825 | validation: 0.8230710501844476]
	TIME [epoch: 24.8 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.628247300624948		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 2.628247300624948 | validation: 6.466770145616851]
	TIME [epoch: 24.8 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0775239688367337		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 3.0775239688367337 | validation: 0.9982552528674409]
	TIME [epoch: 24.8 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8279230234787582		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.8279230234787582 | validation: 0.9755899338922348]
	TIME [epoch: 24.8 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7874038044418806		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.7874038044418806 | validation: 0.9436635719665191]
	TIME [epoch: 24.8 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7278059821776401		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.7278059821776401 | validation: 0.9228960094368182]
	TIME [epoch: 24.8 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7587812386889471		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.7587812386889471 | validation: 0.8612346869221105]
	TIME [epoch: 24.8 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7311791596894746		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.7311791596894746 | validation: 0.7672696981385625]
	TIME [epoch: 24.8 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7717039586195467		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.7717039586195467 | validation: 0.7755051238617466]
	TIME [epoch: 24.8 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7584438003253131		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.7584438003253131 | validation: 0.8512324383426989]
	TIME [epoch: 24.8 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7028485194236582		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.7028485194236582 | validation: 0.9294266938338581]
	TIME [epoch: 24.8 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7363179877101367		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.7363179877101367 | validation: 1.7851646392598415]
	TIME [epoch: 24.8 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3622910367507504		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 1.3622910367507504 | validation: 1.0033144650917438]
	TIME [epoch: 24.8 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.745377446096479		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.745377446096479 | validation: 1.1510526409914783]
	TIME [epoch: 24.8 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.938932473074262		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.938932473074262 | validation: 0.6814963014103995]
	TIME [epoch: 24.8 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7443531469576343		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.7443531469576343 | validation: 1.4154526565963048]
	TIME [epoch: 24.8 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8951836396422177		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.8951836396422177 | validation: 0.7392498209448541]
	TIME [epoch: 24.8 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7432531541223514		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.7432531541223514 | validation: 0.6985229528971553]
	TIME [epoch: 24.8 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8859638724826946		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.8859638724826946 | validation: 0.870012014704381]
	TIME [epoch: 24.8 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7852863815878546		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.7852863815878546 | validation: 0.7769256119405265]
	TIME [epoch: 24.8 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7052273882730339		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.7052273882730339 | validation: 0.8878610977778655]
	TIME [epoch: 24.8 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7303386022909868		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.7303386022909868 | validation: 0.8833233606719497]
	TIME [epoch: 24.8 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8105506709132115		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.8105506709132115 | validation: 0.8287245579124871]
	TIME [epoch: 24.8 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.66430129951789		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.66430129951789 | validation: 0.8362811247264744]
	TIME [epoch: 24.8 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.671847408505444		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.671847408505444 | validation: 0.6340162794286092]
	TIME [epoch: 24.8 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.73988980398987		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.73988980398987 | validation: 0.7173621153437597]
	TIME [epoch: 24.8 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7424195157243311		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.7424195157243311 | validation: 0.731608501859125]
	TIME [epoch: 24.8 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7347580930891342		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.7347580930891342 | validation: 0.6408310412400884]
	TIME [epoch: 24.8 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6615957307619971		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.6615957307619971 | validation: 1.1882413334233857]
	TIME [epoch: 24.8 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8330977572559957		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.8330977572559957 | validation: 0.6341893418946523]
	TIME [epoch: 24.8 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6342981540193438		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.6342981540193438 | validation: 0.63383052102639]
	TIME [epoch: 24.8 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6873825478251292		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.6873825478251292 | validation: 0.6376471639539811]
	TIME [epoch: 24.8 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.267438711576241		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 1.267438711576241 | validation: 0.7409646151876693]
	TIME [epoch: 24.8 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7618957100063056		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.7618957100063056 | validation: 0.7132973448206582]
	TIME [epoch: 24.8 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6937042087041322		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.6937042087041322 | validation: 0.7156675795110491]
	TIME [epoch: 24.8 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6383194534138692		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.6383194534138692 | validation: 0.7262355407632773]
	TIME [epoch: 24.8 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6657188104640077		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.6657188104640077 | validation: 0.848574292902495]
	TIME [epoch: 24.8 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6694776050148294		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.6694776050148294 | validation: 1.319600632274857]
	TIME [epoch: 24.8 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0313232329699107		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 1.0313232329699107 | validation: 1.2576035752920622]
	TIME [epoch: 24.8 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9961739929331833		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.9961739929331833 | validation: 1.1514207873410292]
	TIME [epoch: 24.8 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.966166101597039		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.966166101597039 | validation: 1.1768881262130566]
	TIME [epoch: 24.8 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8505171820398391		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.8505171820398391 | validation: 0.6772685110866351]
	TIME [epoch: 24.8 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7482418236241812		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.7482418236241812 | validation: 0.6837613052865303]
	TIME [epoch: 24.8 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6532452832630654		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.6532452832630654 | validation: 1.4587910366164585]
	TIME [epoch: 24.8 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8611555940194409		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.8611555940194409 | validation: 0.7151370494770859]
	TIME [epoch: 24.8 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7205829712867289		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.7205829712867289 | validation: 0.7842556223637217]
	TIME [epoch: 24.8 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7231265036834147		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.7231265036834147 | validation: 0.7066985592415024]
	TIME [epoch: 24.8 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6560185922676441		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.6560185922676441 | validation: 0.8109037177006009]
	TIME [epoch: 24.8 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6628482254883283		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.6628482254883283 | validation: 0.7510386120034594]
	TIME [epoch: 24.8 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7049830432264336		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.7049830432264336 | validation: 0.5699362162451027]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_440.pth
	Model improved!!!
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7065525223871021		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.7065525223871021 | validation: 0.6973872872598054]
	TIME [epoch: 24.8 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6373568722719829		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.6373568722719829 | validation: 0.8974801315375767]
	TIME [epoch: 24.8 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7069806318397194		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.7069806318397194 | validation: 0.8892703239686991]
	TIME [epoch: 24.8 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6107461959278807		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.6107461959278807 | validation: 0.7660362027012767]
	TIME [epoch: 24.8 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6810120706066813		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.6810120706066813 | validation: 0.6141968057152045]
	TIME [epoch: 24.8 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6224642178069661		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.6224642178069661 | validation: 0.629806511791208]
	TIME [epoch: 24.8 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2412293942577772		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 1.2412293942577772 | validation: 1.9481644124083055]
	TIME [epoch: 24.8 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9279967972311647		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.9279967972311647 | validation: 0.6756953392467028]
	TIME [epoch: 24.8 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6347910837975371		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.6347910837975371 | validation: 0.6335804423270873]
	TIME [epoch: 24.8 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8828646456881062		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.8828646456881062 | validation: 0.6137565258699921]
	TIME [epoch: 24.8 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6200791623195046		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.6200791623195046 | validation: 0.5996120838957867]
	TIME [epoch: 24.8 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.63113493176423		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.63113493176423 | validation: 0.7544509905798211]
	TIME [epoch: 24.8 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6360198487240392		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.6360198487240392 | validation: 1.2715029937041658]
	TIME [epoch: 24.8 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.900645089937557		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.900645089937557 | validation: 1.707681655073368]
	TIME [epoch: 24.8 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0386617322440543		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 1.0386617322440543 | validation: 1.615656605519502]
	TIME [epoch: 24.8 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.987820993361545		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.987820993361545 | validation: 1.1705669907076692]
	TIME [epoch: 24.8 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7216120949707141		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.7216120949707141 | validation: 0.6590456827412152]
	TIME [epoch: 24.8 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5964433574656857		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.5964433574656857 | validation: 0.9477205380847068]
	TIME [epoch: 24.8 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9635134504425809		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.9635134504425809 | validation: 1.0437851705208008]
	TIME [epoch: 24.9 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7777408201550859		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.7777408201550859 | validation: 0.6891869194210704]
	TIME [epoch: 24.8 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6102946662912297		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.6102946662912297 | validation: 0.6626886008210802]
	TIME [epoch: 24.8 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4238860808739147		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 2.4238860808739147 | validation: 0.6801315911450553]
	TIME [epoch: 24.8 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5997726596203441		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.5997726596203441 | validation: 2.092333779287804]
	TIME [epoch: 24.8 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2798900291641555		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 1.2798900291641555 | validation: 1.024890874124082]
	TIME [epoch: 24.8 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7664265278870228		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.7664265278870228 | validation: 0.8694777353950666]
	TIME [epoch: 24.8 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6550037830162865		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.6550037830162865 | validation: 0.7322995362515647]
	TIME [epoch: 24.8 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6319779413060718		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.6319779413060718 | validation: 0.5790346406958483]
	TIME [epoch: 24.8 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6463397022969215		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.6463397022969215 | validation: 0.8258466503501936]
	TIME [epoch: 24.9 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6890362331176568		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.6890362331176568 | validation: 0.6138744182994955]
	TIME [epoch: 24.8 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5836281799835362		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.5836281799835362 | validation: 0.7236397189063487]
	TIME [epoch: 24.8 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6206075889452233		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.6206075889452233 | validation: 0.6602421251185868]
	TIME [epoch: 24.8 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6329088215277239		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.6329088215277239 | validation: 0.7005324037418322]
	TIME [epoch: 24.8 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5776014445979288		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.5776014445979288 | validation: 0.5852496346812223]
	TIME [epoch: 24.8 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6107825971183655		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.6107825971183655 | validation: 0.6108024699685518]
	TIME [epoch: 24.8 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6258741185802261		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.6258741185802261 | validation: 0.6303073012345511]
	TIME [epoch: 24.8 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5624275354829577		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.5624275354829577 | validation: 0.9008803901082945]
	TIME [epoch: 24.8 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6258442131137535		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.6258442131137535 | validation: 0.5719657355043775]
	TIME [epoch: 24.8 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6622017382512598		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.6622017382512598 | validation: 0.48092824049803634]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_478.pth
	Model improved!!!
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7050267032859963		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 3.7050267032859963 | validation: 3.5525221610901916]
	TIME [epoch: 24.8 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3744808055225635		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 1.3744808055225635 | validation: 0.7171736134188084]
	TIME [epoch: 24.9 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7306344803553129		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.7306344803553129 | validation: 0.670106281573749]
	TIME [epoch: 24.8 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5944876718167346		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.5944876718167346 | validation: 0.5974033474628219]
	TIME [epoch: 24.8 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5833805937894321		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.5833805937894321 | validation: 0.6099247460730046]
	TIME [epoch: 24.9 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5964671087837052		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.5964671087837052 | validation: 0.6559674415742666]
	TIME [epoch: 24.8 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6072073121665961		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.6072073121665961 | validation: 0.6655982179622429]
	TIME [epoch: 24.8 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5230456045784556		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.5230456045784556 | validation: 0.7370993990968242]
	TIME [epoch: 24.9 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6287783927082075		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.6287783927082075 | validation: 0.49801091431979805]
	TIME [epoch: 24.8 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4841249333634375		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.4841249333634375 | validation: 0.42206791084362283]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_488.pth
	Model improved!!!
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6893420777069159		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.6893420777069159 | validation: 0.7917590210340184]
	TIME [epoch: 24.8 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2092778896571232		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 2.2092778896571232 | validation: 0.8034589502581718]
	TIME [epoch: 24.8 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6406716902574219		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.6406716902574219 | validation: 0.6027978285304392]
	TIME [epoch: 24.8 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5886665957898284		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.5886665957898284 | validation: 0.4865631554095947]
	TIME [epoch: 24.8 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5226447237616978		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.5226447237616978 | validation: 0.5146620862212175]
	TIME [epoch: 24.8 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5512141839112924		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.5512141839112924 | validation: 0.551266602835753]
	TIME [epoch: 24.8 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.886757750642745		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 1.886757750642745 | validation: 6.409443497432757]
	TIME [epoch: 24.8 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6231282822065634		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 3.6231282822065634 | validation: 0.8024528144882548]
	TIME [epoch: 24.8 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6435349014220189		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.6435349014220189 | validation: 1.0297222339345082]
	TIME [epoch: 24.8 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0344566923362555		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 2.0344566923362555 | validation: 0.5003461319543457]
	TIME [epoch: 24.8 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6314229849347242		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.6314229849347242 | validation: 0.44849219222978065]
	TIME [epoch: 24.8 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.715882797953379		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.715882797953379 | validation: 0.46146576507038317]
	TIME [epoch: 24.8 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7298313231256566		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.7298313231256566 | validation: 0.7286741493050414]
	TIME [epoch: 24.8 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6344112720287218		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.6344112720287218 | validation: 0.7616852507814135]
	TIME [epoch: 24.8 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5949837422917315		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.5949837422917315 | validation: 0.578204389559505]
	TIME [epoch: 24.8 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5916573437668337		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.5916573437668337 | validation: 0.5005635116458095]
	TIME [epoch: 24.8 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6026188484745295		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.6026188484745295 | validation: 0.5776787064271318]
	TIME [epoch: 24.8 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6049022408318103		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.6049022408318103 | validation: 0.6759767653708313]
	TIME [epoch: 24.8 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6799029113108237		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.6799029113108237 | validation: 0.687118183356653]
	TIME [epoch: 24.8 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6344149731703863		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.6344149731703863 | validation: 0.6219296948964602]
	TIME [epoch: 24.8 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6428565962157882		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.6428565962157882 | validation: 0.8352878924882414]
	TIME [epoch: 24.8 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5885350541071233		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.5885350541071233 | validation: 0.7697422480469748]
	TIME [epoch: 24.8 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5861835894375634		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.5861835894375634 | validation: 0.5768368398980984]
	TIME [epoch: 24.8 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6272459484031188		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.6272459484031188 | validation: 0.501422418604415]
	TIME [epoch: 24.8 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6127339160252658		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.6127339160252658 | validation: 0.7350043712042114]
	TIME [epoch: 24.8 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5757238981541961		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.5757238981541961 | validation: 0.46828587430310203]
	TIME [epoch: 24.8 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5603490058333244		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.5603490058333244 | validation: 0.6166169134065861]
	TIME [epoch: 24.8 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.560254225360743		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.560254225360743 | validation: 0.7190102717672171]
	TIME [epoch: 24.8 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5060374586328643		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.5060374586328643 | validation: 0.6569056602722302]
	TIME [epoch: 24.8 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5817254292394767		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.5817254292394767 | validation: 0.5637294706601762]
	TIME [epoch: 24.8 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5468930889246472		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.5468930889246472 | validation: 0.5734904351164819]
	TIME [epoch: 24.8 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5663485734505684		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.5663485734505684 | validation: 0.6078540911983258]
	TIME [epoch: 24.8 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5497691937279126		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.5497691937279126 | validation: 0.5194282869555411]
	TIME [epoch: 24.8 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5708739929182156		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.5708739929182156 | validation: 1.019142083884165]
	TIME [epoch: 24.8 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8370097099556502		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.8370097099556502 | validation: 0.4282340261288375]
	TIME [epoch: 24.8 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5639655370166993		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.5639655370166993 | validation: 0.4368561404076526]
	TIME [epoch: 24.8 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5765833027076233		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.5765833027076233 | validation: 0.6784906797759079]
	TIME [epoch: 24.8 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5396722613715147		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.5396722613715147 | validation: 0.5513917409567836]
	TIME [epoch: 24.8 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5675596795797043		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.5675596795797043 | validation: 0.6262484506518157]
	TIME [epoch: 24.8 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5709639231511543		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.5709639231511543 | validation: 0.7425709140138621]
	TIME [epoch: 24.8 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6437591598445924		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.6437591598445924 | validation: 0.9613533521708276]
	TIME [epoch: 24.8 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7498346484098256		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.7498346484098256 | validation: 0.6199135464675493]
	TIME [epoch: 24.8 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.636187225283892		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.636187225283892 | validation: 0.5618405256020961]
	TIME [epoch: 24.8 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5345216887575616		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.5345216887575616 | validation: 0.6040553966727681]
	TIME [epoch: 24.8 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.643584923620663		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.643584923620663 | validation: 0.47709129763062363]
	TIME [epoch: 24.8 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4973738985038379		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.4973738985038379 | validation: 0.8435830230941835]
	TIME [epoch: 24.8 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.576895518788525		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.576895518788525 | validation: 0.5120002975468124]
	TIME [epoch: 24.8 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5628475763750276		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.5628475763750276 | validation: 0.6006087385725783]
	TIME [epoch: 24.8 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5537084890689057		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.5537084890689057 | validation: 0.6298860185677857]
	TIME [epoch: 24.8 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5419766433950626		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.5419766433950626 | validation: 0.8269947608933228]
	TIME [epoch: 24.8 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6065613952079868		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.6065613952079868 | validation: 0.6732135899630336]
	TIME [epoch: 24.8 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6220756916447284		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.6220756916447284 | validation: 0.6207799455300678]
	TIME [epoch: 24.8 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5404271084330461		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.5404271084330461 | validation: 0.5504025792230286]
	TIME [epoch: 24.8 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5459293733459027		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.5459293733459027 | validation: 0.6132482609524865]
	TIME [epoch: 24.8 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5224049245777918		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.5224049245777918 | validation: 0.6213791283503888]
	TIME [epoch: 24.8 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6081533750913569		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.6081533750913569 | validation: 1.0085102672951]
	TIME [epoch: 24.8 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6910050700241767		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.6910050700241767 | validation: 0.6169574019755456]
	TIME [epoch: 24.8 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5474423544809288		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.5474423544809288 | validation: 0.9078064715637615]
	TIME [epoch: 24.8 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7690691562782712		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.7690691562782712 | validation: 0.789793015166634]
	TIME [epoch: 24.8 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5569040431070325		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.5569040431070325 | validation: 0.5530112651168063]
	TIME [epoch: 24.8 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5886911406088715		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.5886911406088715 | validation: 0.5254710876946986]
	TIME [epoch: 24.8 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6846763626631824		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.6846763626631824 | validation: 0.48512965684124737]
	TIME [epoch: 24.8 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8360575607126985		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.8360575607126985 | validation: 0.6975703564209244]
	TIME [epoch: 24.8 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7329730342090739		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.7329730342090739 | validation: 0.6593176206545915]
	TIME [epoch: 24.8 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7349070034295311		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.7349070034295311 | validation: 0.6848711438845906]
	TIME [epoch: 24.8 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6390562368497728		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.6390562368497728 | validation: 0.5771144082938706]
	TIME [epoch: 24.8 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7021026941665335		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.7021026941665335 | validation: 0.6160127170585651]
	TIME [epoch: 24.8 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6574641212950242		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.6574641212950242 | validation: 0.506118999312886]
	TIME [epoch: 24.8 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5376115591333571		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.5376115591333571 | validation: 0.4779524656841595]
	TIME [epoch: 24.8 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5644639797547395		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.5644639797547395 | validation: 0.6620493443824071]
	TIME [epoch: 24.8 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6825701468895332		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.6825701468895332 | validation: 0.5982821135788122]
	TIME [epoch: 24.8 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5180589757117924		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.5180589757117924 | validation: 0.5034741544838667]
	TIME [epoch: 24.8 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43428333985017525		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.43428333985017525 | validation: 0.6471861586479849]
	TIME [epoch: 24.8 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.566454631510177		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.566454631510177 | validation: 0.6100914852469345]
	TIME [epoch: 24.8 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.527166210149387		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.527166210149387 | validation: 0.5077331480047768]
	TIME [epoch: 24.8 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5744870048935267		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.5744870048935267 | validation: 0.6627375705237663]
	TIME [epoch: 24.8 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4905648497236238		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.4905648497236238 | validation: 1.0614472244599902]
	TIME [epoch: 24.8 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6404533278536514		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.6404533278536514 | validation: 0.9527665712671185]
	TIME [epoch: 24.8 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6467003918087253		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.6467003918087253 | validation: 0.6132607127260452]
	TIME [epoch: 24.8 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5129570041013096		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.5129570041013096 | validation: 0.56335434410849]
	TIME [epoch: 24.8 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5458920028235978		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.5458920028235978 | validation: 0.5754904399233449]
	TIME [epoch: 24.8 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9288894049148797		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.9288894049148797 | validation: 0.6094975754073653]
	TIME [epoch: 24.8 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7274168816820996		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.7274168816820996 | validation: 0.5309129980991912]
	TIME [epoch: 24.8 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6415229937005744		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.6415229937005744 | validation: 0.5343451027489273]
	TIME [epoch: 24.8 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5564360600795671		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.5564360600795671 | validation: 0.596295870413942]
	TIME [epoch: 24.8 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5776994045146968		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.5776994045146968 | validation: 0.5836509670780471]
	TIME [epoch: 24.8 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.481809381958851		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.481809381958851 | validation: 0.4708045314668102]
	TIME [epoch: 24.8 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9645966660461687		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.9645966660461687 | validation: 0.7398284565273991]
	TIME [epoch: 24.8 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5676461205888212		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.5676461205888212 | validation: 0.6793690235201796]
	TIME [epoch: 24.8 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5135388144288101		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.5135388144288101 | validation: 0.6372130658805185]
	TIME [epoch: 24.8 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4930367347560387		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.4930367347560387 | validation: 0.9476848108018544]
	TIME [epoch: 24.8 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6730380140925201		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.6730380140925201 | validation: 0.6956085601645182]
	TIME [epoch: 24.8 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6197769758274176		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.6197769758274176 | validation: 0.561083405900652]
	TIME [epoch: 24.8 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5252794990824878		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.5252794990824878 | validation: 0.5649004612831756]
	TIME [epoch: 24.8 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5343744248489375		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.5343744248489375 | validation: 0.6957764389350736]
	TIME [epoch: 24.8 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5746770844722914		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.5746770844722914 | validation: 0.5307981215542025]
	TIME [epoch: 24.8 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5034501691385115		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.5034501691385115 | validation: 0.5507873020750784]
	TIME [epoch: 24.8 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5299469304897142		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.5299469304897142 | validation: 0.640635497507457]
	TIME [epoch: 24.8 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.545617536818572		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.545617536818572 | validation: 0.6303544459213856]
	TIME [epoch: 24.8 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.530935396362634		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.530935396362634 | validation: 0.49724101335121357]
	TIME [epoch: 24.8 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4977305830241496		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.4977305830241496 | validation: 0.5106133930426077]
	TIME [epoch: 24.8 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46478723099248054		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.46478723099248054 | validation: 0.5785163283209598]
	TIME [epoch: 24.8 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7113936995507737		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.7113936995507737 | validation: 0.4805607706008365]
	TIME [epoch: 24.8 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5645410571006714		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.5645410571006714 | validation: 0.4672686153425592]
	TIME [epoch: 24.8 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5138977600595578		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.5138977600595578 | validation: 0.5331645028490868]
	TIME [epoch: 24.8 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5095351104770016		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.5095351104770016 | validation: 0.7507556344364431]
	TIME [epoch: 24.8 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5986797918044208		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.5986797918044208 | validation: 0.5602615084717172]
	TIME [epoch: 24.8 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.555850539894454		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.555850539894454 | validation: 0.4904229843265469]
	TIME [epoch: 24.8 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5459670437063623		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.5459670437063623 | validation: 0.7222524579755382]
	TIME [epoch: 24.8 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5697799631187783		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.5697799631187783 | validation: 0.5354577271949782]
	TIME [epoch: 24.8 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4986988531185699		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.4986988531185699 | validation: 0.4458244524923468]
	TIME [epoch: 24.8 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.603673825724764		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.603673825724764 | validation: 0.520949885315211]
	TIME [epoch: 24.8 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6099792244076729		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.6099792244076729 | validation: 0.5534570090816764]
	TIME [epoch: 24.8 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49288102752400953		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.49288102752400953 | validation: 1.4777063669123163]
	TIME [epoch: 24.8 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7704588789879443		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.7704588789879443 | validation: 0.7288910975095019]
	TIME [epoch: 24.9 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5523282650585157		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.5523282650585157 | validation: 0.4978875127315621]
	TIME [epoch: 24.8 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5230258675347095		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.5230258675347095 | validation: 0.6596634554412814]
	TIME [epoch: 24.8 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6101388133861328		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.6101388133861328 | validation: 0.5842804807684718]
	TIME [epoch: 24.8 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5334600370664657		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.5334600370664657 | validation: 0.577783577800007]
	TIME [epoch: 24.8 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4901436766914334		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.4901436766914334 | validation: 0.40655278352256213]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_608.pth
	Model improved!!!
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4470337004791438		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.4470337004791438 | validation: 0.5484004043778942]
	TIME [epoch: 24.8 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5243452265824042		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.5243452265824042 | validation: 0.627449306701806]
	TIME [epoch: 24.8 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5467522526428793		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.5467522526428793 | validation: 0.4146860101707249]
	TIME [epoch: 24.8 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46006188192287445		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.46006188192287445 | validation: 0.573178547632691]
	TIME [epoch: 24.8 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6797512083416806		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.6797512083416806 | validation: 0.44366965593086977]
	TIME [epoch: 24.8 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5561080119239942		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.5561080119239942 | validation: 0.6148331412593337]
	TIME [epoch: 24.8 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5582222825594298		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.5582222825594298 | validation: 0.5365166218728713]
	TIME [epoch: 24.8 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.596538312400908		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.596538312400908 | validation: 0.5787802580207837]
	TIME [epoch: 24.8 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5154435876964685		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.5154435876964685 | validation: 0.515509696858589]
	TIME [epoch: 24.8 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49202388835378585		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.49202388835378585 | validation: 0.43792640891156537]
	TIME [epoch: 24.8 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46684261596472193		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.46684261596472193 | validation: 0.5314233195559923]
	TIME [epoch: 24.7 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5736409437848803		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.5736409437848803 | validation: 0.8009347462505576]
	TIME [epoch: 24.8 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6254215905425919		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.6254215905425919 | validation: 0.5053334380886054]
	TIME [epoch: 24.8 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5159920416352722		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.5159920416352722 | validation: 0.46111187342835264]
	TIME [epoch: 24.8 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5735221281718735		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.5735221281718735 | validation: 0.4968125480887966]
	TIME [epoch: 24.8 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5065009399295993		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.5065009399295993 | validation: 0.5829820539118634]
	TIME [epoch: 24.8 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5394192995842664		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.5394192995842664 | validation: 0.5134830996002662]
	TIME [epoch: 24.8 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4652511002655954		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.4652511002655954 | validation: 0.5873851385275266]
	TIME [epoch: 24.8 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5067842956293688		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.5067842956293688 | validation: 0.5146430743701226]
	TIME [epoch: 24.8 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4953305356350014		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.4953305356350014 | validation: 0.6307546890959419]
	TIME [epoch: 24.8 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5058019114075403		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.5058019114075403 | validation: 0.5904861105019316]
	TIME [epoch: 24.8 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5211260451494106		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.5211260451494106 | validation: 0.6931030094435461]
	TIME [epoch: 24.8 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5475864144670101		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.5475864144670101 | validation: 0.5267623388398015]
	TIME [epoch: 24.8 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4751611072255688		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.4751611072255688 | validation: 0.5356354401593771]
	TIME [epoch: 24.8 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4548728839749069		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.4548728839749069 | validation: 0.5891134504096097]
	TIME [epoch: 24.7 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48346236835675904		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.48346236835675904 | validation: 0.5206287271270946]
	TIME [epoch: 24.8 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4635282397615018		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.4635282397615018 | validation: 0.5290156190157861]
	TIME [epoch: 24.8 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5937637759160297		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.5937637759160297 | validation: 1.294007388005698]
	TIME [epoch: 24.8 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9165906495452729		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.9165906495452729 | validation: 0.45405553733067733]
	TIME [epoch: 24.7 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5845962638431222		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.5845962638431222 | validation: 0.6289588862992713]
	TIME [epoch: 24.8 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44603910546156744		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.44603910546156744 | validation: 0.5109676088124668]
	TIME [epoch: 24.8 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5056554480403388		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.5056554480403388 | validation: 0.5972006667657057]
	TIME [epoch: 24.7 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4977958694376239		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.4977958694376239 | validation: 0.5215153966404724]
	TIME [epoch: 24.8 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5027603160787577		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.5027603160787577 | validation: 0.8564554914932205]
	TIME [epoch: 24.8 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6283520820684728		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.6283520820684728 | validation: 0.5526755912433265]
	TIME [epoch: 24.7 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5392287297789815		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.5392287297789815 | validation: 0.49713799978879275]
	TIME [epoch: 24.8 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5096347743892105		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.5096347743892105 | validation: 0.5123984577592319]
	TIME [epoch: 24.8 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5052578051215034		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.5052578051215034 | validation: 0.48199749271648423]
	TIME [epoch: 24.8 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5327972691239188		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.5327972691239188 | validation: 0.5777588507397768]
	TIME [epoch: 24.8 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46344591083699643		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.46344591083699643 | validation: 0.8117824979110614]
	TIME [epoch: 24.8 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6764624329701726		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.6764624329701726 | validation: 0.9726283611676957]
	TIME [epoch: 24.8 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6105901484107105		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.6105901484107105 | validation: 0.6230872574495839]
	TIME [epoch: 24.8 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49419673978644685		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.49419673978644685 | validation: 0.6997329315474269]
	TIME [epoch: 24.7 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5568481714988247		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.5568481714988247 | validation: 0.5469770140169067]
	TIME [epoch: 24.8 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5336341658772323		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.5336341658772323 | validation: 0.5054155234480845]
	TIME [epoch: 24.8 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4547348748461727		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.4547348748461727 | validation: 0.5210744910226186]
	TIME [epoch: 24.8 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5233404525223233		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.5233404525223233 | validation: 0.4004342217683091]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_655.pth
	Model improved!!!
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49566006123099116		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.49566006123099116 | validation: 0.5527983894707101]
	TIME [epoch: 24.8 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6006035724441616		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.6006035724441616 | validation: 0.4473311457991073]
	TIME [epoch: 24.8 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4767455426916647		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.4767455426916647 | validation: 0.45760870880163224]
	TIME [epoch: 24.8 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5173193158751882		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.5173193158751882 | validation: 0.44567616479106714]
	TIME [epoch: 24.8 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4675274266993088		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.4675274266993088 | validation: 0.5046906907332468]
	TIME [epoch: 24.8 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4515644721897004		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.4515644721897004 | validation: 0.47566068005306184]
	TIME [epoch: 24.8 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46171173461870463		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.46171173461870463 | validation: 0.44461679721748704]
	TIME [epoch: 24.8 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49387683650203307		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.49387683650203307 | validation: 0.552431002561918]
	TIME [epoch: 24.8 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5572281557278653		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.5572281557278653 | validation: 0.5334959882105239]
	TIME [epoch: 24.7 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49319690128628485		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.49319690128628485 | validation: 0.5666453901398454]
	TIME [epoch: 24.8 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44744584937439313		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.44744584937439313 | validation: 0.49477254070886056]
	TIME [epoch: 24.8 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45958281200123485		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.45958281200123485 | validation: 0.481607989884774]
	TIME [epoch: 24.8 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4086443773108013		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.4086443773108013 | validation: 0.3027647932392418]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_668.pth
	Model improved!!!
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4561632098413612		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.4561632098413612 | validation: 0.452204734516573]
	TIME [epoch: 24.8 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48207274508980635		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.48207274508980635 | validation: 0.4037815171105507]
	TIME [epoch: 24.7 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5257439259233443		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.5257439259233443 | validation: 0.5546144790987906]
	TIME [epoch: 24.8 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5211259893171589		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.5211259893171589 | validation: 0.43895925442690853]
	TIME [epoch: 24.8 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4129652753251851		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.4129652753251851 | validation: 0.3839611215475145]
	TIME [epoch: 24.8 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4333368131277854		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.4333368131277854 | validation: 0.5088352060668383]
	TIME [epoch: 24.8 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49306508931141557		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.49306508931141557 | validation: 0.41336404863038556]
	TIME [epoch: 24.8 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44792383939381164		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.44792383939381164 | validation: 0.56431857664591]
	TIME [epoch: 24.8 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4658621444434342		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.4658621444434342 | validation: 0.5517615146300964]
	TIME [epoch: 24.8 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5592876999179427		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.5592876999179427 | validation: 0.47195790167442697]
	TIME [epoch: 24.8 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5789038701636322		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.5789038701636322 | validation: 0.5264004901612311]
	TIME [epoch: 24.7 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48257096917920794		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.48257096917920794 | validation: 0.4049899431079069]
	TIME [epoch: 24.8 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4785998924598598		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.4785998924598598 | validation: 0.40406289431226483]
	TIME [epoch: 24.7 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42618556973284993		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.42618556973284993 | validation: 0.4696345353355663]
	TIME [epoch: 24.8 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.526354608648619		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.526354608648619 | validation: 0.3986546681442475]
	TIME [epoch: 24.7 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4263117594353053		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.4263117594353053 | validation: 0.49358235026958425]
	TIME [epoch: 24.7 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5100928934693789		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.5100928934693789 | validation: 0.6263779483502122]
	TIME [epoch: 24.7 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5242195201422367		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.5242195201422367 | validation: 0.6931183721225099]
	TIME [epoch: 24.7 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5191522639388367		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.5191522639388367 | validation: 0.5332575893625038]
	TIME [epoch: 24.7 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49039326519754434		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.49039326519754434 | validation: 0.42322125998044147]
	TIME [epoch: 24.8 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5325640451918034		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.5325640451918034 | validation: 0.49304979846172425]
	TIME [epoch: 24.7 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5369882732295937		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.5369882732295937 | validation: 0.43250516187557464]
	TIME [epoch: 24.7 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5511934916124559		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.5511934916124559 | validation: 0.39110199130873974]
	TIME [epoch: 24.7 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4255839752967383		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.4255839752967383 | validation: 0.539449909305762]
	TIME [epoch: 24.8 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5518792085856542		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.5518792085856542 | validation: 0.5038278702130247]
	TIME [epoch: 24.7 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41638789851380364		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.41638789851380364 | validation: 0.8803179486698864]
	TIME [epoch: 24.7 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5637419799800171		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.5637419799800171 | validation: 0.545108864432447]
	TIME [epoch: 24.7 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4015296217234184		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.4015296217234184 | validation: 0.679795305963801]
	TIME [epoch: 24.7 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6048722622716656		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.6048722622716656 | validation: 0.5686902932831838]
	TIME [epoch: 24.7 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4640689921736527		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.4640689921736527 | validation: 0.5246244948935496]
	TIME [epoch: 24.7 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4376217051772795		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.4376217051772795 | validation: 0.3829886668424882]
	TIME [epoch: 24.7 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.530389227595197		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.530389227595197 | validation: 0.39815805538117616]
	TIME [epoch: 24.7 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44524672809977467		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.44524672809977467 | validation: 0.47680463564586234]
	TIME [epoch: 24.8 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4500331848075735		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.4500331848075735 | validation: 0.42998832626120503]
	TIME [epoch: 24.7 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4966924994568585		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.4966924994568585 | validation: 0.5182011139980536]
	TIME [epoch: 24.7 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4660236920787147		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.4660236920787147 | validation: 0.5735764264953649]
	TIME [epoch: 24.8 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4540531868630971		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.4540531868630971 | validation: 0.5114412216090262]
	TIME [epoch: 24.7 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4812933771958035		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.4812933771958035 | validation: 0.44243385348811587]
	TIME [epoch: 24.7 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44427785718018425		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.44427785718018425 | validation: 0.6476750673741383]
	TIME [epoch: 24.8 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5560041658727293		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.5560041658727293 | validation: 0.6263570627266128]
	TIME [epoch: 24.7 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46665816481281186		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.46665816481281186 | validation: 0.737207933215243]
	TIME [epoch: 24.7 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5445674009795786		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.5445674009795786 | validation: 0.5207325565508455]
	TIME [epoch: 24.7 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46327255212425145		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.46327255212425145 | validation: 0.5931996920164558]
	TIME [epoch: 24.7 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45557857852048933		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.45557857852048933 | validation: 0.5350678014666013]
	TIME [epoch: 24.7 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4417348554485504		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.4417348554485504 | validation: 0.5635568028197132]
	TIME [epoch: 24.8 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47060831672436493		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.47060831672436493 | validation: 0.5080597761235413]
	TIME [epoch: 24.7 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.442377289906417		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.442377289906417 | validation: 0.4825511736484592]
	TIME [epoch: 24.7 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43930204651301463		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.43930204651301463 | validation: 0.4621066793693124]
	TIME [epoch: 24.8 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6120250082438123		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.6120250082438123 | validation: 0.6575313987049052]
	TIME [epoch: 24.7 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6305708061797483		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.6305708061797483 | validation: 0.49099956977496034]
	TIME [epoch: 24.7 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4511295077673162		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.4511295077673162 | validation: 0.49502580758945564]
	TIME [epoch: 24.8 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4376586449333143		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.4376586449333143 | validation: 0.512485728385477]
	TIME [epoch: 24.7 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4775381043750374		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.4775381043750374 | validation: 0.52157699850313]
	TIME [epoch: 24.7 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.504041896089062		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.504041896089062 | validation: 0.47907725492516234]
	TIME [epoch: 24.7 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49719218392149833		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.49719218392149833 | validation: 0.47711308531413227]
	TIME [epoch: 24.7 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4517430937981305		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.4517430937981305 | validation: 0.7049359935011696]
	TIME [epoch: 24.7 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46965295398943196		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.46965295398943196 | validation: 0.43459541005395547]
	TIME [epoch: 24.7 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43097827495108537		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.43097827495108537 | validation: 0.44743765395783713]
	TIME [epoch: 24.7 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41827291270163613		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.41827291270163613 | validation: 0.5365787977692279]
	TIME [epoch: 24.7 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5186260493734219		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.5186260493734219 | validation: 0.5336790131875978]
	TIME [epoch: 24.8 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5226975768955162		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.5226975768955162 | validation: 0.4722368560763087]
	TIME [epoch: 24.7 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5506051042798108		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.5506051042798108 | validation: 0.6870530054464827]
	TIME [epoch: 24.7 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5324754820118646		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.5324754820118646 | validation: 0.450522737449244]
	TIME [epoch: 24.8 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42650414533381803		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.42650414533381803 | validation: 0.5171164877889651]
	TIME [epoch: 24.7 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43779037989775227		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.43779037989775227 | validation: 0.52041702523991]
	TIME [epoch: 24.8 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44533647853804326		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.44533647853804326 | validation: 0.4740170482661803]
	TIME [epoch: 24.9 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4906581338706876		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.4906581338706876 | validation: 0.6254564394448741]
	TIME [epoch: 24.8 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46613640691069763		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.46613640691069763 | validation: 0.5724847403683879]
	TIME [epoch: 24.9 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4639829364856042		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.4639829364856042 | validation: 0.5451239215142738]
	TIME [epoch: 24.8 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42429057425457		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.42429057425457 | validation: 0.882480848251744]
	TIME [epoch: 24.8 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5722871560517071		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.5722871560517071 | validation: 0.433021462170492]
	TIME [epoch: 24.8 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42009742681723433		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.42009742681723433 | validation: 0.4264091031804723]
	TIME [epoch: 24.8 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39244474767221055		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.39244474767221055 | validation: 0.3999119642178542]
	TIME [epoch: 24.7 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.409838518735561		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.409838518735561 | validation: 0.39658652292280766]
	TIME [epoch: 24.8 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4082529396176108		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.4082529396176108 | validation: 0.43889142526168234]
	TIME [epoch: 24.8 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41177006334591953		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.41177006334591953 | validation: 0.4752814095915038]
	TIME [epoch: 24.8 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4369670595248189		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.4369670595248189 | validation: 0.43137319040383987]
	TIME [epoch: 24.8 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.423182321457267		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.423182321457267 | validation: 0.44182761249422436]
	TIME [epoch: 24.8 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5182705401182413		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.5182705401182413 | validation: 0.44518415468176215]
	TIME [epoch: 24.8 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42295891311612027		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.42295891311612027 | validation: 0.5765740818254559]
	TIME [epoch: 24.8 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45612682058112614		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.45612682058112614 | validation: 0.5274534990731122]
	TIME [epoch: 24.8 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44743919110485586		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.44743919110485586 | validation: 0.49518655838285797]
	TIME [epoch: 24.7 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44261019921537714		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.44261019921537714 | validation: 0.47384976045837]
	TIME [epoch: 24.8 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42963950735826606		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.42963950735826606 | validation: 0.5392313022846154]
	TIME [epoch: 24.8 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4510666173260732		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.4510666173260732 | validation: 0.4100517082929085]
	TIME [epoch: 24.7 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4147534645159107		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.4147534645159107 | validation: 0.5111399751858594]
	TIME [epoch: 24.8 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4230341611019811		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.4230341611019811 | validation: 0.5380637280703278]
	TIME [epoch: 24.8 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4883628457136743		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.4883628457136743 | validation: 0.5129234582151895]
	TIME [epoch: 24.8 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43967123275048203		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.43967123275048203 | validation: 0.5141785469372383]
	TIME [epoch: 24.8 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41628715264731997		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.41628715264731997 | validation: 0.47982440494240336]
	TIME [epoch: 24.8 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44180619311492675		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.44180619311492675 | validation: 0.5227848444596226]
	TIME [epoch: 24.8 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45682709451536674		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.45682709451536674 | validation: 0.4480656144670535]
	TIME [epoch: 24.8 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.409609745895052		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.409609745895052 | validation: 0.3945395177727942]
	TIME [epoch: 24.8 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37997355621593887		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.37997355621593887 | validation: 0.5223458582406848]
	TIME [epoch: 24.8 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5172252130713985		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.5172252130713985 | validation: 0.5718588289323868]
	TIME [epoch: 24.8 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4487592792221994		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.4487592792221994 | validation: 0.5044864227109223]
	TIME [epoch: 24.8 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4422498233315802		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.4422498233315802 | validation: 0.4398604495401898]
	TIME [epoch: 24.8 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44914277615685916		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.44914277615685916 | validation: 0.5580934275611034]
	TIME [epoch: 24.8 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45591868970993565		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.45591868970993565 | validation: 0.5117512939944935]
	TIME [epoch: 24.8 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4292286463157643		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.4292286463157643 | validation: 0.5319446239799518]
	TIME [epoch: 24.8 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45573507450731243		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.45573507450731243 | validation: 0.5767025965448929]
	TIME [epoch: 24.8 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4666186403608319		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.4666186403608319 | validation: 0.4943456989310006]
	TIME [epoch: 24.8 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4392176581982092		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.4392176581982092 | validation: 0.48284709875508164]
	TIME [epoch: 24.8 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4656268131831846		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.4656268131831846 | validation: 0.3912391398363379]
	TIME [epoch: 24.8 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37054089644298016		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.37054089644298016 | validation: 0.43005599690254087]
	TIME [epoch: 24.8 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4112591959534507		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.4112591959534507 | validation: 0.5369871165981709]
	TIME [epoch: 24.8 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4048597390365233		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.4048597390365233 | validation: 0.5232194298287206]
	TIME [epoch: 24.8 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5518055778768653		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.5518055778768653 | validation: 0.46115206199488895]
	TIME [epoch: 24.8 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4490761868255361		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.4490761868255361 | validation: 0.39216155143369186]
	TIME [epoch: 24.8 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41589103701886077		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.41589103701886077 | validation: 0.40111818861525217]
	TIME [epoch: 24.8 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4113664770871852		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.4113664770871852 | validation: 0.4624090202033682]
	TIME [epoch: 24.8 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4725172923768336		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.4725172923768336 | validation: 0.41610883478043226]
	TIME [epoch: 24.8 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7467302566916623		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.7467302566916623 | validation: 1.264330468351184]
	TIME [epoch: 24.8 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8113791271103639		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.8113791271103639 | validation: 0.29268708116196057]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_782.pth
	Model improved!!!
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3988941511277081		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.3988941511277081 | validation: 0.44262122448538377]
	TIME [epoch: 24.8 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40562773863168955		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.40562773863168955 | validation: 0.3765873877986443]
	TIME [epoch: 24.8 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4015746229910895		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.4015746229910895 | validation: 0.2657421184902475]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_785.pth
	Model improved!!!
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38555551127084464		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.38555551127084464 | validation: 0.49723590567531245]
	TIME [epoch: 24.7 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43913191610011204		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.43913191610011204 | validation: 0.6964716169563921]
	TIME [epoch: 24.8 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4429537556710118		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.4429537556710118 | validation: 0.6768409764296351]
	TIME [epoch: 24.8 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8181158900332726		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.8181158900332726 | validation: 0.49113208797147184]
	TIME [epoch: 24.7 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4895841785986016		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.4895841785986016 | validation: 0.25961653668445145]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_790.pth
	Model improved!!!
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3417404802742726		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.3417404802742726 | validation: 0.34404972465516437]
	TIME [epoch: 24.8 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41458737776482735		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.41458737776482735 | validation: 0.4319426277832635]
	TIME [epoch: 24.8 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4179042411831697		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.4179042411831697 | validation: 0.3446515975653947]
	TIME [epoch: 24.8 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3455687488984415		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.3455687488984415 | validation: 0.40338721371079417]
	TIME [epoch: 24.8 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4169574267971799		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.4169574267971799 | validation: 0.3382947993220289]
	TIME [epoch: 24.7 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4238198783962639		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.4238198783962639 | validation: 0.31887785353751213]
	TIME [epoch: 24.8 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33842595447946333		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.33842595447946333 | validation: 0.44928199694648263]
	TIME [epoch: 24.7 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.557042935473484		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.557042935473484 | validation: 0.3033102394564476]
	TIME [epoch: 24.7 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3646190353570233		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.3646190353570233 | validation: 0.5112427473124314]
	TIME [epoch: 24.8 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44384222835912784		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.44384222835912784 | validation: 0.5229976666068784]
	TIME [epoch: 24.8 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42943889956696457		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.42943889956696457 | validation: 0.3886617745544811]
	TIME [epoch: 24.8 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3635206017163876		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.3635206017163876 | validation: 0.36037507773341515]
	TIME [epoch: 24.8 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35269352026121786		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.35269352026121786 | validation: 0.3603993052494133]
	TIME [epoch: 24.8 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.387353722741823		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.387353722741823 | validation: 0.44407191927027995]
	TIME [epoch: 24.7 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3804146272054861		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.3804146272054861 | validation: 0.2867129252311535]
	TIME [epoch: 24.8 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44615719446776125		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.44615719446776125 | validation: 0.5012660720854835]
	TIME [epoch: 24.7 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4556780920312783		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.4556780920312783 | validation: 0.3439136412051452]
	TIME [epoch: 24.7 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.365156140326099		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.365156140326099 | validation: 0.343901302975399]
	TIME [epoch: 24.8 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3805567910719342		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.3805567910719342 | validation: 0.40342370085721585]
	TIME [epoch: 24.7 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3864210252716862		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.3864210252716862 | validation: 0.3936246868051196]
	TIME [epoch: 24.8 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38620318846049073		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.38620318846049073 | validation: 0.4268994597431234]
	TIME [epoch: 24.8 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3924400517263975		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.3924400517263975 | validation: 0.45991035922797047]
	TIME [epoch: 24.8 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36023786811007347		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.36023786811007347 | validation: 0.3058980041163723]
	TIME [epoch: 24.8 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3603062079843282		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.3603062079843282 | validation: 0.3864953539980948]
	TIME [epoch: 24.8 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39800642848427137		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.39800642848427137 | validation: 0.4220041926889937]
	TIME [epoch: 24.8 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.384370349896594		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.384370349896594 | validation: 0.34972730208311603]
	TIME [epoch: 24.7 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41079563249881107		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.41079563249881107 | validation: 0.4256901458059258]
	TIME [epoch: 24.7 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4498977729441276		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.4498977729441276 | validation: 0.4323041577610573]
	TIME [epoch: 24.7 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40272064128632906		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.40272064128632906 | validation: 0.40342863899611564]
	TIME [epoch: 24.7 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38566088638130236		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.38566088638130236 | validation: 0.3541549528752495]
	TIME [epoch: 24.8 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3874400181150737		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.3874400181150737 | validation: 0.32767527653539674]
	TIME [epoch: 24.7 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36229222119284327		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.36229222119284327 | validation: 0.3464119064401101]
	TIME [epoch: 24.7 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3860614507444736		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.3860614507444736 | validation: 0.4429729667349247]
	TIME [epoch: 24.8 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4560814974123472		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.4560814974123472 | validation: 0.3571103248911965]
	TIME [epoch: 24.8 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39559832133640627		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.39559832133640627 | validation: 0.39658388441822573]
	TIME [epoch: 24.7 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3913957785321851		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.3913957785321851 | validation: 0.41625346525447243]
	TIME [epoch: 24.8 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3730402551494797		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.3730402551494797 | validation: 0.5834740602488488]
	TIME [epoch: 24.8 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8861598464073084		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.8861598464073084 | validation: 0.33252928450392505]
	TIME [epoch: 24.7 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3508799249096468		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.3508799249096468 | validation: 0.4120207837432794]
	TIME [epoch: 24.8 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36385415580199615		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.36385415580199615 | validation: 0.400635130337102]
	TIME [epoch: 24.8 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35733236402470536		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.35733236402470536 | validation: 0.4208568639897279]
	TIME [epoch: 24.7 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38568451443317386		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.38568451443317386 | validation: 1.2406079798504082]
	TIME [epoch: 24.8 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1933297416082793		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 1.1933297416082793 | validation: 0.43453402538324454]
	TIME [epoch: 24.8 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32080698528216667		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.32080698528216667 | validation: 0.4633105042801364]
	TIME [epoch: 24.8 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35612529035947144		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.35612529035947144 | validation: 0.3803626716218743]
	TIME [epoch: 24.8 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33862519970395444		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.33862519970395444 | validation: 0.27760849722243525]
	TIME [epoch: 24.7 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3268636638807574		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.3268636638807574 | validation: 0.4104529868108061]
	TIME [epoch: 24.8 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43595183090263623		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.43595183090263623 | validation: 0.33577368368167926]
	TIME [epoch: 24.8 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3377696996256909		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.3377696996256909 | validation: 0.3154801692141446]
	TIME [epoch: 24.8 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2960369107886808		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.2960369107886808 | validation: 0.2603525204699136]
	TIME [epoch: 24.7 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3344062070897964		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.3344062070897964 | validation: 0.23979605456215425]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_841.pth
	Model improved!!!
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3818411583051172		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.3818411583051172 | validation: 0.3687862386461876]
	TIME [epoch: 24.8 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3675520413669172		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.3675520413669172 | validation: 0.38126600587246784]
	TIME [epoch: 24.8 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3855730777756184		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.3855730777756184 | validation: 0.36152972280806206]
	TIME [epoch: 24.8 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3570592144411386		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.3570592144411386 | validation: 0.4017949347210245]
	TIME [epoch: 24.8 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41165911580553766		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.41165911580553766 | validation: 0.45299842122492423]
	TIME [epoch: 24.8 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39442511586945284		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.39442511586945284 | validation: 0.35409584986370435]
	TIME [epoch: 24.8 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38752861677374595		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.38752861677374595 | validation: 0.3889277715439175]
	TIME [epoch: 24.8 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4501727087608437		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.4501727087608437 | validation: 0.4934886811908498]
	TIME [epoch: 24.8 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4218141169799152		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.4218141169799152 | validation: 0.49533013589503344]
	TIME [epoch: 24.8 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3983041398149019		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.3983041398149019 | validation: 0.4218969300720228]
	TIME [epoch: 24.8 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4099332447098144		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.4099332447098144 | validation: 0.39946098224937354]
	TIME [epoch: 24.8 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42923355587362527		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.42923355587362527 | validation: 0.38175883121289306]
	TIME [epoch: 24.8 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4022810634566335		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.4022810634566335 | validation: 0.4887549323610469]
	TIME [epoch: 24.8 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4278618516756325		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.4278618516756325 | validation: 0.45377834959732505]
	TIME [epoch: 24.8 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4226512749158683		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.4226512749158683 | validation: 0.42171070540507344]
	TIME [epoch: 24.8 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.393749894586729		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.393749894586729 | validation: 0.42386774725340615]
	TIME [epoch: 24.8 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4054317188602732		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.4054317188602732 | validation: 0.4272573815571062]
	TIME [epoch: 24.8 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4387776821662479		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.4387776821662479 | validation: 0.4689898086083516]
	TIME [epoch: 24.8 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38707035379344235		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.38707035379344235 | validation: 0.4586840244365681]
	TIME [epoch: 24.8 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4163768611884121		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.4163768611884121 | validation: 0.4254977003535093]
	TIME [epoch: 24.8 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40692129087421763		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.40692129087421763 | validation: 0.47322539913941514]
	TIME [epoch: 24.8 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3933986859731368		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.3933986859731368 | validation: 0.4770458860123706]
	TIME [epoch: 24.8 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44348329472853293		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.44348329472853293 | validation: 0.5173461637719864]
	TIME [epoch: 24.8 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4490188173062114		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.4490188173062114 | validation: 0.44643864356105495]
	TIME [epoch: 24.8 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41591152125019215		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.41591152125019215 | validation: 0.4515774685419307]
	TIME [epoch: 24.8 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42742590481883247		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.42742590481883247 | validation: 0.4219838770330486]
	TIME [epoch: 24.8 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4407282333703591		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.4407282333703591 | validation: 0.45415704676205737]
	TIME [epoch: 24.8 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4111560183000181		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.4111560183000181 | validation: 0.48859983028210635]
	TIME [epoch: 24.8 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4286274348516996		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.4286274348516996 | validation: 0.6564390960257027]
	TIME [epoch: 24.8 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44659185098792664		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.44659185098792664 | validation: 0.4581591501693039]
	TIME [epoch: 24.8 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4224793680585983		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.4224793680585983 | validation: 0.45868263349020055]
	TIME [epoch: 24.8 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4153341211856971		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.4153341211856971 | validation: 0.5517255712989523]
	TIME [epoch: 24.8 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42365498710104404		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.42365498710104404 | validation: 0.5782848410231063]
	TIME [epoch: 24.8 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4328856303238427		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.4328856303238427 | validation: 0.5600214720697968]
	TIME [epoch: 24.8 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4483713251339526		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.4483713251339526 | validation: 0.46222199248257023]
	TIME [epoch: 24.8 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4642440502599546		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.4642440502599546 | validation: 0.45113042150074384]
	TIME [epoch: 24.8 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38582824757189865		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.38582824757189865 | validation: 0.45110163342057163]
	TIME [epoch: 24.7 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3913282710260982		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.3913282710260982 | validation: 0.4090326723198346]
	TIME [epoch: 24.8 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39630351805748243		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.39630351805748243 | validation: 0.4250399373397389]
	TIME [epoch: 24.8 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3982492702062306		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.3982492702062306 | validation: 0.37727680831094307]
	TIME [epoch: 24.7 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4188231202372906		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.4188231202372906 | validation: 0.4663163141062703]
	TIME [epoch: 24.8 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.387039912651965		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.387039912651965 | validation: 0.4564667386483076]
	TIME [epoch: 24.8 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43650811644617316		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.43650811644617316 | validation: 0.4212365888660206]
	TIME [epoch: 24.8 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3870055884396849		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.3870055884396849 | validation: 0.44847127847876794]
	TIME [epoch: 24.8 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39240953519038174		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.39240953519038174 | validation: 0.42621037601155065]
	TIME [epoch: 24.8 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3777945646758308		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.3777945646758308 | validation: 0.4165069930338459]
	TIME [epoch: 24.7 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3890312231929008		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.3890312231929008 | validation: 0.3932305181273003]
	TIME [epoch: 24.8 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39219188601025246		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.39219188601025246 | validation: 0.4251134671018994]
	TIME [epoch: 24.8 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3997464529298769		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.3997464529298769 | validation: 0.44654158748281064]
	TIME [epoch: 24.7 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4088544158208354		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.4088544158208354 | validation: 0.40433066352997626]
	TIME [epoch: 24.8 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3932213743955052		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.3932213743955052 | validation: 0.46532189736225366]
	TIME [epoch: 24.8 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.389601949110994		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.389601949110994 | validation: 0.4063268225958073]
	TIME [epoch: 24.7 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3805801082375196		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.3805801082375196 | validation: 0.44407627233517494]
	TIME [epoch: 24.8 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41041416066916836		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.41041416066916836 | validation: 0.43188189407973304]
	TIME [epoch: 24.8 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3609623349825476		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.3609623349825476 | validation: 0.3410391635737643]
	TIME [epoch: 24.7 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3649312752306778		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.3649312752306778 | validation: 0.4431409348730758]
	TIME [epoch: 24.8 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3840939304652795		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.3840939304652795 | validation: 0.5045277966579089]
	TIME [epoch: 24.8 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41065715112811385		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.41065715112811385 | validation: 0.3745922444424098]
	TIME [epoch: 24.7 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36444193304776185		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.36444193304776185 | validation: 0.38952907721290686]
	TIME [epoch: 24.8 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3579520249228156		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.3579520249228156 | validation: 0.42551477846143515]
	TIME [epoch: 24.8 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3596286106959913		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.3596286106959913 | validation: 0.36181067869463507]
	TIME [epoch: 24.8 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3405825668632363		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.3405825668632363 | validation: 0.3476851875987168]
	TIME [epoch: 24.8 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3344119511175234		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.3344119511175234 | validation: 0.3108418751371906]
	TIME [epoch: 24.8 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3525883931424359		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.3525883931424359 | validation: 0.36971141333392665]
	TIME [epoch: 24.8 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5357911175517305		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.5357911175517305 | validation: 0.4774761421366755]
	TIME [epoch: 24.8 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34946358062391086		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.34946358062391086 | validation: 0.36249444338497294]
	TIME [epoch: 24.8 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3489134087766465		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.3489134087766465 | validation: 0.3775225323154114]
	TIME [epoch: 24.8 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3891780080792836		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.3891780080792836 | validation: 0.36507879308121793]
	TIME [epoch: 24.8 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3419035755533071		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.3419035755533071 | validation: 0.33022225563259194]
	TIME [epoch: 24.8 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31615244218613375		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.31615244218613375 | validation: 0.26978986968421015]
	TIME [epoch: 24.8 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3271212127290739		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.3271212127290739 | validation: 0.44810287353989225]
	TIME [epoch: 24.8 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42285370004144385		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.42285370004144385 | validation: 0.4797815708843609]
	TIME [epoch: 24.8 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3868403870483558		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.3868403870483558 | validation: 0.39314746702580083]
	TIME [epoch: 24.8 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34431489435663093		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.34431489435663093 | validation: 0.35064844622281577]
	TIME [epoch: 24.8 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3464674699770789		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.3464674699770789 | validation: 0.342255911093829]
	TIME [epoch: 24.8 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3606456940008554		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.3606456940008554 | validation: 0.3123257524940105]
	TIME [epoch: 24.8 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5960745361115389		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.5960745361115389 | validation: 1.2092389142092066]
	TIME [epoch: 24.8 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6275757219105452		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.6275757219105452 | validation: 0.24740816111318226]
	TIME [epoch: 24.8 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26741136029346346		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.26741136029346346 | validation: 0.2946328920099305]
	TIME [epoch: 24.8 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42350540460704866		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.42350540460704866 | validation: 0.46323157353044075]
	TIME [epoch: 24.8 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3196150457274637		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.3196150457274637 | validation: 0.2512070263054358]
	TIME [epoch: 24.8 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34718958469677624		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.34718958469677624 | validation: 0.4566562622384566]
	TIME [epoch: 24.8 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5029592016071939		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.5029592016071939 | validation: 0.26860509564091006]
	TIME [epoch: 24.8 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30730928984219913		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.30730928984219913 | validation: 0.30668322422063415]
	TIME [epoch: 24.8 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3168386252866654		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.3168386252866654 | validation: 0.2616195467738473]
	TIME [epoch: 24.7 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32004765562262616		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.32004765562262616 | validation: 0.2948273727744279]
	TIME [epoch: 24.8 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2996182532193212		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.2996182532193212 | validation: 0.30012828059599445]
	TIME [epoch: 24.8 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30766283558937807		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.30766283558937807 | validation: 0.24606492716274653]
	TIME [epoch: 24.8 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34196553034740584		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.34196553034740584 | validation: 0.3625729075486774]
	TIME [epoch: 24.8 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37077924978821997		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.37077924978821997 | validation: 0.30397770799573304]
	TIME [epoch: 24.8 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29583420601782534		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.29583420601782534 | validation: 0.3139095301115306]
	TIME [epoch: 24.8 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31484853558512915		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.31484853558512915 | validation: 0.29093635056489336]
	TIME [epoch: 24.8 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3104295966980807		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.3104295966980807 | validation: 0.26161599709172]
	TIME [epoch: 24.8 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.315325715565954		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.315325715565954 | validation: 0.28223840785867127]
	TIME [epoch: 24.8 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32581583220483695		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.32581583220483695 | validation: 0.2811635357130888]
	TIME [epoch: 24.8 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30118987388311236		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.30118987388311236 | validation: 0.3372569190438173]
	TIME [epoch: 24.8 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2838875789190375		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.2838875789190375 | validation: 0.2451182370859938]
	TIME [epoch: 24.8 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3244837859809109		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.3244837859809109 | validation: 0.3729441964191822]
	TIME [epoch: 24.8 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35780328555593566		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.35780328555593566 | validation: 0.40331348846259035]
	TIME [epoch: 24.8 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3889570367321177		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.3889570367321177 | validation: 0.35749296865801705]
	TIME [epoch: 24.8 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41661738726183806		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.41661738726183806 | validation: 0.43022132973615856]
	TIME [epoch: 24.8 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3983451993155094		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.3983451993155094 | validation: 0.38459696153394846]
	TIME [epoch: 24.8 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36011885967289237		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.36011885967289237 | validation: 0.35609495907813427]
	TIME [epoch: 24.8 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3671135529464758		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.3671135529464758 | validation: 0.38824938440177936]
	TIME [epoch: 24.8 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3591796544053949		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.3591796544053949 | validation: 0.37865203616613474]
	TIME [epoch: 24.8 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.348858171767093		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.348858171767093 | validation: 0.5664272506814085]
	TIME [epoch: 24.8 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6587351411010245		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.6587351411010245 | validation: 0.36045933687857146]
	TIME [epoch: 24.8 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3212714084492786		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.3212714084492786 | validation: 0.30680570237037186]
	TIME [epoch: 24.8 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3030061850286665		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.3030061850286665 | validation: 0.2711104486724613]
	TIME [epoch: 24.7 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35833685914250013		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.35833685914250013 | validation: 0.4179331871339455]
	TIME [epoch: 24.8 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5221014784721689		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.5221014784721689 | validation: 0.6703987480936056]
	TIME [epoch: 24.8 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38021336541905354		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.38021336541905354 | validation: 0.25068060779346235]
	TIME [epoch: 24.7 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28430892389128487		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.28430892389128487 | validation: 0.33604154828294425]
	TIME [epoch: 24.8 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48303240217106774		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.48303240217106774 | validation: 0.49311176301863396]
	TIME [epoch: 24.8 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3238101179253851		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.3238101179253851 | validation: 0.27522099835081754]
	TIME [epoch: 24.7 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32566958645360833		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.32566958645360833 | validation: 0.25565059908307053]
	TIME [epoch: 24.8 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2915687226286774		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.2915687226286774 | validation: 0.2781085990911305]
	TIME [epoch: 24.7 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2677785962545509		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.2677785962545509 | validation: 0.2290008322481824]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_959.pth
	Model improved!!!
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2806348552597891		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.2806348552597891 | validation: 0.24631599264345297]
	TIME [epoch: 24.8 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3155723936049596		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.3155723936049596 | validation: 0.3239482898543905]
	TIME [epoch: 24.7 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31668634035358006		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.31668634035358006 | validation: 0.292616732652168]
	TIME [epoch: 24.8 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29941219298517807		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.29941219298517807 | validation: 0.3226531713812304]
	TIME [epoch: 24.8 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3028328601379695		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.3028328601379695 | validation: 0.24672428130521995]
	TIME [epoch: 24.8 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2839838420050671		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.2839838420050671 | validation: 0.2676601041913244]
	TIME [epoch: 24.8 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32250670339793597		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.32250670339793597 | validation: 0.2637594155045709]
	TIME [epoch: 24.8 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29771632072237997		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.29771632072237997 | validation: 0.24053393098310835]
	TIME [epoch: 24.8 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2671443482131038		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.2671443482131038 | validation: 0.28774208277315694]
	TIME [epoch: 24.8 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29422105593054043		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.29422105593054043 | validation: 0.30291816703784774]
	TIME [epoch: 24.8 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4130104783221556		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.4130104783221556 | validation: 0.4588242214559032]
	TIME [epoch: 24.7 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41170809936722486		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.41170809936722486 | validation: 0.39304851766151844]
	TIME [epoch: 24.8 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4106893482995729		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.4106893482995729 | validation: 0.4974091314496772]
	TIME [epoch: 24.8 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45035760799396823		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.45035760799396823 | validation: 0.4811047755495315]
	TIME [epoch: 24.7 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4007130054959538		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.4007130054959538 | validation: 0.3622534294972904]
	TIME [epoch: 24.8 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3355210737454227		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.3355210737454227 | validation: 0.3178128449876281]
	TIME [epoch: 24.8 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35669249754105486		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.35669249754105486 | validation: 0.305251693424404]
	TIME [epoch: 24.7 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31991507083082626		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.31991507083082626 | validation: 0.38704650173442956]
	TIME [epoch: 24.8 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38349763852722074		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.38349763852722074 | validation: 0.37513217714966013]
	TIME [epoch: 24.8 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36661253343346556		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.36661253343346556 | validation: 0.31325035141527563]
	TIME [epoch: 24.8 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3713042203847252		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.3713042203847252 | validation: 0.47066414291724046]
	TIME [epoch: 24.7 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43921522382351963		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.43921522382351963 | validation: 0.41043816621413853]
	TIME [epoch: 24.8 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3601688555517703		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.3601688555517703 | validation: 0.3418378922738191]
	TIME [epoch: 24.7 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.330115557089255		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.330115557089255 | validation: 0.3407348220395139]
	TIME [epoch: 24.8 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34809534241351375		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.34809534241351375 | validation: 0.33671921278032324]
	TIME [epoch: 24.8 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35806430694338537		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.35806430694338537 | validation: 0.33275802470621935]
	TIME [epoch: 24.7 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30978508316747494		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.30978508316747494 | validation: 0.2834489944963898]
	TIME [epoch: 24.8 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3003387285109612		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.3003387285109612 | validation: 0.28565737905246946]
	TIME [epoch: 24.8 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30597307959332076		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.30597307959332076 | validation: 0.31388672645509996]
	TIME [epoch: 24.7 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4177457434978916		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.4177457434978916 | validation: 0.7364938432685103]
	TIME [epoch: 24.8 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3574572161015497		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 1.3574572161015497 | validation: 2.426823370818295]
	TIME [epoch: 24.8 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7288743695777413		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 1.7288743695777413 | validation: 0.772981779527783]
	TIME [epoch: 24.7 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39309285086936385		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.39309285086936385 | validation: 0.23496052173576956]
	TIME [epoch: 24.9 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2956495393398462		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.2956495393398462 | validation: 0.40094856183505806]
	TIME [epoch: 24.8 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4124718715809629		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.4124718715809629 | validation: 0.4596066949824821]
	TIME [epoch: 24.7 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2955915398697352		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.2955915398697352 | validation: 0.22920062890794002]
	TIME [epoch: 24.8 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3750071960987449		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.3750071960987449 | validation: 0.6590042518078709]
	TIME [epoch: 24.8 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6903899600197273		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.6903899600197273 | validation: 0.4781942172346446]
	TIME [epoch: 24.7 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30445896080421087		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.30445896080421087 | validation: 0.2334569004075251]
	TIME [epoch: 24.8 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29620474347161546		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.29620474347161546 | validation: 0.27197579371290526]
	TIME [epoch: 24.8 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3057638402249886		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.3057638402249886 | validation: 0.3633604028844998]
	TIME [epoch: 24.7 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3373114370947952		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.3373114370947952 | validation: 0.2687629475015557]
	TIME [epoch: 24.8 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3093059601732351		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.3093059601732351 | validation: 0.3243196582064817]
	TIME [epoch: 24.8 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3069921571428185		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.3069921571428185 | validation: 0.24368216774368961]
	TIME [epoch: 24.8 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2956897535665926		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.2956897535665926 | validation: 0.3656309938825166]
	TIME [epoch: 24.8 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3307151885566009		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.3307151885566009 | validation: 0.2894747864878175]
	TIME [epoch: 24.8 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2991738179424478		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.2991738179424478 | validation: 0.2651101892670236]
	TIME [epoch: 24.8 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2842152505307343		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.2842152505307343 | validation: 0.2351371336723739]
	TIME [epoch: 24.8 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30989048788293394		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.30989048788293394 | validation: 0.28279673281788376]
	TIME [epoch: 24.8 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28432785597917115		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.28432785597917115 | validation: 0.23693725251378236]
	TIME [epoch: 24.7 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.300479670430358		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.300479670430358 | validation: 0.374598353794497]
	TIME [epoch: 24.8 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29941289932152404		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.29941289932152404 | validation: 0.25190763616583695]
	TIME [epoch: 24.8 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2824231628865712		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.2824231628865712 | validation: 0.3095432328367067]
	TIME [epoch: 24.7 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33794053003453256		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.33794053003453256 | validation: 0.34674272486189295]
	TIME [epoch: 24.8 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3372082283283757		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.3372082283283757 | validation: 0.31726755110984034]
	TIME [epoch: 24.7 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3140500982683383		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.3140500982683383 | validation: 0.3536120014875284]
	TIME [epoch: 24.7 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3407841033399791		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.3407841033399791 | validation: 0.27426880734579473]
	TIME [epoch: 24.7 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28176337313443356		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.28176337313443356 | validation: 0.2544092987846962]
	TIME [epoch: 24.8 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29012889843472167		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.29012889843472167 | validation: 0.25822657497882573]
	TIME [epoch: 24.7 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28202581724069553		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.28202581724069553 | validation: 0.2538068260378239]
	TIME [epoch: 24.7 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3000390487447646		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.3000390487447646 | validation: 0.2954016411682494]
	TIME [epoch: 24.8 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35224490579749357		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.35224490579749357 | validation: 0.4384155932625211]
	TIME [epoch: 24.7 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3837464581146853		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.3837464581146853 | validation: 0.27513328609364157]
	TIME [epoch: 24.8 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30804754161498515		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.30804754161498515 | validation: 0.2615985646692031]
	TIME [epoch: 24.8 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27426573424591727		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.27426573424591727 | validation: 0.2693126916946848]
	TIME [epoch: 24.7 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31040944855961566		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.31040944855961566 | validation: 0.3256616288862933]
	TIME [epoch: 24.8 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34451991648852986		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.34451991648852986 | validation: 0.33710060785291335]
	TIME [epoch: 24.8 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3076835584677811		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.3076835584677811 | validation: 0.2979642923555017]
	TIME [epoch: 24.8 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3217058975565629		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.3217058975565629 | validation: 0.3083839440302165]
	TIME [epoch: 24.8 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33561126629932564		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.33561126629932564 | validation: 0.32348097526650166]
	TIME [epoch: 24.8 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.321826110315435		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.321826110315435 | validation: 0.3254720871364174]
	TIME [epoch: 24.7 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2915056024330754		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.2915056024330754 | validation: 0.2795213397140963]
	TIME [epoch: 24.8 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.290926871954815		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.290926871954815 | validation: 0.25471015333967617]
	TIME [epoch: 24.8 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2994715719423572		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.2994715719423572 | validation: 0.28518804286363014]
	TIME [epoch: 24.7 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.300330647129061		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.300330647129061 | validation: 0.24224127012520133]
	TIME [epoch: 24.8 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3012046819908798		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.3012046819908798 | validation: 0.26888015711268587]
	TIME [epoch: 24.8 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30681647725723576		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.30681647725723576 | validation: 0.4840167210317736]
	TIME [epoch: 24.7 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36731239670652005		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.36731239670652005 | validation: 0.29818549767939423]
	TIME [epoch: 24.7 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2778303057677551		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.2778303057677551 | validation: 0.2500356355996479]
	TIME [epoch: 24.8 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33871144573602086		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.33871144573602086 | validation: 0.39936795756504084]
	TIME [epoch: 24.7 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35475682848156176		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.35475682848156176 | validation: 0.30993948976348923]
	TIME [epoch: 24.7 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32074142676477857		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.32074142676477857 | validation: 0.3059643500074632]
	TIME [epoch: 24.8 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28583782353029896		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.28583782353029896 | validation: 0.24987398849690906]
	TIME [epoch: 24.8 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2924148876297338		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.2924148876297338 | validation: 0.25474670571496283]
	TIME [epoch: 24.8 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35913630640509697		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.35913630640509697 | validation: 0.6438185229671788]
	TIME [epoch: 24.8 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4815886680742377		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.4815886680742377 | validation: 0.24305387224950714]
	TIME [epoch: 24.8 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27340368538916815		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.27340368538916815 | validation: 0.24141801986581804]
	TIME [epoch: 24.8 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26979362971041576		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.26979362971041576 | validation: 0.26148982436418144]
	TIME [epoch: 24.8 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2970179075899281		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.2970179075899281 | validation: 0.261913431931204]
	TIME [epoch: 24.7 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29066987187770366		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.29066987187770366 | validation: 0.22969514312476158]
	TIME [epoch: 24.8 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2595456356271891		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.2595456356271891 | validation: 0.2517844647568741]
	TIME [epoch: 24.8 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2653728521666453		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.2653728521666453 | validation: 0.2556124599047195]
	TIME [epoch: 24.7 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29914398179854007		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.29914398179854007 | validation: 0.2513162034755379]
	TIME [epoch: 24.8 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2784163807770929		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.2784163807770929 | validation: 0.2714357728896185]
	TIME [epoch: 24.8 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29253592161021885		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.29253592161021885 | validation: 0.24241526142263722]
	TIME [epoch: 24.7 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2944397035326114		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.2944397035326114 | validation: 0.2802246614123608]
	TIME [epoch: 24.9 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30162100330151426		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.30162100330151426 | validation: 0.24271581325368113]
	TIME [epoch: 24.8 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2778235970641966		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.2778235970641966 | validation: 0.2658904277395224]
	TIME [epoch: 24.8 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2844584217850815		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.2844584217850815 | validation: 0.25981301528390255]
	TIME [epoch: 24.8 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27633900489285745		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.27633900489285745 | validation: 0.2664205498355336]
	TIME [epoch: 24.8 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2781120657002282		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.2781120657002282 | validation: 0.3015445365913716]
	TIME [epoch: 24.7 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3193526800467417		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.3193526800467417 | validation: 0.21831390673337636]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_1061.pth
	Model improved!!!
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2538223981354275		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.2538223981354275 | validation: 0.2306814235783557]
	TIME [epoch: 24.8 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2626513632796601		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.2626513632796601 | validation: 0.22364168595346864]
	TIME [epoch: 24.7 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.267652710709222		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.267652710709222 | validation: 0.22640940068684728]
	TIME [epoch: 24.8 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25402539488568154		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.25402539488568154 | validation: 0.2301329995660579]
	TIME [epoch: 24.8 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26856886226226345		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.26856886226226345 | validation: 0.2746941459946004]
	TIME [epoch: 24.8 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.285371038611134		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.285371038611134 | validation: 0.23129503961204365]
	TIME [epoch: 24.8 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33849812607445107		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.33849812607445107 | validation: 0.3576759579116241]
	TIME [epoch: 24.8 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3653776483177207		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.3653776483177207 | validation: 0.28053788787832284]
	TIME [epoch: 24.7 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27310278401230864		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.27310278401230864 | validation: 0.2354490933692123]
	TIME [epoch: 24.8 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26315104072865103		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.26315104072865103 | validation: 0.45533827686448186]
	TIME [epoch: 24.8 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34332385487058076		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.34332385487058076 | validation: 0.2767651987147305]
	TIME [epoch: 24.7 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38806506128967433		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.38806506128967433 | validation: 0.4551809198916844]
	TIME [epoch: 24.8 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30853390871686126		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.30853390871686126 | validation: 0.22391401833157001]
	TIME [epoch: 24.7 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2663705182820719		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.2663705182820719 | validation: 0.2585148299241217]
	TIME [epoch: 24.7 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28888370386515777		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.28888370386515777 | validation: 0.2686132795736658]
	TIME [epoch: 24.8 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26395737685466736		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.26395737685466736 | validation: 0.24104749544796522]
	TIME [epoch: 24.7 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31518926385801194		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.31518926385801194 | validation: 0.37994630468482926]
	TIME [epoch: 24.7 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33256167225790106		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.33256167225790106 | validation: 0.2953181259469781]
	TIME [epoch: 24.8 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.300846672029341		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.300846672029341 | validation: 0.2915152185118048]
	TIME [epoch: 24.8 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3217896263610661		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.3217896263610661 | validation: 0.30738879452204976]
	TIME [epoch: 24.7 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3003665783795771		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.3003665783795771 | validation: 0.2642309238805291]
	TIME [epoch: 24.8 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26866859519129993		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.26866859519129993 | validation: 0.23522699440204067]
	TIME [epoch: 24.7 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.261915360713633		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.261915360713633 | validation: 0.26422038105842777]
	TIME [epoch: 24.8 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4149118298869041		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.4149118298869041 | validation: 0.398614743612696]
	TIME [epoch: 24.8 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28888761133726304		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.28888761133726304 | validation: 0.2291092673713205]
	TIME [epoch: 24.8 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2919751515979533		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.2919751515979533 | validation: 0.32330614608607433]
	TIME [epoch: 24.7 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31044627593510854		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.31044627593510854 | validation: 0.2748842956005026]
	TIME [epoch: 24.8 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2781569748015302		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.2781569748015302 | validation: 0.27535307740075154]
	TIME [epoch: 24.7 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3090929917703519		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.3090929917703519 | validation: 0.34962002975247414]
	TIME [epoch: 24.7 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2987448059200246		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.2987448059200246 | validation: 0.276618928759403]
	TIME [epoch: 24.7 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3169638058462142		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.3169638058462142 | validation: 0.27725617920895823]
	TIME [epoch: 24.7 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26861588367230993		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.26861588367230993 | validation: 0.25673915133462666]
	TIME [epoch: 24.7 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28719888928917026		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.28719888928917026 | validation: 0.254337055016455]
	TIME [epoch: 24.8 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2686524106384382		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.2686524106384382 | validation: 0.22538327245327047]
	TIME [epoch: 24.7 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2794911896239052		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.2794911896239052 | validation: 0.2852125897592781]
	TIME [epoch: 24.7 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27576440038616257		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.27576440038616257 | validation: 0.25098721586407224]
	TIME [epoch: 24.8 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2804094519106895		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.2804094519106895 | validation: 0.25110156252674165]
	TIME [epoch: 24.7 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27933381941958846		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.27933381941958846 | validation: 0.2713305280715932]
	TIME [epoch: 24.7 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3031549532771628		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.3031549532771628 | validation: 0.23471680000724646]
	TIME [epoch: 24.8 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2878442965764499		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.2878442965764499 | validation: 0.28963304302199794]
	TIME [epoch: 24.7 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.299086845623596		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.299086845623596 | validation: 0.26378426412179]
	TIME [epoch: 24.7 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27337826383884173		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.27337826383884173 | validation: 0.2867625469156255]
	TIME [epoch: 24.8 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3160035186020821		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.3160035186020821 | validation: 0.31731653707209656]
	TIME [epoch: 24.7 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30598450912532166		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.30598450912532166 | validation: 0.2603887919129585]
	TIME [epoch: 24.8 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.280975742073202		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.280975742073202 | validation: 0.2987840315257045]
	TIME [epoch: 24.8 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28896270962927845		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.28896270962927845 | validation: 0.2725167660309514]
	TIME [epoch: 24.7 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.296104748412755		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.296104748412755 | validation: 0.3180512634983821]
	TIME [epoch: 24.7 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31910009318609894		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.31910009318609894 | validation: 0.29411920614205495]
	TIME [epoch: 24.8 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29502676834870467		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.29502676834870467 | validation: 0.32353321976902527]
	TIME [epoch: 24.7 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3383737130553012		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.3383737130553012 | validation: 0.36517036768957406]
	TIME [epoch: 24.8 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3385093391313647		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.3385093391313647 | validation: 0.3217820709342341]
	TIME [epoch: 24.8 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3308528828987219		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.3308528828987219 | validation: 0.3088394824939057]
	TIME [epoch: 24.8 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31066017504843346		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.31066017504843346 | validation: 0.42399461918522874]
	TIME [epoch: 24.8 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33858440350304214		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.33858440350304214 | validation: 0.26360681087559307]
	TIME [epoch: 24.8 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28421171805866186		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.28421171805866186 | validation: 0.24303466185676953]
	TIME [epoch: 24.8 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2676896696955315		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.2676896696955315 | validation: 0.2487300200015337]
	TIME [epoch: 24.8 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2848043968418177		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.2848043968418177 | validation: 0.29161973239182265]
	TIME [epoch: 24.8 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29265406333985167		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.29265406333985167 | validation: 0.32571933139361753]
	TIME [epoch: 24.7 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3273569186495037		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.3273569186495037 | validation: 0.48190311517652556]
	TIME [epoch: 24.8 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42078425590921686		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.42078425590921686 | validation: 0.2973328418872176]
	TIME [epoch: 24.7 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32050242173402627		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.32050242173402627 | validation: 0.2546654245091356]
	TIME [epoch: 24.8 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26463632941855575		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.26463632941855575 | validation: 0.25565661522931427]
	TIME [epoch: 24.8 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31402795455217675		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.31402795455217675 | validation: 0.3231528164257038]
	TIME [epoch: 24.8 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.278311916642271		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.278311916642271 | validation: 0.23267069595912027]
	TIME [epoch: 24.7 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2563276036135246		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.2563276036135246 | validation: 0.3194954294923291]
	TIME [epoch: 24.8 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2695397241122718		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.2695397241122718 | validation: 0.25640342437683605]
	TIME [epoch: 24.8 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2745757272855035		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.2745757272855035 | validation: 0.27245355537950666]
	TIME [epoch: 24.8 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2640714272405041		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.2640714272405041 | validation: 0.27953297387913223]
	TIME [epoch: 24.8 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.283892923899012		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.283892923899012 | validation: 0.2522834798876504]
	TIME [epoch: 24.7 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2786997548986435		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.2786997548986435 | validation: 0.29471488680175506]
	TIME [epoch: 24.7 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3222865470053651		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.3222865470053651 | validation: 0.3654675586407507]
	TIME [epoch: 24.7 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33857831860405574		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.33857831860405574 | validation: 0.2980001805592905]
	TIME [epoch: 24.7 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2939004439106057		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.2939004439106057 | validation: 0.29892787530513737]
	TIME [epoch: 24.7 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3225232705938377		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.3225232705938377 | validation: 0.3561268851155968]
	TIME [epoch: 24.7 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3772099319310434		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.3772099319310434 | validation: 0.3776555186560193]
	TIME [epoch: 24.7 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36642161869889506		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.36642161869889506 | validation: 0.3574230875348641]
	TIME [epoch: 24.7 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3324119637290959		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.3324119637290959 | validation: 0.30424821348311815]
	TIME [epoch: 24.7 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3100511543850445		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.3100511543850445 | validation: 0.26359969912700093]
	TIME [epoch: 24.7 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2789085867999581		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.2789085867999581 | validation: 0.2907492198877587]
	TIME [epoch: 24.7 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29988961116054436		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.29988961116054436 | validation: 0.32327174782703644]
	TIME [epoch: 24.7 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3065894865192323		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.3065894865192323 | validation: 0.3065255362990953]
	TIME [epoch: 24.7 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3420338532361446		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.3420338532361446 | validation: 0.33504369735773565]
	TIME [epoch: 24.7 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3376400118683001		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.3376400118683001 | validation: 0.3852547148946492]
	TIME [epoch: 24.7 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31617944999157555		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.31617944999157555 | validation: 0.3009404745269048]
	TIME [epoch: 24.7 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.303319510392528		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.303319510392528 | validation: 0.2943110501883244]
	TIME [epoch: 24.7 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3435126532652543		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.3435126532652543 | validation: 0.39815823997330285]
	TIME [epoch: 24.8 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4247813145925764		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.4247813145925764 | validation: 0.4763209277486143]
	TIME [epoch: 24.8 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.409252505387997		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.409252505387997 | validation: 0.41130325550605085]
	TIME [epoch: 24.7 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3589066895306963		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.3589066895306963 | validation: 0.3848103129409235]
	TIME [epoch: 24.7 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35436779813002		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.35436779813002 | validation: 0.35268329730432807]
	TIME [epoch: 24.7 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3378658861436101		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.3378658861436101 | validation: 0.2872402199758063]
	TIME [epoch: 24.7 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3263816205966421		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.3263816205966421 | validation: 0.33233016835736123]
	TIME [epoch: 24.7 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32964671399586976		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.32964671399586976 | validation: 0.32825758657796705]
	TIME [epoch: 24.7 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2964337831629429		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.2964337831629429 | validation: 0.25315420761241625]
	TIME [epoch: 24.7 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27403491365173926		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.27403491365173926 | validation: 0.2559177504387224]
	TIME [epoch: 24.7 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29073985433107263		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.29073985433107263 | validation: 0.34286019397227147]
	TIME [epoch: 24.7 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3204670612170234		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.3204670612170234 | validation: 0.310672769216352]
	TIME [epoch: 24.7 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29367306463443954		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.29367306463443954 | validation: 0.25331160912034517]
	TIME [epoch: 24.7 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2825406360076077		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.2825406360076077 | validation: 0.2832649286870767]
	TIME [epoch: 24.7 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33076763160073197		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.33076763160073197 | validation: 0.373979566362416]
	TIME [epoch: 24.7 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34522182311872945		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.34522182311872945 | validation: 0.31931168613666217]
	TIME [epoch: 24.7 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30730377142804943		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.30730377142804943 | validation: 0.33190991448047574]
	TIME [epoch: 24.8 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35341126468022277		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.35341126468022277 | validation: 0.37454201270825244]
	TIME [epoch: 24.7 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3529423562834265		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.3529423562834265 | validation: 0.39473499288061403]
	TIME [epoch: 24.8 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3388744940650064		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.3388744940650064 | validation: 0.39203096847547464]
	TIME [epoch: 24.8 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35869298769777014		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.35869298769777014 | validation: 0.34931166140165665]
	TIME [epoch: 24.8 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37964687841422773		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.37964687841422773 | validation: 0.3442680307956963]
	TIME [epoch: 24.8 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31911590431143916		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.31911590431143916 | validation: 0.28768139758260486]
	TIME [epoch: 24.8 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28355131506551345		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.28355131506551345 | validation: 0.2572341100919449]
	TIME [epoch: 24.8 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2835260746880206		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.2835260746880206 | validation: 0.2609360312192282]
	TIME [epoch: 24.8 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28985275875752514		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.28985275875752514 | validation: 0.25668563906895225]
	TIME [epoch: 24.8 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28484239993921723		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.28484239993921723 | validation: 0.273553546321463]
	TIME [epoch: 24.8 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28813211514891734		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.28813211514891734 | validation: 0.2880764029202229]
	TIME [epoch: 24.8 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3116273004715118		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.3116273004715118 | validation: 0.27361637082285173]
	TIME [epoch: 24.8 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28612809314475124		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.28612809314475124 | validation: 0.2625186452470185]
	TIME [epoch: 24.8 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27529197612536394		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.27529197612536394 | validation: 0.25563375637927566]
	TIME [epoch: 24.8 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3067044085064202		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.3067044085064202 | validation: 0.39205649099337225]
	TIME [epoch: 24.7 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3238807537341405		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.3238807537341405 | validation: 0.2542879416500868]
	TIME [epoch: 24.7 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2592606284177786		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.2592606284177786 | validation: 0.23564077412366455]
	TIME [epoch: 24.8 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24946175931667308		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.24946175931667308 | validation: 0.23846227740134043]
	TIME [epoch: 24.7 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2592536871656473		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.2592536871656473 | validation: 0.224497019560172]
	TIME [epoch: 24.7 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25730892721865034		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.25730892721865034 | validation: 0.22405178219520264]
	TIME [epoch: 24.8 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28222258600632905		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.28222258600632905 | validation: 0.4530078537408757]
	TIME [epoch: 24.8 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37231183813262386		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.37231183813262386 | validation: 0.7049518462606454]
	TIME [epoch: 24.8 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.635947131574917		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.635947131574917 | validation: 0.7541421537190058]
	TIME [epoch: 24.8 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49584518123851884		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.49584518123851884 | validation: 0.4595140448721196]
	TIME [epoch: 24.8 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40333107164544224		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.40333107164544224 | validation: 0.6301697710357201]
	TIME [epoch: 24.8 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5335641149366676		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.5335641149366676 | validation: 0.4700003735991092]
	TIME [epoch: 24.8 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42580334598674		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.42580334598674 | validation: 0.44143747012478574]
	TIME [epoch: 24.8 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30875426135132955		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.30875426135132955 | validation: 0.27977798605026033]
	TIME [epoch: 24.7 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2568870891014953		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.2568870891014953 | validation: 0.2814591109061043]
	TIME [epoch: 24.8 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2705738065875845		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.2705738065875845 | validation: 0.3017276634661263]
	TIME [epoch: 24.7 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26543915493305853		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.26543915493305853 | validation: 0.21252261339733747]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_1194.pth
	Model improved!!!
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2348105393711096		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.2348105393711096 | validation: 0.23057810131155074]
	TIME [epoch: 24.7 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2603072708221454		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.2603072708221454 | validation: 0.23984505731112749]
	TIME [epoch: 24.7 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2544222391134885		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.2544222391134885 | validation: 0.35564684435762745]
	TIME [epoch: 24.8 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37660156536120737		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.37660156536120737 | validation: 0.31425947604697674]
	TIME [epoch: 24.8 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27644908930496276		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.27644908930496276 | validation: 0.21383059223115922]
	TIME [epoch: 24.8 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23705625271956474		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.23705625271956474 | validation: 0.22681300571255072]
	TIME [epoch: 24.8 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25318022448866273		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.25318022448866273 | validation: 0.24515088457882223]
	TIME [epoch: 24.8 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24226308123486884		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.24226308123486884 | validation: 0.23143185152393664]
	TIME [epoch: 24.8 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2536011440684505		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.2536011440684505 | validation: 0.23974387909051195]
	TIME [epoch: 24.8 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2772958109696179		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.2772958109696179 | validation: 0.23889065765238532]
	TIME [epoch: 24.8 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2601083335764788		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.2601083335764788 | validation: 0.2516735571894474]
	TIME [epoch: 24.8 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2582857019149818		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.2582857019149818 | validation: 0.2176209196875062]
	TIME [epoch: 24.7 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26023412174309124		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.26023412174309124 | validation: 0.5238192146176366]
	TIME [epoch: 24.8 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37382954295073756		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.37382954295073756 | validation: 0.23121589896362896]
	TIME [epoch: 24.7 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24257425931678905		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.24257425931678905 | validation: 0.2673520473709566]
	TIME [epoch: 24.7 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3200808576569044		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.3200808576569044 | validation: 0.32998902995832935]
	TIME [epoch: 24.8 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29677841108664793		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.29677841108664793 | validation: 0.3163511974889661]
	TIME [epoch: 24.7 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37662756371535067		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.37662756371535067 | validation: 0.6096297863488819]
	TIME [epoch: 24.7 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5159656811093348		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.5159656811093348 | validation: 0.36037654675315384]
	TIME [epoch: 24.7 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28114164851563017		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.28114164851563017 | validation: 0.32602137012451293]
	TIME [epoch: 24.8 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.286232959845251		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.286232959845251 | validation: 0.2590450852798888]
	TIME [epoch: 24.8 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2539491045038095		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.2539491045038095 | validation: 0.3103502824601015]
	TIME [epoch: 24.8 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3052864642622135		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.3052864642622135 | validation: 0.26484595734043725]
	TIME [epoch: 24.7 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24542338820273446		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.24542338820273446 | validation: 0.25123609827001087]
	TIME [epoch: 24.7 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26621753353761435		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.26621753353761435 | validation: 0.20858315499459257]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_1219.pth
	Model improved!!!
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2362001227414725		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.2362001227414725 | validation: 0.2201947558953965]
	TIME [epoch: 24.7 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24150407954531117		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.24150407954531117 | validation: 0.21899022603081733]
	TIME [epoch: 24.7 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23505358964520687		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.23505358964520687 | validation: 0.2130864214633657]
	TIME [epoch: 24.8 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23383280076355184		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.23383280076355184 | validation: 0.19820616770907848]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_1223.pth
	Model improved!!!
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2504856799483183		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.2504856799483183 | validation: 0.21062712392553642]
	TIME [epoch: 24.8 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24585280549337613		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.24585280549337613 | validation: 0.2295673127692392]
	TIME [epoch: 24.7 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27269116438779323		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.27269116438779323 | validation: 0.21649427062475987]
	TIME [epoch: 24.7 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25865954173856764		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.25865954173856764 | validation: 0.23860253690075361]
	TIME [epoch: 24.8 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3326213486435396		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.3326213486435396 | validation: 0.31292293500933754]
	TIME [epoch: 24.8 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34739170759153293		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.34739170759153293 | validation: 0.37274600176657013]
	TIME [epoch: 24.7 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3531592715541211		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.3531592715541211 | validation: 0.29049385559572904]
	TIME [epoch: 24.8 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28204991394811224		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.28204991394811224 | validation: 0.21230024417065024]
	TIME [epoch: 24.7 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.234688134746171		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.234688134746171 | validation: 0.2704728048579611]
	TIME [epoch: 24.8 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2520907007220171		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.2520907007220171 | validation: 0.21523281239431463]
	TIME [epoch: 24.8 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23992421190516908		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.23992421190516908 | validation: 0.2172318543813503]
	TIME [epoch: 24.8 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22958649433702366		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.22958649433702366 | validation: 0.21000950595076645]
	TIME [epoch: 24.8 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2486217764681614		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.2486217764681614 | validation: 0.21958570584621157]
	TIME [epoch: 24.8 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2430827217955011		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.2430827217955011 | validation: 0.21117451478315274]
	TIME [epoch: 24.8 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.244015274296432		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.244015274296432 | validation: 0.21217120082729948]
	TIME [epoch: 24.8 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23949814944903983		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.23949814944903983 | validation: 0.2835105978923339]
	TIME [epoch: 24.8 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2904664220374441		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.2904664220374441 | validation: 0.24960425674767073]
	TIME [epoch: 24.8 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25693738902208957		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.25693738902208957 | validation: 0.22410470655937548]
	TIME [epoch: 24.8 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2497773950877805		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.2497773950877805 | validation: 0.20894764783635592]
	TIME [epoch: 24.7 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25751511625393947		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.25751511625393947 | validation: 0.2266006312355131]
	TIME [epoch: 24.7 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25652206047572046		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.25652206047572046 | validation: 0.20772816818136883]
	TIME [epoch: 24.8 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26252893808107275		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.26252893808107275 | validation: 0.27254583115576597]
	TIME [epoch: 24.8 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2956727902938201		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.2956727902938201 | validation: 0.27909494048980765]
	TIME [epoch: 24.8 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25851575980051344		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.25851575980051344 | validation: 0.22359066066017733]
	TIME [epoch: 24.7 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23360297962471444		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.23360297962471444 | validation: 0.20627480851919494]
	TIME [epoch: 24.8 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23555299356998186		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.23555299356998186 | validation: 0.2205166115502346]
	TIME [epoch: 24.8 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22961663271111227		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.22961663271111227 | validation: 0.1989678951406905]
	TIME [epoch: 24.7 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22792024854930196		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.22792024854930196 | validation: 0.2462460855193458]
	TIME [epoch: 24.8 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23806308664783132		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.23806308664783132 | validation: 0.25847861820254797]
	TIME [epoch: 24.8 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31862885380835376		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.31862885380835376 | validation: 0.31284217805271464]
	TIME [epoch: 24.8 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3141263169988875		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.3141263169988875 | validation: 0.27995497367073957]
	TIME [epoch: 24.8 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2616482191311045		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.2616482191311045 | validation: 0.2277309129767984]
	TIME [epoch: 24.8 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26035306195448926		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.26035306195448926 | validation: 0.25966821175715743]
	TIME [epoch: 24.7 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27487386654621837		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.27487386654621837 | validation: 0.2610952063788491]
	TIME [epoch: 24.8 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2795379121508904		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.2795379121508904 | validation: 0.2578064090247285]
	TIME [epoch: 24.8 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2726021821339219		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.2726021821339219 | validation: 0.2821660890149321]
	TIME [epoch: 24.8 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.303025289614677		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.303025289614677 | validation: 0.25109286264194636]
	TIME [epoch: 24.8 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24779950735314113		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.24779950735314113 | validation: 0.2049535346540609]
	TIME [epoch: 24.8 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24018933281716573		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.24018933281716573 | validation: 0.22063889480614382]
	TIME [epoch: 24.7 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2364383528014749		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.2364383528014749 | validation: 0.21752661750955032]
	TIME [epoch: 24.8 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24425030298980233		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.24425030298980233 | validation: 0.21821270335251405]
	TIME [epoch: 24.8 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23127582148095507		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.23127582148095507 | validation: 0.21467336267197928]
	TIME [epoch: 24.8 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22678417006182905		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.22678417006182905 | validation: 0.21407948356436962]
	TIME [epoch: 24.8 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23545262121790977		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.23545262121790977 | validation: 0.22592611170870858]
	TIME [epoch: 24.8 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25558817698221237		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.25558817698221237 | validation: 0.20153459913438604]
	TIME [epoch: 24.8 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24455946651263938		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.24455946651263938 | validation: 0.24154497722820542]
	TIME [epoch: 24.8 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25594650416493775		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.25594650416493775 | validation: 0.22706227492943765]
	TIME [epoch: 24.8 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22751733595242674		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.22751733595242674 | validation: 0.21432773275495115]
	TIME [epoch: 24.8 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23275575609726945		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.23275575609726945 | validation: 0.21577674420289994]
	TIME [epoch: 24.8 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2513301508916834		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.2513301508916834 | validation: 0.2066450138818259]
	TIME [epoch: 24.8 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2397644892230657		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.2397644892230657 | validation: 0.22240990634347582]
	TIME [epoch: 24.8 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2650521293177221		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.2650521293177221 | validation: 0.26098487930197195]
	TIME [epoch: 24.8 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2843638420860406		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.2843638420860406 | validation: 0.24545913498842495]
	TIME [epoch: 24.9 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24353728645694936		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.24353728645694936 | validation: 0.22267980933713305]
	TIME [epoch: 24.9 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23018787365383578		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.23018787365383578 | validation: 0.2035557910080477]
	TIME [epoch: 24.9 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23553680602954577		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.23553680602954577 | validation: 0.20794439637483458]
	TIME [epoch: 24.9 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23855215038697025		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.23855215038697025 | validation: 0.2159179788578731]
	TIME [epoch: 24.9 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22652973013259395		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.22652973013259395 | validation: 0.20434287292836392]
	TIME [epoch: 24.8 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24369412983805447		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.24369412983805447 | validation: 0.2978832699342073]
	TIME [epoch: 24.8 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34825395435561346		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.34825395435561346 | validation: 0.3804959619756951]
	TIME [epoch: 24.8 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36846387915703027		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.36846387915703027 | validation: 0.3526310001760457]
	TIME [epoch: 24.8 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28119273655797405		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.28119273655797405 | validation: 0.28987878261157946]
	TIME [epoch: 24.8 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29864630625638167		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.29864630625638167 | validation: 0.23934081451485298]
	TIME [epoch: 24.8 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24516105252602968		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.24516105252602968 | validation: 0.2286179112503934]
	TIME [epoch: 24.9 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2748670127164706		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.2748670127164706 | validation: 0.24987179097879422]
	TIME [epoch: 24.9 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2320453266613169		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.2320453266613169 | validation: 0.199912386107768]
	TIME [epoch: 24.8 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2308604263730784		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.2308604263730784 | validation: 0.20143532987022256]
	TIME [epoch: 24.9 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2289300528601452		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.2289300528601452 | validation: 0.21009739861152057]
	TIME [epoch: 24.8 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25177496376929637		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.25177496376929637 | validation: 0.21479650525964758]
	TIME [epoch: 24.8 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22906084086100972		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.22906084086100972 | validation: 0.24119791122744288]
	TIME [epoch: 24.9 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25589970881734475		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.25589970881734475 | validation: 0.21981747387970876]
	TIME [epoch: 24.9 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24381161268602355		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.24381161268602355 | validation: 0.258104083005145]
	TIME [epoch: 24.8 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2607218275262596		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.2607218275262596 | validation: 0.2647953317533478]
	TIME [epoch: 24.8 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27043480624943006		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.27043480624943006 | validation: 0.32618860899513424]
	TIME [epoch: 24.8 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3524700609966511		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.3524700609966511 | validation: 0.4921474767983425]
	TIME [epoch: 24.8 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3441397422262982		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.3441397422262982 | validation: 0.2522396642560428]
	TIME [epoch: 24.9 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23799519886525056		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.23799519886525056 | validation: 0.21374903308990875]
	TIME [epoch: 24.9 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22712452649861545		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.22712452649861545 | validation: 0.21685639767920506]
	TIME [epoch: 24.9 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23002436714413102		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.23002436714413102 | validation: 0.20496974673712098]
	TIME [epoch: 25 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2310208560748073		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.2310208560748073 | validation: 0.20505397305672432]
	TIME [epoch: 24.8 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2246166826880745		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.2246166826880745 | validation: 0.20425958662717528]
	TIME [epoch: 24.9 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.228761031061678		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.228761031061678 | validation: 0.19683894408021665]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_1305.pth
	Model improved!!!
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22575301460267463		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.22575301460267463 | validation: 0.21221507181111635]
	TIME [epoch: 24.9 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23028661777042417		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.23028661777042417 | validation: 0.19572824459761776]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r3_20240310_060952/states/model_tr_study206_1307.pth
	Model improved!!!
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23617570709415422		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.23617570709415422 | validation: 0.20843641527632892]
	TIME [epoch: 24.8 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23715081988668757		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.23715081988668757 | validation: 0.2218880299498134]
	TIME [epoch: 24.8 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.268552545729238		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.268552545729238 | validation: 0.27274635280534154]
	TIME [epoch: 25 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29601405890473004		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.29601405890473004 | validation: 0.23414820261092978]
	TIME [epoch: 25 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.254942613834595		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.254942613834595 | validation: 0.2298314980918652]
	TIME [epoch: 24.9 sec]
