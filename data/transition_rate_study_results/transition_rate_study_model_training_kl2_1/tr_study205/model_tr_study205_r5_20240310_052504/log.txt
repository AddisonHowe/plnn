Args:
Namespace(name='model_tr_study205', outdir='out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5', training_data='data/transition_rate_studies/tr_study205/tr_study205_training/r5', validation_data='data/transition_rate_studies/tr_study205/tr_study205_validation/r5', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.075, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 581175981

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 14.1616914098417		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 14.1616914098417 | validation: 13.324681262318308]
	TIME [epoch: 110 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 12.969069476292958		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 12.969069476292958 | validation: 11.025099299882031]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 12.804559782786152		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 12.804559782786152 | validation: 13.29593710688758]
	TIME [epoch: 24.9 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 13.169149912272356		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 13.169149912272356 | validation: 12.842219619984471]
	TIME [epoch: 24.9 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.95583811879444		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.95583811879444 | validation: 7.012485198245577]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.151035356693638		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.151035356693638 | validation: 7.709295445943147]
	TIME [epoch: 24.9 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.09656999372502		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.09656999372502 | validation: 6.549649357489074]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.515564739869559		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.515564739869559 | validation: 5.910148175910731]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.540655747693789		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.540655747693789 | validation: 5.601154428593279]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.34184779206564		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.34184779206564 | validation: 7.662504294459195]
	TIME [epoch: 24.9 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.044969140552264		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.044969140552264 | validation: 6.087533358822311]
	TIME [epoch: 24.9 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.719334064437392		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.719334064437392 | validation: 5.624560061654769]
	TIME [epoch: 24.9 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.384894096520767		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.384894096520767 | validation: 5.3838361999068685]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.293118762801317		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.293118762801317 | validation: 5.366872698887748]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.505042613450925		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.505042613450925 | validation: 6.154679635176489]
	TIME [epoch: 24.9 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.420703927362467		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.420703927362467 | validation: 5.039614025307151]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.4162293808995345		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.4162293808995345 | validation: 5.308325205289382]
	TIME [epoch: 24.9 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.113687304288984		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.113687304288984 | validation: 5.366279277406599]
	TIME [epoch: 24.9 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.381528575609794		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.381528575609794 | validation: 5.108851191698379]
	TIME [epoch: 24.8 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.819966183736033		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.819966183736033 | validation: 4.99707055608815]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.451385750517276		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.451385750517276 | validation: 7.24995016161577]
	TIME [epoch: 24.9 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.447210019113348		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.447210019113348 | validation: 5.463023194446134]
	TIME [epoch: 24.8 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.909470177215114		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.909470177215114 | validation: 4.886124702789686]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.015529015962805		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.015529015962805 | validation: 4.614581380098249]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.931791265477987		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.931791265477987 | validation: 4.865036949387312]
	TIME [epoch: 24.9 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.643159354576437		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.643159354576437 | validation: 5.136383766359838]
	TIME [epoch: 24.9 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.939449213917636		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.939449213917636 | validation: 4.598613291841082]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.660577927348221		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.660577927348221 | validation: 4.726570888778224]
	TIME [epoch: 24.9 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.818859848207252		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.818859848207252 | validation: 5.423768913448464]
	TIME [epoch: 24.9 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.75011685839116		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.75011685839116 | validation: 4.445892343827152]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.791023701826196		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.791023701826196 | validation: 5.138448971167019]
	TIME [epoch: 24.9 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.639645457992161		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.639645457992161 | validation: 4.820745348420724]
	TIME [epoch: 24.8 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.554969733996129		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.554969733996129 | validation: 4.75116842524694]
	TIME [epoch: 24.9 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.414227016444002		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.414227016444002 | validation: 4.743884122396848]
	TIME [epoch: 24.9 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.941198298539386		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.941198298539386 | validation: 5.366181625514068]
	TIME [epoch: 24.8 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.51789581839517		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.51789581839517 | validation: 6.337968059920927]
	TIME [epoch: 24.9 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.4932530640456925		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.4932530640456925 | validation: 5.144910829742943]
	TIME [epoch: 24.9 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.441746119810086		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.441746119810086 | validation: 4.377847796792633]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.3904338135286025		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.3904338135286025 | validation: 4.678458246742904]
	TIME [epoch: 24.9 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.341072047950795		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.341072047950795 | validation: 4.170114372938862]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.319628986479691		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.319628986479691 | validation: 4.987771362212035]
	TIME [epoch: 24.9 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.506385877392187		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.506385877392187 | validation: 4.743680551171464]
	TIME [epoch: 24.9 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.349179085955325		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.349179085955325 | validation: 4.660438496948758]
	TIME [epoch: 24.9 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.246738975199851		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.246738975199851 | validation: 4.03410053686724]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.074775838758624		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.074775838758624 | validation: 4.858569599334599]
	TIME [epoch: 24.9 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.215374799672592		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.215374799672592 | validation: 4.447165180923374]
	TIME [epoch: 24.9 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.406054926978109		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.406054926978109 | validation: 4.135896446463652]
	TIME [epoch: 24.9 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.041028894254767		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.041028894254767 | validation: 3.8726833033690076]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.286592782278282		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.286592782278282 | validation: 5.054942685413793]
	TIME [epoch: 24.9 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.239392597431812		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.239392597431812 | validation: 4.626206253173704]
	TIME [epoch: 24.9 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.186327935259475		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 4.186327935259475 | validation: 4.195283585737821]
	TIME [epoch: 24.9 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.120284016029003		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 4.120284016029003 | validation: 4.206424575066393]
	TIME [epoch: 24.9 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9284037141963584		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 3.9284037141963584 | validation: 4.5151227927893745]
	TIME [epoch: 24.9 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.174955810117144		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 4.174955810117144 | validation: 4.006211119065316]
	TIME [epoch: 24.9 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.95379462173699		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 3.95379462173699 | validation: 4.3278939010239705]
	TIME [epoch: 24.9 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.015101265507182		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 4.015101265507182 | validation: 4.291788948829432]
	TIME [epoch: 24.9 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.964153028507014		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 3.964153028507014 | validation: 4.964034912724386]
	TIME [epoch: 24.9 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.084590852321631		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 4.084590852321631 | validation: 4.634522729751845]
	TIME [epoch: 24.9 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9966975677419363		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 3.9966975677419363 | validation: 3.8127796019865934]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.814067727941428		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 3.814067727941428 | validation: 4.268423120176322]
	TIME [epoch: 24.9 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9771724382864653		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 3.9771724382864653 | validation: 3.9503535845944326]
	TIME [epoch: 24.8 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8887250376992792		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 3.8887250376992792 | validation: 3.796116361063611]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8731387565671707		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 3.8731387565671707 | validation: 4.003478382748267]
	TIME [epoch: 25 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.891431947883248		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 3.891431947883248 | validation: 3.973645723771341]
	TIME [epoch: 24.9 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8821890259527523		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 3.8821890259527523 | validation: 3.8752992216894087]
	TIME [epoch: 25 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7345778139352106		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 3.7345778139352106 | validation: 4.585002224322231]
	TIME [epoch: 25 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8349184657084674		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 3.8349184657084674 | validation: 4.303432749695339]
	TIME [epoch: 25 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.915222349000323		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 3.915222349000323 | validation: 4.244828013023626]
	TIME [epoch: 24.9 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.743279602447032		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 3.743279602447032 | validation: 3.689888527065319]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.876973101926917		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 3.876973101926917 | validation: 4.016359377156722]
	TIME [epoch: 25 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.807128720625001		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 3.807128720625001 | validation: 3.9049675287436436]
	TIME [epoch: 25 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7342541165337835		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 3.7342541165337835 | validation: 3.608554947686231]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7465559659269054		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 3.7465559659269054 | validation: 4.106931966283296]
	TIME [epoch: 25 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5691280086116635		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 3.5691280086116635 | validation: 5.016017724110303]
	TIME [epoch: 25 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.919768515788369		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 3.919768515788369 | validation: 3.591065279048172]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_75.pth
	Model improved!!!
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.714341022148483		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 3.714341022148483 | validation: 4.28234784257671]
	TIME [epoch: 24.9 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.874084320379823		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 3.874084320379823 | validation: 3.533595195228412]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.820310199885955		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 3.820310199885955 | validation: 3.715662864978434]
	TIME [epoch: 25 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.508421239905187		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 3.508421239905187 | validation: 3.4883940494439822]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9186325238393067		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 3.9186325238393067 | validation: 3.7307632879000914]
	TIME [epoch: 24.9 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7338846520127644		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 3.7338846520127644 | validation: 3.451548559553288]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_81.pth
	Model improved!!!
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7335542819420424		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 3.7335542819420424 | validation: 3.9854470347086077]
	TIME [epoch: 25 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.697187523233291		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 3.697187523233291 | validation: 3.9949315072998797]
	TIME [epoch: 24.9 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.767032675356427		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 3.767032675356427 | validation: 3.6333600038757754]
	TIME [epoch: 25 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4827997476198362		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 3.4827997476198362 | validation: 4.264313599914266]
	TIME [epoch: 25 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.600968239150709		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 3.600968239150709 | validation: 4.045062578021156]
	TIME [epoch: 24.9 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6076892487110244		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 3.6076892487110244 | validation: 4.625060378604889]
	TIME [epoch: 24.9 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.707885893779722		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 3.707885893779722 | validation: 3.760093972249444]
	TIME [epoch: 25 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.289753086347372		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 4.289753086347372 | validation: 3.6151002021197973]
	TIME [epoch: 25 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.053080379350345		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 4.053080379350345 | validation: 3.74560794993605]
	TIME [epoch: 24.9 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7594862646738756		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 3.7594862646738756 | validation: 3.915851719372893]
	TIME [epoch: 24.9 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.697945731610322		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 3.697945731610322 | validation: 3.717753314060618]
	TIME [epoch: 25 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.592866038309239		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 3.592866038309239 | validation: 4.005048329965675]
	TIME [epoch: 24.9 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.600562360048041		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 3.600562360048041 | validation: 3.777228258124237]
	TIME [epoch: 24.9 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.57568450762207		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 3.57568450762207 | validation: 3.633078736749112]
	TIME [epoch: 25 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5722075429627105		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 3.5722075429627105 | validation: 3.9158332430697294]
	TIME [epoch: 25 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6715480443178015		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 3.6715480443178015 | validation: 3.436408101016679]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.508397341155826		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 3.508397341155826 | validation: 3.907850938455132]
	TIME [epoch: 24.9 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4509055270793287		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 3.4509055270793287 | validation: 3.814996259667581]
	TIME [epoch: 24.9 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8519506488570223		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 3.8519506488570223 | validation: 3.5183980642150217]
	TIME [epoch: 24.9 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7629271793216774		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 3.7629271793216774 | validation: 3.530816366337014]
	TIME [epoch: 24.9 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.834623684882301		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 3.834623684882301 | validation: 3.566828109522099]
	TIME [epoch: 24.9 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.674423429361052		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 3.674423429361052 | validation: 3.4158913788859016]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_103.pth
	Model improved!!!
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.433915484440581		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 3.433915484440581 | validation: 5.199500781563274]
	TIME [epoch: 24.9 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8935814335250685		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 3.8935814335250685 | validation: 3.6602461994706044]
	TIME [epoch: 24.9 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6192976729042377		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 3.6192976729042377 | validation: 3.4358514208939197]
	TIME [epoch: 24.9 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.615905065032247		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 3.615905065032247 | validation: 3.7594883611820094]
	TIME [epoch: 25 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.6661974057972095		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 5.6661974057972095 | validation: 6.362934845018133]
	TIME [epoch: 24.9 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.655496387603331		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 4.655496387603331 | validation: 5.081244614670651]
	TIME [epoch: 24.9 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.170844574304644		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 4.170844574304644 | validation: 4.75566932238852]
	TIME [epoch: 25 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.935592400608014		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 3.935592400608014 | validation: 3.6528325078338084]
	TIME [epoch: 24.9 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.557924648214012		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 3.557924648214012 | validation: 3.5812664733597557]
	TIME [epoch: 24.9 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.460775601800149		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 3.460775601800149 | validation: 3.6659719809885813]
	TIME [epoch: 25 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.541990873236977		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 3.541990873236977 | validation: 4.020199684432377]
	TIME [epoch: 25 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.551339354200921		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 3.551339354200921 | validation: 3.8503824614937803]
	TIME [epoch: 25 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.388262423157097		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 3.388262423157097 | validation: 3.422407249667381]
	TIME [epoch: 24.9 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5964419158217034		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 3.5964419158217034 | validation: 3.6208618952616405]
	TIME [epoch: 25 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5366128262460066		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 3.5366128262460066 | validation: 3.9327780180345258]
	TIME [epoch: 25 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.674924187708414		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 3.674924187708414 | validation: 3.322663461626448]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_119.pth
	Model improved!!!
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4511386758042706		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 3.4511386758042706 | validation: 3.5954078854679032]
	TIME [epoch: 24.9 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.471079293232663		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 3.471079293232663 | validation: 3.6630702598669007]
	TIME [epoch: 24.9 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4981295067737657		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 3.4981295067737657 | validation: 3.828175396194622]
	TIME [epoch: 24.9 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.537306769557147		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 3.537306769557147 | validation: 3.3990872219291566]
	TIME [epoch: 24.9 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.51705667037473		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 3.51705667037473 | validation: 3.566950164677426]
	TIME [epoch: 24.9 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.546944687376217		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 3.546944687376217 | validation: 4.2478136363163275]
	TIME [epoch: 24.9 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5939053261446183		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 3.5939053261446183 | validation: 3.643500370137254]
	TIME [epoch: 24.9 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4845412250445342		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 3.4845412250445342 | validation: 3.412025406647087]
	TIME [epoch: 24.9 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3017547747507354		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 3.3017547747507354 | validation: 4.573894231781611]
	TIME [epoch: 24.9 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.890747452410806		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 3.890747452410806 | validation: 3.76764121758136]
	TIME [epoch: 24.9 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.616461562744352		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 3.616461562744352 | validation: 3.500469620223841]
	TIME [epoch: 24.9 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.455287410052592		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 3.455287410052592 | validation: 3.8718103922795923]
	TIME [epoch: 24.9 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.437766135034315		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 3.437766135034315 | validation: 3.3615170071845104]
	TIME [epoch: 24.9 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.436452888207815		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 3.436452888207815 | validation: 3.886906181099299]
	TIME [epoch: 24.9 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2757412139289905		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 3.2757412139289905 | validation: 3.3033218117373564]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_134.pth
	Model improved!!!
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4933464437190054		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 3.4933464437190054 | validation: 3.5906921993260124]
	TIME [epoch: 25 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.430320937443135		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 3.430320937443135 | validation: 3.6169807606918427]
	TIME [epoch: 24.9 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3812698667862056		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 3.3812698667862056 | validation: 3.908537441895138]
	TIME [epoch: 24.9 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5847635107130227		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 3.5847635107130227 | validation: 3.316352349423711]
	TIME [epoch: 24.9 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3551911545012625		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 3.3551911545012625 | validation: 3.4041407533649135]
	TIME [epoch: 25 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.350548103859645		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 3.350548103859645 | validation: 4.065591896263006]
	TIME [epoch: 24.9 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.423326835320827		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 3.423326835320827 | validation: 3.8247527950440396]
	TIME [epoch: 24.9 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.356756350248756		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 3.356756350248756 | validation: 3.2934824986436517]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_142.pth
	Model improved!!!
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3832158219244355		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 3.3832158219244355 | validation: 3.5255533817550724]
	TIME [epoch: 25 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.342223844398349		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 3.342223844398349 | validation: 3.519317909533236]
	TIME [epoch: 24.9 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3815738081623934		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 3.3815738081623934 | validation: 3.8076604072779343]
	TIME [epoch: 24.9 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4386801222380408		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 3.4386801222380408 | validation: 3.6667187931512646]
	TIME [epoch: 24.9 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3423854600606018		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 3.3423854600606018 | validation: 3.638145921653745]
	TIME [epoch: 24.9 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2662727191866225		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 3.2662727191866225 | validation: 3.3773525125338946]
	TIME [epoch: 24.9 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.49871237823686		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 3.49871237823686 | validation: 3.952624473956044]
	TIME [epoch: 24.9 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.256379846473517		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 3.256379846473517 | validation: 3.5998516346645055]
	TIME [epoch: 24.9 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.446299419223542		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 3.446299419223542 | validation: 3.504122379241733]
	TIME [epoch: 24.9 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.462212181782057		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 3.462212181782057 | validation: 3.2859241702811954]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_152.pth
	Model improved!!!
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.416224727278899		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 3.416224727278899 | validation: 4.09318599862693]
	TIME [epoch: 24.9 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4117276568285466		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 3.4117276568285466 | validation: 4.362772662296917]
	TIME [epoch: 24.9 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5778580729793488		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 3.5778580729793488 | validation: 3.6869809132135605]
	TIME [epoch: 24.9 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1990118999830814		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 3.1990118999830814 | validation: 3.698886767676387]
	TIME [epoch: 24.9 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4296462484152257		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 3.4296462484152257 | validation: 4.396855639557139]
	TIME [epoch: 24.9 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4810788598469		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 3.4810788598469 | validation: 4.672459305808054]
	TIME [epoch: 24.9 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8471466381727706		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 3.8471466381727706 | validation: 3.4482924279953693]
	TIME [epoch: 24.9 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3986122772680916		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 3.3986122772680916 | validation: 3.243467014158428]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_160.pth
	Model improved!!!
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.301498485353822		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 3.301498485353822 | validation: 3.434215168541314]
	TIME [epoch: 24.9 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2304623429215664		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 3.2304623429215664 | validation: 3.337103714174539]
	TIME [epoch: 24.9 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3556341433896053		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 3.3556341433896053 | validation: 3.7942485318917045]
	TIME [epoch: 24.9 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.324043127798978		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 3.324043127798978 | validation: 3.5962839852741935]
	TIME [epoch: 24.9 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.320323255755511		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 3.320323255755511 | validation: 3.5990661767515792]
	TIME [epoch: 24.9 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.371578780074501		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 3.371578780074501 | validation: 3.19513294909235]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_166.pth
	Model improved!!!
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3939298115488867		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 3.3939298115488867 | validation: 3.3416605574324145]
	TIME [epoch: 24.9 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.353597110549109		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 3.353597110549109 | validation: 3.622401500875345]
	TIME [epoch: 24.9 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.499282486482584		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 3.499282486482584 | validation: 3.328643892382387]
	TIME [epoch: 24.9 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.379334382122712		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 3.379334382122712 | validation: 3.321999888111812]
	TIME [epoch: 24.9 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2060594416239914		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 3.2060594416239914 | validation: 3.773882284832513]
	TIME [epoch: 24.9 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.319317974968031		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 3.319317974968031 | validation: 3.540219494985332]
	TIME [epoch: 24.9 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2854804593426072		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 3.2854804593426072 | validation: 3.52980803027803]
	TIME [epoch: 24.9 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.348578318912708		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 3.348578318912708 | validation: 3.497582477583459]
	TIME [epoch: 24.9 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3831356522673244		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 3.3831356522673244 | validation: 3.4048479146910213]
	TIME [epoch: 25 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.185285854397647		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 3.185285854397647 | validation: 3.763345953842424]
	TIME [epoch: 24.9 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3160670981146207		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 3.3160670981146207 | validation: 4.241322530534919]
	TIME [epoch: 24.9 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6603242207314977		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 3.6603242207314977 | validation: 3.425591188687956]
	TIME [epoch: 24.9 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3290170120158273		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 3.3290170120158273 | validation: 3.2860617833645938]
	TIME [epoch: 24.9 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2665286432762644		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 3.2665286432762644 | validation: 3.5318574124448974]
	TIME [epoch: 24.9 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3255910197980088		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 3.3255910197980088 | validation: 3.312822629843623]
	TIME [epoch: 24.8 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.416885571382993		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 3.416885571382993 | validation: 3.6294405386890447]
	TIME [epoch: 24.9 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3424216924062717		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 3.3424216924062717 | validation: 3.42750036133836]
	TIME [epoch: 24.9 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2731950081354664		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 3.2731950081354664 | validation: 3.577569240704968]
	TIME [epoch: 24.9 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3290353460960844		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 3.3290353460960844 | validation: 3.3907105779125146]
	TIME [epoch: 24.9 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3479643808947124		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 3.3479643808947124 | validation: 3.2086853291978823]
	TIME [epoch: 24.9 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.428252817927945		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 3.428252817927945 | validation: 3.2975346357259214]
	TIME [epoch: 24.9 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.228775058462271		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 3.228775058462271 | validation: 4.274208409176755]
	TIME [epoch: 24.9 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4341867967287896		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 3.4341867967287896 | validation: 3.88127072593525]
	TIME [epoch: 24.9 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4179160335705587		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 3.4179160335705587 | validation: 3.9948924759221174]
	TIME [epoch: 24.9 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.410304414678614		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 3.410304414678614 | validation: 3.3358477783544376]
	TIME [epoch: 24.9 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2732606405563365		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 3.2732606405563365 | validation: 3.7189146588175443]
	TIME [epoch: 24.9 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2331167930727425		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 3.2331167930727425 | validation: 3.8036449190816017]
	TIME [epoch: 24.9 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3143847177726222		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 3.3143847177726222 | validation: 4.0916427367777235]
	TIME [epoch: 24.9 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4685901273882918		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 3.4685901273882918 | validation: 3.4945645415934927]
	TIME [epoch: 24.9 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3152212198255944		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 3.3152212198255944 | validation: 4.044497666559441]
	TIME [epoch: 24.9 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4099194584822343		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 3.4099194584822343 | validation: 3.6062990422153827]
	TIME [epoch: 24.9 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.201783936213735		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 3.201783936213735 | validation: 4.1473207856767695]
	TIME [epoch: 24.9 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.395801896168477		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 3.395801896168477 | validation: 4.240386989420341]
	TIME [epoch: 24.9 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.350907036898635		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 3.350907036898635 | validation: 3.5385871721912667]
	TIME [epoch: 24.9 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.166044208785926		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 3.166044208785926 | validation: 4.520189955659419]
	TIME [epoch: 24.9 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8425570592881244		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 3.8425570592881244 | validation: 4.684536048200975]
	TIME [epoch: 24.9 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.76326719423428		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 3.76326719423428 | validation: 3.948249503371495]
	TIME [epoch: 24.9 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.315895918386409		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 3.315895918386409 | validation: 3.359472943237769]
	TIME [epoch: 24.9 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.228501801930957		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 3.228501801930957 | validation: 3.2235494591022977]
	TIME [epoch: 24.9 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3579577667767837		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 3.3579577667767837 | validation: 3.935405561158873]
	TIME [epoch: 24.9 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3518111787255718		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 3.3518111787255718 | validation: 3.2099050041907233]
	TIME [epoch: 24.9 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.34754317088328		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 3.34754317088328 | validation: 4.334968748708091]
	TIME [epoch: 24.9 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.478364022272789		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 3.478364022272789 | validation: 3.311220492793846]
	TIME [epoch: 24.9 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2713725881202063		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 3.2713725881202063 | validation: 3.226602112732791]
	TIME [epoch: 24.9 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1939261835607824		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 3.1939261835607824 | validation: 3.8416606676294944]
	TIME [epoch: 24.9 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3434102182871293		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 3.3434102182871293 | validation: 3.2803192894805386]
	TIME [epoch: 24.9 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2825954818449414		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 3.2825954818449414 | validation: 3.4363797762781996]
	TIME [epoch: 24.9 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3035776429599544		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 3.3035776429599544 | validation: 3.1876869503829077]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_214.pth
	Model improved!!!
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1746656273497917		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 3.1746656273497917 | validation: 3.2173274986295586]
	TIME [epoch: 24.9 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2476987957379815		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 3.2476987957379815 | validation: 3.177238452877295]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_216.pth
	Model improved!!!
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2561020185097997		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 3.2561020185097997 | validation: 3.3982405881319977]
	TIME [epoch: 24.9 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2711841269508177		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 3.2711841269508177 | validation: 3.4027421163957627]
	TIME [epoch: 24.9 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.236865978007992		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 3.236865978007992 | validation: 3.355728313032955]
	TIME [epoch: 25 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2216523054334947		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 3.2216523054334947 | validation: 3.2256214426556644]
	TIME [epoch: 24.9 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0903730960614304		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 3.0903730960614304 | validation: 3.139675918105951]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_221.pth
	Model improved!!!
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2658240374328558		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 3.2658240374328558 | validation: 3.5882989762539363]
	TIME [epoch: 25 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2669399316857923		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 3.2669399316857923 | validation: 3.2720054532502094]
	TIME [epoch: 25 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.194669275304326		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 3.194669275304326 | validation: 3.3992517364941905]
	TIME [epoch: 24.9 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.189390420901472		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 3.189390420901472 | validation: 3.1459634267321634]
	TIME [epoch: 24.9 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1594414355145957		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 3.1594414355145957 | validation: 3.2159753948495062]
	TIME [epoch: 24.9 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.306909751559453		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 3.306909751559453 | validation: 3.3797517039267246]
	TIME [epoch: 24.9 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.210190448322662		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 3.210190448322662 | validation: 3.1983254291020002]
	TIME [epoch: 24.9 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.166592570690928		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 3.166592570690928 | validation: 3.765639856528761]
	TIME [epoch: 24.9 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1940113646992505		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 3.1940113646992505 | validation: 3.547550418793773]
	TIME [epoch: 24.9 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.346873594496468		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 3.346873594496468 | validation: 3.143131693211732]
	TIME [epoch: 24.9 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2041998359485686		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 3.2041998359485686 | validation: 3.2812726186658234]
	TIME [epoch: 24.9 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.205791309704738		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 3.205791309704738 | validation: 3.40944317080965]
	TIME [epoch: 24.9 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.228209694700179		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 3.228209694700179 | validation: 3.6350089808380224]
	TIME [epoch: 24.9 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2027047241940854		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 3.2027047241940854 | validation: 3.407131877077719]
	TIME [epoch: 24.9 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2350615560944758		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 3.2350615560944758 | validation: 3.2539487642206235]
	TIME [epoch: 24.9 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0187865852916604		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 3.0187865852916604 | validation: 3.471480537889768]
	TIME [epoch: 24.9 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1956434109276337		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 3.1956434109276337 | validation: 3.3921736342958653]
	TIME [epoch: 24.9 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.232162064541424		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 3.232162064541424 | validation: 3.274867369231416]
	TIME [epoch: 24.9 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.090824405954187		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 3.090824405954187 | validation: 4.135224210369731]
	TIME [epoch: 24.9 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2371994323914635		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 3.2371994323914635 | validation: 3.6227805078739337]
	TIME [epoch: 24.9 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1731166458684337		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 3.1731166458684337 | validation: 3.538487480042071]
	TIME [epoch: 24.9 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.193065810483308		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 3.193065810483308 | validation: 3.7679182946849887]
	TIME [epoch: 24.9 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2403813597080875		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 3.2403813597080875 | validation: 3.1892826189515766]
	TIME [epoch: 25 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.102240355050396		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 3.102240355050396 | validation: 3.849448412639357]
	TIME [epoch: 25 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2833571090747267		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 3.2833571090747267 | validation: 3.1248681991360288]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_246.pth
	Model improved!!!
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.99037800021659		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 3.99037800021659 | validation: 3.421462559115856]
	TIME [epoch: 24.9 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.357787525007268		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 3.357787525007268 | validation: 3.4163339732531224]
	TIME [epoch: 24.9 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.045626664348201		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 3.045626664348201 | validation: 4.247717549053905]
	TIME [epoch: 24.9 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.505527250918176		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 3.505527250918176 | validation: 3.5445843243154407]
	TIME [epoch: 24.9 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1209148911908704		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 3.1209148911908704 | validation: 3.203514920573023]
	TIME [epoch: 24.9 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2643635229380146		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 3.2643635229380146 | validation: 3.572116724015025]
	TIME [epoch: 24.9 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2674052722172147		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 3.2674052722172147 | validation: 3.2364168588530453]
	TIME [epoch: 24.9 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.174212364416275		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 3.174212364416275 | validation: 3.1574302513387593]
	TIME [epoch: 24.9 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.270432991533411		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 3.270432991533411 | validation: 3.3164541750615193]
	TIME [epoch: 24.9 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.111145734646302		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 3.111145734646302 | validation: 3.3798328691124175]
	TIME [epoch: 24.9 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.612068437691356		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 3.612068437691356 | validation: 3.245757285148974]
	TIME [epoch: 24.9 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.455430409338325		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 3.455430409338325 | validation: 3.460984329614721]
	TIME [epoch: 24.9 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2604763534878534		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 3.2604763534878534 | validation: 3.7099720687100564]
	TIME [epoch: 24.9 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.379125035715128		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 3.379125035715128 | validation: 4.102928894396976]
	TIME [epoch: 24.9 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.30424723531583		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 3.30424723531583 | validation: 3.457367753304193]
	TIME [epoch: 24.9 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.226826165431608		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 3.226826165431608 | validation: 3.277382790581198]
	TIME [epoch: 24.9 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.110639956145781		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 3.110639956145781 | validation: 3.233794841905915]
	TIME [epoch: 24.9 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.328777246753701		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 3.328777246753701 | validation: 3.257361962663315]
	TIME [epoch: 24.9 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.170864263964984		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 3.170864263964984 | validation: 3.58908350136175]
	TIME [epoch: 24.9 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.189057222959307		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 3.189057222959307 | validation: 3.1770645316769515]
	TIME [epoch: 24.9 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.258292440780809		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 3.258292440780809 | validation: 3.1378042885640345]
	TIME [epoch: 25 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1685851427638796		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 3.1685851427638796 | validation: 3.311031312895608]
	TIME [epoch: 24.9 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1598274187076156		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 3.1598274187076156 | validation: 3.297299672668452]
	TIME [epoch: 25 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0443739226568214		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 3.0443739226568214 | validation: 3.145548554106357]
	TIME [epoch: 24.9 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.078524576666112		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 3.078524576666112 | validation: 3.3393462425951776]
	TIME [epoch: 24.9 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0768190738995145		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 3.0768190738995145 | validation: 3.2361400329010213]
	TIME [epoch: 24.9 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1121824408967833		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 3.1121824408967833 | validation: 3.641177023810292]
	TIME [epoch: 24.9 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.211945846385496		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 3.211945846385496 | validation: 3.261611303506405]
	TIME [epoch: 24.9 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.068878167180956		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 3.068878167180956 | validation: 3.399434699709366]
	TIME [epoch: 24.9 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1914097690664085		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 3.1914097690664085 | validation: 3.400452765046048]
	TIME [epoch: 24.9 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.142426584922671		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 3.142426584922671 | validation: 3.132640557307051]
	TIME [epoch: 24.9 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.02809520673513		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 3.02809520673513 | validation: 3.3429179108619396]
	TIME [epoch: 24.9 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.137282440526187		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 3.137282440526187 | validation: 3.3130407392807535]
	TIME [epoch: 24.9 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1512648506110628		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 3.1512648506110628 | validation: 3.093117802359552]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_280.pth
	Model improved!!!
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.06051694287366		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 3.06051694287366 | validation: 3.1738650554314867]
	TIME [epoch: 24.9 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0812289749757555		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 3.0812289749757555 | validation: 3.1565582787702784]
	TIME [epoch: 24.9 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1359995348345677		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 3.1359995348345677 | validation: 3.119958208239853]
	TIME [epoch: 24.9 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.240048670621654		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 3.240048670621654 | validation: 3.3372005327541348]
	TIME [epoch: 24.9 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0494570942732806		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 3.0494570942732806 | validation: 3.305295235901789]
	TIME [epoch: 24.9 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0422688483267137		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 3.0422688483267137 | validation: 3.2067223995090712]
	TIME [epoch: 24.9 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1263418843969446		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 3.1263418843969446 | validation: 3.1396877613468765]
	TIME [epoch: 24.9 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0476514438647064		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 3.0476514438647064 | validation: 3.327327409151767]
	TIME [epoch: 24.9 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0207324164548526		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 3.0207324164548526 | validation: 3.616154022349862]
	TIME [epoch: 24.9 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1790638167780605		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 3.1790638167780605 | validation: 3.2026796571175273]
	TIME [epoch: 24.9 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1761521240032233		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 3.1761521240032233 | validation: 3.161262418944154]
	TIME [epoch: 25 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3057463959085		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 3.3057463959085 | validation: 3.2513522910682844]
	TIME [epoch: 25 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.124047021175333		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 3.124047021175333 | validation: 3.1355320782759883]
	TIME [epoch: 24.9 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.082436748811288		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 3.082436748811288 | validation: 3.335080941068471]
	TIME [epoch: 24.9 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0681156960579226		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 3.0681156960579226 | validation: 3.2004439677876384]
	TIME [epoch: 24.9 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1249287935857026		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 3.1249287935857026 | validation: 3.3986365664815956]
	TIME [epoch: 24.9 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.061591902583885		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 3.061591902583885 | validation: 3.1761803312564383]
	TIME [epoch: 24.9 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0714192894101906		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 3.0714192894101906 | validation: 3.635314468196068]
	TIME [epoch: 24.9 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1018132037736224		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 3.1018132037736224 | validation: 3.199254151377281]
	TIME [epoch: 24.9 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.044704856512603		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 3.044704856512603 | validation: 3.123761998005077]
	TIME [epoch: 24.9 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0545732576153224		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 3.0545732576153224 | validation: 3.5812565754116448]
	TIME [epoch: 24.9 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.261893988551915		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 3.261893988551915 | validation: 3.1980164496724894]
	TIME [epoch: 24.9 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.028545905527084		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 3.028545905527084 | validation: 3.089785888316646]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_303.pth
	Model improved!!!
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9527289410832602		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 2.9527289410832602 | validation: 3.219637877427648]
	TIME [epoch: 24.9 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0439901953043615		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 3.0439901953043615 | validation: 3.182602259492082]
	TIME [epoch: 25 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0855977851109992		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 3.0855977851109992 | validation: 3.247138312492209]
	TIME [epoch: 25 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3307854484932347		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 3.3307854484932347 | validation: 3.292516882113191]
	TIME [epoch: 24.9 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0856956832205977		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 3.0856956832205977 | validation: 3.212902062289513]
	TIME [epoch: 24.9 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1191805853513936		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 3.1191805853513936 | validation: 3.1628432144844636]
	TIME [epoch: 25 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0007327654414206		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 3.0007327654414206 | validation: 3.9446597795012113]
	TIME [epoch: 25 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.363873460886234		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 3.363873460886234 | validation: 3.0928701889283365]
	TIME [epoch: 24.9 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0617528369021993		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 3.0617528369021993 | validation: 3.391662283552064]
	TIME [epoch: 24.9 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.181397342016269		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 3.181397342016269 | validation: 3.2363389568949663]
	TIME [epoch: 25 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0373184362762853		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 3.0373184362762853 | validation: 3.158288847323147]
	TIME [epoch: 25 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.062024843955386		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 3.062024843955386 | validation: 3.099701899580139]
	TIME [epoch: 24.9 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2111195012876173		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 3.2111195012876173 | validation: 3.324867022580654]
	TIME [epoch: 25 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.080035421503072		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 3.080035421503072 | validation: 3.084716840314157]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_317.pth
	Model improved!!!
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2559080905385573		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 3.2559080905385573 | validation: 3.2176879343762597]
	TIME [epoch: 24.9 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0722865686825678		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 3.0722865686825678 | validation: 3.0849685215367675]
	TIME [epoch: 24.9 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1549751694587864		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 3.1549751694587864 | validation: 3.208357849514097]
	TIME [epoch: 24.9 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.100157620036956		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 3.100157620036956 | validation: 3.253069919618273]
	TIME [epoch: 24.9 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.065624225654572		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 3.065624225654572 | validation: 3.1457308500216845]
	TIME [epoch: 24.9 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.950072530900493		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 2.950072530900493 | validation: 3.180675726689649]
	TIME [epoch: 24.9 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.087502705228432		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 3.087502705228432 | validation: 3.111541410291886]
	TIME [epoch: 25 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.13797243398519		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 3.13797243398519 | validation: 3.2951691831771166]
	TIME [epoch: 24.9 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0653523362100374		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 3.0653523362100374 | validation: 3.0990944148340884]
	TIME [epoch: 24.9 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.088949254374722		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 3.088949254374722 | validation: 3.11796169639263]
	TIME [epoch: 24.9 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.112126721927429		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 3.112126721927429 | validation: 3.1140874813320525]
	TIME [epoch: 24.9 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9526712502416532		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 2.9526712502416532 | validation: 3.2665249392687277]
	TIME [epoch: 24.9 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1696141995185134		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 3.1696141995185134 | validation: 3.2263630813852036]
	TIME [epoch: 24.9 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.002477876767648		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 3.002477876767648 | validation: 3.5409865650205177]
	TIME [epoch: 24.9 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.121444639317837		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 3.121444639317837 | validation: 3.0921772417827476]
	TIME [epoch: 24.9 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.116874230400846		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 3.116874230400846 | validation: 3.112132627534362]
	TIME [epoch: 24.9 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0604187869545374		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 3.0604187869545374 | validation: 3.1088174597141456]
	TIME [epoch: 24.9 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0662523073041035		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 3.0662523073041035 | validation: 3.116576039651953]
	TIME [epoch: 24.9 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.970920993235668		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 2.970920993235668 | validation: 3.6952482779855025]
	TIME [epoch: 24.9 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2237056724013122		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 3.2237056724013122 | validation: 3.487777495617058]
	TIME [epoch: 24.9 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1098205599545707		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 3.1098205599545707 | validation: 3.6860158892051507]
	TIME [epoch: 24.9 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.126445936545718		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 3.126445936545718 | validation: 3.1492902762682013]
	TIME [epoch: 24.9 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9729724584101636		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 2.9729724584101636 | validation: 3.2148798300390253]
	TIME [epoch: 24.9 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9899439579605587		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 2.9899439579605587 | validation: 3.2080763761391764]
	TIME [epoch: 24.9 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.003643096901584		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 3.003643096901584 | validation: 3.5801280089208127]
	TIME [epoch: 24.9 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0543203988916736		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 3.0543203988916736 | validation: 3.4056428571210087]
	TIME [epoch: 24.9 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1202029363264607		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 3.1202029363264607 | validation: 3.1719658943742504]
	TIME [epoch: 24.9 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.005121503892583		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 3.005121503892583 | validation: 3.1172468100352746]
	TIME [epoch: 24.9 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9891279781825295		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 2.9891279781825295 | validation: 3.273624526332099]
	TIME [epoch: 24.9 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0537946188208576		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 3.0537946188208576 | validation: 3.1539453312202683]
	TIME [epoch: 24.9 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9807628778059714		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 2.9807628778059714 | validation: 3.217008242393646]
	TIME [epoch: 24.9 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.038509679367075		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 3.038509679367075 | validation: 3.122555755172953]
	TIME [epoch: 24.9 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.022904125910244		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 3.022904125910244 | validation: 4.325055413121842]
	TIME [epoch: 24.9 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.519294870289055		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 3.519294870289055 | validation: 3.5485023574811168]
	TIME [epoch: 24.9 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.212100924186465		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 3.212100924186465 | validation: 3.3866270394344453]
	TIME [epoch: 24.9 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.067902491550357		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 3.067902491550357 | validation: 3.088714421487584]
	TIME [epoch: 24.9 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9964112235783262		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 2.9964112235783262 | validation: 3.1179488538489233]
	TIME [epoch: 24.9 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.014876040023036		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 3.014876040023036 | validation: 3.0573811755773637]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_355.pth
	Model improved!!!
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.979345754971191		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 2.979345754971191 | validation: 3.1949175464037434]
	TIME [epoch: 24.9 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.995368951337043		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 2.995368951337043 | validation: 3.1884598956824592]
	TIME [epoch: 24.9 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.321662312700378		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 3.321662312700378 | validation: 3.276113088253193]
	TIME [epoch: 24.9 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.022674862247492		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 3.022674862247492 | validation: 3.391885438876601]
	TIME [epoch: 24.9 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.034185369071686		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 3.034185369071686 | validation: 3.539826526435157]
	TIME [epoch: 24.9 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.104383439051425		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 3.104383439051425 | validation: 3.2751796652847753]
	TIME [epoch: 24.9 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.986790724710747		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 2.986790724710747 | validation: 3.6976959871703072]
	TIME [epoch: 24.9 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1430399818914005		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 3.1430399818914005 | validation: 3.1722500819394264]
	TIME [epoch: 24.9 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9844869631750397		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 2.9844869631750397 | validation: 3.0874790783730752]
	TIME [epoch: 24.9 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.971307392112964		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 2.971307392112964 | validation: 3.4332106545717282]
	TIME [epoch: 24.9 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0955003831823116		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 3.0955003831823116 | validation: 3.095962942423318]
	TIME [epoch: 24.9 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.991084212286479		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 2.991084212286479 | validation: 3.0699878380328536]
	TIME [epoch: 24.9 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0053056240752722		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 3.0053056240752722 | validation: 3.2318730830216533]
	TIME [epoch: 24.9 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9853314699091174		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 2.9853314699091174 | validation: 3.075005428464298]
	TIME [epoch: 24.9 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0025452824972554		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 3.0025452824972554 | validation: 3.5383604163265456]
	TIME [epoch: 24.9 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0949167580115864		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 3.0949167580115864 | validation: 3.0625456939357263]
	TIME [epoch: 24.9 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.097317832796962		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 3.097317832796962 | validation: 3.0518228533177036]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_372.pth
	Model improved!!!
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9917151910760333		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 2.9917151910760333 | validation: 3.2435586806539676]
	TIME [epoch: 24.9 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.05355308786612		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 3.05355308786612 | validation: 3.037984891825682]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_374.pth
	Model improved!!!
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.26985289138959		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 3.26985289138959 | validation: 3.2456905275503254]
	TIME [epoch: 24.9 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.991167592156639		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 2.991167592156639 | validation: 3.3093561272015086]
	TIME [epoch: 24.9 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0016368104020015		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 3.0016368104020015 | validation: 3.165164417941245]
	TIME [epoch: 24.9 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.994453932659236		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 2.994453932659236 | validation: 3.0712454834314253]
	TIME [epoch: 24.9 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0227583396448527		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 3.0227583396448527 | validation: 3.0769258536097523]
	TIME [epoch: 24.9 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9343243874407734		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 2.9343243874407734 | validation: 3.0895576161219673]
	TIME [epoch: 24.9 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9919015457731057		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 2.9919015457731057 | validation: 3.233471189563079]
	TIME [epoch: 24.9 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.036065385859296		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 3.036065385859296 | validation: 3.1979834226767685]
	TIME [epoch: 24.9 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0872138790622747		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 3.0872138790622747 | validation: 3.2318863751680458]
	TIME [epoch: 24.9 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.991779040570666		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 2.991779040570666 | validation: 3.041114935572271]
	TIME [epoch: 24.8 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.998246027311857		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 2.998246027311857 | validation: 3.0473482946407437]
	TIME [epoch: 24.9 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9508746706235462		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 2.9508746706235462 | validation: 3.424159985606404]
	TIME [epoch: 24.9 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0460503428360557		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 3.0460503428360557 | validation: 3.223510640848936]
	TIME [epoch: 24.9 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.945913109622719		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 2.945913109622719 | validation: 3.0405786623515856]
	TIME [epoch: 24.9 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9120740142211536		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 2.9120740142211536 | validation: 3.410523779429316]
	TIME [epoch: 24.9 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.132598455240383		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 3.132598455240383 | validation: 3.0980671901752532]
	TIME [epoch: 24.9 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.013619758617069		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 3.013619758617069 | validation: 3.4712160157158305]
	TIME [epoch: 24.9 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1385178769588222		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 3.1385178769588222 | validation: 3.130681317067381]
	TIME [epoch: 24.9 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.059778794325932		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 3.059778794325932 | validation: 3.4115280276241275]
	TIME [epoch: 24.9 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.135642752874898		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 3.135642752874898 | validation: 3.51008131462266]
	TIME [epoch: 24.9 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.126932666547557		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 3.126932666547557 | validation: 3.61332214428276]
	TIME [epoch: 24.9 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.153301579917124		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 3.153301579917124 | validation: 3.1117497910389806]
	TIME [epoch: 24.9 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.944375811957224		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 2.944375811957224 | validation: 3.1338324538951863]
	TIME [epoch: 24.9 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0004626154782437		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 3.0004626154782437 | validation: 3.140738952330939]
	TIME [epoch: 24.9 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.949599118934148		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 2.949599118934148 | validation: 3.0844171178006747]
	TIME [epoch: 24.9 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8994823388645665		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 2.8994823388645665 | validation: 3.3021809808786293]
	TIME [epoch: 24.9 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.996023296934537		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 2.996023296934537 | validation: 3.186419265369992]
	TIME [epoch: 24.9 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.973270522867924		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 2.973270522867924 | validation: 3.0680817797661426]
	TIME [epoch: 24.9 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9552200559223047		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 2.9552200559223047 | validation: 3.191783141886528]
	TIME [epoch: 24.9 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1858158030145187		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 3.1858158030145187 | validation: 3.0652402873362434]
	TIME [epoch: 24.9 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9324686721125603		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 2.9324686721125603 | validation: 3.151616354129114]
	TIME [epoch: 24.9 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.951605467056109		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 2.951605467056109 | validation: 3.0639214083883486]
	TIME [epoch: 24.9 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.944241048107121		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 2.944241048107121 | validation: 3.0649445166562153]
	TIME [epoch: 24.9 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.051239292854362		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 3.051239292854362 | validation: 3.0842991806440416]
	TIME [epoch: 24.9 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.965954733290439		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 2.965954733290439 | validation: 3.348648520792675]
	TIME [epoch: 24.9 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.075317951008676		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 3.075317951008676 | validation: 3.07180057248924]
	TIME [epoch: 24.9 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.955394100205176		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 2.955394100205176 | validation: 3.2540432577635823]
	TIME [epoch: 24.9 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.971923273136199		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 2.971923273136199 | validation: 3.2081417967215025]
	TIME [epoch: 24.9 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.029123218733459		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 3.029123218733459 | validation: 3.125206611662332]
	TIME [epoch: 24.9 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1545488089512235		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 3.1545488089512235 | validation: 3.2471617625248532]
	TIME [epoch: 24.9 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0487894435498384		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 3.0487894435498384 | validation: 3.0930001603018322]
	TIME [epoch: 24.9 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9524920664114687		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 2.9524920664114687 | validation: 3.426631530665475]
	TIME [epoch: 24.9 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.05641628652242		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 3.05641628652242 | validation: 3.1033091199283547]
	TIME [epoch: 24.9 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9486579913159137		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 2.9486579913159137 | validation: 3.1210007887572164]
	TIME [epoch: 24.9 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.053005880745618		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 3.053005880745618 | validation: 3.097679271334188]
	TIME [epoch: 24.9 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.951491480903723		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 2.951491480903723 | validation: 3.2231638402703915]
	TIME [epoch: 24.9 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0139245651680997		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 3.0139245651680997 | validation: 3.034032657782932]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_421.pth
	Model improved!!!
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.180764080993471		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 3.180764080993471 | validation: 3.261045253163845]
	TIME [epoch: 24.9 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0973201687657377		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 3.0973201687657377 | validation: 3.128868704792359]
	TIME [epoch: 24.9 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9672553246717124		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 2.9672553246717124 | validation: 3.15819871859548]
	TIME [epoch: 24.9 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.941964854336133		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 2.941964854336133 | validation: 3.0417939276543087]
	TIME [epoch: 24.9 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0506302034286823		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 3.0506302034286823 | validation: 3.0836203927081103]
	TIME [epoch: 24.9 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9464026586163774		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 2.9464026586163774 | validation: 3.0661039472967127]
	TIME [epoch: 24.9 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9353818080097644		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 2.9353818080097644 | validation: 3.238577871029416]
	TIME [epoch: 24.9 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9580733430559425		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 2.9580733430559425 | validation: 3.3366286062995574]
	TIME [epoch: 24.9 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.139258585445236		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 3.139258585445236 | validation: 3.069955807488707]
	TIME [epoch: 24.9 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.999742548350014		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 2.999742548350014 | validation: 3.0497590184051018]
	TIME [epoch: 24.9 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.921469866225067		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 2.921469866225067 | validation: 3.051594134710853]
	TIME [epoch: 25 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.914772671019862		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 2.914772671019862 | validation: 3.5864596350440525]
	TIME [epoch: 24.9 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0956521563426005		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 3.0956521563426005 | validation: 3.3551919016837157]
	TIME [epoch: 24.9 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1625784135269486		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 3.1625784135269486 | validation: 3.3037329073479946]
	TIME [epoch: 24.8 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0781057586084164		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 3.0781057586084164 | validation: 3.303248810251578]
	TIME [epoch: 24.9 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1757347368111595		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 3.1757347368111595 | validation: 3.1484776822965688]
	TIME [epoch: 24.9 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9806266457382713		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 2.9806266457382713 | validation: 3.2450733868740493]
	TIME [epoch: 24.9 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.936929428822282		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 2.936929428822282 | validation: 3.110446381282376]
	TIME [epoch: 24.9 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9163220716154674		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 2.9163220716154674 | validation: 3.1293657289189016]
	TIME [epoch: 24.9 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9801460415187853		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 2.9801460415187853 | validation: 3.069682646517996]
	TIME [epoch: 24.9 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.985521160988016		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 2.985521160988016 | validation: 3.2179880672744003]
	TIME [epoch: 24.9 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.021307557953772		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 3.021307557953772 | validation: 3.055630450043617]
	TIME [epoch: 24.9 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.926792827726915		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 2.926792827726915 | validation: 3.1176892190890726]
	TIME [epoch: 24.9 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.988662422180851		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 2.988662422180851 | validation: 3.2173668122686285]
	TIME [epoch: 24.9 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9347290286001417		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 2.9347290286001417 | validation: 3.0742314076890103]
	TIME [epoch: 24.9 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9256114591077624		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 2.9256114591077624 | validation: 3.0511414274228303]
	TIME [epoch: 24.9 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9104729680500774		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 2.9104729680500774 | validation: 3.2696816123451646]
	TIME [epoch: 24.9 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9796215548825575		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 2.9796215548825575 | validation: 3.2403403044873382]
	TIME [epoch: 24.9 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0354583559040647		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 3.0354583559040647 | validation: 3.0645747897757873]
	TIME [epoch: 24.9 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.935325908027311		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 2.935325908027311 | validation: 3.1192653872080407]
	TIME [epoch: 24.9 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.059903196006044		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 3.059903196006044 | validation: 3.0838683928360955]
	TIME [epoch: 24.9 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.956507105133653		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 2.956507105133653 | validation: 3.109656510365649]
	TIME [epoch: 24.9 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0128425436091346		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 3.0128425436091346 | validation: 3.093850076636242]
	TIME [epoch: 24.9 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9445651138943045		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 2.9445651138943045 | validation: 3.1859606625280925]
	TIME [epoch: 24.9 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9707489082574723		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 2.9707489082574723 | validation: 3.038410303831454]
	TIME [epoch: 24.9 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9254069780040695		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 2.9254069780040695 | validation: 3.396244667703265]
	TIME [epoch: 24.9 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.04061542712698		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 3.04061542712698 | validation: 3.316751057029282]
	TIME [epoch: 24.9 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0112165830365574		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 3.0112165830365574 | validation: 3.262875413977994]
	TIME [epoch: 24.9 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9419646431573874		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 2.9419646431573874 | validation: 3.0363241223247086]
	TIME [epoch: 24.8 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.91952926130713		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 2.91952926130713 | validation: 3.485747385234573]
	TIME [epoch: 24.9 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.070833599457522		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 3.070833599457522 | validation: 3.265225684598728]
	TIME [epoch: 24.9 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9731748856467863		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 2.9731748856467863 | validation: 3.0679302414706]
	TIME [epoch: 24.9 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8975671182535687		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 2.8975671182535687 | validation: 3.1012474292274037]
	TIME [epoch: 24.9 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9381566623024806		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 2.9381566623024806 | validation: 3.0443738399466462]
	TIME [epoch: 24.9 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.979818069534518		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 2.979818069534518 | validation: 3.384679275532734]
	TIME [epoch: 24.9 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0827529103858433		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 3.0827529103858433 | validation: 3.3536714977118165]
	TIME [epoch: 24.9 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.005002760914264		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 3.005002760914264 | validation: 3.102670754809015]
	TIME [epoch: 24.9 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9357429176642134		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 2.9357429176642134 | validation: 3.183242975761931]
	TIME [epoch: 24.9 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9991719176049165		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 2.9991719176049165 | validation: 3.1158252996016746]
	TIME [epoch: 24.9 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9013742655762047		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 2.9013742655762047 | validation: 3.0892103135261024]
	TIME [epoch: 24.9 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.999464138932108		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 2.999464138932108 | validation: 3.27605684692193]
	TIME [epoch: 24.9 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0297646944720054		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 3.0297646944720054 | validation: 3.1654083952990972]
	TIME [epoch: 24.9 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.914580318388979		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 2.914580318388979 | validation: 3.089006119694782]
	TIME [epoch: 24.9 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9247324952893874		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 2.9247324952893874 | validation: 3.0743839698459317]
	TIME [epoch: 24.9 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.956083930704572		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 2.956083930704572 | validation: 3.0346190090793947]
	TIME [epoch: 25 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0114876654804386		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 3.0114876654804386 | validation: 3.327688454334478]
	TIME [epoch: 24.9 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9686959057007325		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 2.9686959057007325 | validation: 3.110028305999821]
	TIME [epoch: 24.9 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.938599757102461		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 2.938599757102461 | validation: 3.0229268063796617]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_479.pth
	Model improved!!!
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1432566423699067		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 3.1432566423699067 | validation: 3.1201153037169043]
	TIME [epoch: 24.9 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.903625540372697		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 2.903625540372697 | validation: 3.0804351577443967]
	TIME [epoch: 24.9 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.915384568594186		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 2.915384568594186 | validation: 3.207948184519229]
	TIME [epoch: 24.9 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1463011664052867		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 3.1463011664052867 | validation: 3.0516107623287407]
	TIME [epoch: 24.9 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0935269588481997		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 3.0935269588481997 | validation: 3.084516201104403]
	TIME [epoch: 25 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9315225084723995		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 2.9315225084723995 | validation: 3.0935277560073904]
	TIME [epoch: 24.9 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9387321763917416		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 2.9387321763917416 | validation: 3.168311455312601]
	TIME [epoch: 24.9 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9676630637311003		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 2.9676630637311003 | validation: 3.094855368668068]
	TIME [epoch: 24.9 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.058443362013464		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 3.058443362013464 | validation: 3.1225496626936127]
	TIME [epoch: 24.9 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.905933426022429		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 2.905933426022429 | validation: 3.04860798007195]
	TIME [epoch: 24.9 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9464430436529505		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 2.9464430436529505 | validation: 3.1474766431095214]
	TIME [epoch: 24.9 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9183511795214856		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 2.9183511795214856 | validation: 3.1154070778000587]
	TIME [epoch: 24.9 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9124696176148857		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 2.9124696176148857 | validation: 3.039628541654762]
	TIME [epoch: 24.9 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.041350642081661		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 3.041350642081661 | validation: 3.0572492146553487]
	TIME [epoch: 24.9 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8916897184082258		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 2.8916897184082258 | validation: 3.0194237034103]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_494.pth
	Model improved!!!
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8934430669752476		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 2.8934430669752476 | validation: 3.0250676430743284]
	TIME [epoch: 24.9 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.896956391355163		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 2.896956391355163 | validation: 3.0558077400633055]
	TIME [epoch: 24.9 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.91585665938295		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 2.91585665938295 | validation: 3.235058824885665]
	TIME [epoch: 25 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9806911168547874		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 2.9806911168547874 | validation: 3.1082887483844024]
	TIME [epoch: 24.9 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.901882794245196		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 2.901882794245196 | validation: 3.085205972592456]
	TIME [epoch: 24.9 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.903494500805679		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 2.903494500805679 | validation: 3.3146835012436147]
	TIME [epoch: 24.9 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0703732191446704		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 3.0703732191446704 | validation: 3.05895822530347]
	TIME [epoch: 24.9 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.873499221693857		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 2.873499221693857 | validation: 3.0216128511535296]
	TIME [epoch: 24.9 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.900961665575496		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 2.900961665575496 | validation: 3.042682720721394]
	TIME [epoch: 24.9 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9975806310501554		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 2.9975806310501554 | validation: 3.0655689542500855]
	TIME [epoch: 24.9 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9334763773336707		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 2.9334763773336707 | validation: 3.023865389500418]
	TIME [epoch: 24.9 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0067323777880732		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 3.0067323777880732 | validation: 3.1562359367653006]
	TIME [epoch: 24.9 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.938195554581181		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 2.938195554581181 | validation: 3.184376676384923]
	TIME [epoch: 24.9 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9104284497734594		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 2.9104284497734594 | validation: 3.0522932876199174]
	TIME [epoch: 24.9 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0252799846075367		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 3.0252799846075367 | validation: 3.13478558786459]
	TIME [epoch: 24.9 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9273397207026615		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 2.9273397207026615 | validation: 3.0402177881007426]
	TIME [epoch: 24.9 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8896481043879776		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 2.8896481043879776 | validation: 3.0817457058805005]
	TIME [epoch: 24.9 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.912672762035476		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 2.912672762035476 | validation: 3.1987393148169465]
	TIME [epoch: 24.9 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9421908629845834		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 2.9421908629845834 | validation: 3.0907728874210205]
	TIME [epoch: 25 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.919404130308817		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 2.919404130308817 | validation: 3.122897152801972]
	TIME [epoch: 24.9 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.939961580072165		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 2.939961580072165 | validation: 3.0373721709844475]
	TIME [epoch: 24.9 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.959895900001904		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 2.959895900001904 | validation: 3.5190935778285355]
	TIME [epoch: 25 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.24694001726585		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 3.24694001726585 | validation: 3.1432812442253617]
	TIME [epoch: 24.9 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9561746590597737		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 2.9561746590597737 | validation: 3.0589984838071587]
	TIME [epoch: 24.9 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.882214556155521		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 2.882214556155521 | validation: 3.06331104675465]
	TIME [epoch: 24.9 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.005901181368417		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 3.005901181368417 | validation: 3.100657644905653]
	TIME [epoch: 24.9 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0019740124777554		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 3.0019740124777554 | validation: 3.0240316366647177]
	TIME [epoch: 24.9 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8749562742708905		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 2.8749562742708905 | validation: 3.0806680705335823]
	TIME [epoch: 24.9 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9001036169036403		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 2.9001036169036403 | validation: 3.2667073005753777]
	TIME [epoch: 24.9 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.313017343913321		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 3.313017343913321 | validation: 3.049836605286348]
	TIME [epoch: 24.9 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.91560248012438		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 2.91560248012438 | validation: 3.1558370704487766]
	TIME [epoch: 24.9 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9599598831451326		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 2.9599598831451326 | validation: 3.03249634371405]
	TIME [epoch: 24.9 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.900149793430846		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 2.900149793430846 | validation: 3.081609679836743]
	TIME [epoch: 24.9 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9362452879097996		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 2.9362452879097996 | validation: 3.0382827547391176]
	TIME [epoch: 24.9 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.875378574782231		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 2.875378574782231 | validation: 3.025772779971601]
	TIME [epoch: 24.9 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8776699207482292		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 2.8776699207482292 | validation: 3.22288032551238]
	TIME [epoch: 24.9 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.948262590185084		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 2.948262590185084 | validation: 3.022213538617757]
	TIME [epoch: 24.9 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.900408019739581		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 2.900408019739581 | validation: 3.154340195267866]
	TIME [epoch: 24.9 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9590811090930895		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 2.9590811090930895 | validation: 3.168018512038716]
	TIME [epoch: 24.9 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9345049102396743		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 2.9345049102396743 | validation: 3.2470205715951117]
	TIME [epoch: 24.9 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9715751538976685		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 2.9715751538976685 | validation: 3.035091135147833]
	TIME [epoch: 24.9 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9890485324655156		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 2.9890485324655156 | validation: 3.0374471414253255]
	TIME [epoch: 24.9 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8775546685878584		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 2.8775546685878584 | validation: 3.0387048122120817]
	TIME [epoch: 25 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.892427030002275		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 2.892427030002275 | validation: 3.0489531900518343]
	TIME [epoch: 24.9 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9404430513450825		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 2.9404430513450825 | validation: 3.10801349328381]
	TIME [epoch: 24.9 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.906453457206463		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 2.906453457206463 | validation: 3.1311703515558227]
	TIME [epoch: 24.9 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2109828266584266		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 3.2109828266584266 | validation: 3.0271424676241274]
	TIME [epoch: 24.9 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8566684839501395		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 2.8566684839501395 | validation: 3.068609977775151]
	TIME [epoch: 24.9 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.942650038547158		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 2.942650038547158 | validation: 3.025767701079388]
	TIME [epoch: 24.8 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.909515000158116		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 2.909515000158116 | validation: 3.0620282142529933]
	TIME [epoch: 24.9 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.886884406378079		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 2.886884406378079 | validation: 3.1482819031788343]
	TIME [epoch: 24.9 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9333129880305653		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 2.9333129880305653 | validation: 3.0419277311157518]
	TIME [epoch: 24.9 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.886158935004371		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 2.886158935004371 | validation: 3.0202360054102364]
	TIME [epoch: 24.9 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8859261840072117		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 2.8859261840072117 | validation: 3.0567794498310223]
	TIME [epoch: 24.9 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.902247794841374		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 2.902247794841374 | validation: 3.0106077875346573]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_549.pth
	Model improved!!!
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.903495703126156		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 2.903495703126156 | validation: 3.0789532600350347]
	TIME [epoch: 24.9 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.869066644937221		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 2.869066644937221 | validation: 3.16745161218293]
	TIME [epoch: 24.9 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9606759797229785		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 2.9606759797229785 | validation: 3.152655287876048]
	TIME [epoch: 24.9 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9104779579316116		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 2.9104779579316116 | validation: 3.014847340718528]
	TIME [epoch: 24.9 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8800834194273577		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 2.8800834194273577 | validation: 3.087749535611097]
	TIME [epoch: 24.8 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9244772145360898		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 2.9244772145360898 | validation: 3.1044550800170736]
	TIME [epoch: 24.9 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.906875021304198		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 2.906875021304198 | validation: 3.00894727082335]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_556.pth
	Model improved!!!
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9344718938547016		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 2.9344718938547016 | validation: 3.158319271545249]
	TIME [epoch: 24.9 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9876004923502553		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 2.9876004923502553 | validation: 3.048857059738198]
	TIME [epoch: 24.9 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8672297232855755		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 2.8672297232855755 | validation: 3.0121837829130005]
	TIME [epoch: 24.9 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.880924565967563		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 2.880924565967563 | validation: 3.0399359422028875]
	TIME [epoch: 24.9 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8759735180939434		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 2.8759735180939434 | validation: 3.062995009919062]
	TIME [epoch: 24.9 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8891085333521747		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 2.8891085333521747 | validation: 3.0514786990286034]
	TIME [epoch: 24.9 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8657895167842655		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 2.8657895167842655 | validation: 3.0638130356129385]
	TIME [epoch: 24.9 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9345993949067273		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 2.9345993949067273 | validation: 3.011922037191906]
	TIME [epoch: 24.9 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8633711734630505		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 2.8633711734630505 | validation: 3.006808970310426]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_565.pth
	Model improved!!!
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9114090029975186		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 2.9114090029975186 | validation: 3.0254845837014224]
	TIME [epoch: 24.9 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9018245652600663		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 2.9018245652600663 | validation: 3.0155710278356684]
	TIME [epoch: 24.9 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9605155690337117		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 2.9605155690337117 | validation: 3.0537044017647363]
	TIME [epoch: 24.9 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8660675590982194		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 2.8660675590982194 | validation: 3.1800435550504598]
	TIME [epoch: 24.9 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8953046102994233		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 2.8953046102994233 | validation: 3.022743664312021]
	TIME [epoch: 25 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.932835787473554		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 2.932835787473554 | validation: 3.031747205915406]
	TIME [epoch: 24.9 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.878843964934135		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 2.878843964934135 | validation: 3.0995257983071314]
	TIME [epoch: 24.8 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.911123261025643		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 2.911123261025643 | validation: 3.0377469116885822]
	TIME [epoch: 24.9 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8898542227753494		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 2.8898542227753494 | validation: 3.070375680041028]
	TIME [epoch: 24.9 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8774032940697976		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 2.8774032940697976 | validation: 3.0633359488546943]
	TIME [epoch: 24.9 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9063744449159614		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 2.9063744449159614 | validation: 3.0093107765083538]
	TIME [epoch: 24.9 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.862851781046897		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 2.862851781046897 | validation: 3.097206372543517]
	TIME [epoch: 24.9 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.887519030490554		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 2.887519030490554 | validation: 3.0941333325108453]
	TIME [epoch: 24.9 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.942648401307979		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 2.942648401307979 | validation: 3.0366824214095494]
	TIME [epoch: 24.9 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.878193950533869		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 2.878193950533869 | validation: 3.010782296627235]
	TIME [epoch: 24.9 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8980991442451747		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 2.8980991442451747 | validation: 3.018929668651523]
	TIME [epoch: 24.9 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8991152252423946		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 2.8991152252423946 | validation: 3.017773236154868]
	TIME [epoch: 24.9 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8553119362841874		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 2.8553119362841874 | validation: 3.0119165327819033]
	TIME [epoch: 24.9 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8569434551260224		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 2.8569434551260224 | validation: 3.090049188849604]
	TIME [epoch: 24.9 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8694623512920767		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 2.8694623512920767 | validation: 3.0235288622347922]
	TIME [epoch: 24.9 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8998216556886063		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 2.8998216556886063 | validation: 3.09703850218887]
	TIME [epoch: 24.9 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8714655754059826		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 2.8714655754059826 | validation: 3.0421825828111793]
	TIME [epoch: 24.9 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.869569026518596		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 2.869569026518596 | validation: 3.1091927471958822]
	TIME [epoch: 24.9 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.887182177643689		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 2.887182177643689 | validation: 3.035760380426252]
	TIME [epoch: 24.9 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8720922305647676		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 2.8720922305647676 | validation: 3.0643342692479774]
	TIME [epoch: 24.9 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8628134541384407		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 2.8628134541384407 | validation: 3.0549676397492362]
	TIME [epoch: 24.9 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8818644363226884		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 2.8818644363226884 | validation: 3.0987421211183905]
	TIME [epoch: 24.9 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9356103566699683		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 2.9356103566699683 | validation: 3.039219469136483]
	TIME [epoch: 24.9 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8941781577866514		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 2.8941781577866514 | validation: 3.090112067080951]
	TIME [epoch: 24.9 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8920199572129395		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 2.8920199572129395 | validation: 3.0760656494250807]
	TIME [epoch: 24.9 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.876253573936993		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 2.876253573936993 | validation: 3.104536606485216]
	TIME [epoch: 24.9 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8796779640111367		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 2.8796779640111367 | validation: 3.1029837597915115]
	TIME [epoch: 24.9 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9243365365987515		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 2.9243365365987515 | validation: 3.1627030535233374]
	TIME [epoch: 24.8 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9519878748976565		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 2.9519878748976565 | validation: 3.1302557066655083]
	TIME [epoch: 24.9 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.865659231983023		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 2.865659231983023 | validation: 3.0593545979005556]
	TIME [epoch: 24.9 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8671782775777666		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 2.8671782775777666 | validation: 3.0313586861559885]
	TIME [epoch: 24.9 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.882897339295875		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 2.882897339295875 | validation: 3.0543115084633388]
	TIME [epoch: 24.9 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8707025171046143		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 2.8707025171046143 | validation: 3.116637172947469]
	TIME [epoch: 24.9 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8770079145698744		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 2.8770079145698744 | validation: 3.0084104627676527]
	TIME [epoch: 24.9 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9441024697089384		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 2.9441024697089384 | validation: 3.161656825744225]
	TIME [epoch: 24.9 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.958659160862578		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 2.958659160862578 | validation: 3.0088126299595537]
	TIME [epoch: 24.9 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8501856791906586		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 2.8501856791906586 | validation: 3.0451389101316146]
	TIME [epoch: 24.9 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.974190110638161		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 2.974190110638161 | validation: 3.0414503816885885]
	TIME [epoch: 24.8 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.91284632169142		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 2.91284632169142 | validation: 3.1466433997722585]
	TIME [epoch: 24.9 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8889804930871406		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 2.8889804930871406 | validation: 3.066428095029788]
	TIME [epoch: 24.9 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8629966927310333		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 2.8629966927310333 | validation: 3.1157382592093605]
	TIME [epoch: 24.9 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.89362075077223		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 2.89362075077223 | validation: 3.028522743901782]
	TIME [epoch: 24.8 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8947513485379233		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 2.8947513485379233 | validation: 3.0009113002903223]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_613.pth
	Model improved!!!
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.863714677465988		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 2.863714677465988 | validation: 3.0337871102138583]
	TIME [epoch: 24.9 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.845632217680168		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 2.845632217680168 | validation: 3.012692604819873]
	TIME [epoch: 24.9 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.862696223414622		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 2.862696223414622 | validation: 3.0056185213824076]
	TIME [epoch: 24.9 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8628338838486522		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 2.8628338838486522 | validation: 3.0033668644910643]
	TIME [epoch: 24.9 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.869125139972688		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 2.869125139972688 | validation: 3.132469903378369]
	TIME [epoch: 24.9 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8987283389440544		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 2.8987283389440544 | validation: 3.1130600078524284]
	TIME [epoch: 24.9 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.881408967948608		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 2.881408967948608 | validation: 3.0088099485990427]
	TIME [epoch: 24.9 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.878880783176573		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 2.878880783176573 | validation: 3.034269263388552]
	TIME [epoch: 25 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9528783105989436		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 2.9528783105989436 | validation: 3.0445626252877833]
	TIME [epoch: 24.9 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8692632774906754		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 2.8692632774906754 | validation: 3.1372077607422466]
	TIME [epoch: 24.9 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9098611302379926		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 2.9098611302379926 | validation: 3.041994968029235]
	TIME [epoch: 24.9 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9488566500457294		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 2.9488566500457294 | validation: 3.005030131988545]
	TIME [epoch: 24.9 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.889671921774986		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 2.889671921774986 | validation: 3.0163214036362]
	TIME [epoch: 24.9 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8867395614563174		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 2.8867395614563174 | validation: 3.0725984551251155]
	TIME [epoch: 24.9 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.883269207223365		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 2.883269207223365 | validation: 3.0206849569766097]
	TIME [epoch: 24.9 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8671108333577084		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 2.8671108333577084 | validation: 3.0068735413955574]
	TIME [epoch: 24.9 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8515908472205487		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 2.8515908472205487 | validation: 3.1057265414465474]
	TIME [epoch: 24.8 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9025197133994514		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 2.9025197133994514 | validation: 3.09885847708228]
	TIME [epoch: 24.9 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9005692130409684		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 2.9005692130409684 | validation: 3.189527281446341]
	TIME [epoch: 24.9 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.885388654680309		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 2.885388654680309 | validation: 3.070371962261313]
	TIME [epoch: 24.9 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9104873704074343		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 2.9104873704074343 | validation: 3.073665727625006]
	TIME [epoch: 24.9 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9372794721538718		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 2.9372794721538718 | validation: 3.148643795216882]
	TIME [epoch: 24.9 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9588137118694027		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 2.9588137118694027 | validation: 3.036754884674012]
	TIME [epoch: 24.9 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8941772482758563		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 2.8941772482758563 | validation: 3.010901911433098]
	TIME [epoch: 24.8 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8584314895982756		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 2.8584314895982756 | validation: 3.0148195872699093]
	TIME [epoch: 24.9 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8596109937010015		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 2.8596109937010015 | validation: 3.0072071896408854]
	TIME [epoch: 24.9 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8594533912870808		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 2.8594533912870808 | validation: 3.1897726011763727]
	TIME [epoch: 24.9 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9349632899544327		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 2.9349632899544327 | validation: 2.996491668023346]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_641.pth
	Model improved!!!
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.843398200645744		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 2.843398200645744 | validation: 3.0375607347282307]
	TIME [epoch: 25.1 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.876431059392231		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 2.876431059392231 | validation: 3.091307247143188]
	TIME [epoch: 24.9 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0198699436765626		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 3.0198699436765626 | validation: 3.0026881867385726]
	TIME [epoch: 24.9 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8868709827645818		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 2.8868709827645818 | validation: 3.013372480330355]
	TIME [epoch: 24.9 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8865530498654404		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 2.8865530498654404 | validation: 3.0112676959743716]
	TIME [epoch: 24.9 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8714045864595406		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 2.8714045864595406 | validation: 3.038875983436372]
	TIME [epoch: 24.9 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.854693812294362		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 2.854693812294362 | validation: 3.1055924661166308]
	TIME [epoch: 24.9 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8996141758327743		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 2.8996141758327743 | validation: 3.041368771691034]
	TIME [epoch: 24.9 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8544793240474062		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 2.8544793240474062 | validation: 3.0378274344628724]
	TIME [epoch: 25 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.876805690605708		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 2.876805690605708 | validation: 3.0461352174876777]
	TIME [epoch: 24.9 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.889312230986456		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 2.889312230986456 | validation: 3.0704955762305355]
	TIME [epoch: 24.9 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8764331955162317		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 2.8764331955162317 | validation: 3.136309820930531]
	TIME [epoch: 24.9 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9058103666213304		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 2.9058103666213304 | validation: 3.079071713316778]
	TIME [epoch: 24.9 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8683584624992378		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 2.8683584624992378 | validation: 3.0199612154698974]
	TIME [epoch: 24.9 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.899219214895497		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 2.899219214895497 | validation: 2.9917891828330734]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_656.pth
	Model improved!!!
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.896012286431734		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 2.896012286431734 | validation: 3.170116966574392]
	TIME [epoch: 24.9 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8899928150667202		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 2.8899928150667202 | validation: 2.98942570173262]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_658.pth
	Model improved!!!
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8434220627280284		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 2.8434220627280284 | validation: 3.042774412273771]
	TIME [epoch: 24.9 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.870057013085388		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 2.870057013085388 | validation: 3.0728579128699516]
	TIME [epoch: 24.9 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.848986329835573		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 2.848986329835573 | validation: 3.1481369503477725]
	TIME [epoch: 24.9 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9038452828571932		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 2.9038452828571932 | validation: 3.006307506491942]
	TIME [epoch: 24.9 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8361221971819597		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 2.8361221971819597 | validation: 3.0052742234337235]
	TIME [epoch: 24.9 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.862132135904245		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 2.862132135904245 | validation: 3.008796677207838]
	TIME [epoch: 24.9 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.858101939392471		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 2.858101939392471 | validation: 3.049972411278119]
	TIME [epoch: 24.9 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.875477567561819		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 2.875477567561819 | validation: 3.0531906123463193]
	TIME [epoch: 24.9 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8977690367418996		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 2.8977690367418996 | validation: 3.033865893185526]
	TIME [epoch: 24.9 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8525361258613895		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 2.8525361258613895 | validation: 3.003690206325865]
	TIME [epoch: 24.9 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.862357292721501		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 2.862357292721501 | validation: 3.0508519217454033]
	TIME [epoch: 24.9 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8721679255313286		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 2.8721679255313286 | validation: 3.1146452585731437]
	TIME [epoch: 24.9 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.878590123597816		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 2.878590123597816 | validation: 3.062161820465316]
	TIME [epoch: 24.9 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9143287239111086		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 2.9143287239111086 | validation: 3.2069274937849137]
	TIME [epoch: 24.9 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.881445389221359		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 2.881445389221359 | validation: 3.0010406641139604]
	TIME [epoch: 24.9 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.861429281654263		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 2.861429281654263 | validation: 3.0516155776295246]
	TIME [epoch: 24.9 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.888636040704384		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 2.888636040704384 | validation: 3.0331268173955683]
	TIME [epoch: 24.9 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8481259881726664		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 2.8481259881726664 | validation: 3.0251779278698847]
	TIME [epoch: 24.9 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8379053980010465		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 2.8379053980010465 | validation: 3.022778738273391]
	TIME [epoch: 24.9 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8981442923555085		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 2.8981442923555085 | validation: 3.0054598261025665]
	TIME [epoch: 24.9 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8794268977337873		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 2.8794268977337873 | validation: 3.199038456711426]
	TIME [epoch: 24.9 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9337156404303903		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 2.9337156404303903 | validation: 3.0161759226529656]
	TIME [epoch: 24.9 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.878341721093901		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 2.878341721093901 | validation: 2.9989844053649963]
	TIME [epoch: 24.9 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.844525979793826		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 2.844525979793826 | validation: 3.010389771791834]
	TIME [epoch: 24.9 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.862061408177338		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 2.862061408177338 | validation: 3.007535770671004]
	TIME [epoch: 24.9 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.867954359839164		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 2.867954359839164 | validation: 3.0506224663428076]
	TIME [epoch: 24.9 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.887794669481147		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 2.887794669481147 | validation: 3.143702505101233]
	TIME [epoch: 24.9 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.880727408540806		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 2.880727408540806 | validation: 3.001185291228576]
	TIME [epoch: 24.9 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8490136608638217		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 2.8490136608638217 | validation: 3.0676386617017886]
	TIME [epoch: 24.9 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.878391477417636		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 2.878391477417636 | validation: 3.0362008458026835]
	TIME [epoch: 24.9 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.893713850025514		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 2.893713850025514 | validation: 3.049271577395998]
	TIME [epoch: 24.9 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8787910358079425		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 2.8787910358079425 | validation: 3.3301262073961837]
	TIME [epoch: 24.9 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.947756626112595		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 2.947756626112595 | validation: 3.005460106018088]
	TIME [epoch: 24.9 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.841729431399481		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 2.841729431399481 | validation: 3.032018959189527]
	TIME [epoch: 24.9 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.843228260916981		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 2.843228260916981 | validation: 2.997668956966241]
	TIME [epoch: 24.9 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.830727129566063		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 2.830727129566063 | validation: 3.006906383013728]
	TIME [epoch: 24.9 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.837280065130077		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 2.837280065130077 | validation: 3.0131442924426732]
	TIME [epoch: 24.9 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8400674830527386		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 2.8400674830527386 | validation: 3.0819986554866916]
	TIME [epoch: 24.9 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8786234606472685		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 2.8786234606472685 | validation: 3.0398931860648917]
	TIME [epoch: 24.9 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.877744751525622		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 2.877744751525622 | validation: 3.0162105935447276]
	TIME [epoch: 24.9 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8395140554244205		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 2.8395140554244205 | validation: 3.047454723223507]
	TIME [epoch: 24.9 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8400263757826987		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 2.8400263757826987 | validation: 2.9945886352627236]
	TIME [epoch: 24.9 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9236898824878876		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 2.9236898824878876 | validation: 3.0812072314018155]
	TIME [epoch: 24.9 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9019622848075914		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 2.9019622848075914 | validation: 3.0317470126891375]
	TIME [epoch: 24.9 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8390206204977444		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 2.8390206204977444 | validation: 2.99310237993802]
	TIME [epoch: 24.9 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.842039212891579		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 2.842039212891579 | validation: 3.0025222180360065]
	TIME [epoch: 24.9 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8675195442366257		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 2.8675195442366257 | validation: 3.0753372377576467]
	TIME [epoch: 24.9 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8634452008806206		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 2.8634452008806206 | validation: 3.022181269502661]
	TIME [epoch: 24.9 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8484077112138655		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 2.8484077112138655 | validation: 3.1225102365632402]
	TIME [epoch: 24.9 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9024253010369883		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 2.9024253010369883 | validation: 2.9912117112708594]
	TIME [epoch: 24.9 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8522937469591465		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 2.8522937469591465 | validation: 2.9968777182902104]
	TIME [epoch: 24.9 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8296590980047225		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 2.8296590980047225 | validation: 3.000491946943825]
	TIME [epoch: 24.9 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8470900242656816		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 2.8470900242656816 | validation: 2.9988744681505266]
	TIME [epoch: 24.9 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8329531154387837		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 2.8329531154387837 | validation: 3.032714379937382]
	TIME [epoch: 24.9 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.832363984494594		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 2.832363984494594 | validation: 3.0535680499283124]
	TIME [epoch: 24.9 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9218024355829058		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 2.9218024355829058 | validation: 3.223950768190594]
	TIME [epoch: 24.9 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9066740744016366		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 2.9066740744016366 | validation: 2.9957792386901803]
	TIME [epoch: 24.9 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8498489258763273		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 2.8498489258763273 | validation: 2.993394253766268]
	TIME [epoch: 24.9 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.84699837267405		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 2.84699837267405 | validation: 3.0050408302801337]
	TIME [epoch: 24.9 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8927893199282124		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 2.8927893199282124 | validation: 3.007591584158902]
	TIME [epoch: 24.9 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.858906271966046		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 2.858906271966046 | validation: 3.040877697708793]
	TIME [epoch: 24.9 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8567651084465018		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 2.8567651084465018 | validation: 2.9951434034566358]
	TIME [epoch: 24.9 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.847582109292384		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 2.847582109292384 | validation: 2.987292899769152]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_721.pth
	Model improved!!!
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8636393239553497		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 2.8636393239553497 | validation: 3.0202783813400402]
	TIME [epoch: 24.9 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8387214257901254		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 2.8387214257901254 | validation: 3.035194188563435]
	TIME [epoch: 24.9 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.843750259117245		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 2.843750259117245 | validation: 2.9925784336529215]
	TIME [epoch: 24.9 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9411185596117213		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 2.9411185596117213 | validation: 2.9853322841560233]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_725.pth
	Model improved!!!
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8353519119893402		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 2.8353519119893402 | validation: 2.9959083446032078]
	TIME [epoch: 24.9 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.837259627391019		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 2.837259627391019 | validation: 3.0079307613563855]
	TIME [epoch: 24.9 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.844499631487405		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 2.844499631487405 | validation: 2.9801144128101993]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_728.pth
	Model improved!!!
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8390528753453967		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 2.8390528753453967 | validation: 2.989146829644316]
	TIME [epoch: 24.9 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8526112316040715		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 2.8526112316040715 | validation: 3.07813984792506]
	TIME [epoch: 24.9 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9515920671714864		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 2.9515920671714864 | validation: 3.031953327976595]
	TIME [epoch: 24.9 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.848629569234601		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 2.848629569234601 | validation: 2.9957426216899887]
	TIME [epoch: 24.9 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8547875652388566		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 2.8547875652388566 | validation: 2.992068822155261]
	TIME [epoch: 24.9 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.861103159092571		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 2.861103159092571 | validation: 3.048130146819641]
	TIME [epoch: 24.9 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8422605888321053		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 2.8422605888321053 | validation: 3.011755982430707]
	TIME [epoch: 24.9 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.843449682706099		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 2.843449682706099 | validation: 3.0453972002675163]
	TIME [epoch: 24.9 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8848457834819152		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 2.8848457834819152 | validation: 3.0111034028910955]
	TIME [epoch: 24.9 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8508485085496846		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 2.8508485085496846 | validation: 3.0567112422850076]
	TIME [epoch: 24.9 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8452912958900622		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 2.8452912958900622 | validation: 3.0067289894441775]
	TIME [epoch: 24.9 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.830858274129881		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 2.830858274129881 | validation: 3.0226697917660386]
	TIME [epoch: 24.9 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.840207417579375		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 2.840207417579375 | validation: 3.0009551081397627]
	TIME [epoch: 24.9 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.846595628309073		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 2.846595628309073 | validation: 2.996315480171418]
	TIME [epoch: 24.9 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8356743066185843		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 2.8356743066185843 | validation: 3.0035178820518698]
	TIME [epoch: 24.9 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8262461109064425		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 2.8262461109064425 | validation: 3.069382982130359]
	TIME [epoch: 24.9 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8453267169351086		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 2.8453267169351086 | validation: 3.0268956329123506]
	TIME [epoch: 24.9 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8528013839458612		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 2.8528013839458612 | validation: 3.0496577245646677]
	TIME [epoch: 24.9 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.855166125233358		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 2.855166125233358 | validation: 2.983150588770663]
	TIME [epoch: 24.9 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8310476507566467		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 2.8310476507566467 | validation: 3.034307826816123]
	TIME [epoch: 24.9 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.876462386416061		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 2.876462386416061 | validation: 2.9933645380057454]
	TIME [epoch: 24.9 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8337751713174395		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 2.8337751713174395 | validation: 2.9990348382620176]
	TIME [epoch: 24.9 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.855330905489276		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 2.855330905489276 | validation: 2.996300456433348]
	TIME [epoch: 24.9 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.835944290907637		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 2.835944290907637 | validation: 3.098709561508932]
	TIME [epoch: 24.9 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8504862933873794		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 2.8504862933873794 | validation: 3.0161267888434113]
	TIME [epoch: 24.9 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8270798397885812		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 2.8270798397885812 | validation: 2.9967924314161074]
	TIME [epoch: 24.8 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8337364229462514		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 2.8337364229462514 | validation: 2.998648655405205]
	TIME [epoch: 24.9 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8707804327368396		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 2.8707804327368396 | validation: 3.0522673808471756]
	TIME [epoch: 24.9 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.884799760983494		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 2.884799760983494 | validation: 2.9941848104373117]
	TIME [epoch: 24.9 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.829822065595464		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 2.829822065595464 | validation: 3.0335443296161295]
	TIME [epoch: 24.9 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.862466955198856		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 2.862466955198856 | validation: 2.9926654050724113]
	TIME [epoch: 24.9 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8691499539789764		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 2.8691499539789764 | validation: 2.9939789501648866]
	TIME [epoch: 24.9 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8374561866012558		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 2.8374561866012558 | validation: 2.9876055395562298]
	TIME [epoch: 24.9 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.82744488644227		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 2.82744488644227 | validation: 3.0002122459876386]
	TIME [epoch: 24.9 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.857160116806786		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 2.857160116806786 | validation: 3.1401350084829995]
	TIME [epoch: 24.9 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.908154011596763		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 2.908154011596763 | validation: 3.0622591393337633]
	TIME [epoch: 24.9 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.851622936900383		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 2.851622936900383 | validation: 2.9938897420834185]
	TIME [epoch: 24.9 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.851176894517919		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 2.851176894517919 | validation: 3.099817441324083]
	TIME [epoch: 24.9 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.841343526037167		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 2.841343526037167 | validation: 3.058787662867097]
	TIME [epoch: 24.9 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.866238696238022		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 2.866238696238022 | validation: 3.138041076202806]
	TIME [epoch: 24.9 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.882616303717674		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 2.882616303717674 | validation: 2.9850060740578352]
	TIME [epoch: 24.9 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.84418271459184		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 2.84418271459184 | validation: 3.001249863303061]
	TIME [epoch: 24.9 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8359129426805048		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 2.8359129426805048 | validation: 3.0134606942388404]
	TIME [epoch: 24.9 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.827136966601085		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 2.827136966601085 | validation: 3.007062857755546]
	TIME [epoch: 24.9 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8629087061185636		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 2.8629087061185636 | validation: 3.0191754394172383]
	TIME [epoch: 24.9 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.829927462850391		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 2.829927462850391 | validation: 3.029495722776827]
	TIME [epoch: 24.9 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8518105591397216		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 2.8518105591397216 | validation: 3.0131477502857007]
	TIME [epoch: 24.9 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.84425512022373		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 2.84425512022373 | validation: 3.0207693008430887]
	TIME [epoch: 24.9 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.918193742258018		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 2.918193742258018 | validation: 3.0013511237340853]
	TIME [epoch: 24.9 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.834524999144656		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 2.834524999144656 | validation: 3.061866263252351]
	TIME [epoch: 24.9 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.901234382678926		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 2.901234382678926 | validation: 3.0206221619196088]
	TIME [epoch: 24.9 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8636434953262544		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 2.8636434953262544 | validation: 3.0608433994705555]
	TIME [epoch: 24.9 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.859478026950543		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 2.859478026950543 | validation: 2.988672519306149]
	TIME [epoch: 24.9 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8402684431745415		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 2.8402684431745415 | validation: 2.9839538323234764]
	TIME [epoch: 24.9 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8307419104678457		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 2.8307419104678457 | validation: 3.017825441851029]
	TIME [epoch: 24.9 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.823677295563256		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 2.823677295563256 | validation: 3.033441753776019]
	TIME [epoch: 24.9 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8394031752976083		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 2.8394031752976083 | validation: 3.060691209612276]
	TIME [epoch: 24.9 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8572966663390518		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 2.8572966663390518 | validation: 3.0880421869181243]
	TIME [epoch: 24.9 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.865903080364504		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 2.865903080364504 | validation: 2.9762772432693807]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_787.pth
	Model improved!!!
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.836844806238601		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 2.836844806238601 | validation: 2.9976670422939993]
	TIME [epoch: 24.9 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8302257706797107		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 2.8302257706797107 | validation: 3.0366704941903397]
	TIME [epoch: 24.9 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.870928366133048		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 2.870928366133048 | validation: 3.0119519526789826]
	TIME [epoch: 24.8 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8278228638664724		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 2.8278228638664724 | validation: 3.0063791996993987]
	TIME [epoch: 24.8 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8276852419773184		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 2.8276852419773184 | validation: 2.991131941665465]
	TIME [epoch: 24.9 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8262694793577214		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 2.8262694793577214 | validation: 3.037509888100517]
	TIME [epoch: 24.9 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8325295269277517		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 2.8325295269277517 | validation: 3.0469148784025752]
	TIME [epoch: 24.8 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.84877203027458		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 2.84877203027458 | validation: 3.0026085057196656]
	TIME [epoch: 24.9 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8180781126647925		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 2.8180781126647925 | validation: 2.9999132737843777]
	TIME [epoch: 24.9 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.87729562503721		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 2.87729562503721 | validation: 3.0144694061717052]
	TIME [epoch: 24.9 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.828111665386888		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 2.828111665386888 | validation: 2.987170537064691]
	TIME [epoch: 24.9 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8200286650016535		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 2.8200286650016535 | validation: 2.987786603473321]
	TIME [epoch: 24.9 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8399439023308433		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 2.8399439023308433 | validation: 3.0658206760252127]
	TIME [epoch: 24.9 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8314998138051286		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 2.8314998138051286 | validation: 2.9859853646779584]
	TIME [epoch: 24.8 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8279978874021054		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 2.8279978874021054 | validation: 2.9914142769422813]
	TIME [epoch: 24.9 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8126194168996483		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 2.8126194168996483 | validation: 2.9917800236296617]
	TIME [epoch: 24.9 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.854494013648003		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 2.854494013648003 | validation: 2.9920666675643592]
	TIME [epoch: 24.8 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.821775855987474		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 2.821775855987474 | validation: 2.9986743170248618]
	TIME [epoch: 24.9 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.82556519886195		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 2.82556519886195 | validation: 3.0442488488160384]
	TIME [epoch: 24.9 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.843456795392748		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 2.843456795392748 | validation: 3.030605194590456]
	TIME [epoch: 24.9 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8602151233055992		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 2.8602151233055992 | validation: 3.05176644001235]
	TIME [epoch: 24.9 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8505622044189582		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 2.8505622044189582 | validation: 3.0541212968453952]
	TIME [epoch: 24.9 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8338877157846296		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 2.8338877157846296 | validation: 3.025494257985755]
	TIME [epoch: 24.9 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.841395240482764		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 2.841395240482764 | validation: 3.021959125877854]
	TIME [epoch: 24.9 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8209876575925956		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 2.8209876575925956 | validation: 2.982189615375534]
	TIME [epoch: 24.8 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8327423469212984		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 2.8327423469212984 | validation: 2.991337075815816]
	TIME [epoch: 24.9 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8180891621233597		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 2.8180891621233597 | validation: 2.9849311359742705]
	TIME [epoch: 24.9 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.820118107164525		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 2.820118107164525 | validation: 2.9978411704484134]
	TIME [epoch: 24.9 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.827055296456871		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 2.827055296456871 | validation: 3.0756630074101885]
	TIME [epoch: 24.9 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8976866448353276		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 2.8976866448353276 | validation: 2.995766195273877]
	TIME [epoch: 24.9 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.822917687010483		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 2.822917687010483 | validation: 3.0762390444160657]
	TIME [epoch: 24.9 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.869188712524691		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 2.869188712524691 | validation: 3.044367179164293]
	TIME [epoch: 24.9 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8695463265296395		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 2.8695463265296395 | validation: 3.0147444203108877]
	TIME [epoch: 24.9 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8360979481734434		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 2.8360979481734434 | validation: 2.986799812302863]
	TIME [epoch: 24.9 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.827067167312004		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 2.827067167312004 | validation: 3.045523401831906]
	TIME [epoch: 24.9 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8496444943856636		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 2.8496444943856636 | validation: 2.9920299981938583]
	TIME [epoch: 24.9 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8258920760460007		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 2.8258920760460007 | validation: 3.065918817583381]
	TIME [epoch: 24.9 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8439718883388188		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 2.8439718883388188 | validation: 3.0519788771659933]
	TIME [epoch: 24.9 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.865111379017084		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 2.865111379017084 | validation: 3.052090156867365]
	TIME [epoch: 24.9 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8360606947370846		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 2.8360606947370846 | validation: 2.9945162836010684]
	TIME [epoch: 24.8 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8417952560244597		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 2.8417952560244597 | validation: 2.988152314387181]
	TIME [epoch: 24.9 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8405275151056424		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 2.8405275151056424 | validation: 3.05057781137089]
	TIME [epoch: 24.9 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8434272635806517		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 2.8434272635806517 | validation: 2.986787022869722]
	TIME [epoch: 24.9 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8360027921097477		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 2.8360027921097477 | validation: 2.973547868229149]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_831.pth
	Model improved!!!
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8176885568555887		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 2.8176885568555887 | validation: 2.9811421184100966]
	TIME [epoch: 24.9 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.810020324924696		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 2.810020324924696 | validation: 3.013223027962322]
	TIME [epoch: 24.9 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8192447536122955		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 2.8192447536122955 | validation: 2.998861446662919]
	TIME [epoch: 24.8 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8288067704793844		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 2.8288067704793844 | validation: 3.018283650054101]
	TIME [epoch: 24.9 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.816726970528854		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 2.816726970528854 | validation: 3.0241104285831213]
	TIME [epoch: 24.9 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8240418631886897		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 2.8240418631886897 | validation: 2.9956376927581756]
	TIME [epoch: 24.9 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8497036827965565		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 2.8497036827965565 | validation: 2.987789012372764]
	TIME [epoch: 24.8 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.818609267009117		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 2.818609267009117 | validation: 2.9995706412427556]
	TIME [epoch: 24.9 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8477587846675423		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 2.8477587846675423 | validation: 3.061884864709158]
	TIME [epoch: 24.9 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8315301807393536		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 2.8315301807393536 | validation: 2.9856953145080873]
	TIME [epoch: 24.8 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.842495273094128		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 2.842495273094128 | validation: 3.019476844857617]
	TIME [epoch: 24.9 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8316372504007035		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 2.8316372504007035 | validation: 3.0461850698289745]
	TIME [epoch: 24.9 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9001164243425963		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 2.9001164243425963 | validation: 2.9878813823943973]
	TIME [epoch: 24.9 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.826728163690129		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 2.826728163690129 | validation: 2.988696809608679]
	TIME [epoch: 24.9 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8100342820214648		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 2.8100342820214648 | validation: 2.9882326399101475]
	TIME [epoch: 24.9 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.812500972961137		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 2.812500972961137 | validation: 3.004089885051095]
	TIME [epoch: 24.9 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8212787380751125		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 2.8212787380751125 | validation: 2.9840475669101614]
	TIME [epoch: 24.9 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.823524826706593		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 2.823524826706593 | validation: 3.050432437523643]
	TIME [epoch: 24.9 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.825048746051058		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 2.825048746051058 | validation: 2.9838286453158465]
	TIME [epoch: 24.9 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.823407092682463		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 2.823407092682463 | validation: 2.981236465601287]
	TIME [epoch: 24.9 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.816289138910489		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 2.816289138910489 | validation: 2.988766137396027]
	TIME [epoch: 24.9 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.821377099061435		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 2.821377099061435 | validation: 2.9811398614331597]
	TIME [epoch: 24.9 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.811305166076339		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 2.811305166076339 | validation: 2.9813637490803795]
	TIME [epoch: 24.9 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8187508593888646		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 2.8187508593888646 | validation: 2.9860490979531824]
	TIME [epoch: 24.9 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.838016147894331		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 2.838016147894331 | validation: 2.9877938463672957]
	TIME [epoch: 24.9 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8142338199385795		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 2.8142338199385795 | validation: 3.0450341785338093]
	TIME [epoch: 24.9 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.82897712269825		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 2.82897712269825 | validation: 3.0004957024214964]
	TIME [epoch: 24.9 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.816946557116361		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 2.816946557116361 | validation: 2.994633408963117]
	TIME [epoch: 24.9 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.812917216913736		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 2.812917216913736 | validation: 2.98712502040494]
	TIME [epoch: 24.9 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8138351878120607		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 2.8138351878120607 | validation: 2.9994620555020584]
	TIME [epoch: 24.9 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.820142441478172		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 2.820142441478172 | validation: 3.0007541509102187]
	TIME [epoch: 24.9 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8306532079049163		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 2.8306532079049163 | validation: 2.983565110190018]
	TIME [epoch: 24.9 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.822657390624271		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 2.822657390624271 | validation: 3.0345342521010776]
	TIME [epoch: 24.9 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9116260549567867		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 2.9116260549567867 | validation: 2.9902244716530113]
	TIME [epoch: 24.9 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.824528320658552		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 2.824528320658552 | validation: 3.0109417125162112]
	TIME [epoch: 24.9 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.834396703267169		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 2.834396703267169 | validation: 2.974841704820631]
	TIME [epoch: 24.9 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8144293932184987		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 2.8144293932184987 | validation: 2.988194405593098]
	TIME [epoch: 24.9 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8144229479439202		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 2.8144229479439202 | validation: 2.9939385002977343]
	TIME [epoch: 24.9 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.830441331498793		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 2.830441331498793 | validation: 3.0399444204099026]
	TIME [epoch: 24.9 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8306308872196326		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 2.8306308872196326 | validation: 2.9846036503798006]
	TIME [epoch: 24.9 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.82144117076109		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 2.82144117076109 | validation: 3.028187292344884]
	TIME [epoch: 24.9 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.83232878158584		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 2.83232878158584 | validation: 2.9817394578636014]
	TIME [epoch: 24.9 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8212913283035808		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 2.8212913283035808 | validation: 2.987473595453845]
	TIME [epoch: 24.9 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.813091841239021		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 2.813091841239021 | validation: 2.994978244753287]
	TIME [epoch: 24.9 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.830928261604018		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 2.830928261604018 | validation: 2.983651120184687]
	TIME [epoch: 24.9 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.832660510747821		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 2.832660510747821 | validation: 3.034005867890304]
	TIME [epoch: 24.9 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8322940687835265		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 2.8322940687835265 | validation: 3.006588751480705]
	TIME [epoch: 24.9 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.831872254996277		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 2.831872254996277 | validation: 3.019919383130903]
	TIME [epoch: 24.9 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8615312431417914		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 2.8615312431417914 | validation: 3.0076849229071376]
	TIME [epoch: 24.9 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8279853746025942		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 2.8279853746025942 | validation: 2.9875228681185892]
	TIME [epoch: 24.8 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8369999393894667		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 2.8369999393894667 | validation: 2.9867395387655122]
	TIME [epoch: 24.9 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.817054693046873		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 2.817054693046873 | validation: 3.0195898311149945]
	TIME [epoch: 24.9 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8756311271801556		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 2.8756311271801556 | validation: 3.0011915262320374]
	TIME [epoch: 24.9 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8716383790910474		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 2.8716383790910474 | validation: 3.113730343556475]
	TIME [epoch: 24.9 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.862030364076851		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 2.862030364076851 | validation: 2.990532857678071]
	TIME [epoch: 24.9 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.817025229848348		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 2.817025229848348 | validation: 2.9839861711509856]
	TIME [epoch: 24.9 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8204332794528435		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 2.8204332794528435 | validation: 2.9738556534743124]
	TIME [epoch: 24.9 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8104314758930435		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 2.8104314758930435 | validation: 2.972466865775479]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_889.pth
	Model improved!!!
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8098248378124455		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 2.8098248378124455 | validation: 2.9986766698983773]
	TIME [epoch: 24.9 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8280335858120913		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 2.8280335858120913 | validation: 3.0044493816355913]
	TIME [epoch: 24.9 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.819054856967996		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 2.819054856967996 | validation: 3.0144745202351197]
	TIME [epoch: 24.9 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.876784839237829		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 2.876784839237829 | validation: 3.004741313242557]
	TIME [epoch: 24.9 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8168312657798555		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 2.8168312657798555 | validation: 2.9762065641912923]
	TIME [epoch: 24.9 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8130078278454307		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 2.8130078278454307 | validation: 2.982815971449331]
	TIME [epoch: 24.9 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8238123698873325		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 2.8238123698873325 | validation: 3.047333911799442]
	TIME [epoch: 24.9 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8430963811115078		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 2.8430963811115078 | validation: 2.99254871783838]
	TIME [epoch: 24.9 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.816455446471412		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 2.816455446471412 | validation: 2.988717419006922]
	TIME [epoch: 24.9 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8179855037780253		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 2.8179855037780253 | validation: 3.0644681121801938]
	TIME [epoch: 24.9 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8410889193370776		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 2.8410889193370776 | validation: 2.9802613176590316]
	TIME [epoch: 24.9 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8182960901387846		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 2.8182960901387846 | validation: 2.9787181907803433]
	TIME [epoch: 24.9 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.806046511463471		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 2.806046511463471 | validation: 2.9807512031344436]
	TIME [epoch: 24.9 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8136803169682887		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 2.8136803169682887 | validation: 2.9896695394746753]
	TIME [epoch: 24.8 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8086452487789635		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 2.8086452487789635 | validation: 2.9955623717296023]
	TIME [epoch: 24.9 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8272397361559514		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 2.8272397361559514 | validation: 2.979099937083547]
	TIME [epoch: 24.9 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.849065216246202		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 2.849065216246202 | validation: 2.9947648429092717]
	TIME [epoch: 24.9 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8249419647691356		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 2.8249419647691356 | validation: 2.994291322265009]
	TIME [epoch: 24.9 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.82232472601334		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 2.82232472601334 | validation: 2.9794039906751664]
	TIME [epoch: 24.9 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.838695185268329		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 2.838695185268329 | validation: 2.975497250853448]
	TIME [epoch: 24.9 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8224013501324414		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 2.8224013501324414 | validation: 2.9830835549254595]
	TIME [epoch: 24.9 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.834588588822121		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 2.834588588822121 | validation: 3.0487659354986847]
	TIME [epoch: 24.9 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8201513711572597		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 2.8201513711572597 | validation: 2.9746282799803603]
	TIME [epoch: 24.9 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8085661596620968		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 2.8085661596620968 | validation: 2.987542515155186]
	TIME [epoch: 24.9 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8345785149948526		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 2.8345785149948526 | validation: 3.0243329089775193]
	TIME [epoch: 24.9 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8259648691264285		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 2.8259648691264285 | validation: 2.9715320639533367]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_915.pth
	Model improved!!!
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.808427373095571		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 2.808427373095571 | validation: 3.0156065442785485]
	TIME [epoch: 24.9 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8191332605396497		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 2.8191332605396497 | validation: 3.046715219054658]
	TIME [epoch: 24.9 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8426787776407934		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 2.8426787776407934 | validation: 2.986582903405381]
	TIME [epoch: 24.9 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8252990471909984		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 2.8252990471909984 | validation: 2.980590327971445]
	TIME [epoch: 24.9 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8158067304078522		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 2.8158067304078522 | validation: 3.0096908061431713]
	TIME [epoch: 24.9 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.830502126356926		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 2.830502126356926 | validation: 2.9908921314530597]
	TIME [epoch: 24.9 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.809203019157847		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 2.809203019157847 | validation: 2.973918030156434]
	TIME [epoch: 24.9 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.815220960548924		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 2.815220960548924 | validation: 2.985270123048749]
	TIME [epoch: 24.9 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.820165413932177		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 2.820165413932177 | validation: 2.9885851040570173]
	TIME [epoch: 24.8 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.817009872509768		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 2.817009872509768 | validation: 2.986730784769909]
	TIME [epoch: 24.9 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.811257926073674		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 2.811257926073674 | validation: 2.9819343431696463]
	TIME [epoch: 24.9 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.80844695091716		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 2.80844695091716 | validation: 2.9765192629322086]
	TIME [epoch: 24.9 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.832730131808642		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 2.832730131808642 | validation: 2.9910916959365457]
	TIME [epoch: 24.9 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8433176736020025		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 2.8433176736020025 | validation: 2.9738922238467156]
	TIME [epoch: 24.9 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.80326476787788		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 2.80326476787788 | validation: 2.984255169824262]
	TIME [epoch: 24.9 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.809305831737721		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 2.809305831737721 | validation: 2.990797332705061]
	TIME [epoch: 24.8 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.809788756032951		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 2.809788756032951 | validation: 2.972344823195104]
	TIME [epoch: 24.9 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.813897627569501		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 2.813897627569501 | validation: 2.981048588096909]
	TIME [epoch: 24.9 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8201666776145164		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 2.8201666776145164 | validation: 2.999741348599787]
	TIME [epoch: 24.9 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8500424234912867		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 2.8500424234912867 | validation: 2.9965887966249567]
	TIME [epoch: 24.9 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8122193805633753		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 2.8122193805633753 | validation: 2.9775057209927303]
	TIME [epoch: 24.9 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8045924130360236		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 2.8045924130360236 | validation: 2.980438223012318]
	TIME [epoch: 24.9 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8153715521597156		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 2.8153715521597156 | validation: 2.974991159387313]
	TIME [epoch: 24.9 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.822483418742248		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 2.822483418742248 | validation: 2.9902436519373463]
	TIME [epoch: 24.9 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8179784362368623		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 2.8179784362368623 | validation: 2.9866426487428255]
	TIME [epoch: 24.9 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8175273994418037		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 2.8175273994418037 | validation: 3.004477899408258]
	TIME [epoch: 24.9 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8117310504880315		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 2.8117310504880315 | validation: 2.9802774535578016]
	TIME [epoch: 24.9 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8131055050953644		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 2.8131055050953644 | validation: 2.998746859282757]
	TIME [epoch: 24.9 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8192330556693266		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 2.8192330556693266 | validation: 3.0080635720492377]
	TIME [epoch: 24.9 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8170285353350337		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 2.8170285353350337 | validation: 2.998962995411759]
	TIME [epoch: 24.9 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8174989171408216		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 2.8174989171408216 | validation: 3.003467898385738]
	TIME [epoch: 24.9 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8166474159808628		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 2.8166474159808628 | validation: 2.975122649064488]
	TIME [epoch: 24.9 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.806602991020186		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 2.806602991020186 | validation: 2.984702340127601]
	TIME [epoch: 24.8 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.799226317295335		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 2.799226317295335 | validation: 2.974234407503212]
	TIME [epoch: 24.9 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8129018447203267		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 2.8129018447203267 | validation: 3.0031555452206007]
	TIME [epoch: 24.8 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8245098167221236		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 2.8245098167221236 | validation: 3.0439844880508424]
	TIME [epoch: 24.9 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.831148611931396		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 2.831148611931396 | validation: 2.9714241576105156]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_952.pth
	Model improved!!!
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.821823083822837		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 2.821823083822837 | validation: 2.9911770038244208]
	TIME [epoch: 24.9 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.813168814500853		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 2.813168814500853 | validation: 2.999917531778725]
	TIME [epoch: 24.9 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8167642661217034		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 2.8167642661217034 | validation: 2.9738379279761795]
	TIME [epoch: 24.9 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.808118119704711		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 2.808118119704711 | validation: 2.966239915953575]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_956.pth
	Model improved!!!
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8024599378255846		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 2.8024599378255846 | validation: 2.9942358007433847]
	TIME [epoch: 24.9 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8144139789451725		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 2.8144139789451725 | validation: 2.9788394612777496]
	TIME [epoch: 24.9 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7992368922855326		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 2.7992368922855326 | validation: 2.9816059128299925]
	TIME [epoch: 24.9 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8150491291427198		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 2.8150491291427198 | validation: 2.991259365006705]
	TIME [epoch: 24.9 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.810585243301257		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 2.810585243301257 | validation: 3.017650698876295]
	TIME [epoch: 24.8 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8188613338231736		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 2.8188613338231736 | validation: 2.9658821058548894]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_962.pth
	Model improved!!!
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.805982060760808		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 2.805982060760808 | validation: 2.990287261234769]
	TIME [epoch: 24.9 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.844460672894332		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 2.844460672894332 | validation: 2.985737965583402]
	TIME [epoch: 24.9 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8262411006667647		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 2.8262411006667647 | validation: 2.975710487449305]
	TIME [epoch: 24.9 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8265171097804584		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 2.8265171097804584 | validation: 2.9803570200873093]
	TIME [epoch: 24.9 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.815997485165534		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 2.815997485165534 | validation: 2.9656561238607693]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_967.pth
	Model improved!!!
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8143975044198264		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 2.8143975044198264 | validation: 2.977419444982954]
	TIME [epoch: 24.9 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8073579958878376		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 2.8073579958878376 | validation: 3.0097534315743695]
	TIME [epoch: 24.9 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.818501673579003		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 2.818501673579003 | validation: 2.9938864897512985]
	TIME [epoch: 24.9 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8199427467558214		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 2.8199427467558214 | validation: 2.9931156085026327]
	TIME [epoch: 24.9 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.80707528329743		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 2.80707528329743 | validation: 2.9767629217587515]
	TIME [epoch: 24.9 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8194888175399284		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 2.8194888175399284 | validation: 2.9950667680916885]
	TIME [epoch: 24.9 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.812571430804274		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 2.812571430804274 | validation: 2.9725028670361144]
	TIME [epoch: 24.9 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.818747533518243		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 2.818747533518243 | validation: 3.033182888636184]
	TIME [epoch: 24.9 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.820552393910481		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 2.820552393910481 | validation: 3.002011073431229]
	TIME [epoch: 24.9 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8322208351250757		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 2.8322208351250757 | validation: 2.967288033994759]
	TIME [epoch: 24.9 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8067253491645507		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 2.8067253491645507 | validation: 2.9810110411907282]
	TIME [epoch: 24.9 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.812080984324284		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 2.812080984324284 | validation: 2.984638088335462]
	TIME [epoch: 24.9 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.810024789883854		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 2.810024789883854 | validation: 2.971048790973928]
	TIME [epoch: 24.9 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8178379123934505		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 2.8178379123934505 | validation: 2.9712605101640577]
	TIME [epoch: 24.9 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8268982317814957		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 2.8268982317814957 | validation: 2.9863505107086588]
	TIME [epoch: 24.9 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8059547220618493		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 2.8059547220618493 | validation: 3.00574956306713]
	TIME [epoch: 24.8 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.811418185422755		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 2.811418185422755 | validation: 2.976621276928767]
	TIME [epoch: 24.9 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.80468377081959		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 2.80468377081959 | validation: 2.964813840240655]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_985.pth
	Model improved!!!
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8004217459520695		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 2.8004217459520695 | validation: 2.9731729107250042]
	TIME [epoch: 24.9 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.802077499881177		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 2.802077499881177 | validation: 3.010567293409051]
	TIME [epoch: 24.9 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.82572257344582		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 2.82572257344582 | validation: 3.034177200825151]
	TIME [epoch: 24.9 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8274162337121815		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 2.8274162337121815 | validation: 2.964353348173662]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_989.pth
	Model improved!!!
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7997552506682197		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 2.7997552506682197 | validation: 2.978069915344871]
	TIME [epoch: 24.9 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8041276072837684		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 2.8041276072837684 | validation: 2.974891564903331]
	TIME [epoch: 24.9 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8074886125532377		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 2.8074886125532377 | validation: 2.9691248795764613]
	TIME [epoch: 24.9 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.818010594676493		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 2.818010594676493 | validation: 2.9799399461372014]
	TIME [epoch: 24.9 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.801198646013055		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 2.801198646013055 | validation: 2.978414470828783]
	TIME [epoch: 24.9 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.806966867144244		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 2.806966867144244 | validation: 2.9901778864289237]
	TIME [epoch: 24.9 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8211321188814873		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 2.8211321188814873 | validation: 2.9753337566109046]
	TIME [epoch: 24.9 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.815159377236202		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 2.815159377236202 | validation: 2.9902791745087143]
	TIME [epoch: 24.9 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7958489908291417		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 2.7958489908291417 | validation: 2.966880359309554]
	TIME [epoch: 24.9 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.806699069788249		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 2.806699069788249 | validation: 2.978599727632534]
	TIME [epoch: 24.9 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.80374647070933		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 2.80374647070933 | validation: 2.974986285188892]
	TIME [epoch: 24.9 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8060077673656516		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 2.8060077673656516 | validation: 2.9730064840708263]
	TIME [epoch: 24.9 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8066968554053036		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 2.8066968554053036 | validation: 3.0045643904411383]
	TIME [epoch: 24.9 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8194265486915246		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 2.8194265486915246 | validation: 2.9827489567626815]
	TIME [epoch: 24.9 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8000279010626903		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 2.8000279010626903 | validation: 2.9688844496913407]
	TIME [epoch: 24.9 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8037456961954006		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 2.8037456961954006 | validation: 2.9872678983708716]
	TIME [epoch: 24.9 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8027070592500434		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 2.8027070592500434 | validation: 2.977582567738236]
	TIME [epoch: 24.9 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.799050676239055		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 2.799050676239055 | validation: 2.9791056713498656]
	TIME [epoch: 24.9 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.805219119289854		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 2.805219119289854 | validation: 2.9874850712321654]
	TIME [epoch: 24.9 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.824969817267613		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 2.824969817267613 | validation: 2.974365316945382]
	TIME [epoch: 24.9 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8068797454648857		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 2.8068797454648857 | validation: 3.0182435913800054]
	TIME [epoch: 24.9 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8175044553305915		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 2.8175044553305915 | validation: 2.9775634599070453]
	TIME [epoch: 24.9 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8011942530420493		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 2.8011942530420493 | validation: 2.9753263079698598]
	TIME [epoch: 24.9 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8018022271117142		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 2.8018022271117142 | validation: 2.969645891287728]
	TIME [epoch: 25 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.799956120855019		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 2.799956120855019 | validation: 2.9898614114756037]
	TIME [epoch: 24.9 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8186063225788116		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 2.8186063225788116 | validation: 2.9835331164404306]
	TIME [epoch: 24.9 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.825810274210963		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 2.825810274210963 | validation: 3.011454317319023]
	TIME [epoch: 24.9 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.825438644008579		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 2.825438644008579 | validation: 3.027138113753781]
	TIME [epoch: 25 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.832885620927617		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 2.832885620927617 | validation: 2.9938264166735498]
	TIME [epoch: 24.9 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.805155700770557		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 2.805155700770557 | validation: 2.981009631053741]
	TIME [epoch: 24.9 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8051522959131665		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 2.8051522959131665 | validation: 2.993382694909954]
	TIME [epoch: 24.9 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.814977197436241		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 2.814977197436241 | validation: 2.9868653481141223]
	TIME [epoch: 24.9 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.799783656761118		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 2.799783656761118 | validation: 2.984124419820462]
	TIME [epoch: 24.9 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8107201587779715		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 2.8107201587779715 | validation: 2.9848682313862422]
	TIME [epoch: 24.9 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8075995295404903		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 2.8075995295404903 | validation: 3.041625255976031]
	TIME [epoch: 24.9 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.861230891076388		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 2.861230891076388 | validation: 2.9770799621087014]
	TIME [epoch: 25 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8010798616533163		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 2.8010798616533163 | validation: 2.9718171715014545]
	TIME [epoch: 24.9 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8022574116954426		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 2.8022574116954426 | validation: 2.985663978317334]
	TIME [epoch: 24.9 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.802305556896318		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 2.802305556896318 | validation: 2.980999435055901]
	TIME [epoch: 24.9 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8087640795303654		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 2.8087640795303654 | validation: 2.972283895552546]
	TIME [epoch: 24.9 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.806275987381265		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 2.806275987381265 | validation: 2.973157005406969]
	TIME [epoch: 24.9 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.804691743854592		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 2.804691743854592 | validation: 2.9714644596476583]
	TIME [epoch: 24.9 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8049016720555233		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 2.8049016720555233 | validation: 2.9886009088014065]
	TIME [epoch: 25 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8246129050149853		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 2.8246129050149853 | validation: 3.0166169218497227]
	TIME [epoch: 24.9 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8130843679200668		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 2.8130843679200668 | validation: 2.9804323454825368]
	TIME [epoch: 24.9 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8075463045618503		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 2.8075463045618503 | validation: 2.975685022433527]
	TIME [epoch: 25 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.803881043261393		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 2.803881043261393 | validation: 2.975867974200985]
	TIME [epoch: 25 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8001842389052545		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 2.8001842389052545 | validation: 2.9699654803865334]
	TIME [epoch: 24.9 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8145118776883957		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 2.8145118776883957 | validation: 2.9875004711637865]
	TIME [epoch: 24.9 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.807430346117727		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 2.807430346117727 | validation: 3.0167386685849737]
	TIME [epoch: 24.9 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8175027798811128		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 2.8175027798811128 | validation: 2.9836531536488082]
	TIME [epoch: 25 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7994858238465614		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 2.7994858238465614 | validation: 2.98439395949849]
	TIME [epoch: 24.9 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.805518112835256		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 2.805518112835256 | validation: 2.9735279535198744]
	TIME [epoch: 24.9 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8005351808235175		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 2.8005351808235175 | validation: 2.982338038348317]
	TIME [epoch: 25 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.803312772050971		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 2.803312772050971 | validation: 2.96404867832728]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_1044.pth
	Model improved!!!
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8056485890226965		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 2.8056485890226965 | validation: 2.981256944374126]
	TIME [epoch: 24.9 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.808085106232762		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 2.808085106232762 | validation: 2.988958409944871]
	TIME [epoch: 24.9 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8080437792835315		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 2.8080437792835315 | validation: 2.977140417097566]
	TIME [epoch: 24.9 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7988081528369095		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 2.7988081528369095 | validation: 2.967989426717277]
	TIME [epoch: 24.9 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8039149008077873		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 2.8039149008077873 | validation: 2.9796614126942838]
	TIME [epoch: 24.9 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8003784539878636		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 2.8003784539878636 | validation: 2.974966474835777]
	TIME [epoch: 24.9 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8012317410794756		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 2.8012317410794756 | validation: 2.977338263103478]
	TIME [epoch: 24.9 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8027508087895443		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 2.8027508087895443 | validation: 2.975582644485086]
	TIME [epoch: 24.9 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.805840831480253		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 2.805840831480253 | validation: 2.9774403809834054]
	TIME [epoch: 24.9 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.810955604078889		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 2.810955604078889 | validation: 2.9727832073152034]
	TIME [epoch: 24.9 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.803572619295902		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 2.803572619295902 | validation: 2.9968841631699012]
	TIME [epoch: 24.9 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.816008782611339		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 2.816008782611339 | validation: 2.997954293928517]
	TIME [epoch: 24.9 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8099988086159726		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 2.8099988086159726 | validation: 2.964149759002695]
	TIME [epoch: 24.9 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7999683895465957		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 2.7999683895465957 | validation: 2.977162754000937]
	TIME [epoch: 24.9 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8153868382820564		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 2.8153868382820564 | validation: 2.977529586948583]
	TIME [epoch: 24.9 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.806665475543387		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 2.806665475543387 | validation: 2.9910675048352715]
	TIME [epoch: 24.9 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.803926760392634		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 2.803926760392634 | validation: 2.975412951253119]
	TIME [epoch: 24.8 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8104383007162594		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 2.8104383007162594 | validation: 2.9896014379918645]
	TIME [epoch: 24.9 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.804511698771911		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 2.804511698771911 | validation: 2.997448953779305]
	TIME [epoch: 24.9 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.811776237032423		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 2.811776237032423 | validation: 3.0044486444860956]
	TIME [epoch: 24.9 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8079073308149143		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 2.8079073308149143 | validation: 2.9724122689101105]
	TIME [epoch: 24.8 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7969002560055967		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 2.7969002560055967 | validation: 2.9771853236776273]
	TIME [epoch: 24.9 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8026426162822604		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 2.8026426162822604 | validation: 2.9693546452317134]
	TIME [epoch: 24.9 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8051037607718285		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 2.8051037607718285 | validation: 2.966010853523871]
	TIME [epoch: 24.9 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7944514618572516		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 2.7944514618572516 | validation: 2.9716462139307613]
	TIME [epoch: 24.9 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7956003541246477		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 2.7956003541246477 | validation: 2.9821970446679713]
	TIME [epoch: 24.8 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8045226487737613		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 2.8045226487737613 | validation: 2.982417286616013]
	TIME [epoch: 24.9 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7983163314890227		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 2.7983163314890227 | validation: 2.995698617924054]
	TIME [epoch: 24.9 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8109207867741723		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 2.8109207867741723 | validation: 2.9884018471872626]
	TIME [epoch: 24.9 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.80333556110193		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 2.80333556110193 | validation: 2.973369994056787]
	TIME [epoch: 24.9 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.802382794850276		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 2.802382794850276 | validation: 2.9822638247578097]
	TIME [epoch: 24.9 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8012742042646464		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 2.8012742042646464 | validation: 2.9719252360536763]
	TIME [epoch: 24.9 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.802004933344764		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 2.802004933344764 | validation: 2.9733430273760946]
	TIME [epoch: 24.9 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8268868483229803		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 2.8268868483229803 | validation: 2.9821349662481578]
	TIME [epoch: 24.9 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7988969216020143		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 2.7988969216020143 | validation: 2.9724539262221983]
	TIME [epoch: 24.9 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7968726708758096		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 2.7968726708758096 | validation: 2.966690354914104]
	TIME [epoch: 24.9 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.800254319015731		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 2.800254319015731 | validation: 2.9713218931623913]
	TIME [epoch: 24.8 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8140393823140504		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 2.8140393823140504 | validation: 2.9758739162918566]
	TIME [epoch: 24.9 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8176614751559304		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 2.8176614751559304 | validation: 2.97291679172257]
	TIME [epoch: 24.9 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8311397133019676		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 2.8311397133019676 | validation: 3.0121742540736527]
	TIME [epoch: 24.9 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8122236819436957		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 2.8122236819436957 | validation: 2.9644860272662856]
	TIME [epoch: 24.8 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8017140856743126		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 2.8017140856743126 | validation: 2.9785370350875633]
	TIME [epoch: 24.9 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.814155069249984		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 2.814155069249984 | validation: 2.9759262076554376]
	TIME [epoch: 24.9 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8047509321950064		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 2.8047509321950064 | validation: 2.9811074489862857]
	TIME [epoch: 24.8 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.818645220656089		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 2.818645220656089 | validation: 2.969337815808751]
	TIME [epoch: 24.9 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.802336993671533		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 2.802336993671533 | validation: 2.9701608967165045]
	TIME [epoch: 24.9 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8011024228453945		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 2.8011024228453945 | validation: 2.9659957288124588]
	TIME [epoch: 24.9 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.803683367918862		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 2.803683367918862 | validation: 2.9693564096567093]
	TIME [epoch: 24.9 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8099093554682337		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 2.8099093554682337 | validation: 2.9801098259660557]
	TIME [epoch: 24.9 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8019630428333633		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 2.8019630428333633 | validation: 2.976157985884262]
	TIME [epoch: 24.9 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7947686615245098		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 2.7947686615245098 | validation: 2.9828302524936197]
	TIME [epoch: 24.9 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7971468144338303		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 2.7971468144338303 | validation: 2.9722455175062623]
	TIME [epoch: 24.9 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.797066947031753		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 2.797066947031753 | validation: 2.9673726248377092]
	TIME [epoch: 24.9 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.801104559201465		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 2.801104559201465 | validation: 2.961428852998257]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_1098.pth
	Model improved!!!
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7986100055883		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 2.7986100055883 | validation: 2.968871624389072]
	TIME [epoch: 24.8 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7939897719747493		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 2.7939897719747493 | validation: 2.9734253549663445]
	TIME [epoch: 24.9 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8333940398709974		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 2.8333940398709974 | validation: 2.9916249966668285]
	TIME [epoch: 24.9 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8088480066880965		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 2.8088480066880965 | validation: 2.9669303045471405]
	TIME [epoch: 24.8 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8033419202381094		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 2.8033419202381094 | validation: 2.9720378768328306]
	TIME [epoch: 24.8 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.80487017646608		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 2.80487017646608 | validation: 2.9977397525994047]
	TIME [epoch: 24.9 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8085424133797168		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 2.8085424133797168 | validation: 2.984165698888235]
	TIME [epoch: 24.9 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8228001517726073		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 2.8228001517726073 | validation: 3.0019797843046163]
	TIME [epoch: 24.9 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.802275160142572		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 2.802275160142572 | validation: 2.9728130071822343]
	TIME [epoch: 24.9 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8223263459825043		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 2.8223263459825043 | validation: 2.962942913729212]
	TIME [epoch: 24.9 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.799277938779336		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 2.799277938779336 | validation: 2.968624858867885]
	TIME [epoch: 24.8 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7983163688681523		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 2.7983163688681523 | validation: 2.980824152816765]
	TIME [epoch: 24.9 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.797176009950139		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 2.797176009950139 | validation: 2.969691487784601]
	TIME [epoch: 24.9 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8076666047796848		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 2.8076666047796848 | validation: 2.968341822939442]
	TIME [epoch: 24.9 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7968834698994574		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 2.7968834698994574 | validation: 2.9756601077533067]
	TIME [epoch: 24.9 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.804317171002289		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 2.804317171002289 | validation: 2.9839347211915506]
	TIME [epoch: 24.9 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8082016439809427		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 2.8082016439809427 | validation: 2.97633057761404]
	TIME [epoch: 24.9 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.802234023609726		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 2.802234023609726 | validation: 2.973143086891331]
	TIME [epoch: 24.9 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7946721759156166		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 2.7946721759156166 | validation: 2.9719483683502053]
	TIME [epoch: 24.9 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8046092225049786		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 2.8046092225049786 | validation: 2.9827745906667906]
	TIME [epoch: 24.9 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.801136844659426		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 2.801136844659426 | validation: 2.968947272460704]
	TIME [epoch: 24.9 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.819404959605757		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 2.819404959605757 | validation: 2.999908967308919]
	TIME [epoch: 24.9 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.805360039855036		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 2.805360039855036 | validation: 2.9794793306505]
	TIME [epoch: 24.9 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8023988998276974		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 2.8023988998276974 | validation: 2.967117193611623]
	TIME [epoch: 24.9 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.796391797928302		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 2.796391797928302 | validation: 2.963839234483272]
	TIME [epoch: 24.9 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.793749492760498		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 2.793749492760498 | validation: 2.975434265240593]
	TIME [epoch: 24.9 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.79587000717933		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 2.79587000717933 | validation: 2.9731791715963585]
	TIME [epoch: 24.9 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8006637565528445		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 2.8006637565528445 | validation: 3.0040162085285367]
	TIME [epoch: 24.9 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8326078959708676		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 2.8326078959708676 | validation: 3.07152936237561]
	TIME [epoch: 24.9 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.853385367763357		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 2.853385367763357 | validation: 2.9818144474213066]
	TIME [epoch: 24.9 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8109449297352986		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 2.8109449297352986 | validation: 2.9928022291754495]
	TIME [epoch: 24.9 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.801417191542139		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 2.801417191542139 | validation: 2.9808630538180667]
	TIME [epoch: 24.9 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8040213288567353		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 2.8040213288567353 | validation: 2.9700745048825277]
	TIME [epoch: 24.9 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8006789547243454		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 2.8006789547243454 | validation: 2.9711567347597225]
	TIME [epoch: 24.9 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8017872803908177		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 2.8017872803908177 | validation: 2.96716571666977]
	TIME [epoch: 24.9 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7933252134878637		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 2.7933252134878637 | validation: 2.966983559541078]
	TIME [epoch: 24.9 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7978388714661464		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 2.7978388714661464 | validation: 2.962943421489158]
	TIME [epoch: 24.9 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.798512176202653		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 2.798512176202653 | validation: 2.9705881883603356]
	TIME [epoch: 24.9 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8008519337121793		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 2.8008519337121793 | validation: 2.994840645783896]
	TIME [epoch: 24.9 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8144281174183026		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 2.8144281174183026 | validation: 2.993484699567544]
	TIME [epoch: 24.9 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.804217348754193		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 2.804217348754193 | validation: 2.9817262979739163]
	TIME [epoch: 24.8 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.803597362897035		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 2.803597362897035 | validation: 2.9622088839643745]
	TIME [epoch: 24.9 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7922439167776476		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 2.7922439167776476 | validation: 2.9637481373137344]
	TIME [epoch: 24.8 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.795488852842403		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 2.795488852842403 | validation: 2.9803728672312637]
	TIME [epoch: 24.8 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8051439628020787		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 2.8051439628020787 | validation: 2.963307609338954]
	TIME [epoch: 24.8 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7935624383443134		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 2.7935624383443134 | validation: 2.9649482851651827]
	TIME [epoch: 24.9 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7924264465381636		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 2.7924264465381636 | validation: 2.9777233341262286]
	TIME [epoch: 24.9 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8072365632530354		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 2.8072365632530354 | validation: 2.9723713696149003]
	TIME [epoch: 24.9 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7963467293595596		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 2.7963467293595596 | validation: 2.9649188464066185]
	TIME [epoch: 24.9 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.79489392781948		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 2.79489392781948 | validation: 2.9624292637379153]
	TIME [epoch: 24.9 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8001957797477424		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 2.8001957797477424 | validation: 2.979215049474272]
	TIME [epoch: 24.8 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7979122008270663		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 2.7979122008270663 | validation: 2.9596944952541695]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_1150.pth
	Model improved!!!
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.813702482457992		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 2.813702482457992 | validation: 2.9792291083880857]
	TIME [epoch: 24.9 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8042039665464085		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 2.8042039665464085 | validation: 2.991612126399941]
	TIME [epoch: 24.9 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8022579832488606		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 2.8022579832488606 | validation: 2.9704386852708264]
	TIME [epoch: 24.9 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.798034610801717		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 2.798034610801717 | validation: 2.9961144046357844]
	TIME [epoch: 24.9 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8080225813749844		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 2.8080225813749844 | validation: 2.992073330494512]
	TIME [epoch: 24.9 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.79759328867331		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 2.79759328867331 | validation: 2.9635747659396157]
	TIME [epoch: 24.9 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.796780973513707		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 2.796780973513707 | validation: 2.9820808310947196]
	TIME [epoch: 24.9 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.795610271640909		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 2.795610271640909 | validation: 2.965866863152202]
	TIME [epoch: 24.9 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.792645278769676		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 2.792645278769676 | validation: 2.9716527418699377]
	TIME [epoch: 24.9 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.808772407023597		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 2.808772407023597 | validation: 2.9713848233879467]
	TIME [epoch: 24.8 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.795113595398344		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 2.795113595398344 | validation: 2.970745653965048]
	TIME [epoch: 24.9 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8031990734252017		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 2.8031990734252017 | validation: 2.9779679538124926]
	TIME [epoch: 24.9 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7881963244223114		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 2.7881963244223114 | validation: 2.9592750293870145]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_1163.pth
	Model improved!!!
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7915621481372668		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 2.7915621481372668 | validation: 2.974646765882925]
	TIME [epoch: 24.9 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.79787117352563		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 2.79787117352563 | validation: 2.975533669654768]
	TIME [epoch: 24.9 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7987383655762583		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 2.7987383655762583 | validation: 2.9623185376448533]
	TIME [epoch: 24.9 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7936760092989887		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 2.7936760092989887 | validation: 2.9624099980079337]
	TIME [epoch: 24.9 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.792500945374933		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 2.792500945374933 | validation: 2.965581185223557]
	TIME [epoch: 24.9 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7979394455551487		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 2.7979394455551487 | validation: 2.9628749461444874]
	TIME [epoch: 24.8 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7945345408673754		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 2.7945345408673754 | validation: 2.9799213734377714]
	TIME [epoch: 24.9 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.799313030988235		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 2.799313030988235 | validation: 2.997397273234111]
	TIME [epoch: 24.8 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8147925922562833		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 2.8147925922562833 | validation: 2.987549115537912]
	TIME [epoch: 24.9 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.807904835958568		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 2.807904835958568 | validation: 2.972697886944343]
	TIME [epoch: 24.9 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8007574700594535		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 2.8007574700594535 | validation: 2.983808597002893]
	TIME [epoch: 24.9 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7937235392521877		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 2.7937235392521877 | validation: 2.9709413095433206]
	TIME [epoch: 24.8 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.791976977352139		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 2.791976977352139 | validation: 2.9791509660554287]
	TIME [epoch: 24.8 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7951968972952184		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 2.7951968972952184 | validation: 2.973198037272027]
	TIME [epoch: 24.8 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8063744237681503		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 2.8063744237681503 | validation: 2.959910759040896]
	TIME [epoch: 24.8 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.800817935212852		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 2.800817935212852 | validation: 2.970122872956849]
	TIME [epoch: 24.8 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8013832243567025		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 2.8013832243567025 | validation: 2.9749319440922997]
	TIME [epoch: 24.8 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.797187033943464		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 2.797187033943464 | validation: 2.9715836719665116]
	TIME [epoch: 24.9 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.79992635527854		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 2.79992635527854 | validation: 2.968189672606191]
	TIME [epoch: 24.8 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7990440801460412		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 2.7990440801460412 | validation: 2.968054702795204]
	TIME [epoch: 24.8 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8093100603916823		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 2.8093100603916823 | validation: 2.9837598109660997]
	TIME [epoch: 24.9 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8004987715664313		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 2.8004987715664313 | validation: 2.9723836349689976]
	TIME [epoch: 24.9 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8022545957034355		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 2.8022545957034355 | validation: 2.9679738382627643]
	TIME [epoch: 24.8 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7958666200310525		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 2.7958666200310525 | validation: 2.9739459485727746]
	TIME [epoch: 24.8 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7987267350675107		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 2.7987267350675107 | validation: 2.9768032557064403]
	TIME [epoch: 24.9 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7953304134723496		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 2.7953304134723496 | validation: 2.967386208616304]
	TIME [epoch: 24.9 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7949020035070715		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 2.7949020035070715 | validation: 2.972328626206001]
	TIME [epoch: 24.8 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.79101518499984		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 2.79101518499984 | validation: 2.976915632634724]
	TIME [epoch: 24.9 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.812852379547293		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 2.812852379547293 | validation: 3.0072007295329364]
	TIME [epoch: 24.9 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8080868244821073		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 2.8080868244821073 | validation: 2.9956718977252774]
	TIME [epoch: 24.8 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8032187585654134		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 2.8032187585654134 | validation: 2.9729232586491996]
	TIME [epoch: 24.9 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7912707284955074		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 2.7912707284955074 | validation: 2.9760442901901296]
	TIME [epoch: 24.9 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7977426590705106		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 2.7977426590705106 | validation: 2.977270872314107]
	TIME [epoch: 24.9 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.815589210499248		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 2.815589210499248 | validation: 2.9641902706594387]
	TIME [epoch: 24.8 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.803594789254886		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 2.803594789254886 | validation: 3.01459685307118]
	TIME [epoch: 24.9 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8131183045389268		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 2.8131183045389268 | validation: 2.976613830572791]
	TIME [epoch: 24.9 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7985702745367487		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 2.7985702745367487 | validation: 2.95364319489542]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240310_052504/states/model_tr_study205_1200.pth
	Model improved!!!
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7899721229339076		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 2.7899721229339076 | validation: 2.9736034090962926]
	TIME [epoch: 24.9 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8004154405778885		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 2.8004154405778885 | validation: 2.9730787341212364]
	TIME [epoch: 24.9 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7993573944324788		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 2.7993573944324788 | validation: 2.9736776076365112]
	TIME [epoch: 24.9 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8024629223820936		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 2.8024629223820936 | validation: 2.9655119356357376]
	TIME [epoch: 24.8 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7889471937130743		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 2.7889471937130743 | validation: 2.9624038155935795]
	TIME [epoch: 24.8 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.792377454970998		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 2.792377454970998 | validation: 2.972401483290957]
	TIME [epoch: 24.9 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8016223080953844		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 2.8016223080953844 | validation: 2.9661510933169164]
	TIME [epoch: 24.8 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7989640797219537		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 2.7989640797219537 | validation: 2.9662764091846476]
	TIME [epoch: 24.9 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.801320265330673		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 2.801320265330673 | validation: 2.98418309304475]
	TIME [epoch: 24.9 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7998634421238617		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 2.7998634421238617 | validation: 2.9795994833611825]
	TIME [epoch: 24.9 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7997292553632005		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 2.7997292553632005 | validation: 2.9756449412860166]
	TIME [epoch: 24.8 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7955749891415502		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 2.7955749891415502 | validation: 2.971995964148845]
	TIME [epoch: 24.9 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.814619437139706		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 2.814619437139706 | validation: 2.971420528258757]
	TIME [epoch: 24.9 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.798552908161592		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 2.798552908161592 | validation: 2.95516958294716]
	TIME [epoch: 24.9 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7878549105576287		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 2.7878549105576287 | validation: 2.979099065721436]
	TIME [epoch: 24.8 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7964329812980813		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 2.7964329812980813 | validation: 2.9593435314340417]
	TIME [epoch: 24.8 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7921671193183455		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 2.7921671193183455 | validation: 2.962395457567733]
	TIME [epoch: 24.9 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7924716237009033		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 2.7924716237009033 | validation: 2.9730269426173983]
	TIME [epoch: 24.9 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7924193256402257		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 2.7924193256402257 | validation: 2.9713135735661527]
	TIME [epoch: 24.9 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8085908605226226		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 2.8085908605226226 | validation: 2.984688365706073]
	TIME [epoch: 24.9 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7976342651551853		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 2.7976342651551853 | validation: 2.9817514540584704]
	TIME [epoch: 24.9 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7980962616557012		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 2.7980962616557012 | validation: 2.9774102832470994]
	TIME [epoch: 24.9 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.793581215750828		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 2.793581215750828 | validation: 2.9759823036204973]
	TIME [epoch: 24.9 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.798034385175508		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 2.798034385175508 | validation: 2.9780407632304664]
	TIME [epoch: 24.9 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8054373825812364		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 2.8054373825812364 | validation: 2.9576023939514937]
	TIME [epoch: 24.9 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.79109061133334		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 2.79109061133334 | validation: 2.962799241606217]
	TIME [epoch: 24.9 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.78941899064292		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 2.78941899064292 | validation: 2.961282210395915]
	TIME [epoch: 24.9 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.790962215106095		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 2.790962215106095 | validation: 2.9631592774869864]
	TIME [epoch: 24.9 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.793808365759067		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 2.793808365759067 | validation: 2.964986580564355]
	TIME [epoch: 24.9 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.798059469103873		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 2.798059469103873 | validation: 2.966024969339219]
	TIME [epoch: 24.9 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.809074726301753		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 2.809074726301753 | validation: 2.9597196408527835]
	TIME [epoch: 24.9 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7883942974118034		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 2.7883942974118034 | validation: 2.9665944537975726]
	TIME [epoch: 24.9 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.801986383642536		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 2.801986383642536 | validation: 2.9821966347540116]
	TIME [epoch: 24.9 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7948797436902053		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 2.7948797436902053 | validation: 2.9562160908057855]
	TIME [epoch: 24.9 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7944899171214876		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 2.7944899171214876 | validation: 2.970672765156554]
	TIME [epoch: 24.9 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.793579625815881		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 2.793579625815881 | validation: 2.974068869063592]
	TIME [epoch: 24.9 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.791106203228435		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 2.791106203228435 | validation: 2.96452957836398]
	TIME [epoch: 24.9 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7973909895953115		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 2.7973909895953115 | validation: 2.967660268852983]
	TIME [epoch: 24.9 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.793232901835533		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 2.793232901835533 | validation: 2.968769918602516]
	TIME [epoch: 24.9 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7939305401967442		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 2.7939305401967442 | validation: 2.9593808269170028]
	TIME [epoch: 24.9 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7933029516629686		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 2.7933029516629686 | validation: 2.967336499320396]
	TIME [epoch: 24.9 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7948501936444545		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 2.7948501936444545 | validation: 2.966095825292914]
	TIME [epoch: 24.9 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.797830543332465		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 2.797830543332465 | validation: 2.974532945746125]
	TIME [epoch: 24.9 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.795181876993957		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 2.795181876993957 | validation: 2.9781059172047644]
	TIME [epoch: 24.9 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.794942788689913		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 2.794942788689913 | validation: 2.956482552720377]
	TIME [epoch: 24.9 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.801241949274629		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 2.801241949274629 | validation: 2.9649084466774305]
	TIME [epoch: 24.9 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.797716715449836		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 2.797716715449836 | validation: 2.9660809579156884]
	TIME [epoch: 24.9 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7932582462545175		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 2.7932582462545175 | validation: 2.9549941169075034]
	TIME [epoch: 24.9 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7897941004645057		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 2.7897941004645057 | validation: 2.967787115173885]
	TIME [epoch: 24.9 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7912860822734498		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 2.7912860822734498 | validation: 2.9575620741913133]
	TIME [epoch: 24.9 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.793510877879977		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 2.793510877879977 | validation: 2.9629263610837255]
	TIME [epoch: 24.9 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.800355897062017		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 2.800355897062017 | validation: 2.9620276334535003]
	TIME [epoch: 24.9 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7980580159729374		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 2.7980580159729374 | validation: 2.983729437987164]
	TIME [epoch: 24.9 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.804608701804562		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 2.804608701804562 | validation: 2.96570408234541]
	TIME [epoch: 24.9 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7936808139905134		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 2.7936808139905134 | validation: 2.9752576237289925]
	TIME [epoch: 24.9 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7959404105362347		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 2.7959404105362347 | validation: 2.96761580287704]
	TIME [epoch: 24.9 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.793226078310507		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 2.793226078310507 | validation: 2.959035540945356]
	TIME [epoch: 24.9 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7907804622042507		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 2.7907804622042507 | validation: 2.967339461726799]
	TIME [epoch: 24.9 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7930963735449716		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 2.7930963735449716 | validation: 2.971447075878148]
	TIME [epoch: 24.8 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.806618652187543		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 2.806618652187543 | validation: 2.9625783520175246]
	TIME [epoch: 24.9 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.794955422701438		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 2.794955422701438 | validation: 2.9595784878999236]
	TIME [epoch: 24.9 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.793092362034759		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 2.793092362034759 | validation: 2.966524563436816]
	TIME [epoch: 24.9 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7898380319285816		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 2.7898380319285816 | validation: 2.9670667600178127]
	TIME [epoch: 24.8 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7926631903022856		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 2.7926631903022856 | validation: 2.971957910039935]
	TIME [epoch: 24.9 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.794187873952806		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 2.794187873952806 | validation: 2.9577079283114682]
	TIME [epoch: 24.9 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.790933311292269		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 2.790933311292269 | validation: 2.9682375693012104]
	TIME [epoch: 24.8 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7888344821198974		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 2.7888344821198974 | validation: 2.969332217155841]
	TIME [epoch: 24.9 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7947150487897363		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 2.7947150487897363 | validation: 2.961345235801385]
	TIME [epoch: 24.9 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7937688479863096		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 2.7937688479863096 | validation: 2.9640866974130335]
	TIME [epoch: 24.8 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7921086123168606		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 2.7921086123168606 | validation: 2.972155842204435]
	TIME [epoch: 24.9 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.794553341660575		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 2.794553341660575 | validation: 2.9832408771244]
	TIME [epoch: 24.9 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.797533612491118		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 2.797533612491118 | validation: 2.9741161882950724]
	TIME [epoch: 24.9 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7907766827426563		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 2.7907766827426563 | validation: 2.9547822898292786]
	TIME [epoch: 24.9 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7913716025543898		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 2.7913716025543898 | validation: 2.959713588609119]
	TIME [epoch: 24.9 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.789894328421318		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 2.789894328421318 | validation: 2.9708250093841815]
	TIME [epoch: 24.9 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7918351585158567		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 2.7918351585158567 | validation: 2.957914457655551]
	TIME [epoch: 24.9 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.793119740787995		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 2.793119740787995 | validation: 2.966451434104521]
	TIME [epoch: 24.9 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.796789880197991		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 2.796789880197991 | validation: 2.96652538039919]
	TIME [epoch: 24.9 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7972808290275526		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 2.7972808290275526 | validation: 2.975335553957718]
	TIME [epoch: 24.9 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7948384155870354		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 2.7948384155870354 | validation: 2.968897190532134]
	TIME [epoch: 24.9 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.788162684478068		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 2.788162684478068 | validation: 2.96228710711379]
	TIME [epoch: 24.8 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.799476225595113		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 2.799476225595113 | validation: 2.975097125663649]
	TIME [epoch: 24.9 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8021563911107465		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 2.8021563911107465 | validation: 2.9638391840970884]
	TIME [epoch: 24.9 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.794989586404596		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 2.794989586404596 | validation: 2.960313322201516]
	TIME [epoch: 24.8 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.792260783234705		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 2.792260783234705 | validation: 2.969574752811699]
	TIME [epoch: 24.9 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.789929227179708		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 2.789929227179708 | validation: 2.9748040896405614]
	TIME [epoch: 24.9 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.798530024766524		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 2.798530024766524 | validation: 2.971304624058439]
	TIME [epoch: 24.9 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.790208429355729		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 2.790208429355729 | validation: 2.985265946055016]
	TIME [epoch: 24.9 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.81135092792704		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 2.81135092792704 | validation: 2.9907983492640726]
	TIME [epoch: 24.9 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.803479349653304		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 2.803479349653304 | validation: 2.977767005009336]
	TIME [epoch: 24.9 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7979831525441394		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 2.7979831525441394 | validation: 2.9814738232447535]
	TIME [epoch: 24.8 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7931617707909195		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 2.7931617707909195 | validation: 2.9674293560089438]
	TIME [epoch: 24.9 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.794620988446226		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 2.794620988446226 | validation: 2.9703457604103085]
	TIME [epoch: 24.9 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7901128573080296		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 2.7901128573080296 | validation: 2.9730189276352084]
	TIME [epoch: 24.8 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.795011264643655		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 2.795011264643655 | validation: 2.970573652303949]
	TIME [epoch: 24.8 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7931628130715946		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 2.7931628130715946 | validation: 2.9616339715723403]
	TIME [epoch: 24.9 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.789289248908399		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 2.789289248908399 | validation: 2.970370030043576]
	TIME [epoch: 24.9 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.800066206867193		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 2.800066206867193 | validation: 2.9747286750893873]
	TIME [epoch: 24.9 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.796702202574706		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 2.796702202574706 | validation: 2.975803346898062]
	TIME [epoch: 24.8 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.799775418594958		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 2.799775418594958 | validation: 2.961971134689711]
	TIME [epoch: 24.9 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7901173446039733		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 2.7901173446039733 | validation: 2.9567508054618954]
	TIME [epoch: 24.9 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.795211945192921		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 2.795211945192921 | validation: 2.9703448847801948]
	TIME [epoch: 24.9 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7948256363720123		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 2.7948256363720123 | validation: 2.982273920859876]
	TIME [epoch: 24.9 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.797854494592958		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 2.797854494592958 | validation: 2.9688112053043434]
	TIME [epoch: 24.9 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.792255437098233		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 2.792255437098233 | validation: 2.973646125760642]
	TIME [epoch: 24.9 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7934957021017595		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 2.7934957021017595 | validation: 2.954673412980646]
	TIME [epoch: 24.8 sec]
EPOCH 1307/2000:
	Training over batches...
