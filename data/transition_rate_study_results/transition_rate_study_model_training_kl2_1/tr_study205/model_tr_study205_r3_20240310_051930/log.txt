Args:
Namespace(name='model_tr_study205', outdir='out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3', training_data='data/transition_rate_studies/tr_study205/tr_study205_training/r3', validation_data='data/transition_rate_studies/tr_study205/tr_study205_validation/r3', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.075, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1359743556

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 13.228441125440463		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 13.228441125440463 | validation: 14.25770669332872]
	TIME [epoch: 111 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 13.154633788690239		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 13.154633788690239 | validation: 11.781450836572526]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.40979984752968		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.40979984752968 | validation: 9.610144144119781]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.083944036995351		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.083944036995351 | validation: 8.721106250485489]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.023835590806922		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.023835590806922 | validation: 8.206180130459325]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.513328653039058		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.513328653039058 | validation: 8.500693483440113]
	TIME [epoch: 24.7 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.475842706973156		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.475842706973156 | validation: 7.574355915949489]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.28286873586387		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.28286873586387 | validation: 7.326228198217593]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.672124209588862		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.672124209588862 | validation: 7.454325065786702]
	TIME [epoch: 24.8 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.042539179713805		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.042539179713805 | validation: 6.584292932694922]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.199667641026542		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.199667641026542 | validation: 6.881239193143001]
	TIME [epoch: 24.9 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.889233550392138		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.889233550392138 | validation: 6.016339778660613]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.6277277622816415		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.6277277622816415 | validation: 7.154106617712337]
	TIME [epoch: 24.7 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.266382419248888		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.266382419248888 | validation: 5.876421754929366]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.551314688107697		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.551314688107697 | validation: 6.701625118303098]
	TIME [epoch: 24.8 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.593768693404295		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.593768693404295 | validation: 5.755169370992921]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.548960779001122		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.548960779001122 | validation: 5.357608095958483]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.344780454341758		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.344780454341758 | validation: 5.683307586789814]
	TIME [epoch: 24.7 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.4074212969878115		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.4074212969878115 | validation: 5.580053091363132]
	TIME [epoch: 24.8 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.11759740193345		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.11759740193345 | validation: 5.665567320627275]
	TIME [epoch: 24.8 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.3984703835740255		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.3984703835740255 | validation: 5.3361215081137585]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.998471567163871		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.998471567163871 | validation: 5.140348432337113]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.109099344833773		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.109099344833773 | validation: 4.940339657875949]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.018671537269027		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.018671537269027 | validation: 5.383124006255378]
	TIME [epoch: 24.7 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.902073028151183		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.902073028151183 | validation: 5.243122192283913]
	TIME [epoch: 24.8 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.927656624480544		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.927656624480544 | validation: 4.78211135541981]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.786911232354601		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.786911232354601 | validation: 5.533152372897098]
	TIME [epoch: 24.8 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.105564905621443		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.105564905621443 | validation: 4.797629526484977]
	TIME [epoch: 24.8 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.796599737850714		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.796599737850714 | validation: 4.888161178340534]
	TIME [epoch: 24.7 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.617595796329389		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.617595796329389 | validation: 5.085066380662794]
	TIME [epoch: 24.7 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.913530059577127		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.913530059577127 | validation: 4.786863596304599]
	TIME [epoch: 24.7 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.47781803077015		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.47781803077015 | validation: 4.867485255079721]
	TIME [epoch: 24.7 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.431996489097511		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.431996489097511 | validation: 5.815967338170005]
	TIME [epoch: 24.7 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.611858982961359		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.611858982961359 | validation: 4.647288271429369]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.557650089721758		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.557650089721758 | validation: 4.623572501186313]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.385687648774924		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.385687648774924 | validation: 5.227386904494803]
	TIME [epoch: 24.7 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5716625727374725		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.5716625727374725 | validation: 4.381908153869459]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.787215937844271		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.787215937844271 | validation: 4.273581154922145]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.552807258530121		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.552807258530121 | validation: 4.649739320597686]
	TIME [epoch: 24.8 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.489467229297539		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.489467229297539 | validation: 4.486829845688621]
	TIME [epoch: 24.7 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.286214432141928		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.286214432141928 | validation: 4.39456604128136]
	TIME [epoch: 24.8 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.315880085818874		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.315880085818874 | validation: 4.718354625479767]
	TIME [epoch: 24.8 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.278479300437603		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.278479300437603 | validation: 5.347821527859835]
	TIME [epoch: 24.7 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.424699500873995		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.424699500873995 | validation: 4.305732152844879]
	TIME [epoch: 24.8 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.238657387428908		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.238657387428908 | validation: 4.159770457063749]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.25582982645822		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.25582982645822 | validation: 4.308239144333975]
	TIME [epoch: 24.7 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.250602814049698		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.250602814049698 | validation: 4.319135123361597]
	TIME [epoch: 24.8 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.287872857642965		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.287872857642965 | validation: 4.4272220446605575]
	TIME [epoch: 24.8 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.063142342976509		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.063142342976509 | validation: 4.0204417524982885]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8814532690025363		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8814532690025363 | validation: 6.681229011144876]
	TIME [epoch: 24.8 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.591744290345128		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 4.591744290345128 | validation: 5.579718844562187]
	TIME [epoch: 24.8 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.105663018953018		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 4.105663018953018 | validation: 4.797748498473312]
	TIME [epoch: 24.7 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.280197054025843		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 4.280197054025843 | validation: 4.2053229168313555]
	TIME [epoch: 24.8 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.125987374345976		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 4.125987374345976 | validation: 4.34048471027826]
	TIME [epoch: 24.8 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9640924684481553		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 3.9640924684481553 | validation: 4.492949059639345]
	TIME [epoch: 24.7 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.150326881026658		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 4.150326881026658 | validation: 3.995222441261069]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7012036579742382		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 3.7012036579742382 | validation: 3.783700312954841]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.1479526718576185		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 4.1479526718576185 | validation: 3.8384572305869997]
	TIME [epoch: 24.7 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.946734283053941		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 3.946734283053941 | validation: 4.171872306022134]
	TIME [epoch: 24.8 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.953693789137522		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 3.953693789137522 | validation: 3.761269945775601]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.162333603875198		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 4.162333603875198 | validation: 3.887405991391499]
	TIME [epoch: 24.7 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.92277542596118		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 3.92277542596118 | validation: 3.802585189843879]
	TIME [epoch: 24.8 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9030495083645995		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 3.9030495083645995 | validation: 4.268516014064836]
	TIME [epoch: 24.8 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8605239851664273		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 3.8605239851664273 | validation: 4.0971925733407994]
	TIME [epoch: 24.7 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.748804703517845		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 3.748804703517845 | validation: 4.1014433663507335]
	TIME [epoch: 24.8 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8395456090551976		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 3.8395456090551976 | validation: 3.675089644264756]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4231949405101467		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 3.4231949405101467 | validation: 3.9342285001484756]
	TIME [epoch: 24.7 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.174267841073665		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 4.174267841073665 | validation: 3.997859106740549]
	TIME [epoch: 24.8 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.826298905481809		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 3.826298905481809 | validation: 3.8444909784389365]
	TIME [epoch: 24.8 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.624231755105176		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 3.624231755105176 | validation: 4.492244470118014]
	TIME [epoch: 24.8 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.802000190081817		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 3.802000190081817 | validation: 4.068035425109874]
	TIME [epoch: 24.8 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.766134927721659		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 3.766134927721659 | validation: 3.690869625206271]
	TIME [epoch: 24.7 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5192639869045235		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 3.5192639869045235 | validation: 4.845838923871006]
	TIME [epoch: 24.7 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.817289519467724		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 3.817289519467724 | validation: 4.101602641352837]
	TIME [epoch: 24.8 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7322931684247167		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 3.7322931684247167 | validation: 4.149531481810693]
	TIME [epoch: 24.8 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.63598587416378		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 3.63598587416378 | validation: 3.5271988286028364]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5685988816648373		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 3.5685988816648373 | validation: 3.7207392420726215]
	TIME [epoch: 24.8 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6379937380519722		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 3.6379937380519722 | validation: 3.6679452190937134]
	TIME [epoch: 24.8 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.461725881998543		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 3.461725881998543 | validation: 3.5258202774531218]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6609571764987043		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 3.6609571764987043 | validation: 3.5497627728926897]
	TIME [epoch: 24.8 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5701191675350854		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 3.5701191675350854 | validation: 3.7349301391484087]
	TIME [epoch: 24.7 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.532984542745319		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 3.532984542745319 | validation: 3.4446921485533624]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_82.pth
	Model improved!!!
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5211619592237966		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 3.5211619592237966 | validation: 3.45977966251911]
	TIME [epoch: 24.8 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.373094056106249		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 3.373094056106249 | validation: 3.7988307601866245]
	TIME [epoch: 24.8 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6368431365226304		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 3.6368431365226304 | validation: 3.624204605853434]
	TIME [epoch: 24.7 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.413882757660534		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 3.413882757660534 | validation: 3.4796163506794664]
	TIME [epoch: 24.8 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5249994412747574		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 3.5249994412747574 | validation: 3.4820440936526507]
	TIME [epoch: 24.8 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4366484321842856		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 3.4366484321842856 | validation: 3.5591920180410144]
	TIME [epoch: 24.8 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.202277319804944		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 3.202277319804944 | validation: 5.703227893376342]
	TIME [epoch: 24.8 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.514303475569537		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 4.514303475569537 | validation: 3.5994765917625933]
	TIME [epoch: 24.8 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3939119917872755		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 3.3939119917872755 | validation: 3.4984818020533566]
	TIME [epoch: 24.7 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4780410514379083		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 3.4780410514379083 | validation: 3.4556488763019195]
	TIME [epoch: 24.8 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4231326549555123		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 3.4231326549555123 | validation: 3.6615869619552592]
	TIME [epoch: 24.8 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.453454219339665		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 3.453454219339665 | validation: 3.481667419500102]
	TIME [epoch: 24.7 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.528512839561126		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 3.528512839561126 | validation: 3.3329279585224447]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_95.pth
	Model improved!!!
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1884692505282435		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 3.1884692505282435 | validation: 4.522746765079308]
	TIME [epoch: 24.8 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.666146466690808		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 3.666146466690808 | validation: 3.513915951064871]
	TIME [epoch: 24.7 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.621780196669106		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 3.621780196669106 | validation: 3.25205265660917]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_98.pth
	Model improved!!!
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3447712257935804		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 3.3447712257935804 | validation: 3.574743443855548]
	TIME [epoch: 24.8 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1258207072218185		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 3.1258207072218185 | validation: 3.6336390589483494]
	TIME [epoch: 24.7 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4214104257573625		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 3.4214104257573625 | validation: 3.403386979270849]
	TIME [epoch: 24.7 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.255633040102267		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 3.255633040102267 | validation: 3.6688398258864727]
	TIME [epoch: 24.7 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.288990885280341		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 3.288990885280341 | validation: 3.482751165301485]
	TIME [epoch: 24.7 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.270523453953596		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 3.270523453953596 | validation: 3.7099173867388755]
	TIME [epoch: 25 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2933092699005413		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 3.2933092699005413 | validation: 3.569701404215721]
	TIME [epoch: 24.8 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3007621097396114		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 3.3007621097396114 | validation: 3.5170937469437478]
	TIME [epoch: 24.7 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.355269900013792		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 3.355269900013792 | validation: 3.4383481109418166]
	TIME [epoch: 24.7 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1700324913355686		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 3.1700324913355686 | validation: 3.2284462743511013]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_108.pth
	Model improved!!!
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1416697573399834		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 3.1416697573399834 | validation: 4.124312550193378]
	TIME [epoch: 24.7 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3718318743216398		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 3.3718318743216398 | validation: 3.364405359425013]
	TIME [epoch: 24.7 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.213786090703963		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 3.213786090703963 | validation: 3.149057366038056]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_111.pth
	Model improved!!!
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.894518121248801		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 2.894518121248801 | validation: 4.1249735333369575]
	TIME [epoch: 24.7 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.402763509232787		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 3.402763509232787 | validation: 3.5497585879773736]
	TIME [epoch: 24.7 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.377357403779178		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 3.377357403779178 | validation: 3.457491024622753]
	TIME [epoch: 24.7 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3085008812834618		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 3.3085008812834618 | validation: 3.212546045476703]
	TIME [epoch: 24.7 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9129803692585243		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 2.9129803692585243 | validation: 3.5552507196100898]
	TIME [epoch: 24.7 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3142881561177693		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 3.3142881561177693 | validation: 3.203216140898829]
	TIME [epoch: 24.7 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.261173623920491		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 3.261173623920491 | validation: 3.1921468158908706]
	TIME [epoch: 24.7 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2560354890245105		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 3.2560354890245105 | validation: 3.298317470865198]
	TIME [epoch: 24.7 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1864121379510255		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 3.1864121379510255 | validation: 3.4080219287308444]
	TIME [epoch: 24.7 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1049445347842255		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 3.1049445347842255 | validation: 3.2416248457557613]
	TIME [epoch: 24.7 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.245578538762513		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 3.245578538762513 | validation: 3.2725867003847955]
	TIME [epoch: 24.8 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.345961014093505		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 3.345961014093505 | validation: 3.381026719677898]
	TIME [epoch: 24.7 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.045886162078072		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 3.045886162078072 | validation: 3.228239700845234]
	TIME [epoch: 24.7 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1057651572713882		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 3.1057651572713882 | validation: 3.3157346029011627]
	TIME [epoch: 24.7 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1028680764938894		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 3.1028680764938894 | validation: 3.509694557144938]
	TIME [epoch: 24.7 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.13393641857665		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 3.13393641857665 | validation: 3.616256748786492]
	TIME [epoch: 24.7 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1906003710431508		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 3.1906003710431508 | validation: 3.271485475855817]
	TIME [epoch: 24.7 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.933427532995527		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 2.933427532995527 | validation: 3.5459071718208732]
	TIME [epoch: 24.7 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1076410237902903		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 3.1076410237902903 | validation: 3.5508157279502672]
	TIME [epoch: 24.7 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.351178094925219		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 3.351178094925219 | validation: 3.017091526059886]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_131.pth
	Model improved!!!
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0688558609622865		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 3.0688558609622865 | validation: 3.2463265902230067]
	TIME [epoch: 24.7 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0869575659109705		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 3.0869575659109705 | validation: 3.4558254514319033]
	TIME [epoch: 24.7 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1677464223305583		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 3.1677464223305583 | validation: 3.1954535246785247]
	TIME [epoch: 24.7 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0242739047275062		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 3.0242739047275062 | validation: 3.3636904312807445]
	TIME [epoch: 24.7 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.382232961598727		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 3.382232961598727 | validation: 3.752009540392054]
	TIME [epoch: 24.7 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.155716387853589		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 3.155716387853589 | validation: 3.113599134542866]
	TIME [epoch: 24.7 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0608145377909612		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 3.0608145377909612 | validation: 3.263895098449733]
	TIME [epoch: 24.7 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.009535382450244		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 3.009535382450244 | validation: 3.020511197306529]
	TIME [epoch: 24.7 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9067720831480335		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 2.9067720831480335 | validation: 3.4786246492830424]
	TIME [epoch: 24.7 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.063040907536965		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 3.063040907536965 | validation: 3.2319490453865587]
	TIME [epoch: 24.7 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8882066506985433		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 2.8882066506985433 | validation: 3.412359785859826]
	TIME [epoch: 24.7 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.997528866380938		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 2.997528866380938 | validation: 2.9233576503526697]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_143.pth
	Model improved!!!
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0278472895969557		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 3.0278472895969557 | validation: 3.5158916031915055]
	TIME [epoch: 24.7 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.978019412135441		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 2.978019412135441 | validation: 4.173820632148431]
	TIME [epoch: 24.7 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.138348024502781		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 3.138348024502781 | validation: 3.2854441571874022]
	TIME [epoch: 24.7 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8640671743379804		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 2.8640671743379804 | validation: 3.353909218618296]
	TIME [epoch: 24.7 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0873898744602624		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 3.0873898744602624 | validation: 4.1574947019601165]
	TIME [epoch: 24.7 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3565945165869975		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 3.3565945165869975 | validation: 2.963679295560382]
	TIME [epoch: 24.7 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.013826806214696		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 3.013826806214696 | validation: 3.13473073862827]
	TIME [epoch: 24.7 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.015777127980015		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 3.015777127980015 | validation: 3.451309981109507]
	TIME [epoch: 24.7 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.947693352161005		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 2.947693352161005 | validation: 3.5598667155896533]
	TIME [epoch: 24.7 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0387701609781796		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 3.0387701609781796 | validation: 3.118420247302615]
	TIME [epoch: 24.7 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9703096270830787		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 2.9703096270830787 | validation: 2.981829824052153]
	TIME [epoch: 24.7 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9976558253886596		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 2.9976558253886596 | validation: 2.9432003614217503]
	TIME [epoch: 24.7 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9958193436960263		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 2.9958193436960263 | validation: 2.921319118077393]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_156.pth
	Model improved!!!
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.946611775766909		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 2.946611775766909 | validation: 3.027485825497547]
	TIME [epoch: 24.7 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0026996186866954		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 3.0026996186866954 | validation: 3.02489390405475]
	TIME [epoch: 24.7 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.940213180842907		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 2.940213180842907 | validation: 2.9759025879843692]
	TIME [epoch: 24.7 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.915665895420473		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 2.915665895420473 | validation: 2.884916999875013]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_160.pth
	Model improved!!!
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9426019725654333		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 2.9426019725654333 | validation: 2.897450322738956]
	TIME [epoch: 24.7 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8150813925619977		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 2.8150813925619977 | validation: 3.0460678927380473]
	TIME [epoch: 24.7 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8842904366221234		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 2.8842904366221234 | validation: 2.883539492587492]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_163.pth
	Model improved!!!
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.013229687709484		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 3.013229687709484 | validation: 2.905169868090717]
	TIME [epoch: 24.7 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.86058213232912		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 2.86058213232912 | validation: 2.9905192649446133]
	TIME [epoch: 24.7 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.909419082321045		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 2.909419082321045 | validation: 2.880140025698695]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_166.pth
	Model improved!!!
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7774579144144083		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 2.7774579144144083 | validation: 3.467789459244349]
	TIME [epoch: 24.7 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.930922170800685		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 2.930922170800685 | validation: 3.4113498988937665]
	TIME [epoch: 24.7 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.060938027948382		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 3.060938027948382 | validation: 3.348605055044856]
	TIME [epoch: 24.7 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.959682503891649		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 2.959682503891649 | validation: 3.2161670811364265]
	TIME [epoch: 24.8 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.866990076157042		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 2.866990076157042 | validation: 3.2135841292240537]
	TIME [epoch: 24.7 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.903023248270082		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 2.903023248270082 | validation: 2.9854904502529025]
	TIME [epoch: 24.7 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.791836320789319		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 2.791836320789319 | validation: 2.9225779741691276]
	TIME [epoch: 24.8 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.891183477692702		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 2.891183477692702 | validation: 2.9906919110934314]
	TIME [epoch: 24.7 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8823775039016386		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 2.8823775039016386 | validation: 2.8229621712483413]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_175.pth
	Model improved!!!
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7661669698024434		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 2.7661669698024434 | validation: 3.053147936658792]
	TIME [epoch: 24.8 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.786386920594787		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 2.786386920594787 | validation: 2.951073233938459]
	TIME [epoch: 24.7 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7294245894152995		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 2.7294245894152995 | validation: 2.845837751269532]
	TIME [epoch: 24.8 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8253746091657153		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 2.8253746091657153 | validation: 2.8780684464650053]
	TIME [epoch: 24.8 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8272102903140315		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 2.8272102903140315 | validation: 3.2110888209468293]
	TIME [epoch: 24.7 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.815574385310366		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 2.815574385310366 | validation: 2.850008297346981]
	TIME [epoch: 24.8 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7856516758702305		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 2.7856516758702305 | validation: 2.9600077708772305]
	TIME [epoch: 24.8 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7691490157976406		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 2.7691490157976406 | validation: 2.794741412551314]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_183.pth
	Model improved!!!
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8852540916442404		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 2.8852540916442404 | validation: 2.865620032426086]
	TIME [epoch: 24.7 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.765498922683971		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 2.765498922683971 | validation: 3.3574675690279423]
	TIME [epoch: 24.7 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.811356907566835		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 2.811356907566835 | validation: 3.076256193165215]
	TIME [epoch: 24.8 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8327860376728635		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 2.8327860376728635 | validation: 2.865356634507183]
	TIME [epoch: 24.7 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.663899455258562		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 2.663899455258562 | validation: 3.3977998406938634]
	TIME [epoch: 24.8 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.875817117370003		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 2.875817117370003 | validation: 3.0403486239364255]
	TIME [epoch: 24.7 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7186781776770492		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 2.7186781776770492 | validation: 3.615141943429975]
	TIME [epoch: 24.8 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.926137313303296		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 2.926137313303296 | validation: 3.143266630164387]
	TIME [epoch: 24.7 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.937157280879675		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 2.937157280879675 | validation: 2.994701504687794]
	TIME [epoch: 24.7 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.617871953077881		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 2.617871953077881 | validation: 2.891118748293526]
	TIME [epoch: 24.7 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.81704438411445		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 2.81704438411445 | validation: 3.1231086616826906]
	TIME [epoch: 24.8 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.842853886806948		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 2.842853886806948 | validation: 2.8811138533302767]
	TIME [epoch: 24.7 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7111870031753176		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 2.7111870031753176 | validation: 2.906175099553333]
	TIME [epoch: 24.8 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7245003110164667		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 2.7245003110164667 | validation: 3.35583534225937]
	TIME [epoch: 24.7 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.805754842005833		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 2.805754842005833 | validation: 3.2535008933352643]
	TIME [epoch: 24.8 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8788735172467805		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 2.8788735172467805 | validation: 2.8039926562963267]
	TIME [epoch: 24.7 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.736034802303777		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 2.736034802303777 | validation: 2.99423754981855]
	TIME [epoch: 24.8 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7674821194254706		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 2.7674821194254706 | validation: 2.794589597316995]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_201.pth
	Model improved!!!
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8483378645760777		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 2.8483378645760777 | validation: 2.9103977612577037]
	TIME [epoch: 24.8 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.897126941848618		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 2.897126941848618 | validation: 3.4803421530687917]
	TIME [epoch: 24.8 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9066692172341986		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 2.9066692172341986 | validation: 3.063670936512878]
	TIME [epoch: 24.7 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7828980819260205		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 2.7828980819260205 | validation: 2.8341618052893933]
	TIME [epoch: 24.8 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.691988409469523		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 2.691988409469523 | validation: 2.9622800500327946]
	TIME [epoch: 24.8 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8595785501759226		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 2.8595785501759226 | validation: 2.8757465525101304]
	TIME [epoch: 24.7 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.83271562780748		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 2.83271562780748 | validation: 2.8287698272876707]
	TIME [epoch: 24.8 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.842299472131031		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 2.842299472131031 | validation: 2.871619798975345]
	TIME [epoch: 24.8 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7554135253530334		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 2.7554135253530334 | validation: 3.2147030028737986]
	TIME [epoch: 24.7 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7333363204698897		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 2.7333363204698897 | validation: 2.863852238819473]
	TIME [epoch: 24.8 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.736475673674108		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 2.736475673674108 | validation: 3.0420186863904597]
	TIME [epoch: 24.8 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6825076813957134		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 2.6825076813957134 | validation: 3.0166503691156605]
	TIME [epoch: 24.7 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7945458696740544		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 2.7945458696740544 | validation: 3.030963332102758]
	TIME [epoch: 24.8 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7965760801963118		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 2.7965760801963118 | validation: 2.7895577748268354]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_215.pth
	Model improved!!!
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.680764619849926		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 2.680764619849926 | validation: 2.89643600786789]
	TIME [epoch: 24.7 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.644628606836461		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 2.644628606836461 | validation: 3.247590135733418]
	TIME [epoch: 24.8 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7784611985466023		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 2.7784611985466023 | validation: 3.1084397780499775]
	TIME [epoch: 24.8 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.674545377789981		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 2.674545377789981 | validation: 2.809297947227575]
	TIME [epoch: 24.7 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.883079014875861		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 2.883079014875861 | validation: 3.631968598891841]
	TIME [epoch: 24.8 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.823286194056467		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 2.823286194056467 | validation: 3.0011144446100526]
	TIME [epoch: 24.8 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7472971350114848		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 2.7472971350114848 | validation: 3.0226191567829814]
	TIME [epoch: 24.7 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7229515933495		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 2.7229515933495 | validation: 3.112403373745693]
	TIME [epoch: 24.8 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.652620600872389		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 2.652620600872389 | validation: 2.886256125119039]
	TIME [epoch: 24.8 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7186020826892334		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 2.7186020826892334 | validation: 2.9219956097197963]
	TIME [epoch: 24.7 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.69856080082364		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 2.69856080082364 | validation: 3.0524348248723276]
	TIME [epoch: 24.8 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.744788988923971		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 2.744788988923971 | validation: 2.8812750320065597]
	TIME [epoch: 24.8 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.809104020207563		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 2.809104020207563 | validation: 2.9276528511132076]
	TIME [epoch: 24.7 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6934339424127036		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 2.6934339424127036 | validation: 3.020498805548168]
	TIME [epoch: 24.8 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7168901722850336		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 2.7168901722850336 | validation: 3.158179561478679]
	TIME [epoch: 24.7 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6413613537484477		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 2.6413613537484477 | validation: 3.2726020857317235]
	TIME [epoch: 24.7 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7031012886271832		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 2.7031012886271832 | validation: 2.8628469453431227]
	TIME [epoch: 24.7 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.797482182494412		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 2.797482182494412 | validation: 2.862737282214389]
	TIME [epoch: 24.8 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6435856355487473		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 2.6435856355487473 | validation: 2.9691520812374215]
	TIME [epoch: 24.7 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6900511196195898		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 2.6900511196195898 | validation: 3.116767298845555]
	TIME [epoch: 24.8 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.721919366400662		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 2.721919366400662 | validation: 2.941440621759216]
	TIME [epoch: 24.7 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.744093534607307		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 2.744093534607307 | validation: 2.9477872851481237]
	TIME [epoch: 24.7 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.723846547456004		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 2.723846547456004 | validation: 2.8547815916839276]
	TIME [epoch: 24.8 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6149383501992456		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 2.6149383501992456 | validation: 2.9829132855556497]
	TIME [epoch: 24.8 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6873108113377966		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 2.6873108113377966 | validation: 3.523930381776885]
	TIME [epoch: 24.8 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.855400418365758		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 2.855400418365758 | validation: 3.0503512416139085]
	TIME [epoch: 24.8 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6394934969742354		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 2.6394934969742354 | validation: 2.8834949085889185]
	TIME [epoch: 24.8 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6253930900676616		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 2.6253930900676616 | validation: 2.834709376525826]
	TIME [epoch: 24.8 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6675671283597064		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 2.6675671283597064 | validation: 2.7925440959435184]
	TIME [epoch: 24.8 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6780937778819953		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 2.6780937778819953 | validation: 2.8775546136258185]
	TIME [epoch: 24.8 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.644966429025192		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 2.644966429025192 | validation: 3.4294248285486146]
	TIME [epoch: 24.7 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.698758969105638		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 2.698758969105638 | validation: 2.8388115097061]
	TIME [epoch: 24.8 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.614908007740095		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 2.614908007740095 | validation: 3.3488476772623823]
	TIME [epoch: 24.8 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7735957402274387		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 2.7735957402274387 | validation: 2.727431976170665]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_249.pth
	Model improved!!!
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.690266378327486		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 2.690266378327486 | validation: 2.752896760893748]
	TIME [epoch: 24.7 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6319607596112675		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 2.6319607596112675 | validation: 2.7053253376772695]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_251.pth
	Model improved!!!
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4694768833929626		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 2.4694768833929626 | validation: 2.842829553895428]
	TIME [epoch: 24.7 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.802281094756358		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 2.802281094756358 | validation: 2.9190270522073396]
	TIME [epoch: 24.7 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6293260797536977		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 2.6293260797536977 | validation: 2.841897003907146]
	TIME [epoch: 24.7 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6282843341671924		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 2.6282843341671924 | validation: 2.9579988196497915]
	TIME [epoch: 24.7 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6712793977666185		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 2.6712793977666185 | validation: 2.865925745226629]
	TIME [epoch: 24.7 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.681566726970769		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 2.681566726970769 | validation: 2.697891135979914]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_257.pth
	Model improved!!!
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6733112309660987		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 2.6733112309660987 | validation: 2.7793018076135025]
	TIME [epoch: 24.7 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5371028926007266		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 2.5371028926007266 | validation: 2.827946684225206]
	TIME [epoch: 24.7 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6516762613707052		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 2.6516762613707052 | validation: 2.768720636961376]
	TIME [epoch: 24.7 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6010534229498736		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 2.6010534229498736 | validation: 2.8397189533552627]
	TIME [epoch: 24.7 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.676356380244026		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 2.676356380244026 | validation: 2.992056657306144]
	TIME [epoch: 24.7 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6384301235773675		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 2.6384301235773675 | validation: 2.8927204720718795]
	TIME [epoch: 24.7 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7655114473200353		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 2.7655114473200353 | validation: 2.785557269590802]
	TIME [epoch: 24.7 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5455073415573		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 2.5455073415573 | validation: 2.7128123812134532]
	TIME [epoch: 24.7 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5834622661984388		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 2.5834622661984388 | validation: 2.803585834017083]
	TIME [epoch: 24.7 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6561414024799737		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 2.6561414024799737 | validation: 2.7613329243707905]
	TIME [epoch: 24.7 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5576799179843137		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 2.5576799179843137 | validation: 2.8233791823626735]
	TIME [epoch: 24.7 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.605982719819128		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 2.605982719819128 | validation: 2.702217220363017]
	TIME [epoch: 24.7 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5414933207885575		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 2.5414933207885575 | validation: 2.753119870988622]
	TIME [epoch: 24.7 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6154860597139087		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 2.6154860597139087 | validation: 2.961333740065023]
	TIME [epoch: 24.7 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.574629717402339		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 2.574629717402339 | validation: 3.079602450092093]
	TIME [epoch: 24.7 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6267803344877367		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 2.6267803344877367 | validation: 2.746372703042109]
	TIME [epoch: 24.7 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5431770138777408		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 2.5431770138777408 | validation: 2.757898045712599]
	TIME [epoch: 24.7 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.504454076925114		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 2.504454076925114 | validation: 2.839121526663711]
	TIME [epoch: 24.7 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5294776338185736		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 2.5294776338185736 | validation: 2.7291646724230665]
	TIME [epoch: 24.7 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4970326811465804		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 2.4970326811465804 | validation: 2.8590650247090923]
	TIME [epoch: 24.7 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.488440099546399		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 2.488440099546399 | validation: 2.9310716923890965]
	TIME [epoch: 24.7 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5764635538999547		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 2.5764635538999547 | validation: 2.746155424151811]
	TIME [epoch: 24.7 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5562010940262363		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 2.5562010940262363 | validation: 2.9125741503096925]
	TIME [epoch: 24.7 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5086253907777794		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 2.5086253907777794 | validation: 2.6956304519397616]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_281.pth
	Model improved!!!
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.493994225256372		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 2.493994225256372 | validation: 3.1871110981987636]
	TIME [epoch: 24.7 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.59009501640214		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 2.59009501640214 | validation: 2.8160399331885895]
	TIME [epoch: 24.8 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4782075533062664		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 2.4782075533062664 | validation: 2.928108782491279]
	TIME [epoch: 24.7 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6518196648889063		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 2.6518196648889063 | validation: 2.687739675613003]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_285.pth
	Model improved!!!
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4961606407394403		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 2.4961606407394403 | validation: 2.8918986157406255]
	TIME [epoch: 24.7 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5955271775740485		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 2.5955271775740485 | validation: 2.673028024469535]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_287.pth
	Model improved!!!
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.474683158631267		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 2.474683158631267 | validation: 2.673103856663402]
	TIME [epoch: 24.7 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.523404431022186		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 2.523404431022186 | validation: 2.6875757901482933]
	TIME [epoch: 24.8 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.538414755304986		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 2.538414755304986 | validation: 2.8130649859018293]
	TIME [epoch: 24.7 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4553235337097457		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 2.4553235337097457 | validation: 2.721864105100918]
	TIME [epoch: 24.7 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6681788931888453		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 2.6681788931888453 | validation: 3.0865703310699972]
	TIME [epoch: 24.8 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.614679990698785		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 2.614679990698785 | validation: 2.7048830469678147]
	TIME [epoch: 24.8 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4725442300986664		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 2.4725442300986664 | validation: 2.7488498900053773]
	TIME [epoch: 24.8 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4458352670955783		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 2.4458352670955783 | validation: 2.7525954408391966]
	TIME [epoch: 24.8 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5123776999953096		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 2.5123776999953096 | validation: 2.9971137756428634]
	TIME [epoch: 24.7 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.615985981576914		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 2.615985981576914 | validation: 2.7915122920469573]
	TIME [epoch: 24.8 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.522456455396		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 2.522456455396 | validation: 3.0265439714235334]
	TIME [epoch: 24.7 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.558041777412498		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 2.558041777412498 | validation: 2.9897780602538426]
	TIME [epoch: 24.7 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.546653150912737		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 2.546653150912737 | validation: 2.7553712379813713]
	TIME [epoch: 24.7 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5239957448693864		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 2.5239957448693864 | validation: 3.2906623461002953]
	TIME [epoch: 24.7 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5892310117274846		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 2.5892310117274846 | validation: 2.8373209552863123]
	TIME [epoch: 24.7 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5104860399691455		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 2.5104860399691455 | validation: 2.6114633024027287]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_303.pth
	Model improved!!!
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5507427213149843		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 2.5507427213149843 | validation: 2.707509068985367]
	TIME [epoch: 24.7 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3735851118420035		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 2.3735851118420035 | validation: 3.162963406238089]
	TIME [epoch: 24.7 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.533233020421452		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 2.533233020421452 | validation: 2.6725404561353296]
	TIME [epoch: 24.7 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.43432046416454		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 2.43432046416454 | validation: 2.7171107181947423]
	TIME [epoch: 24.7 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.449510029939015		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 2.449510029939015 | validation: 2.8029603478512297]
	TIME [epoch: 24.7 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5204570534264357		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 2.5204570534264357 | validation: 2.7384095048262727]
	TIME [epoch: 24.8 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.532749169404523		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 2.532749169404523 | validation: 2.6114258444832075]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_310.pth
	Model improved!!!
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.492659873269967		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 2.492659873269967 | validation: 2.6671306127214316]
	TIME [epoch: 24.7 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4585541828313735		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 2.4585541828313735 | validation: 2.654249169634103]
	TIME [epoch: 24.7 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.432791508674704		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 2.432791508674704 | validation: 2.694913845086858]
	TIME [epoch: 24.8 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4284784520419365		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 2.4284784520419365 | validation: 2.7367066369895032]
	TIME [epoch: 24.7 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.452804221690725		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 2.452804221690725 | validation: 2.6075666029454645]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_315.pth
	Model improved!!!
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.476074436349343		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 2.476074436349343 | validation: 2.7522739491964923]
	TIME [epoch: 24.8 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6234202490784932		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 2.6234202490784932 | validation: 2.687722907759452]
	TIME [epoch: 24.7 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4671480447226717		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 2.4671480447226717 | validation: 2.790914102412453]
	TIME [epoch: 24.7 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4479295550967524		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 2.4479295550967524 | validation: 2.94557842713862]
	TIME [epoch: 24.7 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.589542732861281		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 2.589542732861281 | validation: 2.6428781072290177]
	TIME [epoch: 24.7 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.430171797196305		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 2.430171797196305 | validation: 2.615454734844724]
	TIME [epoch: 24.8 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3918800483969913		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 2.3918800483969913 | validation: 2.694190180918268]
	TIME [epoch: 24.8 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.414807818833597		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 2.414807818833597 | validation: 2.808532843722418]
	TIME [epoch: 24.7 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5336354961194787		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 2.5336354961194787 | validation: 2.7132865084070263]
	TIME [epoch: 24.7 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.441482200370953		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 2.441482200370953 | validation: 2.723781571397237]
	TIME [epoch: 24.7 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4460278287125705		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 2.4460278287125705 | validation: 2.6477109566335826]
	TIME [epoch: 24.7 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4090868506020375		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 2.4090868506020375 | validation: 2.617211689884285]
	TIME [epoch: 24.7 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1762253830250575		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 3.1762253830250575 | validation: 2.7765038952692476]
	TIME [epoch: 24.7 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3905150135895785		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 2.3905150135895785 | validation: 2.659196898120522]
	TIME [epoch: 24.7 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.416539424841854		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 2.416539424841854 | validation: 2.722741809657193]
	TIME [epoch: 24.8 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4067478702262917		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 2.4067478702262917 | validation: 2.5878368149950153]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_331.pth
	Model improved!!!
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4043489819268355		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 2.4043489819268355 | validation: 2.8385060575469243]
	TIME [epoch: 24.7 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.448160625213827		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 2.448160625213827 | validation: 2.8630106494283325]
	TIME [epoch: 24.8 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4216297470971275		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 2.4216297470971275 | validation: 2.6735554650615776]
	TIME [epoch: 24.8 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4034665058330824		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 2.4034665058330824 | validation: 2.6531970284356845]
	TIME [epoch: 24.7 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.41533204395052		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 2.41533204395052 | validation: 2.7713209111846004]
	TIME [epoch: 24.8 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5939022532321507		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 2.5939022532321507 | validation: 2.95415715458906]
	TIME [epoch: 24.8 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4877205877140156		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 2.4877205877140156 | validation: 2.600127594869355]
	TIME [epoch: 24.7 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.421410270001698		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 2.421410270001698 | validation: 2.5632515379391965]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_339.pth
	Model improved!!!
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.414680564767215		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 2.414680564767215 | validation: 2.612981189768778]
	TIME [epoch: 24.8 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4283113971673878		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 2.4283113971673878 | validation: 2.659905876375491]
	TIME [epoch: 24.7 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.402385621219307		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 2.402385621219307 | validation: 2.6268331913398675]
	TIME [epoch: 24.8 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3816576559835143		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 2.3816576559835143 | validation: 2.7328837466187674]
	TIME [epoch: 24.8 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3823339539665023		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 2.3823339539665023 | validation: 2.8175964782591585]
	TIME [epoch: 24.7 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4259837285757913		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 2.4259837285757913 | validation: 2.5907433961657973]
	TIME [epoch: 24.8 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.407928244454437		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 2.407928244454437 | validation: 2.696553637235872]
	TIME [epoch: 24.8 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.42539857504864		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 2.42539857504864 | validation: 2.657671769006482]
	TIME [epoch: 24.7 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4204051291637576		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 2.4204051291637576 | validation: 2.6050430007357765]
	TIME [epoch: 24.8 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3893286357318937		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 2.3893286357318937 | validation: 2.6597478025060766]
	TIME [epoch: 24.8 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3670778406398005		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 2.3670778406398005 | validation: 2.6979785689165428]
	TIME [epoch: 24.7 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.399169661992963		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 2.399169661992963 | validation: 2.6536137152637016]
	TIME [epoch: 24.8 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4766727197221456		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 2.4766727197221456 | validation: 2.715705312238861]
	TIME [epoch: 24.8 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.341875164840062		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 2.341875164840062 | validation: 2.7964611083559725]
	TIME [epoch: 24.7 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.407939220983109		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 2.407939220983109 | validation: 2.851740175687951]
	TIME [epoch: 24.8 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.335765048743387		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 2.335765048743387 | validation: 2.6589147316693085]
	TIME [epoch: 24.8 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.386271216951398		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 2.386271216951398 | validation: 2.63494322495514]
	TIME [epoch: 24.7 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4143270251697966		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 2.4143270251697966 | validation: 2.8051730783372957]
	TIME [epoch: 24.8 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4545980721418634		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 2.4545980721418634 | validation: 2.7466350985461974]
	TIME [epoch: 24.8 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.521963396223561		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 2.521963396223561 | validation: 2.626230563504892]
	TIME [epoch: 24.7 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.401924306368155		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 2.401924306368155 | validation: 2.5720862714739643]
	TIME [epoch: 24.8 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5138514998755426		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 2.5138514998755426 | validation: 2.7050286542079016]
	TIME [epoch: 24.8 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.410469675075367		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 2.410469675075367 | validation: 2.9233468078179454]
	TIME [epoch: 24.7 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.44723203685056		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 2.44723203685056 | validation: 2.753912748276671]
	TIME [epoch: 24.8 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4121792249340825		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 2.4121792249340825 | validation: 2.5697227007365093]
	TIME [epoch: 24.8 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.375381720263605		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 2.375381720263605 | validation: 2.871618194229226]
	TIME [epoch: 24.7 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.473019446176536		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 2.473019446176536 | validation: 2.5438072365192053]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_366.pth
	Model improved!!!
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8967309575844333		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 2.8967309575844333 | validation: 2.5344354647594054]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_367.pth
	Model improved!!!
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4192339966112115		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 2.4192339966112115 | validation: 2.6322307734866826]
	TIME [epoch: 24.7 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3618123843042684		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 2.3618123843042684 | validation: 2.65491775999409]
	TIME [epoch: 24.8 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4200156059276052		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 2.4200156059276052 | validation: 2.5775850130112077]
	TIME [epoch: 24.8 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.445028052813238		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 2.445028052813238 | validation: 2.701471084825292]
	TIME [epoch: 24.7 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.314172658193385		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 2.314172658193385 | validation: 2.523790355383576]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_372.pth
	Model improved!!!
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3300644433722315		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 2.3300644433722315 | validation: 2.6516339044969577]
	TIME [epoch: 24.8 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.396094194910396		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 2.396094194910396 | validation: 2.554509697952934]
	TIME [epoch: 24.7 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3807470009177534		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 2.3807470009177534 | validation: 2.6611264023091223]
	TIME [epoch: 24.8 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.28450968651502		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 2.28450968651502 | validation: 2.6909324655743325]
	TIME [epoch: 24.7 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.317934804252685		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 2.317934804252685 | validation: 2.658251860212404]
	TIME [epoch: 24.7 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.313998740843295		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 2.313998740843295 | validation: 2.8382185021620323]
	TIME [epoch: 24.8 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3857627028049375		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 2.3857627028049375 | validation: 2.724573152773804]
	TIME [epoch: 24.7 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.348102001358924		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 2.348102001358924 | validation: 2.540149164309471]
	TIME [epoch: 24.7 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3627878614764986		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 2.3627878614764986 | validation: 2.719967340744184]
	TIME [epoch: 24.7 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3536404970108262		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 2.3536404970108262 | validation: 2.5246568445017217]
	TIME [epoch: 24.7 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3052997814875287		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 2.3052997814875287 | validation: 2.567506082650581]
	TIME [epoch: 24.7 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.322544233731446		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 2.322544233731446 | validation: 2.6213175539284914]
	TIME [epoch: 24.7 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.405054686785033		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 2.405054686785033 | validation: 2.523320139689009]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_385.pth
	Model improved!!!
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2486665243289456		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 2.2486665243289456 | validation: 3.0448700652864296]
	TIME [epoch: 24.7 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.376890349336632		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 2.376890349336632 | validation: 2.6405617673978368]
	TIME [epoch: 24.7 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4190742731019914		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 2.4190742731019914 | validation: 2.685593165376838]
	TIME [epoch: 24.7 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4757802380346385		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 2.4757802380346385 | validation: 2.5059428519880838]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_389.pth
	Model improved!!!
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.336264753942602		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 2.336264753942602 | validation: 2.5650733140465207]
	TIME [epoch: 24.8 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3039436790961965		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 2.3039436790961965 | validation: 2.5133010293928386]
	TIME [epoch: 24.7 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2584619302436044		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 2.2584619302436044 | validation: 2.594566479009726]
	TIME [epoch: 24.7 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.291533622558213		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 2.291533622558213 | validation: 2.561409915867728]
	TIME [epoch: 24.7 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2929821127268335		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 2.2929821127268335 | validation: 2.6953755265711847]
	TIME [epoch: 24.8 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3773479669662723		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 2.3773479669662723 | validation: 2.5661994302002586]
	TIME [epoch: 24.8 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2640606672733887		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 2.2640606672733887 | validation: 2.616782057107323]
	TIME [epoch: 24.7 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3079499628537485		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 2.3079499628537485 | validation: 2.628436789777063]
	TIME [epoch: 24.7 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2729409128316855		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 2.2729409128316855 | validation: 2.674773301314906]
	TIME [epoch: 24.7 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3987762552196514		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 2.3987762552196514 | validation: 2.8660830667878816]
	TIME [epoch: 24.8 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3494875069456294		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 2.3494875069456294 | validation: 2.5387934116975974]
	TIME [epoch: 24.7 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3412073652097156		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 2.3412073652097156 | validation: 2.8035752577780473]
	TIME [epoch: 24.7 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3210687326129715		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 2.3210687326129715 | validation: 2.5391646342157372]
	TIME [epoch: 24.8 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2803592522322274		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 2.2803592522322274 | validation: 2.5645339943508976]
	TIME [epoch: 24.7 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3802185415791755		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 2.3802185415791755 | validation: 2.5003901747940938]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_404.pth
	Model improved!!!
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4322304184414336		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 2.4322304184414336 | validation: 2.5616058826437587]
	TIME [epoch: 24.7 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3552767702328143		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 2.3552767702328143 | validation: 2.725117463985939]
	TIME [epoch: 24.7 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2880164358067563		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 2.2880164358067563 | validation: 2.563181994300781]
	TIME [epoch: 24.7 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3962745183226613		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 2.3962745183226613 | validation: 2.6219618432009577]
	TIME [epoch: 24.7 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2871869425041638		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 2.2871869425041638 | validation: 2.6130912742194106]
	TIME [epoch: 24.7 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2515046010611357		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 2.2515046010611357 | validation: 2.7126992344199268]
	TIME [epoch: 24.7 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.312155140324863		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 2.312155140324863 | validation: 2.6096667808844165]
	TIME [epoch: 24.7 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3919191366193218		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 2.3919191366193218 | validation: 2.5778279111650724]
	TIME [epoch: 24.7 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3771749062702243		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 2.3771749062702243 | validation: 2.4870984283230557]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_413.pth
	Model improved!!!
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2893409128439157		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 2.2893409128439157 | validation: 2.4905645372822396]
	TIME [epoch: 24.7 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.277818116358562		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 2.277818116358562 | validation: 2.5607739764107795]
	TIME [epoch: 24.7 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.256483708266611		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 2.256483708266611 | validation: 2.857575328742831]
	TIME [epoch: 24.7 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3577723800923507		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 2.3577723800923507 | validation: 2.5742307266431848]
	TIME [epoch: 24.7 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.283714495000319		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 2.283714495000319 | validation: 2.633718758001497]
	TIME [epoch: 24.7 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2971636635154034		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 2.2971636635154034 | validation: 2.6151364073112155]
	TIME [epoch: 24.7 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3014115726440143		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 2.3014115726440143 | validation: 2.5288635950060607]
	TIME [epoch: 24.7 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2557100082130943		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 2.2557100082130943 | validation: 2.5259521721227176]
	TIME [epoch: 24.7 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5928208221638975		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 2.5928208221638975 | validation: 2.783686405810483]
	TIME [epoch: 24.7 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3717167121960183		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 2.3717167121960183 | validation: 2.631103373936141]
	TIME [epoch: 24.7 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.290546707168917		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 2.290546707168917 | validation: 2.527986298875481]
	TIME [epoch: 24.7 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2616968351828364		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 2.2616968351828364 | validation: 2.9905743693767546]
	TIME [epoch: 24.7 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4940963356909185		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 2.4940963356909185 | validation: 2.959981906983109]
	TIME [epoch: 24.7 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.399710168028435		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 2.399710168028435 | validation: 3.047522636494051]
	TIME [epoch: 24.7 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3810104901514255		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 2.3810104901514255 | validation: 2.5854474194626254]
	TIME [epoch: 24.7 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2462189966608666		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 2.2462189966608666 | validation: 2.4763326606051512]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_429.pth
	Model improved!!!
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2422708989937057		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 2.2422708989937057 | validation: 2.958400617623052]
	TIME [epoch: 24.7 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3949099743054307		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 2.3949099743054307 | validation: 2.80278420987784]
	TIME [epoch: 24.8 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3312742579667725		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 2.3312742579667725 | validation: 2.55924302556888]
	TIME [epoch: 24.7 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3542693900153404		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 2.3542693900153404 | validation: 2.5573415245734963]
	TIME [epoch: 24.7 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.291468815265399		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 2.291468815265399 | validation: 2.6782875613195634]
	TIME [epoch: 24.8 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2927517089214167		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 2.2927517089214167 | validation: 2.4850138555633863]
	TIME [epoch: 24.8 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2495998320061417		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 2.2495998320061417 | validation: 2.652535232228237]
	TIME [epoch: 24.7 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3244548212393195		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 2.3244548212393195 | validation: 2.4799545567514687]
	TIME [epoch: 24.7 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.219225714805641		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 2.219225714805641 | validation: 2.566561601166151]
	TIME [epoch: 24.7 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.28563876501232		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 2.28563876501232 | validation: 2.482509810091625]
	TIME [epoch: 24.7 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.267519088551669		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 2.267519088551669 | validation: 2.4559150392367544]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_440.pth
	Model improved!!!
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2706087815018776		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 2.2706087815018776 | validation: 2.7797782350163143]
	TIME [epoch: 24.8 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.345595177797643		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 2.345595177797643 | validation: 2.5328478933052927]
	TIME [epoch: 24.7 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.254013388362643		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 2.254013388362643 | validation: 2.66285405391773]
	TIME [epoch: 24.8 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3904731467092315		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 2.3904731467092315 | validation: 2.724323322047105]
	TIME [epoch: 24.7 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3059502484963845		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 2.3059502484963845 | validation: 2.656759436521824]
	TIME [epoch: 24.7 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.286467527773513		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 2.286467527773513 | validation: 2.4955710597587273]
	TIME [epoch: 24.7 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2438299287928025		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 2.2438299287928025 | validation: 2.4799206271380068]
	TIME [epoch: 24.7 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.23224439719827		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 2.23224439719827 | validation: 2.5802208129939834]
	TIME [epoch: 24.7 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2559057318121822		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 2.2559057318121822 | validation: 2.4735671688351135]
	TIME [epoch: 24.7 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3014626841553074		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 2.3014626841553074 | validation: 2.5300518577585986]
	TIME [epoch: 24.7 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2392766356781864		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 2.2392766356781864 | validation: 2.475202707444111]
	TIME [epoch: 24.7 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.271055810888753		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 2.271055810888753 | validation: 2.4804882288925327]
	TIME [epoch: 24.7 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4207133417564237		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 2.4207133417564237 | validation: 2.591627924740262]
	TIME [epoch: 24.7 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.286387634267932		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 2.286387634267932 | validation: 2.737236545887314]
	TIME [epoch: 24.8 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.260570045852399		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 2.260570045852399 | validation: 2.4495480202996127]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_455.pth
	Model improved!!!
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3814643137269726		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 2.3814643137269726 | validation: 2.550121599449219]
	TIME [epoch: 24.7 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3594265599448296		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 2.3594265599448296 | validation: 2.6754522989275915]
	TIME [epoch: 24.7 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2278234396490726		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 2.2278234396490726 | validation: 2.6344112194892033]
	TIME [epoch: 24.8 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2441779804057798		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 2.2441779804057798 | validation: 2.4476125857773474]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_459.pth
	Model improved!!!
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.268454870054632		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 2.268454870054632 | validation: 2.7224755772047162]
	TIME [epoch: 24.7 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2941463137468987		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 2.2941463137468987 | validation: 2.5603985202015656]
	TIME [epoch: 24.7 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2264535816594253		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 2.2264535816594253 | validation: 2.542860407048811]
	TIME [epoch: 24.7 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2178197328180937		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 2.2178197328180937 | validation: 2.4736971235763794]
	TIME [epoch: 24.7 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2864380111480664		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 2.2864380111480664 | validation: 2.4509716879065855]
	TIME [epoch: 24.7 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2527185301160615		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 2.2527185301160615 | validation: 2.4865789384991825]
	TIME [epoch: 24.7 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3001361697573492		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 2.3001361697573492 | validation: 2.6599945018500057]
	TIME [epoch: 24.7 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.250388958292314		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 2.250388958292314 | validation: 2.446724674823837]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_467.pth
	Model improved!!!
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2219365798128474		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 2.2219365798128474 | validation: 2.4367604288391163]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_468.pth
	Model improved!!!
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1850694071319636		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 2.1850694071319636 | validation: 2.6892231229695462]
	TIME [epoch: 24.7 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2764648760050856		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 2.2764648760050856 | validation: 2.527445074683985]
	TIME [epoch: 24.7 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.201729963493658		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 2.201729963493658 | validation: 2.6158825138475827]
	TIME [epoch: 24.7 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.284898139814148		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 2.284898139814148 | validation: 2.7792812540540535]
	TIME [epoch: 24.7 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3276657512691155		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 2.3276657512691155 | validation: 2.442405304480259]
	TIME [epoch: 24.7 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.217254147893617		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 2.217254147893617 | validation: 2.474167418539722]
	TIME [epoch: 24.7 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1829998333587017		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 2.1829998333587017 | validation: 2.475836377988047]
	TIME [epoch: 24.7 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.375789782217349		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 2.375789782217349 | validation: 2.4748557617019644]
	TIME [epoch: 24.7 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3125504222466495		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 2.3125504222466495 | validation: 2.4803220717943875]
	TIME [epoch: 24.7 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2014876426416974		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 2.2014876426416974 | validation: 2.4504835087896417]
	TIME [epoch: 24.7 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2078711727012608		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 2.2078711727012608 | validation: 2.622767484405059]
	TIME [epoch: 24.7 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2748895544947363		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 2.2748895544947363 | validation: 2.470231377772815]
	TIME [epoch: 24.7 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2354752964224955		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 2.2354752964224955 | validation: 2.556240557577237]
	TIME [epoch: 24.7 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.325426327334307		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 2.325426327334307 | validation: 2.55286874040705]
	TIME [epoch: 24.8 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2497079517861813		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 2.2497079517861813 | validation: 2.4631741350292042]
	TIME [epoch: 24.7 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1958516658944705		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 2.1958516658944705 | validation: 2.674257020591832]
	TIME [epoch: 24.7 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.318965594439411		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 2.318965594439411 | validation: 2.4550259684436573]
	TIME [epoch: 24.8 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2396521715893414		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 2.2396521715893414 | validation: 2.502755631354855]
	TIME [epoch: 24.7 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.216511987466298		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 2.216511987466298 | validation: 2.597640695440351]
	TIME [epoch: 24.7 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2041528761763365		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 2.2041528761763365 | validation: 2.4268883704010604]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_488.pth
	Model improved!!!
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2223514864288383		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 2.2223514864288383 | validation: 2.586767693961276]
	TIME [epoch: 24.7 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.347934689111933		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 2.347934689111933 | validation: 2.6536954654052214]
	TIME [epoch: 24.7 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3107806773050656		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 2.3107806773050656 | validation: 2.558811737863501]
	TIME [epoch: 24.7 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.21618880733219		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 2.21618880733219 | validation: 2.597489244495551]
	TIME [epoch: 24.7 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.28387074753382		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 2.28387074753382 | validation: 2.5592765600795047]
	TIME [epoch: 24.7 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.252581424187615		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 2.252581424187615 | validation: 2.6581977790957825]
	TIME [epoch: 24.7 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.271960678584843		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 2.271960678584843 | validation: 2.735023670821024]
	TIME [epoch: 24.7 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.28937523347566		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 2.28937523347566 | validation: 2.459871014775597]
	TIME [epoch: 24.7 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.180391736706503		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 2.180391736706503 | validation: 2.8079781261595422]
	TIME [epoch: 24.7 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.282770524547052		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 2.282770524547052 | validation: 2.43710314443398]
	TIME [epoch: 24.7 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2616333132231654		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 2.2616333132231654 | validation: 2.441077917639323]
	TIME [epoch: 24.7 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.303638856944264		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 2.303638856944264 | validation: 2.4439537367042106]
	TIME [epoch: 24.7 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.311358485625365		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 2.311358485625365 | validation: 2.544928226616288]
	TIME [epoch: 24.7 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2322763734304982		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 2.2322763734304982 | validation: 2.4246159906356697]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_502.pth
	Model improved!!!
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1844699730114816		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 2.1844699730114816 | validation: 2.4720960935675897]
	TIME [epoch: 24.7 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.211031062502477		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 2.211031062502477 | validation: 2.4804161397730953]
	TIME [epoch: 24.7 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2240163361010117		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 2.2240163361010117 | validation: 2.5389176409557748]
	TIME [epoch: 24.7 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.18820207121853		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 2.18820207121853 | validation: 2.5689246071981353]
	TIME [epoch: 24.7 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.242582606764961		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 2.242582606764961 | validation: 2.6742110262023333]
	TIME [epoch: 24.7 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.209094864671168		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 2.209094864671168 | validation: 2.5305201797466577]
	TIME [epoch: 24.7 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1686780979516342		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 2.1686780979516342 | validation: 2.540165712616877]
	TIME [epoch: 24.7 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2019886001875415		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 2.2019886001875415 | validation: 2.5282766255948066]
	TIME [epoch: 24.7 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3230289016758343		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 2.3230289016758343 | validation: 2.436341924909941]
	TIME [epoch: 24.7 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.218732670799382		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 2.218732670799382 | validation: 2.4361969647910304]
	TIME [epoch: 24.7 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.207789485510473		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 2.207789485510473 | validation: 2.559411760930841]
	TIME [epoch: 24.7 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2361318145957374		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 2.2361318145957374 | validation: 2.447918173744279]
	TIME [epoch: 24.7 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.218082192474108		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 2.218082192474108 | validation: 2.413167338991881]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_515.pth
	Model improved!!!
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1783926389782255		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 2.1783926389782255 | validation: 2.4394821766248227]
	TIME [epoch: 24.7 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1769746020039897		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 2.1769746020039897 | validation: 2.4385016121873857]
	TIME [epoch: 24.7 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3547974253840405		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 2.3547974253840405 | validation: 2.5597213625601936]
	TIME [epoch: 24.7 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2361750848200055		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 2.2361750848200055 | validation: 2.4088776497184203]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_519.pth
	Model improved!!!
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1733952170219895		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 2.1733952170219895 | validation: 2.417793535046426]
	TIME [epoch: 24.7 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2100258643275876		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 2.2100258643275876 | validation: 2.4586760293410648]
	TIME [epoch: 24.7 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2281357667841277		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 2.2281357667841277 | validation: 2.4561034902186263]
	TIME [epoch: 24.7 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1959983655428736		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 2.1959983655428736 | validation: 2.4692354911563172]
	TIME [epoch: 24.7 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.180065270301929		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 2.180065270301929 | validation: 2.4659542876634775]
	TIME [epoch: 24.7 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.207574040332606		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 2.207574040332606 | validation: 2.4111768483642346]
	TIME [epoch: 24.7 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1749689596216917		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 2.1749689596216917 | validation: 2.432300939632435]
	TIME [epoch: 24.7 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.278041547880772		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 2.278041547880772 | validation: 2.4500537876436836]
	TIME [epoch: 24.7 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2822980765321743		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 2.2822980765321743 | validation: 2.4091652183145973]
	TIME [epoch: 24.7 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.175105714745627		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 2.175105714745627 | validation: 2.4214408179437124]
	TIME [epoch: 24.7 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1857313036679997		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 2.1857313036679997 | validation: 2.4388303485398812]
	TIME [epoch: 24.7 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2100830482930096		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 2.2100830482930096 | validation: 2.5333694080618447]
	TIME [epoch: 24.7 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2144819188683806		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 2.2144819188683806 | validation: 2.4576614569542614]
	TIME [epoch: 24.7 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.229499807211411		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 2.229499807211411 | validation: 2.411376080915111]
	TIME [epoch: 24.7 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1674304470271304		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 2.1674304470271304 | validation: 2.412904939256695]
	TIME [epoch: 24.7 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.210303132681642		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 2.210303132681642 | validation: 2.4012756546692304]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_535.pth
	Model improved!!!
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.15667635541941		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 2.15667635541941 | validation: 2.4221358607836856]
	TIME [epoch: 24.7 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2531931455242846		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 2.2531931455242846 | validation: 2.55329254091642]
	TIME [epoch: 24.7 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2477604174882817		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 2.2477604174882817 | validation: 2.44142239707327]
	TIME [epoch: 24.7 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.181164951617591		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 2.181164951617591 | validation: 2.5220901990800857]
	TIME [epoch: 24.7 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.210101610226004		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 2.210101610226004 | validation: 2.4701404448585853]
	TIME [epoch: 24.7 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2405295462956887		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 2.2405295462956887 | validation: 2.467311158430814]
	TIME [epoch: 24.7 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.183517123401118		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 2.183517123401118 | validation: 2.4347345427996063]
	TIME [epoch: 24.7 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1952419792948934		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 2.1952419792948934 | validation: 2.4087404709500926]
	TIME [epoch: 24.7 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1759784010247714		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 2.1759784010247714 | validation: 2.439134449419321]
	TIME [epoch: 24.7 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.250152382178109		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 2.250152382178109 | validation: 2.563457081184704]
	TIME [epoch: 24.7 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.270948565090347		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 2.270948565090347 | validation: 2.5083733852739387]
	TIME [epoch: 24.7 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1975615531873953		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 2.1975615531873953 | validation: 2.4399226936731218]
	TIME [epoch: 24.7 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1972768016755544		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 2.1972768016755544 | validation: 2.394104610060609]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_548.pth
	Model improved!!!
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.221337792352578		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 2.221337792352578 | validation: 2.43017302138058]
	TIME [epoch: 24.7 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2024735521793626		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 2.2024735521793626 | validation: 2.437593268270758]
	TIME [epoch: 24.7 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1692952090603583		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 2.1692952090603583 | validation: 2.444953711303361]
	TIME [epoch: 24.7 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.244856955812306		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 2.244856955812306 | validation: 2.502969880575145]
	TIME [epoch: 24.7 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.188268101460684		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 2.188268101460684 | validation: 2.405801705473694]
	TIME [epoch: 24.7 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.160490743526203		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 2.160490743526203 | validation: 2.4239503814292753]
	TIME [epoch: 24.7 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1463437181428255		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 2.1463437181428255 | validation: 2.4551200524831636]
	TIME [epoch: 24.7 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2557208583467214		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 2.2557208583467214 | validation: 2.4279659422774147]
	TIME [epoch: 24.7 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1714204753671997		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 2.1714204753671997 | validation: 2.4096797527083855]
	TIME [epoch: 24.7 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.143981283868544		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 2.143981283868544 | validation: 2.4338003618217385]
	TIME [epoch: 24.7 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.290702369701996		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 2.290702369701996 | validation: 2.45045476082657]
	TIME [epoch: 24.7 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1800003045824394		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 2.1800003045824394 | validation: 2.484671417039472]
	TIME [epoch: 24.7 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.173631855401812		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 2.173631855401812 | validation: 2.4902654804369058]
	TIME [epoch: 24.7 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.170454361197856		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 2.170454361197856 | validation: 2.4846059280989015]
	TIME [epoch: 24.7 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.191476288634165		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 2.191476288634165 | validation: 2.4084657790109607]
	TIME [epoch: 24.7 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2025507125829757		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 2.2025507125829757 | validation: 2.4092474265825197]
	TIME [epoch: 24.7 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1913960113290583		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 2.1913960113290583 | validation: 2.4005310419556554]
	TIME [epoch: 24.7 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.138351298458482		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 2.138351298458482 | validation: 2.5809452746067905]
	TIME [epoch: 24.7 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1757362688109723		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 2.1757362688109723 | validation: 2.5504031756009082]
	TIME [epoch: 24.7 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.183962355679272		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 2.183962355679272 | validation: 2.399870355784905]
	TIME [epoch: 24.7 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.13553205446037		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 2.13553205446037 | validation: 2.5549262825205923]
	TIME [epoch: 24.7 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.25377442943822		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 2.25377442943822 | validation: 2.534874824921933]
	TIME [epoch: 24.7 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1687807254640052		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 2.1687807254640052 | validation: 2.4251855988700375]
	TIME [epoch: 24.7 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1509353393569555		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 2.1509353393569555 | validation: 2.4764204256001543]
	TIME [epoch: 24.7 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.222719576538695		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 2.222719576538695 | validation: 2.4270939700453282]
	TIME [epoch: 24.7 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.168533783200523		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 2.168533783200523 | validation: 2.41742532280935]
	TIME [epoch: 24.7 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1947634571893238		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 2.1947634571893238 | validation: 2.4271890248861316]
	TIME [epoch: 24.7 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.142128046533236		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 2.142128046533236 | validation: 2.585069354201526]
	TIME [epoch: 24.7 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3532464504408734		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 2.3532464504408734 | validation: 2.791333188008143]
	TIME [epoch: 24.7 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.254381135450942		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 2.254381135450942 | validation: 2.4196134437942107]
	TIME [epoch: 24.7 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.154035740631564		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 2.154035740631564 | validation: 2.399576506800885]
	TIME [epoch: 24.7 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.154503587771796		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 2.154503587771796 | validation: 2.4991389872946157]
	TIME [epoch: 24.7 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.178676888946914		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 2.178676888946914 | validation: 2.405999712972549]
	TIME [epoch: 24.7 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2597493437608915		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 2.2597493437608915 | validation: 2.6422225048186045]
	TIME [epoch: 24.7 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1939807043416057		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 2.1939807043416057 | validation: 2.4201067528374107]
	TIME [epoch: 24.8 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1678677296770648		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 2.1678677296770648 | validation: 2.4238003657482543]
	TIME [epoch: 24.7 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.129946174308923		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 2.129946174308923 | validation: 2.5468926648585914]
	TIME [epoch: 24.7 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.207848290866791		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 2.207848290866791 | validation: 2.530500909523983]
	TIME [epoch: 24.8 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1503057394903964		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 2.1503057394903964 | validation: 2.4098407393918855]
	TIME [epoch: 24.7 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1157899907652817		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 2.1157899907652817 | validation: 2.5207149260524346]
	TIME [epoch: 24.7 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.177438193518272		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 2.177438193518272 | validation: 2.394898029688178]
	TIME [epoch: 24.8 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.143527168365562		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 2.143527168365562 | validation: 2.3810976548684284]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_590.pth
	Model improved!!!
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.194194358874283		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 2.194194358874283 | validation: 2.3828134875132925]
	TIME [epoch: 24.7 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2341425286582437		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 2.2341425286582437 | validation: 2.4233568854028293]
	TIME [epoch: 24.8 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2070413448269877		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 2.2070413448269877 | validation: 2.4476404443290183]
	TIME [epoch: 24.8 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.146446613118824		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 2.146446613118824 | validation: 2.470622470449173]
	TIME [epoch: 24.7 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.149240409806268		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 2.149240409806268 | validation: 2.438026828457972]
	TIME [epoch: 24.8 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1459322335704716		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 2.1459322335704716 | validation: 2.421167797358794]
	TIME [epoch: 24.7 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.14137096936426		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 2.14137096936426 | validation: 2.4438257888950456]
	TIME [epoch: 24.8 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.143137812015611		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 2.143137812015611 | validation: 2.6309424234670122]
	TIME [epoch: 24.8 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2300545126855353		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 2.2300545126855353 | validation: 2.3955647662943296]
	TIME [epoch: 24.8 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.149323169876415		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 2.149323169876415 | validation: 2.5644237374820342]
	TIME [epoch: 24.8 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1970152073003466		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 2.1970152073003466 | validation: 2.415433329040352]
	TIME [epoch: 24.8 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.146716599919291		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 2.146716599919291 | validation: 2.3941836821776326]
	TIME [epoch: 24.7 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1297764484068558		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 2.1297764484068558 | validation: 2.44669343055884]
	TIME [epoch: 24.7 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1340475888389667		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 2.1340475888389667 | validation: 2.407167671237547]
	TIME [epoch: 24.7 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1448753781392123		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 2.1448753781392123 | validation: 2.50408479918448]
	TIME [epoch: 24.7 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.174780424164557		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 2.174780424164557 | validation: 2.443698385929182]
	TIME [epoch: 24.8 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.133601947416442		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 2.133601947416442 | validation: 2.5267851229973024]
	TIME [epoch: 24.7 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.149751555630881		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 2.149751555630881 | validation: 2.4210781719043393]
	TIME [epoch: 24.7 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1455520204098684		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 2.1455520204098684 | validation: 2.395984998113208]
	TIME [epoch: 24.7 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1278613191861306		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 2.1278613191861306 | validation: 2.426648596772402]
	TIME [epoch: 24.8 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.127587355148644		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 2.127587355148644 | validation: 2.5411629425595432]
	TIME [epoch: 24.7 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.181816939560545		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 2.181816939560545 | validation: 2.405042037467552]
	TIME [epoch: 24.7 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1525846772544397		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 2.1525846772544397 | validation: 2.4480708490765553]
	TIME [epoch: 24.7 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2038648297282295		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 2.2038648297282295 | validation: 2.390741575893336]
	TIME [epoch: 24.7 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1377584824877243		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 2.1377584824877243 | validation: 2.459122374261812]
	TIME [epoch: 24.7 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1187193192385507		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 2.1187193192385507 | validation: 2.381769573262114]
	TIME [epoch: 24.8 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.158375844320474		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 2.158375844320474 | validation: 2.42300078692671]
	TIME [epoch: 24.7 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1214659727840695		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 2.1214659727840695 | validation: 2.4016891625587817]
	TIME [epoch: 24.7 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.139026148055936		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 2.139026148055936 | validation: 2.5231861766018917]
	TIME [epoch: 24.7 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1469932755374175		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 2.1469932755374175 | validation: 2.439101503311463]
	TIME [epoch: 24.8 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1316700998644267		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 2.1316700998644267 | validation: 2.405651787956716]
	TIME [epoch: 24.7 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.126078427737315		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 2.126078427737315 | validation: 2.4713469101016265]
	TIME [epoch: 24.8 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.160566690185174		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 2.160566690185174 | validation: 2.40236665212388]
	TIME [epoch: 24.7 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1366394631844448		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 2.1366394631844448 | validation: 2.4653647225914237]
	TIME [epoch: 24.8 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1376336944259458		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 2.1376336944259458 | validation: 2.397670332961157]
	TIME [epoch: 24.7 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1370222517478314		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 2.1370222517478314 | validation: 2.3963110408576673]
	TIME [epoch: 24.7 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.146237430140593		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 2.146237430140593 | validation: 2.448190701328974]
	TIME [epoch: 24.7 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.147727483239585		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 2.147727483239585 | validation: 2.4292838936645125]
	TIME [epoch: 24.7 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1217354075574884		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 2.1217354075574884 | validation: 2.3887270468781128]
	TIME [epoch: 24.7 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.153644049176612		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 2.153644049176612 | validation: 2.414672901979951]
	TIME [epoch: 24.7 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1153839143688744		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 2.1153839143688744 | validation: 2.3955204594055135]
	TIME [epoch: 24.7 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1062310939063154		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 2.1062310939063154 | validation: 2.3922537720907413]
	TIME [epoch: 24.7 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1285193436982204		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 2.1285193436982204 | validation: 2.4202222943861735]
	TIME [epoch: 24.7 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1262734978124294		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 2.1262734978124294 | validation: 2.633818374701235]
	TIME [epoch: 24.7 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.172884413714149		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 2.172884413714149 | validation: 2.3841051931963015]
	TIME [epoch: 24.7 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1060280626367507		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 2.1060280626367507 | validation: 2.520919409381005]
	TIME [epoch: 24.8 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.204220284477864		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 2.204220284477864 | validation: 2.4344851387549364]
	TIME [epoch: 24.8 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.116267963487136		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 2.116267963487136 | validation: 2.4206970012052955]
	TIME [epoch: 24.8 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1270145514665613		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 2.1270145514665613 | validation: 2.5670266009610856]
	TIME [epoch: 24.8 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1494978577090795		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 2.1494978577090795 | validation: 2.40081641625958]
	TIME [epoch: 24.8 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1347414243164113		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 2.1347414243164113 | validation: 2.5137342372773017]
	TIME [epoch: 24.7 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1437177387508966		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 2.1437177387508966 | validation: 2.458469246540409]
	TIME [epoch: 24.8 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1614415514516283		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 2.1614415514516283 | validation: 2.439250747312111]
	TIME [epoch: 24.7 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1942424314057742		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 2.1942424314057742 | validation: 2.432852110682591]
	TIME [epoch: 24.7 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.140424221394118		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 2.140424221394118 | validation: 2.4617941610249683]
	TIME [epoch: 24.7 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1305356474874575		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 2.1305356474874575 | validation: 2.440980962289886]
	TIME [epoch: 24.7 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1356281264747143		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 2.1356281264747143 | validation: 2.398927174575456]
	TIME [epoch: 24.7 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.100239708632578		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 2.100239708632578 | validation: 2.410656064223258]
	TIME [epoch: 24.7 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.12098168492816		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 2.12098168492816 | validation: 2.3977483193100757]
	TIME [epoch: 24.8 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1228479598261503		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 2.1228479598261503 | validation: 2.407521298150528]
	TIME [epoch: 24.7 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1421333142761294		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 2.1421333142761294 | validation: 2.4552881187979674]
	TIME [epoch: 24.7 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2137665571209597		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 2.2137665571209597 | validation: 2.6153357606669867]
	TIME [epoch: 24.7 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2083303664367087		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 2.2083303664367087 | validation: 2.4211812315726187]
	TIME [epoch: 24.7 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.121974932924899		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 2.121974932924899 | validation: 2.4189711072635336]
	TIME [epoch: 24.8 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.131849322021614		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 2.131849322021614 | validation: 2.366178625080854]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_655.pth
	Model improved!!!
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1176399407866526		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 2.1176399407866526 | validation: 2.37983582774122]
	TIME [epoch: 24.7 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.124931076167747		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 2.124931076167747 | validation: 2.471523665219394]
	TIME [epoch: 24.7 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.110400984026006		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 2.110400984026006 | validation: 2.3979733454777827]
	TIME [epoch: 24.7 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.123394873239003		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 2.123394873239003 | validation: 2.3979655104074613]
	TIME [epoch: 24.7 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.205076945624113		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 2.205076945624113 | validation: 2.4378934786197037]
	TIME [epoch: 24.7 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.147550248619962		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 2.147550248619962 | validation: 2.377364066277582]
	TIME [epoch: 24.7 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0994653281946856		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 2.0994653281946856 | validation: 2.384516935010729]
	TIME [epoch: 24.7 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.115501697122497		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 2.115501697122497 | validation: 2.4103255034488362]
	TIME [epoch: 24.7 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1266438930736395		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 2.1266438930736395 | validation: 2.4078500215076066]
	TIME [epoch: 24.7 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1831830890805923		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 2.1831830890805923 | validation: 2.416537399395592]
	TIME [epoch: 24.7 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.144837197290219		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 2.144837197290219 | validation: 2.4211845334725415]
	TIME [epoch: 24.7 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1708793858013236		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 2.1708793858013236 | validation: 2.4006830339472693]
	TIME [epoch: 24.7 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.115275764273501		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 2.115275764273501 | validation: 2.5435999096945276]
	TIME [epoch: 24.7 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.165255231712046		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 2.165255231712046 | validation: 2.3933852320780216]
	TIME [epoch: 24.7 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1390157835254104		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 2.1390157835254104 | validation: 2.41679293075825]
	TIME [epoch: 24.7 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1147073075441547		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 2.1147073075441547 | validation: 2.387728422918196]
	TIME [epoch: 24.7 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.097410782145944		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 2.097410782145944 | validation: 2.376162359089479]
	TIME [epoch: 24.7 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.118317552381761		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 2.118317552381761 | validation: 2.4106021819885797]
	TIME [epoch: 24.7 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1323682411334337		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 2.1323682411334337 | validation: 2.420399939110743]
	TIME [epoch: 24.7 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1235604524227156		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 2.1235604524227156 | validation: 2.3647734189911067]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_675.pth
	Model improved!!!
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.130732844627569		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 2.130732844627569 | validation: 2.409183332913821]
	TIME [epoch: 24.7 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1239859666760132		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 2.1239859666760132 | validation: 2.383887338601887]
	TIME [epoch: 24.7 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.108314865466528		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 2.108314865466528 | validation: 2.4031497224855807]
	TIME [epoch: 24.7 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.149490569859524		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 2.149490569859524 | validation: 2.382769676645628]
	TIME [epoch: 24.7 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.131838070211222		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 2.131838070211222 | validation: 2.392806930873142]
	TIME [epoch: 24.7 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1012190380149187		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 2.1012190380149187 | validation: 2.552918525372701]
	TIME [epoch: 24.7 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.152760294228746		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 2.152760294228746 | validation: 2.424425667632948]
	TIME [epoch: 24.7 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0941552576835836		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 2.0941552576835836 | validation: 2.476317739709656]
	TIME [epoch: 24.7 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.133979622760365		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 2.133979622760365 | validation: 2.397622859364799]
	TIME [epoch: 24.7 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.15051841330647		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 2.15051841330647 | validation: 2.420591014224946]
	TIME [epoch: 24.7 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1709468117224873		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 2.1709468117224873 | validation: 2.374448188391349]
	TIME [epoch: 24.7 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.096416608621844		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 2.096416608621844 | validation: 2.4395875058125758]
	TIME [epoch: 24.7 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1439371594072036		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 2.1439371594072036 | validation: 2.4196002258526685]
	TIME [epoch: 24.7 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1122416739600602		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 2.1122416739600602 | validation: 2.3842900595901275]
	TIME [epoch: 24.7 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1057378553167583		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 2.1057378553167583 | validation: 2.389771820944353]
	TIME [epoch: 24.7 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1072313892674437		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 2.1072313892674437 | validation: 2.3748913911047347]
	TIME [epoch: 24.7 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.109496234127934		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 2.109496234127934 | validation: 2.391957385945471]
	TIME [epoch: 24.7 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1495434022530335		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 2.1495434022530335 | validation: 2.428807841627599]
	TIME [epoch: 24.7 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.106073752994126		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 2.106073752994126 | validation: 2.387317457209924]
	TIME [epoch: 24.7 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1201990757931015		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 2.1201990757931015 | validation: 2.3700369667695034]
	TIME [epoch: 24.7 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.095076069525219		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 2.095076069525219 | validation: 2.4385847434890544]
	TIME [epoch: 24.7 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1270717298347743		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 2.1270717298347743 | validation: 2.4672552690223264]
	TIME [epoch: 24.7 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.108610709240164		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 2.108610709240164 | validation: 2.376420435216472]
	TIME [epoch: 24.7 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1051306589717704		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 2.1051306589717704 | validation: 2.36924620964522]
	TIME [epoch: 24.7 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1070493560826016		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 2.1070493560826016 | validation: 2.3933724489363364]
	TIME [epoch: 24.7 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1015564978535903		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 2.1015564978535903 | validation: 2.481585118445118]
	TIME [epoch: 24.7 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1127604461181955		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 2.1127604461181955 | validation: 2.5521753462596637]
	TIME [epoch: 24.7 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.174263999613838		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 2.174263999613838 | validation: 2.383047279366884]
	TIME [epoch: 24.7 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1151497591581894		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 2.1151497591581894 | validation: 2.408532820726169]
	TIME [epoch: 24.7 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.123599621795785		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 2.123599621795785 | validation: 2.436069714464868]
	TIME [epoch: 24.7 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.120615633019823		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 2.120615633019823 | validation: 2.4285972284432984]
	TIME [epoch: 24.7 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.272533205649646		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 2.272533205649646 | validation: 2.4473209735409145]
	TIME [epoch: 24.7 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.099101524857715		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 2.099101524857715 | validation: 2.370787870986606]
	TIME [epoch: 24.7 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1011685486156644		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 2.1011685486156644 | validation: 2.388399695778569]
	TIME [epoch: 24.7 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.094024330229815		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 2.094024330229815 | validation: 2.4197237150661306]
	TIME [epoch: 24.7 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0840142619942075		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 2.0840142619942075 | validation: 2.3729936442156254]
	TIME [epoch: 24.7 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.165683983782914		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 2.165683983782914 | validation: 2.38687461199094]
	TIME [epoch: 24.7 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.139669134412104		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 2.139669134412104 | validation: 2.5792618141627526]
	TIME [epoch: 24.7 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1452786668686894		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 2.1452786668686894 | validation: 2.4045355975571105]
	TIME [epoch: 24.7 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1039274131217094		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 2.1039274131217094 | validation: 2.4282792183152333]
	TIME [epoch: 24.7 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1275232402443205		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 2.1275232402443205 | validation: 2.461677138819471]
	TIME [epoch: 24.7 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.135872999625975		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 2.135872999625975 | validation: 2.4774272759920417]
	TIME [epoch: 24.7 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1283717236213477		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 2.1283717236213477 | validation: 2.4510796613531203]
	TIME [epoch: 24.7 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.15074807513114		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 2.15074807513114 | validation: 2.384066417604471]
	TIME [epoch: 24.7 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.099995042709066		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 2.099995042709066 | validation: 2.379218182136394]
	TIME [epoch: 24.7 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.120755714251777		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 2.120755714251777 | validation: 2.4668397107090994]
	TIME [epoch: 24.7 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1473840773447646		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 2.1473840773447646 | validation: 2.4033855798743744]
	TIME [epoch: 24.7 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1183385006444215		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 2.1183385006444215 | validation: 2.3884357525002473]
	TIME [epoch: 24.7 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1210926261428673		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 2.1210926261428673 | validation: 2.3776280792113114]
	TIME [epoch: 24.7 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.100749112284494		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 2.100749112284494 | validation: 2.4138677124682504]
	TIME [epoch: 24.7 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.115629576806634		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 2.115629576806634 | validation: 2.3754447338252667]
	TIME [epoch: 24.7 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1322071803012435		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 2.1322071803012435 | validation: 2.534555456405638]
	TIME [epoch: 24.7 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.141266681050898		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 2.141266681050898 | validation: 2.3942888018162383]
	TIME [epoch: 24.7 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1368560068953624		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 2.1368560068953624 | validation: 2.4628175512441675]
	TIME [epoch: 24.7 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.110358628708504		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 2.110358628708504 | validation: 2.376781194860118]
	TIME [epoch: 24.7 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1045502426109186		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 2.1045502426109186 | validation: 2.3829111788508412]
	TIME [epoch: 24.7 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0981045942761067		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 2.0981045942761067 | validation: 2.420272226648724]
	TIME [epoch: 24.7 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1144673796507782		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 2.1144673796507782 | validation: 2.3609070697156755]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_733.pth
	Model improved!!!
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1585703913080274		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 2.1585703913080274 | validation: 2.485097723174905]
	TIME [epoch: 24.8 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.132240133021281		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 2.132240133021281 | validation: 2.423874900182132]
	TIME [epoch: 24.8 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.192690445244648		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 2.192690445244648 | validation: 2.610808439720524]
	TIME [epoch: 24.8 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.242854850366981		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 2.242854850366981 | validation: 2.436307903826874]
	TIME [epoch: 24.8 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.117741255420204		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 2.117741255420204 | validation: 2.402395848858159]
	TIME [epoch: 24.8 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1231590397951625		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 2.1231590397951625 | validation: 2.386622224540567]
	TIME [epoch: 24.8 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0969336613091283		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 2.0969336613091283 | validation: 2.3889143594557485]
	TIME [epoch: 24.8 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0870549652166557		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 2.0870549652166557 | validation: 2.397328252687411]
	TIME [epoch: 24.8 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1390190949609273		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 2.1390190949609273 | validation: 2.36639697716058]
	TIME [epoch: 24.8 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1511057560315896		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 2.1511057560315896 | validation: 2.397862387566462]
	TIME [epoch: 24.8 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1036918083999074		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 2.1036918083999074 | validation: 2.4124183144028075]
	TIME [epoch: 24.8 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0958973690983487		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 2.0958973690983487 | validation: 2.386076063351688]
	TIME [epoch: 24.8 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1073529797934496		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 2.1073529797934496 | validation: 2.401998981448362]
	TIME [epoch: 24.8 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0790020614887728		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 2.0790020614887728 | validation: 2.4267259236083465]
	TIME [epoch: 24.8 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1008334562925675		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 2.1008334562925675 | validation: 2.3913471742916093]
	TIME [epoch: 24.8 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0989701655108663		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 2.0989701655108663 | validation: 2.4623837423011645]
	TIME [epoch: 24.8 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1104540003816914		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 2.1104540003816914 | validation: 2.4401803171502956]
	TIME [epoch: 24.8 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.131166363946554		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 2.131166363946554 | validation: 2.4707076892343274]
	TIME [epoch: 24.8 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1171380298120077		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 2.1171380298120077 | validation: 2.4133899640565653]
	TIME [epoch: 24.8 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1198148261884473		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 2.1198148261884473 | validation: 2.608915478406566]
	TIME [epoch: 24.8 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1475667945035264		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 2.1475667945035264 | validation: 2.4059713124520377]
	TIME [epoch: 24.8 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1092871624916656		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 2.1092871624916656 | validation: 2.3879839967979994]
	TIME [epoch: 24.8 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0900685947789786		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 2.0900685947789786 | validation: 2.368212377631303]
	TIME [epoch: 24.8 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0997232576332387		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 2.0997232576332387 | validation: 2.358470407461971]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_757.pth
	Model improved!!!
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0835138145813827		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 2.0835138145813827 | validation: 2.475652254669]
	TIME [epoch: 24.8 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1164434330775737		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 2.1164434330775737 | validation: 2.3770580756464232]
	TIME [epoch: 24.8 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.130022583564567		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 2.130022583564567 | validation: 2.4229040892306775]
	TIME [epoch: 24.7 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.090471640605821		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 2.090471640605821 | validation: 2.347720267872461]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_761.pth
	Model improved!!!
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.087256667515634		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 2.087256667515634 | validation: 2.456563410316735]
	TIME [epoch: 24.8 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1397097498190143		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 2.1397097498190143 | validation: 2.3693328660571895]
	TIME [epoch: 24.8 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1093756299704705		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 2.1093756299704705 | validation: 2.365413548764503]
	TIME [epoch: 24.8 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1301164808942636		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 2.1301164808942636 | validation: 2.39413815389367]
	TIME [epoch: 24.8 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0984078555883214		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 2.0984078555883214 | validation: 2.3835220045274217]
	TIME [epoch: 24.8 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.09231063544827		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 2.09231063544827 | validation: 2.35809478707115]
	TIME [epoch: 24.7 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0921918889285713		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 2.0921918889285713 | validation: 2.3674943664287436]
	TIME [epoch: 24.8 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0933065953179577		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 2.0933065953179577 | validation: 2.354482936567887]
	TIME [epoch: 24.8 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.07692566625063		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 2.07692566625063 | validation: 2.392670017833432]
	TIME [epoch: 24.7 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1107709651214517		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 2.1107709651214517 | validation: 2.3908530630956837]
	TIME [epoch: 24.8 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.161345042100805		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 2.161345042100805 | validation: 2.4071180411616018]
	TIME [epoch: 24.8 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1090912882006156		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 2.1090912882006156 | validation: 2.363281215885984]
	TIME [epoch: 24.8 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0774962218579898		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 2.0774962218579898 | validation: 2.381865178648504]
	TIME [epoch: 24.8 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0766235537626683		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 2.0766235537626683 | validation: 2.3843312443932327]
	TIME [epoch: 24.7 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.076370826554448		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 2.076370826554448 | validation: 2.4844620750695072]
	TIME [epoch: 24.8 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.130860274285313		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 2.130860274285313 | validation: 2.398913004796028]
	TIME [epoch: 24.8 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.096107493463107		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 2.096107493463107 | validation: 2.3849505396872446]
	TIME [epoch: 24.8 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.077084126585815		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 2.077084126585815 | validation: 2.4297338852958514]
	TIME [epoch: 24.7 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1057594372545916		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 2.1057594372545916 | validation: 2.3840882632434983]
	TIME [epoch: 24.8 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0876492919143073		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 2.0876492919143073 | validation: 2.3849928730215346]
	TIME [epoch: 24.8 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1159253734947194		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 2.1159253734947194 | validation: 2.3835527963492416]
	TIME [epoch: 24.8 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.106004603037145		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 2.106004603037145 | validation: 2.362758102597845]
	TIME [epoch: 24.8 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0896824728400656		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 2.0896824728400656 | validation: 2.3606682340207685]
	TIME [epoch: 24.8 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.076506148584793		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 2.076506148584793 | validation: 2.4368592199649743]
	TIME [epoch: 24.8 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1044507944966435		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 2.1044507944966435 | validation: 2.350031465403707]
	TIME [epoch: 24.8 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.14234594198358		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 2.14234594198358 | validation: 2.408761892677928]
	TIME [epoch: 24.8 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.089757300606135		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 2.089757300606135 | validation: 2.354670043870013]
	TIME [epoch: 24.8 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.093306591636088		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 2.093306591636088 | validation: 2.36396080204463]
	TIME [epoch: 24.8 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0842302490060796		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 2.0842302490060796 | validation: 2.4110358416929847]
	TIME [epoch: 24.7 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0991128143394473		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 2.0991128143394473 | validation: 2.3848806467201062]
	TIME [epoch: 24.7 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0677138651255444		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 2.0677138651255444 | validation: 2.3544648674247135]
	TIME [epoch: 24.8 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.066171699230159		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 2.066171699230159 | validation: 2.472357143131761]
	TIME [epoch: 24.8 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1323667017209957		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 2.1323667017209957 | validation: 2.43426447288765]
	TIME [epoch: 24.8 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0938548846387732		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 2.0938548846387732 | validation: 2.4027698508985216]
	TIME [epoch: 24.8 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0997393625936485		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 2.0997393625936485 | validation: 2.356399787511127]
	TIME [epoch: 24.8 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.100985965575419		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 2.100985965575419 | validation: 2.3566177129339834]
	TIME [epoch: 24.8 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0998842534280424		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 2.0998842534280424 | validation: 2.4054038345668753]
	TIME [epoch: 24.8 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1064852495755693		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 2.1064852495755693 | validation: 2.3544307596092207]
	TIME [epoch: 24.7 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0978732490789884		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 2.0978732490789884 | validation: 2.433118607100187]
	TIME [epoch: 24.8 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0852663190116885		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 2.0852663190116885 | validation: 2.356401217861843]
	TIME [epoch: 24.7 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.110945787220535		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 2.110945787220535 | validation: 2.375303345590741]
	TIME [epoch: 24.8 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.088840177005709		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 2.088840177005709 | validation: 2.370982900722707]
	TIME [epoch: 24.8 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.115862447206626		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 2.115862447206626 | validation: 2.3596634404812513]
	TIME [epoch: 24.8 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.089734418035544		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 2.089734418035544 | validation: 2.396533570525704]
	TIME [epoch: 24.7 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0739413743377626		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 2.0739413743377626 | validation: 2.3611051365592592]
	TIME [epoch: 24.8 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0925717357291855		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 2.0925717357291855 | validation: 2.3558680300534465]
	TIME [epoch: 24.8 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.074407495780807		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 2.074407495780807 | validation: 2.4152300709824552]
	TIME [epoch: 24.8 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0985761352802563		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 2.0985761352802563 | validation: 2.393055917107358]
	TIME [epoch: 24.7 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.085513844517185		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 2.085513844517185 | validation: 2.369429821944479]
	TIME [epoch: 24.8 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0902775817885826		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 2.0902775817885826 | validation: 2.471492641299324]
	TIME [epoch: 24.7 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.105746527608768		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 2.105746527608768 | validation: 2.3715912312910694]
	TIME [epoch: 24.7 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.091082915603474		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 2.091082915603474 | validation: 2.3637269581923035]
	TIME [epoch: 24.8 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0867697947977026		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 2.0867697947977026 | validation: 2.3958343737646475]
	TIME [epoch: 24.7 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0940105098216146		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 2.0940105098216146 | validation: 2.3949941098495096]
	TIME [epoch: 24.8 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.125720680071007		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 2.125720680071007 | validation: 2.4280313691954976]
	TIME [epoch: 24.8 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0873707474705476		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 2.0873707474705476 | validation: 2.3559699021801936]
	TIME [epoch: 24.7 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.081432893869718		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 2.081432893869718 | validation: 2.3681084349485646]
	TIME [epoch: 24.7 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0717046840608706		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 2.0717046840608706 | validation: 2.365721024463135]
	TIME [epoch: 24.7 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0842914729337956		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 2.0842914729337956 | validation: 2.352602473159259]
	TIME [epoch: 24.7 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0659844936382696		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 2.0659844936382696 | validation: 2.4022695910563834]
	TIME [epoch: 24.7 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0962417657563117		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 2.0962417657563117 | validation: 2.3660088843788922]
	TIME [epoch: 24.8 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.065868544251444		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 2.065868544251444 | validation: 2.384993814859309]
	TIME [epoch: 24.7 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.068570933283773		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 2.068570933283773 | validation: 2.384150425614152]
	TIME [epoch: 24.7 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.079973960854309		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 2.079973960854309 | validation: 2.3590533305233206]
	TIME [epoch: 24.8 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0638380101316103		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 2.0638380101316103 | validation: 2.353112303962838]
	TIME [epoch: 24.7 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1059637356308123		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 2.1059637356308123 | validation: 2.3556429166438826]
	TIME [epoch: 24.7 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0908614562372994		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 2.0908614562372994 | validation: 2.357007239097012]
	TIME [epoch: 24.7 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0770335208888944		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 2.0770335208888944 | validation: 2.351904657624926]
	TIME [epoch: 24.7 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0727155228685796		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 2.0727155228685796 | validation: 2.3838056901570646]
	TIME [epoch: 24.7 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.092259527347279		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 2.092259527347279 | validation: 2.3965625369728323]
	TIME [epoch: 24.7 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.099035095778357		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 2.099035095778357 | validation: 2.349979022119135]
	TIME [epoch: 24.7 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.062499772208833		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 2.062499772208833 | validation: 2.356743890875856]
	TIME [epoch: 24.8 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0621609217146224		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 2.0621609217146224 | validation: 2.347148215406901]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_834.pth
	Model improved!!!
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1022450897754297		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 2.1022450897754297 | validation: 2.369118577172357]
	TIME [epoch: 24.7 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.075934848850888		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 2.075934848850888 | validation: 2.349493338844807]
	TIME [epoch: 24.8 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.07523596830051		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 2.07523596830051 | validation: 2.384828416798031]
	TIME [epoch: 24.8 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.08820200338121		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 2.08820200338121 | validation: 2.3827684637373254]
	TIME [epoch: 24.8 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1187873389700003		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 2.1187873389700003 | validation: 2.3438084276134687]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_839.pth
	Model improved!!!
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.078414983920588		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 2.078414983920588 | validation: 2.3512534841709805]
	TIME [epoch: 24.7 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0836161383212444		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 2.0836161383212444 | validation: 2.345362234134551]
	TIME [epoch: 24.7 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.060365729502512		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 2.060365729502512 | validation: 2.350363717523554]
	TIME [epoch: 24.8 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0693603098131828		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 2.0693603098131828 | validation: 2.3632421704070765]
	TIME [epoch: 24.7 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0772443474499602		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 2.0772443474499602 | validation: 2.399599976093421]
	TIME [epoch: 24.7 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.253788355921632		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 2.253788355921632 | validation: 2.362809816735275]
	TIME [epoch: 24.7 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0874257244488787		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 2.0874257244488787 | validation: 2.3730700769727426]
	TIME [epoch: 24.8 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.083867966698447		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 2.083867966698447 | validation: 2.3511102279349916]
	TIME [epoch: 24.7 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0646997214887137		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 2.0646997214887137 | validation: 2.3842497552266613]
	TIME [epoch: 24.7 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.085677200291134		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 2.085677200291134 | validation: 2.3473955019008286]
	TIME [epoch: 24.8 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.07489735219853		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 2.07489735219853 | validation: 2.379811807274558]
	TIME [epoch: 24.7 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0631304709031464		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 2.0631304709031464 | validation: 2.361209182529806]
	TIME [epoch: 24.8 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0891765417818786		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 2.0891765417818786 | validation: 2.3738440514273544]
	TIME [epoch: 24.7 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.075966004214261		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 2.075966004214261 | validation: 2.375208807748375]
	TIME [epoch: 24.7 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.066581336069788		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 2.066581336069788 | validation: 2.346706463327312]
	TIME [epoch: 24.7 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0690243515737974		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 2.0690243515737974 | validation: 2.3646842290822114]
	TIME [epoch: 24.7 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0676544277003557		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 2.0676544277003557 | validation: 2.3392545408235286]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_856.pth
	Model improved!!!
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.069573700474161		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 2.069573700474161 | validation: 2.3730203794930658]
	TIME [epoch: 24.7 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0748741889208904		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 2.0748741889208904 | validation: 2.3403052570211633]
	TIME [epoch: 24.7 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0630232575042626		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 2.0630232575042626 | validation: 2.3493979571337342]
	TIME [epoch: 24.7 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0729340469824495		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 2.0729340469824495 | validation: 2.357196565380038]
	TIME [epoch: 24.8 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1158010317419222		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 2.1158010317419222 | validation: 2.3411032544010952]
	TIME [epoch: 24.8 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.078787610380821		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 2.078787610380821 | validation: 2.4363636758606257]
	TIME [epoch: 24.7 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0927629745275738		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 2.0927629745275738 | validation: 2.407073855626965]
	TIME [epoch: 24.8 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0928420283606926		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 2.0928420283606926 | validation: 2.3368229123723916]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_864.pth
	Model improved!!!
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.073546540280087		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 2.073546540280087 | validation: 2.3711934324919657]
	TIME [epoch: 24.8 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.069678085208792		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 2.069678085208792 | validation: 2.3602004773497924]
	TIME [epoch: 24.7 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.059125790348795		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 2.059125790348795 | validation: 2.3537654713182747]
	TIME [epoch: 24.7 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.06380557126906		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 2.06380557126906 | validation: 2.352892831310798]
	TIME [epoch: 24.7 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.094387792541468		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 2.094387792541468 | validation: 2.450227677605869]
	TIME [epoch: 24.7 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.156107523809929		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 2.156107523809929 | validation: 2.3972040616644783]
	TIME [epoch: 24.7 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0845746173516044		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 2.0845746173516044 | validation: 2.357795835363744]
	TIME [epoch: 24.7 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.065821050120212		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 2.065821050120212 | validation: 2.344951015184281]
	TIME [epoch: 24.7 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0694374745107216		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 2.0694374745107216 | validation: 2.4052813100321866]
	TIME [epoch: 24.7 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0922111684219318		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 2.0922111684219318 | validation: 2.348963038321849]
	TIME [epoch: 24.7 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.05895156242882		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 2.05895156242882 | validation: 2.3555025051719944]
	TIME [epoch: 24.7 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.05772137717433		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 2.05772137717433 | validation: 2.3544770140258238]
	TIME [epoch: 24.7 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1568174458619396		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 2.1568174458619396 | validation: 2.484932207707087]
	TIME [epoch: 24.7 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.098740140090807		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 2.098740140090807 | validation: 2.3508671478556]
	TIME [epoch: 24.8 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.074631154348811		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 2.074631154348811 | validation: 2.3827119152584046]
	TIME [epoch: 24.7 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.062451915771906		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 2.062451915771906 | validation: 2.3729548487014553]
	TIME [epoch: 24.7 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0926181050594064		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 2.0926181050594064 | validation: 2.428830008992366]
	TIME [epoch: 24.8 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0921534745087866		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 2.0921534745087866 | validation: 2.358150275739748]
	TIME [epoch: 24.8 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0756898772701144		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 2.0756898772701144 | validation: 2.3475837528614507]
	TIME [epoch: 24.7 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.066821615196721		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 2.066821615196721 | validation: 2.3724191761137705]
	TIME [epoch: 24.7 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.080171570386959		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 2.080171570386959 | validation: 2.3816885591998513]
	TIME [epoch: 24.7 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0745859234702495		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 2.0745859234702495 | validation: 2.464393885059429]
	TIME [epoch: 24.7 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.086315984694955		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 2.086315984694955 | validation: 2.34737409744229]
	TIME [epoch: 24.7 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.067290866816916		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 2.067290866816916 | validation: 2.3480755380294434]
	TIME [epoch: 24.7 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.069351692165876		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 2.069351692165876 | validation: 2.3454453537766313]
	TIME [epoch: 24.7 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0739344501840744		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 2.0739344501840744 | validation: 2.348779920744419]
	TIME [epoch: 24.7 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.08286157197689		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 2.08286157197689 | validation: 2.369643375597811]
	TIME [epoch: 24.8 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.075506537442898		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 2.075506537442898 | validation: 2.346294293367029]
	TIME [epoch: 24.8 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.066521752920694		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 2.066521752920694 | validation: 2.3937742372038957]
	TIME [epoch: 24.7 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0639828937927307		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 2.0639828937927307 | validation: 2.3634713245582324]
	TIME [epoch: 24.8 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0731605519376624		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 2.0731605519376624 | validation: 2.339536351428635]
	TIME [epoch: 24.7 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0866407314410553		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 2.0866407314410553 | validation: 2.342082207729786]
	TIME [epoch: 24.7 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.07330342030646		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 2.07330342030646 | validation: 2.384739119503277]
	TIME [epoch: 24.7 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0708890096024706		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 2.0708890096024706 | validation: 2.3548921099665363]
	TIME [epoch: 24.7 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0627375046595726		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 2.0627375046595726 | validation: 2.341324983896257]
	TIME [epoch: 24.7 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0654173281909487		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 2.0654173281909487 | validation: 2.337472213683984]
	TIME [epoch: 24.8 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.063146153431872		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 2.063146153431872 | validation: 2.376440145750818]
	TIME [epoch: 24.7 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0707417694344707		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 2.0707417694344707 | validation: 2.356099340479464]
	TIME [epoch: 24.8 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.056061641852388		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 2.056061641852388 | validation: 2.35769743782916]
	TIME [epoch: 24.7 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0688127352751526		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 2.0688127352751526 | validation: 2.382654166044743]
	TIME [epoch: 24.8 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0712272131278917		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 2.0712272131278917 | validation: 2.4097367176084243]
	TIME [epoch: 24.8 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0694436904969993		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 2.0694436904969993 | validation: 2.355017950351747]
	TIME [epoch: 24.8 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0800596854566593		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 2.0800596854566593 | validation: 2.3668771973280536]
	TIME [epoch: 24.8 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0738671849866623		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 2.0738671849866623 | validation: 2.367657497493232]
	TIME [epoch: 24.7 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0668499972252463		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 2.0668499972252463 | validation: 2.365348278695918]
	TIME [epoch: 24.8 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.080053179382032		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 2.080053179382032 | validation: 2.3632162532929]
	TIME [epoch: 24.7 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.072261138493282		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 2.072261138493282 | validation: 2.3442495582865237]
	TIME [epoch: 24.8 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.078580557839138		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 2.078580557839138 | validation: 2.3671669839551432]
	TIME [epoch: 24.8 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.057466919325816		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 2.057466919325816 | validation: 2.344781650006499]
	TIME [epoch: 24.8 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0674381560119652		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 2.0674381560119652 | validation: 2.402208132544937]
	TIME [epoch: 24.8 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.073108267951339		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 2.073108267951339 | validation: 2.3682745167966774]
	TIME [epoch: 24.7 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.067934210772046		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 2.067934210772046 | validation: 2.4092325213283834]
	TIME [epoch: 24.8 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0861700770595855		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 2.0861700770595855 | validation: 2.3734191747558713]
	TIME [epoch: 24.8 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.082390582406023		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 2.082390582406023 | validation: 2.3939316215789748]
	TIME [epoch: 24.7 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.070682954333972		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 2.070682954333972 | validation: 2.337029730947532]
	TIME [epoch: 24.8 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0623221690000872		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 2.0623221690000872 | validation: 2.359664022915242]
	TIME [epoch: 24.8 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0574087666795613		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 2.0574087666795613 | validation: 2.4322922017343958]
	TIME [epoch: 24.7 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0872778706516337		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 2.0872778706516337 | validation: 2.404632684945422]
	TIME [epoch: 24.7 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.08885728236699		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 2.08885728236699 | validation: 2.3570899723777723]
	TIME [epoch: 24.8 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.058044587092286		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 2.058044587092286 | validation: 2.41946289577697]
	TIME [epoch: 24.7 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0847550649840607		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 2.0847550649840607 | validation: 2.359283783279317]
	TIME [epoch: 24.7 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.06191182199213		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 2.06191182199213 | validation: 2.34845418549519]
	TIME [epoch: 24.7 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.065184197698713		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 2.065184197698713 | validation: 2.3769967349667662]
	TIME [epoch: 24.7 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.074790054173619		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 2.074790054173619 | validation: 2.3963766038811207]
	TIME [epoch: 24.8 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.061156597026623		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 2.061156597026623 | validation: 2.3507221956344626]
	TIME [epoch: 24.8 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.09104947711152		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 2.09104947711152 | validation: 2.3653390313738067]
	TIME [epoch: 24.7 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.056848867922639		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 2.056848867922639 | validation: 2.3407293221715944]
	TIME [epoch: 24.8 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.054061769359099		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 2.054061769359099 | validation: 2.367162193298579]
	TIME [epoch: 24.7 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0606173941674037		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 2.0606173941674037 | validation: 2.3630930737773475]
	TIME [epoch: 24.7 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.066044027070881		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 2.066044027070881 | validation: 2.38463501563241]
	TIME [epoch: 24.8 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0673978429646453		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 2.0673978429646453 | validation: 2.3348952720880063]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_935.pth
	Model improved!!!
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.063222887787413		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 2.063222887787413 | validation: 2.3418917871959275]
	TIME [epoch: 24.7 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0603198919451917		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 2.0603198919451917 | validation: 2.375950997912006]
	TIME [epoch: 24.8 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0655396037270584		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 2.0655396037270584 | validation: 2.3647057019657964]
	TIME [epoch: 24.8 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.066230301625381		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 2.066230301625381 | validation: 2.344202057710087]
	TIME [epoch: 24.7 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.056097239887927		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 2.056097239887927 | validation: 2.397924782617069]
	TIME [epoch: 24.8 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.066967065610849		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 2.066967065610849 | validation: 2.345982535054879]
	TIME [epoch: 24.8 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0593603167824845		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 2.0593603167824845 | validation: 2.3689439603951636]
	TIME [epoch: 24.7 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0882781630612377		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 2.0882781630612377 | validation: 2.341524804372666]
	TIME [epoch: 24.8 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.058837879568521		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 2.058837879568521 | validation: 2.3549491406282725]
	TIME [epoch: 24.8 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0552951452533215		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 2.0552951452533215 | validation: 2.346376704634373]
	TIME [epoch: 24.7 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.059756292973536		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 2.059756292973536 | validation: 2.337815430950149]
	TIME [epoch: 24.8 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0667023784881633		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 2.0667023784881633 | validation: 2.364199626424094]
	TIME [epoch: 24.8 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0703066919893223		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 2.0703066919893223 | validation: 2.3551640055491014]
	TIME [epoch: 24.7 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.060917385972241		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 2.060917385972241 | validation: 2.3519554461517083]
	TIME [epoch: 24.8 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0695111859783415		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 2.0695111859783415 | validation: 2.361952616856817]
	TIME [epoch: 24.8 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0818138352927753		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 2.0818138352927753 | validation: 2.335078557874931]
	TIME [epoch: 24.7 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0642140040585266		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 2.0642140040585266 | validation: 2.3526825818561568]
	TIME [epoch: 24.8 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0577942000818417		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 2.0577942000818417 | validation: 2.393395474538819]
	TIME [epoch: 24.7 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.090126919809188		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 2.090126919809188 | validation: 2.345544204781612]
	TIME [epoch: 24.7 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.076030079262148		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 2.076030079262148 | validation: 2.3496650381247974]
	TIME [epoch: 24.8 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0595696527683116		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 2.0595696527683116 | validation: 2.3767075248406884]
	TIME [epoch: 24.7 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0668519840409436		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 2.0668519840409436 | validation: 2.3335276053859157]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_957.pth
	Model improved!!!
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.055519132070282		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 2.055519132070282 | validation: 2.3772392511658125]
	TIME [epoch: 24.7 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0805517744163886		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 2.0805517744163886 | validation: 2.34434065034355]
	TIME [epoch: 24.8 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0661276299549054		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 2.0661276299549054 | validation: 2.3475705228568358]
	TIME [epoch: 24.7 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.057915808111346		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 2.057915808111346 | validation: 2.414683402015481]
	TIME [epoch: 24.8 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.099088503000538		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 2.099088503000538 | validation: 2.349815081349939]
	TIME [epoch: 24.8 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.070954637357002		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 2.070954637357002 | validation: 2.345518229423923]
	TIME [epoch: 24.7 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0723979433588746		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 2.0723979433588746 | validation: 2.343209773260906]
	TIME [epoch: 24.7 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0624578859903595		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 2.0624578859903595 | validation: 2.3503001428048584]
	TIME [epoch: 24.7 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0523257681601756		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 2.0523257681601756 | validation: 2.3391636883121767]
	TIME [epoch: 24.7 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.053637332551584		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 2.053637332551584 | validation: 2.3543000234810423]
	TIME [epoch: 24.8 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.074878760283732		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 2.074878760283732 | validation: 2.382950357838176]
	TIME [epoch: 24.7 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.095543342162654		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 2.095543342162654 | validation: 2.358617052688891]
	TIME [epoch: 24.7 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.083908846829487		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 2.083908846829487 | validation: 2.3664851301230976]
	TIME [epoch: 24.8 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.082724521937815		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 2.082724521937815 | validation: 2.352866978673829]
	TIME [epoch: 24.8 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.068243272278263		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 2.068243272278263 | validation: 2.356464033328047]
	TIME [epoch: 24.7 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0582380458761644		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 2.0582380458761644 | validation: 2.3606477169025606]
	TIME [epoch: 24.7 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0654455666376283		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 2.0654455666376283 | validation: 2.3398115803308888]
	TIME [epoch: 24.8 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0506964461671195		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 2.0506964461671195 | validation: 2.3522305996152]
	TIME [epoch: 24.7 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.146410962076384		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 2.146410962076384 | validation: 2.4233632516678028]
	TIME [epoch: 24.8 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.089818257525982		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 2.089818257525982 | validation: 2.3525063575039447]
	TIME [epoch: 24.7 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0619362766801825		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 2.0619362766801825 | validation: 2.3439601470397493]
	TIME [epoch: 24.7 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0521728769914995		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 2.0521728769914995 | validation: 2.3647522378947072]
	TIME [epoch: 24.7 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0681749526490765		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 2.0681749526490765 | validation: 2.350827566003698]
	TIME [epoch: 24.7 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0656855660253504		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 2.0656855660253504 | validation: 2.371103487931429]
	TIME [epoch: 24.7 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0679904759707757		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 2.0679904759707757 | validation: 2.4183573441695447]
	TIME [epoch: 24.8 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.094875085320056		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 2.094875085320056 | validation: 2.361963805331439]
	TIME [epoch: 24.7 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.053197464324438		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 2.053197464324438 | validation: 2.3873523457474146]
	TIME [epoch: 24.7 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.06829507737736		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 2.06829507737736 | validation: 2.362194932115183]
	TIME [epoch: 24.8 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.060824530017391		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 2.060824530017391 | validation: 2.344834220806288]
	TIME [epoch: 24.7 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0506411217310174		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 2.0506411217310174 | validation: 2.346156950728847]
	TIME [epoch: 24.7 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0515272569092207		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 2.0515272569092207 | validation: 2.373457164172705]
	TIME [epoch: 24.7 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0588245589778453		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 2.0588245589778453 | validation: 2.3435222673863367]
	TIME [epoch: 24.7 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.066768862941479		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 2.066768862941479 | validation: 2.346476334432963]
	TIME [epoch: 24.7 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.057901876955568		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 2.057901876955568 | validation: 2.362564722276731]
	TIME [epoch: 24.8 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0639161174058174		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 2.0639161174058174 | validation: 2.3555556307502448]
	TIME [epoch: 24.8 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.06645088955528		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 2.06645088955528 | validation: 2.358414415965592]
	TIME [epoch: 24.7 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0560842694424366		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 2.0560842694424366 | validation: 2.3660587083127798]
	TIME [epoch: 24.7 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.058323529823877		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 2.058323529823877 | validation: 2.4043481019447586]
	TIME [epoch: 24.7 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.067392182673747		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 2.067392182673747 | validation: 2.3497287027004554]
	TIME [epoch: 24.8 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.054043834883247		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 2.054043834883247 | validation: 2.3863698436517065]
	TIME [epoch: 24.8 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0579634339263935		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 2.0579634339263935 | validation: 2.3499401181545454]
	TIME [epoch: 24.7 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.123398265946553		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 2.123398265946553 | validation: 2.4658301364594557]
	TIME [epoch: 24.7 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.142417497945475		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 2.142417497945475 | validation: 2.352225373000358]
	TIME [epoch: 24.7 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0582607150360355		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 2.0582607150360355 | validation: 2.3585895415058826]
	TIME [epoch: 24.7 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0663041175713848		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 2.0663041175713848 | validation: 2.343233935534771]
	TIME [epoch: 24.8 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0487793300395576		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 2.0487793300395576 | validation: 2.346735592483991]
	TIME [epoch: 24.7 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0596523897230985		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 2.0596523897230985 | validation: 2.3797666520561127]
	TIME [epoch: 24.7 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0571826802003015		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 2.0571826802003015 | validation: 2.351265815623795]
	TIME [epoch: 24.7 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.056270119882908		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 2.056270119882908 | validation: 2.38056975228725]
	TIME [epoch: 24.7 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0714151923211808		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 2.0714151923211808 | validation: 2.375938771206078]
	TIME [epoch: 24.7 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.058250171192224		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 2.058250171192224 | validation: 2.3344509742554043]
	TIME [epoch: 24.7 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0730003058110027		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 2.0730003058110027 | validation: 2.3755052438120208]
	TIME [epoch: 24.8 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0898620576903415		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 2.0898620576903415 | validation: 2.3416391675561132]
	TIME [epoch: 24.8 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0478370783434836		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 2.0478370783434836 | validation: 2.3508265045009753]
	TIME [epoch: 24.7 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.068046488099941		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 2.068046488099941 | validation: 2.3695423818497217]
	TIME [epoch: 24.7 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0533908847135094		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 2.0533908847135094 | validation: 2.339656601025831]
	TIME [epoch: 24.7 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0592250511205688		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 2.0592250511205688 | validation: 2.349756500158204]
	TIME [epoch: 24.7 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0527358605394728		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 2.0527358605394728 | validation: 2.341484166348042]
	TIME [epoch: 24.7 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0525489775589083		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 2.0525489775589083 | validation: 2.3362294567340887]
	TIME [epoch: 24.7 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.056787486422206		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 2.056787486422206 | validation: 2.354988337570442]
	TIME [epoch: 24.8 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0690147631733717		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 2.0690147631733717 | validation: 2.351816520029018]
	TIME [epoch: 24.8 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0551446769804462		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 2.0551446769804462 | validation: 2.360605756070463]
	TIME [epoch: 24.7 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0607356671747477		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 2.0607356671747477 | validation: 2.385238094693485]
	TIME [epoch: 24.7 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.069313470942317		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 2.069313470942317 | validation: 2.3429203657589337]
	TIME [epoch: 24.8 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.049143129732532		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 2.049143129732532 | validation: 2.3504127526136136]
	TIME [epoch: 24.7 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0611006832078917		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 2.0611006832078917 | validation: 2.3505038364416455]
	TIME [epoch: 24.8 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0523101452784362		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 2.0523101452784362 | validation: 2.368367520611103]
	TIME [epoch: 24.8 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0813101932313107		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 2.0813101932313107 | validation: 2.428764607693563]
	TIME [epoch: 24.7 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0744830858147107		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 2.0744830858147107 | validation: 2.3458737498772386]
	TIME [epoch: 24.8 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0496892330632477		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 2.0496892330632477 | validation: 2.345823003389069]
	TIME [epoch: 24.7 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0860943003141665		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 2.0860943003141665 | validation: 2.3820369683080753]
	TIME [epoch: 24.7 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.071359812920228		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 2.071359812920228 | validation: 2.3496365773465935]
	TIME [epoch: 24.8 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0501618631027467		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 2.0501618631027467 | validation: 2.3427054766514135]
	TIME [epoch: 24.8 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0479190831850067		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 2.0479190831850067 | validation: 2.3417243979130844]
	TIME [epoch: 24.7 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0556373701522954		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 2.0556373701522954 | validation: 2.3406550370129104]
	TIME [epoch: 24.8 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.053131960861443		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 2.053131960861443 | validation: 2.3600985355362347]
	TIME [epoch: 24.8 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.051833168340106		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 2.051833168340106 | validation: 2.353997031637151]
	TIME [epoch: 24.7 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0524336292864764		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 2.0524336292864764 | validation: 2.3429334182974135]
	TIME [epoch: 24.8 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0566733368866235		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 2.0566733368866235 | validation: 2.340022082254072]
	TIME [epoch: 24.8 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.049426103970406		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 2.049426103970406 | validation: 2.3398870697732894]
	TIME [epoch: 24.8 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0688425814906006		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 2.0688425814906006 | validation: 2.340767267112485]
	TIME [epoch: 24.8 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0464234419445937		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 2.0464234419445937 | validation: 2.3389990536595033]
	TIME [epoch: 24.7 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0506111528117525		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 2.0506111528117525 | validation: 2.3581133085684587]
	TIME [epoch: 24.7 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0804872677373742		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 2.0804872677373742 | validation: 2.3560639873897156]
	TIME [epoch: 24.8 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.060253624799778		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 2.060253624799778 | validation: 2.3566072668608578]
	TIME [epoch: 24.7 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0706872688036757		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 2.0706872688036757 | validation: 2.351520706286617]
	TIME [epoch: 24.7 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.051999005205243		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 2.051999005205243 | validation: 2.3402185910795477]
	TIME [epoch: 24.8 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.051461333977824		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 2.051461333977824 | validation: 2.355057274204217]
	TIME [epoch: 24.7 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0492365295982924		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 2.0492365295982924 | validation: 2.386776770757275]
	TIME [epoch: 24.7 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0974129672719415		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 2.0974129672719415 | validation: 2.351696108791237]
	TIME [epoch: 24.8 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0545801518490743		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 2.0545801518490743 | validation: 2.3358873243470835]
	TIME [epoch: 24.8 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0510531480164658		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 2.0510531480164658 | validation: 2.3361737336071884]
	TIME [epoch: 24.7 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.05773515681549		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 2.05773515681549 | validation: 2.358355774793222]
	TIME [epoch: 24.8 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.062431909601817		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 2.062431909601817 | validation: 2.334995507528996]
	TIME [epoch: 24.8 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0504878450859194		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 2.0504878450859194 | validation: 2.354733710216133]
	TIME [epoch: 24.7 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.054587692394841		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 2.054587692394841 | validation: 2.3546294889505845]
	TIME [epoch: 24.8 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.062555358646451		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 2.062555358646451 | validation: 2.349583074234802]
	TIME [epoch: 24.7 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.054513143534265		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 2.054513143534265 | validation: 2.340990454572578]
	TIME [epoch: 24.7 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0484998989580148		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 2.0484998989580148 | validation: 2.339328696650469]
	TIME [epoch: 24.8 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.048192362129353		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 2.048192362129353 | validation: 2.3339216237221674]
	TIME [epoch: 24.8 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.053197767910213		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 2.053197767910213 | validation: 2.3338587087319222]
	TIME [epoch: 24.7 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0540165611251657		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 2.0540165611251657 | validation: 2.353701722602925]
	TIME [epoch: 24.7 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.04538092003067		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 2.04538092003067 | validation: 2.3427244687956397]
	TIME [epoch: 24.8 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.055172498653018		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 2.055172498653018 | validation: 2.3355106526739586]
	TIME [epoch: 24.7 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.053461333007041		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 2.053461333007041 | validation: 2.353447271127273]
	TIME [epoch: 24.7 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0481581120795793		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 2.0481581120795793 | validation: 2.326637633166356]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_1063.pth
	Model improved!!!
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0542019756720347		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 2.0542019756720347 | validation: 2.3357834927847234]
	TIME [epoch: 24.7 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0628407806587146		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 2.0628407806587146 | validation: 2.3599555569134547]
	TIME [epoch: 24.7 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0584580073018053		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 2.0584580073018053 | validation: 2.3485368403204454]
	TIME [epoch: 24.7 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0512651770089136		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 2.0512651770089136 | validation: 2.3579160968678945]
	TIME [epoch: 24.7 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0499209307530157		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 2.0499209307530157 | validation: 2.3380096033292923]
	TIME [epoch: 24.7 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0940893608388573		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 2.0940893608388573 | validation: 2.3459231646045184]
	TIME [epoch: 24.7 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0586185418544596		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 2.0586185418544596 | validation: 2.337975938097101]
	TIME [epoch: 24.7 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0581864810579975		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 2.0581864810579975 | validation: 2.3406001916442567]
	TIME [epoch: 24.7 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.052925171246615		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 2.052925171246615 | validation: 2.3396786022483433]
	TIME [epoch: 24.7 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0539142394018812		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 2.0539142394018812 | validation: 2.4101508031415513]
	TIME [epoch: 24.7 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0664114806852583		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 2.0664114806852583 | validation: 2.338185382334905]
	TIME [epoch: 24.7 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.049861455542528		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 2.049861455542528 | validation: 2.419123953919732]
	TIME [epoch: 24.7 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.078858523561878		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 2.078858523561878 | validation: 2.3855713310799245]
	TIME [epoch: 24.7 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.073098052792005		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 2.073098052792005 | validation: 2.34798850113295]
	TIME [epoch: 24.7 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.057856987558412		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 2.057856987558412 | validation: 2.3687721625196856]
	TIME [epoch: 24.7 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0518769217751975		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 2.0518769217751975 | validation: 2.3416189440670965]
	TIME [epoch: 24.7 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0500586680997857		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 2.0500586680997857 | validation: 2.357061796305708]
	TIME [epoch: 24.7 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0608702251668003		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 2.0608702251668003 | validation: 2.3492782989391565]
	TIME [epoch: 24.7 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0521598804848193		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 2.0521598804848193 | validation: 2.3446048236478507]
	TIME [epoch: 24.7 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.059268315165992		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 2.059268315165992 | validation: 2.3741554771607905]
	TIME [epoch: 24.7 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.059728814487169		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 2.059728814487169 | validation: 2.334318629204305]
	TIME [epoch: 24.7 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0509919471612177		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 2.0509919471612177 | validation: 2.342989525748308]
	TIME [epoch: 24.7 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0486055910007264		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 2.0486055910007264 | validation: 2.346614564046528]
	TIME [epoch: 24.7 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.049638453567505		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 2.049638453567505 | validation: 2.403145686753775]
	TIME [epoch: 24.7 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0653150228778774		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 2.0653150228778774 | validation: 2.3488703292316684]
	TIME [epoch: 24.7 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.042297500012048		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 2.042297500012048 | validation: 2.350870846644793]
	TIME [epoch: 24.7 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0641064545731678		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 2.0641064545731678 | validation: 2.3365164654267496]
	TIME [epoch: 24.7 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.04592513153889		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 2.04592513153889 | validation: 2.3377077871239598]
	TIME [epoch: 24.7 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0479715068022477		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 2.0479715068022477 | validation: 2.342211568095519]
	TIME [epoch: 24.7 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0565421068719294		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 2.0565421068719294 | validation: 2.3543314092130525]
	TIME [epoch: 24.7 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0477120714581787		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 2.0477120714581787 | validation: 2.3375506926382457]
	TIME [epoch: 24.7 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0483622910748784		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 2.0483622910748784 | validation: 2.345366403154264]
	TIME [epoch: 24.7 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.054950018030406		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 2.054950018030406 | validation: 2.3692577378860733]
	TIME [epoch: 24.7 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.057624632253345		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 2.057624632253345 | validation: 2.3500944144297082]
	TIME [epoch: 24.7 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0453035717471053		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 2.0453035717471053 | validation: 2.3452741862798403]
	TIME [epoch: 24.7 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0485501343558266		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 2.0485501343558266 | validation: 2.3412363774085785]
	TIME [epoch: 24.7 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0450775272613653		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 2.0450775272613653 | validation: 2.3419177085847616]
	TIME [epoch: 24.7 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0493617794826293		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 2.0493617794826293 | validation: 2.3454603950228354]
	TIME [epoch: 24.7 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0508379867383906		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 2.0508379867383906 | validation: 2.346765485322601]
	TIME [epoch: 24.7 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.047415647444669		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 2.047415647444669 | validation: 2.359449799897639]
	TIME [epoch: 24.7 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0477979673375986		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 2.0477979673375986 | validation: 2.365851898787323]
	TIME [epoch: 24.7 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0941445653405206		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 2.0941445653405206 | validation: 2.366982258754087]
	TIME [epoch: 24.7 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.051071112802162		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 2.051071112802162 | validation: 2.3335447387582526]
	TIME [epoch: 24.7 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0486485498517766		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 2.0486485498517766 | validation: 2.3504690417059346]
	TIME [epoch: 24.7 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.053597841317783		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 2.053597841317783 | validation: 2.351052560973114]
	TIME [epoch: 24.7 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.048974294322492		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 2.048974294322492 | validation: 2.356702422926883]
	TIME [epoch: 24.7 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0472124869719006		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 2.0472124869719006 | validation: 2.338628202553956]
	TIME [epoch: 24.7 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.050456749704053		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 2.050456749704053 | validation: 2.343667752465181]
	TIME [epoch: 24.7 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0464008808629615		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 2.0464008808629615 | validation: 2.353787844166111]
	TIME [epoch: 24.7 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.060078008864654		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 2.060078008864654 | validation: 2.348122687522056]
	TIME [epoch: 24.7 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0479192427804795		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 2.0479192427804795 | validation: 2.344410657291322]
	TIME [epoch: 24.7 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0501704826651874		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 2.0501704826651874 | validation: 2.37002716425264]
	TIME [epoch: 24.7 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.059165272658488		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 2.059165272658488 | validation: 2.337502653499246]
	TIME [epoch: 24.7 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0492460913787443		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 2.0492460913787443 | validation: 2.3479102014226076]
	TIME [epoch: 24.7 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0472741334821625		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 2.0472741334821625 | validation: 2.340413610690512]
	TIME [epoch: 24.7 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0582082521426077		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 2.0582082521426077 | validation: 2.360937027815863]
	TIME [epoch: 24.7 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.055006928095243		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 2.055006928095243 | validation: 2.3417898657310103]
	TIME [epoch: 24.7 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0590839087053507		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 2.0590839087053507 | validation: 2.3544983138913618]
	TIME [epoch: 24.7 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0530527589744327		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 2.0530527589744327 | validation: 2.347172891823737]
	TIME [epoch: 24.7 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.050665442714817		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 2.050665442714817 | validation: 2.343901651365266]
	TIME [epoch: 24.7 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0550715008130678		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 2.0550715008130678 | validation: 2.342873128854913]
	TIME [epoch: 24.7 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0481167752751976		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 2.0481167752751976 | validation: 2.363417391050742]
	TIME [epoch: 24.8 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0539849076358414		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 2.0539849076358414 | validation: 2.3540441850393643]
	TIME [epoch: 24.7 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0444783397916972		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 2.0444783397916972 | validation: 2.3389731035490984]
	TIME [epoch: 24.7 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0577827767453436		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 2.0577827767453436 | validation: 2.389246991790187]
	TIME [epoch: 24.7 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.060445189553757		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 2.060445189553757 | validation: 2.34191279036324]
	TIME [epoch: 24.7 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0472883291195636		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 2.0472883291195636 | validation: 2.333590223934144]
	TIME [epoch: 24.7 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.050980686079124		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 2.050980686079124 | validation: 2.3422232112843906]
	TIME [epoch: 24.7 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.070597343747745		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 2.070597343747745 | validation: 2.3406962776170794]
	TIME [epoch: 24.7 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.050802325599041		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 2.050802325599041 | validation: 2.3502936749619776]
	TIME [epoch: 24.7 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0455177653184147		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 2.0455177653184147 | validation: 2.3271127309614035]
	TIME [epoch: 24.7 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0478599885559294		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 2.0478599885559294 | validation: 2.3382433294534093]
	TIME [epoch: 24.7 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0439183391994273		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 2.0439183391994273 | validation: 2.3398295894731715]
	TIME [epoch: 24.7 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0476401303114953		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 2.0476401303114953 | validation: 2.349965840119708]
	TIME [epoch: 24.7 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0508406706655773		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 2.0508406706655773 | validation: 2.3620535799805125]
	TIME [epoch: 24.7 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.057253119578691		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 2.057253119578691 | validation: 2.339074383952034]
	TIME [epoch: 24.7 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.048257334547277		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 2.048257334547277 | validation: 2.329788824073464]
	TIME [epoch: 24.7 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0410020526542896		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 2.0410020526542896 | validation: 2.347815286646237]
	TIME [epoch: 24.7 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0420914518775524		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 2.0420914518775524 | validation: 2.3573354412864216]
	TIME [epoch: 24.7 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0481305729135673		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 2.0481305729135673 | validation: 2.354793727192199]
	TIME [epoch: 24.7 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.051472739081438		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 2.051472739081438 | validation: 2.354460216549012]
	TIME [epoch: 24.7 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0453848375648462		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 2.0453848375648462 | validation: 2.3423961591269835]
	TIME [epoch: 24.7 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0488673122040333		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 2.0488673122040333 | validation: 2.3379002662212476]
	TIME [epoch: 24.7 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0450993029228703		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 2.0450993029228703 | validation: 2.3539605702133306]
	TIME [epoch: 24.7 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.045620032749338		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 2.045620032749338 | validation: 2.3413891093138566]
	TIME [epoch: 24.7 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.050158734326154		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 2.050158734326154 | validation: 2.396205107041961]
	TIME [epoch: 24.7 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.062041406922849		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 2.062041406922849 | validation: 2.342559953369669]
	TIME [epoch: 24.7 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0429387745373		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 2.0429387745373 | validation: 2.3283640540365385]
	TIME [epoch: 24.7 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.04420491327752		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 2.04420491327752 | validation: 2.3510983430508476]
	TIME [epoch: 24.7 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0570291204559346		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 2.0570291204559346 | validation: 2.3606256952546354]
	TIME [epoch: 24.7 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0478725250436494		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 2.0478725250436494 | validation: 2.3365247795159103]
	TIME [epoch: 24.7 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.064784445889811		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 2.064784445889811 | validation: 2.368314978082309]
	TIME [epoch: 24.7 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0637584457517724		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 2.0637584457517724 | validation: 2.36445633017771]
	TIME [epoch: 24.7 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.052703854605671		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 2.052703854605671 | validation: 2.351150534791707]
	TIME [epoch: 24.7 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0450022296629347		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 2.0450022296629347 | validation: 2.3402838776395276]
	TIME [epoch: 24.7 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0480878289496136		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 2.0480878289496136 | validation: 2.3577054887456996]
	TIME [epoch: 24.7 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0767316166590772		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 2.0767316166590772 | validation: 2.3774607232006777]
	TIME [epoch: 24.8 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0541629100424212		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 2.0541629100424212 | validation: 2.3364245294908943]
	TIME [epoch: 24.7 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.044770643451901		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 2.044770643451901 | validation: 2.3393658761242087]
	TIME [epoch: 24.7 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.046864426453423		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 2.046864426453423 | validation: 2.373424821447346]
	TIME [epoch: 24.7 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.054342335871163		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 2.054342335871163 | validation: 2.3731805082838515]
	TIME [epoch: 24.7 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0505302257649096		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 2.0505302257649096 | validation: 2.3385639209583964]
	TIME [epoch: 24.7 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0506552579282085		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 2.0506552579282085 | validation: 2.3332396172364036]
	TIME [epoch: 24.7 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.043876534344909		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 2.043876534344909 | validation: 2.349942801914111]
	TIME [epoch: 24.7 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0503712088798633		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 2.0503712088798633 | validation: 2.3509068614832844]
	TIME [epoch: 24.7 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.041677343189096		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 2.041677343189096 | validation: 2.339128375665971]
	TIME [epoch: 24.7 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.047311471954284		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 2.047311471954284 | validation: 2.356936004966815]
	TIME [epoch: 24.7 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.055727676441447		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 2.055727676441447 | validation: 2.3342119591580994]
	TIME [epoch: 24.7 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0467550447408938		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 2.0467550447408938 | validation: 2.3465726825568107]
	TIME [epoch: 24.7 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0497814731927857		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 2.0497814731927857 | validation: 2.3365863569796024]
	TIME [epoch: 24.7 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0571375510659404		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 2.0571375510659404 | validation: 2.342373940799124]
	TIME [epoch: 24.7 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0429513721973724		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 2.0429513721973724 | validation: 2.3374123346956233]
	TIME [epoch: 24.7 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0631716378210063		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 2.0631716378210063 | validation: 2.3311932427834785]
	TIME [epoch: 24.7 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.059339886191864		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 2.059339886191864 | validation: 2.3511932798996233]
	TIME [epoch: 24.7 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.051525007242788		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 2.051525007242788 | validation: 2.334858116994203]
	TIME [epoch: 24.7 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.041077068756511		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 2.041077068756511 | validation: 2.349558271922609]
	TIME [epoch: 24.7 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0459355652541404		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 2.0459355652541404 | validation: 2.3473008789531877]
	TIME [epoch: 24.7 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0404479983521955		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 2.0404479983521955 | validation: 2.3581769574135887]
	TIME [epoch: 24.7 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0491344394326427		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 2.0491344394326427 | validation: 2.3461525348770165]
	TIME [epoch: 24.7 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0591171311056273		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 2.0591171311056273 | validation: 2.336757327816903]
	TIME [epoch: 24.7 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0439074699254314		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 2.0439074699254314 | validation: 2.3465150786749382]
	TIME [epoch: 24.7 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.042676685621489		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 2.042676685621489 | validation: 2.341087238926365]
	TIME [epoch: 24.7 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.04769748879626		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 2.04769748879626 | validation: 2.3354492787752514]
	TIME [epoch: 24.7 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0562118013993276		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 2.0562118013993276 | validation: 2.3546455301343845]
	TIME [epoch: 24.7 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.06563643151775		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 2.06563643151775 | validation: 2.335356434087643]
	TIME [epoch: 24.7 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0518291359749936		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 2.0518291359749936 | validation: 2.3278621436854685]
	TIME [epoch: 24.7 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0447558282397047		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 2.0447558282397047 | validation: 2.359304615166903]
	TIME [epoch: 24.7 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0491793597507435		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 2.0491793597507435 | validation: 2.3718620181469636]
	TIME [epoch: 24.7 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.051606375520548		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 2.051606375520548 | validation: 2.3395402878027434]
	TIME [epoch: 24.7 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.043217878203001		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 2.043217878203001 | validation: 2.3346301433456174]
	TIME [epoch: 24.7 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0506451104496186		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 2.0506451104496186 | validation: 2.3302237000089536]
	TIME [epoch: 24.7 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.042407979723429		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 2.042407979723429 | validation: 2.3425148331001258]
	TIME [epoch: 24.7 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0455922664896677		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 2.0455922664896677 | validation: 2.3435105727494854]
	TIME [epoch: 24.7 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.051495096910005		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 2.051495096910005 | validation: 2.3466591460127613]
	TIME [epoch: 24.7 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0459666841056956		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 2.0459666841056956 | validation: 2.3445517250815953]
	TIME [epoch: 24.7 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0434426045457212		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 2.0434426045457212 | validation: 2.3388750427221487]
	TIME [epoch: 24.7 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0432392213861337		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 2.0432392213861337 | validation: 2.3505735427701833]
	TIME [epoch: 24.7 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.043573148959695		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 2.043573148959695 | validation: 2.3383402492689425]
	TIME [epoch: 24.7 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0376104593040125		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 2.0376104593040125 | validation: 2.336964656331678]
	TIME [epoch: 24.7 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0476864486129474		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 2.0476864486129474 | validation: 2.3421489612660182]
	TIME [epoch: 24.7 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0490728875355515		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 2.0490728875355515 | validation: 2.332085613186395]
	TIME [epoch: 24.7 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.047152888306628		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 2.047152888306628 | validation: 2.3328039017856455]
	TIME [epoch: 24.7 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0447487380737353		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 2.0447487380737353 | validation: 2.326755011312492]
	TIME [epoch: 24.7 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0477274833723103		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 2.0477274833723103 | validation: 2.345120191558734]
	TIME [epoch: 24.7 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.056901950676908		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 2.056901950676908 | validation: 2.3547690314367395]
	TIME [epoch: 24.7 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0600306534239206		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 2.0600306534239206 | validation: 2.352241178839858]
	TIME [epoch: 24.7 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.054299628615607		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 2.054299628615607 | validation: 2.3393115050019966]
	TIME [epoch: 24.7 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.043250466928234		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 2.043250466928234 | validation: 2.3296383618154617]
	TIME [epoch: 24.7 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.046912125997045		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 2.046912125997045 | validation: 2.3346825131745392]
	TIME [epoch: 24.7 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.043734412762264		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 2.043734412762264 | validation: 2.370359016783258]
	TIME [epoch: 24.7 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.069586165657772		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 2.069586165657772 | validation: 2.344297556379229]
	TIME [epoch: 24.7 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0445979814690562		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 2.0445979814690562 | validation: 2.3314466328554175]
	TIME [epoch: 24.7 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0399635618801533		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 2.0399635618801533 | validation: 2.339488591358552]
	TIME [epoch: 24.7 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.04519164926831		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 2.04519164926831 | validation: 2.3485996539385745]
	TIME [epoch: 24.7 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0410461407705296		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 2.0410461407705296 | validation: 2.3333843157326473]
	TIME [epoch: 24.7 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.045690707311203		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 2.045690707311203 | validation: 2.343235034723557]
	TIME [epoch: 24.7 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.046224596066841		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 2.046224596066841 | validation: 2.3593321738021222]
	TIME [epoch: 24.7 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.043422632642285		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 2.043422632642285 | validation: 2.342807039097923]
	TIME [epoch: 24.7 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0494067827553524		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 2.0494067827553524 | validation: 2.3420740615559525]
	TIME [epoch: 24.7 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0437291787723524		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 2.0437291787723524 | validation: 2.342416345619163]
	TIME [epoch: 24.7 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0389335031398343		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 2.0389335031398343 | validation: 2.3381747224416456]
	TIME [epoch: 24.7 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0490854263328107		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 2.0490854263328107 | validation: 2.339239959233554]
	TIME [epoch: 24.7 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0417853299190996		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 2.0417853299190996 | validation: 2.3369176954539177]
	TIME [epoch: 24.7 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0398665848117243		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 2.0398665848117243 | validation: 2.341067807721384]
	TIME [epoch: 24.7 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0423311215052795		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 2.0423311215052795 | validation: 2.3497026106875736]
	TIME [epoch: 24.7 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.049138660602949		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 2.049138660602949 | validation: 2.3374997184743793]
	TIME [epoch: 24.7 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0543050916061		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 2.0543050916061 | validation: 2.3362666374550347]
	TIME [epoch: 24.7 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.059110735720437		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 2.059110735720437 | validation: 2.352357368461409]
	TIME [epoch: 24.7 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.071296135034978		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 2.071296135034978 | validation: 2.352266016656826]
	TIME [epoch: 24.7 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0883999825961483		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 2.0883999825961483 | validation: 2.349325309955396]
	TIME [epoch: 24.7 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.050676202787955		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 2.050676202787955 | validation: 2.3366037883645263]
	TIME [epoch: 24.7 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.039760807636751		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 2.039760807636751 | validation: 2.329046829371007]
	TIME [epoch: 24.7 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0428047813150063		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 2.0428047813150063 | validation: 2.3383711042996755]
	TIME [epoch: 24.7 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.041139762224109		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 2.041139762224109 | validation: 2.342433157483462]
	TIME [epoch: 24.7 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0486389846913426		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 2.0486389846913426 | validation: 2.340380699313233]
	TIME [epoch: 24.7 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.047940644241547		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 2.047940644241547 | validation: 2.350161125741564]
	TIME [epoch: 24.7 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0694807740002044		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 2.0694807740002044 | validation: 2.328385095577843]
	TIME [epoch: 24.7 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0443349929917103		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 2.0443349929917103 | validation: 2.342940823695696]
	TIME [epoch: 24.7 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0488837012249452		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 2.0488837012249452 | validation: 2.368874548415339]
	TIME [epoch: 24.7 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0518253616235307		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 2.0518253616235307 | validation: 2.338186938944666]
	TIME [epoch: 24.7 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0391094549957587		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 2.0391094549957587 | validation: 2.340520406007107]
	TIME [epoch: 24.7 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.040799919684945		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 2.040799919684945 | validation: 2.342028263847201]
	TIME [epoch: 24.7 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.043332229737077		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 2.043332229737077 | validation: 2.3682869622507146]
	TIME [epoch: 24.7 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.073328130641616		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 2.073328130641616 | validation: 2.3530889798797032]
	TIME [epoch: 24.7 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0421394735913965		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 2.0421394735913965 | validation: 2.330297969709505]
	TIME [epoch: 24.7 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0424512471861163		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 2.0424512471861163 | validation: 2.3297406502309563]
	TIME [epoch: 24.7 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0419384709265933		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 2.0419384709265933 | validation: 2.3412064230121596]
	TIME [epoch: 24.7 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0431285946467805		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 2.0431285946467805 | validation: 2.3508322583815375]
	TIME [epoch: 24.7 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0493205307752786		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 2.0493205307752786 | validation: 2.326404122738073]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_1252.pth
	Model improved!!!
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0424491061492285		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 2.0424491061492285 | validation: 2.3362166371222783]
	TIME [epoch: 24.7 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0404903146812243		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 2.0404903146812243 | validation: 2.338476954029265]
	TIME [epoch: 24.7 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.048076519643106		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 2.048076519643106 | validation: 2.3312286331482843]
	TIME [epoch: 24.7 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.040288114171347		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 2.040288114171347 | validation: 2.3367205341569046]
	TIME [epoch: 24.7 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0424886666105175		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 2.0424886666105175 | validation: 2.3324581647534384]
	TIME [epoch: 24.7 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0490169497831836		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 2.0490169497831836 | validation: 2.3383867377068954]
	TIME [epoch: 24.7 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.049056827429675		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 2.049056827429675 | validation: 2.348628062050025]
	TIME [epoch: 24.7 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0410031174875884		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 2.0410031174875884 | validation: 2.3513956645354086]
	TIME [epoch: 24.7 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.050501236942624		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 2.050501236942624 | validation: 2.3576914979305226]
	TIME [epoch: 24.7 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.055513835483975		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 2.055513835483975 | validation: 2.342772632832548]
	TIME [epoch: 24.7 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0431526569332847		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 2.0431526569332847 | validation: 2.3392007758544446]
	TIME [epoch: 24.7 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.043151478822754		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 2.043151478822754 | validation: 2.3418626439927284]
	TIME [epoch: 24.7 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.039946992019596		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 2.039946992019596 | validation: 2.3470763126513807]
	TIME [epoch: 24.7 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0550834713486235		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 2.0550834713486235 | validation: 2.3390390317613132]
	TIME [epoch: 24.7 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0455926180706703		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 2.0455926180706703 | validation: 2.336518139881053]
	TIME [epoch: 24.7 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0450395053875257		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 2.0450395053875257 | validation: 2.3369908270420514]
	TIME [epoch: 24.7 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0510149392253796		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 2.0510149392253796 | validation: 2.3468891001216368]
	TIME [epoch: 24.7 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0615074790672803		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 2.0615074790672803 | validation: 2.3423530483535746]
	TIME [epoch: 24.7 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.040592148518866		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 2.040592148518866 | validation: 2.3359558536207063]
	TIME [epoch: 24.7 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0366015138716578		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 2.0366015138716578 | validation: 2.3475779961547487]
	TIME [epoch: 24.7 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0401059778567783		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 2.0401059778567783 | validation: 2.3277507188270765]
	TIME [epoch: 24.7 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0365111318915696		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 2.0365111318915696 | validation: 2.335403203276139]
	TIME [epoch: 24.7 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.045385406460978		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 2.045385406460978 | validation: 2.378454934986044]
	TIME [epoch: 24.7 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.050887919905083		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 2.050887919905083 | validation: 2.3424375061519025]
	TIME [epoch: 24.7 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.043358545823504		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 2.043358545823504 | validation: 2.341874048860616]
	TIME [epoch: 24.7 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.03966466064849		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 2.03966466064849 | validation: 2.337074561691364]
	TIME [epoch: 24.7 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0434538199625885		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 2.0434538199625885 | validation: 2.336047497916668]
	TIME [epoch: 24.7 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.03942443141357		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 2.03942443141357 | validation: 2.339758660664023]
	TIME [epoch: 24.7 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0423079998341254		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 2.0423079998341254 | validation: 2.348475776091626]
	TIME [epoch: 24.7 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.041357380612376		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 2.041357380612376 | validation: 2.3481615717439728]
	TIME [epoch: 24.7 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0458342235617497		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 2.0458342235617497 | validation: 2.3337178711113022]
	TIME [epoch: 24.7 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.044320395698673		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 2.044320395698673 | validation: 2.3367140477663018]
	TIME [epoch: 24.7 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.038259325402487		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 2.038259325402487 | validation: 2.3327372568102125]
	TIME [epoch: 24.7 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.044956065583121		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 2.044956065583121 | validation: 2.347021701613385]
	TIME [epoch: 24.7 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.043339136779547		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 2.043339136779547 | validation: 2.346712448093562]
	TIME [epoch: 24.7 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0435360338098194		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 2.0435360338098194 | validation: 2.3412422927466334]
	TIME [epoch: 24.7 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0504409701517394		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 2.0504409701517394 | validation: 2.3462460873757434]
	TIME [epoch: 24.7 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.053795778093874		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 2.053795778093874 | validation: 2.3346150875767826]
	TIME [epoch: 24.7 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.04575701216255		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 2.04575701216255 | validation: 2.3370259364724397]
	TIME [epoch: 24.7 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.037436202409785		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 2.037436202409785 | validation: 2.3322778454842337]
	TIME [epoch: 24.7 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.042037308069583		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 2.042037308069583 | validation: 2.3553915165936097]
	TIME [epoch: 24.7 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.047635836495802		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 2.047635836495802 | validation: 2.3375302733796737]
	TIME [epoch: 24.7 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.044001836154039		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 2.044001836154039 | validation: 2.3561322017680872]
	TIME [epoch: 24.7 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.040813007400741		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 2.040813007400741 | validation: 2.327039661806084]
	TIME [epoch: 24.7 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0448698393110525		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 2.0448698393110525 | validation: 2.3331834157829134]
	TIME [epoch: 24.7 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.040483762590455		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 2.040483762590455 | validation: 2.3295189419692783]
	TIME [epoch: 24.7 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.036876287801562		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 2.036876287801562 | validation: 2.3265785290154515]
	TIME [epoch: 24.7 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.036058303760803		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 2.036058303760803 | validation: 2.341794087517315]
	TIME [epoch: 24.7 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.040309527248366		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 2.040309527248366 | validation: 2.340164568865709]
	TIME [epoch: 24.7 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0415823670722175		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 2.0415823670722175 | validation: 2.330628130615067]
	TIME [epoch: 24.7 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0397419657768032		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 2.0397419657768032 | validation: 2.334279487273968]
	TIME [epoch: 24.7 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0383708589618763		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 2.0383708589618763 | validation: 2.3384565394407635]
	TIME [epoch: 24.7 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.046563578231951		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 2.046563578231951 | validation: 2.3367148698210274]
	TIME [epoch: 24.7 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0466937988118645		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 2.0466937988118645 | validation: 2.325383267977668]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r3_20240310_051930/states/model_tr_study205_1306.pth
	Model improved!!!
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.037194520675916		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 2.037194520675916 | validation: 2.3449647230666217]
	TIME [epoch: 24.7 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0426724346832934		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 2.0426724346832934 | validation: 2.33185776971293]
	TIME [epoch: 24.7 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.040044543689437		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 2.040044543689437 | validation: 2.342359141336829]
	TIME [epoch: 24.7 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0457092381478823		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 2.0457092381478823 | validation: 2.363451652413262]
	TIME [epoch: 24.7 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0626029312507947		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 2.0626029312507947 | validation: 2.36057687854747]
	TIME [epoch: 24.7 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0539834273955484		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 2.0539834273955484 | validation: 2.3430435004305337]
	TIME [epoch: 24.7 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0454815181184376		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 2.0454815181184376 | validation: 2.3685841784290607]
	TIME [epoch: 24.7 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.074628895870427		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 2.074628895870427 | validation: 2.375495186082724]
	TIME [epoch: 24.7 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.050606893827646		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 2.050606893827646 | validation: 2.331180257088838]
	TIME [epoch: 24.7 sec]
EPOCH 1316/2000:
	Training over batches...
