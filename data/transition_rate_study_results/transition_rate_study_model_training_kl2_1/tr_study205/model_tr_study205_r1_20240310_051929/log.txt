Args:
Namespace(name='model_tr_study205', outdir='out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1', training_data='data/transition_rate_studies/tr_study205/tr_study205_training/r1', validation_data='data/transition_rate_studies/tr_study205/tr_study205_validation/r1', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.075, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1477090458

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 13.158937948230648		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 13.158937948230648 | validation: 12.889897694789681]
	TIME [epoch: 112 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.785765115877915		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.785765115877915 | validation: 9.219254759366468]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.028650544712429		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.028650544712429 | validation: 8.49604566368087]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.632673930614796		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.632673930614796 | validation: 7.41526807876553]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.725074180530527		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.725074180530527 | validation: 9.451157862869273]
	TIME [epoch: 24.8 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.941566770877685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.941566770877685 | validation: 6.440427733127482]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.340708145228505		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.340708145228505 | validation: 5.786454044831139]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.132585230301417		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.132585230301417 | validation: 5.542702876741942]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.713909207482219		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.713909207482219 | validation: 4.978550292233013]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.4665174894880835		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.4665174894880835 | validation: 5.06405951550578]
	TIME [epoch: 24.8 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.143833082371493		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.143833082371493 | validation: 4.733413816216555]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.096031824252174		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.096031824252174 | validation: 4.784934121414729]
	TIME [epoch: 24.8 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.820708545574079		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.820708545574079 | validation: 4.980018449479313]
	TIME [epoch: 24.9 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.88840124508245		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.88840124508245 | validation: 4.3501242958970066]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.873590023480565		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.873590023480565 | validation: 4.303644997145339]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.583756734331272		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.583756734331272 | validation: 4.995349489339041]
	TIME [epoch: 24.8 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.880377299924302		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.880377299924302 | validation: 4.953663711969077]
	TIME [epoch: 24.8 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.530702418083751		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.530702418083751 | validation: 3.9956051165474773]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.9598660306602715		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.9598660306602715 | validation: 4.1601606143923995]
	TIME [epoch: 24.8 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.519428159549587		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.519428159549587 | validation: 3.8674828338451186]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.470062181275725		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.470062181275725 | validation: 4.087918353881984]
	TIME [epoch: 24.8 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.243837219720149		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.243837219720149 | validation: 4.096442189329945]
	TIME [epoch: 24.8 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.359650818766719		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.359650818766719 | validation: 4.461358128957836]
	TIME [epoch: 24.7 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.292466778078851		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.292466778078851 | validation: 4.024927100822575]
	TIME [epoch: 24.8 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.346816282314682		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.346816282314682 | validation: 4.307843782753338]
	TIME [epoch: 24.8 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.267213086774161		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.267213086774161 | validation: 3.8829747739907363]
	TIME [epoch: 24.7 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0931450491246935		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.0931450491246935 | validation: 4.364074526282604]
	TIME [epoch: 24.8 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.316086996292741		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.316086996292741 | validation: 4.095835276441721]
	TIME [epoch: 24.8 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.186776549424351		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.186776549424351 | validation: 4.231819878735652]
	TIME [epoch: 24.8 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.151306715004523		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.151306715004523 | validation: 4.979695753632304]
	TIME [epoch: 24.8 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.34887373727282		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.34887373727282 | validation: 3.7935079957024276]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.190613750495501		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.190613750495501 | validation: 3.982645485904171]
	TIME [epoch: 24.8 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.098365509605893		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.098365509605893 | validation: 3.50677085004356]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.229537364922262		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.229537364922262 | validation: 3.848216819958251]
	TIME [epoch: 24.8 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.075432578568375		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.075432578568375 | validation: 4.063479098243996]
	TIME [epoch: 24.8 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.03624477484819		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.03624477484819 | validation: 3.882941003383535]
	TIME [epoch: 24.8 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.925787840515549		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.925787840515549 | validation: 4.153508562836667]
	TIME [epoch: 24.8 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0101706246501365		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.0101706246501365 | validation: 4.782915467585881]
	TIME [epoch: 24.8 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.157467619015776		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.157467619015776 | validation: 4.228233601075845]
	TIME [epoch: 24.8 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.034226136816843		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.034226136816843 | validation: 4.071785514311058]
	TIME [epoch: 24.8 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.015564699301361		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.015564699301361 | validation: 3.400402399045486]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.971365399939996		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.971365399939996 | validation: 3.634336398248284]
	TIME [epoch: 24.8 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.010522463069322		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.010522463069322 | validation: 3.761683046052824]
	TIME [epoch: 24.8 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.892138896965078		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.892138896965078 | validation: 3.4808576907230737]
	TIME [epoch: 24.8 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.896937946143841		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.896937946143841 | validation: 3.488940662109528]
	TIME [epoch: 24.8 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.966654746068869		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.966654746068869 | validation: 3.414103775164545]
	TIME [epoch: 24.8 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8778288215324612		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8778288215324612 | validation: 3.4288025970834775]
	TIME [epoch: 24.8 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.839751353595158		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.839751353595158 | validation: 3.5037531016295165]
	TIME [epoch: 24.8 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7760986053066796		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7760986053066796 | validation: 3.6148850844962066]
	TIME [epoch: 24.8 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9153813473816257		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9153813473816257 | validation: 3.8523194101680613]
	TIME [epoch: 24.8 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8538119605308903		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 3.8538119605308903 | validation: 3.5097500006576894]
	TIME [epoch: 24.8 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.836477589493777		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 3.836477589493777 | validation: 3.500412955110388]
	TIME [epoch: 24.8 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9194523231356238		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 3.9194523231356238 | validation: 3.0729304086278275]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8623449471339546		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 3.8623449471339546 | validation: 3.428867213817508]
	TIME [epoch: 24.8 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.444800427806523		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 3.444800427806523 | validation: 3.6734472304423083]
	TIME [epoch: 24.8 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8005548705880035		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 3.8005548705880035 | validation: 3.398791368928271]
	TIME [epoch: 24.7 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.715017630019393		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 3.715017630019393 | validation: 3.4189575181190084]
	TIME [epoch: 24.8 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6153516210823153		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 3.6153516210823153 | validation: 3.678596822806526]
	TIME [epoch: 24.8 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6043251689242726		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 3.6043251689242726 | validation: 3.262637724362495]
	TIME [epoch: 24.8 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7643589985097425		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 3.7643589985097425 | validation: 3.037672721079]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7195944351830965		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 3.7195944351830965 | validation: 3.3762446089829763]
	TIME [epoch: 24.8 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5170424713574455		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 3.5170424713574455 | validation: 5.694967451408968]
	TIME [epoch: 24.8 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.104120260248106		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 4.104120260248106 | validation: 3.8992440256121412]
	TIME [epoch: 24.8 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.095581997909454		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 4.095581997909454 | validation: 2.916613693554909]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_64.pth
	Model improved!!!
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6429298967738517		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 3.6429298967738517 | validation: 3.64716315972763]
	TIME [epoch: 24.9 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7380388383985874		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 3.7380388383985874 | validation: 3.346657513003851]
	TIME [epoch: 24.8 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5428590456774147		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 3.5428590456774147 | validation: 4.675793209591352]
	TIME [epoch: 24.8 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.097641935904467		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 4.097641935904467 | validation: 3.0883919036255794]
	TIME [epoch: 24.8 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.569637010007845		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 3.569637010007845 | validation: 3.303439574278743]
	TIME [epoch: 24.8 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6628534299699984		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 3.6628534299699984 | validation: 3.441254580028579]
	TIME [epoch: 24.8 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.573675435645946		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 3.573675435645946 | validation: 3.224452588282619]
	TIME [epoch: 24.9 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.394339002851596		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 3.394339002851596 | validation: 2.8585049702186653]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5227449374587803		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 3.5227449374587803 | validation: 3.516725068693332]
	TIME [epoch: 24.9 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.560712567732986		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 3.560712567732986 | validation: 3.063875372326937]
	TIME [epoch: 24.9 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.433886025858753		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 3.433886025858753 | validation: 3.796124384085226]
	TIME [epoch: 24.9 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.516309934132262		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 3.516309934132262 | validation: 3.21470982629176]
	TIME [epoch: 24.8 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4354472898771697		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 3.4354472898771697 | validation: 3.288933543651834]
	TIME [epoch: 24.9 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5890803027621057		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 3.5890803027621057 | validation: 3.44127084906885]
	TIME [epoch: 24.8 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5322269291748096		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 3.5322269291748096 | validation: 2.8240031513159]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6162600010003674		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 3.6162600010003674 | validation: 3.004758142605421]
	TIME [epoch: 24.8 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.531274919680288		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 3.531274919680288 | validation: 3.5605388608239776]
	TIME [epoch: 24.8 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.486060285610881		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 3.486060285610881 | validation: 2.9820083069563714]
	TIME [epoch: 24.8 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.218034961149989		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 3.218034961149989 | validation: 3.0195293529437266]
	TIME [epoch: 24.8 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4170787219730956		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 3.4170787219730956 | validation: 3.17160816883803]
	TIME [epoch: 24.8 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.388132236792938		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 3.388132236792938 | validation: 3.0702425129126936]
	TIME [epoch: 24.8 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3746252880569165		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 3.3746252880569165 | validation: 2.849929426300692]
	TIME [epoch: 24.8 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.378251486002989		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 3.378251486002989 | validation: 2.972301483472327]
	TIME [epoch: 24.8 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3768006466469465		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 3.3768006466469465 | validation: 3.294394952784736]
	TIME [epoch: 24.8 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2003402621815975		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 3.2003402621815975 | validation: 3.469212146640158]
	TIME [epoch: 24.8 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.433480234851338		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 3.433480234851338 | validation: 2.6798796292888376]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_90.pth
	Model improved!!!
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3660577493035744		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 3.3660577493035744 | validation: 2.940272237895275]
	TIME [epoch: 24.8 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.279260814802919		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 3.279260814802919 | validation: 2.9863290812827477]
	TIME [epoch: 24.8 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2314276833264914		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 3.2314276833264914 | validation: 2.8449875213848292]
	TIME [epoch: 24.8 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.157732815016434		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 3.157732815016434 | validation: 2.9184365383465196]
	TIME [epoch: 24.8 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.312796521335642		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 3.312796521335642 | validation: 3.112470907429739]
	TIME [epoch: 24.8 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.287426840627196		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 3.287426840627196 | validation: 2.7295780587044227]
	TIME [epoch: 24.8 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.174602836789869		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 3.174602836789869 | validation: 3.4770919910098304]
	TIME [epoch: 24.8 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.351007329793108		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 3.351007329793108 | validation: 2.822476978913303]
	TIME [epoch: 24.8 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.18093225153456		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 3.18093225153456 | validation: 2.88129958280928]
	TIME [epoch: 24.8 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.349618579424798		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 3.349618579424798 | validation: 2.5251459089681862]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_100.pth
	Model improved!!!
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4380774887166714		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 3.4380774887166714 | validation: 2.5623138081591095]
	TIME [epoch: 24.8 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5538451338145345		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 3.5538451338145345 | validation: 2.6963908834974357]
	TIME [epoch: 24.8 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3378591673529443		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 3.3378591673529443 | validation: 2.982656401201648]
	TIME [epoch: 24.8 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.244751768305224		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 3.244751768305224 | validation: 3.1841360813064212]
	TIME [epoch: 24.8 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2318065948611427		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 3.2318065948611427 | validation: 3.2646385946657888]
	TIME [epoch: 24.8 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2118014440058653		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 3.2118014440058653 | validation: 2.8083191480581924]
	TIME [epoch: 24.8 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0391429737908378		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 3.0391429737908378 | validation: 3.3244202384823427]
	TIME [epoch: 24.8 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1318559957248087		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 3.1318559957248087 | validation: 3.248970353026859]
	TIME [epoch: 24.8 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.18670649033878		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 3.18670649033878 | validation: 3.056861990802556]
	TIME [epoch: 24.8 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1168447545387963		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 3.1168447545387963 | validation: 2.588014449059256]
	TIME [epoch: 24.8 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.04346877805864		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 3.04346877805864 | validation: 2.949044637275346]
	TIME [epoch: 24.8 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.135708060194538		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 3.135708060194538 | validation: 2.6093943055589386]
	TIME [epoch: 24.8 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.122158006310941		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 3.122158006310941 | validation: 3.0566374078266465]
	TIME [epoch: 24.8 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.234146497963927		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 3.234146497963927 | validation: 2.890577678717758]
	TIME [epoch: 24.8 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1184079894992607		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 3.1184079894992607 | validation: 2.680181629720554]
	TIME [epoch: 24.8 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.990711939530812		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 2.990711939530812 | validation: 2.8682335654622935]
	TIME [epoch: 24.8 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.119296594122079		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 3.119296594122079 | validation: 2.6762267856369646]
	TIME [epoch: 24.8 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9975520086740994		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 2.9975520086740994 | validation: 2.507764960718842]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_118.pth
	Model improved!!!
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.223133075732842		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 3.223133075732842 | validation: 2.436532667867389]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_119.pth
	Model improved!!!
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1141027105418373		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 3.1141027105418373 | validation: 2.8732722183017323]
	TIME [epoch: 24.9 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0703221381362713		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 3.0703221381362713 | validation: 3.5452084244000686]
	TIME [epoch: 24.8 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.26645651701536		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 3.26645651701536 | validation: 2.8699781500907124]
	TIME [epoch: 24.8 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9966295625965382		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 2.9966295625965382 | validation: 2.4946861717393185]
	TIME [epoch: 24.9 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.160520786888455		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 3.160520786888455 | validation: 2.4833893122730597]
	TIME [epoch: 24.8 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.059419911576892		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 3.059419911576892 | validation: 2.488290047823928]
	TIME [epoch: 24.8 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6039709887470126		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 3.6039709887470126 | validation: 3.0015008593829]
	TIME [epoch: 24.9 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1993726339696087		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 3.1993726339696087 | validation: 2.753779453072815]
	TIME [epoch: 24.8 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1639396275296408		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 3.1639396275296408 | validation: 3.028557928122154]
	TIME [epoch: 24.9 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.127010267558005		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 3.127010267558005 | validation: 2.6694210625366273]
	TIME [epoch: 24.9 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.142461482935377		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 3.142461482935377 | validation: 2.560742564190267]
	TIME [epoch: 24.8 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.197958281442588		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 3.197958281442588 | validation: 2.549345284545864]
	TIME [epoch: 24.9 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9901483294131395		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 2.9901483294131395 | validation: 3.118622470919869]
	TIME [epoch: 24.8 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9576655432281034		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 2.9576655432281034 | validation: 3.378436436237251]
	TIME [epoch: 24.9 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1919692797268606		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 3.1919692797268606 | validation: 2.8289847325533697]
	TIME [epoch: 24.8 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8592916637433046		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 2.8592916637433046 | validation: 4.44502486435864]
	TIME [epoch: 24.8 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4797722544163645		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 3.4797722544163645 | validation: 3.141341938576379]
	TIME [epoch: 24.8 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1415143566977415		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 3.1415143566977415 | validation: 2.617740737059908]
	TIME [epoch: 24.9 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9549448951695303		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 2.9549448951695303 | validation: 2.7525487351870463]
	TIME [epoch: 24.8 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0219396877436013		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 3.0219396877436013 | validation: 3.616771031007179]
	TIME [epoch: 24.9 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.146380564063271		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 3.146380564063271 | validation: 3.5494402956915803]
	TIME [epoch: 24.9 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4881715653994805		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 3.4881715653994805 | validation: 3.395584064675987]
	TIME [epoch: 24.7 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.227867107687981		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 3.227867107687981 | validation: 2.8924849093857192]
	TIME [epoch: 24.9 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9917285593395184		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 2.9917285593395184 | validation: 3.352290782093494]
	TIME [epoch: 24.8 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.13118791834025		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 3.13118791834025 | validation: 2.5265766975077018]
	TIME [epoch: 24.8 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8956876183919205		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 2.8956876183919205 | validation: 2.9781590042359465]
	TIME [epoch: 24.8 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1775479842876235		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 3.1775479842876235 | validation: 2.5566964168711044]
	TIME [epoch: 24.8 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2086068382254957		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 3.2086068382254957 | validation: 2.733536093894082]
	TIME [epoch: 24.8 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.115469283572004		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 3.115469283572004 | validation: 2.718218359473184]
	TIME [epoch: 24.8 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9197342438134952		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 2.9197342438134952 | validation: 2.47340641222128]
	TIME [epoch: 24.8 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.051858094906469		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 3.051858094906469 | validation: 2.7351956053224478]
	TIME [epoch: 24.8 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0044026715218313		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 3.0044026715218313 | validation: 2.6787197388641677]
	TIME [epoch: 24.8 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0287569772122938		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 3.0287569772122938 | validation: 2.73422721839925]
	TIME [epoch: 24.8 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.915312920177859		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 2.915312920177859 | validation: 3.792213804041419]
	TIME [epoch: 24.8 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3707433913896914		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 3.3707433913896914 | validation: 2.751927538857154]
	TIME [epoch: 24.8 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1534182602804917		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 3.1534182602804917 | validation: 2.437009362359445]
	TIME [epoch: 24.8 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.911443726914371		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 2.911443726914371 | validation: 2.950377265811211]
	TIME [epoch: 24.8 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.01308028150475		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 3.01308028150475 | validation: 2.9111007686456674]
	TIME [epoch: 24.8 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9405668039109147		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 2.9405668039109147 | validation: 4.765750250677662]
	TIME [epoch: 24.8 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7915570403652907		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 3.7915570403652907 | validation: 2.498014645476828]
	TIME [epoch: 24.9 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1564283872133228		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 3.1564283872133228 | validation: 2.42586516733337]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_160.pth
	Model improved!!!
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1153859560745047		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 3.1153859560745047 | validation: 2.638881669171437]
	TIME [epoch: 24.9 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.943537888537519		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 2.943537888537519 | validation: 3.0324241503291605]
	TIME [epoch: 24.9 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0021349953308083		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 3.0021349953308083 | validation: 2.71501316328252]
	TIME [epoch: 24.8 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8181186096173043		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 2.8181186096173043 | validation: 4.17021235290382]
	TIME [epoch: 24.9 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6635883018427666		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 3.6635883018427666 | validation: 4.102967046202123]
	TIME [epoch: 24.8 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7282376070936145		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 3.7282376070936145 | validation: 3.7883447830088084]
	TIME [epoch: 24.8 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4238176776973517		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 3.4238176776973517 | validation: 3.4935309885329096]
	TIME [epoch: 24.8 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2259491164352374		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 3.2259491164352374 | validation: 2.7641662135244385]
	TIME [epoch: 24.8 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8942993887916977		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 2.8942993887916977 | validation: 2.671333637946792]
	TIME [epoch: 24.9 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9461934979682223		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 2.9461934979682223 | validation: 2.650565978633149]
	TIME [epoch: 24.8 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.817567683077172		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 2.817567683077172 | validation: 2.832648961030202]
	TIME [epoch: 24.8 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9109144804856153		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 2.9109144804856153 | validation: 2.624161378458058]
	TIME [epoch: 24.8 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.850852593736584		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 2.850852593736584 | validation: 2.4667701705949554]
	TIME [epoch: 24.8 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.890277524405937		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 2.890277524405937 | validation: 2.7209028556537183]
	TIME [epoch: 24.8 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.879518076401861		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 2.879518076401861 | validation: 2.5338457468538134]
	TIME [epoch: 24.9 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.990013613387075		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 2.990013613387075 | validation: 2.69721547496196]
	TIME [epoch: 24.8 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8598458905564463		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 2.8598458905564463 | validation: 2.8089034216220172]
	TIME [epoch: 24.9 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.774014788891113		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 2.774014788891113 | validation: 2.6073723319162743]
	TIME [epoch: 24.9 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.810518415241244		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 2.810518415241244 | validation: 2.73045386555878]
	TIME [epoch: 24.8 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.789634545181828		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 2.789634545181828 | validation: 2.315553388259772]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_180.pth
	Model improved!!!
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.969883435238469		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 2.969883435238469 | validation: 2.800304103736396]
	TIME [epoch: 24.8 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9695222076289385		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 2.9695222076289385 | validation: 2.5906830874129243]
	TIME [epoch: 24.8 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1364558935372915		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 3.1364558935372915 | validation: 2.8999651855334174]
	TIME [epoch: 24.9 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.941313813973244		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 2.941313813973244 | validation: 2.37346198487533]
	TIME [epoch: 24.8 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8608423220099377		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 2.8608423220099377 | validation: 2.4578926525168767]
	TIME [epoch: 24.8 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.918542989739152		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 2.918542989739152 | validation: 2.951090467827801]
	TIME [epoch: 24.9 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.906884003960994		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 2.906884003960994 | validation: 2.5983155949759658]
	TIME [epoch: 24.8 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.876001642244172		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 2.876001642244172 | validation: 2.3866089014387626]
	TIME [epoch: 24.8 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.715609216328985		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 2.715609216328985 | validation: 2.528729021175905]
	TIME [epoch: 24.8 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.794139355248636		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 2.794139355248636 | validation: 3.093759095345638]
	TIME [epoch: 24.8 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.985266436224874		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 2.985266436224874 | validation: 2.627129563278468]
	TIME [epoch: 24.8 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.922975195872245		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 2.922975195872245 | validation: 2.279479081064311]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_192.pth
	Model improved!!!
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.813159538883974		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 2.813159538883974 | validation: 3.0341549720600716]
	TIME [epoch: 24.8 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9978462536336554		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 2.9978462536336554 | validation: 2.558856850563753]
	TIME [epoch: 24.8 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7961830988588323		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 2.7961830988588323 | validation: 2.855634647347047]
	TIME [epoch: 24.8 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8970306694699914		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 2.8970306694699914 | validation: 2.3950915824938828]
	TIME [epoch: 24.9 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.913418804246509		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 2.913418804246509 | validation: 2.5794385865230685]
	TIME [epoch: 24.9 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.854849658020461		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 2.854849658020461 | validation: 2.2908485324052967]
	TIME [epoch: 24.8 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7549772213012913		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 2.7549772213012913 | validation: 2.738811367937061]
	TIME [epoch: 24.9 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.153586256276696		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 3.153586256276696 | validation: 2.6730145419336337]
	TIME [epoch: 24.8 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9098167075581367		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 2.9098167075581367 | validation: 2.358238011536247]
	TIME [epoch: 24.8 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1710899754470336		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 3.1710899754470336 | validation: 2.8253251960494117]
	TIME [epoch: 24.8 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.862834971773148		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 2.862834971773148 | validation: 2.5777326901604547]
	TIME [epoch: 24.8 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9132285649417238		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 2.9132285649417238 | validation: 2.8928506456341525]
	TIME [epoch: 24.8 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0156869421714103		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 3.0156869421714103 | validation: 2.59748402853112]
	TIME [epoch: 24.8 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.701892864244854		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 2.701892864244854 | validation: 3.472763497056416]
	TIME [epoch: 24.8 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1853517252550967		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 3.1853517252550967 | validation: 3.688894286099989]
	TIME [epoch: 24.8 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3081983284689653		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 3.3081983284689653 | validation: 2.938822229371083]
	TIME [epoch: 24.8 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9021393485193414		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 2.9021393485193414 | validation: 2.3993331066493826]
	TIME [epoch: 24.8 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.755601857257653		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 2.755601857257653 | validation: 2.5036210213557526]
	TIME [epoch: 24.8 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6835850876299183		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 2.6835850876299183 | validation: 2.7929475090484743]
	TIME [epoch: 24.8 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.877395225495005		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 2.877395225495005 | validation: 2.6855202747449756]
	TIME [epoch: 24.8 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.97066453326197		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 2.97066453326197 | validation: 2.859185258472159]
	TIME [epoch: 24.8 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.918881569793756		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 2.918881569793756 | validation: 2.5572624701780535]
	TIME [epoch: 24.9 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.807085466056892		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 2.807085466056892 | validation: 2.6288151730590017]
	TIME [epoch: 24.8 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8939127810386784		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 2.8939127810386784 | validation: 2.465684884471283]
	TIME [epoch: 24.8 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7246439261996342		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 2.7246439261996342 | validation: 2.3286042030290215]
	TIME [epoch: 24.8 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6384376186111864		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 2.6384376186111864 | validation: 2.333150322279437]
	TIME [epoch: 24.8 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8078866456822524		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 2.8078866456822524 | validation: 2.2738862666197646]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_219.pth
	Model improved!!!
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.817982288695536		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 2.817982288695536 | validation: 2.8147175367293835]
	TIME [epoch: 24.8 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8845023294604104		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 2.8845023294604104 | validation: 2.6977977687227317]
	TIME [epoch: 24.8 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.767651507655232		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 2.767651507655232 | validation: 2.421839645953921]
	TIME [epoch: 24.8 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.938186948944288		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 2.938186948944288 | validation: 2.6140034322160455]
	TIME [epoch: 24.8 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8339804365252874		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 2.8339804365252874 | validation: 2.3306522097022384]
	TIME [epoch: 24.9 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7455254410857486		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 2.7455254410857486 | validation: 2.634213501326682]
	TIME [epoch: 24.8 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8556392966058026		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 2.8556392966058026 | validation: 2.670061469819826]
	TIME [epoch: 24.8 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8686716922596105		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 2.8686716922596105 | validation: 3.2817309702453326]
	TIME [epoch: 24.8 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9341024465506726		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 2.9341024465506726 | validation: 2.708240529503505]
	TIME [epoch: 24.8 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.816598254201506		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 2.816598254201506 | validation: 2.6177893239197387]
	TIME [epoch: 24.8 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6238508658522415		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 2.6238508658522415 | validation: 2.4124758416634773]
	TIME [epoch: 24.8 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9320464715161516		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 2.9320464715161516 | validation: 2.4514919674616067]
	TIME [epoch: 24.8 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8736792555661417		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 2.8736792555661417 | validation: 2.4318683560888315]
	TIME [epoch: 24.8 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.666468037238607		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 2.666468037238607 | validation: 2.5298103878553344]
	TIME [epoch: 24.8 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8922362328678073		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 2.8922362328678073 | validation: 2.3259693154167898]
	TIME [epoch: 24.8 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7115545958305014		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 2.7115545958305014 | validation: 2.449069384268172]
	TIME [epoch: 24.8 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7761843817871914		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 2.7761843817871914 | validation: 2.3304536483289393]
	TIME [epoch: 24.8 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9402839834840706		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 2.9402839834840706 | validation: 2.4786693563255024]
	TIME [epoch: 24.8 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9799558398317982		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 2.9799558398317982 | validation: 3.185256543882528]
	TIME [epoch: 24.8 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9822315092765246		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 2.9822315092765246 | validation: 2.472745640637137]
	TIME [epoch: 24.8 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7293221600112485		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 2.7293221600112485 | validation: 2.488209506264445]
	TIME [epoch: 24.8 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7009229848728302		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 2.7009229848728302 | validation: 2.5202535869261875]
	TIME [epoch: 24.8 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6361854865706835		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 2.6361854865706835 | validation: 2.4672239173280723]
	TIME [epoch: 24.8 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7304743362261847		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 2.7304743362261847 | validation: 2.6068567498117368]
	TIME [epoch: 24.8 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8151587762737815		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 2.8151587762737815 | validation: 2.3268484922362935]
	TIME [epoch: 24.8 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.77249639899383		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 2.77249639899383 | validation: 2.718836039730436]
	TIME [epoch: 24.8 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.803745701494359		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 2.803745701494359 | validation: 2.5334065437943556]
	TIME [epoch: 24.8 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6771186216764087		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 2.6771186216764087 | validation: 2.484504974279856]
	TIME [epoch: 24.8 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.635168385116048		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 2.635168385116048 | validation: 2.2783293311832664]
	TIME [epoch: 24.8 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7005570183771854		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 2.7005570183771854 | validation: 2.408779390499812]
	TIME [epoch: 24.8 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.617770146732628		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 2.617770146732628 | validation: 2.5738321205504313]
	TIME [epoch: 24.8 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8461239908676492		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 2.8461239908676492 | validation: 2.5826264652033286]
	TIME [epoch: 24.8 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7493422452379295		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 2.7493422452379295 | validation: 2.5642405893351485]
	TIME [epoch: 24.8 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8223086187149438		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 2.8223086187149438 | validation: 2.3174109560575444]
	TIME [epoch: 24.8 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.708153059126486		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 2.708153059126486 | validation: 2.337042514574797]
	TIME [epoch: 24.8 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6666537974412186		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 2.6666537974412186 | validation: 2.325288231369433]
	TIME [epoch: 24.8 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.630061672479423		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 2.630061672479423 | validation: 2.340090298149946]
	TIME [epoch: 24.8 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.863860183809957		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 2.863860183809957 | validation: 2.3807679033952556]
	TIME [epoch: 24.8 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.820155190052227		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 2.820155190052227 | validation: 3.1221510821670897]
	TIME [epoch: 24.8 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.869579337586366		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 2.869579337586366 | validation: 2.8208056260232013]
	TIME [epoch: 24.8 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7243360727700856		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 2.7243360727700856 | validation: 2.487792878652861]
	TIME [epoch: 24.8 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.67321454776088		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 2.67321454776088 | validation: 2.4801848974045604]
	TIME [epoch: 24.8 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6942301613504425		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 2.6942301613504425 | validation: 2.5290909729977047]
	TIME [epoch: 24.8 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7091113768859993		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 2.7091113768859993 | validation: 3.1790032846054705]
	TIME [epoch: 24.8 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.900960333881703		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 2.900960333881703 | validation: 2.6208562493581473]
	TIME [epoch: 24.7 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6493851183632686		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 2.6493851183632686 | validation: 2.9092048325134803]
	TIME [epoch: 24.8 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.796224498676636		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 2.796224498676636 | validation: 2.382296194558581]
	TIME [epoch: 24.9 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7064397177742388		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 2.7064397177742388 | validation: 2.2881574868998547]
	TIME [epoch: 24.8 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7155455069364094		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 2.7155455069364094 | validation: 3.10272857910055]
	TIME [epoch: 24.8 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.985388143138751		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 2.985388143138751 | validation: 2.2592100581048915]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_269.pth
	Model improved!!!
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6941182985946965		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 2.6941182985946965 | validation: 2.307095242932428]
	TIME [epoch: 24.8 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.776332311660367		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 2.776332311660367 | validation: 2.699430562457388]
	TIME [epoch: 24.8 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7798500510833755		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 2.7798500510833755 | validation: 2.293141730424353]
	TIME [epoch: 24.8 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.710833237838395		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 2.710833237838395 | validation: 2.385206009155322]
	TIME [epoch: 24.8 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7343874622135242		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 2.7343874622135242 | validation: 2.2467529501524486]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_274.pth
	Model improved!!!
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.660069415397147		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 2.660069415397147 | validation: 2.392607760179639]
	TIME [epoch: 24.8 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.700750064070317		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 2.700750064070317 | validation: 2.2433661597924295]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_276.pth
	Model improved!!!
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8058134093426608		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 2.8058134093426608 | validation: 3.2824824887865884]
	TIME [epoch: 24.8 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.049285262752951		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 3.049285262752951 | validation: 2.625402195420785]
	TIME [epoch: 24.8 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6935189973286704		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 2.6935189973286704 | validation: 2.284215904658044]
	TIME [epoch: 24.8 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8798924124702263		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 2.8798924124702263 | validation: 2.9595985769548765]
	TIME [epoch: 24.8 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.819004803037715		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 2.819004803037715 | validation: 2.3929619466919134]
	TIME [epoch: 24.8 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.643259406513296		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 2.643259406513296 | validation: 2.298371709753243]
	TIME [epoch: 24.8 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7301193474397496		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 2.7301193474397496 | validation: 2.3298874116548665]
	TIME [epoch: 24.8 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.69684926659009		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 2.69684926659009 | validation: 2.6851082221274147]
	TIME [epoch: 24.8 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.668180609532901		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 2.668180609532901 | validation: 2.5581076664717886]
	TIME [epoch: 24.8 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6975024845849696		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 2.6975024845849696 | validation: 2.413632478840679]
	TIME [epoch: 24.8 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.839138593787265		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 2.839138593787265 | validation: 2.3612128812320523]
	TIME [epoch: 24.8 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.700086771312251		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 2.700086771312251 | validation: 2.2767842412316885]
	TIME [epoch: 24.8 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.695375129435843		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 2.695375129435843 | validation: 2.4206124831915923]
	TIME [epoch: 24.8 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7665335652505245		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 2.7665335652505245 | validation: 2.3057583126297745]
	TIME [epoch: 24.8 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.572733712195394		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 2.572733712195394 | validation: 2.421044779092902]
	TIME [epoch: 24.8 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.649834920286846		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 2.649834920286846 | validation: 2.582462319950674]
	TIME [epoch: 24.8 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.756471268028581		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 2.756471268028581 | validation: 2.2800558764848335]
	TIME [epoch: 24.8 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6275619479707797		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 2.6275619479707797 | validation: 2.3049572830057294]
	TIME [epoch: 24.8 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6660695589818526		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 2.6660695589818526 | validation: 2.2290441266425645]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_295.pth
	Model improved!!!
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5892556841265115		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 2.5892556841265115 | validation: 2.4712760807548055]
	TIME [epoch: 24.8 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7604628312714956		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 2.7604628312714956 | validation: 2.2697711956651454]
	TIME [epoch: 24.8 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8204495014690663		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 2.8204495014690663 | validation: 2.2792795536712647]
	TIME [epoch: 24.8 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.563872937237676		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 2.563872937237676 | validation: 2.499075130978097]
	TIME [epoch: 24.8 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5917224745995435		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 2.5917224745995435 | validation: 3.9296214352871677]
	TIME [epoch: 24.7 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2766323551446854		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 3.2766323551446854 | validation: 2.3290030242987947]
	TIME [epoch: 24.8 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6396088108844387		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 2.6396088108844387 | validation: 2.911293202219691]
	TIME [epoch: 24.8 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.839907422802104		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 2.839907422802104 | validation: 2.387760236237778]
	TIME [epoch: 24.8 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.586779329405648		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 2.586779329405648 | validation: 2.287711168792937]
	TIME [epoch: 24.8 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.553149576746218		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 2.553149576746218 | validation: 2.4962182310298586]
	TIME [epoch: 24.8 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7204642061172803		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 2.7204642061172803 | validation: 2.4945601697247275]
	TIME [epoch: 24.8 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.773529762378857		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 2.773529762378857 | validation: 2.3517212713426523]
	TIME [epoch: 24.8 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6978247017193375		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 2.6978247017193375 | validation: 2.4055946918303084]
	TIME [epoch: 24.8 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6521273110918955		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 2.6521273110918955 | validation: 2.33207015984161]
	TIME [epoch: 24.7 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5972621963081792		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 2.5972621963081792 | validation: 2.3940935007689865]
	TIME [epoch: 24.8 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.913170847872776		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 2.913170847872776 | validation: 2.585622394876552]
	TIME [epoch: 24.8 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7221953952419318		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 2.7221953952419318 | validation: 2.261938910151021]
	TIME [epoch: 24.8 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5198672057141382		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 2.5198672057141382 | validation: 2.579347999008537]
	TIME [epoch: 24.8 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6648741306341357		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 2.6648741306341357 | validation: 2.44514433959421]
	TIME [epoch: 24.8 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6041812289949124		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 2.6041812289949124 | validation: 2.263457009108147]
	TIME [epoch: 24.7 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.722780909220823		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 2.722780909220823 | validation: 2.241487848721967]
	TIME [epoch: 24.8 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.60351222097616		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 2.60351222097616 | validation: 2.3332976136938313]
	TIME [epoch: 24.8 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7062807454689968		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 2.7062807454689968 | validation: 2.280815438673252]
	TIME [epoch: 24.8 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.632391794367387		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 2.632391794367387 | validation: 2.395920707458248]
	TIME [epoch: 24.8 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7192974894840214		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 2.7192974894840214 | validation: 2.2344968788088755]
	TIME [epoch: 24.8 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.685107354274372		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 2.685107354274372 | validation: 3.1754853505570892]
	TIME [epoch: 24.8 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.978221386063797		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 2.978221386063797 | validation: 2.2872846987214794]
	TIME [epoch: 24.8 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6146126341774436		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 2.6146126341774436 | validation: 2.2364537939208966]
	TIME [epoch: 24.8 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.566799588461884		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 2.566799588461884 | validation: 2.316059037116302]
	TIME [epoch: 24.8 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5579254127977467		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 2.5579254127977467 | validation: 2.22981328595196]
	TIME [epoch: 24.8 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.530143234996127		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 2.530143234996127 | validation: 2.19719141272737]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_326.pth
	Model improved!!!
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4219845786984733		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 3.4219845786984733 | validation: 4.297932832826385]
	TIME [epoch: 24.7 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3121907779798994		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 3.3121907779798994 | validation: 2.4200987646525993]
	TIME [epoch: 24.8 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6513210068769335		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 2.6513210068769335 | validation: 2.348244259647935]
	TIME [epoch: 24.8 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5562859427186932		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 2.5562859427186932 | validation: 2.318259167793064]
	TIME [epoch: 24.8 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5821505729125334		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 2.5821505729125334 | validation: 2.8502038326416415]
	TIME [epoch: 24.8 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.729271147585252		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 2.729271147585252 | validation: 2.3437315929741693]
	TIME [epoch: 24.8 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5502818300533736		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 2.5502818300533736 | validation: 2.184754657334529]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_333.pth
	Model improved!!!
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.579797997561523		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 2.579797997561523 | validation: 2.2015264396155105]
	TIME [epoch: 24.9 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.638083545099672		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 2.638083545099672 | validation: 2.313773548321587]
	TIME [epoch: 24.8 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.591907787059399		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 2.591907787059399 | validation: 2.2362586747219]
	TIME [epoch: 24.8 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.49736248619794		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 2.49736248619794 | validation: 2.3343141709680375]
	TIME [epoch: 24.8 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.507590470219859		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 2.507590470219859 | validation: 2.3017194211184915]
	TIME [epoch: 24.8 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.598045170732014		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 2.598045170732014 | validation: 2.20754875827551]
	TIME [epoch: 24.8 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.624486003196904		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 2.624486003196904 | validation: 2.277551848565819]
	TIME [epoch: 24.8 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4833164941362136		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 2.4833164941362136 | validation: 2.823796767801784]
	TIME [epoch: 24.8 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6949427475961865		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 2.6949427475961865 | validation: 2.4840207742898333]
	TIME [epoch: 24.8 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6390644497065527		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 2.6390644497065527 | validation: 2.4027319979894366]
	TIME [epoch: 24.8 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.552873056458232		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 2.552873056458232 | validation: 2.334844997137701]
	TIME [epoch: 24.9 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.580518629255673		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 2.580518629255673 | validation: 2.372945000876309]
	TIME [epoch: 24.8 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5593524730228263		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 2.5593524730228263 | validation: 2.3519884111396157]
	TIME [epoch: 24.9 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5489277308487206		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 2.5489277308487206 | validation: 2.418038479667875]
	TIME [epoch: 24.8 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5304772690444013		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 2.5304772690444013 | validation: 2.371764734341584]
	TIME [epoch: 24.8 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6271939841031307		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 2.6271939841031307 | validation: 2.3888572190941373]
	TIME [epoch: 24.8 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5908319626285685		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 2.5908319626285685 | validation: 2.2762015445285475]
	TIME [epoch: 24.8 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.545768988899869		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 2.545768988899869 | validation: 2.2253352979372902]
	TIME [epoch: 24.8 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5401578870843604		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 2.5401578870843604 | validation: 2.204480807765412]
	TIME [epoch: 24.8 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5544421994957704		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 2.5544421994957704 | validation: 2.2110363860900573]
	TIME [epoch: 24.8 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.461627336880322		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 2.461627336880322 | validation: 3.069847422313136]
	TIME [epoch: 24.8 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0304517053195155		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 3.0304517053195155 | validation: 2.5270123402959164]
	TIME [epoch: 24.8 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6735463249878526		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 2.6735463249878526 | validation: 2.269194978856661]
	TIME [epoch: 24.8 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5281784365821878		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 2.5281784365821878 | validation: 2.3582460834283814]
	TIME [epoch: 24.8 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5917796844843464		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 2.5917796844843464 | validation: 2.4416476646971783]
	TIME [epoch: 24.8 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6308935401776568		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 2.6308935401776568 | validation: 2.246311875570123]
	TIME [epoch: 24.8 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.617953395477965		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 2.617953395477965 | validation: 2.204509446770977]
	TIME [epoch: 24.8 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.475289140658823		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 2.475289140658823 | validation: 2.3133062121402044]
	TIME [epoch: 24.8 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5330130666287873		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 2.5330130666287873 | validation: 2.3961772962446473]
	TIME [epoch: 24.8 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.667755307801452		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 2.667755307801452 | validation: 2.2363501668700234]
	TIME [epoch: 24.8 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.523014560159529		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 2.523014560159529 | validation: 2.5782003740370016]
	TIME [epoch: 24.9 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6218820838494583		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 2.6218820838494583 | validation: 2.418989778081769]
	TIME [epoch: 24.8 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5744408476953557		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 2.5744408476953557 | validation: 2.2453366092822455]
	TIME [epoch: 24.8 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5262406568315727		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 2.5262406568315727 | validation: 3.037885397848457]
	TIME [epoch: 24.9 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.859031521148113		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 2.859031521148113 | validation: 2.185900537839877]
	TIME [epoch: 24.8 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4880440500380177		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 2.4880440500380177 | validation: 2.256497849637905]
	TIME [epoch: 24.8 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5384685973742664		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 2.5384685973742664 | validation: 2.4001193659729028]
	TIME [epoch: 24.9 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.63762941761185		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 2.63762941761185 | validation: 2.2126301362961804]
	TIME [epoch: 24.9 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5832719699745947		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 2.5832719699745947 | validation: 2.2505850237627216]
	TIME [epoch: 24.8 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.532430011353342		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 2.532430011353342 | validation: 2.3982242298109435]
	TIME [epoch: 24.9 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.67165887675781		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 2.67165887675781 | validation: 2.1943272507612055]
	TIME [epoch: 24.9 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4553614731467697		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 2.4553614731467697 | validation: 2.1946082214060314]
	TIME [epoch: 24.8 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6527547146400847		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 2.6527547146400847 | validation: 2.3232006633203883]
	TIME [epoch: 24.8 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4765740105572425		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 2.4765740105572425 | validation: 2.272950695690098]
	TIME [epoch: 24.8 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5177440104813176		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 2.5177440104813176 | validation: 2.231445682949639]
	TIME [epoch: 24.8 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.513836982879112		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 2.513836982879112 | validation: 2.202527768326262]
	TIME [epoch: 24.8 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.48433137345783		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 2.48433137345783 | validation: 2.2116487936748435]
	TIME [epoch: 24.9 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5011984731012076		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 2.5011984731012076 | validation: 2.2052819520122693]
	TIME [epoch: 24.7 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6340979328960312		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 2.6340979328960312 | validation: 2.3988658271730974]
	TIME [epoch: 24.9 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.542821954412889		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 2.542821954412889 | validation: 2.266050479018126]
	TIME [epoch: 24.8 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5116318224057164		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 2.5116318224057164 | validation: 2.3190071493138116]
	TIME [epoch: 24.8 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5181712948394095		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 2.5181712948394095 | validation: 2.499307842376681]
	TIME [epoch: 24.8 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5909608753652753		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 2.5909608753652753 | validation: 2.3351858257745266]
	TIME [epoch: 24.8 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.690135173334639		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 2.690135173334639 | validation: 2.248168186712235]
	TIME [epoch: 24.8 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.578825446363237		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 2.578825446363237 | validation: 2.2712805306743555]
	TIME [epoch: 24.9 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.551780209280132		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 2.551780209280132 | validation: 2.217537432851082]
	TIME [epoch: 24.9 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.613932150726268		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 2.613932150726268 | validation: 2.2016277389446492]
	TIME [epoch: 24.8 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4830479215472723		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 2.4830479215472723 | validation: 2.218756118563075]
	TIME [epoch: 24.9 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.600608019098996		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 2.600608019098996 | validation: 2.1762663455645384]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_392.pth
	Model improved!!!
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.526291189444074		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 2.526291189444074 | validation: 2.373943448698761]
	TIME [epoch: 24.8 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.50260602381007		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 2.50260602381007 | validation: 2.2111001761111546]
	TIME [epoch: 24.9 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5658295058564073		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 2.5658295058564073 | validation: 2.325178005674538]
	TIME [epoch: 24.9 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6061971140089484		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 2.6061971140089484 | validation: 2.7676242783497638]
	TIME [epoch: 24.8 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6641360081914516		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 2.6641360081914516 | validation: 2.1839092306059853]
	TIME [epoch: 24.8 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5123554882850163		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 2.5123554882850163 | validation: 2.3025175696791207]
	TIME [epoch: 24.8 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5728176496277437		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 2.5728176496277437 | validation: 2.183243421953437]
	TIME [epoch: 24.8 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.509095215914918		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 2.509095215914918 | validation: 2.311983895756484]
	TIME [epoch: 24.9 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.559987792574338		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 2.559987792574338 | validation: 2.236848244226435]
	TIME [epoch: 24.8 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.468655040415707		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 2.468655040415707 | validation: 2.999955093486422]
	TIME [epoch: 24.8 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.816346340692327		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 2.816346340692327 | validation: 2.5536059272748837]
	TIME [epoch: 24.8 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6684294662785657		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 2.6684294662785657 | validation: 2.250171009120324]
	TIME [epoch: 24.8 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5619222319981634		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 2.5619222319981634 | validation: 2.2282365056727778]
	TIME [epoch: 24.8 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5204906014399535		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 2.5204906014399535 | validation: 2.181150492841744]
	TIME [epoch: 24.8 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.452288920976421		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 2.452288920976421 | validation: 2.3779186252361293]
	TIME [epoch: 24.8 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6248493631191194		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 2.6248493631191194 | validation: 2.325446037832804]
	TIME [epoch: 24.8 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.484204623056071		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 2.484204623056071 | validation: 2.2494687446170647]
	TIME [epoch: 24.8 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.557215886122792		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 2.557215886122792 | validation: 2.304428084501643]
	TIME [epoch: 24.8 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.506184564922671		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 2.506184564922671 | validation: 2.1642459950157305]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_411.pth
	Model improved!!!
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4928116025185667		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 2.4928116025185667 | validation: 2.1400564509049365]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_412.pth
	Model improved!!!
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5408485140582715		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 2.5408485140582715 | validation: 2.2149417845504398]
	TIME [epoch: 24.8 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4716849668773975		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 2.4716849668773975 | validation: 2.167680126508513]
	TIME [epoch: 24.8 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4605096891920866		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 2.4605096891920866 | validation: 2.223035373542907]
	TIME [epoch: 24.8 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4958483663331466		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 2.4958483663331466 | validation: 2.137114728556181]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_416.pth
	Model improved!!!
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.412350661802645		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 2.412350661802645 | validation: 2.443505472064206]
	TIME [epoch: 24.8 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5557632011081046		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 2.5557632011081046 | validation: 2.6421691066673003]
	TIME [epoch: 24.8 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.627754872022866		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 2.627754872022866 | validation: 2.3221333049759285]
	TIME [epoch: 24.8 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.492085324784642		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 2.492085324784642 | validation: 2.191668571301299]
	TIME [epoch: 24.8 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4614231460022173		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 2.4614231460022173 | validation: 2.1646107721108616]
	TIME [epoch: 24.8 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5229845763617016		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 2.5229845763617016 | validation: 2.1691570098362813]
	TIME [epoch: 24.9 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.565510727694866		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 2.565510727694866 | validation: 2.1434289023111375]
	TIME [epoch: 24.8 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4874372626031622		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 2.4874372626031622 | validation: 2.2802065880035345]
	TIME [epoch: 24.9 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.530984513624037		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 2.530984513624037 | validation: 2.231158758645118]
	TIME [epoch: 24.8 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.439213462044282		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 2.439213462044282 | validation: 2.217297268131173]
	TIME [epoch: 24.8 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4841858293017003		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 2.4841858293017003 | validation: 2.295942880821189]
	TIME [epoch: 24.9 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4874158608524146		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 2.4874158608524146 | validation: 2.250104012703509]
	TIME [epoch: 24.8 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.456193792292206		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 2.456193792292206 | validation: 2.331010410778115]
	TIME [epoch: 24.8 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5264968057170996		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 2.5264968057170996 | validation: 2.1629275924422915]
	TIME [epoch: 24.8 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.441656775493829		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 2.441656775493829 | validation: 2.1525107693724608]
	TIME [epoch: 24.9 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4923471561225155		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 2.4923471561225155 | validation: 2.2477861657749774]
	TIME [epoch: 24.8 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.467447176358557		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 2.467447176358557 | validation: 2.4466084337223766]
	TIME [epoch: 24.8 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5784749009966914		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 2.5784749009966914 | validation: 2.144909996019047]
	TIME [epoch: 24.8 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5390808852547977		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 2.5390808852547977 | validation: 2.210269344596335]
	TIME [epoch: 24.8 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5134309586989856		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 2.5134309586989856 | validation: 2.187996945228198]
	TIME [epoch: 24.9 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4626515088830105		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 2.4626515088830105 | validation: 2.1258689467494]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_437.pth
	Model improved!!!
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4320900817868303		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 2.4320900817868303 | validation: 2.2346057958836973]
	TIME [epoch: 24.8 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4501851755924657		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 2.4501851755924657 | validation: 2.16421418136403]
	TIME [epoch: 24.8 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4933076335107835		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 2.4933076335107835 | validation: 2.22596741835028]
	TIME [epoch: 24.8 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.697147029649191		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 2.697147029649191 | validation: 2.238459559420188]
	TIME [epoch: 24.8 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4764632991340436		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 2.4764632991340436 | validation: 2.1710258362409243]
	TIME [epoch: 24.9 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4508849031975775		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 2.4508849031975775 | validation: 2.1853812446601926]
	TIME [epoch: 24.8 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.484396620121416		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 2.484396620121416 | validation: 2.223253990493716]
	TIME [epoch: 24.8 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.459490546652508		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 2.459490546652508 | validation: 2.201433548308475]
	TIME [epoch: 24.8 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4962927088106097		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 2.4962927088106097 | validation: 2.225686839807322]
	TIME [epoch: 24.9 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4553044459864553		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 2.4553044459864553 | validation: 2.5840810939473284]
	TIME [epoch: 24.8 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5745336560678065		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 2.5745336560678065 | validation: 2.125270860166002]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_448.pth
	Model improved!!!
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4292574630404467		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 2.4292574630404467 | validation: 2.365682696633715]
	TIME [epoch: 24.8 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4946932544310316		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 2.4946932544310316 | validation: 2.2282329384374457]
	TIME [epoch: 24.8 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5236585685742723		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 2.5236585685742723 | validation: 2.1403516774224403]
	TIME [epoch: 24.9 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.503826679365994		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 2.503826679365994 | validation: 2.22529662053871]
	TIME [epoch: 24.9 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4877606619469046		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 2.4877606619469046 | validation: 2.150694114824117]
	TIME [epoch: 24.9 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4817356086980866		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 2.4817356086980866 | validation: 2.2186495669273776]
	TIME [epoch: 24.9 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5880780225827493		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 2.5880780225827493 | validation: 2.251822538865009]
	TIME [epoch: 24.9 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.453296497032467		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 2.453296497032467 | validation: 2.1367394206813537]
	TIME [epoch: 24.8 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5414032046655364		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 2.5414032046655364 | validation: 2.1780154274508696]
	TIME [epoch: 24.9 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.450298595681193		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 2.450298595681193 | validation: 2.334970440075501]
	TIME [epoch: 24.9 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.533416506597311		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 2.533416506597311 | validation: 2.159375983633978]
	TIME [epoch: 24.8 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.450872274357302		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 2.450872274357302 | validation: 2.2124964892056607]
	TIME [epoch: 24.9 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4632691777708446		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 2.4632691777708446 | validation: 2.1449396986814797]
	TIME [epoch: 24.9 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4639095639480493		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 2.4639095639480493 | validation: 2.4896857710122764]
	TIME [epoch: 24.8 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5504669451819924		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 2.5504669451819924 | validation: 2.1728329356709577]
	TIME [epoch: 24.9 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4300993334156518		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 2.4300993334156518 | validation: 2.250272887715365]
	TIME [epoch: 24.9 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6192562312427907		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 2.6192562312427907 | validation: 2.1242867898478686]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_465.pth
	Model improved!!!
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4691146398032866		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 2.4691146398032866 | validation: 2.16197148416704]
	TIME [epoch: 24.9 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4341108425167817		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 2.4341108425167817 | validation: 2.427504535118353]
	TIME [epoch: 24.8 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5201493834069284		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 2.5201493834069284 | validation: 2.290185233249292]
	TIME [epoch: 24.9 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4584401864139447		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 2.4584401864139447 | validation: 2.2200327878862867]
	TIME [epoch: 24.8 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4368034975372215		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 2.4368034975372215 | validation: 2.361001314318686]
	TIME [epoch: 24.9 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4919832417047427		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 2.4919832417047427 | validation: 2.1510994829845878]
	TIME [epoch: 24.8 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4432805732074687		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 2.4432805732074687 | validation: 2.1885920335928306]
	TIME [epoch: 24.8 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.426948606665614		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 2.426948606665614 | validation: 2.219941925384587]
	TIME [epoch: 24.9 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.46249136017816		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 2.46249136017816 | validation: 2.209978681536728]
	TIME [epoch: 24.8 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4008306744697765		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 2.4008306744697765 | validation: 2.247235984988584]
	TIME [epoch: 24.9 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4103779881458878		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 2.4103779881458878 | validation: 2.2494496327917513]
	TIME [epoch: 24.9 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4314485430577815		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 2.4314485430577815 | validation: 2.2529971044901185]
	TIME [epoch: 24.8 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4602203493481647		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 2.4602203493481647 | validation: 2.217358757654624]
	TIME [epoch: 24.9 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.864378165698754		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 2.864378165698754 | validation: 2.137499670675511]
	TIME [epoch: 24.8 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4495078931834655		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 2.4495078931834655 | validation: 2.3356283423530506]
	TIME [epoch: 24.8 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4994433460497807		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 2.4994433460497807 | validation: 2.359671137434448]
	TIME [epoch: 24.9 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4987554116299413		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 2.4987554116299413 | validation: 2.3394396732767215]
	TIME [epoch: 24.9 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5893944064038816		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 2.5893944064038816 | validation: 2.2633828627218886]
	TIME [epoch: 24.8 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4343807896234386		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 2.4343807896234386 | validation: 2.229284339179655]
	TIME [epoch: 24.9 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.452757450935737		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 2.452757450935737 | validation: 2.2060720036945107]
	TIME [epoch: 24.8 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4507391174532764		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 2.4507391174532764 | validation: 2.1836326240185686]
	TIME [epoch: 24.8 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.438688348699522		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 2.438688348699522 | validation: 2.1732405464382323]
	TIME [epoch: 24.9 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.458596252638521		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 2.458596252638521 | validation: 2.1666835544170446]
	TIME [epoch: 24.9 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.416480652635325		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 2.416480652635325 | validation: 2.2192677081645997]
	TIME [epoch: 24.8 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4339343427178126		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 2.4339343427178126 | validation: 2.3722057916530916]
	TIME [epoch: 24.9 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.521002405710869		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 2.521002405710869 | validation: 2.2087842527582513]
	TIME [epoch: 24.8 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.428140251479873		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 2.428140251479873 | validation: 2.1257730320291794]
	TIME [epoch: 24.8 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.381622264204742		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 2.381622264204742 | validation: 2.4994398107792755]
	TIME [epoch: 24.9 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.610794529084915		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 2.610794529084915 | validation: 2.344942803893622]
	TIME [epoch: 24.9 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5967085709006668		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 2.5967085709006668 | validation: 2.20586039408737]
	TIME [epoch: 24.8 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.460547671317045		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 2.460547671317045 | validation: 2.144954985192653]
	TIME [epoch: 24.9 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.424556656503501		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 2.424556656503501 | validation: 2.1512014272364355]
	TIME [epoch: 24.9 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.476169827828749		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 2.476169827828749 | validation: 2.124315296091451]
	TIME [epoch: 24.8 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4413793117651537		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 2.4413793117651537 | validation: 2.264928389356127]
	TIME [epoch: 24.9 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.551289383710577		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 2.551289383710577 | validation: 2.2305529631369154]
	TIME [epoch: 24.8 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4412553922513505		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 2.4412553922513505 | validation: 2.1135633013574444]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_501.pth
	Model improved!!!
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.440146245073325		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 2.440146245073325 | validation: 2.301300018359]
	TIME [epoch: 24.8 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.444695824072477		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 2.444695824072477 | validation: 2.1430268856569916]
	TIME [epoch: 24.8 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.394029527569552		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 2.394029527569552 | validation: 2.266443840606085]
	TIME [epoch: 24.8 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.442507936968113		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 2.442507936968113 | validation: 2.1173499943354046]
	TIME [epoch: 24.8 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3921543132083145		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 2.3921543132083145 | validation: 2.2703695200410023]
	TIME [epoch: 24.8 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4803650690780024		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 2.4803650690780024 | validation: 2.1697766497517366]
	TIME [epoch: 24.8 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3970116133755575		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 2.3970116133755575 | validation: 2.1401742620227626]
	TIME [epoch: 24.8 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4020858280328956		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 2.4020858280328956 | validation: 2.107996425233562]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_509.pth
	Model improved!!!
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4102423048358643		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 2.4102423048358643 | validation: 2.1760364491130253]
	TIME [epoch: 24.8 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4037308219526046		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 2.4037308219526046 | validation: 2.1020987051427094]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_511.pth
	Model improved!!!
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4658201039352727		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 2.4658201039352727 | validation: 2.1182878512868193]
	TIME [epoch: 24.8 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.392035711194906		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 2.392035711194906 | validation: 2.114531129000542]
	TIME [epoch: 24.8 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.378740857411182		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 2.378740857411182 | validation: 2.1688484154281475]
	TIME [epoch: 24.8 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.410392952081508		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 2.410392952081508 | validation: 2.3925104589980264]
	TIME [epoch: 24.8 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.464987609825002		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 2.464987609825002 | validation: 2.439364530647081]
	TIME [epoch: 24.8 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.490013652170623		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 2.490013652170623 | validation: 2.2508448742480223]
	TIME [epoch: 24.8 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4642044038899122		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 2.4642044038899122 | validation: 2.1192713439131605]
	TIME [epoch: 24.8 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.369193605745331		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 2.369193605745331 | validation: 2.118837778410006]
	TIME [epoch: 24.8 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4680887211673608		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 2.4680887211673608 | validation: 2.1565089414402467]
	TIME [epoch: 24.8 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.601261122535197		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 2.601261122535197 | validation: 2.3622136448875115]
	TIME [epoch: 24.8 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4656513365375856		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 2.4656513365375856 | validation: 2.122158408704883]
	TIME [epoch: 24.8 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3901466554442936		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 2.3901466554442936 | validation: 2.1198047557277637]
	TIME [epoch: 24.8 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4132178599926855		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 2.4132178599926855 | validation: 2.272757776921025]
	TIME [epoch: 24.8 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.443500612826269		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 2.443500612826269 | validation: 2.358653147555825]
	TIME [epoch: 24.8 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5414684340346594		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 2.5414684340346594 | validation: 2.2698566757396113]
	TIME [epoch: 24.8 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4203377204429586		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 2.4203377204429586 | validation: 2.1857359051772445]
	TIME [epoch: 24.8 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4317042936434707		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 2.4317042936434707 | validation: 2.1648408586726093]
	TIME [epoch: 24.8 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3680399912763876		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 2.3680399912763876 | validation: 2.112055175131421]
	TIME [epoch: 24.8 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4431247158638056		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 2.4431247158638056 | validation: 2.154399896803023]
	TIME [epoch: 24.8 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.380784733353473		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 2.380784733353473 | validation: 2.1655059790785054]
	TIME [epoch: 24.8 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.379461578081672		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 2.379461578081672 | validation: 2.105072168861605]
	TIME [epoch: 24.8 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3700413221909344		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 2.3700413221909344 | validation: 2.1831015425782323]
	TIME [epoch: 24.8 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4059206605954317		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 2.4059206605954317 | validation: 2.158809248464924]
	TIME [epoch: 24.8 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4184042605764375		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 2.4184042605764375 | validation: 2.1541470974347594]
	TIME [epoch: 24.8 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.564315084215651		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 2.564315084215651 | validation: 2.1309543093863814]
	TIME [epoch: 24.8 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3679196519645656		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 2.3679196519645656 | validation: 2.0963783099949898]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_537.pth
	Model improved!!!
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.367820779604715		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 2.367820779604715 | validation: 2.0969966821019126]
	TIME [epoch: 24.8 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3977926657757864		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 2.3977926657757864 | validation: 2.3186341573371103]
	TIME [epoch: 24.8 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.482815753826606		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 2.482815753826606 | validation: 2.126661182837508]
	TIME [epoch: 24.8 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4075341702317266		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 2.4075341702317266 | validation: 2.1593499485195324]
	TIME [epoch: 24.8 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.409155460096008		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 2.409155460096008 | validation: 2.1256675477524265]
	TIME [epoch: 24.8 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3935673350585063		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 2.3935673350585063 | validation: 2.1103045069329642]
	TIME [epoch: 24.8 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4345958001658756		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 2.4345958001658756 | validation: 2.3161607536055535]
	TIME [epoch: 24.8 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4522717408735466		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 2.4522717408735466 | validation: 2.194029630684083]
	TIME [epoch: 24.9 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.457274985990435		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 2.457274985990435 | validation: 2.1001751333352017]
	TIME [epoch: 24.8 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.426409954909497		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 2.426409954909497 | validation: 2.4264240485456194]
	TIME [epoch: 24.9 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.488937565165723		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 2.488937565165723 | validation: 2.1518198421780954]
	TIME [epoch: 24.8 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.372635050749711		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 2.372635050749711 | validation: 2.2448816931870472]
	TIME [epoch: 24.8 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4237348622936903		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 2.4237348622936903 | validation: 2.246950814217659]
	TIME [epoch: 24.9 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.393861045543364		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 2.393861045543364 | validation: 2.149482291318539]
	TIME [epoch: 24.8 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.405672328302199		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 2.405672328302199 | validation: 2.088823009933333]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_552.pth
	Model improved!!!
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.383330470176091		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 2.383330470176091 | validation: 2.1451808534907033]
	TIME [epoch: 24.9 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.396968398648556		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 2.396968398648556 | validation: 2.26802065403942]
	TIME [epoch: 24.8 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4218872945599834		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 2.4218872945599834 | validation: 2.092524904387676]
	TIME [epoch: 24.9 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.449050663154738		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 2.449050663154738 | validation: 2.21850705076989]
	TIME [epoch: 24.9 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4556965388088634		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 2.4556965388088634 | validation: 2.1657662257392776]
	TIME [epoch: 24.9 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.36640942175581		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 2.36640942175581 | validation: 2.2034342473039654]
	TIME [epoch: 24.8 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.493563245517873		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 2.493563245517873 | validation: 2.1411923166652342]
	TIME [epoch: 24.9 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6049187104224427		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 2.6049187104224427 | validation: 2.110461038663489]
	TIME [epoch: 24.9 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.369215520190093		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 2.369215520190093 | validation: 2.2029027905304113]
	TIME [epoch: 24.8 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4186790423614917		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 2.4186790423614917 | validation: 2.1140970651173587]
	TIME [epoch: 24.8 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3972364562955697		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 2.3972364562955697 | validation: 2.0987162891762625]
	TIME [epoch: 24.8 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.364489850763912		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 2.364489850763912 | validation: 2.1124063356850193]
	TIME [epoch: 24.8 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3566773505745156		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 2.3566773505745156 | validation: 2.1137016135445514]
	TIME [epoch: 24.8 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.453738047572679		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 2.453738047572679 | validation: 2.183913497020796]
	TIME [epoch: 24.8 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.377844670661132		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 2.377844670661132 | validation: 2.0893505088415236]
	TIME [epoch: 24.8 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4086253466816085		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 2.4086253466816085 | validation: 2.156725663203979]
	TIME [epoch: 24.8 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3729394596616125		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 2.3729394596616125 | validation: 2.128344664174101]
	TIME [epoch: 24.8 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3516748209913203		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 2.3516748209913203 | validation: 2.070118597098446]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_570.pth
	Model improved!!!
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.373154596173827		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 2.373154596173827 | validation: 2.1156498569615723]
	TIME [epoch: 24.8 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3839709204436392		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 2.3839709204436392 | validation: 2.085353195452199]
	TIME [epoch: 24.9 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.393721776648102		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 2.393721776648102 | validation: 2.0892855311231906]
	TIME [epoch: 24.8 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3574044541133805		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 2.3574044541133805 | validation: 2.143953831253312]
	TIME [epoch: 24.8 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3803890628535043		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 2.3803890628535043 | validation: 2.084889868953421]
	TIME [epoch: 24.8 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.388994153073492		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 2.388994153073492 | validation: 2.0960634327970293]
	TIME [epoch: 24.8 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4763860243171023		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 2.4763860243171023 | validation: 2.0978482451375497]
	TIME [epoch: 24.8 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.346701525651145		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 2.346701525651145 | validation: 2.1324166085828256]
	TIME [epoch: 24.8 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4098794087741098		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 2.4098794087741098 | validation: 2.1278505989579393]
	TIME [epoch: 24.8 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3747547849022226		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 2.3747547849022226 | validation: 2.1358579266447975]
	TIME [epoch: 24.8 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3899863561718058		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 2.3899863561718058 | validation: 2.1525667654003477]
	TIME [epoch: 24.8 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.37100439403802		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 2.37100439403802 | validation: 2.1464168644375827]
	TIME [epoch: 24.8 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3833771067312313		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 2.3833771067312313 | validation: 2.0996545479793376]
	TIME [epoch: 24.8 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3863880236565946		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 2.3863880236565946 | validation: 2.0828145479908335]
	TIME [epoch: 24.8 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.355342604868153		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 2.355342604868153 | validation: 2.189585009041965]
	TIME [epoch: 24.8 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4396323963102193		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 2.4396323963102193 | validation: 2.080491697992011]
	TIME [epoch: 24.8 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.353553349076296		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 2.353553349076296 | validation: 2.0896121776130245]
	TIME [epoch: 24.8 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4147842279552387		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 2.4147842279552387 | validation: 2.157192074892392]
	TIME [epoch: 24.7 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3599584816845542		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 2.3599584816845542 | validation: 2.0756437328466864]
	TIME [epoch: 24.8 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.555163611412791		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 2.555163611412791 | validation: 2.668161212742264]
	TIME [epoch: 24.8 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5513063071021898		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 2.5513063071021898 | validation: 2.129919978024824]
	TIME [epoch: 24.8 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3437199518805256		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 2.3437199518805256 | validation: 2.0827825490374683]
	TIME [epoch: 24.8 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3316822845498635		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 2.3316822845498635 | validation: 2.2146513406511072]
	TIME [epoch: 24.8 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.444655801143178		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 2.444655801143178 | validation: 2.2780472057745293]
	TIME [epoch: 24.8 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3859636865252716		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 2.3859636865252716 | validation: 2.3904654237801948]
	TIME [epoch: 24.8 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4640440401045067		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 2.4640440401045067 | validation: 2.0735715559886856]
	TIME [epoch: 24.8 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.336085025195391		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 2.336085025195391 | validation: 2.1615897095112797]
	TIME [epoch: 24.8 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.413087203068477		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 2.413087203068477 | validation: 2.3062587517918565]
	TIME [epoch: 24.8 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4460544568468072		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 2.4460544568468072 | validation: 2.174438448038375]
	TIME [epoch: 24.8 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.368681881012029		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 2.368681881012029 | validation: 2.1416522264229165]
	TIME [epoch: 24.8 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4920531498167247		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 2.4920531498167247 | validation: 2.1910832046066724]
	TIME [epoch: 24.8 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.532209705274261		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 2.532209705274261 | validation: 2.084634889492878]
	TIME [epoch: 24.8 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.393766506374887		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 2.393766506374887 | validation: 2.1618215168122323]
	TIME [epoch: 24.8 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.37188535148455		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 2.37188535148455 | validation: 2.1164284640418853]
	TIME [epoch: 24.8 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4138077999263223		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 2.4138077999263223 | validation: 2.0862485694913158]
	TIME [epoch: 24.7 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4709668721846105		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 2.4709668721846105 | validation: 2.079615523924644]
	TIME [epoch: 24.7 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.342364348452938		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 2.342364348452938 | validation: 2.1970247027314254]
	TIME [epoch: 24.8 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.397513348621998		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 2.397513348621998 | validation: 2.092643388624378]
	TIME [epoch: 24.8 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3471245604286324		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 2.3471245604286324 | validation: 2.157299155771263]
	TIME [epoch: 24.7 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3899305217578566		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 2.3899305217578566 | validation: 2.1200383243991467]
	TIME [epoch: 24.8 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3826993847125655		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 2.3826993847125655 | validation: 2.1026496120651363]
	TIME [epoch: 24.8 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.350018665328534		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 2.350018665328534 | validation: 2.091709211992021]
	TIME [epoch: 24.8 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3562200671039673		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 2.3562200671039673 | validation: 2.135478132362025]
	TIME [epoch: 24.8 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3782072126630815		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 2.3782072126630815 | validation: 2.2134479506302718]
	TIME [epoch: 24.8 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.383279580248081		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 2.383279580248081 | validation: 2.124589866073088]
	TIME [epoch: 24.8 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3833464926942796		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 2.3833464926942796 | validation: 2.3806523876998478]
	TIME [epoch: 24.8 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4284414712685027		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 2.4284414712685027 | validation: 2.1704299384244297]
	TIME [epoch: 24.8 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3577007510216816		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 2.3577007510216816 | validation: 2.110132185820375]
	TIME [epoch: 24.8 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.366250689096054		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 2.366250689096054 | validation: 2.0818345799713005]
	TIME [epoch: 24.8 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.349340479962754		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 2.349340479962754 | validation: 2.157463191547351]
	TIME [epoch: 24.8 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.458466449462107		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 2.458466449462107 | validation: 2.296883029225894]
	TIME [epoch: 24.8 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4241724635703474		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 2.4241724635703474 | validation: 2.1330941719443284]
	TIME [epoch: 24.8 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3578665028039327		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 2.3578665028039327 | validation: 2.2511092893290257]
	TIME [epoch: 24.8 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3898880548309944		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 2.3898880548309944 | validation: 2.185128003116482]
	TIME [epoch: 24.8 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4044842266016815		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 2.4044842266016815 | validation: 2.2193562073390214]
	TIME [epoch: 24.8 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.394224872016286		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 2.394224872016286 | validation: 2.1319983725859344]
	TIME [epoch: 24.8 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.382219670174142		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 2.382219670174142 | validation: 2.2329711998162347]
	TIME [epoch: 24.8 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.384479858538998		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 2.384479858538998 | validation: 2.476446013953287]
	TIME [epoch: 24.8 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4646952294267366		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 2.4646952294267366 | validation: 2.0572737398628376]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_629.pth
	Model improved!!!
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3315512244928938		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 2.3315512244928938 | validation: 2.0835159171016726]
	TIME [epoch: 24.7 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3489127485582473		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 2.3489127485582473 | validation: 2.1151302007368433]
	TIME [epoch: 24.8 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3391421173460127		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 2.3391421173460127 | validation: 2.0643965597033125]
	TIME [epoch: 24.8 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3657578848837		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 2.3657578848837 | validation: 2.106902720002279]
	TIME [epoch: 24.8 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3818601422897765		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 2.3818601422897765 | validation: 2.111328279475716]
	TIME [epoch: 24.8 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.417738808619604		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 2.417738808619604 | validation: 2.0639230670707875]
	TIME [epoch: 24.8 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.333165847068445		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 2.333165847068445 | validation: 2.1121291902479364]
	TIME [epoch: 24.8 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.39096458892342		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 2.39096458892342 | validation: 2.113513907509906]
	TIME [epoch: 24.8 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3595827289893907		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 2.3595827289893907 | validation: 2.126509646193859]
	TIME [epoch: 24.7 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3528941848385614		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 2.3528941848385614 | validation: 2.2254302372092165]
	TIME [epoch: 24.8 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.415556045733766		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 2.415556045733766 | validation: 2.066034703376376]
	TIME [epoch: 24.8 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.335830089324262		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 2.335830089324262 | validation: 2.1323209898365705]
	TIME [epoch: 24.8 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.34509418805563		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 2.34509418805563 | validation: 2.069222258034116]
	TIME [epoch: 24.8 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3195435677675054		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 2.3195435677675054 | validation: 2.3971892808354296]
	TIME [epoch: 24.8 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.472294384085764		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 2.472294384085764 | validation: 2.3118420652109717]
	TIME [epoch: 24.8 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4675188356662883		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 2.4675188356662883 | validation: 2.1715515141815747]
	TIME [epoch: 24.8 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3774710544884026		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 2.3774710544884026 | validation: 2.070092684872101]
	TIME [epoch: 24.8 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3484490350220377		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 2.3484490350220377 | validation: 2.0727720662794225]
	TIME [epoch: 24.8 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3731746199815076		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 2.3731746199815076 | validation: 2.0534782857092604]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_648.pth
	Model improved!!!
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3832751644706365		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 2.3832751644706365 | validation: 2.1000266788045625]
	TIME [epoch: 24.8 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.470626179521684		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 2.470626179521684 | validation: 2.1343958471721303]
	TIME [epoch: 24.8 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.431323431957229		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 2.431323431957229 | validation: 2.1013649736648303]
	TIME [epoch: 24.8 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.357250445571343		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 2.357250445571343 | validation: 2.2153668346750335]
	TIME [epoch: 24.8 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.379049988437696		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 2.379049988437696 | validation: 2.1015811412408403]
	TIME [epoch: 24.8 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3578507857592315		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 2.3578507857592315 | validation: 2.083778304135981]
	TIME [epoch: 24.8 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4037642849643537		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 2.4037642849643537 | validation: 2.248210924068116]
	TIME [epoch: 24.8 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4446712496081355		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 2.4446712496081355 | validation: 2.055162096404182]
	TIME [epoch: 24.8 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.346308629549109		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 2.346308629549109 | validation: 2.0738367640422006]
	TIME [epoch: 24.8 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3782536560410645		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 2.3782536560410645 | validation: 2.188239779416444]
	TIME [epoch: 24.8 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3528530876205505		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 2.3528530876205505 | validation: 2.0851117108259034]
	TIME [epoch: 24.7 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.365253311903354		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 2.365253311903354 | validation: 2.177923685798092]
	TIME [epoch: 24.8 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3568022018184047		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 2.3568022018184047 | validation: 2.145357003500488]
	TIME [epoch: 24.8 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.397598806631276		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 2.397598806631276 | validation: 2.16809898862535]
	TIME [epoch: 24.8 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3706094913125		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 2.3706094913125 | validation: 2.161362348957943]
	TIME [epoch: 24.7 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3412835960085263		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 2.3412835960085263 | validation: 2.1020694384570566]
	TIME [epoch: 24.8 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3520647995592734		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 2.3520647995592734 | validation: 2.2442619036898193]
	TIME [epoch: 24.7 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.389194835400623		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 2.389194835400623 | validation: 2.0717159859542416]
	TIME [epoch: 24.8 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.38396123615375		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 2.38396123615375 | validation: 2.2392612166272405]
	TIME [epoch: 24.8 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3792533188631992		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 2.3792533188631992 | validation: 2.1636584295313774]
	TIME [epoch: 24.8 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3734567335038683		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 2.3734567335038683 | validation: 2.073301615458088]
	TIME [epoch: 24.8 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.361571983844554		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 2.361571983844554 | validation: 2.090873918913875]
	TIME [epoch: 24.8 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.344865873580868		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 2.344865873580868 | validation: 2.0770784666186946]
	TIME [epoch: 24.7 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3500802138645627		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 2.3500802138645627 | validation: 2.0812029804309757]
	TIME [epoch: 24.8 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.324508807534677		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 2.324508807534677 | validation: 2.0541834110523287]
	TIME [epoch: 24.8 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.358585296643295		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 2.358585296643295 | validation: 2.1915848519804504]
	TIME [epoch: 24.8 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.39828017403935		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 2.39828017403935 | validation: 2.0967895958400278]
	TIME [epoch: 24.7 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.34497263762083		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 2.34497263762083 | validation: 2.0616901307913507]
	TIME [epoch: 24.8 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3101080060780683		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 2.3101080060780683 | validation: 2.090081778792654]
	TIME [epoch: 24.8 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3534337460001087		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 2.3534337460001087 | validation: 2.127875283456923]
	TIME [epoch: 24.8 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3282681409998363		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 2.3282681409998363 | validation: 2.230341107196841]
	TIME [epoch: 24.8 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.381108351290626		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 2.381108351290626 | validation: 2.141321493095754]
	TIME [epoch: 24.8 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3928820810972113		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 2.3928820810972113 | validation: 2.090767102459047]
	TIME [epoch: 24.8 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.321943654247295		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 2.321943654247295 | validation: 2.054121119112528]
	TIME [epoch: 24.9 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.321141184850929		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 2.321141184850929 | validation: 2.08734055791821]
	TIME [epoch: 24.7 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3232627291215358		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 2.3232627291215358 | validation: 2.0626201572898277]
	TIME [epoch: 24.8 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3366276712242575		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 2.3366276712242575 | validation: 2.1050483612404607]
	TIME [epoch: 24.8 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3407471770172537		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 2.3407471770172537 | validation: 2.146029925769281]
	TIME [epoch: 24.8 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3415064560316563		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 2.3415064560316563 | validation: 2.0744436377052105]
	TIME [epoch: 24.8 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3719214062602303		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 2.3719214062602303 | validation: 2.058687028484308]
	TIME [epoch: 24.8 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.323912204179947		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 2.323912204179947 | validation: 2.1637713799125016]
	TIME [epoch: 24.8 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3535021918776575		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 2.3535021918776575 | validation: 2.2439924551906474]
	TIME [epoch: 24.8 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3812313144060484		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 2.3812313144060484 | validation: 2.1548584736942265]
	TIME [epoch: 24.8 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.341634739977178		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 2.341634739977178 | validation: 2.059459035933455]
	TIME [epoch: 24.8 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.320123829625026		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 2.320123829625026 | validation: 2.066081094755451]
	TIME [epoch: 24.8 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.323497297178082		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 2.323497297178082 | validation: 2.0720471626939436]
	TIME [epoch: 24.8 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.349898273848586		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 2.349898273848586 | validation: 2.1027829377916665]
	TIME [epoch: 24.8 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3356227559492466		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 2.3356227559492466 | validation: 2.0769165772390505]
	TIME [epoch: 24.8 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3234347036331022		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 2.3234347036331022 | validation: 2.064165786826146]
	TIME [epoch: 24.8 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3524713268403525		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 2.3524713268403525 | validation: 2.089746285199401]
	TIME [epoch: 24.8 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3454117330864337		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 2.3454117330864337 | validation: 2.0985577461347846]
	TIME [epoch: 24.8 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.327479134577737		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 2.327479134577737 | validation: 2.1151209803309596]
	TIME [epoch: 24.8 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3725995704572984		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 2.3725995704572984 | validation: 2.0696134307922707]
	TIME [epoch: 24.8 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3374227010464885		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 2.3374227010464885 | validation: 2.2461204134411]
	TIME [epoch: 24.8 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.391426576692017		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 2.391426576692017 | validation: 2.176008777521148]
	TIME [epoch: 24.8 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3603856640264667		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 2.3603856640264667 | validation: 2.096401528743819]
	TIME [epoch: 24.7 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.315088106347334		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 2.315088106347334 | validation: 2.1469463412676744]
	TIME [epoch: 24.8 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3382575169889295		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 2.3382575169889295 | validation: 2.097603623533707]
	TIME [epoch: 24.8 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3553132944423174		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 2.3553132944423174 | validation: 2.1854836909801167]
	TIME [epoch: 24.7 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.34573417288053		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 2.34573417288053 | validation: 2.05393537145677]
	TIME [epoch: 24.8 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.357532088851422		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 2.357532088851422 | validation: 2.1434035030442398]
	TIME [epoch: 24.8 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3431875784688287		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 2.3431875784688287 | validation: 2.0811560075828934]
	TIME [epoch: 24.7 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.329655152051947		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 2.329655152051947 | validation: 2.065571311768616]
	TIME [epoch: 24.8 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3382260409793956		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 2.3382260409793956 | validation: 2.13583264268782]
	TIME [epoch: 24.8 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.369283432062525		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 2.369283432062525 | validation: 2.097747490090997]
	TIME [epoch: 24.7 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3184116003612667		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 2.3184116003612667 | validation: 2.039465192815851]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_714.pth
	Model improved!!!
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3398499227133955		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 2.3398499227133955 | validation: 2.059698166596386]
	TIME [epoch: 24.8 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.313682343957503		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 2.313682343957503 | validation: 2.0695669607146585]
	TIME [epoch: 24.7 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3309356289416163		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 2.3309356289416163 | validation: 2.103519010668544]
	TIME [epoch: 24.8 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3377110674371426		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 2.3377110674371426 | validation: 2.1805965575722746]
	TIME [epoch: 24.8 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3477492050178013		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 2.3477492050178013 | validation: 2.1037145904667596]
	TIME [epoch: 24.8 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.322218868127521		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 2.322218868127521 | validation: 2.126884454535546]
	TIME [epoch: 24.8 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3742829426973757		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 2.3742829426973757 | validation: 2.0933936160474436]
	TIME [epoch: 24.8 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3341861746558408		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 2.3341861746558408 | validation: 2.050228149462003]
	TIME [epoch: 24.7 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3285129713523998		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 2.3285129713523998 | validation: 2.1662030838669772]
	TIME [epoch: 24.8 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3528494795880066		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 2.3528494795880066 | validation: 2.1363471213261374]
	TIME [epoch: 24.8 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3982739080014737		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 2.3982739080014737 | validation: 2.0777194800543293]
	TIME [epoch: 24.7 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3023975668470413		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 2.3023975668470413 | validation: 2.0884822801343588]
	TIME [epoch: 24.8 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.382672374421898		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 2.382672374421898 | validation: 2.0832903119835384]
	TIME [epoch: 24.8 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3977637142676134		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 2.3977637142676134 | validation: 2.0515145540914976]
	TIME [epoch: 24.8 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3093298822465407		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 2.3093298822465407 | validation: 2.05168121195733]
	TIME [epoch: 24.8 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3249405490563646		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 2.3249405490563646 | validation: 2.184938721653011]
	TIME [epoch: 24.8 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3461721674807383		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 2.3461721674807383 | validation: 2.063517969893598]
	TIME [epoch: 24.7 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3360122044365013		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 2.3360122044365013 | validation: 2.073731828455279]
	TIME [epoch: 24.8 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3329331484548326		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 2.3329331484548326 | validation: 2.244437714843275]
	TIME [epoch: 24.8 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3613846247088413		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 2.3613846247088413 | validation: 2.0531915718348124]
	TIME [epoch: 24.8 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3634938523790963		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 2.3634938523790963 | validation: 2.1752318022768744]
	TIME [epoch: 24.8 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.359947045858338		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 2.359947045858338 | validation: 2.144959593509522]
	TIME [epoch: 24.8 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.33371759475264		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 2.33371759475264 | validation: 2.081682939831447]
	TIME [epoch: 24.7 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.336023324881489		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 2.336023324881489 | validation: 2.1151359266901646]
	TIME [epoch: 24.8 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3400134000677397		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 2.3400134000677397 | validation: 2.0734323666681296]
	TIME [epoch: 24.8 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.335891938686946		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 2.335891938686946 | validation: 2.0538503508876196]
	TIME [epoch: 24.8 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.312257747687565		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 2.312257747687565 | validation: 2.058404773253692]
	TIME [epoch: 24.8 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3330753169308047		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 2.3330753169308047 | validation: 2.0875822575810075]
	TIME [epoch: 24.8 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.308895715355218		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 2.308895715355218 | validation: 2.0588272099722076]
	TIME [epoch: 24.8 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2981174285304564		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 2.2981174285304564 | validation: 2.0994183700446665]
	TIME [epoch: 24.7 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.327841146005549		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 2.327841146005549 | validation: 2.1097639711454703]
	TIME [epoch: 24.8 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3230533559845257		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 2.3230533559845257 | validation: 2.054075384543012]
	TIME [epoch: 24.8 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.32932762610773		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 2.32932762610773 | validation: 2.0543441716919366]
	TIME [epoch: 24.8 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3144100061829787		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 2.3144100061829787 | validation: 2.1382737732167443]
	TIME [epoch: 24.8 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3261809346498965		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 2.3261809346498965 | validation: 2.059314687949784]
	TIME [epoch: 24.8 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3068477912972174		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 2.3068477912972174 | validation: 2.0415169372074313]
	TIME [epoch: 24.8 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3317628190029067		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 2.3317628190029067 | validation: 2.0422219666388486]
	TIME [epoch: 24.8 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3773855274555653		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 2.3773855274555653 | validation: 2.2282161940642333]
	TIME [epoch: 24.8 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3545556831011		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 2.3545556831011 | validation: 2.0600358191854378]
	TIME [epoch: 24.8 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3678966129024257		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 2.3678966129024257 | validation: 2.1565335428690293]
	TIME [epoch: 24.8 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.37370018379272		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 2.37370018379272 | validation: 2.058337227358693]
	TIME [epoch: 24.7 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2972443887463245		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 2.2972443887463245 | validation: 2.1342995532155933]
	TIME [epoch: 24.8 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3334419219286144		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 2.3334419219286144 | validation: 2.087782218027936]
	TIME [epoch: 24.8 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3441590180338663		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 2.3441590180338663 | validation: 2.1390059338684004]
	TIME [epoch: 24.8 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.34698931809578		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 2.34698931809578 | validation: 2.088317671984996]
	TIME [epoch: 24.8 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.312002929573807		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 2.312002929573807 | validation: 2.0736699954369113]
	TIME [epoch: 24.8 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.361905679799417		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 2.361905679799417 | validation: 2.062555648834203]
	TIME [epoch: 24.8 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3099195774491923		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 2.3099195774491923 | validation: 2.0605673050096693]
	TIME [epoch: 24.8 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.330177091478836		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 2.330177091478836 | validation: 2.086165028562295]
	TIME [epoch: 24.8 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.302237934310543		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 2.302237934310543 | validation: 2.056498021428591]
	TIME [epoch: 24.7 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.313483201663718		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 2.313483201663718 | validation: 2.0566254206869723]
	TIME [epoch: 24.8 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3020766038410603		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 2.3020766038410603 | validation: 2.0787849507940868]
	TIME [epoch: 24.8 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.365120396116441		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 2.365120396116441 | validation: 2.116235824683364]
	TIME [epoch: 24.7 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3318513541257406		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 2.3318513541257406 | validation: 2.079265864986382]
	TIME [epoch: 24.8 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.338856194276681		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 2.338856194276681 | validation: 2.092106433441412]
	TIME [epoch: 24.8 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.337126827057095		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 2.337126827057095 | validation: 2.052117740912877]
	TIME [epoch: 24.7 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.297034435377191		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 2.297034435377191 | validation: 2.0589791202068954]
	TIME [epoch: 24.8 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3199043941354236		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 2.3199043941354236 | validation: 2.09862056572749]
	TIME [epoch: 24.9 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.322088913048202		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 2.322088913048202 | validation: 2.0851099099317763]
	TIME [epoch: 24.7 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.321730200192703		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 2.321730200192703 | validation: 2.0532397111876763]
	TIME [epoch: 24.8 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3268139646901482		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 2.3268139646901482 | validation: 2.0401205321435514]
	TIME [epoch: 24.8 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.322888185391106		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 2.322888185391106 | validation: 2.079899242218789]
	TIME [epoch: 24.7 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.305205214210643		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 2.305205214210643 | validation: 2.051132069459238]
	TIME [epoch: 24.8 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.314565438410737		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 2.314565438410737 | validation: 2.0613055487963705]
	TIME [epoch: 24.8 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.322420443227294		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 2.322420443227294 | validation: 2.1118233547051726]
	TIME [epoch: 24.7 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3609187462944474		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 2.3609187462944474 | validation: 2.2098753740576385]
	TIME [epoch: 24.8 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3380044032228957		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 2.3380044032228957 | validation: 2.057521289863817]
	TIME [epoch: 24.8 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2971456207256358		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 2.2971456207256358 | validation: 2.041551742386157]
	TIME [epoch: 24.8 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.328945647870922		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 2.328945647870922 | validation: 2.090004282142051]
	TIME [epoch: 24.8 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3142208297142206		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 2.3142208297142206 | validation: 2.1299677609569367]
	TIME [epoch: 24.8 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3682990017019714		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 2.3682990017019714 | validation: 2.1540205801723165]
	TIME [epoch: 24.8 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3386570600331007		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 2.3386570600331007 | validation: 2.073661278243707]
	TIME [epoch: 24.8 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.323769444650794		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 2.323769444650794 | validation: 2.090263430471348]
	TIME [epoch: 24.8 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3194560605333336		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 2.3194560605333336 | validation: 2.049638305924297]
	TIME [epoch: 24.8 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3105028597684427		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 2.3105028597684427 | validation: 2.0512734572625146]
	TIME [epoch: 24.8 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2948446031179186		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 2.2948446031179186 | validation: 2.0508000084124682]
	TIME [epoch: 24.8 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.29907182377762		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 2.29907182377762 | validation: 2.082036995224245]
	TIME [epoch: 24.8 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.400715552682188		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 2.400715552682188 | validation: 2.0369889968264427]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_792.pth
	Model improved!!!
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3328542204204865		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 2.3328542204204865 | validation: 2.05355871134899]
	TIME [epoch: 24.7 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3244787928650963		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 2.3244787928650963 | validation: 2.058990367915369]
	TIME [epoch: 24.8 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.298529794104322		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 2.298529794104322 | validation: 2.042538118887732]
	TIME [epoch: 24.8 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2913366444030814		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 2.2913366444030814 | validation: 2.053097092487805]
	TIME [epoch: 24.8 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3104646515857192		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 2.3104646515857192 | validation: 2.0585265574837686]
	TIME [epoch: 24.8 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.305373888030121		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 2.305373888030121 | validation: 2.0456019343415983]
	TIME [epoch: 24.8 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2921687889874516		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 2.2921687889874516 | validation: 2.0715522113840383]
	TIME [epoch: 24.8 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.292463702633444		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 2.292463702633444 | validation: 2.0792644412290544]
	TIME [epoch: 24.7 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.305082717462671		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 2.305082717462671 | validation: 2.07189147243118]
	TIME [epoch: 24.8 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.304061886100303		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 2.304061886100303 | validation: 2.056567894042461]
	TIME [epoch: 24.8 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3176257651130547		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 2.3176257651130547 | validation: 2.0960027082298867]
	TIME [epoch: 24.8 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3504179033428114		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 2.3504179033428114 | validation: 2.050999639080512]
	TIME [epoch: 24.8 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3327617366699376		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 2.3327617366699376 | validation: 2.0435558096931925]
	TIME [epoch: 24.7 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.303735875475734		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 2.303735875475734 | validation: 2.043011986493628]
	TIME [epoch: 24.7 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.304383452184263		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 2.304383452184263 | validation: 2.0493965682582855]
	TIME [epoch: 24.8 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.318080973254681		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 2.318080973254681 | validation: 2.0891780723237225]
	TIME [epoch: 24.7 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.314860279446053		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 2.314860279446053 | validation: 2.0464381276139]
	TIME [epoch: 24.7 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3173805552876114		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 2.3173805552876114 | validation: 2.113452487035991]
	TIME [epoch: 24.8 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.328359142986593		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 2.328359142986593 | validation: 2.0416284784658396]
	TIME [epoch: 24.7 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.312786747026073		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 2.312786747026073 | validation: 2.0582216645919114]
	TIME [epoch: 24.8 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.302765930733343		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 2.302765930733343 | validation: 2.0780544853351137]
	TIME [epoch: 24.8 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3126626384031344		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 2.3126626384031344 | validation: 2.121200369894027]
	TIME [epoch: 24.8 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3134610693453723		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 2.3134610693453723 | validation: 2.0378995064906182]
	TIME [epoch: 24.8 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3046314337397664		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 2.3046314337397664 | validation: 2.0521774885684714]
	TIME [epoch: 24.8 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3107794643991046		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 2.3107794643991046 | validation: 2.0421014767989685]
	TIME [epoch: 24.8 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3092487583204444		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 2.3092487583204444 | validation: 2.045946846175542]
	TIME [epoch: 24.7 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3059115321990413		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 2.3059115321990413 | validation: 2.0516923786694745]
	TIME [epoch: 24.8 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2976071188290406		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 2.2976071188290406 | validation: 2.0669982331902834]
	TIME [epoch: 24.8 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.292151646571468		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 2.292151646571468 | validation: 2.1348588849500887]
	TIME [epoch: 24.8 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.33392612912555		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 2.33392612912555 | validation: 2.0875935020187764]
	TIME [epoch: 24.8 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.312597230273977		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 2.312597230273977 | validation: 2.042472142990287]
	TIME [epoch: 24.7 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3011345606693006		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 2.3011345606693006 | validation: 2.059985241360681]
	TIME [epoch: 24.8 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2973516042119053		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 2.2973516042119053 | validation: 2.0486642707221345]
	TIME [epoch: 24.8 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2899331586273344		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 2.2899331586273344 | validation: 2.1090219271096657]
	TIME [epoch: 24.7 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3483705847916263		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 2.3483705847916263 | validation: 2.0438425982596717]
	TIME [epoch: 24.8 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.297057092002879		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 2.297057092002879 | validation: 2.118010480455528]
	TIME [epoch: 24.8 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3161030379392584		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 2.3161030379392584 | validation: 2.0637706810531227]
	TIME [epoch: 24.7 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.30208815270399		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 2.30208815270399 | validation: 2.050181075796931]
	TIME [epoch: 24.8 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.289986082975287		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 2.289986082975287 | validation: 2.038616919129177]
	TIME [epoch: 24.8 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2932929057664135		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 2.2932929057664135 | validation: 2.101411497364268]
	TIME [epoch: 24.7 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3158572942635978		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 2.3158572942635978 | validation: 2.058056058501115]
	TIME [epoch: 24.8 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.315756631927476		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 2.315756631927476 | validation: 2.0603139940400697]
	TIME [epoch: 24.8 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.315998130311459		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 2.315998130311459 | validation: 2.1344073478379735]
	TIME [epoch: 24.7 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3981725480402165		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 2.3981725480402165 | validation: 2.0410277454745747]
	TIME [epoch: 24.8 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.305656171037243		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 2.305656171037243 | validation: 2.0775199258806074]
	TIME [epoch: 24.8 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.297251238463063		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 2.297251238463063 | validation: 2.03457664871181]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_838.pth
	Model improved!!!
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2928238005974		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 2.2928238005974 | validation: 2.062158673170672]
	TIME [epoch: 24.8 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3211234460875763		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 2.3211234460875763 | validation: 2.047827225734793]
	TIME [epoch: 24.8 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3148488663799345		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 2.3148488663799345 | validation: 2.03808971837129]
	TIME [epoch: 24.8 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3047816706114412		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 2.3047816706114412 | validation: 2.048937764884721]
	TIME [epoch: 24.7 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.301311134558368		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 2.301311134558368 | validation: 2.0421469820315306]
	TIME [epoch: 24.8 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.286908288259193		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 2.286908288259193 | validation: 2.043032962992597]
	TIME [epoch: 24.7 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3201022964143103		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 2.3201022964143103 | validation: 2.0348555670079342]
	TIME [epoch: 24.7 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2858229952503226		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 2.2858229952503226 | validation: 2.0444188809842125]
	TIME [epoch: 24.8 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.298394260724641		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 2.298394260724641 | validation: 2.057021513134946]
	TIME [epoch: 24.7 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2992959179597325		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 2.2992959179597325 | validation: 2.064733581356251]
	TIME [epoch: 24.8 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3010195411333414		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 2.3010195411333414 | validation: 2.04383655913831]
	TIME [epoch: 24.8 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2911988434501724		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 2.2911988434501724 | validation: 2.1570272291694317]
	TIME [epoch: 24.7 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3279545700815327		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 2.3279545700815327 | validation: 2.0596928070092524]
	TIME [epoch: 24.8 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2965963018748052		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 2.2965963018748052 | validation: 2.0846195298001904]
	TIME [epoch: 24.8 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3231616650205376		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 2.3231616650205376 | validation: 2.026502493314992]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_853.pth
	Model improved!!!
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.289641844917417		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 2.289641844917417 | validation: 2.0406898694662248]
	TIME [epoch: 24.8 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3034742777428847		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 2.3034742777428847 | validation: 2.0975090074053684]
	TIME [epoch: 24.8 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.321754698129679		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 2.321754698129679 | validation: 2.049832934207131]
	TIME [epoch: 24.7 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2874125788581274		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 2.2874125788581274 | validation: 2.035747153304972]
	TIME [epoch: 24.7 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2945033253715197		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 2.2945033253715197 | validation: 2.1529338871254646]
	TIME [epoch: 24.8 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.375816515512075		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 2.375816515512075 | validation: 2.0451828802190413]
	TIME [epoch: 24.7 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3536696002026622		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 2.3536696002026622 | validation: 2.0459874891593524]
	TIME [epoch: 24.7 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.299804500926437		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 2.299804500926437 | validation: 2.075751830917081]
	TIME [epoch: 24.8 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.290763418033209		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 2.290763418033209 | validation: 2.084514466906888]
	TIME [epoch: 24.7 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.302668627001802		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 2.302668627001802 | validation: 2.078001472977428]
	TIME [epoch: 24.8 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3375663936146616		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 2.3375663936146616 | validation: 2.0339271830004475]
	TIME [epoch: 24.8 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.311369508324951		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 2.311369508324951 | validation: 2.0532958620201116]
	TIME [epoch: 24.7 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.357845648605015		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 2.357845648605015 | validation: 2.191177960568007]
	TIME [epoch: 24.8 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.322303969158457		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 2.322303969158457 | validation: 2.045647344829193]
	TIME [epoch: 24.8 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2963348276065174		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 2.2963348276065174 | validation: 2.0433821618035237]
	TIME [epoch: 24.7 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.295131883976449		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 2.295131883976449 | validation: 2.0524618081927573]
	TIME [epoch: 24.8 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2924156970917595		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 2.2924156970917595 | validation: 2.0937443711121735]
	TIME [epoch: 24.8 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.299148571928375		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 2.299148571928375 | validation: 2.100536170319077]
	TIME [epoch: 24.7 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.317488144009975		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 2.317488144009975 | validation: 2.053055516905401]
	TIME [epoch: 24.8 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.300377147298477		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 2.300377147298477 | validation: 2.0729066442836093]
	TIME [epoch: 24.8 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2975237491340237		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 2.2975237491340237 | validation: 2.091008064551391]
	TIME [epoch: 24.7 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.301838807817534		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 2.301838807817534 | validation: 2.0744140274700213]
	TIME [epoch: 24.8 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.303656791672287		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 2.303656791672287 | validation: 2.0377432471215906]
	TIME [epoch: 24.8 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.30025374859372		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 2.30025374859372 | validation: 2.0567129927632304]
	TIME [epoch: 24.7 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3161434900502345		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 2.3161434900502345 | validation: 2.053307306291295]
	TIME [epoch: 24.8 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.442866342285856		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 2.442866342285856 | validation: 2.1879802334737017]
	TIME [epoch: 24.7 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.350364083236499		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 2.350364083236499 | validation: 2.1159704466106555]
	TIME [epoch: 24.7 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.326923926646968		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 2.326923926646968 | validation: 2.0452663120114627]
	TIME [epoch: 24.8 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3051822444440044		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 2.3051822444440044 | validation: 2.067985803657168]
	TIME [epoch: 24.8 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.298418532194668		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 2.298418532194668 | validation: 2.048060156572223]
	TIME [epoch: 24.7 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.282093055808137		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 2.282093055808137 | validation: 2.0518954130405174]
	TIME [epoch: 24.8 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.300230133208883		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 2.300230133208883 | validation: 2.0643147124681627]
	TIME [epoch: 24.8 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2898153011433027		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 2.2898153011433027 | validation: 2.0539136140344287]
	TIME [epoch: 24.7 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3001303007212885		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 2.3001303007212885 | validation: 2.0646773677793595]
	TIME [epoch: 24.8 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.298886199321955		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 2.298886199321955 | validation: 2.128983020179511]
	TIME [epoch: 24.7 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.323700768810026		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 2.323700768810026 | validation: 2.0722666134974355]
	TIME [epoch: 24.7 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3694045476715755		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 2.3694045476715755 | validation: 2.0569857162533958]
	TIME [epoch: 24.7 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.282504585662056		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 2.282504585662056 | validation: 2.0334552844095097]
	TIME [epoch: 24.7 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2891959695898687		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 2.2891959695898687 | validation: 2.0591376426837886]
	TIME [epoch: 24.7 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.29745593300407		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 2.29745593300407 | validation: 2.0349979472579496]
	TIME [epoch: 24.7 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2832719039350673		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 2.2832719039350673 | validation: 2.0727646979574565]
	TIME [epoch: 24.7 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.300236752673488		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 2.300236752673488 | validation: 2.0614872883874362]
	TIME [epoch: 24.7 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2926373523385677		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 2.2926373523385677 | validation: 2.0503674981349027]
	TIME [epoch: 24.7 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2894496739362706		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 2.2894496739362706 | validation: 2.060656488308496]
	TIME [epoch: 24.7 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.294648770350405		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 2.294648770350405 | validation: 2.0680224797743048]
	TIME [epoch: 24.7 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2845555474182744		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 2.2845555474182744 | validation: 2.0351588708103803]
	TIME [epoch: 24.7 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2806418214073623		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 2.2806418214073623 | validation: 2.0680757558916776]
	TIME [epoch: 24.7 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3096252021465364		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 2.3096252021465364 | validation: 2.0349106113056576]
	TIME [epoch: 24.7 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3038518021836607		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 2.3038518021836607 | validation: 2.0276891260085255]
	TIME [epoch: 24.7 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2837242757445684		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 2.2837242757445684 | validation: 2.040855872435066]
	TIME [epoch: 24.7 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2852625573052823		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 2.2852625573052823 | validation: 2.0557625258785293]
	TIME [epoch: 24.7 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3003988866963283		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 2.3003988866963283 | validation: 2.052063021616018]
	TIME [epoch: 24.7 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.308180288422309		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 2.308180288422309 | validation: 2.048633594148532]
	TIME [epoch: 24.7 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2992178554980187		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 2.2992178554980187 | validation: 2.0461636915961443]
	TIME [epoch: 24.7 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.291783576642704		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 2.291783576642704 | validation: 2.0506476685568917]
	TIME [epoch: 24.7 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.320027232498725		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 2.320027232498725 | validation: 2.042685537453051]
	TIME [epoch: 24.7 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2846767540185957		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 2.2846767540185957 | validation: 2.0892156633763816]
	TIME [epoch: 24.7 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.310991915893101		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 2.310991915893101 | validation: 2.0622017410303535]
	TIME [epoch: 24.7 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.292295143745914		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 2.292295143745914 | validation: 2.032757956096352]
	TIME [epoch: 24.7 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3009871252143697		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 2.3009871252143697 | validation: 2.0414881507522287]
	TIME [epoch: 24.7 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.28431514030391		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 2.28431514030391 | validation: 2.041421743485864]
	TIME [epoch: 24.7 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3117175935041145		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 2.3117175935041145 | validation: 2.0530111841755883]
	TIME [epoch: 24.7 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.284972250153421		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 2.284972250153421 | validation: 2.038176678042167]
	TIME [epoch: 24.7 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.321537609282315		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 2.321537609282315 | validation: 2.08222343442305]
	TIME [epoch: 24.7 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.303002908316919		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 2.303002908316919 | validation: 2.03691431684516]
	TIME [epoch: 24.7 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.279461512498487		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 2.279461512498487 | validation: 2.119411360068198]
	TIME [epoch: 24.7 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.311089140309693		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 2.311089140309693 | validation: 2.043707455439378]
	TIME [epoch: 24.7 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2820940333618243		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 2.2820940333618243 | validation: 2.07508612797943]
	TIME [epoch: 24.7 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.342258297870052		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 2.342258297870052 | validation: 2.0598836200426205]
	TIME [epoch: 24.7 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3104338323074756		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 2.3104338323074756 | validation: 2.1223314563488453]
	TIME [epoch: 24.7 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3286246038796694		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 2.3286246038796694 | validation: 2.0394056718460964]
	TIME [epoch: 24.7 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2975845842047757		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 2.2975845842047757 | validation: 2.03954586582792]
	TIME [epoch: 24.7 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2839886777804583		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 2.2839886777804583 | validation: 2.055821111486082]
	TIME [epoch: 24.8 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.306144367006909		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 2.306144367006909 | validation: 2.1041641626660725]
	TIME [epoch: 24.7 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2964334916780427		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 2.2964334916780427 | validation: 2.021050163410649]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_928.pth
	Model improved!!!
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2814749848969167		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 2.2814749848969167 | validation: 2.034803090205439]
	TIME [epoch: 24.7 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.296733819970469		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 2.296733819970469 | validation: 2.06581573564813]
	TIME [epoch: 24.8 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3037626784001586		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 2.3037626784001586 | validation: 2.034605320020061]
	TIME [epoch: 24.7 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.307830886207361		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 2.307830886207361 | validation: 2.0795487670293364]
	TIME [epoch: 24.7 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.302133288412144		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 2.302133288412144 | validation: 2.04351341854173]
	TIME [epoch: 24.7 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2919383474989665		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 2.2919383474989665 | validation: 2.044959534836578]
	TIME [epoch: 24.7 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2923914750391043		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 2.2923914750391043 | validation: 2.0507292564673056]
	TIME [epoch: 24.7 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.287878838131761		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 2.287878838131761 | validation: 2.038921534584805]
	TIME [epoch: 24.8 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.299704237898557		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 2.299704237898557 | validation: 2.0396985746163443]
	TIME [epoch: 24.8 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.288555495784871		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 2.288555495784871 | validation: 2.0902644587687327]
	TIME [epoch: 24.8 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.312949477028716		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 2.312949477028716 | validation: 2.098899784309299]
	TIME [epoch: 24.7 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3152155560102505		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 2.3152155560102505 | validation: 2.036406872254493]
	TIME [epoch: 24.7 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.285739623300238		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 2.285739623300238 | validation: 2.0355444266157634]
	TIME [epoch: 24.7 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2830981352935877		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 2.2830981352935877 | validation: 2.0389762226198207]
	TIME [epoch: 24.7 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.278549897889146		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 2.278549897889146 | validation: 2.0266190633432783]
	TIME [epoch: 24.8 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2857285936430567		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 2.2857285936430567 | validation: 2.0513265182505904]
	TIME [epoch: 24.8 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2897759888007796		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 2.2897759888007796 | validation: 2.042885126017378]
	TIME [epoch: 24.8 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2772008875384357		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 2.2772008875384357 | validation: 2.032787478225458]
	TIME [epoch: 24.8 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2869968023245035		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 2.2869968023245035 | validation: 2.05937656159881]
	TIME [epoch: 24.8 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.295746747946419		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 2.295746747946419 | validation: 2.0701766348086204]
	TIME [epoch: 24.8 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.290251081383029		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 2.290251081383029 | validation: 2.0832091237508967]
	TIME [epoch: 24.8 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2985831939316728		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 2.2985831939316728 | validation: 2.0544899831067442]
	TIME [epoch: 24.8 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.28833193783535		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 2.28833193783535 | validation: 2.0396512297968625]
	TIME [epoch: 24.8 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.307780646218046		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 2.307780646218046 | validation: 2.0580429857738824]
	TIME [epoch: 24.7 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.295727680251222		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 2.295727680251222 | validation: 2.0647540722013464]
	TIME [epoch: 24.7 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2926532070854773		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 2.2926532070854773 | validation: 2.100154127716853]
	TIME [epoch: 24.8 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3010828727313193		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 2.3010828727313193 | validation: 2.0412609974842986]
	TIME [epoch: 24.7 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2919545643582415		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 2.2919545643582415 | validation: 2.066805789370827]
	TIME [epoch: 24.8 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.291734509746		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 2.291734509746 | validation: 2.0320836817981873]
	TIME [epoch: 24.7 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.276757942595588		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 2.276757942595588 | validation: 2.0338671847863328]
	TIME [epoch: 24.8 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2874055161493296		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 2.2874055161493296 | validation: 2.0329545723254188]
	TIME [epoch: 24.8 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2758902523419264		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 2.2758902523419264 | validation: 2.0462698104343513]
	TIME [epoch: 24.8 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3019648404823903		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 2.3019648404823903 | validation: 2.211961623203037]
	TIME [epoch: 24.8 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3809651102109575		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 2.3809651102109575 | validation: 2.053104585699511]
	TIME [epoch: 24.8 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.329946757288034		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 2.329946757288034 | validation: 2.062370407490447]
	TIME [epoch: 24.8 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3117858717917876		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 2.3117858717917876 | validation: 2.08613155205302]
	TIME [epoch: 24.7 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2953912994290366		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 2.2953912994290366 | validation: 2.0348166017988887]
	TIME [epoch: 24.8 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2819054344534804		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 2.2819054344534804 | validation: 2.033423637767032]
	TIME [epoch: 24.7 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.27950846220512		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 2.27950846220512 | validation: 2.04431070184644]
	TIME [epoch: 24.8 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2808360674421673		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 2.2808360674421673 | validation: 2.031943551342607]
	TIME [epoch: 24.8 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.286395800245323		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 2.286395800245323 | validation: 2.028435983340467]
	TIME [epoch: 24.7 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.290853172633388		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 2.290853172633388 | validation: 2.051998638634529]
	TIME [epoch: 24.8 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2895143614884326		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 2.2895143614884326 | validation: 2.0264267524872537]
	TIME [epoch: 24.8 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2788997284247277		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 2.2788997284247277 | validation: 2.0362124491945544]
	TIME [epoch: 24.7 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.287601333372837		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 2.287601333372837 | validation: 2.06156730832054]
	TIME [epoch: 24.8 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.293887878818502		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 2.293887878818502 | validation: 2.042348594233598]
	TIME [epoch: 24.8 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2874262204739657		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 2.2874262204739657 | validation: 2.051543084871791]
	TIME [epoch: 24.7 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.276264735344208		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 2.276264735344208 | validation: 2.0284084907202056]
	TIME [epoch: 24.8 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2762765106284175		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 2.2762765106284175 | validation: 2.030975583148855]
	TIME [epoch: 24.8 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2765625911563014		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 2.2765625911563014 | validation: 2.039565043981601]
	TIME [epoch: 24.8 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2956999692569546		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 2.2956999692569546 | validation: 2.097598135423539]
	TIME [epoch: 24.8 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3014431641424933		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 2.3014431641424933 | validation: 2.0503917632597006]
	TIME [epoch: 24.8 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2897682025199577		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 2.2897682025199577 | validation: 2.0363206521406574]
	TIME [epoch: 24.8 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2849139801215665		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 2.2849139801215665 | validation: 2.1371369084947536]
	TIME [epoch: 24.8 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3792654764871655		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 2.3792654764871655 | validation: 2.1730016833247094]
	TIME [epoch: 24.8 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3325442566532715		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 2.3325442566532715 | validation: 2.049879407220782]
	TIME [epoch: 24.7 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.280807268418785		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 2.280807268418785 | validation: 2.0228242348691015]
	TIME [epoch: 24.8 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2868956852706535		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 2.2868956852706535 | validation: 2.0401613443137645]
	TIME [epoch: 24.8 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2690606030269125		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 2.2690606030269125 | validation: 2.0261201879640764]
	TIME [epoch: 24.8 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2859039319201364		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 2.2859039319201364 | validation: 2.0519808610179395]
	TIME [epoch: 24.8 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2895856214316828		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 2.2895856214316828 | validation: 2.0229039657233367]
	TIME [epoch: 24.8 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2796144425113463		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 2.2796144425113463 | validation: 2.0337875589487835]
	TIME [epoch: 24.7 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.278257452913634		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 2.278257452913634 | validation: 2.0297260911544273]
	TIME [epoch: 24.8 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.28315144419408		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 2.28315144419408 | validation: 2.0796437969056423]
	TIME [epoch: 24.8 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.289485585233143		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 2.289485585233143 | validation: 2.0516144423439076]
	TIME [epoch: 24.8 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.288314113813447		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 2.288314113813447 | validation: 2.070815565268752]
	TIME [epoch: 24.8 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2907171030519913		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 2.2907171030519913 | validation: 2.034229386430904]
	TIME [epoch: 24.8 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2750905064158524		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 2.2750905064158524 | validation: 2.0679272260395885]
	TIME [epoch: 24.7 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3100569948257514		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 2.3100569948257514 | validation: 2.023709756886357]
	TIME [epoch: 24.8 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.285852119009788		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 2.285852119009788 | validation: 2.0350219488183408]
	TIME [epoch: 24.8 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2739589955143726		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 2.2739589955143726 | validation: 2.0346080817704104]
	TIME [epoch: 24.7 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2812911085980443		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 2.2812911085980443 | validation: 2.0499822813966317]
	TIME [epoch: 24.8 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2991201973839237		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 2.2991201973839237 | validation: 2.035623669762607]
	TIME [epoch: 24.8 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.27991265419636		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 2.27991265419636 | validation: 2.0255143891471312]
	TIME [epoch: 24.8 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.286194606448806		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 2.286194606448806 | validation: 2.03036300190958]
	TIME [epoch: 24.8 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2727796577700845		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 2.2727796577700845 | validation: 2.038288240164669]
	TIME [epoch: 24.8 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.280230743038567		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 2.280230743038567 | validation: 2.0477548209365004]
	TIME [epoch: 24.7 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.284396785158586		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 2.284396785158586 | validation: 2.0310510349920343]
	TIME [epoch: 24.8 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2861472444020774		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 2.2861472444020774 | validation: 2.0353990476435375]
	TIME [epoch: 24.8 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2794641406171476		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 2.2794641406171476 | validation: 2.0712191264658872]
	TIME [epoch: 24.7 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2904558888044737		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 2.2904558888044737 | validation: 2.056220484014591]
	TIME [epoch: 24.8 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2825293388505625		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 2.2825293388505625 | validation: 2.0290924978618112]
	TIME [epoch: 24.8 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.280244507691138		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 2.280244507691138 | validation: 2.0331279650462717]
	TIME [epoch: 24.8 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.295632316251014		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 2.295632316251014 | validation: 2.0312357467683753]
	TIME [epoch: 24.8 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2816979246930913		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 2.2816979246930913 | validation: 2.034134622424453]
	TIME [epoch: 24.8 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2889936773476376		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 2.2889936773476376 | validation: 2.091056000902719]
	TIME [epoch: 24.7 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3003679501095893		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 2.3003679501095893 | validation: 2.0556307093593045]
	TIME [epoch: 24.8 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3415617318610455		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 2.3415617318610455 | validation: 2.0915698370912628]
	TIME [epoch: 24.8 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.281771745892841		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 2.281771745892841 | validation: 2.050173740620473]
	TIME [epoch: 24.8 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.282348518114765		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 2.282348518114765 | validation: 2.037619505299678]
	TIME [epoch: 24.8 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.284824412262715		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 2.284824412262715 | validation: 2.0385145803096014]
	TIME [epoch: 24.8 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2909219203029636		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 2.2909219203029636 | validation: 2.0501412246439146]
	TIME [epoch: 24.7 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.325437635304173		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 2.325437635304173 | validation: 2.069880937424137]
	TIME [epoch: 24.8 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2992995069149007		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 2.2992995069149007 | validation: 2.0279543274286587]
	TIME [epoch: 24.8 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2742874573823224		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 2.2742874573823224 | validation: 2.0492514909191586]
	TIME [epoch: 24.8 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.280662714927317		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 2.280662714927317 | validation: 2.0491423568405533]
	TIME [epoch: 24.8 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2866558456443706		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 2.2866558456443706 | validation: 2.0651224234568706]
	TIME [epoch: 24.8 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.296686788748067		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 2.296686788748067 | validation: 2.030636706876807]
	TIME [epoch: 24.7 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2929614588189415		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 2.2929614588189415 | validation: 2.028798000758676]
	TIME [epoch: 24.8 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.278283983162203		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 2.278283983162203 | validation: 2.0357450743886365]
	TIME [epoch: 24.8 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2890132461005113		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 2.2890132461005113 | validation: 2.0342214034210566]
	TIME [epoch: 24.8 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.281282955188482		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 2.281282955188482 | validation: 2.0376457272517503]
	TIME [epoch: 24.8 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.276823747094406		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 2.276823747094406 | validation: 2.0344273310176626]
	TIME [epoch: 24.8 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.280222576435779		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 2.280222576435779 | validation: 2.0428575453593028]
	TIME [epoch: 24.7 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2970389813786074		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 2.2970389813786074 | validation: 2.0388184999793326]
	TIME [epoch: 24.8 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.275084907160404		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 2.275084907160404 | validation: 2.0247743295152794]
	TIME [epoch: 24.8 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.277671514819857		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 2.277671514819857 | validation: 2.0230912883961834]
	TIME [epoch: 24.8 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.273142016528306		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 2.273142016528306 | validation: 2.0811499248272494]
	TIME [epoch: 24.8 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3257271341664936		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 2.3257271341664936 | validation: 2.0374896513161262]
	TIME [epoch: 24.8 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.274981887919048		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 2.274981887919048 | validation: 2.0571630398755927]
	TIME [epoch: 24.8 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3141477402211263		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 2.3141477402211263 | validation: 2.0713098497612794]
	TIME [epoch: 24.8 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.285499658484846		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 2.285499658484846 | validation: 2.026918122736347]
	TIME [epoch: 24.8 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.272267205595027		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 2.272267205595027 | validation: 2.0357424958676567]
	TIME [epoch: 24.8 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.269301117531813		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 2.269301117531813 | validation: 2.0488430750926154]
	TIME [epoch: 24.8 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2985883731226915		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 2.2985883731226915 | validation: 2.030691365760891]
	TIME [epoch: 24.8 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.269309773066459		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 2.269309773066459 | validation: 2.0458554428965146]
	TIME [epoch: 24.8 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.293545695909841		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 2.293545695909841 | validation: 2.0363678332136343]
	TIME [epoch: 24.8 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2733178367435047		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 2.2733178367435047 | validation: 2.0338958956802675]
	TIME [epoch: 24.8 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.288259829654222		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 2.288259829654222 | validation: 2.0329272584387246]
	TIME [epoch: 24.8 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.27147353178265		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 2.27147353178265 | validation: 2.038750695443337]
	TIME [epoch: 24.8 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.270616272386342		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 2.270616272386342 | validation: 2.032092433627523]
	TIME [epoch: 24.8 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.295085047309452		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 2.295085047309452 | validation: 2.0515369480086973]
	TIME [epoch: 24.8 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2845528796395675		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 2.2845528796395675 | validation: 2.0273475102689082]
	TIME [epoch: 24.8 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2704122541144414		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 2.2704122541144414 | validation: 2.02360986871228]
	TIME [epoch: 24.8 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.284232509867317		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 2.284232509867317 | validation: 2.0414638918070405]
	TIME [epoch: 24.7 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.282498538779058		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 2.282498538779058 | validation: 2.0386179962661743]
	TIME [epoch: 24.8 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2802102887980586		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 2.2802102887980586 | validation: 2.0217574941980794]
	TIME [epoch: 24.8 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.272541535831055		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 2.272541535831055 | validation: 2.0373569377882994]
	TIME [epoch: 24.8 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2698072827794964		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 2.2698072827794964 | validation: 2.031457202131037]
	TIME [epoch: 24.8 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2716379057591216		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 2.2716379057591216 | validation: 2.027885987607367]
	TIME [epoch: 24.8 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.290310545526789		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 2.290310545526789 | validation: 2.039027394478658]
	TIME [epoch: 24.8 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2687180260469884		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 2.2687180260469884 | validation: 2.0377849158685586]
	TIME [epoch: 24.8 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.284146060114853		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 2.284146060114853 | validation: 2.036766867600795]
	TIME [epoch: 24.8 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.27768388087207		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 2.27768388087207 | validation: 2.036173426427955]
	TIME [epoch: 24.7 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2902391777783953		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 2.2902391777783953 | validation: 2.0458486795314004]
	TIME [epoch: 24.8 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.279285618637675		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 2.279285618637675 | validation: 2.02960329575607]
	TIME [epoch: 24.7 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2775623301194603		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 2.2775623301194603 | validation: 2.0457402609096853]
	TIME [epoch: 24.8 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2939633832260977		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 2.2939633832260977 | validation: 2.0538463800378963]
	TIME [epoch: 24.8 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2796136485547533		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 2.2796136485547533 | validation: 2.0621498767604014]
	TIME [epoch: 24.8 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2809034936868526		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 2.2809034936868526 | validation: 2.0380663856155214]
	TIME [epoch: 24.8 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2663205295013613		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 2.2663205295013613 | validation: 2.0292387219281047]
	TIME [epoch: 24.8 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2743706217038286		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 2.2743706217038286 | validation: 2.034099902029381]
	TIME [epoch: 24.8 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.290003694390478		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 2.290003694390478 | validation: 2.0540223098587136]
	TIME [epoch: 24.8 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.283590920121171		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 2.283590920121171 | validation: 2.066168192729142]
	TIME [epoch: 24.8 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2928900325425743		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 2.2928900325425743 | validation: 2.0343276145758438]
	TIME [epoch: 24.7 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2756563323727272		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 2.2756563323727272 | validation: 2.02725795784695]
	TIME [epoch: 24.7 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.275448408823028		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 2.275448408823028 | validation: 2.043147727533282]
	TIME [epoch: 24.8 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2783797564033446		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 2.2783797564033446 | validation: 2.0358826798737937]
	TIME [epoch: 24.7 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2747769894364342		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 2.2747769894364342 | validation: 2.021655259416994]
	TIME [epoch: 24.7 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.267685410224681		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 2.267685410224681 | validation: 2.0305297193074963]
	TIME [epoch: 24.8 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2728911865581845		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 2.2728911865581845 | validation: 2.0395772039071347]
	TIME [epoch: 24.8 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.284137331044506		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 2.284137331044506 | validation: 2.0351380557584258]
	TIME [epoch: 24.8 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2756224058326118		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 2.2756224058326118 | validation: 2.0752903288072515]
	TIME [epoch: 24.8 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2908509292695065		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 2.2908509292695065 | validation: 2.0286837748825137]
	TIME [epoch: 24.7 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.274807777512311		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 2.274807777512311 | validation: 2.039404954637174]
	TIME [epoch: 24.8 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2755648540900446		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 2.2755648540900446 | validation: 2.045018571431072]
	TIME [epoch: 24.8 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2771817114884803		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 2.2771817114884803 | validation: 2.0404438403168768]
	TIME [epoch: 24.8 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.274746453921369		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 2.274746453921369 | validation: 2.034477742708221]
	TIME [epoch: 24.8 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2830288796423326		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 2.2830288796423326 | validation: 2.042958437476602]
	TIME [epoch: 24.8 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.285554454758007		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 2.285554454758007 | validation: 2.033155737527013]
	TIME [epoch: 24.8 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.289755042505305		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 2.289755042505305 | validation: 2.029538389962179]
	TIME [epoch: 24.7 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.272659359293134		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 2.272659359293134 | validation: 2.0525579672570453]
	TIME [epoch: 24.7 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.273171983187165		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 2.273171983187165 | validation: 2.025338184673026]
	TIME [epoch: 24.7 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.268464082320671		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 2.268464082320671 | validation: 2.0296975983862087]
	TIME [epoch: 24.8 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.267227241678886		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 2.267227241678886 | validation: 2.038800406185828]
	TIME [epoch: 24.8 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2891883449699324		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 2.2891883449699324 | validation: 2.049303018503608]
	TIME [epoch: 24.8 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.271158046502543		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 2.271158046502543 | validation: 2.029528719079464]
	TIME [epoch: 24.8 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2801334794363246		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 2.2801334794363246 | validation: 2.0543087940138447]
	TIME [epoch: 24.8 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.279173699113283		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 2.279173699113283 | validation: 2.022633148995739]
	TIME [epoch: 24.8 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2704946767666514		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 2.2704946767666514 | validation: 2.0545480321835816]
	TIME [epoch: 24.7 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.273895831351491		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 2.273895831351491 | validation: 2.038242682921139]
	TIME [epoch: 24.8 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2766479537319495		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 2.2766479537319495 | validation: 2.0379922625392113]
	TIME [epoch: 24.8 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.272540013907835		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 2.272540013907835 | validation: 2.031327444953509]
	TIME [epoch: 24.8 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2723588724150785		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 2.2723588724150785 | validation: 2.0331219454322946]
	TIME [epoch: 24.8 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2758860099470724		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 2.2758860099470724 | validation: 2.0480075958131674]
	TIME [epoch: 24.7 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.27789389162578		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 2.27789389162578 | validation: 2.0282005989582963]
	TIME [epoch: 24.8 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2720770904826106		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 2.2720770904826106 | validation: 2.0524857900047513]
	TIME [epoch: 24.8 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2814340719967188		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 2.2814340719967188 | validation: 2.0431833315806656]
	TIME [epoch: 24.8 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.273738171753396		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 2.273738171753396 | validation: 2.0304424585482095]
	TIME [epoch: 24.8 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.271470202611309		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 2.271470202611309 | validation: 2.0381182409232395]
	TIME [epoch: 24.8 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.275623961206736		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 2.275623961206736 | validation: 2.0341657759163487]
	TIME [epoch: 24.7 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.266262114359659		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 2.266262114359659 | validation: 2.0284307108752198]
	TIME [epoch: 24.8 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2805476779546545		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 2.2805476779546545 | validation: 2.028735298077712]
	TIME [epoch: 24.8 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2702478876553673		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 2.2702478876553673 | validation: 2.0676219413441377]
	TIME [epoch: 24.8 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2919417960370447		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 2.2919417960370447 | validation: 2.02578284065734]
	TIME [epoch: 24.7 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.267901246994643		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 2.267901246994643 | validation: 2.034075954592357]
	TIME [epoch: 24.8 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.280800885254746		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 2.280800885254746 | validation: 2.033197859580661]
	TIME [epoch: 24.8 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2999480978137483		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 2.2999480978137483 | validation: 2.0550721462906036]
	TIME [epoch: 24.7 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.27778820430327		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 2.27778820430327 | validation: 2.0302369808838265]
	TIME [epoch: 24.8 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.26798820381788		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 2.26798820381788 | validation: 2.0385691054545663]
	TIME [epoch: 24.7 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.276689582251007		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 2.276689582251007 | validation: 2.028044329462246]
	TIME [epoch: 24.8 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.285345256739989		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 2.285345256739989 | validation: 2.0776388352914763]
	TIME [epoch: 24.8 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2869271652510097		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 2.2869271652510097 | validation: 2.0315973945068833]
	TIME [epoch: 24.8 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.274223010904041		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 2.274223010904041 | validation: 2.046798393160967]
	TIME [epoch: 24.8 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.26925785545496		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 2.26925785545496 | validation: 2.036202700391869]
	TIME [epoch: 24.8 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.276719900313202		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 2.276719900313202 | validation: 2.0357769252669535]
	TIME [epoch: 24.8 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2852150750376317		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 2.2852150750376317 | validation: 2.029331337126885]
	TIME [epoch: 24.8 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2760657685465215		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 2.2760657685465215 | validation: 2.0309813251051922]
	TIME [epoch: 24.8 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.274460564730868		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 2.274460564730868 | validation: 2.02959255359039]
	TIME [epoch: 24.8 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2738544005082373		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 2.2738544005082373 | validation: 2.025261962248055]
	TIME [epoch: 24.8 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2692507285028456		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 2.2692507285028456 | validation: 2.0397733055901996]
	TIME [epoch: 24.8 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2758270655714874		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 2.2758270655714874 | validation: 2.03008017057909]
	TIME [epoch: 24.8 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.273020304300007		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 2.273020304300007 | validation: 2.0360431883865537]
	TIME [epoch: 24.8 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.277977842877407		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 2.277977842877407 | validation: 2.042069814883275]
	TIME [epoch: 24.8 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.27654049705495		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 2.27654049705495 | validation: 2.025344422038699]
	TIME [epoch: 24.8 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2747535766938376		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 2.2747535766938376 | validation: 2.0384910009411654]
	TIME [epoch: 24.8 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2685716961846305		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 2.2685716961846305 | validation: 2.0234156026276198]
	TIME [epoch: 24.7 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2722852331230285		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 2.2722852331230285 | validation: 2.0232630299888372]
	TIME [epoch: 24.8 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2789810210160035		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 2.2789810210160035 | validation: 2.0187332223349954]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_1137.pth
	Model improved!!!
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.285736699532469		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 2.285736699532469 | validation: 2.0470067823984026]
	TIME [epoch: 24.8 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2772632876259333		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 2.2772632876259333 | validation: 2.035333381959289]
	TIME [epoch: 24.8 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2773861149376122		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 2.2773861149376122 | validation: 2.0275651651205715]
	TIME [epoch: 24.7 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.283225640409574		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 2.283225640409574 | validation: 2.053906180286215]
	TIME [epoch: 24.8 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2758823332693963		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 2.2758823332693963 | validation: 2.0466497943635855]
	TIME [epoch: 24.8 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.292368898674635		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 2.292368898674635 | validation: 2.0617569904886746]
	TIME [epoch: 24.8 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2860601445642206		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 2.2860601445642206 | validation: 2.024372612424899]
	TIME [epoch: 24.8 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2696006471317887		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 2.2696006471317887 | validation: 2.0516641810635154]
	TIME [epoch: 24.7 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.279115974218437		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 2.279115974218437 | validation: 2.0372857835547205]
	TIME [epoch: 24.8 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.271073072092131		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 2.271073072092131 | validation: 2.029031337186666]
	TIME [epoch: 24.8 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2697102481223332		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 2.2697102481223332 | validation: 2.0187631329418383]
	TIME [epoch: 24.8 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.26483664421845		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 2.26483664421845 | validation: 2.0202979310760654]
	TIME [epoch: 24.8 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.272440946825183		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 2.272440946825183 | validation: 2.023302019262088]
	TIME [epoch: 24.8 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2685245299517947		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 2.2685245299517947 | validation: 2.024149685603267]
	TIME [epoch: 24.7 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2687869485557948		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 2.2687869485557948 | validation: 2.030507835945282]
	TIME [epoch: 24.8 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2714972588698283		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 2.2714972588698283 | validation: 2.0564950472139563]
	TIME [epoch: 24.8 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2851265172435644		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 2.2851265172435644 | validation: 2.024543159624171]
	TIME [epoch: 24.8 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2670580823250908		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 2.2670580823250908 | validation: 2.0223229554643574]
	TIME [epoch: 24.8 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2691641388353707		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 2.2691641388353707 | validation: 2.029449130818335]
	TIME [epoch: 24.7 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2673884583107524		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 2.2673884583107524 | validation: 2.032094943868975]
	TIME [epoch: 24.8 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2806137245204594		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 2.2806137245204594 | validation: 2.030393238115962]
	TIME [epoch: 24.8 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2868963675773024		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 2.2868963675773024 | validation: 2.0416221900769553]
	TIME [epoch: 24.8 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.273155130985872		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 2.273155130985872 | validation: 2.0347114147287697]
	TIME [epoch: 24.7 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.268043358103288		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 2.268043358103288 | validation: 2.033823331276785]
	TIME [epoch: 24.8 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.281497687233068		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 2.281497687233068 | validation: 2.0367032053282608]
	TIME [epoch: 24.8 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.267075811350494		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 2.267075811350494 | validation: 2.033975635328159]
	TIME [epoch: 24.8 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.303965254593729		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 2.303965254593729 | validation: 2.093984329764556]
	TIME [epoch: 24.8 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2860282218423644		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 2.2860282218423644 | validation: 2.03107759953735]
	TIME [epoch: 24.8 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2649717851590463		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 2.2649717851590463 | validation: 2.0355871357257103]
	TIME [epoch: 24.8 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2823582318444267		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 2.2823582318444267 | validation: 2.02687458499414]
	TIME [epoch: 24.8 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2677826648831267		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 2.2677826648831267 | validation: 2.0298978728373]
	TIME [epoch: 24.8 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2669781068881334		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 2.2669781068881334 | validation: 2.0233909623448394]
	TIME [epoch: 24.7 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.265099990417461		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 2.265099990417461 | validation: 2.02336860675912]
	TIME [epoch: 24.8 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2690565491175243		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 2.2690565491175243 | validation: 2.023430500607524]
	TIME [epoch: 24.8 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.270316123492704		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 2.270316123492704 | validation: 2.0274729770889257]
	TIME [epoch: 24.8 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2729768468254195		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 2.2729768468254195 | validation: 2.03955537828517]
	TIME [epoch: 24.8 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2692981099752547		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 2.2692981099752547 | validation: 2.025432015634148]
	TIME [epoch: 24.8 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.26793203681518		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 2.26793203681518 | validation: 2.0285326214319794]
	TIME [epoch: 24.7 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2668861751899425		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 2.2668861751899425 | validation: 2.0301942294214337]
	TIME [epoch: 24.8 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.268157309130316		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 2.268157309130316 | validation: 2.0200700296995873]
	TIME [epoch: 24.8 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2813542605672046		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 2.2813542605672046 | validation: 2.0289306675460126]
	TIME [epoch: 24.7 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.264733463882543		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 2.264733463882543 | validation: 2.0301229348339076]
	TIME [epoch: 24.7 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.264285867054679		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 2.264285867054679 | validation: 2.0135682147383034]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_1180.pth
	Model improved!!!
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.266317464276316		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 2.266317464276316 | validation: 2.0281007216003877]
	TIME [epoch: 24.8 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2744883694006863		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 2.2744883694006863 | validation: 2.0295448126714204]
	TIME [epoch: 24.8 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.270689471860898		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 2.270689471860898 | validation: 2.023985204457479]
	TIME [epoch: 24.8 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2652695631489785		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 2.2652695631489785 | validation: 2.037516267065837]
	TIME [epoch: 24.8 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2686125273066775		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 2.2686125273066775 | validation: 2.034828587419099]
	TIME [epoch: 24.8 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.26669892396765		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 2.26669892396765 | validation: 2.022151111350262]
	TIME [epoch: 24.8 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.267676457395015		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 2.267676457395015 | validation: 2.0198453511955075]
	TIME [epoch: 24.7 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2709868380620977		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 2.2709868380620977 | validation: 2.031783240162347]
	TIME [epoch: 24.8 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2748885550812132		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 2.2748885550812132 | validation: 2.0296402228405572]
	TIME [epoch: 24.8 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2691052989252123		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 2.2691052989252123 | validation: 2.0197449741902576]
	TIME [epoch: 24.7 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.265112708715171		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 2.265112708715171 | validation: 2.02358589223709]
	TIME [epoch: 24.8 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.266239030339485		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 2.266239030339485 | validation: 2.0147903708413004]
	TIME [epoch: 24.8 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.267353871504453		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 2.267353871504453 | validation: 2.0262091686465253]
	TIME [epoch: 24.7 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2613677537770083		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 2.2613677537770083 | validation: 2.0244362721914686]
	TIME [epoch: 24.7 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2671522534424238		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 2.2671522534424238 | validation: 2.020087369560033]
	TIME [epoch: 24.8 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2752193224405315		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 2.2752193224405315 | validation: 2.0454700417862024]
	TIME [epoch: 24.7 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.281205457448039		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 2.281205457448039 | validation: 2.033685089973508]
	TIME [epoch: 24.8 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2666461154950315		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 2.2666461154950315 | validation: 2.033621845518009]
	TIME [epoch: 24.7 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2752310765242		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 2.2752310765242 | validation: 2.0508498592276134]
	TIME [epoch: 24.7 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2784614768386304		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 2.2784614768386304 | validation: 2.0320549082285417]
	TIME [epoch: 24.7 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2680526291549445		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 2.2680526291549445 | validation: 2.025750960713324]
	TIME [epoch: 24.8 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2698556861844845		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 2.2698556861844845 | validation: 2.01725252613453]
	TIME [epoch: 24.7 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2661657160255357		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 2.2661657160255357 | validation: 2.028201979427032]
	TIME [epoch: 24.7 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.265511109374697		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 2.265511109374697 | validation: 2.021580905475178]
	TIME [epoch: 24.8 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.270455731843117		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 2.270455731843117 | validation: 2.0428109169221016]
	TIME [epoch: 24.8 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2841808877195313		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 2.2841808877195313 | validation: 2.0257360479938264]
	TIME [epoch: 24.7 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2667936323872935		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 2.2667936323872935 | validation: 2.033082831079231]
	TIME [epoch: 24.7 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2772876709930405		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 2.2772876709930405 | validation: 2.0339191116681175]
	TIME [epoch: 24.7 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2695636670018065		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 2.2695636670018065 | validation: 2.0308930540729437]
	TIME [epoch: 24.8 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.274778785801538		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 2.274778785801538 | validation: 2.0336090181063264]
	TIME [epoch: 24.8 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2811891708845726		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 2.2811891708845726 | validation: 2.0381694786695657]
	TIME [epoch: 24.7 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.278521144756388		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 2.278521144756388 | validation: 2.0899754334647507]
	TIME [epoch: 24.8 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.300386455683588		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 2.300386455683588 | validation: 2.0330556618675315]
	TIME [epoch: 24.8 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2703179064889145		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 2.2703179064889145 | validation: 2.047393794589037]
	TIME [epoch: 24.8 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2927293394111485		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 2.2927293394111485 | validation: 2.046899878295397]
	TIME [epoch: 24.8 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.267926227175824		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 2.267926227175824 | validation: 2.0303735887066785]
	TIME [epoch: 24.7 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2685257077931924		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 2.2685257077931924 | validation: 2.0233484633026952]
	TIME [epoch: 24.7 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.277295264882213		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 2.277295264882213 | validation: 2.0595889888145393]
	TIME [epoch: 24.7 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.275440104144733		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 2.275440104144733 | validation: 2.0315378161501907]
	TIME [epoch: 24.8 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.285713259663314		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 2.285713259663314 | validation: 2.036627439707483]
	TIME [epoch: 24.8 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.265578602656097		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 2.265578602656097 | validation: 2.033001980186542]
	TIME [epoch: 24.8 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2591905652430526		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 2.2591905652430526 | validation: 2.0239496908306274]
	TIME [epoch: 24.7 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2741525037444		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 2.2741525037444 | validation: 2.0294145101279235]
	TIME [epoch: 24.8 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.269347328381503		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 2.269347328381503 | validation: 2.0265713668909666]
	TIME [epoch: 24.8 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.264559708833056		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 2.264559708833056 | validation: 2.026897226985151]
	TIME [epoch: 24.7 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2664204478997374		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 2.2664204478997374 | validation: 2.031264432510162]
	TIME [epoch: 24.7 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.273990050926879		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 2.273990050926879 | validation: 2.0253278911555466]
	TIME [epoch: 24.8 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2787426144139156		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 2.2787426144139156 | validation: 2.0500164720666705]
	TIME [epoch: 24.8 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2732223151279047		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 2.2732223151279047 | validation: 2.0221815992272174]
	TIME [epoch: 24.7 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2651311144681645		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 2.2651311144681645 | validation: 2.0245776080623377]
	TIME [epoch: 24.8 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.266765512904546		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 2.266765512904546 | validation: 2.0275338343034117]
	TIME [epoch: 24.7 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2688758789094288		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 2.2688758789094288 | validation: 2.0265564150976987]
	TIME [epoch: 24.8 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2734466513439964		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 2.2734466513439964 | validation: 2.0283565771773397]
	TIME [epoch: 24.8 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2731064048860423		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 2.2731064048860423 | validation: 2.0312950637445306]
	TIME [epoch: 24.8 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2679712152991542		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 2.2679712152991542 | validation: 2.0300156770302515]
	TIME [epoch: 24.7 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.282159441909074		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 2.282159441909074 | validation: 2.027378880701722]
	TIME [epoch: 24.8 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.269325779952539		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 2.269325779952539 | validation: 2.038869257605748]
	TIME [epoch: 24.7 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2755776129421186		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 2.2755776129421186 | validation: 2.036547848731674]
	TIME [epoch: 24.7 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2745359243730614		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 2.2745359243730614 | validation: 2.0272103413859406]
	TIME [epoch: 24.8 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.265672125571216		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 2.265672125571216 | validation: 2.0207069493683565]
	TIME [epoch: 24.7 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.262118036462211		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 2.262118036462211 | validation: 2.029155598087617]
	TIME [epoch: 24.7 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2667566989404735		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 2.2667566989404735 | validation: 2.02413746882761]
	TIME [epoch: 24.8 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.263110034512085		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 2.263110034512085 | validation: 2.0218743981467497]
	TIME [epoch: 24.7 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.272227706951527		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 2.272227706951527 | validation: 2.0346134299976577]
	TIME [epoch: 24.8 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.268970779884504		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 2.268970779884504 | validation: 2.025122801146897]
	TIME [epoch: 24.8 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2716529214855457		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 2.2716529214855457 | validation: 2.0189331920669242]
	TIME [epoch: 24.7 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2649151579116853		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 2.2649151579116853 | validation: 2.0355887650938618]
	TIME [epoch: 24.7 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.264028259127508		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 2.264028259127508 | validation: 2.0285036933850757]
	TIME [epoch: 24.8 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2712716293364243		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 2.2712716293364243 | validation: 2.027235146346655]
	TIME [epoch: 24.8 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.269941285310404		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 2.269941285310404 | validation: 2.030152648438613]
	TIME [epoch: 24.8 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2710287796344035		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 2.2710287796344035 | validation: 2.0267259676886584]
	TIME [epoch: 24.8 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.267243955522545		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 2.267243955522545 | validation: 2.02629808375443]
	TIME [epoch: 24.8 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2684279509893943		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 2.2684279509893943 | validation: 2.021346122188954]
	TIME [epoch: 24.8 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.261660336782891		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 2.261660336782891 | validation: 2.031973183106948]
	TIME [epoch: 24.8 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2682912779176525		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 2.2682912779176525 | validation: 2.020845890592505]
	TIME [epoch: 24.7 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2609712427328765		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 2.2609712427328765 | validation: 2.0215551512024303]
	TIME [epoch: 24.8 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.266612490576345		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 2.266612490576345 | validation: 2.0233673539599555]
	TIME [epoch: 24.8 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2612457362942213		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 2.2612457362942213 | validation: 2.030762215988153]
	TIME [epoch: 24.8 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2632928290981327		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 2.2632928290981327 | validation: 2.0226964725258307]
	TIME [epoch: 24.8 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.261992403772402		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 2.261992403772402 | validation: 2.0216010225542345]
	TIME [epoch: 24.8 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2734707340176046		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 2.2734707340176046 | validation: 2.0413565561397906]
	TIME [epoch: 24.7 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2824811047192064		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 2.2824811047192064 | validation: 2.0249276259204096]
	TIME [epoch: 24.7 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2662030701361813		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 2.2662030701361813 | validation: 2.0360538530201984]
	TIME [epoch: 24.8 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2787229473682706		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 2.2787229473682706 | validation: 2.0328787159301043]
	TIME [epoch: 24.8 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2680413145448783		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 2.2680413145448783 | validation: 2.0281044280026386]
	TIME [epoch: 24.8 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.271597187594942		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 2.271597187594942 | validation: 2.019432352331242]
	TIME [epoch: 24.8 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2691935783310693		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 2.2691935783310693 | validation: 2.019451925188245]
	TIME [epoch: 24.7 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2697316757179213		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 2.2697316757179213 | validation: 2.042802975220922]
	TIME [epoch: 24.7 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2737713131437793		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 2.2737713131437793 | validation: 2.019930082747276]
	TIME [epoch: 24.7 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2613144713904476		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 2.2613144713904476 | validation: 2.0132616919399693]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_1270.pth
	Model improved!!!
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.27157111776681		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 2.27157111776681 | validation: 2.0294508430793794]
	TIME [epoch: 24.8 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.265187682125629		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 2.265187682125629 | validation: 2.021033529755117]
	TIME [epoch: 24.8 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.266786551049387		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 2.266786551049387 | validation: 2.0190021383153596]
	TIME [epoch: 24.8 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2637783779571006		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 2.2637783779571006 | validation: 2.016549629846846]
	TIME [epoch: 24.8 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2681606397944325		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 2.2681606397944325 | validation: 2.0292279531537747]
	TIME [epoch: 24.7 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2637254644930485		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 2.2637254644930485 | validation: 2.025716224213099]
	TIME [epoch: 24.7 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2671100383074383		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 2.2671100383074383 | validation: 2.021164338649003]
	TIME [epoch: 24.7 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.260737200031592		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 2.260737200031592 | validation: 2.027281452042973]
	TIME [epoch: 24.8 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2637806148589528		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 2.2637806148589528 | validation: 2.0251161581375605]
	TIME [epoch: 24.7 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2715273674630176		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 2.2715273674630176 | validation: 2.0250126733796967]
	TIME [epoch: 24.8 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2637051147536043		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 2.2637051147536043 | validation: 2.0224688980844503]
	TIME [epoch: 24.8 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.270089593497609		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 2.270089593497609 | validation: 2.0286336942348937]
	TIME [epoch: 24.7 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.271341042143277		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 2.271341042143277 | validation: 2.0282551575372354]
	TIME [epoch: 24.8 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.268628254220263		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 2.268628254220263 | validation: 2.0241931057609497]
	TIME [epoch: 24.8 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2674446218407995		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 2.2674446218407995 | validation: 2.0183088373829343]
	TIME [epoch: 24.8 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.269380103867725		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 2.269380103867725 | validation: 2.0225043769009834]
	TIME [epoch: 24.8 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2716204775066746		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 2.2716204775066746 | validation: 2.016366960441441]
	TIME [epoch: 24.8 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.26368372028118		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 2.26368372028118 | validation: 2.014961508466641]
	TIME [epoch: 24.8 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2631391067344695		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 2.2631391067344695 | validation: 2.027354662570742]
	TIME [epoch: 24.8 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.269242748436659		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 2.269242748436659 | validation: 2.018355630181238]
	TIME [epoch: 24.8 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2641399958706305		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 2.2641399958706305 | validation: 2.018755322040443]
	TIME [epoch: 24.8 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2664599052415135		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 2.2664599052415135 | validation: 2.0402839013933884]
	TIME [epoch: 24.8 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2709649238624596		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 2.2709649238624596 | validation: 2.0274819094596204]
	TIME [epoch: 24.8 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.263695916711801		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 2.263695916711801 | validation: 2.01546105135195]
	TIME [epoch: 24.7 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2641619209627986		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 2.2641619209627986 | validation: 2.0249980510810777]
	TIME [epoch: 24.8 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2641599001879356		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 2.2641599001879356 | validation: 2.0146961376817525]
	TIME [epoch: 24.8 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2632195763698046		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 2.2632195763698046 | validation: 2.017545939645637]
	TIME [epoch: 24.7 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2573270948643733		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 2.2573270948643733 | validation: 2.028145285165702]
	TIME [epoch: 24.8 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.262280269778238		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 2.262280269778238 | validation: 2.022048012570424]
	TIME [epoch: 24.8 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2644160471436097		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 2.2644160471436097 | validation: 2.023554390750909]
	TIME [epoch: 24.7 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2703919556704326		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 2.2703919556704326 | validation: 2.030636841981875]
	TIME [epoch: 24.8 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.26967129371741		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 2.26967129371741 | validation: 2.025626007646531]
	TIME [epoch: 24.7 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.274195383821162		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 2.274195383821162 | validation: 2.0396037258074826]
	TIME [epoch: 24.7 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.273446402465477		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 2.273446402465477 | validation: 2.0198549408821203]
	TIME [epoch: 24.8 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.26923028735315		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 2.26923028735315 | validation: 2.0285737143345415]
	TIME [epoch: 24.8 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.264379617644254		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 2.264379617644254 | validation: 2.0187319677615614]
	TIME [epoch: 24.7 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.262339660337006		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 2.262339660337006 | validation: 2.013911781179721]
	TIME [epoch: 24.8 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2633813252300996		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 2.2633813252300996 | validation: 2.024185930742026]
	TIME [epoch: 24.8 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2639427022895666		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 2.2639427022895666 | validation: 2.020264941185287]
	TIME [epoch: 24.7 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2660123135589725		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 2.2660123135589725 | validation: 2.022496591065577]
	TIME [epoch: 24.8 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2633999749855005		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 2.2633999749855005 | validation: 2.010550017016991]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240310_051929/states/model_tr_study205_1311.pth
	Model improved!!!
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.258850670708756		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 2.258850670708756 | validation: 2.0292927293365026]
	TIME [epoch: 24.8 sec]
EPOCH 1313/2000:
	Training over batches...
